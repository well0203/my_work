{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No Patching](#3-no-patching)\n",
    "- [4. Time series decomposition](#4-ts-decomposition)\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_lens = [512, 512, 336, 168, 168]\n",
    "\n",
    "model = \"PatchTST\"\n",
    "loss = \"MSE\"\n",
    "itr=1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1222990\n",
      "\tspeed: 0.0613s/iter; left time: 1365.9819s\n",
      "\titers: 200, epoch: 1 | loss: 0.1122023\n",
      "\tspeed: 0.0312s/iter; left time: 693.7261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.1267766 Vali Loss: 0.0935439 Test Loss: 0.0950520\n",
      "Validation loss decreased (inf --> 0.093544).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0419376\n",
      "\tspeed: 0.0607s/iter; left time: 1339.2066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0284766\n",
      "\tspeed: 0.0316s/iter; left time: 694.4481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0480114 Vali Loss: 0.0276108 Test Loss: 0.0294567\n",
      "Validation loss decreased (0.093544 --> 0.027611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0220861\n",
      "\tspeed: 0.0613s/iter; left time: 1338.8868s\n",
      "\titers: 200, epoch: 3 | loss: 0.0211231\n",
      "\tspeed: 0.0317s/iter; left time: 690.3014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 224 | Train Loss: 0.0230827 Vali Loss: 0.0250716 Test Loss: 0.0266407\n",
      "Validation loss decreased (0.027611 --> 0.025072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0220476\n",
      "\tspeed: 0.0602s/iter; left time: 1301.6703s\n",
      "\titers: 200, epoch: 4 | loss: 0.0232012\n",
      "\tspeed: 0.0317s/iter; left time: 682.4173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0197940 Vali Loss: 0.0232434 Test Loss: 0.0251538\n",
      "Validation loss decreased (0.025072 --> 0.023243).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0189569\n",
      "\tspeed: 0.0614s/iter; left time: 1314.2460s\n",
      "\titers: 200, epoch: 5 | loss: 0.0175613\n",
      "\tspeed: 0.0324s/iter; left time: 689.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0180648 Vali Loss: 0.0219851 Test Loss: 0.0238013\n",
      "Validation loss decreased (0.023243 --> 0.021985).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0212432\n",
      "\tspeed: 0.0611s/iter; left time: 1294.1797s\n",
      "\titers: 200, epoch: 6 | loss: 0.0167787\n",
      "\tspeed: 0.0318s/iter; left time: 670.6090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0171204 Vali Loss: 0.0217660 Test Loss: 0.0235090\n",
      "Validation loss decreased (0.021985 --> 0.021766).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0163779\n",
      "\tspeed: 0.0619s/iter; left time: 1296.7421s\n",
      "\titers: 200, epoch: 7 | loss: 0.0178758\n",
      "\tspeed: 0.0320s/iter; left time: 667.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0164427 Vali Loss: 0.0213234 Test Loss: 0.0231106\n",
      "Validation loss decreased (0.021766 --> 0.021323).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0153116\n",
      "\tspeed: 0.0618s/iter; left time: 1281.3828s\n",
      "\titers: 200, epoch: 8 | loss: 0.0156371\n",
      "\tspeed: 0.0318s/iter; left time: 657.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0160626 Vali Loss: 0.0215641 Test Loss: 0.0235629\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0175868\n",
      "\tspeed: 0.0613s/iter; left time: 1257.8290s\n",
      "\titers: 200, epoch: 9 | loss: 0.0172233\n",
      "\tspeed: 0.0321s/iter; left time: 655.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0157584 Vali Loss: 0.0211341 Test Loss: 0.0230975\n",
      "Validation loss decreased (0.021323 --> 0.021134).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0164381\n",
      "\tspeed: 0.0615s/iter; left time: 1247.0120s\n",
      "\titers: 200, epoch: 10 | loss: 0.0152910\n",
      "\tspeed: 0.0320s/iter; left time: 645.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0154029 Vali Loss: 0.0212651 Test Loss: 0.0235113\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0129175\n",
      "\tspeed: 0.0606s/iter; left time: 1215.8429s\n",
      "\titers: 200, epoch: 11 | loss: 0.0147491\n",
      "\tspeed: 0.0321s/iter; left time: 640.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 224 | Train Loss: 0.0152441 Vali Loss: 0.0207131 Test Loss: 0.0226023\n",
      "Validation loss decreased (0.021134 --> 0.020713).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0151582\n",
      "\tspeed: 0.0617s/iter; left time: 1223.1939s\n",
      "\titers: 200, epoch: 12 | loss: 0.0152677\n",
      "\tspeed: 0.0321s/iter; left time: 633.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0150385 Vali Loss: 0.0210057 Test Loss: 0.0228386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0136673\n",
      "\tspeed: 0.0604s/iter; left time: 1185.0591s\n",
      "\titers: 200, epoch: 13 | loss: 0.0141618\n",
      "\tspeed: 0.0330s/iter; left time: 643.2613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0149006 Vali Loss: 0.0205923 Test Loss: 0.0225011\n",
      "Validation loss decreased (0.020713 --> 0.020592).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0141812\n",
      "\tspeed: 0.0610s/iter; left time: 1182.7181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0148937\n",
      "\tspeed: 0.0321s/iter; left time: 618.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0147474 Vali Loss: 0.0204325 Test Loss: 0.0223470\n",
      "Validation loss decreased (0.020592 --> 0.020433).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0142198\n",
      "\tspeed: 0.0626s/iter; left time: 1199.0431s\n",
      "\titers: 200, epoch: 15 | loss: 0.0126263\n",
      "\tspeed: 0.0321s/iter; left time: 612.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0146567 Vali Loss: 0.0203714 Test Loss: 0.0223274\n",
      "Validation loss decreased (0.020433 --> 0.020371).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0147880\n",
      "\tspeed: 0.0618s/iter; left time: 1170.3107s\n",
      "\titers: 200, epoch: 16 | loss: 0.0144410\n",
      "\tspeed: 0.0323s/iter; left time: 608.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0146212 Vali Loss: 0.0207287 Test Loss: 0.0225603\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0148663\n",
      "\tspeed: 0.0618s/iter; left time: 1157.2427s\n",
      "\titers: 200, epoch: 17 | loss: 0.0141908\n",
      "\tspeed: 0.0322s/iter; left time: 599.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0144554 Vali Loss: 0.0202148 Test Loss: 0.0221464\n",
      "Validation loss decreased (0.020371 --> 0.020215).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0148504\n",
      "\tspeed: 0.0634s/iter; left time: 1173.1980s\n",
      "\titers: 200, epoch: 18 | loss: 0.0172588\n",
      "\tspeed: 0.0330s/iter; left time: 607.7259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0144195 Vali Loss: 0.0200641 Test Loss: 0.0218430\n",
      "Validation loss decreased (0.020215 --> 0.020064).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0126696\n",
      "\tspeed: 0.0628s/iter; left time: 1146.6626s\n",
      "\titers: 200, epoch: 19 | loss: 0.0133310\n",
      "\tspeed: 0.0325s/iter; left time: 591.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0143151 Vali Loss: 0.0205285 Test Loss: 0.0225459\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0141876\n",
      "\tspeed: 0.0620s/iter; left time: 1118.9593s\n",
      "\titers: 200, epoch: 20 | loss: 0.0154408\n",
      "\tspeed: 0.0325s/iter; left time: 582.6493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0142808 Vali Loss: 0.0203298 Test Loss: 0.0220595\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0120954\n",
      "\tspeed: 0.0624s/iter; left time: 1112.0831s\n",
      "\titers: 200, epoch: 21 | loss: 0.0147030\n",
      "\tspeed: 0.0325s/iter; left time: 575.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0142541 Vali Loss: 0.0202322 Test Loss: 0.0224036\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0121426\n",
      "\tspeed: 0.0614s/iter; left time: 1079.7388s\n",
      "\titers: 200, epoch: 22 | loss: 0.0135340\n",
      "\tspeed: 0.0337s/iter; left time: 589.0041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0141983 Vali Loss: 0.0201447 Test Loss: 0.0221023\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0145164\n",
      "\tspeed: 0.0613s/iter; left time: 1065.5831s\n",
      "\titers: 200, epoch: 23 | loss: 0.0128908\n",
      "\tspeed: 0.0324s/iter; left time: 559.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0141312 Vali Loss: 0.0203349 Test Loss: 0.0227068\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0137177\n",
      "\tspeed: 0.0605s/iter; left time: 1036.7531s\n",
      "\titers: 200, epoch: 24 | loss: 0.0136329\n",
      "\tspeed: 0.0320s/iter; left time: 545.3447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0140988 Vali Loss: 0.0202100 Test Loss: 0.0221388\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0139595\n",
      "\tspeed: 0.0582s/iter; left time: 985.3597s\n",
      "\titers: 200, epoch: 25 | loss: 0.0172756\n",
      "\tspeed: 0.0322s/iter; left time: 541.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0140711 Vali Loss: 0.0200398 Test Loss: 0.0219033\n",
      "Validation loss decreased (0.020064 --> 0.020040).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0137785\n",
      "\tspeed: 0.0594s/iter; left time: 991.2793s\n",
      "\titers: 200, epoch: 26 | loss: 0.0135769\n",
      "\tspeed: 0.0319s/iter; left time: 529.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 224 | Train Loss: 0.0140351 Vali Loss: 0.0200323 Test Loss: 0.0218325\n",
      "Validation loss decreased (0.020040 --> 0.020032).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0150175\n",
      "\tspeed: 0.0582s/iter; left time: 958.7707s\n",
      "\titers: 200, epoch: 27 | loss: 0.0154345\n",
      "\tspeed: 0.0323s/iter; left time: 529.1345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0139935 Vali Loss: 0.0199558 Test Loss: 0.0218374\n",
      "Validation loss decreased (0.020032 --> 0.019956).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0122481\n",
      "\tspeed: 0.0620s/iter; left time: 1008.3606s\n",
      "\titers: 200, epoch: 28 | loss: 0.0150768\n",
      "\tspeed: 0.0320s/iter; left time: 517.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0139888 Vali Loss: 0.0201497 Test Loss: 0.0222160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0144535\n",
      "\tspeed: 0.0578s/iter; left time: 926.5491s\n",
      "\titers: 200, epoch: 29 | loss: 0.0119596\n",
      "\tspeed: 0.0318s/iter; left time: 506.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 224 | Train Loss: 0.0139765 Vali Loss: 0.0200327 Test Loss: 0.0220907\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0161402\n",
      "\tspeed: 0.0594s/iter; left time: 938.5773s\n",
      "\titers: 200, epoch: 30 | loss: 0.0147173\n",
      "\tspeed: 0.0325s/iter; left time: 511.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0139347 Vali Loss: 0.0199370 Test Loss: 0.0221591\n",
      "Validation loss decreased (0.019956 --> 0.019937).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0135855\n",
      "\tspeed: 0.0615s/iter; left time: 957.6345s\n",
      "\titers: 200, epoch: 31 | loss: 0.0129211\n",
      "\tspeed: 0.0329s/iter; left time: 508.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0139453 Vali Loss: 0.0200089 Test Loss: 0.0217233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0130386\n",
      "\tspeed: 0.0644s/iter; left time: 988.5046s\n",
      "\titers: 200, epoch: 32 | loss: 0.0151058\n",
      "\tspeed: 0.0357s/iter; left time: 544.7457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0139052 Vali Loss: 0.0198388 Test Loss: 0.0217656\n",
      "Validation loss decreased (0.019937 --> 0.019839).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0151810\n",
      "\tspeed: 0.0651s/iter; left time: 985.8966s\n",
      "\titers: 200, epoch: 33 | loss: 0.0121507\n",
      "\tspeed: 0.0357s/iter; left time: 535.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0138984 Vali Loss: 0.0199295 Test Loss: 0.0219177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0138505\n",
      "\tspeed: 0.0660s/iter; left time: 983.3781s\n",
      "\titers: 200, epoch: 34 | loss: 0.0144497\n",
      "\tspeed: 0.0342s/iter; left time: 505.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0138961 Vali Loss: 0.0199464 Test Loss: 0.0218640\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0145499\n",
      "\tspeed: 0.0688s/iter; left time: 1010.8486s\n",
      "\titers: 200, epoch: 35 | loss: 0.0122951\n",
      "\tspeed: 0.0339s/iter; left time: 494.1309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0138513 Vali Loss: 0.0198913 Test Loss: 0.0217917\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0140391\n",
      "\tspeed: 0.0666s/iter; left time: 962.9506s\n",
      "\titers: 200, epoch: 36 | loss: 0.0156457\n",
      "\tspeed: 0.0347s/iter; left time: 497.6383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0138767 Vali Loss: 0.0201202 Test Loss: 0.0219720\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0174159\n",
      "\tspeed: 0.0648s/iter; left time: 923.0512s\n",
      "\titers: 200, epoch: 37 | loss: 0.0135666\n",
      "\tspeed: 0.0340s/iter; left time: 481.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0138484 Vali Loss: 0.0199732 Test Loss: 0.0218658\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0138687\n",
      "\tspeed: 0.0650s/iter; left time: 910.7446s\n",
      "\titers: 200, epoch: 38 | loss: 0.0129105\n",
      "\tspeed: 0.0345s/iter; left time: 479.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.0138696 Vali Loss: 0.0199889 Test Loss: 0.0218638\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0153570\n",
      "\tspeed: 0.0644s/iter; left time: 887.8654s\n",
      "\titers: 200, epoch: 39 | loss: 0.0127968\n",
      "\tspeed: 0.0344s/iter; left time: 470.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0138804 Vali Loss: 0.0198075 Test Loss: 0.0218017\n",
      "Validation loss decreased (0.019839 --> 0.019807).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0122012\n",
      "\tspeed: 0.0659s/iter; left time: 893.5174s\n",
      "\titers: 200, epoch: 40 | loss: 0.0156413\n",
      "\tspeed: 0.0365s/iter; left time: 490.9232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 224 | Train Loss: 0.0138368 Vali Loss: 0.0199014 Test Loss: 0.0218669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0124090\n",
      "\tspeed: 0.0655s/iter; left time: 873.6033s\n",
      "\titers: 200, epoch: 41 | loss: 0.0136367\n",
      "\tspeed: 0.0337s/iter; left time: 446.8212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0138275 Vali Loss: 0.0198964 Test Loss: 0.0220496\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0127942\n",
      "\tspeed: 0.0647s/iter; left time: 848.3028s\n",
      "\titers: 200, epoch: 42 | loss: 0.0153207\n",
      "\tspeed: 0.0347s/iter; left time: 452.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0138310 Vali Loss: 0.0199408 Test Loss: 0.0219102\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0150594\n",
      "\tspeed: 0.0666s/iter; left time: 858.7574s\n",
      "\titers: 200, epoch: 43 | loss: 0.0142191\n",
      "\tspeed: 0.0352s/iter; left time: 450.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.0138246 Vali Loss: 0.0199161 Test Loss: 0.0220573\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0119022\n",
      "\tspeed: 0.0658s/iter; left time: 833.1813s\n",
      "\titers: 200, epoch: 44 | loss: 0.0138348\n",
      "\tspeed: 0.0340s/iter; left time: 427.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0137990 Vali Loss: 0.0199644 Test Loss: 0.0219828\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0142369\n",
      "\tspeed: 0.0663s/iter; left time: 825.3889s\n",
      "\titers: 200, epoch: 45 | loss: 0.0147083\n",
      "\tspeed: 0.0339s/iter; left time: 418.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0138106 Vali Loss: 0.0199118 Test Loss: 0.0219210\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0138345\n",
      "\tspeed: 0.0656s/iter; left time: 802.0637s\n",
      "\titers: 200, epoch: 46 | loss: 0.0150223\n",
      "\tspeed: 0.0350s/iter; left time: 424.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0137858 Vali Loss: 0.0199091 Test Loss: 0.0218749\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0139790\n",
      "\tspeed: 0.0641s/iter; left time: 768.4079s\n",
      "\titers: 200, epoch: 47 | loss: 0.0130415\n",
      "\tspeed: 0.0349s/iter; left time: 415.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0137935 Vali Loss: 0.0199717 Test Loss: 0.0220268\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0148001\n",
      "\tspeed: 0.0634s/iter; left time: 746.6352s\n",
      "\titers: 200, epoch: 48 | loss: 0.0131510\n",
      "\tspeed: 0.0338s/iter; left time: 395.0902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0137964 Vali Loss: 0.0198949 Test Loss: 0.0219121\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0140426\n",
      "\tspeed: 0.0647s/iter; left time: 747.0507s\n",
      "\titers: 200, epoch: 49 | loss: 0.0147091\n",
      "\tspeed: 0.0333s/iter; left time: 381.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0137915 Vali Loss: 0.0198982 Test Loss: 0.0218868\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02180168777704239, rmse:0.1476539522409439, mae:0.09520922601222992, rse:0.5210912227630615\n",
      "Intermediate time for DE and pred_len 24: 00h:08m:00.96s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1211567\n",
      "\tspeed: 0.0795s/iter; left time: 1757.5864s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046408\n",
      "\tspeed: 0.0497s/iter; left time: 1094.2503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.60s\n",
      "Steps: 222 | Train Loss: 0.1242929 Vali Loss: 0.0921334 Test Loss: 0.0956747\n",
      "Validation loss decreased (inf --> 0.092133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0427316\n",
      "\tspeed: 0.0925s/iter; left time: 2024.8100s\n",
      "\titers: 200, epoch: 2 | loss: 0.0360543\n",
      "\tspeed: 0.0503s/iter; left time: 1095.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.50s\n",
      "Steps: 222 | Train Loss: 0.0495366 Vali Loss: 0.0375714 Test Loss: 0.0424508\n",
      "Validation loss decreased (0.092133 --> 0.037571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0282392\n",
      "\tspeed: 0.0945s/iter; left time: 2047.2490s\n",
      "\titers: 200, epoch: 3 | loss: 0.0292974\n",
      "\tspeed: 0.0500s/iter; left time: 1076.9347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 222 | Train Loss: 0.0303366 Vali Loss: 0.0345866 Test Loss: 0.0395371\n",
      "Validation loss decreased (0.037571 --> 0.034587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0250123\n",
      "\tspeed: 0.0925s/iter; left time: 1982.9671s\n",
      "\titers: 200, epoch: 4 | loss: 0.0266757\n",
      "\tspeed: 0.0508s/iter; left time: 1083.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.52s\n",
      "Steps: 222 | Train Loss: 0.0267789 Vali Loss: 0.0351737 Test Loss: 0.0422639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0277342\n",
      "\tspeed: 0.0912s/iter; left time: 1934.9650s\n",
      "\titers: 200, epoch: 5 | loss: 0.0253331\n",
      "\tspeed: 0.0500s/iter; left time: 1055.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 222 | Train Loss: 0.0252380 Vali Loss: 0.0339698 Test Loss: 0.0410371\n",
      "Validation loss decreased (0.034587 --> 0.033970).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0240003\n",
      "\tspeed: 0.0936s/iter; left time: 1964.8351s\n",
      "\titers: 200, epoch: 6 | loss: 0.0239523\n",
      "\tspeed: 0.0490s/iter; left time: 1023.7036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 222 | Train Loss: 0.0244408 Vali Loss: 0.0329343 Test Loss: 0.0393448\n",
      "Validation loss decreased (0.033970 --> 0.032934).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0246434\n",
      "\tspeed: 0.0935s/iter; left time: 1941.9605s\n",
      "\titers: 200, epoch: 7 | loss: 0.0262259\n",
      "\tspeed: 0.0501s/iter; left time: 1034.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.39s\n",
      "Steps: 222 | Train Loss: 0.0240215 Vali Loss: 0.0328176 Test Loss: 0.0386598\n",
      "Validation loss decreased (0.032934 --> 0.032818).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0231876\n",
      "\tspeed: 0.0922s/iter; left time: 1894.9070s\n",
      "\titers: 200, epoch: 8 | loss: 0.0238847\n",
      "\tspeed: 0.0501s/iter; left time: 1024.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 222 | Train Loss: 0.0236295 Vali Loss: 0.0320381 Test Loss: 0.0376855\n",
      "Validation loss decreased (0.032818 --> 0.032038).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0231493\n",
      "\tspeed: 0.0995s/iter; left time: 2022.9142s\n",
      "\titers: 200, epoch: 9 | loss: 0.0213140\n",
      "\tspeed: 0.0512s/iter; left time: 1036.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.70s\n",
      "Steps: 222 | Train Loss: 0.0233542 Vali Loss: 0.0310939 Test Loss: 0.0364179\n",
      "Validation loss decreased (0.032038 --> 0.031094).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0240150\n",
      "\tspeed: 0.0930s/iter; left time: 1869.0709s\n",
      "\titers: 200, epoch: 10 | loss: 0.0250064\n",
      "\tspeed: 0.0492s/iter; left time: 985.1227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 222 | Train Loss: 0.0230431 Vali Loss: 0.0318775 Test Loss: 0.0378130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0221963\n",
      "\tspeed: 0.0931s/iter; left time: 1851.7991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0231455\n",
      "\tspeed: 0.0516s/iter; left time: 1020.6763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.53s\n",
      "Steps: 222 | Train Loss: 0.0229509 Vali Loss: 0.0310655 Test Loss: 0.0365913\n",
      "Validation loss decreased (0.031094 --> 0.031065).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0235978\n",
      "\tspeed: 0.0920s/iter; left time: 1808.2538s\n",
      "\titers: 200, epoch: 12 | loss: 0.0198639\n",
      "\tspeed: 0.0506s/iter; left time: 988.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 222 | Train Loss: 0.0227393 Vali Loss: 0.0312596 Test Loss: 0.0370144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0211119\n",
      "\tspeed: 0.0918s/iter; left time: 1783.4331s\n",
      "\titers: 200, epoch: 13 | loss: 0.0218012\n",
      "\tspeed: 0.0493s/iter; left time: 952.4029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 222 | Train Loss: 0.0226356 Vali Loss: 0.0310768 Test Loss: 0.0369859\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0216071\n",
      "\tspeed: 0.0907s/iter; left time: 1743.7480s\n",
      "\titers: 200, epoch: 14 | loss: 0.0224764\n",
      "\tspeed: 0.0493s/iter; left time: 942.5669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0224288 Vali Loss: 0.0311917 Test Loss: 0.0372712\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0242154\n",
      "\tspeed: 0.0918s/iter; left time: 1742.9386s\n",
      "\titers: 200, epoch: 15 | loss: 0.0240646\n",
      "\tspeed: 0.0489s/iter; left time: 924.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0224298 Vali Loss: 0.0313455 Test Loss: 0.0377980\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0246799\n",
      "\tspeed: 0.0916s/iter; left time: 1719.4874s\n",
      "\titers: 200, epoch: 16 | loss: 0.0186449\n",
      "\tspeed: 0.0502s/iter; left time: 936.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 222 | Train Loss: 0.0222451 Vali Loss: 0.0310605 Test Loss: 0.0372748\n",
      "Validation loss decreased (0.031065 --> 0.031061).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0223297\n",
      "\tspeed: 0.0910s/iter; left time: 1687.8289s\n",
      "\titers: 200, epoch: 17 | loss: 0.0224854\n",
      "\tspeed: 0.0510s/iter; left time: 941.3186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0221587 Vali Loss: 0.0311874 Test Loss: 0.0372214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0234007\n",
      "\tspeed: 0.0929s/iter; left time: 1703.3257s\n",
      "\titers: 200, epoch: 18 | loss: 0.0206719\n",
      "\tspeed: 0.0505s/iter; left time: 920.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 222 | Train Loss: 0.0221142 Vali Loss: 0.0305699 Test Loss: 0.0367941\n",
      "Validation loss decreased (0.031061 --> 0.030570).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0215925\n",
      "\tspeed: 0.0941s/iter; left time: 1703.7624s\n",
      "\titers: 200, epoch: 19 | loss: 0.0215316\n",
      "\tspeed: 0.0504s/iter; left time: 907.3937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.63s\n",
      "Steps: 222 | Train Loss: 0.0219753 Vali Loss: 0.0307330 Test Loss: 0.0371570\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0211730\n",
      "\tspeed: 0.0966s/iter; left time: 1727.7496s\n",
      "\titers: 200, epoch: 20 | loss: 0.0200390\n",
      "\tspeed: 0.0491s/iter; left time: 872.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.38s\n",
      "Steps: 222 | Train Loss: 0.0218705 Vali Loss: 0.0308751 Test Loss: 0.0372903\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0211775\n",
      "\tspeed: 0.0909s/iter; left time: 1604.8162s\n",
      "\titers: 200, epoch: 21 | loss: 0.0211960\n",
      "\tspeed: 0.0496s/iter; left time: 871.0781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.31s\n",
      "Steps: 222 | Train Loss: 0.0218680 Vali Loss: 0.0309477 Test Loss: 0.0376379\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0190556\n",
      "\tspeed: 0.0917s/iter; left time: 1598.8915s\n",
      "\titers: 200, epoch: 22 | loss: 0.0211424\n",
      "\tspeed: 0.0499s/iter; left time: 865.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 222 | Train Loss: 0.0218106 Vali Loss: 0.0301766 Test Loss: 0.0363203\n",
      "Validation loss decreased (0.030570 --> 0.030177).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0218515\n",
      "\tspeed: 0.0932s/iter; left time: 1605.3351s\n",
      "\titers: 200, epoch: 23 | loss: 0.0205890\n",
      "\tspeed: 0.0493s/iter; left time: 843.1417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.39s\n",
      "Steps: 222 | Train Loss: 0.0217329 Vali Loss: 0.0304868 Test Loss: 0.0365636\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0217730\n",
      "\tspeed: 0.0908s/iter; left time: 1542.4728s\n",
      "\titers: 200, epoch: 24 | loss: 0.0215464\n",
      "\tspeed: 0.0504s/iter; left time: 851.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.38s\n",
      "Steps: 222 | Train Loss: 0.0216485 Vali Loss: 0.0305330 Test Loss: 0.0369576\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0208029\n",
      "\tspeed: 0.0904s/iter; left time: 1516.2784s\n",
      "\titers: 200, epoch: 25 | loss: 0.0230684\n",
      "\tspeed: 0.0489s/iter; left time: 815.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0216396 Vali Loss: 0.0307227 Test Loss: 0.0374036\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0216803\n",
      "\tspeed: 0.0894s/iter; left time: 1479.2788s\n",
      "\titers: 200, epoch: 26 | loss: 0.0221263\n",
      "\tspeed: 0.0510s/iter; left time: 838.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 222 | Train Loss: 0.0216196 Vali Loss: 0.0304883 Test Loss: 0.0369750\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0219150\n",
      "\tspeed: 0.0909s/iter; left time: 1484.9353s\n",
      "\titers: 200, epoch: 27 | loss: 0.0205100\n",
      "\tspeed: 0.0509s/iter; left time: 826.7998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 222 | Train Loss: 0.0215644 Vali Loss: 0.0305989 Test Loss: 0.0369882\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0214528\n",
      "\tspeed: 0.0921s/iter; left time: 1483.0199s\n",
      "\titers: 200, epoch: 28 | loss: 0.0225728\n",
      "\tspeed: 0.0505s/iter; left time: 808.7824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.43s\n",
      "Steps: 222 | Train Loss: 0.0215246 Vali Loss: 0.0305688 Test Loss: 0.0372255\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0228054\n",
      "\tspeed: 0.0979s/iter; left time: 1555.4951s\n",
      "\titers: 200, epoch: 29 | loss: 0.0198161\n",
      "\tspeed: 0.0509s/iter; left time: 803.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.65s\n",
      "Steps: 222 | Train Loss: 0.0214989 Vali Loss: 0.0308266 Test Loss: 0.0376735\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0225791\n",
      "\tspeed: 0.0898s/iter; left time: 1406.4823s\n",
      "\titers: 200, epoch: 30 | loss: 0.0206602\n",
      "\tspeed: 0.0501s/iter; left time: 779.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0214766 Vali Loss: 0.0305522 Test Loss: 0.0371724\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0220604\n",
      "\tspeed: 0.0937s/iter; left time: 1446.7781s\n",
      "\titers: 200, epoch: 31 | loss: 0.0228703\n",
      "\tspeed: 0.0486s/iter; left time: 745.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.25s\n",
      "Steps: 222 | Train Loss: 0.0214585 Vali Loss: 0.0305483 Test Loss: 0.0373443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0206055\n",
      "\tspeed: 0.0893s/iter; left time: 1359.1688s\n",
      "\titers: 200, epoch: 32 | loss: 0.0194962\n",
      "\tspeed: 0.0502s/iter; left time: 758.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.27s\n",
      "Steps: 222 | Train Loss: 0.0214005 Vali Loss: 0.0306938 Test Loss: 0.0374660\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0363202802836895, rmse:0.19057880342006683, mae:0.1305510699748993, rse:0.6748781204223633\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:48.74s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1201970\n",
      "\tspeed: 0.0648s/iter; left time: 1431.4377s\n",
      "\titers: 200, epoch: 1 | loss: 0.1105937\n",
      "\tspeed: 0.0497s/iter; left time: 1092.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.73s\n",
      "Steps: 222 | Train Loss: 0.1248253 Vali Loss: 0.0926596 Test Loss: 0.0964285\n",
      "Validation loss decreased (inf --> 0.092660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0401608\n",
      "\tspeed: 0.1001s/iter; left time: 2190.7127s\n",
      "\titers: 200, epoch: 2 | loss: 0.0348200\n",
      "\tspeed: 0.0507s/iter; left time: 1104.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.61s\n",
      "Steps: 222 | Train Loss: 0.0505578 Vali Loss: 0.0382297 Test Loss: 0.0440547\n",
      "Validation loss decreased (0.092660 --> 0.038230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0341885\n",
      "\tspeed: 0.0972s/iter; left time: 2105.0437s\n",
      "\titers: 200, epoch: 3 | loss: 0.0301632\n",
      "\tspeed: 0.0497s/iter; left time: 1072.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.60s\n",
      "Steps: 222 | Train Loss: 0.0315709 Vali Loss: 0.0371159 Test Loss: 0.0438923\n",
      "Validation loss decreased (0.038230 --> 0.037116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0303969\n",
      "\tspeed: 0.1027s/iter; left time: 2201.9701s\n",
      "\titers: 200, epoch: 4 | loss: 0.0268241\n",
      "\tspeed: 0.0523s/iter; left time: 1115.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.72s\n",
      "Steps: 222 | Train Loss: 0.0282432 Vali Loss: 0.0384147 Test Loss: 0.0474597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0252197\n",
      "\tspeed: 0.0941s/iter; left time: 1995.4230s\n",
      "\titers: 200, epoch: 5 | loss: 0.0290112\n",
      "\tspeed: 0.0495s/iter; left time: 1044.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.48s\n",
      "Steps: 222 | Train Loss: 0.0270696 Vali Loss: 0.0356162 Test Loss: 0.0434251\n",
      "Validation loss decreased (0.037116 --> 0.035616).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0258138\n",
      "\tspeed: 0.0957s/iter; left time: 2008.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0258394\n",
      "\tspeed: 0.0503s/iter; left time: 1051.2614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.53s\n",
      "Steps: 222 | Train Loss: 0.0261948 Vali Loss: 0.0369859 Test Loss: 0.0446513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0253084\n",
      "\tspeed: 0.0927s/iter; left time: 1924.9626s\n",
      "\titers: 200, epoch: 7 | loss: 0.0254496\n",
      "\tspeed: 0.0508s/iter; left time: 1050.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.48s\n",
      "Steps: 222 | Train Loss: 0.0256539 Vali Loss: 0.0347947 Test Loss: 0.0414930\n",
      "Validation loss decreased (0.035616 --> 0.034795).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0247787\n",
      "\tspeed: 0.0940s/iter; left time: 1931.9962s\n",
      "\titers: 200, epoch: 8 | loss: 0.0252390\n",
      "\tspeed: 0.0504s/iter; left time: 1029.7618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.46s\n",
      "Steps: 222 | Train Loss: 0.0252846 Vali Loss: 0.0341283 Test Loss: 0.0409065\n",
      "Validation loss decreased (0.034795 --> 0.034128).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0245752\n",
      "\tspeed: 0.0928s/iter; left time: 1886.6479s\n",
      "\titers: 200, epoch: 9 | loss: 0.0251687\n",
      "\tspeed: 0.0501s/iter; left time: 1013.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 222 | Train Loss: 0.0250233 Vali Loss: 0.0326594 Test Loss: 0.0391561\n",
      "Validation loss decreased (0.034128 --> 0.032659).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0240354\n",
      "\tspeed: 0.0925s/iter; left time: 1860.0336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0253937\n",
      "\tspeed: 0.0506s/iter; left time: 1012.6363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0247593 Vali Loss: 0.0332664 Test Loss: 0.0404661\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0261423\n",
      "\tspeed: 0.0922s/iter; left time: 1833.5847s\n",
      "\titers: 200, epoch: 11 | loss: 0.0256753\n",
      "\tspeed: 0.0497s/iter; left time: 983.4680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.36s\n",
      "Steps: 222 | Train Loss: 0.0245814 Vali Loss: 0.0325092 Test Loss: 0.0393523\n",
      "Validation loss decreased (0.032659 --> 0.032509).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0264353\n",
      "\tspeed: 0.0940s/iter; left time: 1848.8127s\n",
      "\titers: 200, epoch: 12 | loss: 0.0250716\n",
      "\tspeed: 0.0505s/iter; left time: 988.4411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.50s\n",
      "Steps: 222 | Train Loss: 0.0244160 Vali Loss: 0.0331964 Test Loss: 0.0405376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0224045\n",
      "\tspeed: 0.0980s/iter; left time: 1905.0400s\n",
      "\titers: 200, epoch: 13 | loss: 0.0240942\n",
      "\tspeed: 0.0500s/iter; left time: 966.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.38s\n",
      "Steps: 222 | Train Loss: 0.0241919 Vali Loss: 0.0327617 Test Loss: 0.0397237\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0224042\n",
      "\tspeed: 0.0930s/iter; left time: 1787.1382s\n",
      "\titers: 200, epoch: 14 | loss: 0.0228675\n",
      "\tspeed: 0.0511s/iter; left time: 977.4657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 222 | Train Loss: 0.0240532 Vali Loss: 0.0325049 Test Loss: 0.0400462\n",
      "Validation loss decreased (0.032509 --> 0.032505).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0224264\n",
      "\tspeed: 0.0981s/iter; left time: 1864.0594s\n",
      "\titers: 200, epoch: 15 | loss: 0.0239447\n",
      "\tspeed: 0.0517s/iter; left time: 975.9017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.59s\n",
      "Steps: 222 | Train Loss: 0.0238901 Vali Loss: 0.0326816 Test Loss: 0.0407697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0228343\n",
      "\tspeed: 0.0941s/iter; left time: 1766.4159s\n",
      "\titers: 200, epoch: 16 | loss: 0.0244847\n",
      "\tspeed: 0.0502s/iter; left time: 936.7524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.50s\n",
      "Steps: 222 | Train Loss: 0.0238586 Vali Loss: 0.0328233 Test Loss: 0.0409972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0249028\n",
      "\tspeed: 0.0937s/iter; left time: 1737.2823s\n",
      "\titers: 200, epoch: 17 | loss: 0.0245231\n",
      "\tspeed: 0.0498s/iter; left time: 918.8094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 222 | Train Loss: 0.0236727 Vali Loss: 0.0318149 Test Loss: 0.0389934\n",
      "Validation loss decreased (0.032505 --> 0.031815).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0259864\n",
      "\tspeed: 0.0936s/iter; left time: 1714.8901s\n",
      "\titers: 200, epoch: 18 | loss: 0.0249082\n",
      "\tspeed: 0.0509s/iter; left time: 928.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.45s\n",
      "Steps: 222 | Train Loss: 0.0236133 Vali Loss: 0.0326205 Test Loss: 0.0401949\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0230845\n",
      "\tspeed: 0.0912s/iter; left time: 1651.2096s\n",
      "\titers: 200, epoch: 19 | loss: 0.0244532\n",
      "\tspeed: 0.0502s/iter; left time: 904.5764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 222 | Train Loss: 0.0234732 Vali Loss: 0.0324181 Test Loss: 0.0406701\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0229646\n",
      "\tspeed: 0.0930s/iter; left time: 1663.2793s\n",
      "\titers: 200, epoch: 20 | loss: 0.0225817\n",
      "\tspeed: 0.0500s/iter; left time: 888.4947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0233922 Vali Loss: 0.0328225 Test Loss: 0.0413763\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0235294\n",
      "\tspeed: 0.0924s/iter; left time: 1631.6374s\n",
      "\titers: 200, epoch: 21 | loss: 0.0233960\n",
      "\tspeed: 0.0508s/iter; left time: 891.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 222 | Train Loss: 0.0233425 Vali Loss: 0.0323448 Test Loss: 0.0405806\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0227897\n",
      "\tspeed: 0.0918s/iter; left time: 1600.9618s\n",
      "\titers: 200, epoch: 22 | loss: 0.0233587\n",
      "\tspeed: 0.0511s/iter; left time: 885.7920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.46s\n",
      "Steps: 222 | Train Loss: 0.0232400 Vali Loss: 0.0327108 Test Loss: 0.0415128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0230084\n",
      "\tspeed: 0.0923s/iter; left time: 1589.5557s\n",
      "\titers: 200, epoch: 23 | loss: 0.0227019\n",
      "\tspeed: 0.0503s/iter; left time: 861.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 222 | Train Loss: 0.0231599 Vali Loss: 0.0328264 Test Loss: 0.0417051\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0220565\n",
      "\tspeed: 0.0949s/iter; left time: 1612.9663s\n",
      "\titers: 200, epoch: 24 | loss: 0.0225118\n",
      "\tspeed: 0.0491s/iter; left time: 829.3603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0231256 Vali Loss: 0.0326759 Test Loss: 0.0414577\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0253219\n",
      "\tspeed: 0.0909s/iter; left time: 1525.4396s\n",
      "\titers: 200, epoch: 25 | loss: 0.0229667\n",
      "\tspeed: 0.0506s/iter; left time: 843.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.45s\n",
      "Steps: 222 | Train Loss: 0.0230608 Vali Loss: 0.0324623 Test Loss: 0.0410861\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0217467\n",
      "\tspeed: 0.0909s/iter; left time: 1504.6154s\n",
      "\titers: 200, epoch: 26 | loss: 0.0222396\n",
      "\tspeed: 0.0505s/iter; left time: 830.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 222 | Train Loss: 0.0230109 Vali Loss: 0.0326253 Test Loss: 0.0417797\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0220535\n",
      "\tspeed: 0.0938s/iter; left time: 1530.8813s\n",
      "\titers: 200, epoch: 27 | loss: 0.0242244\n",
      "\tspeed: 0.0510s/iter; left time: 827.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 222 | Train Loss: 0.0229573 Vali Loss: 0.0326033 Test Loss: 0.0413879\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0389934666454792, rmse:0.197467640042305, mae:0.1372816115617752, rse:0.6994462013244629\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:38.81s\n",
      "Intermediate time for DE: 00h:22m:28.51s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1296732\n",
      "\tspeed: 0.0642s/iter; left time: 1424.7886s\n",
      "\titers: 200, epoch: 1 | loss: 0.1225555\n",
      "\tspeed: 0.0491s/iter; left time: 1085.7828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.54s\n",
      "Steps: 223 | Train Loss: 0.1316660 Vali Loss: 0.0944922 Test Loss: 0.1096129\n",
      "Validation loss decreased (inf --> 0.094492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0377319\n",
      "\tspeed: 0.0930s/iter; left time: 2043.8811s\n",
      "\titers: 200, epoch: 2 | loss: 0.0261822\n",
      "\tspeed: 0.0498s/iter; left time: 1090.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.56s\n",
      "Steps: 223 | Train Loss: 0.0454864 Vali Loss: 0.0248178 Test Loss: 0.0346409\n",
      "Validation loss decreased (0.094492 --> 0.024818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0243949\n",
      "\tspeed: 0.0902s/iter; left time: 1962.3430s\n",
      "\titers: 200, epoch: 3 | loss: 0.0203790\n",
      "\tspeed: 0.0503s/iter; left time: 1088.3158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 223 | Train Loss: 0.0222196 Vali Loss: 0.0212921 Test Loss: 0.0278196\n",
      "Validation loss decreased (0.024818 --> 0.021292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0207562\n",
      "\tspeed: 0.0921s/iter; left time: 1982.1556s\n",
      "\titers: 200, epoch: 4 | loss: 0.0200337\n",
      "\tspeed: 0.0494s/iter; left time: 1058.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.29s\n",
      "Steps: 223 | Train Loss: 0.0183250 Vali Loss: 0.0207108 Test Loss: 0.0272615\n",
      "Validation loss decreased (0.021292 --> 0.020711).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0151180\n",
      "\tspeed: 0.0898s/iter; left time: 1914.2871s\n",
      "\titers: 200, epoch: 5 | loss: 0.0161550\n",
      "\tspeed: 0.0496s/iter; left time: 1052.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 223 | Train Loss: 0.0166715 Vali Loss: 0.0204913 Test Loss: 0.0278639\n",
      "Validation loss decreased (0.020711 --> 0.020491).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0140818\n",
      "\tspeed: 0.0897s/iter; left time: 1890.7865s\n",
      "\titers: 200, epoch: 6 | loss: 0.0173617\n",
      "\tspeed: 0.0496s/iter; left time: 1041.6864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 223 | Train Loss: 0.0157911 Vali Loss: 0.0205434 Test Loss: 0.0280114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0153887\n",
      "\tspeed: 0.0896s/iter; left time: 1869.9129s\n",
      "\titers: 200, epoch: 7 | loss: 0.0141236\n",
      "\tspeed: 0.0496s/iter; left time: 1030.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 223 | Train Loss: 0.0154214 Vali Loss: 0.0204262 Test Loss: 0.0280592\n",
      "Validation loss decreased (0.020491 --> 0.020426).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0162005\n",
      "\tspeed: 0.0900s/iter; left time: 1857.6455s\n",
      "\titers: 200, epoch: 8 | loss: 0.0151308\n",
      "\tspeed: 0.0483s/iter; left time: 992.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 223 | Train Loss: 0.0151685 Vali Loss: 0.0205546 Test Loss: 0.0274767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0159596\n",
      "\tspeed: 0.0912s/iter; left time: 1862.4431s\n",
      "\titers: 200, epoch: 9 | loss: 0.0138793\n",
      "\tspeed: 0.0501s/iter; left time: 1017.7224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.57s\n",
      "Steps: 223 | Train Loss: 0.0149537 Vali Loss: 0.0201726 Test Loss: 0.0266926\n",
      "Validation loss decreased (0.020426 --> 0.020173).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0142701\n",
      "\tspeed: 0.0892s/iter; left time: 1800.5891s\n",
      "\titers: 200, epoch: 10 | loss: 0.0156937\n",
      "\tspeed: 0.0494s/iter; left time: 993.1446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.29s\n",
      "Steps: 223 | Train Loss: 0.0147354 Vali Loss: 0.0200238 Test Loss: 0.0267262\n",
      "Validation loss decreased (0.020173 --> 0.020024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0162956\n",
      "\tspeed: 0.0890s/iter; left time: 1776.5867s\n",
      "\titers: 200, epoch: 11 | loss: 0.0157453\n",
      "\tspeed: 0.0491s/iter; left time: 976.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 223 | Train Loss: 0.0147208 Vali Loss: 0.0202973 Test Loss: 0.0269148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0120478\n",
      "\tspeed: 0.0902s/iter; left time: 1781.3780s\n",
      "\titers: 200, epoch: 12 | loss: 0.0157311\n",
      "\tspeed: 0.0494s/iter; left time: 969.8544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 223 | Train Loss: 0.0144875 Vali Loss: 0.0199512 Test Loss: 0.0266800\n",
      "Validation loss decreased (0.020024 --> 0.019951).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0137041\n",
      "\tspeed: 0.0914s/iter; left time: 1783.6364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0147808\n",
      "\tspeed: 0.0507s/iter; left time: 984.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 223 | Train Loss: 0.0143374 Vali Loss: 0.0200135 Test Loss: 0.0267759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0139965\n",
      "\tspeed: 0.0905s/iter; left time: 1746.9507s\n",
      "\titers: 200, epoch: 14 | loss: 0.0139776\n",
      "\tspeed: 0.0487s/iter; left time: 934.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.21s\n",
      "Steps: 223 | Train Loss: 0.0142924 Vali Loss: 0.0201385 Test Loss: 0.0269570\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0141281\n",
      "\tspeed: 0.0904s/iter; left time: 1724.9560s\n",
      "\titers: 200, epoch: 15 | loss: 0.0135372\n",
      "\tspeed: 0.0496s/iter; left time: 940.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.25s\n",
      "Steps: 223 | Train Loss: 0.0141842 Vali Loss: 0.0197869 Test Loss: 0.0266150\n",
      "Validation loss decreased (0.019951 --> 0.019787).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0136077\n",
      "\tspeed: 0.0910s/iter; left time: 1715.0691s\n",
      "\titers: 200, epoch: 16 | loss: 0.0126454\n",
      "\tspeed: 0.0494s/iter; left time: 925.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 223 | Train Loss: 0.0141280 Vali Loss: 0.0200392 Test Loss: 0.0273709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0148440\n",
      "\tspeed: 0.0888s/iter; left time: 1653.9312s\n",
      "\titers: 200, epoch: 17 | loss: 0.0133331\n",
      "\tspeed: 0.0505s/iter; left time: 936.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.42s\n",
      "Steps: 223 | Train Loss: 0.0140650 Vali Loss: 0.0198028 Test Loss: 0.0266699\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0139154\n",
      "\tspeed: 0.0897s/iter; left time: 1650.5469s\n",
      "\titers: 200, epoch: 18 | loss: 0.0142051\n",
      "\tspeed: 0.0499s/iter; left time: 913.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.39s\n",
      "Steps: 223 | Train Loss: 0.0139809 Vali Loss: 0.0200569 Test Loss: 0.0271863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0132001\n",
      "\tspeed: 0.0898s/iter; left time: 1632.2960s\n",
      "\titers: 200, epoch: 19 | loss: 0.0152973\n",
      "\tspeed: 0.0497s/iter; left time: 899.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.32s\n",
      "Steps: 223 | Train Loss: 0.0138989 Vali Loss: 0.0201339 Test Loss: 0.0271165\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0138798\n",
      "\tspeed: 0.0902s/iter; left time: 1620.6189s\n",
      "\titers: 200, epoch: 20 | loss: 0.0122192\n",
      "\tspeed: 0.0498s/iter; left time: 889.2672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.43s\n",
      "Steps: 223 | Train Loss: 0.0138612 Vali Loss: 0.0199807 Test Loss: 0.0271351\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0130000\n",
      "\tspeed: 0.0895s/iter; left time: 1588.4832s\n",
      "\titers: 200, epoch: 21 | loss: 0.0156088\n",
      "\tspeed: 0.0493s/iter; left time: 869.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 223 | Train Loss: 0.0138289 Vali Loss: 0.0198444 Test Loss: 0.0270159\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0137042\n",
      "\tspeed: 0.0902s/iter; left time: 1580.2412s\n",
      "\titers: 200, epoch: 22 | loss: 0.0144793\n",
      "\tspeed: 0.0480s/iter; left time: 835.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.02s\n",
      "Steps: 223 | Train Loss: 0.0137971 Vali Loss: 0.0200208 Test Loss: 0.0274525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0149143\n",
      "\tspeed: 0.0905s/iter; left time: 1565.7847s\n",
      "\titers: 200, epoch: 23 | loss: 0.0120591\n",
      "\tspeed: 0.0504s/iter; left time: 866.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.58s\n",
      "Steps: 223 | Train Loss: 0.0137535 Vali Loss: 0.0198494 Test Loss: 0.0272250\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0139830\n",
      "\tspeed: 0.0920s/iter; left time: 1569.8186s\n",
      "\titers: 200, epoch: 24 | loss: 0.0142577\n",
      "\tspeed: 0.0505s/iter; left time: 856.8954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.56s\n",
      "Steps: 223 | Train Loss: 0.0137470 Vali Loss: 0.0199485 Test Loss: 0.0269865\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0144327\n",
      "\tspeed: 0.0920s/iter; left time: 1549.5189s\n",
      "\titers: 200, epoch: 25 | loss: 0.0133431\n",
      "\tspeed: 0.0492s/iter; left time: 824.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.17s\n",
      "Steps: 223 | Train Loss: 0.0136602 Vali Loss: 0.0199846 Test Loss: 0.0274140\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026614956557750702, rmse:0.1631409078836441, mae:0.10954777151346207, rse:0.5627899169921875\n",
      "Intermediate time for GB and pred_len 24: 00h:05m:57.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1323240\n",
      "\tspeed: 0.0647s/iter; left time: 1430.2825s\n",
      "\titers: 200, epoch: 1 | loss: 0.1149986\n",
      "\tspeed: 0.0489s/iter; left time: 1076.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.54s\n",
      "Steps: 222 | Train Loss: 0.1320870 Vali Loss: 0.0994640 Test Loss: 0.1168359\n",
      "Validation loss decreased (inf --> 0.099464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0393860\n",
      "\tspeed: 0.0945s/iter; left time: 2067.8632s\n",
      "\titers: 200, epoch: 2 | loss: 0.0319159\n",
      "\tspeed: 0.0487s/iter; left time: 1059.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.22s\n",
      "Steps: 222 | Train Loss: 0.0481805 Vali Loss: 0.0330101 Test Loss: 0.0472668\n",
      "Validation loss decreased (0.099464 --> 0.033010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0261547\n",
      "\tspeed: 0.0906s/iter; left time: 1963.0412s\n",
      "\titers: 200, epoch: 3 | loss: 0.0259022\n",
      "\tspeed: 0.0494s/iter; left time: 1065.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.32s\n",
      "Steps: 222 | Train Loss: 0.0273623 Vali Loss: 0.0302135 Test Loss: 0.0438073\n",
      "Validation loss decreased (0.033010 --> 0.030213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0226433\n",
      "\tspeed: 0.0986s/iter; left time: 2113.7828s\n",
      "\titers: 200, epoch: 4 | loss: 0.0245221\n",
      "\tspeed: 0.0495s/iter; left time: 1055.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0241833 Vali Loss: 0.0304314 Test Loss: 0.0490374\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0251091\n",
      "\tspeed: 0.0916s/iter; left time: 1942.7026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0233933\n",
      "\tspeed: 0.0503s/iter; left time: 1061.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 222 | Train Loss: 0.0231457 Vali Loss: 0.0307405 Test Loss: 0.0483087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0226541\n",
      "\tspeed: 0.0910s/iter; left time: 1910.3219s\n",
      "\titers: 200, epoch: 6 | loss: 0.0229256\n",
      "\tspeed: 0.0499s/iter; left time: 1041.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 222 | Train Loss: 0.0226541 Vali Loss: 0.0304898 Test Loss: 0.0448133\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0223542\n",
      "\tspeed: 0.0918s/iter; left time: 1906.7280s\n",
      "\titers: 200, epoch: 7 | loss: 0.0214087\n",
      "\tspeed: 0.0498s/iter; left time: 1030.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.43s\n",
      "Steps: 222 | Train Loss: 0.0222953 Vali Loss: 0.0299704 Test Loss: 0.0423198\n",
      "Validation loss decreased (0.030213 --> 0.029970).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0221992\n",
      "\tspeed: 0.0919s/iter; left time: 1888.2188s\n",
      "\titers: 200, epoch: 8 | loss: 0.0222362\n",
      "\tspeed: 0.0497s/iter; left time: 1016.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 222 | Train Loss: 0.0220033 Vali Loss: 0.0299967 Test Loss: 0.0426890\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0217263\n",
      "\tspeed: 0.0906s/iter; left time: 1842.3125s\n",
      "\titers: 200, epoch: 9 | loss: 0.0209402\n",
      "\tspeed: 0.0505s/iter; left time: 1020.3849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 222 | Train Loss: 0.0217836 Vali Loss: 0.0296291 Test Loss: 0.0417050\n",
      "Validation loss decreased (0.029970 --> 0.029629).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0209449\n",
      "\tspeed: 0.0932s/iter; left time: 1873.5750s\n",
      "\titers: 200, epoch: 10 | loss: 0.0209933\n",
      "\tspeed: 0.0493s/iter; left time: 986.1424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0215704 Vali Loss: 0.0298925 Test Loss: 0.0420922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0209658\n",
      "\tspeed: 0.0925s/iter; left time: 1839.4380s\n",
      "\titers: 200, epoch: 11 | loss: 0.0199631\n",
      "\tspeed: 0.0498s/iter; left time: 985.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0214490 Vali Loss: 0.0293610 Test Loss: 0.0405640\n",
      "Validation loss decreased (0.029629 --> 0.029361).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0216354\n",
      "\tspeed: 0.0979s/iter; left time: 1923.9231s\n",
      "\titers: 200, epoch: 12 | loss: 0.0204532\n",
      "\tspeed: 0.0493s/iter; left time: 963.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.31s\n",
      "Steps: 222 | Train Loss: 0.0212971 Vali Loss: 0.0297991 Test Loss: 0.0413098\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0192091\n",
      "\tspeed: 0.0949s/iter; left time: 1844.5210s\n",
      "\titers: 200, epoch: 13 | loss: 0.0213485\n",
      "\tspeed: 0.0501s/iter; left time: 968.8332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.36s\n",
      "Steps: 222 | Train Loss: 0.0212116 Vali Loss: 0.0300655 Test Loss: 0.0417966\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0204063\n",
      "\tspeed: 0.0917s/iter; left time: 1762.2465s\n",
      "\titers: 200, epoch: 14 | loss: 0.0211266\n",
      "\tspeed: 0.0493s/iter; left time: 941.9815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.40s\n",
      "Steps: 222 | Train Loss: 0.0211267 Vali Loss: 0.0298509 Test Loss: 0.0411874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0234450\n",
      "\tspeed: 0.0951s/iter; left time: 1805.6532s\n",
      "\titers: 200, epoch: 15 | loss: 0.0221137\n",
      "\tspeed: 0.0495s/iter; left time: 935.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.24s\n",
      "Steps: 222 | Train Loss: 0.0210179 Vali Loss: 0.0296575 Test Loss: 0.0406219\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0207905\n",
      "\tspeed: 0.0913s/iter; left time: 1713.8075s\n",
      "\titers: 200, epoch: 16 | loss: 0.0185365\n",
      "\tspeed: 0.0497s/iter; left time: 928.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 222 | Train Loss: 0.0209206 Vali Loss: 0.0299610 Test Loss: 0.0415653\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0202313\n",
      "\tspeed: 0.0898s/iter; left time: 1664.9106s\n",
      "\titers: 200, epoch: 17 | loss: 0.0208116\n",
      "\tspeed: 0.0511s/iter; left time: 942.5208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.46s\n",
      "Steps: 222 | Train Loss: 0.0208105 Vali Loss: 0.0303820 Test Loss: 0.0420282\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0221342\n",
      "\tspeed: 0.0924s/iter; left time: 1694.0103s\n",
      "\titers: 200, epoch: 18 | loss: 0.0200218\n",
      "\tspeed: 0.0494s/iter; left time: 901.0935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 222 | Train Loss: 0.0207714 Vali Loss: 0.0299171 Test Loss: 0.0420240\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0193397\n",
      "\tspeed: 0.0903s/iter; left time: 1634.6046s\n",
      "\titers: 200, epoch: 19 | loss: 0.0221446\n",
      "\tspeed: 0.0499s/iter; left time: 898.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.37s\n",
      "Steps: 222 | Train Loss: 0.0206576 Vali Loss: 0.0299749 Test Loss: 0.0419878\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0193885\n",
      "\tspeed: 0.0910s/iter; left time: 1626.8947s\n",
      "\titers: 200, epoch: 20 | loss: 0.0205301\n",
      "\tspeed: 0.0502s/iter; left time: 893.2843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.36s\n",
      "Steps: 222 | Train Loss: 0.0206312 Vali Loss: 0.0298362 Test Loss: 0.0417427\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0197740\n",
      "\tspeed: 0.0917s/iter; left time: 1619.6744s\n",
      "\titers: 200, epoch: 21 | loss: 0.0227434\n",
      "\tspeed: 0.0507s/iter; left time: 890.4546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 222 | Train Loss: 0.0206033 Vali Loss: 0.0300504 Test Loss: 0.0424300\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.040564022958278656, rmse:0.2014051228761673, mae:0.1430739164352417, rse:0.6964869499206543\n",
      "Intermediate time for GB and pred_len 96: 00h:05m:08.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1281811\n",
      "\tspeed: 0.0763s/iter; left time: 1686.8462s\n",
      "\titers: 200, epoch: 1 | loss: 0.1206248\n",
      "\tspeed: 0.0498s/iter; left time: 1096.5213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.47s\n",
      "Steps: 222 | Train Loss: 0.1323972 Vali Loss: 0.1000619 Test Loss: 0.1167016\n",
      "Validation loss decreased (inf --> 0.100062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0420797\n",
      "\tspeed: 0.0914s/iter; left time: 1998.8544s\n",
      "\titers: 200, epoch: 2 | loss: 0.0311064\n",
      "\tspeed: 0.0495s/iter; left time: 1077.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.28s\n",
      "Steps: 222 | Train Loss: 0.0486551 Vali Loss: 0.0341354 Test Loss: 0.0488688\n",
      "Validation loss decreased (0.100062 --> 0.034135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0288977\n",
      "\tspeed: 0.0959s/iter; left time: 2075.8970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0273455\n",
      "\tspeed: 0.0494s/iter; left time: 1065.5569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.25s\n",
      "Steps: 222 | Train Loss: 0.0279936 Vali Loss: 0.0316944 Test Loss: 0.0481999\n",
      "Validation loss decreased (0.034135 --> 0.031694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0267540\n",
      "\tspeed: 0.0914s/iter; left time: 1958.9806s\n",
      "\titers: 200, epoch: 4 | loss: 0.0237245\n",
      "\tspeed: 0.0497s/iter; left time: 1059.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 222 | Train Loss: 0.0252568 Vali Loss: 0.0321467 Test Loss: 0.0511265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0232651\n",
      "\tspeed: 0.0917s/iter; left time: 1944.7708s\n",
      "\titers: 200, epoch: 5 | loss: 0.0249807\n",
      "\tspeed: 0.0501s/iter; left time: 1056.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.26s\n",
      "Steps: 222 | Train Loss: 0.0244643 Vali Loss: 0.0326758 Test Loss: 0.0522774\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0223662\n",
      "\tspeed: 0.0910s/iter; left time: 1909.6339s\n",
      "\titers: 200, epoch: 6 | loss: 0.0243166\n",
      "\tspeed: 0.0494s/iter; left time: 1032.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 222 | Train Loss: 0.0239696 Vali Loss: 0.0324708 Test Loss: 0.0497946\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0234233\n",
      "\tspeed: 0.0883s/iter; left time: 1833.4758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0236040\n",
      "\tspeed: 0.0498s/iter; left time: 1030.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.43s\n",
      "Steps: 222 | Train Loss: 0.0235794 Vali Loss: 0.0324006 Test Loss: 0.0479286\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0232106\n",
      "\tspeed: 0.0965s/iter; left time: 1983.6651s\n",
      "\titers: 200, epoch: 8 | loss: 0.0215790\n",
      "\tspeed: 0.0506s/iter; left time: 1034.8418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.44s\n",
      "Steps: 222 | Train Loss: 0.0232308 Vali Loss: 0.0325789 Test Loss: 0.0474472\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0229674\n",
      "\tspeed: 0.0908s/iter; left time: 1845.9255s\n",
      "\titers: 200, epoch: 9 | loss: 0.0228480\n",
      "\tspeed: 0.0516s/iter; left time: 1043.5017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.53s\n",
      "Steps: 222 | Train Loss: 0.0230120 Vali Loss: 0.0318836 Test Loss: 0.0453121\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0225253\n",
      "\tspeed: 0.0954s/iter; left time: 1917.6663s\n",
      "\titers: 200, epoch: 10 | loss: 0.0229859\n",
      "\tspeed: 0.0499s/iter; left time: 997.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.56s\n",
      "Steps: 222 | Train Loss: 0.0228531 Vali Loss: 0.0317617 Test Loss: 0.0442896\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0240105\n",
      "\tspeed: 0.0924s/iter; left time: 1837.1662s\n",
      "\titers: 200, epoch: 11 | loss: 0.0231950\n",
      "\tspeed: 0.0492s/iter; left time: 972.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.33s\n",
      "Steps: 222 | Train Loss: 0.0226830 Vali Loss: 0.0319622 Test Loss: 0.0452901\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0240522\n",
      "\tspeed: 0.0930s/iter; left time: 1828.0749s\n",
      "\titers: 200, epoch: 12 | loss: 0.0224349\n",
      "\tspeed: 0.0509s/iter; left time: 996.3293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.66s\n",
      "Steps: 222 | Train Loss: 0.0225790 Vali Loss: 0.0319162 Test Loss: 0.0447830\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0210353\n",
      "\tspeed: 0.0938s/iter; left time: 1822.4410s\n",
      "\titers: 200, epoch: 13 | loss: 0.0226072\n",
      "\tspeed: 0.0499s/iter; left time: 965.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.51s\n",
      "Steps: 222 | Train Loss: 0.0224231 Vali Loss: 0.0321067 Test Loss: 0.0451294\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048199884593486786, rmse:0.21954472362995148, mae:0.15564729273319244, rse:0.7611930966377258\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:16.33s\n",
      "Intermediate time for GB: 00h:14m:21.84s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1235685\n",
      "\tspeed: 0.0390s/iter; left time: 868.9787s\n",
      "\titers: 200, epoch: 1 | loss: 0.1166312\n",
      "\tspeed: 0.0210s/iter; left time: 467.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 224 | Train Loss: 0.1306442 Vali Loss: 0.0743393 Test Loss: 0.0910288\n",
      "Validation loss decreased (inf --> 0.074339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0414139\n",
      "\tspeed: 0.0446s/iter; left time: 984.8645s\n",
      "\titers: 200, epoch: 2 | loss: 0.0266411\n",
      "\tspeed: 0.0212s/iter; left time: 466.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0490632 Vali Loss: 0.0170418 Test Loss: 0.0199101\n",
      "Validation loss decreased (0.074339 --> 0.017042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0221347\n",
      "\tspeed: 0.0448s/iter; left time: 978.7034s\n",
      "\titers: 200, epoch: 3 | loss: 0.0209304\n",
      "\tspeed: 0.0207s/iter; left time: 451.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0225532 Vali Loss: 0.0141340 Test Loss: 0.0165208\n",
      "Validation loss decreased (0.017042 --> 0.014134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0175069\n",
      "\tspeed: 0.0459s/iter; left time: 992.7903s\n",
      "\titers: 200, epoch: 4 | loss: 0.0180933\n",
      "\tspeed: 0.0208s/iter; left time: 448.1361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0189549 Vali Loss: 0.0126682 Test Loss: 0.0149519\n",
      "Validation loss decreased (0.014134 --> 0.012668).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0158055\n",
      "\tspeed: 0.0438s/iter; left time: 937.6032s\n",
      "\titers: 200, epoch: 5 | loss: 0.0164286\n",
      "\tspeed: 0.0230s/iter; left time: 489.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0169486 Vali Loss: 0.0124042 Test Loss: 0.0145784\n",
      "Validation loss decreased (0.012668 --> 0.012404).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0160598\n",
      "\tspeed: 0.0498s/iter; left time: 1054.0352s\n",
      "\titers: 200, epoch: 6 | loss: 0.0156461\n",
      "\tspeed: 0.0211s/iter; left time: 445.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0154126 Vali Loss: 0.0123237 Test Loss: 0.0142485\n",
      "Validation loss decreased (0.012404 --> 0.012324).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0163689\n",
      "\tspeed: 0.0448s/iter; left time: 939.4813s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149154\n",
      "\tspeed: 0.0205s/iter; left time: 427.0370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 224 | Train Loss: 0.0142636 Vali Loss: 0.0114231 Test Loss: 0.0135450\n",
      "Validation loss decreased (0.012324 --> 0.011423).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132940\n",
      "\tspeed: 0.0455s/iter; left time: 943.5529s\n",
      "\titers: 200, epoch: 8 | loss: 0.0116993\n",
      "\tspeed: 0.0212s/iter; left time: 437.8071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0130814 Vali Loss: 0.0109222 Test Loss: 0.0140578\n",
      "Validation loss decreased (0.011423 --> 0.010922).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0113352\n",
      "\tspeed: 0.0448s/iter; left time: 919.0434s\n",
      "\titers: 200, epoch: 9 | loss: 0.0105395\n",
      "\tspeed: 0.0209s/iter; left time: 425.7818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0120762 Vali Loss: 0.0108338 Test Loss: 0.0172134\n",
      "Validation loss decreased (0.010922 --> 0.010834).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0116649\n",
      "\tspeed: 0.0455s/iter; left time: 922.6808s\n",
      "\titers: 200, epoch: 10 | loss: 0.0099158\n",
      "\tspeed: 0.0241s/iter; left time: 486.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0114562 Vali Loss: 0.0104998 Test Loss: 0.0165373\n",
      "Validation loss decreased (0.010834 --> 0.010500).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0113771\n",
      "\tspeed: 0.0491s/iter; left time: 985.4491s\n",
      "\titers: 200, epoch: 11 | loss: 0.0114219\n",
      "\tspeed: 0.0204s/iter; left time: 406.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0110821 Vali Loss: 0.0103820 Test Loss: 0.0219415\n",
      "Validation loss decreased (0.010500 --> 0.010382).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0108638\n",
      "\tspeed: 0.0437s/iter; left time: 866.4537s\n",
      "\titers: 200, epoch: 12 | loss: 0.0102516\n",
      "\tspeed: 0.0207s/iter; left time: 408.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0106935 Vali Loss: 0.0100026 Test Loss: 0.0214718\n",
      "Validation loss decreased (0.010382 --> 0.010003).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0098957\n",
      "\tspeed: 0.0440s/iter; left time: 863.6807s\n",
      "\titers: 200, epoch: 13 | loss: 0.0092505\n",
      "\tspeed: 0.0211s/iter; left time: 412.6698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0104717 Vali Loss: 0.0099261 Test Loss: 0.0182114\n",
      "Validation loss decreased (0.010003 --> 0.009926).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0108826\n",
      "\tspeed: 0.0465s/iter; left time: 900.9547s\n",
      "\titers: 200, epoch: 14 | loss: 0.0088690\n",
      "\tspeed: 0.0213s/iter; left time: 410.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0102703 Vali Loss: 0.0098426 Test Loss: 0.0177606\n",
      "Validation loss decreased (0.009926 --> 0.009843).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0105166\n",
      "\tspeed: 0.0485s/iter; left time: 929.9886s\n",
      "\titers: 200, epoch: 15 | loss: 0.0097342\n",
      "\tspeed: 0.0236s/iter; left time: 450.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0101483 Vali Loss: 0.0098085 Test Loss: 0.0205569\n",
      "Validation loss decreased (0.009843 --> 0.009809).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0087296\n",
      "\tspeed: 0.0486s/iter; left time: 920.4659s\n",
      "\titers: 200, epoch: 16 | loss: 0.0096730\n",
      "\tspeed: 0.0205s/iter; left time: 386.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0101333 Vali Loss: 0.0097114 Test Loss: 0.0196735\n",
      "Validation loss decreased (0.009809 --> 0.009711).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0108441\n",
      "\tspeed: 0.0452s/iter; left time: 845.9819s\n",
      "\titers: 200, epoch: 17 | loss: 0.0097255\n",
      "\tspeed: 0.0209s/iter; left time: 388.8264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0099599 Vali Loss: 0.0095411 Test Loss: 0.0179444\n",
      "Validation loss decreased (0.009711 --> 0.009541).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0088029\n",
      "\tspeed: 0.0469s/iter; left time: 867.0468s\n",
      "\titers: 200, epoch: 18 | loss: 0.0095050\n",
      "\tspeed: 0.0204s/iter; left time: 376.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0098107 Vali Loss: 0.0095047 Test Loss: 0.0188733\n",
      "Validation loss decreased (0.009541 --> 0.009505).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0096069\n",
      "\tspeed: 0.0449s/iter; left time: 820.5002s\n",
      "\titers: 200, epoch: 19 | loss: 0.0100707\n",
      "\tspeed: 0.0206s/iter; left time: 374.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0097356 Vali Loss: 0.0095299 Test Loss: 0.0189880\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0096012\n",
      "\tspeed: 0.0479s/iter; left time: 864.6471s\n",
      "\titers: 200, epoch: 20 | loss: 0.0103081\n",
      "\tspeed: 0.0241s/iter; left time: 431.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0096700 Vali Loss: 0.0094713 Test Loss: 0.0193751\n",
      "Validation loss decreased (0.009505 --> 0.009471).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0099798\n",
      "\tspeed: 0.0468s/iter; left time: 834.6476s\n",
      "\titers: 200, epoch: 21 | loss: 0.0106904\n",
      "\tspeed: 0.0208s/iter; left time: 368.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0096355 Vali Loss: 0.0094038 Test Loss: 0.0190703\n",
      "Validation loss decreased (0.009471 --> 0.009404).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0098239\n",
      "\tspeed: 0.0452s/iter; left time: 795.9743s\n",
      "\titers: 200, epoch: 22 | loss: 0.0093015\n",
      "\tspeed: 0.0207s/iter; left time: 362.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0095963 Vali Loss: 0.0094222 Test Loss: 0.0179196\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0091338\n",
      "\tspeed: 0.0464s/iter; left time: 805.9490s\n",
      "\titers: 200, epoch: 23 | loss: 0.0098065\n",
      "\tspeed: 0.0209s/iter; left time: 360.8202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0095129 Vali Loss: 0.0092669 Test Loss: 0.0183864\n",
      "Validation loss decreased (0.009404 --> 0.009267).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0093905\n",
      "\tspeed: 0.0456s/iter; left time: 782.6386s\n",
      "\titers: 200, epoch: 24 | loss: 0.0102782\n",
      "\tspeed: 0.0209s/iter; left time: 355.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0095316 Vali Loss: 0.0093195 Test Loss: 0.0209839\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0104343\n",
      "\tspeed: 0.0585s/iter; left time: 989.4332s\n",
      "\titers: 200, epoch: 25 | loss: 0.0088957\n",
      "\tspeed: 0.0229s/iter; left time: 385.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 224 | Train Loss: 0.0094462 Vali Loss: 0.0092798 Test Loss: 0.0181019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0092811\n",
      "\tspeed: 0.0439s/iter; left time: 732.5904s\n",
      "\titers: 200, epoch: 26 | loss: 0.0094501\n",
      "\tspeed: 0.0208s/iter; left time: 345.7400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 224 | Train Loss: 0.0096182 Vali Loss: 0.0094344 Test Loss: 0.0172716\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0091324\n",
      "\tspeed: 0.0433s/iter; left time: 714.1331s\n",
      "\titers: 200, epoch: 27 | loss: 0.0106261\n",
      "\tspeed: 0.0213s/iter; left time: 349.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0094139 Vali Loss: 0.0092859 Test Loss: 0.0192018\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0077775\n",
      "\tspeed: 0.0488s/iter; left time: 792.9774s\n",
      "\titers: 200, epoch: 28 | loss: 0.0089043\n",
      "\tspeed: 0.0215s/iter; left time: 346.5681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0093605 Vali Loss: 0.0092553 Test Loss: 0.0188021\n",
      "Validation loss decreased (0.009267 --> 0.009255).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0087630\n",
      "\tspeed: 0.0510s/iter; left time: 816.9954s\n",
      "\titers: 200, epoch: 29 | loss: 0.0096931\n",
      "\tspeed: 0.0219s/iter; left time: 348.2522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0093333 Vali Loss: 0.0091649 Test Loss: 0.0186937\n",
      "Validation loss decreased (0.009255 --> 0.009165).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0092893\n",
      "\tspeed: 0.0516s/iter; left time: 814.9851s\n",
      "\titers: 200, epoch: 30 | loss: 0.0085216\n",
      "\tspeed: 0.0221s/iter; left time: 347.7434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0094238 Vali Loss: 0.0093011 Test Loss: 0.0215952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0095737\n",
      "\tspeed: 0.0485s/iter; left time: 755.2774s\n",
      "\titers: 200, epoch: 31 | loss: 0.0114639\n",
      "\tspeed: 0.0237s/iter; left time: 366.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0093481 Vali Loss: 0.0091937 Test Loss: 0.0199297\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0099808\n",
      "\tspeed: 0.0479s/iter; left time: 735.4189s\n",
      "\titers: 200, epoch: 32 | loss: 0.0079586\n",
      "\tspeed: 0.0247s/iter; left time: 376.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0092504 Vali Loss: 0.0091131 Test Loss: 0.0179925\n",
      "Validation loss decreased (0.009165 --> 0.009113).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0097558\n",
      "\tspeed: 0.0504s/iter; left time: 763.0779s\n",
      "\titers: 200, epoch: 33 | loss: 0.0094637\n",
      "\tspeed: 0.0218s/iter; left time: 327.5777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0092967 Vali Loss: 0.0091046 Test Loss: 0.0196414\n",
      "Validation loss decreased (0.009113 --> 0.009105).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0093406\n",
      "\tspeed: 0.0515s/iter; left time: 767.4945s\n",
      "\titers: 200, epoch: 34 | loss: 0.0088018\n",
      "\tspeed: 0.0218s/iter; left time: 322.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0092845 Vali Loss: 0.0091666 Test Loss: 0.0193905\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0092743\n",
      "\tspeed: 0.0504s/iter; left time: 739.9328s\n",
      "\titers: 200, epoch: 35 | loss: 0.0083632\n",
      "\tspeed: 0.0214s/iter; left time: 312.4219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0092069 Vali Loss: 0.0090927 Test Loss: 0.0179031\n",
      "Validation loss decreased (0.009105 --> 0.009093).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0098525\n",
      "\tspeed: 0.0501s/iter; left time: 724.4961s\n",
      "\titers: 200, epoch: 36 | loss: 0.0083036\n",
      "\tspeed: 0.0245s/iter; left time: 351.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0092492 Vali Loss: 0.0090937 Test Loss: 0.0208244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0083163\n",
      "\tspeed: 0.0496s/iter; left time: 706.3787s\n",
      "\titers: 200, epoch: 37 | loss: 0.0091936\n",
      "\tspeed: 0.0246s/iter; left time: 347.6624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 224 | Train Loss: 0.0092016 Vali Loss: 0.0090485 Test Loss: 0.0183503\n",
      "Validation loss decreased (0.009093 --> 0.009049).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0080988\n",
      "\tspeed: 0.0480s/iter; left time: 672.8010s\n",
      "\titers: 200, epoch: 38 | loss: 0.0095375\n",
      "\tspeed: 0.0217s/iter; left time: 301.6484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0092376 Vali Loss: 0.0091220 Test Loss: 0.0189542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0091136\n",
      "\tspeed: 0.0507s/iter; left time: 699.1222s\n",
      "\titers: 200, epoch: 39 | loss: 0.0088850\n",
      "\tspeed: 0.0231s/iter; left time: 316.0700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0092021 Vali Loss: 0.0090822 Test Loss: 0.0201605\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0085782\n",
      "\tspeed: 0.0523s/iter; left time: 710.1104s\n",
      "\titers: 200, epoch: 40 | loss: 0.0086339\n",
      "\tspeed: 0.0218s/iter; left time: 293.8584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0091749 Vali Loss: 0.0090968 Test Loss: 0.0189611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0097929\n",
      "\tspeed: 0.0514s/iter; left time: 685.7722s\n",
      "\titers: 200, epoch: 41 | loss: 0.0088069\n",
      "\tspeed: 0.0251s/iter; left time: 332.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0091887 Vali Loss: 0.0091413 Test Loss: 0.0185922\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0104537\n",
      "\tspeed: 0.0476s/iter; left time: 624.0175s\n",
      "\titers: 200, epoch: 42 | loss: 0.0085751\n",
      "\tspeed: 0.0237s/iter; left time: 308.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0092292 Vali Loss: 0.0091321 Test Loss: 0.0179263\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0089744\n",
      "\tspeed: 0.0499s/iter; left time: 642.7301s\n",
      "\titers: 200, epoch: 43 | loss: 0.0091920\n",
      "\tspeed: 0.0238s/iter; left time: 303.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0092599 Vali Loss: 0.0091090 Test Loss: 0.0174770\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0096402\n",
      "\tspeed: 0.0519s/iter; left time: 657.3166s\n",
      "\titers: 200, epoch: 44 | loss: 0.0095632\n",
      "\tspeed: 0.0208s/iter; left time: 260.8448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0092053 Vali Loss: 0.0091317 Test Loss: 0.0196726\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0099961\n",
      "\tspeed: 0.0459s/iter; left time: 570.8017s\n",
      "\titers: 200, epoch: 45 | loss: 0.0104771\n",
      "\tspeed: 0.0202s/iter; left time: 249.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0092551 Vali Loss: 0.0091076 Test Loss: 0.0179130\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0084438\n",
      "\tspeed: 0.0508s/iter; left time: 620.7413s\n",
      "\titers: 200, epoch: 46 | loss: 0.0094436\n",
      "\tspeed: 0.0215s/iter; left time: 260.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0091619 Vali Loss: 0.0090871 Test Loss: 0.0172821\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0097950\n",
      "\tspeed: 0.0594s/iter; left time: 712.9968s\n",
      "\titers: 200, epoch: 47 | loss: 0.0084180\n",
      "\tspeed: 0.0206s/iter; left time: 245.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0091385 Vali Loss: 0.0091280 Test Loss: 0.0175781\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01835033856332302, rmse:0.1354634165763855, mae:0.08412059396505356, rse:0.39865246415138245\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:37.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1243099\n",
      "\tspeed: 0.0408s/iter; left time: 909.8857s\n",
      "\titers: 200, epoch: 1 | loss: 0.1112777\n",
      "\tspeed: 0.0269s/iter; left time: 596.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 224 | Train Loss: 0.1304680 Vali Loss: 0.0749759 Test Loss: 0.0934199\n",
      "Validation loss decreased (inf --> 0.074976).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0422750\n",
      "\tspeed: 0.0489s/iter; left time: 1080.3395s\n",
      "\titers: 200, epoch: 2 | loss: 0.0295403\n",
      "\tspeed: 0.0228s/iter; left time: 500.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0484345 Vali Loss: 0.0234643 Test Loss: 0.0291021\n",
      "Validation loss decreased (0.074976 --> 0.023464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0261098\n",
      "\tspeed: 0.0590s/iter; left time: 1290.1647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0251757\n",
      "\tspeed: 0.0210s/iter; left time: 456.4315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0267445 Vali Loss: 0.0204402 Test Loss: 0.0251841\n",
      "Validation loss decreased (0.023464 --> 0.020440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0220553\n",
      "\tspeed: 0.0576s/iter; left time: 1246.2445s\n",
      "\titers: 200, epoch: 4 | loss: 0.0216708\n",
      "\tspeed: 0.0215s/iter; left time: 462.3749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 224 | Train Loss: 0.0230021 Vali Loss: 0.0190462 Test Loss: 0.0245052\n",
      "Validation loss decreased (0.020440 --> 0.019046).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0207762\n",
      "\tspeed: 0.0516s/iter; left time: 1103.9211s\n",
      "\titers: 200, epoch: 5 | loss: 0.0181857\n",
      "\tspeed: 0.0282s/iter; left time: 601.4712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 224 | Train Loss: 0.0199932 Vali Loss: 0.0178145 Test Loss: 0.0349214\n",
      "Validation loss decreased (0.019046 --> 0.017814).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0178383\n",
      "\tspeed: 0.0516s/iter; left time: 1092.2344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0184396\n",
      "\tspeed: 0.0259s/iter; left time: 546.8263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0179342 Vali Loss: 0.0170949 Test Loss: 0.0270423\n",
      "Validation loss decreased (0.017814 --> 0.017095).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0178106\n",
      "\tspeed: 0.0560s/iter; left time: 1172.8880s\n",
      "\titers: 200, epoch: 7 | loss: 0.0158232\n",
      "\tspeed: 0.0219s/iter; left time: 456.0232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0169621 Vali Loss: 0.0164534 Test Loss: 0.0254716\n",
      "Validation loss decreased (0.017095 --> 0.016453).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0172422\n",
      "\tspeed: 0.0583s/iter; left time: 1208.9053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0163265\n",
      "\tspeed: 0.0217s/iter; left time: 447.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0164334 Vali Loss: 0.0159479 Test Loss: 0.0251510\n",
      "Validation loss decreased (0.016453 --> 0.015948).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0159623\n",
      "\tspeed: 0.0501s/iter; left time: 1026.6598s\n",
      "\titers: 200, epoch: 9 | loss: 0.0149368\n",
      "\tspeed: 0.0284s/iter; left time: 579.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0161261 Vali Loss: 0.0157977 Test Loss: 0.0278607\n",
      "Validation loss decreased (0.015948 --> 0.015798).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0162833\n",
      "\tspeed: 0.0500s/iter; left time: 1014.1826s\n",
      "\titers: 200, epoch: 10 | loss: 0.0167888\n",
      "\tspeed: 0.0237s/iter; left time: 479.2145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 224 | Train Loss: 0.0157125 Vali Loss: 0.0157265 Test Loss: 0.0291120\n",
      "Validation loss decreased (0.015798 --> 0.015727).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0157385\n",
      "\tspeed: 0.0579s/iter; left time: 1161.2911s\n",
      "\titers: 200, epoch: 11 | loss: 0.0161697\n",
      "\tspeed: 0.0217s/iter; left time: 432.5084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0155772 Vali Loss: 0.0154291 Test Loss: 0.0283270\n",
      "Validation loss decreased (0.015727 --> 0.015429).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0157377\n",
      "\tspeed: 0.0561s/iter; left time: 1113.0318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0161220\n",
      "\tspeed: 0.0223s/iter; left time: 439.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 224 | Train Loss: 0.0153947 Vali Loss: 0.0155128 Test Loss: 0.0267294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0145680\n",
      "\tspeed: 0.0482s/iter; left time: 945.9392s\n",
      "\titers: 200, epoch: 13 | loss: 0.0151161\n",
      "\tspeed: 0.0303s/iter; left time: 591.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0152482 Vali Loss: 0.0152456 Test Loss: 0.0313342\n",
      "Validation loss decreased (0.015429 --> 0.015246).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0144295\n",
      "\tspeed: 0.0499s/iter; left time: 966.7032s\n",
      "\titers: 200, epoch: 14 | loss: 0.0149595\n",
      "\tspeed: 0.0218s/iter; left time: 420.8543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0156610 Vali Loss: 0.0153661 Test Loss: 0.0282838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0138063\n",
      "\tspeed: 0.0495s/iter; left time: 949.3575s\n",
      "\titers: 200, epoch: 15 | loss: 0.0160840\n",
      "\tspeed: 0.0220s/iter; left time: 418.8333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0153227 Vali Loss: 0.0163661 Test Loss: 0.0256972\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0147027\n",
      "\tspeed: 0.0573s/iter; left time: 1084.7788s\n",
      "\titers: 200, epoch: 16 | loss: 0.0159377\n",
      "\tspeed: 0.0230s/iter; left time: 432.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 224 | Train Loss: 0.0152654 Vali Loss: 0.0152266 Test Loss: 0.0313957\n",
      "Validation loss decreased (0.015246 --> 0.015227).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0147857\n",
      "\tspeed: 0.0495s/iter; left time: 926.3405s\n",
      "\titers: 200, epoch: 17 | loss: 0.0158567\n",
      "\tspeed: 0.0276s/iter; left time: 513.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0149680 Vali Loss: 0.0152546 Test Loss: 0.0288141\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0150313\n",
      "\tspeed: 0.0534s/iter; left time: 987.7152s\n",
      "\titers: 200, epoch: 18 | loss: 0.0153670\n",
      "\tspeed: 0.0217s/iter; left time: 398.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0148922 Vali Loss: 0.0151359 Test Loss: 0.0352062\n",
      "Validation loss decreased (0.015227 --> 0.015136).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0152953\n",
      "\tspeed: 0.0577s/iter; left time: 1054.6472s\n",
      "\titers: 200, epoch: 19 | loss: 0.0164243\n",
      "\tspeed: 0.0208s/iter; left time: 378.7296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0154202 Vali Loss: 0.0154077 Test Loss: 0.0260406\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0139980\n",
      "\tspeed: 0.0535s/iter; left time: 965.1725s\n",
      "\titers: 200, epoch: 20 | loss: 0.0153673\n",
      "\tspeed: 0.0294s/iter; left time: 527.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0148775 Vali Loss: 0.0150819 Test Loss: 0.0291436\n",
      "Validation loss decreased (0.015136 --> 0.015082).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0152630\n",
      "\tspeed: 0.0539s/iter; left time: 960.7991s\n",
      "\titers: 200, epoch: 21 | loss: 0.0139147\n",
      "\tspeed: 0.0249s/iter; left time: 441.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 224 | Train Loss: 0.0147524 Vali Loss: 0.0150175 Test Loss: 0.0302568\n",
      "Validation loss decreased (0.015082 --> 0.015018).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0152948\n",
      "\tspeed: 0.0604s/iter; left time: 1063.5700s\n",
      "\titers: 200, epoch: 22 | loss: 0.0151246\n",
      "\tspeed: 0.0221s/iter; left time: 386.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0147291 Vali Loss: 0.0150637 Test Loss: 0.0294112\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0138211\n",
      "\tspeed: 0.0629s/iter; left time: 1092.2086s\n",
      "\titers: 200, epoch: 23 | loss: 0.0160007\n",
      "\tspeed: 0.0218s/iter; left time: 377.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 224 | Train Loss: 0.0146824 Vali Loss: 0.0149438 Test Loss: 0.0299825\n",
      "Validation loss decreased (0.015018 --> 0.014944).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0137403\n",
      "\tspeed: 0.0496s/iter; left time: 851.4460s\n",
      "\titers: 200, epoch: 24 | loss: 0.0137934\n",
      "\tspeed: 0.0311s/iter; left time: 529.4937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0146960 Vali Loss: 0.0149939 Test Loss: 0.0284647\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0147044\n",
      "\tspeed: 0.0503s/iter; left time: 851.2193s\n",
      "\titers: 200, epoch: 25 | loss: 0.0162568\n",
      "\tspeed: 0.0231s/iter; left time: 388.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0146439 Vali Loss: 0.0149701 Test Loss: 0.0297256\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0135267\n",
      "\tspeed: 0.0602s/iter; left time: 1005.8288s\n",
      "\titers: 200, epoch: 26 | loss: 0.0140600\n",
      "\tspeed: 0.0210s/iter; left time: 348.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0146344 Vali Loss: 0.0149647 Test Loss: 0.0292373\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0148893\n",
      "\tspeed: 0.0540s/iter; left time: 890.1667s\n",
      "\titers: 200, epoch: 27 | loss: 0.0141754\n",
      "\tspeed: 0.0248s/iter; left time: 406.3985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 224 | Train Loss: 0.0145488 Vali Loss: 0.0149350 Test Loss: 0.0312378\n",
      "Validation loss decreased (0.014944 --> 0.014935).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0155144\n",
      "\tspeed: 0.0496s/iter; left time: 805.6401s\n",
      "\titers: 200, epoch: 28 | loss: 0.0170834\n",
      "\tspeed: 0.0262s/iter; left time: 423.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 224 | Train Loss: 0.0145691 Vali Loss: 0.0149834 Test Loss: 0.0311552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0156587\n",
      "\tspeed: 0.0500s/iter; left time: 801.7907s\n",
      "\titers: 200, epoch: 29 | loss: 0.0152508\n",
      "\tspeed: 0.0218s/iter; left time: 346.8408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0145267 Vali Loss: 0.0149104 Test Loss: 0.0324814\n",
      "Validation loss decreased (0.014935 --> 0.014910).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0140890\n",
      "\tspeed: 0.0583s/iter; left time: 921.2751s\n",
      "\titers: 200, epoch: 30 | loss: 0.0135267\n",
      "\tspeed: 0.0219s/iter; left time: 344.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0145276 Vali Loss: 0.0149391 Test Loss: 0.0319644\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0140089\n",
      "\tspeed: 0.0494s/iter; left time: 769.8832s\n",
      "\titers: 200, epoch: 31 | loss: 0.0148899\n",
      "\tspeed: 0.0288s/iter; left time: 446.1483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0144888 Vali Loss: 0.0148844 Test Loss: 0.0310164\n",
      "Validation loss decreased (0.014910 --> 0.014884).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0149111\n",
      "\tspeed: 0.0499s/iter; left time: 766.1411s\n",
      "\titers: 200, epoch: 32 | loss: 0.0149692\n",
      "\tspeed: 0.0212s/iter; left time: 323.2594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0145123 Vali Loss: 0.0149362 Test Loss: 0.0324887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0149417\n",
      "\tspeed: 0.0498s/iter; left time: 753.7339s\n",
      "\titers: 200, epoch: 33 | loss: 0.0151715\n",
      "\tspeed: 0.0259s/iter; left time: 389.3683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0145124 Vali Loss: 0.0149080 Test Loss: 0.0316317\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0130034\n",
      "\tspeed: 0.0498s/iter; left time: 743.0850s\n",
      "\titers: 200, epoch: 34 | loss: 0.0153687\n",
      "\tspeed: 0.0242s/iter; left time: 358.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0144306 Vali Loss: 0.0149091 Test Loss: 0.0325113\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0147780\n",
      "\tspeed: 0.0527s/iter; left time: 773.5512s\n",
      "\titers: 200, epoch: 35 | loss: 0.0155870\n",
      "\tspeed: 0.0241s/iter; left time: 350.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 224 | Train Loss: 0.0145847 Vali Loss: 0.0149064 Test Loss: 0.0315548\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0142555\n",
      "\tspeed: 0.0543s/iter; left time: 784.7606s\n",
      "\titers: 200, epoch: 36 | loss: 0.0138206\n",
      "\tspeed: 0.0223s/iter; left time: 320.6794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 224 | Train Loss: 0.0145906 Vali Loss: 0.0149479 Test Loss: 0.0295329\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0151577\n",
      "\tspeed: 0.0573s/iter; left time: 815.2827s\n",
      "\titers: 200, epoch: 37 | loss: 0.0137488\n",
      "\tspeed: 0.0237s/iter; left time: 334.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0144642 Vali Loss: 0.0148912 Test Loss: 0.0300454\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0134963\n",
      "\tspeed: 0.0567s/iter; left time: 794.7362s\n",
      "\titers: 200, epoch: 38 | loss: 0.0137275\n",
      "\tspeed: 0.0229s/iter; left time: 318.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0147023 Vali Loss: 0.0149361 Test Loss: 0.0297693\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0135200\n",
      "\tspeed: 0.0570s/iter; left time: 786.6198s\n",
      "\titers: 200, epoch: 39 | loss: 0.0149992\n",
      "\tspeed: 0.0232s/iter; left time: 317.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0145202 Vali Loss: 0.0149646 Test Loss: 0.0300370\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0150121\n",
      "\tspeed: 0.0539s/iter; left time: 730.6786s\n",
      "\titers: 200, epoch: 40 | loss: 0.0140267\n",
      "\tspeed: 0.0219s/iter; left time: 295.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 224 | Train Loss: 0.0145302 Vali Loss: 0.0149335 Test Loss: 0.0295037\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0145172\n",
      "\tspeed: 0.0535s/iter; left time: 714.4068s\n",
      "\titers: 200, epoch: 41 | loss: 0.0145294\n",
      "\tspeed: 0.0255s/iter; left time: 337.3747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 224 | Train Loss: 0.0144130 Vali Loss: 0.0149308 Test Loss: 0.0298137\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.031016401946544647, rmse:0.1761147379875183, mae:0.11428863555192947, rse:0.5173721313476562\n",
      "Intermediate time for ES and pred_len 96: 00h:05m:26.67s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1284169\n",
      "\tspeed: 0.0524s/iter; left time: 1163.3076s\n",
      "\titers: 200, epoch: 1 | loss: 0.1172287\n",
      "\tspeed: 0.0246s/iter; left time: 544.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 223 | Train Loss: 0.1315195 Vali Loss: 0.0755308 Test Loss: 0.0935711\n",
      "Validation loss decreased (inf --> 0.075531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0394520\n",
      "\tspeed: 0.0530s/iter; left time: 1164.6696s\n",
      "\titers: 200, epoch: 2 | loss: 0.0300034\n",
      "\tspeed: 0.0277s/iter; left time: 606.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0483511 Vali Loss: 0.0254592 Test Loss: 0.0312638\n",
      "Validation loss decreased (0.075531 --> 0.025459).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0298315\n",
      "\tspeed: 0.0561s/iter; left time: 1221.3866s\n",
      "\titers: 200, epoch: 3 | loss: 0.0257679\n",
      "\tspeed: 0.0241s/iter; left time: 522.1400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 223 | Train Loss: 0.0275876 Vali Loss: 0.0222081 Test Loss: 0.0273541\n",
      "Validation loss decreased (0.025459 --> 0.022208).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0234629\n",
      "\tspeed: 0.0582s/iter; left time: 1252.6069s\n",
      "\titers: 200, epoch: 4 | loss: 0.0214712\n",
      "\tspeed: 0.0207s/iter; left time: 443.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0232781 Vali Loss: 0.0205097 Test Loss: 0.0334549\n",
      "Validation loss decreased (0.022208 --> 0.020510).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0214271\n",
      "\tspeed: 0.0517s/iter; left time: 1102.6461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0183603\n",
      "\tspeed: 0.0248s/iter; left time: 526.3614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0199682 Vali Loss: 0.0189914 Test Loss: 0.0321025\n",
      "Validation loss decreased (0.020510 --> 0.018991).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0175757\n",
      "\tspeed: 0.0596s/iter; left time: 1256.9485s\n",
      "\titers: 200, epoch: 6 | loss: 0.0184193\n",
      "\tspeed: 0.0235s/iter; left time: 492.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0184786 Vali Loss: 0.0183154 Test Loss: 0.0325361\n",
      "Validation loss decreased (0.018991 --> 0.018315).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0176433\n",
      "\tspeed: 0.0559s/iter; left time: 1166.0189s\n",
      "\titers: 200, epoch: 7 | loss: 0.0172115\n",
      "\tspeed: 0.0265s/iter; left time: 549.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0178102 Vali Loss: 0.0178938 Test Loss: 0.0310357\n",
      "Validation loss decreased (0.018315 --> 0.017894).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0161289\n",
      "\tspeed: 0.0564s/iter; left time: 1165.1145s\n",
      "\titers: 200, epoch: 8 | loss: 0.0173672\n",
      "\tspeed: 0.0304s/iter; left time: 624.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0174180 Vali Loss: 0.0177719 Test Loss: 0.0310839\n",
      "Validation loss decreased (0.017894 --> 0.017772).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0172031\n",
      "\tspeed: 0.0568s/iter; left time: 1159.1500s\n",
      "\titers: 200, epoch: 9 | loss: 0.0161021\n",
      "\tspeed: 0.0246s/iter; left time: 500.3097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0170769 Vali Loss: 0.0179210 Test Loss: 0.0304198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0170793\n",
      "\tspeed: 0.0587s/iter; left time: 1186.3701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0183556\n",
      "\tspeed: 0.0241s/iter; left time: 484.8811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 223 | Train Loss: 0.0170377 Vali Loss: 0.0174098 Test Loss: 0.0347562\n",
      "Validation loss decreased (0.017772 --> 0.017410).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0170728\n",
      "\tspeed: 0.0588s/iter; left time: 1173.3801s\n",
      "\titers: 200, epoch: 11 | loss: 0.0171281\n",
      "\tspeed: 0.0233s/iter; left time: 462.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 223 | Train Loss: 0.0183533 Vali Loss: 0.0177499 Test Loss: 0.0281153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0142452\n",
      "\tspeed: 0.0619s/iter; left time: 1222.7719s\n",
      "\titers: 200, epoch: 12 | loss: 0.0168665\n",
      "\tspeed: 0.0284s/iter; left time: 558.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0166846 Vali Loss: 0.0173330 Test Loss: 0.0298354\n",
      "Validation loss decreased (0.017410 --> 0.017333).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0161570\n",
      "\tspeed: 0.0564s/iter; left time: 1101.0648s\n",
      "\titers: 200, epoch: 13 | loss: 0.0165948\n",
      "\tspeed: 0.0299s/iter; left time: 581.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 223 | Train Loss: 0.0166812 Vali Loss: 0.0173812 Test Loss: 0.0305343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0160646\n",
      "\tspeed: 0.0580s/iter; left time: 1120.3349s\n",
      "\titers: 200, epoch: 14 | loss: 0.0174675\n",
      "\tspeed: 0.0300s/iter; left time: 575.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 223 | Train Loss: 0.0164507 Vali Loss: 0.0174721 Test Loss: 0.0310623\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0159258\n",
      "\tspeed: 0.0585s/iter; left time: 1115.2378s\n",
      "\titers: 200, epoch: 15 | loss: 0.0180293\n",
      "\tspeed: 0.0224s/iter; left time: 424.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 223 | Train Loss: 0.0163814 Vali Loss: 0.0171970 Test Loss: 0.0328074\n",
      "Validation loss decreased (0.017333 --> 0.017197).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0171973\n",
      "\tspeed: 0.0501s/iter; left time: 944.4440s\n",
      "\titers: 200, epoch: 16 | loss: 0.0169949\n",
      "\tspeed: 0.0218s/iter; left time: 408.5448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0166250 Vali Loss: 0.0173631 Test Loss: 0.0302975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0154431\n",
      "\tspeed: 0.0539s/iter; left time: 1005.0651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0158963\n",
      "\tspeed: 0.0213s/iter; left time: 394.8036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 223 | Train Loss: 0.0163361 Vali Loss: 0.0173100 Test Loss: 0.0320395\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0158747\n",
      "\tspeed: 0.0562s/iter; left time: 1034.8290s\n",
      "\titers: 200, epoch: 18 | loss: 0.0172246\n",
      "\tspeed: 0.0217s/iter; left time: 396.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0162627 Vali Loss: 0.0172289 Test Loss: 0.0336265\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0153920\n",
      "\tspeed: 0.0572s/iter; left time: 1039.5450s\n",
      "\titers: 200, epoch: 19 | loss: 0.0159192\n",
      "\tspeed: 0.0217s/iter; left time: 393.0789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0161746 Vali Loss: 0.0171079 Test Loss: 0.0315786\n",
      "Validation loss decreased (0.017197 --> 0.017108).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0172178\n",
      "\tspeed: 0.0557s/iter; left time: 1001.4507s\n",
      "\titers: 200, epoch: 20 | loss: 0.0154738\n",
      "\tspeed: 0.0216s/iter; left time: 385.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0162445 Vali Loss: 0.0171308 Test Loss: 0.0327551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0156633\n",
      "\tspeed: 0.0563s/iter; left time: 998.0374s\n",
      "\titers: 200, epoch: 21 | loss: 0.0158444\n",
      "\tspeed: 0.0223s/iter; left time: 392.8931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0161826 Vali Loss: 0.0171602 Test Loss: 0.0327335\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0160388\n",
      "\tspeed: 0.0589s/iter; left time: 1030.9458s\n",
      "\titers: 200, epoch: 22 | loss: 0.0170065\n",
      "\tspeed: 0.0209s/iter; left time: 364.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0160776 Vali Loss: 0.0170937 Test Loss: 0.0331659\n",
      "Validation loss decreased (0.017108 --> 0.017094).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0147220\n",
      "\tspeed: 0.0566s/iter; left time: 979.3674s\n",
      "\titers: 200, epoch: 23 | loss: 0.0174204\n",
      "\tspeed: 0.0218s/iter; left time: 374.5212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0160284 Vali Loss: 0.0170745 Test Loss: 0.0332947\n",
      "Validation loss decreased (0.017094 --> 0.017074).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0157670\n",
      "\tspeed: 0.0562s/iter; left time: 958.7489s\n",
      "\titers: 200, epoch: 24 | loss: 0.0147003\n",
      "\tspeed: 0.0212s/iter; left time: 359.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0159721 Vali Loss: 0.0169896 Test Loss: 0.0325431\n",
      "Validation loss decreased (0.017074 --> 0.016990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0167779\n",
      "\tspeed: 0.0568s/iter; left time: 957.3935s\n",
      "\titers: 200, epoch: 25 | loss: 0.0158870\n",
      "\tspeed: 0.0217s/iter; left time: 363.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0160009 Vali Loss: 0.0169696 Test Loss: 0.0342427\n",
      "Validation loss decreased (0.016990 --> 0.016970).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0182935\n",
      "\tspeed: 0.0596s/iter; left time: 990.8976s\n",
      "\titers: 200, epoch: 26 | loss: 0.0152293\n",
      "\tspeed: 0.0222s/iter; left time: 366.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0159626 Vali Loss: 0.0170733 Test Loss: 0.0365577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0150043\n",
      "\tspeed: 0.0633s/iter; left time: 1037.6241s\n",
      "\titers: 200, epoch: 27 | loss: 0.0167594\n",
      "\tspeed: 0.0218s/iter; left time: 355.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 223 | Train Loss: 0.0158955 Vali Loss: 0.0169665 Test Loss: 0.0339735\n",
      "Validation loss decreased (0.016970 --> 0.016967).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0150428\n",
      "\tspeed: 0.0610s/iter; left time: 987.0886s\n",
      "\titers: 200, epoch: 28 | loss: 0.0171211\n",
      "\tspeed: 0.0215s/iter; left time: 346.4888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0160956 Vali Loss: 0.0170350 Test Loss: 0.0318645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0164731\n",
      "\tspeed: 0.0489s/iter; left time: 780.6280s\n",
      "\titers: 200, epoch: 29 | loss: 0.0175466\n",
      "\tspeed: 0.0242s/iter; left time: 383.6763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0159007 Vali Loss: 0.0170863 Test Loss: 0.0330290\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0160695\n",
      "\tspeed: 0.0539s/iter; left time: 847.6881s\n",
      "\titers: 200, epoch: 30 | loss: 0.0164711\n",
      "\tspeed: 0.0228s/iter; left time: 356.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0158933 Vali Loss: 0.0171437 Test Loss: 0.0331343\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0156804\n",
      "\tspeed: 0.0567s/iter; left time: 878.9248s\n",
      "\titers: 200, epoch: 31 | loss: 0.0155068\n",
      "\tspeed: 0.0244s/iter; left time: 376.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0158197 Vali Loss: 0.0170106 Test Loss: 0.0339011\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0151057\n",
      "\tspeed: 0.0530s/iter; left time: 810.8884s\n",
      "\titers: 200, epoch: 32 | loss: 0.0165237\n",
      "\tspeed: 0.0235s/iter; left time: 356.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0159418 Vali Loss: 0.0170865 Test Loss: 0.0326944\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0154904\n",
      "\tspeed: 0.0533s/iter; left time: 803.4754s\n",
      "\titers: 200, epoch: 33 | loss: 0.0160965\n",
      "\tspeed: 0.0235s/iter; left time: 351.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.0159461 Vali Loss: 0.0170641 Test Loss: 0.0318416\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0153600\n",
      "\tspeed: 0.0536s/iter; left time: 796.0348s\n",
      "\titers: 200, epoch: 34 | loss: 0.0170636\n",
      "\tspeed: 0.0245s/iter; left time: 361.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.0158354 Vali Loss: 0.0170254 Test Loss: 0.0326165\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0164788\n",
      "\tspeed: 0.0520s/iter; left time: 760.6979s\n",
      "\titers: 200, epoch: 35 | loss: 0.0158054\n",
      "\tspeed: 0.0263s/iter; left time: 381.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0158333 Vali Loss: 0.0169850 Test Loss: 0.0334912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0153885\n",
      "\tspeed: 0.0530s/iter; left time: 762.3483s\n",
      "\titers: 200, epoch: 36 | loss: 0.0159685\n",
      "\tspeed: 0.0277s/iter; left time: 396.3024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.0157919 Vali Loss: 0.0170162 Test Loss: 0.0343361\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0170595\n",
      "\tspeed: 0.0532s/iter; left time: 753.4112s\n",
      "\titers: 200, epoch: 37 | loss: 0.0156103\n",
      "\tspeed: 0.0273s/iter; left time: 384.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 223 | Train Loss: 0.0157774 Vali Loss: 0.0169519 Test Loss: 0.0330856\n",
      "Validation loss decreased (0.016967 --> 0.016952).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0175597\n",
      "\tspeed: 0.0543s/iter; left time: 757.3635s\n",
      "\titers: 200, epoch: 38 | loss: 0.0155797\n",
      "\tspeed: 0.0234s/iter; left time: 324.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0158271 Vali Loss: 0.0170436 Test Loss: 0.0333813\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0153492\n",
      "\tspeed: 0.0539s/iter; left time: 739.9745s\n",
      "\titers: 200, epoch: 39 | loss: 0.0160599\n",
      "\tspeed: 0.0229s/iter; left time: 311.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0157613 Vali Loss: 0.0169965 Test Loss: 0.0336042\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0156489\n",
      "\tspeed: 0.0547s/iter; left time: 739.1188s\n",
      "\titers: 200, epoch: 40 | loss: 0.0156041\n",
      "\tspeed: 0.0253s/iter; left time: 339.7186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0159860 Vali Loss: 0.0170430 Test Loss: 0.0325757\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0168099\n",
      "\tspeed: 0.0561s/iter; left time: 745.1231s\n",
      "\titers: 200, epoch: 41 | loss: 0.0156008\n",
      "\tspeed: 0.0256s/iter; left time: 337.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0157786 Vali Loss: 0.0170154 Test Loss: 0.0328521\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0149853\n",
      "\tspeed: 0.0556s/iter; left time: 725.7657s\n",
      "\titers: 200, epoch: 42 | loss: 0.0156122\n",
      "\tspeed: 0.0287s/iter; left time: 372.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0157521 Vali Loss: 0.0169720 Test Loss: 0.0328154\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0155255\n",
      "\tspeed: 0.0493s/iter; left time: 632.3585s\n",
      "\titers: 200, epoch: 43 | loss: 0.0152470\n",
      "\tspeed: 0.0222s/iter; left time: 282.1869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0157695 Vali Loss: 0.0169560 Test Loss: 0.0332695\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0151010\n",
      "\tspeed: 0.0468s/iter; left time: 589.7841s\n",
      "\titers: 200, epoch: 44 | loss: 0.0157190\n",
      "\tspeed: 0.0252s/iter; left time: 315.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0158228 Vali Loss: 0.0170257 Test Loss: 0.0328763\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0156760\n",
      "\tspeed: 0.0569s/iter; left time: 704.9917s\n",
      "\titers: 200, epoch: 45 | loss: 0.0156764\n",
      "\tspeed: 0.0241s/iter; left time: 296.7446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 223 | Train Loss: 0.0157282 Vali Loss: 0.0169368 Test Loss: 0.0327699\n",
      "Validation loss decreased (0.016952 --> 0.016937).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0161030\n",
      "\tspeed: 0.0577s/iter; left time: 701.9405s\n",
      "\titers: 200, epoch: 46 | loss: 0.0172997\n",
      "\tspeed: 0.0243s/iter; left time: 293.1598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 223 | Train Loss: 0.0157710 Vali Loss: 0.0169600 Test Loss: 0.0329193\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0147430\n",
      "\tspeed: 0.0590s/iter; left time: 704.2325s\n",
      "\titers: 200, epoch: 47 | loss: 0.0161302\n",
      "\tspeed: 0.0267s/iter; left time: 316.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0157679 Vali Loss: 0.0169480 Test Loss: 0.0331634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0164486\n",
      "\tspeed: 0.0602s/iter; left time: 705.8398s\n",
      "\titers: 200, epoch: 48 | loss: 0.0148175\n",
      "\tspeed: 0.0279s/iter; left time: 324.3523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0157819 Vali Loss: 0.0169770 Test Loss: 0.0333828\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0163971\n",
      "\tspeed: 0.0550s/iter; left time: 632.5106s\n",
      "\titers: 200, epoch: 49 | loss: 0.0148533\n",
      "\tspeed: 0.0324s/iter; left time: 368.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 223 | Train Loss: 0.0157606 Vali Loss: 0.0168984 Test Loss: 0.0325417\n",
      "Validation loss decreased (0.016937 --> 0.016898).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0165030\n",
      "\tspeed: 0.0520s/iter; left time: 585.6893s\n",
      "\titers: 200, epoch: 50 | loss: 0.0154998\n",
      "\tspeed: 0.0303s/iter; left time: 338.1065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0157381 Vali Loss: 0.0169541 Test Loss: 0.0337758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0161881\n",
      "\tspeed: 0.0580s/iter; left time: 640.8526s\n",
      "\titers: 200, epoch: 51 | loss: 0.0148654\n",
      "\tspeed: 0.0242s/iter; left time: 265.1323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.16s\n",
      "Steps: 223 | Train Loss: 0.0157762 Vali Loss: 0.0169161 Test Loss: 0.0328058\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0165587\n",
      "\tspeed: 0.0585s/iter; left time: 633.8590s\n",
      "\titers: 200, epoch: 52 | loss: 0.0159679\n",
      "\tspeed: 0.0238s/iter; left time: 254.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 223 | Train Loss: 0.0157141 Vali Loss: 0.0169452 Test Loss: 0.0326098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0154703\n",
      "\tspeed: 0.0578s/iter; left time: 613.2819s\n",
      "\titers: 200, epoch: 53 | loss: 0.0147402\n",
      "\tspeed: 0.0239s/iter; left time: 251.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 223 | Train Loss: 0.0157296 Vali Loss: 0.0169105 Test Loss: 0.0328408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0152968\n",
      "\tspeed: 0.0619s/iter; left time: 642.4387s\n",
      "\titers: 200, epoch: 54 | loss: 0.0161895\n",
      "\tspeed: 0.0228s/iter; left time: 234.4221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.0157269 Vali Loss: 0.0169528 Test Loss: 0.0334324\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0161664\n",
      "\tspeed: 0.0598s/iter; left time: 607.6549s\n",
      "\titers: 200, epoch: 55 | loss: 0.0158240\n",
      "\tspeed: 0.0304s/iter; left time: 305.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 223 | Train Loss: 0.0157380 Vali Loss: 0.0169289 Test Loss: 0.0334821\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0162431\n",
      "\tspeed: 0.0574s/iter; left time: 569.9137s\n",
      "\titers: 200, epoch: 56 | loss: 0.0165172\n",
      "\tspeed: 0.0216s/iter; left time: 212.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0157867 Vali Loss: 0.0168710 Test Loss: 0.0329189\n",
      "Validation loss decreased (0.016898 --> 0.016871).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0147179\n",
      "\tspeed: 0.0473s/iter; left time: 459.4196s\n",
      "\titers: 200, epoch: 57 | loss: 0.0167741\n",
      "\tspeed: 0.0245s/iter; left time: 235.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0158918 Vali Loss: 0.0170040 Test Loss: 0.0338830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0151420\n",
      "\tspeed: 0.0565s/iter; left time: 536.0585s\n",
      "\titers: 200, epoch: 58 | loss: 0.0155338\n",
      "\tspeed: 0.0262s/iter; left time: 246.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 223 | Train Loss: 0.0157274 Vali Loss: 0.0169733 Test Loss: 0.0335529\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0157903\n",
      "\tspeed: 0.0601s/iter; left time: 556.7467s\n",
      "\titers: 200, epoch: 59 | loss: 0.0146947\n",
      "\tspeed: 0.0230s/iter; left time: 210.5659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 223 | Train Loss: 0.0157228 Vali Loss: 0.0170033 Test Loss: 0.0348816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0163458\n",
      "\tspeed: 0.0610s/iter; left time: 551.2444s\n",
      "\titers: 200, epoch: 60 | loss: 0.0159373\n",
      "\tspeed: 0.0242s/iter; left time: 216.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0157675 Vali Loss: 0.0168795 Test Loss: 0.0327201\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0158163\n",
      "\tspeed: 0.0611s/iter; left time: 539.3154s\n",
      "\titers: 200, epoch: 61 | loss: 0.0149162\n",
      "\tspeed: 0.0266s/iter; left time: 232.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0157603 Vali Loss: 0.0169108 Test Loss: 0.0329584\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0162279\n",
      "\tspeed: 0.0564s/iter; left time: 484.8630s\n",
      "\titers: 200, epoch: 62 | loss: 0.0151691\n",
      "\tspeed: 0.0295s/iter; left time: 251.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 223 | Train Loss: 0.0157876 Vali Loss: 0.0169134 Test Loss: 0.0335492\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0156255\n",
      "\tspeed: 0.0505s/iter; left time: 422.5204s\n",
      "\titers: 200, epoch: 63 | loss: 0.0155422\n",
      "\tspeed: 0.0305s/iter; left time: 252.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 223 | Train Loss: 0.0157253 Vali Loss: 0.0169123 Test Loss: 0.0329814\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0164308\n",
      "\tspeed: 0.0583s/iter; left time: 475.5381s\n",
      "\titers: 200, epoch: 64 | loss: 0.0141026\n",
      "\tspeed: 0.0235s/iter; left time: 189.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 223 | Train Loss: 0.0157296 Vali Loss: 0.0169038 Test Loss: 0.0327831\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0158460\n",
      "\tspeed: 0.0586s/iter; left time: 464.7772s\n",
      "\titers: 200, epoch: 65 | loss: 0.0152336\n",
      "\tspeed: 0.0255s/iter; left time: 199.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 223 | Train Loss: 0.0157248 Vali Loss: 0.0169858 Test Loss: 0.0333585\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0160218\n",
      "\tspeed: 0.0621s/iter; left time: 478.1986s\n",
      "\titers: 200, epoch: 66 | loss: 0.0162508\n",
      "\tspeed: 0.0244s/iter; left time: 185.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 223 | Train Loss: 0.0157725 Vali Loss: 0.0169603 Test Loss: 0.0329206\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03291890770196915, rmse:0.181435689330101, mae:0.12120398133993149, rse:0.5330417156219482\n",
      "Intermediate time for ES and pred_len 168: 00h:09m:06.54s\n",
      "Intermediate time for ES: 00h:20m:10.26s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1128716\n",
      "\tspeed: 0.0367s/iter; left time: 826.3518s\n",
      "\titers: 200, epoch: 1 | loss: 0.0919740\n",
      "\tspeed: 0.0243s/iter; left time: 544.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 226 | Train Loss: 0.1099309 Vali Loss: 0.0601149 Test Loss: 0.0664455\n",
      "Validation loss decreased (inf --> 0.060115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0454220\n",
      "\tspeed: 0.0475s/iter; left time: 1057.0121s\n",
      "\titers: 200, epoch: 2 | loss: 0.0240695\n",
      "\tspeed: 0.0253s/iter; left time: 562.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0443392 Vali Loss: 0.0177004 Test Loss: 0.0197107\n",
      "Validation loss decreased (0.060115 --> 0.017700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0174665\n",
      "\tspeed: 0.0471s/iter; left time: 1037.8882s\n",
      "\titers: 200, epoch: 3 | loss: 0.0156029\n",
      "\tspeed: 0.0259s/iter; left time: 569.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0176472 Vali Loss: 0.0159071 Test Loss: 0.0172814\n",
      "Validation loss decreased (0.017700 --> 0.015907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0167951\n",
      "\tspeed: 0.0426s/iter; left time: 929.6801s\n",
      "\titers: 200, epoch: 4 | loss: 0.0133514\n",
      "\tspeed: 0.0227s/iter; left time: 493.0963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 226 | Train Loss: 0.0145339 Vali Loss: 0.0150010 Test Loss: 0.0160672\n",
      "Validation loss decreased (0.015907 --> 0.015001).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0125075\n",
      "\tspeed: 0.0489s/iter; left time: 1056.3346s\n",
      "\titers: 200, epoch: 5 | loss: 0.0118828\n",
      "\tspeed: 0.0257s/iter; left time: 553.4823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 226 | Train Loss: 0.0128717 Vali Loss: 0.0137019 Test Loss: 0.0140345\n",
      "Validation loss decreased (0.015001 --> 0.013702).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0114066\n",
      "\tspeed: 0.0476s/iter; left time: 1017.8518s\n",
      "\titers: 200, epoch: 6 | loss: 0.0113185\n",
      "\tspeed: 0.0245s/iter; left time: 521.6975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 226 | Train Loss: 0.0118683 Vali Loss: 0.0131602 Test Loss: 0.0132944\n",
      "Validation loss decreased (0.013702 --> 0.013160).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0114604\n",
      "\tspeed: 0.0449s/iter; left time: 950.4081s\n",
      "\titers: 200, epoch: 7 | loss: 0.0117390\n",
      "\tspeed: 0.0224s/iter; left time: 472.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 226 | Train Loss: 0.0110327 Vali Loss: 0.0118688 Test Loss: 0.0124213\n",
      "Validation loss decreased (0.013160 --> 0.011869).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0095407\n",
      "\tspeed: 0.0464s/iter; left time: 971.3975s\n",
      "\titers: 200, epoch: 8 | loss: 0.0096248\n",
      "\tspeed: 0.0242s/iter; left time: 504.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0102839 Vali Loss: 0.0116305 Test Loss: 0.0123497\n",
      "Validation loss decreased (0.011869 --> 0.011631).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0097565\n",
      "\tspeed: 0.0488s/iter; left time: 1010.0380s\n",
      "\titers: 200, epoch: 9 | loss: 0.0093351\n",
      "\tspeed: 0.0252s/iter; left time: 519.7482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 226 | Train Loss: 0.0097569 Vali Loss: 0.0111807 Test Loss: 0.0120926\n",
      "Validation loss decreased (0.011631 --> 0.011181).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0086483\n",
      "\tspeed: 0.0487s/iter; left time: 996.2656s\n",
      "\titers: 200, epoch: 10 | loss: 0.0097031\n",
      "\tspeed: 0.0255s/iter; left time: 519.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 226 | Train Loss: 0.0093534 Vali Loss: 0.0108828 Test Loss: 0.0119646\n",
      "Validation loss decreased (0.011181 --> 0.010883).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0088099\n",
      "\tspeed: 0.0471s/iter; left time: 952.5624s\n",
      "\titers: 200, epoch: 11 | loss: 0.0084883\n",
      "\tspeed: 0.0242s/iter; left time: 486.7701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 226 | Train Loss: 0.0090376 Vali Loss: 0.0107497 Test Loss: 0.0119239\n",
      "Validation loss decreased (0.010883 --> 0.010750).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0105577\n",
      "\tspeed: 0.0452s/iter; left time: 904.0544s\n",
      "\titers: 200, epoch: 12 | loss: 0.0092621\n",
      "\tspeed: 0.0248s/iter; left time: 493.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0087718 Vali Loss: 0.0106976 Test Loss: 0.0119551\n",
      "Validation loss decreased (0.010750 --> 0.010698).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0079246\n",
      "\tspeed: 0.0404s/iter; left time: 799.8532s\n",
      "\titers: 200, epoch: 13 | loss: 0.0085691\n",
      "\tspeed: 0.0254s/iter; left time: 499.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 226 | Train Loss: 0.0085790 Vali Loss: 0.0104539 Test Loss: 0.0117490\n",
      "Validation loss decreased (0.010698 --> 0.010454).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0095796\n",
      "\tspeed: 0.0490s/iter; left time: 958.9949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0087225\n",
      "\tspeed: 0.0257s/iter; left time: 500.5856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0084359 Vali Loss: 0.0104884 Test Loss: 0.0118595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0077258\n",
      "\tspeed: 0.0465s/iter; left time: 899.1372s\n",
      "\titers: 200, epoch: 15 | loss: 0.0071234\n",
      "\tspeed: 0.0264s/iter; left time: 507.8580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0082627 Vali Loss: 0.0103015 Test Loss: 0.0115612\n",
      "Validation loss decreased (0.010454 --> 0.010302).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0081572\n",
      "\tspeed: 0.0468s/iter; left time: 894.6238s\n",
      "\titers: 200, epoch: 16 | loss: 0.0073905\n",
      "\tspeed: 0.0280s/iter; left time: 532.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0081118 Vali Loss: 0.0102584 Test Loss: 0.0115973\n",
      "Validation loss decreased (0.010302 --> 0.010258).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0077903\n",
      "\tspeed: 0.0450s/iter; left time: 850.3065s\n",
      "\titers: 200, epoch: 17 | loss: 0.0085271\n",
      "\tspeed: 0.0272s/iter; left time: 510.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 226 | Train Loss: 0.0080381 Vali Loss: 0.0102395 Test Loss: 0.0115598\n",
      "Validation loss decreased (0.010258 --> 0.010239).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0074358\n",
      "\tspeed: 0.0483s/iter; left time: 901.3562s\n",
      "\titers: 200, epoch: 18 | loss: 0.0079556\n",
      "\tspeed: 0.0273s/iter; left time: 507.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 226 | Train Loss: 0.0080005 Vali Loss: 0.0101840 Test Loss: 0.0115057\n",
      "Validation loss decreased (0.010239 --> 0.010184).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0083683\n",
      "\tspeed: 0.0481s/iter; left time: 887.3875s\n",
      "\titers: 200, epoch: 19 | loss: 0.0084214\n",
      "\tspeed: 0.0279s/iter; left time: 510.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0078926 Vali Loss: 0.0100710 Test Loss: 0.0114132\n",
      "Validation loss decreased (0.010184 --> 0.010071).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0084008\n",
      "\tspeed: 0.0459s/iter; left time: 835.2010s\n",
      "\titers: 200, epoch: 20 | loss: 0.0095158\n",
      "\tspeed: 0.0275s/iter; left time: 497.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 226 | Train Loss: 0.0078249 Vali Loss: 0.0101010 Test Loss: 0.0114476\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0076617\n",
      "\tspeed: 0.0457s/iter; left time: 821.0012s\n",
      "\titers: 200, epoch: 21 | loss: 0.0072457\n",
      "\tspeed: 0.0245s/iter; left time: 438.2443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 226 | Train Loss: 0.0077804 Vali Loss: 0.0100627 Test Loss: 0.0113515\n",
      "Validation loss decreased (0.010071 --> 0.010063).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0068569\n",
      "\tspeed: 0.0459s/iter; left time: 814.8669s\n",
      "\titers: 200, epoch: 22 | loss: 0.0080052\n",
      "\tspeed: 0.0259s/iter; left time: 457.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0077491 Vali Loss: 0.0100271 Test Loss: 0.0113290\n",
      "Validation loss decreased (0.010063 --> 0.010027).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0075235\n",
      "\tspeed: 0.0487s/iter; left time: 853.9193s\n",
      "\titers: 200, epoch: 23 | loss: 0.0069177\n",
      "\tspeed: 0.0224s/iter; left time: 389.7305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 226 | Train Loss: 0.0076993 Vali Loss: 0.0099996 Test Loss: 0.0113290\n",
      "Validation loss decreased (0.010027 --> 0.010000).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0078292\n",
      "\tspeed: 0.0469s/iter; left time: 810.7168s\n",
      "\titers: 200, epoch: 24 | loss: 0.0076700\n",
      "\tspeed: 0.0269s/iter; left time: 463.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0076460 Vali Loss: 0.0099254 Test Loss: 0.0112511\n",
      "Validation loss decreased (0.010000 --> 0.009925).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0077398\n",
      "\tspeed: 0.0470s/iter; left time: 802.2339s\n",
      "\titers: 200, epoch: 25 | loss: 0.0080779\n",
      "\tspeed: 0.0264s/iter; left time: 447.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0076634 Vali Loss: 0.0099582 Test Loss: 0.0112776\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0074780\n",
      "\tspeed: 0.0466s/iter; left time: 785.9828s\n",
      "\titers: 200, epoch: 26 | loss: 0.0075827\n",
      "\tspeed: 0.0261s/iter; left time: 436.3797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0076121 Vali Loss: 0.0099094 Test Loss: 0.0112128\n",
      "Validation loss decreased (0.009925 --> 0.009909).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0079850\n",
      "\tspeed: 0.0500s/iter; left time: 831.7564s\n",
      "\titers: 200, epoch: 27 | loss: 0.0078030\n",
      "\tspeed: 0.0250s/iter; left time: 412.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0075464 Vali Loss: 0.0099611 Test Loss: 0.0113010\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0069769\n",
      "\tspeed: 0.0478s/iter; left time: 783.5626s\n",
      "\titers: 200, epoch: 28 | loss: 0.0071861\n",
      "\tspeed: 0.0264s/iter; left time: 431.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0075400 Vali Loss: 0.0099150 Test Loss: 0.0112339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0080889\n",
      "\tspeed: 0.0491s/iter; left time: 793.3192s\n",
      "\titers: 200, epoch: 29 | loss: 0.0076567\n",
      "\tspeed: 0.0248s/iter; left time: 399.3400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0075251 Vali Loss: 0.0099069 Test Loss: 0.0112995\n",
      "Validation loss decreased (0.009909 --> 0.009907).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0065259\n",
      "\tspeed: 0.0439s/iter; left time: 700.6394s\n",
      "\titers: 200, epoch: 30 | loss: 0.0075698\n",
      "\tspeed: 0.0271s/iter; left time: 429.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0074991 Vali Loss: 0.0098355 Test Loss: 0.0111918\n",
      "Validation loss decreased (0.009907 --> 0.009836).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0075317\n",
      "\tspeed: 0.0473s/iter; left time: 743.7332s\n",
      "\titers: 200, epoch: 31 | loss: 0.0086341\n",
      "\tspeed: 0.0250s/iter; left time: 390.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0074795 Vali Loss: 0.0098114 Test Loss: 0.0111375\n",
      "Validation loss decreased (0.009836 --> 0.009811).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0076852\n",
      "\tspeed: 0.0475s/iter; left time: 736.3181s\n",
      "\titers: 200, epoch: 32 | loss: 0.0069425\n",
      "\tspeed: 0.0267s/iter; left time: 411.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 226 | Train Loss: 0.0074564 Vali Loss: 0.0098412 Test Loss: 0.0112313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0085172\n",
      "\tspeed: 0.0451s/iter; left time: 688.2950s\n",
      "\titers: 200, epoch: 33 | loss: 0.0081953\n",
      "\tspeed: 0.0265s/iter; left time: 402.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0074508 Vali Loss: 0.0098692 Test Loss: 0.0112476\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0063183\n",
      "\tspeed: 0.0441s/iter; left time: 662.9747s\n",
      "\titers: 200, epoch: 34 | loss: 0.0077615\n",
      "\tspeed: 0.0264s/iter; left time: 395.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 226 | Train Loss: 0.0074334 Vali Loss: 0.0098005 Test Loss: 0.0111092\n",
      "Validation loss decreased (0.009811 --> 0.009801).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0068418\n",
      "\tspeed: 0.0480s/iter; left time: 710.5507s\n",
      "\titers: 200, epoch: 35 | loss: 0.0075842\n",
      "\tspeed: 0.0262s/iter; left time: 385.0667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 226 | Train Loss: 0.0074288 Vali Loss: 0.0098764 Test Loss: 0.0112255\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0085077\n",
      "\tspeed: 0.0449s/iter; left time: 655.8095s\n",
      "\titers: 200, epoch: 36 | loss: 0.0076539\n",
      "\tspeed: 0.0263s/iter; left time: 381.6022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 226 | Train Loss: 0.0074260 Vali Loss: 0.0097790 Test Loss: 0.0110372\n",
      "Validation loss decreased (0.009801 --> 0.009779).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0069371\n",
      "\tspeed: 0.0482s/iter; left time: 692.4355s\n",
      "\titers: 200, epoch: 37 | loss: 0.0080106\n",
      "\tspeed: 0.0239s/iter; left time: 341.3171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0074054 Vali Loss: 0.0098604 Test Loss: 0.0112190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0070336\n",
      "\tspeed: 0.0484s/iter; left time: 684.4896s\n",
      "\titers: 200, epoch: 38 | loss: 0.0076715\n",
      "\tspeed: 0.0273s/iter; left time: 382.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0073978 Vali Loss: 0.0098322 Test Loss: 0.0112414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0071844\n",
      "\tspeed: 0.0469s/iter; left time: 652.0552s\n",
      "\titers: 200, epoch: 39 | loss: 0.0066780\n",
      "\tspeed: 0.0268s/iter; left time: 370.6447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 226 | Train Loss: 0.0074299 Vali Loss: 0.0097835 Test Loss: 0.0111078\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0065640\n",
      "\tspeed: 0.0477s/iter; left time: 653.5499s\n",
      "\titers: 200, epoch: 40 | loss: 0.0078668\n",
      "\tspeed: 0.0264s/iter; left time: 358.1417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0073860 Vali Loss: 0.0097779 Test Loss: 0.0111073\n",
      "Validation loss decreased (0.009779 --> 0.009778).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0077651\n",
      "\tspeed: 0.0498s/iter; left time: 670.7447s\n",
      "\titers: 200, epoch: 41 | loss: 0.0065422\n",
      "\tspeed: 0.0269s/iter; left time: 359.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 226 | Train Loss: 0.0073971 Vali Loss: 0.0098634 Test Loss: 0.0112728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0071227\n",
      "\tspeed: 0.0487s/iter; left time: 644.4144s\n",
      "\titers: 200, epoch: 42 | loss: 0.0074113\n",
      "\tspeed: 0.0265s/iter; left time: 348.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 226 | Train Loss: 0.0073542 Vali Loss: 0.0097589 Test Loss: 0.0111162\n",
      "Validation loss decreased (0.009778 --> 0.009759).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0076495\n",
      "\tspeed: 0.0474s/iter; left time: 616.0548s\n",
      "\titers: 200, epoch: 43 | loss: 0.0071825\n",
      "\tspeed: 0.0265s/iter; left time: 341.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0073650 Vali Loss: 0.0097709 Test Loss: 0.0110386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0085925\n",
      "\tspeed: 0.0438s/iter; left time: 559.5586s\n",
      "\titers: 200, epoch: 44 | loss: 0.0074999\n",
      "\tspeed: 0.0262s/iter; left time: 331.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0073613 Vali Loss: 0.0097453 Test Loss: 0.0110496\n",
      "Validation loss decreased (0.009759 --> 0.009745).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0071460\n",
      "\tspeed: 0.0486s/iter; left time: 610.2360s\n",
      "\titers: 200, epoch: 45 | loss: 0.0082683\n",
      "\tspeed: 0.0272s/iter; left time: 338.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 226 | Train Loss: 0.0073519 Vali Loss: 0.0098793 Test Loss: 0.0111911\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0077008\n",
      "\tspeed: 0.0442s/iter; left time: 544.8672s\n",
      "\titers: 200, epoch: 46 | loss: 0.0069996\n",
      "\tspeed: 0.0269s/iter; left time: 329.0903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0073610 Vali Loss: 0.0098040 Test Loss: 0.0111710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0078941\n",
      "\tspeed: 0.0477s/iter; left time: 577.4845s\n",
      "\titers: 200, epoch: 47 | loss: 0.0078461\n",
      "\tspeed: 0.0262s/iter; left time: 314.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0073608 Vali Loss: 0.0099016 Test Loss: 0.0113324\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0077719\n",
      "\tspeed: 0.0480s/iter; left time: 570.4268s\n",
      "\titers: 200, epoch: 48 | loss: 0.0059703\n",
      "\tspeed: 0.0283s/iter; left time: 333.7328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 226 | Train Loss: 0.0073397 Vali Loss: 0.0097900 Test Loss: 0.0111150\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0076034\n",
      "\tspeed: 0.0472s/iter; left time: 550.4222s\n",
      "\titers: 200, epoch: 49 | loss: 0.0076480\n",
      "\tspeed: 0.0255s/iter; left time: 294.5639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 226 | Train Loss: 0.0073238 Vali Loss: 0.0097820 Test Loss: 0.0111313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0077784\n",
      "\tspeed: 0.0458s/iter; left time: 523.2287s\n",
      "\titers: 200, epoch: 50 | loss: 0.0086826\n",
      "\tspeed: 0.0249s/iter; left time: 281.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 226 | Train Loss: 0.0073742 Vali Loss: 0.0097795 Test Loss: 0.0111120\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0070409\n",
      "\tspeed: 0.0390s/iter; left time: 436.8578s\n",
      "\titers: 200, epoch: 51 | loss: 0.0080854\n",
      "\tspeed: 0.0229s/iter; left time: 254.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 226 | Train Loss: 0.0073432 Vali Loss: 0.0097531 Test Loss: 0.0110949\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0080639\n",
      "\tspeed: 0.0417s/iter; left time: 457.5949s\n",
      "\titers: 200, epoch: 52 | loss: 0.0076307\n",
      "\tspeed: 0.0251s/iter; left time: 272.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 226 | Train Loss: 0.0073577 Vali Loss: 0.0097429 Test Loss: 0.0110933\n",
      "Validation loss decreased (0.009745 --> 0.009743).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0067979\n",
      "\tspeed: 0.0474s/iter; left time: 509.8565s\n",
      "\titers: 200, epoch: 53 | loss: 0.0070733\n",
      "\tspeed: 0.0275s/iter; left time: 292.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 226 | Train Loss: 0.0073570 Vali Loss: 0.0097354 Test Loss: 0.0110799\n",
      "Validation loss decreased (0.009743 --> 0.009735).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0074099\n",
      "\tspeed: 0.0454s/iter; left time: 477.4238s\n",
      "\titers: 200, epoch: 54 | loss: 0.0065128\n",
      "\tspeed: 0.0231s/iter; left time: 241.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 226 | Train Loss: 0.0073377 Vali Loss: 0.0098519 Test Loss: 0.0112452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0073642\n",
      "\tspeed: 0.0460s/iter; left time: 473.5861s\n",
      "\titers: 200, epoch: 55 | loss: 0.0070603\n",
      "\tspeed: 0.0264s/iter; left time: 268.8456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0073712 Vali Loss: 0.0097421 Test Loss: 0.0110505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0075464\n",
      "\tspeed: 0.0466s/iter; left time: 469.0349s\n",
      "\titers: 200, epoch: 56 | loss: 0.0079625\n",
      "\tspeed: 0.0254s/iter; left time: 253.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 226 | Train Loss: 0.0073074 Vali Loss: 0.0098135 Test Loss: 0.0111922\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0062994\n",
      "\tspeed: 0.0486s/iter; left time: 478.6940s\n",
      "\titers: 200, epoch: 57 | loss: 0.0074914\n",
      "\tspeed: 0.0267s/iter; left time: 260.6590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0073146 Vali Loss: 0.0097597 Test Loss: 0.0111272\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0070301\n",
      "\tspeed: 0.0492s/iter; left time: 472.9524s\n",
      "\titers: 200, epoch: 58 | loss: 0.0080159\n",
      "\tspeed: 0.0253s/iter; left time: 240.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0073411 Vali Loss: 0.0098542 Test Loss: 0.0112294\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0077752\n",
      "\tspeed: 0.0432s/iter; left time: 406.1894s\n",
      "\titers: 200, epoch: 59 | loss: 0.0071535\n",
      "\tspeed: 0.0261s/iter; left time: 242.6972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 226 | Train Loss: 0.0073310 Vali Loss: 0.0098229 Test Loss: 0.0111914\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0076468\n",
      "\tspeed: 0.0496s/iter; left time: 454.7313s\n",
      "\titers: 200, epoch: 60 | loss: 0.0069263\n",
      "\tspeed: 0.0272s/iter; left time: 246.3952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 226 | Train Loss: 0.0073323 Vali Loss: 0.0097625 Test Loss: 0.0110864\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0074560\n",
      "\tspeed: 0.0471s/iter; left time: 421.5195s\n",
      "\titers: 200, epoch: 61 | loss: 0.0083241\n",
      "\tspeed: 0.0235s/iter; left time: 207.5506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.0073178 Vali Loss: 0.0097292 Test Loss: 0.0110488\n",
      "Validation loss decreased (0.009735 --> 0.009729).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0072145\n",
      "\tspeed: 0.0462s/iter; left time: 402.2560s\n",
      "\titers: 200, epoch: 62 | loss: 0.0068843\n",
      "\tspeed: 0.0226s/iter; left time: 195.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 226 | Train Loss: 0.0073189 Vali Loss: 0.0097757 Test Loss: 0.0110886\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0078795\n",
      "\tspeed: 0.0470s/iter; left time: 398.6356s\n",
      "\titers: 200, epoch: 63 | loss: 0.0076407\n",
      "\tspeed: 0.0255s/iter; left time: 214.0120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 226 | Train Loss: 0.0073113 Vali Loss: 0.0098350 Test Loss: 0.0112361\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0063528\n",
      "\tspeed: 0.0450s/iter; left time: 371.9840s\n",
      "\titers: 200, epoch: 64 | loss: 0.0075218\n",
      "\tspeed: 0.0249s/iter; left time: 203.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 226 | Train Loss: 0.0073152 Vali Loss: 0.0098300 Test Loss: 0.0111841\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0070828\n",
      "\tspeed: 0.0433s/iter; left time: 347.6982s\n",
      "\titers: 200, epoch: 65 | loss: 0.0068030\n",
      "\tspeed: 0.0254s/iter; left time: 201.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 226 | Train Loss: 0.0073437 Vali Loss: 0.0097178 Test Loss: 0.0109760\n",
      "Validation loss decreased (0.009729 --> 0.009718).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0071458\n",
      "\tspeed: 0.0479s/iter; left time: 373.8890s\n",
      "\titers: 200, epoch: 66 | loss: 0.0072068\n",
      "\tspeed: 0.0272s/iter; left time: 209.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 226 | Train Loss: 0.0073280 Vali Loss: 0.0097456 Test Loss: 0.0110517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0083490\n",
      "\tspeed: 0.0485s/iter; left time: 368.0396s\n",
      "\titers: 200, epoch: 67 | loss: 0.0076469\n",
      "\tspeed: 0.0261s/iter; left time: 195.6571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 226 | Train Loss: 0.0072792 Vali Loss: 0.0097689 Test Loss: 0.0110874\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0069373\n",
      "\tspeed: 0.0475s/iter; left time: 349.4323s\n",
      "\titers: 200, epoch: 68 | loss: 0.0075724\n",
      "\tspeed: 0.0266s/iter; left time: 193.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0073193 Vali Loss: 0.0098146 Test Loss: 0.0111480\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0078234\n",
      "\tspeed: 0.0478s/iter; left time: 340.9984s\n",
      "\titers: 200, epoch: 69 | loss: 0.0066599\n",
      "\tspeed: 0.0265s/iter; left time: 186.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 226 | Train Loss: 0.0073367 Vali Loss: 0.0097884 Test Loss: 0.0111599\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0059663\n",
      "\tspeed: 0.0494s/iter; left time: 341.0797s\n",
      "\titers: 200, epoch: 70 | loss: 0.0079825\n",
      "\tspeed: 0.0260s/iter; left time: 176.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0073102 Vali Loss: 0.0097673 Test Loss: 0.0111429\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0081901\n",
      "\tspeed: 0.0460s/iter; left time: 307.0410s\n",
      "\titers: 200, epoch: 71 | loss: 0.0072638\n",
      "\tspeed: 0.0260s/iter; left time: 171.0411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 226 | Train Loss: 0.0073409 Vali Loss: 0.0097836 Test Loss: 0.0111003\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0067434\n",
      "\tspeed: 0.0493s/iter; left time: 318.0908s\n",
      "\titers: 200, epoch: 72 | loss: 0.0084814\n",
      "\tspeed: 0.0267s/iter; left time: 169.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 226 | Train Loss: 0.0073292 Vali Loss: 0.0097669 Test Loss: 0.0111092\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0083585\n",
      "\tspeed: 0.0458s/iter; left time: 285.5602s\n",
      "\titers: 200, epoch: 73 | loss: 0.0078706\n",
      "\tspeed: 0.0282s/iter; left time: 173.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0073063 Vali Loss: 0.0097382 Test Loss: 0.0110653\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0060933\n",
      "\tspeed: 0.0476s/iter; left time: 285.4438s\n",
      "\titers: 200, epoch: 74 | loss: 0.0085692\n",
      "\tspeed: 0.0273s/iter; left time: 161.0397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0073037 Vali Loss: 0.0097348 Test Loss: 0.0110978\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0066312\n",
      "\tspeed: 0.0472s/iter; left time: 272.8819s\n",
      "\titers: 200, epoch: 75 | loss: 0.0079251\n",
      "\tspeed: 0.0263s/iter; left time: 149.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 226 | Train Loss: 0.0073133 Vali Loss: 0.0097491 Test Loss: 0.0110843\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01097604539245367, rmse:0.10476662218570709, mae:0.06404493004083633, rse:0.4041867256164551\n",
      "Intermediate time for FR and pred_len 24: 00h:09m:10.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1113841\n",
      "\tspeed: 0.0408s/iter; left time: 914.6024s\n",
      "\titers: 200, epoch: 1 | loss: 0.0960350\n",
      "\tspeed: 0.0205s/iter; left time: 457.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.1140842 Vali Loss: 0.0640091 Test Loss: 0.0724323\n",
      "Validation loss decreased (inf --> 0.064009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0396767\n",
      "\tspeed: 0.0352s/iter; left time: 781.1620s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237787\n",
      "\tspeed: 0.0205s/iter; left time: 453.5848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0416248 Vali Loss: 0.0233879 Test Loss: 0.0283799\n",
      "Validation loss decreased (0.064009 --> 0.023388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0195205\n",
      "\tspeed: 0.0432s/iter; left time: 949.2620s\n",
      "\titers: 200, epoch: 3 | loss: 0.0207301\n",
      "\tspeed: 0.0214s/iter; left time: 467.6039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 225 | Train Loss: 0.0201231 Vali Loss: 0.0215313 Test Loss: 0.0250091\n",
      "Validation loss decreased (0.023388 --> 0.021531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0159275\n",
      "\tspeed: 0.0474s/iter; left time: 1029.7220s\n",
      "\titers: 200, epoch: 4 | loss: 0.0168217\n",
      "\tspeed: 0.0232s/iter; left time: 501.0622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 225 | Train Loss: 0.0174908 Vali Loss: 0.0196409 Test Loss: 0.0223041\n",
      "Validation loss decreased (0.021531 --> 0.019641).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0158458\n",
      "\tspeed: 0.0460s/iter; left time: 988.0546s\n",
      "\titers: 200, epoch: 5 | loss: 0.0151958\n",
      "\tspeed: 0.0206s/iter; left time: 441.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 225 | Train Loss: 0.0158961 Vali Loss: 0.0179276 Test Loss: 0.0212669\n",
      "Validation loss decreased (0.019641 --> 0.017928).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0146401\n",
      "\tspeed: 0.0456s/iter; left time: 969.9722s\n",
      "\titers: 200, epoch: 6 | loss: 0.0138012\n",
      "\tspeed: 0.0248s/iter; left time: 524.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 225 | Train Loss: 0.0148701 Vali Loss: 0.0172438 Test Loss: 0.0206284\n",
      "Validation loss decreased (0.017928 --> 0.017244).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0131631\n",
      "\tspeed: 0.0473s/iter; left time: 995.8564s\n",
      "\titers: 200, epoch: 7 | loss: 0.0135497\n",
      "\tspeed: 0.0271s/iter; left time: 568.0906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0141523 Vali Loss: 0.0167315 Test Loss: 0.0206269\n",
      "Validation loss decreased (0.017244 --> 0.016731).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0155353\n",
      "\tspeed: 0.0477s/iter; left time: 993.6517s\n",
      "\titers: 200, epoch: 8 | loss: 0.0145908\n",
      "\tspeed: 0.0259s/iter; left time: 536.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 225 | Train Loss: 0.0136613 Vali Loss: 0.0164862 Test Loss: 0.0204916\n",
      "Validation loss decreased (0.016731 --> 0.016486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0124979\n",
      "\tspeed: 0.0487s/iter; left time: 1002.8748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0141903\n",
      "\tspeed: 0.0259s/iter; left time: 530.1232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 225 | Train Loss: 0.0132657 Vali Loss: 0.0163018 Test Loss: 0.0203900\n",
      "Validation loss decreased (0.016486 --> 0.016302).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0130249\n",
      "\tspeed: 0.0478s/iter; left time: 973.9434s\n",
      "\titers: 200, epoch: 10 | loss: 0.0145992\n",
      "\tspeed: 0.0191s/iter; left time: 387.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 225 | Train Loss: 0.0130031 Vali Loss: 0.0162973 Test Loss: 0.0206071\n",
      "Validation loss decreased (0.016302 --> 0.016297).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0117351\n",
      "\tspeed: 0.0388s/iter; left time: 782.7197s\n",
      "\titers: 200, epoch: 11 | loss: 0.0126542\n",
      "\tspeed: 0.0160s/iter; left time: 321.0418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0128600 Vali Loss: 0.0161040 Test Loss: 0.0201517\n",
      "Validation loss decreased (0.016297 --> 0.016104).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0118891\n",
      "\tspeed: 0.0406s/iter; left time: 809.8770s\n",
      "\titers: 200, epoch: 12 | loss: 0.0141304\n",
      "\tspeed: 0.0177s/iter; left time: 350.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0126416 Vali Loss: 0.0161925 Test Loss: 0.0203752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0115469\n",
      "\tspeed: 0.0373s/iter; left time: 734.5803s\n",
      "\titers: 200, epoch: 13 | loss: 0.0135689\n",
      "\tspeed: 0.0162s/iter; left time: 318.5020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0124961 Vali Loss: 0.0161324 Test Loss: 0.0203338\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0133804\n",
      "\tspeed: 0.0362s/iter; left time: 705.3949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0134761\n",
      "\tspeed: 0.0153s/iter; left time: 296.2817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 225 | Train Loss: 0.0123601 Vali Loss: 0.0159018 Test Loss: 0.0199754\n",
      "Validation loss decreased (0.016104 --> 0.015902).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0123548\n",
      "\tspeed: 0.0398s/iter; left time: 766.5722s\n",
      "\titers: 200, epoch: 15 | loss: 0.0117204\n",
      "\tspeed: 0.0196s/iter; left time: 374.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0122618 Vali Loss: 0.0158032 Test Loss: 0.0197771\n",
      "Validation loss decreased (0.015902 --> 0.015803).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0119051\n",
      "\tspeed: 0.0367s/iter; left time: 698.0305s\n",
      "\titers: 200, epoch: 16 | loss: 0.0120862\n",
      "\tspeed: 0.0155s/iter; left time: 293.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 225 | Train Loss: 0.0121902 Vali Loss: 0.0158244 Test Loss: 0.0198974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0119850\n",
      "\tspeed: 0.0363s/iter; left time: 682.0079s\n",
      "\titers: 200, epoch: 17 | loss: 0.0132078\n",
      "\tspeed: 0.0161s/iter; left time: 300.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0120864 Vali Loss: 0.0159179 Test Loss: 0.0201066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0134467\n",
      "\tspeed: 0.0397s/iter; left time: 736.6075s\n",
      "\titers: 200, epoch: 18 | loss: 0.0124690\n",
      "\tspeed: 0.0152s/iter; left time: 280.7597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0120324 Vali Loss: 0.0157427 Test Loss: 0.0197965\n",
      "Validation loss decreased (0.015803 --> 0.015743).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0115921\n",
      "\tspeed: 0.0366s/iter; left time: 671.8514s\n",
      "\titers: 200, epoch: 19 | loss: 0.0118622\n",
      "\tspeed: 0.0157s/iter; left time: 286.4176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0119771 Vali Loss: 0.0157152 Test Loss: 0.0197621\n",
      "Validation loss decreased (0.015743 --> 0.015715).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0113165\n",
      "\tspeed: 0.0359s/iter; left time: 650.2540s\n",
      "\titers: 200, epoch: 20 | loss: 0.0128192\n",
      "\tspeed: 0.0177s/iter; left time: 318.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0119356 Vali Loss: 0.0156835 Test Loss: 0.0197760\n",
      "Validation loss decreased (0.015715 --> 0.015684).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0105805\n",
      "\tspeed: 0.0393s/iter; left time: 703.6825s\n",
      "\titers: 200, epoch: 21 | loss: 0.0113129\n",
      "\tspeed: 0.0155s/iter; left time: 275.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0118538 Vali Loss: 0.0157063 Test Loss: 0.0198067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0119138\n",
      "\tspeed: 0.0349s/iter; left time: 617.7095s\n",
      "\titers: 200, epoch: 22 | loss: 0.0130232\n",
      "\tspeed: 0.0166s/iter; left time: 292.6130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0118490 Vali Loss: 0.0157687 Test Loss: 0.0199778\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0140942\n",
      "\tspeed: 0.0424s/iter; left time: 740.6491s\n",
      "\titers: 200, epoch: 23 | loss: 0.0104837\n",
      "\tspeed: 0.0153s/iter; left time: 266.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0117976 Vali Loss: 0.0155976 Test Loss: 0.0196915\n",
      "Validation loss decreased (0.015684 --> 0.015598).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0119596\n",
      "\tspeed: 0.0377s/iter; left time: 648.9023s\n",
      "\titers: 200, epoch: 24 | loss: 0.0122438\n",
      "\tspeed: 0.0155s/iter; left time: 265.8476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0117347 Vali Loss: 0.0155869 Test Loss: 0.0196945\n",
      "Validation loss decreased (0.015598 --> 0.015587).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0110265\n",
      "\tspeed: 0.0375s/iter; left time: 638.2705s\n",
      "\titers: 200, epoch: 25 | loss: 0.0106533\n",
      "\tspeed: 0.0181s/iter; left time: 305.6683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 225 | Train Loss: 0.0117112 Vali Loss: 0.0156426 Test Loss: 0.0198788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0123516\n",
      "\tspeed: 0.0395s/iter; left time: 662.9959s\n",
      "\titers: 200, epoch: 26 | loss: 0.0110251\n",
      "\tspeed: 0.0169s/iter; left time: 282.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0117144 Vali Loss: 0.0156266 Test Loss: 0.0196654\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0118690\n",
      "\tspeed: 0.0396s/iter; left time: 654.8026s\n",
      "\titers: 200, epoch: 27 | loss: 0.0126628\n",
      "\tspeed: 0.0160s/iter; left time: 263.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 225 | Train Loss: 0.0116711 Vali Loss: 0.0155167 Test Loss: 0.0196460\n",
      "Validation loss decreased (0.015587 --> 0.015517).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0111083\n",
      "\tspeed: 0.0411s/iter; left time: 670.6492s\n",
      "\titers: 200, epoch: 28 | loss: 0.0124047\n",
      "\tspeed: 0.0184s/iter; left time: 298.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0116553 Vali Loss: 0.0155300 Test Loss: 0.0196517\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0111487\n",
      "\tspeed: 0.0366s/iter; left time: 589.7061s\n",
      "\titers: 200, epoch: 29 | loss: 0.0116333\n",
      "\tspeed: 0.0164s/iter; left time: 262.9206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0116603 Vali Loss: 0.0154778 Test Loss: 0.0194986\n",
      "Validation loss decreased (0.015517 --> 0.015478).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0111717\n",
      "\tspeed: 0.0387s/iter; left time: 613.9011s\n",
      "\titers: 200, epoch: 30 | loss: 0.0109237\n",
      "\tspeed: 0.0169s/iter; left time: 266.6478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0116186 Vali Loss: 0.0155104 Test Loss: 0.0196734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0108955\n",
      "\tspeed: 0.0385s/iter; left time: 602.0151s\n",
      "\titers: 200, epoch: 31 | loss: 0.0120876\n",
      "\tspeed: 0.0154s/iter; left time: 239.2646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0115731 Vali Loss: 0.0155629 Test Loss: 0.0196749\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0112643\n",
      "\tspeed: 0.0374s/iter; left time: 576.8115s\n",
      "\titers: 200, epoch: 32 | loss: 0.0106460\n",
      "\tspeed: 0.0159s/iter; left time: 243.8734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0116208 Vali Loss: 0.0154745 Test Loss: 0.0194838\n",
      "Validation loss decreased (0.015478 --> 0.015474).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0120849\n",
      "\tspeed: 0.0411s/iter; left time: 624.1683s\n",
      "\titers: 200, epoch: 33 | loss: 0.0106973\n",
      "\tspeed: 0.0213s/iter; left time: 321.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0115906 Vali Loss: 0.0154839 Test Loss: 0.0196082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0114681\n",
      "\tspeed: 0.0376s/iter; left time: 563.8245s\n",
      "\titers: 200, epoch: 34 | loss: 0.0103871\n",
      "\tspeed: 0.0179s/iter; left time: 266.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0115730 Vali Loss: 0.0153933 Test Loss: 0.0194390\n",
      "Validation loss decreased (0.015474 --> 0.015393).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0116464\n",
      "\tspeed: 0.0395s/iter; left time: 582.9110s\n",
      "\titers: 200, epoch: 35 | loss: 0.0106844\n",
      "\tspeed: 0.0174s/iter; left time: 255.3271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 225 | Train Loss: 0.0115658 Vali Loss: 0.0154608 Test Loss: 0.0195885\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0130586\n",
      "\tspeed: 0.0395s/iter; left time: 574.2656s\n",
      "\titers: 200, epoch: 36 | loss: 0.0131336\n",
      "\tspeed: 0.0172s/iter; left time: 248.5702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0115078 Vali Loss: 0.0154698 Test Loss: 0.0195335\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0120452\n",
      "\tspeed: 0.0369s/iter; left time: 527.4090s\n",
      "\titers: 200, epoch: 37 | loss: 0.0121271\n",
      "\tspeed: 0.0174s/iter; left time: 246.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0115680 Vali Loss: 0.0154238 Test Loss: 0.0195199\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0119433\n",
      "\tspeed: 0.0402s/iter; left time: 565.6545s\n",
      "\titers: 200, epoch: 38 | loss: 0.0110818\n",
      "\tspeed: 0.0199s/iter; left time: 278.1313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 225 | Train Loss: 0.0115156 Vali Loss: 0.0153970 Test Loss: 0.0194227\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0100204\n",
      "\tspeed: 0.0388s/iter; left time: 537.5923s\n",
      "\titers: 200, epoch: 39 | loss: 0.0113502\n",
      "\tspeed: 0.0160s/iter; left time: 220.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0115199 Vali Loss: 0.0154849 Test Loss: 0.0196535\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0115077\n",
      "\tspeed: 0.0388s/iter; left time: 528.1749s\n",
      "\titers: 200, epoch: 40 | loss: 0.0103217\n",
      "\tspeed: 0.0152s/iter; left time: 204.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 225 | Train Loss: 0.0115064 Vali Loss: 0.0154055 Test Loss: 0.0194664\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0103715\n",
      "\tspeed: 0.0406s/iter; left time: 544.6653s\n",
      "\titers: 200, epoch: 41 | loss: 0.0105630\n",
      "\tspeed: 0.0177s/iter; left time: 235.3172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0115057 Vali Loss: 0.0154118 Test Loss: 0.0195385\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0116243\n",
      "\tspeed: 0.0414s/iter; left time: 546.0989s\n",
      "\titers: 200, epoch: 42 | loss: 0.0111042\n",
      "\tspeed: 0.0176s/iter; left time: 230.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 225 | Train Loss: 0.0114945 Vali Loss: 0.0154482 Test Loss: 0.0195912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0120247\n",
      "\tspeed: 0.0407s/iter; left time: 527.4954s\n",
      "\titers: 200, epoch: 43 | loss: 0.0122419\n",
      "\tspeed: 0.0194s/iter; left time: 248.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.64s\n",
      "Steps: 225 | Train Loss: 0.0115088 Vali Loss: 0.0153739 Test Loss: 0.0193811\n",
      "Validation loss decreased (0.015393 --> 0.015374).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0123291\n",
      "\tspeed: 0.0399s/iter; left time: 507.4273s\n",
      "\titers: 200, epoch: 44 | loss: 0.0108651\n",
      "\tspeed: 0.0178s/iter; left time: 224.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0115130 Vali Loss: 0.0154280 Test Loss: 0.0196132\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0116522\n",
      "\tspeed: 0.0400s/iter; left time: 500.3381s\n",
      "\titers: 200, epoch: 45 | loss: 0.0100763\n",
      "\tspeed: 0.0194s/iter; left time: 240.3175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0115149 Vali Loss: 0.0154189 Test Loss: 0.0195373\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0119316\n",
      "\tspeed: 0.0431s/iter; left time: 529.3590s\n",
      "\titers: 200, epoch: 46 | loss: 0.0121877\n",
      "\tspeed: 0.0176s/iter; left time: 214.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0114768 Vali Loss: 0.0154554 Test Loss: 0.0196083\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0123775\n",
      "\tspeed: 0.0387s/iter; left time: 466.5767s\n",
      "\titers: 200, epoch: 47 | loss: 0.0115821\n",
      "\tspeed: 0.0168s/iter; left time: 201.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 225 | Train Loss: 0.0114788 Vali Loss: 0.0153788 Test Loss: 0.0194893\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0123712\n",
      "\tspeed: 0.0459s/iter; left time: 542.5049s\n",
      "\titers: 200, epoch: 48 | loss: 0.0106740\n",
      "\tspeed: 0.0213s/iter; left time: 249.7321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0115063 Vali Loss: 0.0153871 Test Loss: 0.0194643\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0134893\n",
      "\tspeed: 0.0404s/iter; left time: 469.1885s\n",
      "\titers: 200, epoch: 49 | loss: 0.0116201\n",
      "\tspeed: 0.0169s/iter; left time: 194.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 225 | Train Loss: 0.0114783 Vali Loss: 0.0154132 Test Loss: 0.0195795\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0116107\n",
      "\tspeed: 0.0401s/iter; left time: 455.7130s\n",
      "\titers: 200, epoch: 50 | loss: 0.0103245\n",
      "\tspeed: 0.0196s/iter; left time: 221.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 225 | Train Loss: 0.0114765 Vali Loss: 0.0153764 Test Loss: 0.0194849\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0117851\n",
      "\tspeed: 0.0446s/iter; left time: 496.9526s\n",
      "\titers: 200, epoch: 51 | loss: 0.0107125\n",
      "\tspeed: 0.0162s/iter; left time: 178.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0114667 Vali Loss: 0.0154133 Test Loss: 0.0194795\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0106644\n",
      "\tspeed: 0.0373s/iter; left time: 407.3283s\n",
      "\titers: 200, epoch: 52 | loss: 0.0115350\n",
      "\tspeed: 0.0155s/iter; left time: 167.6295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 225 | Train Loss: 0.0114815 Vali Loss: 0.0153970 Test Loss: 0.0195376\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0115413\n",
      "\tspeed: 0.0445s/iter; left time: 475.7675s\n",
      "\titers: 200, epoch: 53 | loss: 0.0111369\n",
      "\tspeed: 0.0204s/iter; left time: 215.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 225 | Train Loss: 0.0114722 Vali Loss: 0.0154105 Test Loss: 0.0195179\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019381113350391388, rmse:0.13921606540679932, mae:0.087315134704113, rse:0.5385247468948364\n",
      "Intermediate time for FR and pred_len 96: 00h:05m:21.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163086\n",
      "\tspeed: 0.0407s/iter; left time: 911.0389s\n",
      "\titers: 200, epoch: 1 | loss: 0.0959582\n",
      "\tspeed: 0.0156s/iter; left time: 348.3436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.1164011 Vali Loss: 0.0671606 Test Loss: 0.0756801\n",
      "Validation loss decreased (inf --> 0.067161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0380078\n",
      "\tspeed: 0.0387s/iter; left time: 857.1911s\n",
      "\titers: 200, epoch: 2 | loss: 0.0249385\n",
      "\tspeed: 0.0164s/iter; left time: 362.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0402786 Vali Loss: 0.0245649 Test Loss: 0.0294748\n",
      "Validation loss decreased (0.067161 --> 0.024565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0198591\n",
      "\tspeed: 0.0410s/iter; left time: 899.4307s\n",
      "\titers: 200, epoch: 3 | loss: 0.0181067\n",
      "\tspeed: 0.0217s/iter; left time: 474.2215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0208037 Vali Loss: 0.0224972 Test Loss: 0.0261129\n",
      "Validation loss decreased (0.024565 --> 0.022497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0205366\n",
      "\tspeed: 0.0397s/iter; left time: 863.3462s\n",
      "\titers: 200, epoch: 4 | loss: 0.0180572\n",
      "\tspeed: 0.0159s/iter; left time: 342.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0183149 Vali Loss: 0.0198551 Test Loss: 0.0232241\n",
      "Validation loss decreased (0.022497 --> 0.019855).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0173023\n",
      "\tspeed: 0.0417s/iter; left time: 896.1665s\n",
      "\titers: 200, epoch: 5 | loss: 0.0153106\n",
      "\tspeed: 0.0165s/iter; left time: 353.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 225 | Train Loss: 0.0167519 Vali Loss: 0.0186968 Test Loss: 0.0227034\n",
      "Validation loss decreased (0.019855 --> 0.018697).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0151763\n",
      "\tspeed: 0.0472s/iter; left time: 1005.0808s\n",
      "\titers: 200, epoch: 6 | loss: 0.0169578\n",
      "\tspeed: 0.0166s/iter; left time: 350.7544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0158253 Vali Loss: 0.0187366 Test Loss: 0.0234431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0141559\n",
      "\tspeed: 0.0396s/iter; left time: 833.3195s\n",
      "\titers: 200, epoch: 7 | loss: 0.0142905\n",
      "\tspeed: 0.0173s/iter; left time: 361.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0150663 Vali Loss: 0.0178995 Test Loss: 0.0225593\n",
      "Validation loss decreased (0.018697 --> 0.017900).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0129712\n",
      "\tspeed: 0.0383s/iter; left time: 797.0842s\n",
      "\titers: 200, epoch: 8 | loss: 0.0136827\n",
      "\tspeed: 0.0230s/iter; left time: 476.7195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0145871 Vali Loss: 0.0177982 Test Loss: 0.0223871\n",
      "Validation loss decreased (0.017900 --> 0.017798).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0150651\n",
      "\tspeed: 0.0398s/iter; left time: 820.3513s\n",
      "\titers: 200, epoch: 9 | loss: 0.0142423\n",
      "\tspeed: 0.0163s/iter; left time: 333.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 225 | Train Loss: 0.0142830 Vali Loss: 0.0177567 Test Loss: 0.0227289\n",
      "Validation loss decreased (0.017798 --> 0.017757).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0143350\n",
      "\tspeed: 0.0377s/iter; left time: 767.3888s\n",
      "\titers: 200, epoch: 10 | loss: 0.0136892\n",
      "\tspeed: 0.0157s/iter; left time: 318.5943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 225 | Train Loss: 0.0140856 Vali Loss: 0.0176054 Test Loss: 0.0224962\n",
      "Validation loss decreased (0.017757 --> 0.017605).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0144481\n",
      "\tspeed: 0.0448s/iter; left time: 903.6252s\n",
      "\titers: 200, epoch: 11 | loss: 0.0122086\n",
      "\tspeed: 0.0167s/iter; left time: 334.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0139002 Vali Loss: 0.0175063 Test Loss: 0.0222891\n",
      "Validation loss decreased (0.017605 --> 0.017506).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0130901\n",
      "\tspeed: 0.0390s/iter; left time: 777.0067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0136973\n",
      "\tspeed: 0.0160s/iter; left time: 317.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0136572 Vali Loss: 0.0174897 Test Loss: 0.0223212\n",
      "Validation loss decreased (0.017506 --> 0.017490).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0129098\n",
      "\tspeed: 0.0392s/iter; left time: 772.1506s\n",
      "\titers: 200, epoch: 13 | loss: 0.0127208\n",
      "\tspeed: 0.0214s/iter; left time: 420.2287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0136023 Vali Loss: 0.0174103 Test Loss: 0.0221600\n",
      "Validation loss decreased (0.017490 --> 0.017410).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0145014\n",
      "\tspeed: 0.0417s/iter; left time: 812.7398s\n",
      "\titers: 200, epoch: 14 | loss: 0.0142842\n",
      "\tspeed: 0.0160s/iter; left time: 309.7685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0134571 Vali Loss: 0.0173082 Test Loss: 0.0219032\n",
      "Validation loss decreased (0.017410 --> 0.017308).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0122999\n",
      "\tspeed: 0.0383s/iter; left time: 737.0365s\n",
      "\titers: 200, epoch: 15 | loss: 0.0124080\n",
      "\tspeed: 0.0159s/iter; left time: 303.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0133875 Vali Loss: 0.0173671 Test Loss: 0.0223021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0129976\n",
      "\tspeed: 0.0471s/iter; left time: 896.2514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0143465\n",
      "\tspeed: 0.0162s/iter; left time: 305.6643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0132982 Vali Loss: 0.0173716 Test Loss: 0.0222940\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0128105\n",
      "\tspeed: 0.0384s/iter; left time: 721.0799s\n",
      "\titers: 200, epoch: 17 | loss: 0.0133504\n",
      "\tspeed: 0.0164s/iter; left time: 307.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 225 | Train Loss: 0.0131884 Vali Loss: 0.0171983 Test Loss: 0.0221098\n",
      "Validation loss decreased (0.017308 --> 0.017198).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0127477\n",
      "\tspeed: 0.0390s/iter; left time: 725.3888s\n",
      "\titers: 200, epoch: 18 | loss: 0.0133616\n",
      "\tspeed: 0.0215s/iter; left time: 396.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0131289 Vali Loss: 0.0172486 Test Loss: 0.0223695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0132135\n",
      "\tspeed: 0.0466s/iter; left time: 854.6046s\n",
      "\titers: 200, epoch: 19 | loss: 0.0139983\n",
      "\tspeed: 0.0231s/iter; left time: 420.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0130505 Vali Loss: 0.0171564 Test Loss: 0.0222004\n",
      "Validation loss decreased (0.017198 --> 0.017156).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0127651\n",
      "\tspeed: 0.0384s/iter; left time: 696.5206s\n",
      "\titers: 200, epoch: 20 | loss: 0.0131906\n",
      "\tspeed: 0.0156s/iter; left time: 280.5278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0130117 Vali Loss: 0.0170236 Test Loss: 0.0218656\n",
      "Validation loss decreased (0.017156 --> 0.017024).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0132290\n",
      "\tspeed: 0.0383s/iter; left time: 685.8056s\n",
      "\titers: 200, epoch: 21 | loss: 0.0138149\n",
      "\tspeed: 0.0153s/iter; left time: 273.2173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 225 | Train Loss: 0.0129826 Vali Loss: 0.0170017 Test Loss: 0.0218221\n",
      "Validation loss decreased (0.017024 --> 0.017002).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0138705\n",
      "\tspeed: 0.0396s/iter; left time: 700.5474s\n",
      "\titers: 200, epoch: 22 | loss: 0.0132168\n",
      "\tspeed: 0.0226s/iter; left time: 397.4560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0129330 Vali Loss: 0.0171318 Test Loss: 0.0222023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0117958\n",
      "\tspeed: 0.0405s/iter; left time: 707.4557s\n",
      "\titers: 200, epoch: 23 | loss: 0.0121447\n",
      "\tspeed: 0.0156s/iter; left time: 270.4232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 225 | Train Loss: 0.0128791 Vali Loss: 0.0169629 Test Loss: 0.0218639\n",
      "Validation loss decreased (0.017002 --> 0.016963).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0117950\n",
      "\tspeed: 0.0393s/iter; left time: 677.3486s\n",
      "\titers: 200, epoch: 24 | loss: 0.0116022\n",
      "\tspeed: 0.0155s/iter; left time: 265.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0128464 Vali Loss: 0.0169410 Test Loss: 0.0217760\n",
      "Validation loss decreased (0.016963 --> 0.016941).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0132211\n",
      "\tspeed: 0.0447s/iter; left time: 760.1049s\n",
      "\titers: 200, epoch: 25 | loss: 0.0133817\n",
      "\tspeed: 0.0179s/iter; left time: 302.0139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0128302 Vali Loss: 0.0170455 Test Loss: 0.0220150\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0118063\n",
      "\tspeed: 0.0380s/iter; left time: 637.8996s\n",
      "\titers: 200, epoch: 26 | loss: 0.0115659\n",
      "\tspeed: 0.0158s/iter; left time: 263.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 225 | Train Loss: 0.0127902 Vali Loss: 0.0169368 Test Loss: 0.0216894\n",
      "Validation loss decreased (0.016941 --> 0.016937).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0110586\n",
      "\tspeed: 0.0389s/iter; left time: 644.3470s\n",
      "\titers: 200, epoch: 27 | loss: 0.0133453\n",
      "\tspeed: 0.0208s/iter; left time: 341.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0127443 Vali Loss: 0.0169492 Test Loss: 0.0217148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0135904\n",
      "\tspeed: 0.0429s/iter; left time: 700.4644s\n",
      "\titers: 200, epoch: 28 | loss: 0.0124276\n",
      "\tspeed: 0.0169s/iter; left time: 274.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 225 | Train Loss: 0.0127048 Vali Loss: 0.0169174 Test Loss: 0.0216821\n",
      "Validation loss decreased (0.016937 --> 0.016917).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0128987\n",
      "\tspeed: 0.0372s/iter; left time: 598.7599s\n",
      "\titers: 200, epoch: 29 | loss: 0.0128150\n",
      "\tspeed: 0.0155s/iter; left time: 248.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0127015 Vali Loss: 0.0168976 Test Loss: 0.0216197\n",
      "Validation loss decreased (0.016917 --> 0.016898).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0123768\n",
      "\tspeed: 0.0433s/iter; left time: 687.1347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0126488\n",
      "\tspeed: 0.0238s/iter; left time: 375.8884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0126791 Vali Loss: 0.0169204 Test Loss: 0.0216944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0132034\n",
      "\tspeed: 0.0378s/iter; left time: 591.7431s\n",
      "\titers: 200, epoch: 31 | loss: 0.0124356\n",
      "\tspeed: 0.0154s/iter; left time: 239.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0126608 Vali Loss: 0.0169443 Test Loss: 0.0217171\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0126917\n",
      "\tspeed: 0.0397s/iter; left time: 612.2016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0139379\n",
      "\tspeed: 0.0150s/iter; left time: 230.5296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0126862 Vali Loss: 0.0168743 Test Loss: 0.0216627\n",
      "Validation loss decreased (0.016898 --> 0.016874).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0121382\n",
      "\tspeed: 0.0487s/iter; left time: 740.9962s\n",
      "\titers: 200, epoch: 33 | loss: 0.0134788\n",
      "\tspeed: 0.0159s/iter; left time: 240.5201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0126394 Vali Loss: 0.0168715 Test Loss: 0.0216864\n",
      "Validation loss decreased (0.016874 --> 0.016871).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0133380\n",
      "\tspeed: 0.0386s/iter; left time: 577.5417s\n",
      "\titers: 200, epoch: 34 | loss: 0.0120537\n",
      "\tspeed: 0.0158s/iter; left time: 235.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0126101 Vali Loss: 0.0168341 Test Loss: 0.0216229\n",
      "Validation loss decreased (0.016871 --> 0.016834).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0127342\n",
      "\tspeed: 0.0386s/iter; left time: 569.5485s\n",
      "\titers: 200, epoch: 35 | loss: 0.0137883\n",
      "\tspeed: 0.0204s/iter; left time: 299.0700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0126581 Vali Loss: 0.0168800 Test Loss: 0.0216368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0129292\n",
      "\tspeed: 0.0430s/iter; left time: 625.1072s\n",
      "\titers: 200, epoch: 36 | loss: 0.0142377\n",
      "\tspeed: 0.0158s/iter; left time: 227.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0126065 Vali Loss: 0.0168263 Test Loss: 0.0216261\n",
      "Validation loss decreased (0.016834 --> 0.016826).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0144185\n",
      "\tspeed: 0.0388s/iter; left time: 554.9932s\n",
      "\titers: 200, epoch: 37 | loss: 0.0119868\n",
      "\tspeed: 0.0151s/iter; left time: 215.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 225 | Train Loss: 0.0125955 Vali Loss: 0.0169518 Test Loss: 0.0218011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0122964\n",
      "\tspeed: 0.0443s/iter; left time: 623.1646s\n",
      "\titers: 200, epoch: 38 | loss: 0.0118971\n",
      "\tspeed: 0.0211s/iter; left time: 295.5919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 225 | Train Loss: 0.0125857 Vali Loss: 0.0168467 Test Loss: 0.0216006\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0128205\n",
      "\tspeed: 0.0403s/iter; left time: 558.1238s\n",
      "\titers: 200, epoch: 39 | loss: 0.0116396\n",
      "\tspeed: 0.0167s/iter; left time: 229.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0125828 Vali Loss: 0.0168230 Test Loss: 0.0214886\n",
      "Validation loss decreased (0.016826 --> 0.016823).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0135852\n",
      "\tspeed: 0.0387s/iter; left time: 527.0576s\n",
      "\titers: 200, epoch: 40 | loss: 0.0120434\n",
      "\tspeed: 0.0207s/iter; left time: 279.9543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.79s\n",
      "Steps: 225 | Train Loss: 0.0125880 Vali Loss: 0.0168890 Test Loss: 0.0216618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0116446\n",
      "\tspeed: 0.0483s/iter; left time: 646.7323s\n",
      "\titers: 200, epoch: 41 | loss: 0.0124125\n",
      "\tspeed: 0.0173s/iter; left time: 229.7905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0125534 Vali Loss: 0.0168535 Test Loss: 0.0215649\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0124781\n",
      "\tspeed: 0.0422s/iter; left time: 555.5906s\n",
      "\titers: 200, epoch: 42 | loss: 0.0123067\n",
      "\tspeed: 0.0213s/iter; left time: 278.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.85s\n",
      "Steps: 225 | Train Loss: 0.0125586 Vali Loss: 0.0168594 Test Loss: 0.0216211\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0127494\n",
      "\tspeed: 0.0471s/iter; left time: 610.3690s\n",
      "\titers: 200, epoch: 43 | loss: 0.0140274\n",
      "\tspeed: 0.0223s/iter; left time: 286.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 225 | Train Loss: 0.0125723 Vali Loss: 0.0168140 Test Loss: 0.0215049\n",
      "Validation loss decreased (0.016823 --> 0.016814).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0122186\n",
      "\tspeed: 0.0391s/iter; left time: 497.0265s\n",
      "\titers: 200, epoch: 44 | loss: 0.0118770\n",
      "\tspeed: 0.0164s/iter; left time: 206.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0125745 Vali Loss: 0.0167932 Test Loss: 0.0215052\n",
      "Validation loss decreased (0.016814 --> 0.016793).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0120009\n",
      "\tspeed: 0.0387s/iter; left time: 483.6525s\n",
      "\titers: 200, epoch: 45 | loss: 0.0124589\n",
      "\tspeed: 0.0197s/iter; left time: 243.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0125587 Vali Loss: 0.0168187 Test Loss: 0.0215558\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0133484\n",
      "\tspeed: 0.0488s/iter; left time: 598.8816s\n",
      "\titers: 200, epoch: 46 | loss: 0.0134764\n",
      "\tspeed: 0.0162s/iter; left time: 197.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 225 | Train Loss: 0.0125362 Vali Loss: 0.0168852 Test Loss: 0.0217203\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0124050\n",
      "\tspeed: 0.0387s/iter; left time: 466.7395s\n",
      "\titers: 200, epoch: 47 | loss: 0.0133607\n",
      "\tspeed: 0.0158s/iter; left time: 189.2435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 225 | Train Loss: 0.0125397 Vali Loss: 0.0167599 Test Loss: 0.0214477\n",
      "Validation loss decreased (0.016793 --> 0.016760).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0133222\n",
      "\tspeed: 0.0450s/iter; left time: 532.3111s\n",
      "\titers: 200, epoch: 48 | loss: 0.0111298\n",
      "\tspeed: 0.0214s/iter; left time: 251.0576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 225 | Train Loss: 0.0125691 Vali Loss: 0.0169273 Test Loss: 0.0217705\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0110154\n",
      "\tspeed: 0.0456s/iter; left time: 528.4407s\n",
      "\titers: 200, epoch: 49 | loss: 0.0124768\n",
      "\tspeed: 0.0225s/iter; left time: 259.1402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 225 | Train Loss: 0.0125564 Vali Loss: 0.0168432 Test Loss: 0.0215787\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0128464\n",
      "\tspeed: 0.0424s/iter; left time: 482.3756s\n",
      "\titers: 200, epoch: 50 | loss: 0.0131624\n",
      "\tspeed: 0.0222s/iter; left time: 250.6670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 225 | Train Loss: 0.0125534 Vali Loss: 0.0168483 Test Loss: 0.0216448\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0111215\n",
      "\tspeed: 0.0430s/iter; left time: 479.0803s\n",
      "\titers: 200, epoch: 51 | loss: 0.0122721\n",
      "\tspeed: 0.0172s/iter; left time: 190.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 225 | Train Loss: 0.0125398 Vali Loss: 0.0168382 Test Loss: 0.0215763\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0140247\n",
      "\tspeed: 0.0411s/iter; left time: 449.1896s\n",
      "\titers: 200, epoch: 52 | loss: 0.0110990\n",
      "\tspeed: 0.0162s/iter; left time: 174.8441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0125283 Vali Loss: 0.0168521 Test Loss: 0.0215805\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0119962\n",
      "\tspeed: 0.0444s/iter; left time: 475.1415s\n",
      "\titers: 200, epoch: 53 | loss: 0.0125828\n",
      "\tspeed: 0.0201s/iter; left time: 212.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0125533 Vali Loss: 0.0168662 Test Loss: 0.0217082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0110893\n",
      "\tspeed: 0.0394s/iter; left time: 413.0468s\n",
      "\titers: 200, epoch: 54 | loss: 0.0135871\n",
      "\tspeed: 0.0163s/iter; left time: 169.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0125420 Vali Loss: 0.0168111 Test Loss: 0.0215567\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0126214\n",
      "\tspeed: 0.0407s/iter; left time: 417.3350s\n",
      "\titers: 200, epoch: 55 | loss: 0.0112188\n",
      "\tspeed: 0.0192s/iter; left time: 194.5268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0125635 Vali Loss: 0.0168251 Test Loss: 0.0216542\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0120411\n",
      "\tspeed: 0.0409s/iter; left time: 409.6515s\n",
      "\titers: 200, epoch: 56 | loss: 0.0110059\n",
      "\tspeed: 0.0184s/iter; left time: 182.2896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0125221 Vali Loss: 0.0169018 Test Loss: 0.0217581\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0125544\n",
      "\tspeed: 0.0399s/iter; left time: 391.1170s\n",
      "\titers: 200, epoch: 57 | loss: 0.0121166\n",
      "\tspeed: 0.0164s/iter; left time: 158.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0125559 Vali Loss: 0.0168544 Test Loss: 0.0216700\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021447671577334404, rmse:0.1464502364397049, mae:0.09291932731866837, rse:0.567215621471405\n",
      "Intermediate time for FR and pred_len 168: 00h:05m:47.83s\n",
      "Intermediate time for FR: 00h:20m:19.96s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1377798\n",
      "\tspeed: 0.0314s/iter; left time: 707.1201s\n",
      "\titers: 200, epoch: 1 | loss: 0.1134172\n",
      "\tspeed: 0.0169s/iter; left time: 378.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 226 | Train Loss: 0.1356952 Vali Loss: 0.0691775 Test Loss: 0.0705373\n",
      "Validation loss decreased (inf --> 0.069177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0454729\n",
      "\tspeed: 0.0403s/iter; left time: 897.9605s\n",
      "\titers: 200, epoch: 2 | loss: 0.0281168\n",
      "\tspeed: 0.0166s/iter; left time: 367.4979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 226 | Train Loss: 0.0508938 Vali Loss: 0.0187556 Test Loss: 0.0189566\n",
      "Validation loss decreased (0.069177 --> 0.018756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0249880\n",
      "\tspeed: 0.0380s/iter; left time: 837.9958s\n",
      "\titers: 200, epoch: 3 | loss: 0.0227560\n",
      "\tspeed: 0.0156s/iter; left time: 343.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 226 | Train Loss: 0.0242646 Vali Loss: 0.0175866 Test Loss: 0.0178655\n",
      "Validation loss decreased (0.018756 --> 0.017587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0204239\n",
      "\tspeed: 0.0374s/iter; left time: 816.9283s\n",
      "\titers: 200, epoch: 4 | loss: 0.0167463\n",
      "\tspeed: 0.0181s/iter; left time: 392.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0206555 Vali Loss: 0.0154143 Test Loss: 0.0155426\n",
      "Validation loss decreased (0.017587 --> 0.015414).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0191221\n",
      "\tspeed: 0.0401s/iter; left time: 865.8100s\n",
      "\titers: 200, epoch: 5 | loss: 0.0179364\n",
      "\tspeed: 0.0166s/iter; left time: 356.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0187411 Vali Loss: 0.0150593 Test Loss: 0.0152536\n",
      "Validation loss decreased (0.015414 --> 0.015059).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0172716\n",
      "\tspeed: 0.0366s/iter; left time: 781.9464s\n",
      "\titers: 200, epoch: 6 | loss: 0.0160908\n",
      "\tspeed: 0.0158s/iter; left time: 335.3546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0173488 Vali Loss: 0.0142850 Test Loss: 0.0140409\n",
      "Validation loss decreased (0.015059 --> 0.014285).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0192723\n",
      "\tspeed: 0.0388s/iter; left time: 821.4624s\n",
      "\titers: 200, epoch: 7 | loss: 0.0155777\n",
      "\tspeed: 0.0155s/iter; left time: 325.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.0162256 Vali Loss: 0.0136374 Test Loss: 0.0131467\n",
      "Validation loss decreased (0.014285 --> 0.013637).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0142089\n",
      "\tspeed: 0.0372s/iter; left time: 778.5808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0156101\n",
      "\tspeed: 0.0154s/iter; left time: 321.6397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0153529 Vali Loss: 0.0132084 Test Loss: 0.0128746\n",
      "Validation loss decreased (0.013637 --> 0.013208).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0145481\n",
      "\tspeed: 0.0356s/iter; left time: 737.3247s\n",
      "\titers: 200, epoch: 9 | loss: 0.0146893\n",
      "\tspeed: 0.0176s/iter; left time: 363.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0145578 Vali Loss: 0.0127671 Test Loss: 0.0125622\n",
      "Validation loss decreased (0.013208 --> 0.012767).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0143092\n",
      "\tspeed: 0.0400s/iter; left time: 817.7824s\n",
      "\titers: 200, epoch: 10 | loss: 0.0153943\n",
      "\tspeed: 0.0153s/iter; left time: 311.9292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0139438 Vali Loss: 0.0124113 Test Loss: 0.0123004\n",
      "Validation loss decreased (0.012767 --> 0.012411).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0136494\n",
      "\tspeed: 0.0383s/iter; left time: 774.2644s\n",
      "\titers: 200, epoch: 11 | loss: 0.0137830\n",
      "\tspeed: 0.0154s/iter; left time: 311.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0135146 Vali Loss: 0.0120716 Test Loss: 0.0119796\n",
      "Validation loss decreased (0.012411 --> 0.012072).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0143659\n",
      "\tspeed: 0.0392s/iter; left time: 783.6507s\n",
      "\titers: 200, epoch: 12 | loss: 0.0141641\n",
      "\tspeed: 0.0160s/iter; left time: 319.1634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0132291 Vali Loss: 0.0119187 Test Loss: 0.0118970\n",
      "Validation loss decreased (0.012072 --> 0.011919).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0125218\n",
      "\tspeed: 0.0374s/iter; left time: 739.4350s\n",
      "\titers: 200, epoch: 13 | loss: 0.0105008\n",
      "\tspeed: 0.0155s/iter; left time: 306.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 226 | Train Loss: 0.0128624 Vali Loss: 0.0116479 Test Loss: 0.0117148\n",
      "Validation loss decreased (0.011919 --> 0.011648).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0129370\n",
      "\tspeed: 0.0386s/iter; left time: 755.8248s\n",
      "\titers: 200, epoch: 14 | loss: 0.0128722\n",
      "\tspeed: 0.0188s/iter; left time: 365.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0126495 Vali Loss: 0.0116615 Test Loss: 0.0116488\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0116378\n",
      "\tspeed: 0.0387s/iter; left time: 748.0828s\n",
      "\titers: 200, epoch: 15 | loss: 0.0139435\n",
      "\tspeed: 0.0166s/iter; left time: 318.6525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0124032 Vali Loss: 0.0113834 Test Loss: 0.0114933\n",
      "Validation loss decreased (0.011648 --> 0.011383).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0125016\n",
      "\tspeed: 0.0367s/iter; left time: 701.9640s\n",
      "\titers: 200, epoch: 16 | loss: 0.0106876\n",
      "\tspeed: 0.0158s/iter; left time: 299.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 226 | Train Loss: 0.0122276 Vali Loss: 0.0113101 Test Loss: 0.0114584\n",
      "Validation loss decreased (0.011383 --> 0.011310).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0115151\n",
      "\tspeed: 0.0387s/iter; left time: 731.5339s\n",
      "\titers: 200, epoch: 17 | loss: 0.0120240\n",
      "\tspeed: 0.0162s/iter; left time: 305.2480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0120420 Vali Loss: 0.0112633 Test Loss: 0.0113524\n",
      "Validation loss decreased (0.011310 --> 0.011263).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0127090\n",
      "\tspeed: 0.0381s/iter; left time: 710.4053s\n",
      "\titers: 200, epoch: 18 | loss: 0.0114372\n",
      "\tspeed: 0.0158s/iter; left time: 292.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 226 | Train Loss: 0.0119783 Vali Loss: 0.0111370 Test Loss: 0.0113526\n",
      "Validation loss decreased (0.011263 --> 0.011137).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0128387\n",
      "\tspeed: 0.0366s/iter; left time: 674.8819s\n",
      "\titers: 200, epoch: 19 | loss: 0.0113665\n",
      "\tspeed: 0.0160s/iter; left time: 292.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 226 | Train Loss: 0.0118393 Vali Loss: 0.0110697 Test Loss: 0.0112947\n",
      "Validation loss decreased (0.011137 --> 0.011070).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0107364\n",
      "\tspeed: 0.0411s/iter; left time: 748.1290s\n",
      "\titers: 200, epoch: 20 | loss: 0.0134741\n",
      "\tspeed: 0.0162s/iter; left time: 292.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0116963 Vali Loss: 0.0109283 Test Loss: 0.0112035\n",
      "Validation loss decreased (0.011070 --> 0.010928).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0119992\n",
      "\tspeed: 0.0371s/iter; left time: 667.2474s\n",
      "\titers: 200, epoch: 21 | loss: 0.0122915\n",
      "\tspeed: 0.0162s/iter; left time: 289.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 226 | Train Loss: 0.0116031 Vali Loss: 0.0109897 Test Loss: 0.0112439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0104237\n",
      "\tspeed: 0.0400s/iter; left time: 709.7304s\n",
      "\titers: 200, epoch: 22 | loss: 0.0119740\n",
      "\tspeed: 0.0196s/iter; left time: 345.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0115132 Vali Loss: 0.0108854 Test Loss: 0.0111452\n",
      "Validation loss decreased (0.010928 --> 0.010885).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0096794\n",
      "\tspeed: 0.0427s/iter; left time: 747.6887s\n",
      "\titers: 200, epoch: 23 | loss: 0.0107608\n",
      "\tspeed: 0.0175s/iter; left time: 304.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0114976 Vali Loss: 0.0107883 Test Loss: 0.0111224\n",
      "Validation loss decreased (0.010885 --> 0.010788).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0098029\n",
      "\tspeed: 0.0372s/iter; left time: 643.5511s\n",
      "\titers: 200, epoch: 24 | loss: 0.0121425\n",
      "\tspeed: 0.0159s/iter; left time: 274.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0114222 Vali Loss: 0.0107622 Test Loss: 0.0111308\n",
      "Validation loss decreased (0.010788 --> 0.010762).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0106548\n",
      "\tspeed: 0.0396s/iter; left time: 676.6428s\n",
      "\titers: 200, epoch: 25 | loss: 0.0118627\n",
      "\tspeed: 0.0156s/iter; left time: 264.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0113376 Vali Loss: 0.0107183 Test Loss: 0.0110923\n",
      "Validation loss decreased (0.010762 --> 0.010718).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0095081\n",
      "\tspeed: 0.0400s/iter; left time: 674.5490s\n",
      "\titers: 200, epoch: 26 | loss: 0.0126063\n",
      "\tspeed: 0.0240s/iter; left time: 402.0363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 226 | Train Loss: 0.0113432 Vali Loss: 0.0106847 Test Loss: 0.0110543\n",
      "Validation loss decreased (0.010718 --> 0.010685).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0102837\n",
      "\tspeed: 0.0411s/iter; left time: 682.6351s\n",
      "\titers: 200, epoch: 27 | loss: 0.0128509\n",
      "\tspeed: 0.0154s/iter; left time: 253.7999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 226 | Train Loss: 0.0112524 Vali Loss: 0.0106316 Test Loss: 0.0110191\n",
      "Validation loss decreased (0.010685 --> 0.010632).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0112080\n",
      "\tspeed: 0.0379s/iter; left time: 621.3778s\n",
      "\titers: 200, epoch: 28 | loss: 0.0097912\n",
      "\tspeed: 0.0160s/iter; left time: 261.3668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 226 | Train Loss: 0.0112507 Vali Loss: 0.0106654 Test Loss: 0.0110507\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0117082\n",
      "\tspeed: 0.0456s/iter; left time: 737.3555s\n",
      "\titers: 200, epoch: 29 | loss: 0.0121781\n",
      "\tspeed: 0.0150s/iter; left time: 240.7264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0112207 Vali Loss: 0.0106669 Test Loss: 0.0110702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0096842\n",
      "\tspeed: 0.0361s/iter; left time: 575.5568s\n",
      "\titers: 200, epoch: 30 | loss: 0.0130751\n",
      "\tspeed: 0.0153s/iter; left time: 242.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0111561 Vali Loss: 0.0106135 Test Loss: 0.0109990\n",
      "Validation loss decreased (0.010632 --> 0.010614).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0104511\n",
      "\tspeed: 0.0394s/iter; left time: 618.7753s\n",
      "\titers: 200, epoch: 31 | loss: 0.0122376\n",
      "\tspeed: 0.0193s/iter; left time: 301.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 226 | Train Loss: 0.0111730 Vali Loss: 0.0105777 Test Loss: 0.0109957\n",
      "Validation loss decreased (0.010614 --> 0.010578).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0099746\n",
      "\tspeed: 0.0429s/iter; left time: 665.1567s\n",
      "\titers: 200, epoch: 32 | loss: 0.0106001\n",
      "\tspeed: 0.0168s/iter; left time: 259.0305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0111217 Vali Loss: 0.0105124 Test Loss: 0.0109593\n",
      "Validation loss decreased (0.010578 --> 0.010512).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0115203\n",
      "\tspeed: 0.0366s/iter; left time: 559.4682s\n",
      "\titers: 200, epoch: 33 | loss: 0.0115479\n",
      "\tspeed: 0.0152s/iter; left time: 231.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 226 | Train Loss: 0.0111433 Vali Loss: 0.0105266 Test Loss: 0.0109338\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0098360\n",
      "\tspeed: 0.0469s/iter; left time: 706.2570s\n",
      "\titers: 200, epoch: 34 | loss: 0.0118058\n",
      "\tspeed: 0.0164s/iter; left time: 244.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 226 | Train Loss: 0.0110997 Vali Loss: 0.0105341 Test Loss: 0.0109536\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0106727\n",
      "\tspeed: 0.0352s/iter; left time: 521.5914s\n",
      "\titers: 200, epoch: 35 | loss: 0.0121903\n",
      "\tspeed: 0.0168s/iter; left time: 246.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 226 | Train Loss: 0.0110825 Vali Loss: 0.0105078 Test Loss: 0.0109191\n",
      "Validation loss decreased (0.010512 --> 0.010508).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0109003\n",
      "\tspeed: 0.0425s/iter; left time: 620.2390s\n",
      "\titers: 200, epoch: 36 | loss: 0.0107535\n",
      "\tspeed: 0.0212s/iter; left time: 307.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 226 | Train Loss: 0.0110776 Vali Loss: 0.0104943 Test Loss: 0.0109287\n",
      "Validation loss decreased (0.010508 --> 0.010494).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0111721\n",
      "\tspeed: 0.0437s/iter; left time: 627.5663s\n",
      "\titers: 200, epoch: 37 | loss: 0.0111821\n",
      "\tspeed: 0.0165s/iter; left time: 235.6323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 226 | Train Loss: 0.0110402 Vali Loss: 0.0104634 Test Loss: 0.0109022\n",
      "Validation loss decreased (0.010494 --> 0.010463).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0107937\n",
      "\tspeed: 0.0412s/iter; left time: 583.2147s\n",
      "\titers: 200, epoch: 38 | loss: 0.0121695\n",
      "\tspeed: 0.0154s/iter; left time: 216.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 226 | Train Loss: 0.0110640 Vali Loss: 0.0104891 Test Loss: 0.0109258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0102771\n",
      "\tspeed: 0.0486s/iter; left time: 675.8196s\n",
      "\titers: 200, epoch: 39 | loss: 0.0103673\n",
      "\tspeed: 0.0199s/iter; left time: 274.8001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 226 | Train Loss: 0.0110183 Vali Loss: 0.0104331 Test Loss: 0.0108840\n",
      "Validation loss decreased (0.010463 --> 0.010433).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0122261\n",
      "\tspeed: 0.0368s/iter; left time: 504.2283s\n",
      "\titers: 200, epoch: 40 | loss: 0.0112992\n",
      "\tspeed: 0.0182s/iter; left time: 247.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 226 | Train Loss: 0.0110450 Vali Loss: 0.0104266 Test Loss: 0.0109060\n",
      "Validation loss decreased (0.010433 --> 0.010427).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0105818\n",
      "\tspeed: 0.0376s/iter; left time: 506.4033s\n",
      "\titers: 200, epoch: 41 | loss: 0.0132477\n",
      "\tspeed: 0.0219s/iter; left time: 292.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 226 | Train Loss: 0.0110133 Vali Loss: 0.0104213 Test Loss: 0.0108878\n",
      "Validation loss decreased (0.010427 --> 0.010421).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0100628\n",
      "\tspeed: 0.0434s/iter; left time: 574.7919s\n",
      "\titers: 200, epoch: 42 | loss: 0.0111368\n",
      "\tspeed: 0.0186s/iter; left time: 243.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 226 | Train Loss: 0.0109489 Vali Loss: 0.0104123 Test Loss: 0.0108733\n",
      "Validation loss decreased (0.010421 --> 0.010412).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0115083\n",
      "\tspeed: 0.0402s/iter; left time: 522.8612s\n",
      "\titers: 200, epoch: 43 | loss: 0.0104760\n",
      "\tspeed: 0.0185s/iter; left time: 239.0482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0109990 Vali Loss: 0.0103668 Test Loss: 0.0108622\n",
      "Validation loss decreased (0.010412 --> 0.010367).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0111897\n",
      "\tspeed: 0.0484s/iter; left time: 618.6437s\n",
      "\titers: 200, epoch: 44 | loss: 0.0107037\n",
      "\tspeed: 0.0172s/iter; left time: 218.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0110186 Vali Loss: 0.0104406 Test Loss: 0.0108855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0110654\n",
      "\tspeed: 0.0381s/iter; left time: 478.3879s\n",
      "\titers: 200, epoch: 45 | loss: 0.0112306\n",
      "\tspeed: 0.0153s/iter; left time: 190.6268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 226 | Train Loss: 0.0110232 Vali Loss: 0.0103820 Test Loss: 0.0108644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0123103\n",
      "\tspeed: 0.0368s/iter; left time: 454.1900s\n",
      "\titers: 200, epoch: 46 | loss: 0.0101690\n",
      "\tspeed: 0.0212s/iter; left time: 259.1501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.65s\n",
      "Steps: 226 | Train Loss: 0.0109794 Vali Loss: 0.0104060 Test Loss: 0.0108795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0109692\n",
      "\tspeed: 0.0389s/iter; left time: 470.5442s\n",
      "\titers: 200, epoch: 47 | loss: 0.0125076\n",
      "\tspeed: 0.0162s/iter; left time: 194.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 226 | Train Loss: 0.0109345 Vali Loss: 0.0103910 Test Loss: 0.0108578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0114056\n",
      "\tspeed: 0.0374s/iter; left time: 444.4565s\n",
      "\titers: 200, epoch: 48 | loss: 0.0106638\n",
      "\tspeed: 0.0172s/iter; left time: 202.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0109523 Vali Loss: 0.0104009 Test Loss: 0.0108567\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0106638\n",
      "\tspeed: 0.0453s/iter; left time: 528.1298s\n",
      "\titers: 200, epoch: 49 | loss: 0.0125533\n",
      "\tspeed: 0.0154s/iter; left time: 177.8244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0109971 Vali Loss: 0.0104058 Test Loss: 0.0108558\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0118140\n",
      "\tspeed: 0.0383s/iter; left time: 438.2017s\n",
      "\titers: 200, epoch: 50 | loss: 0.0120683\n",
      "\tspeed: 0.0156s/iter; left time: 176.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0109812 Vali Loss: 0.0104026 Test Loss: 0.0108490\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0122474\n",
      "\tspeed: 0.0415s/iter; left time: 464.7840s\n",
      "\titers: 200, epoch: 51 | loss: 0.0104948\n",
      "\tspeed: 0.0204s/iter; left time: 226.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 226 | Train Loss: 0.0109754 Vali Loss: 0.0103916 Test Loss: 0.0108564\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0111523\n",
      "\tspeed: 0.0487s/iter; left time: 534.3213s\n",
      "\titers: 200, epoch: 52 | loss: 0.0121978\n",
      "\tspeed: 0.0230s/iter; left time: 250.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 226 | Train Loss: 0.0109734 Vali Loss: 0.0103702 Test Loss: 0.0108537\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0112344\n",
      "\tspeed: 0.0447s/iter; left time: 480.0841s\n",
      "\titers: 200, epoch: 53 | loss: 0.0115661\n",
      "\tspeed: 0.0268s/iter; left time: 285.0449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 226 | Train Loss: 0.0109682 Vali Loss: 0.0103765 Test Loss: 0.0108480\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01086221169680357, rmse:0.10422193259000778, mae:0.06578190624713898, rse:0.3938033878803253\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:10.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1392661\n",
      "\tspeed: 0.0307s/iter; left time: 688.2546s\n",
      "\titers: 200, epoch: 1 | loss: 0.1204742\n",
      "\tspeed: 0.0182s/iter; left time: 406.0846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 225 | Train Loss: 0.1416145 Vali Loss: 0.0775000 Test Loss: 0.0788219\n",
      "Validation loss decreased (inf --> 0.077500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0494399\n",
      "\tspeed: 0.0501s/iter; left time: 1111.1051s\n",
      "\titers: 200, epoch: 2 | loss: 0.0351452\n",
      "\tspeed: 0.0159s/iter; left time: 351.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0541683 Vali Loss: 0.0280526 Test Loss: 0.0307065\n",
      "Validation loss decreased (0.077500 --> 0.028053).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0307060\n",
      "\tspeed: 0.0398s/iter; left time: 873.9285s\n",
      "\titers: 200, epoch: 3 | loss: 0.0298869\n",
      "\tspeed: 0.0187s/iter; left time: 408.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0315663 Vali Loss: 0.0246129 Test Loss: 0.0260684\n",
      "Validation loss decreased (0.028053 --> 0.024613).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0269790\n",
      "\tspeed: 0.0395s/iter; left time: 857.2184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0263730\n",
      "\tspeed: 0.0246s/iter; left time: 532.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 225 | Train Loss: 0.0273871 Vali Loss: 0.0219977 Test Loss: 0.0225720\n",
      "Validation loss decreased (0.024613 --> 0.021998).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0226175\n",
      "\tspeed: 0.0406s/iter; left time: 872.2530s\n",
      "\titers: 200, epoch: 5 | loss: 0.0209078\n",
      "\tspeed: 0.0154s/iter; left time: 328.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 225 | Train Loss: 0.0243868 Vali Loss: 0.0199966 Test Loss: 0.0200491\n",
      "Validation loss decreased (0.021998 --> 0.019997).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0221272\n",
      "\tspeed: 0.0414s/iter; left time: 880.3996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0230589\n",
      "\tspeed: 0.0164s/iter; left time: 346.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 225 | Train Loss: 0.0224359 Vali Loss: 0.0190496 Test Loss: 0.0193386\n",
      "Validation loss decreased (0.019997 --> 0.019050).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0198746\n",
      "\tspeed: 0.0531s/iter; left time: 1118.7714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0217593\n",
      "\tspeed: 0.0159s/iter; left time: 333.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0213778 Vali Loss: 0.0183945 Test Loss: 0.0188222\n",
      "Validation loss decreased (0.019050 --> 0.018394).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0216212\n",
      "\tspeed: 0.0397s/iter; left time: 826.0295s\n",
      "\titers: 200, epoch: 8 | loss: 0.0201936\n",
      "\tspeed: 0.0155s/iter; left time: 320.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0206121 Vali Loss: 0.0181737 Test Loss: 0.0186618\n",
      "Validation loss decreased (0.018394 --> 0.018174).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0186395\n",
      "\tspeed: 0.0385s/iter; left time: 793.5908s\n",
      "\titers: 200, epoch: 9 | loss: 0.0181642\n",
      "\tspeed: 0.0234s/iter; left time: 479.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.73s\n",
      "Steps: 225 | Train Loss: 0.0200061 Vali Loss: 0.0179292 Test Loss: 0.0186835\n",
      "Validation loss decreased (0.018174 --> 0.017929).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0188193\n",
      "\tspeed: 0.0399s/iter; left time: 812.9797s\n",
      "\titers: 200, epoch: 10 | loss: 0.0192629\n",
      "\tspeed: 0.0192s/iter; left time: 389.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0196039 Vali Loss: 0.0174620 Test Loss: 0.0184903\n",
      "Validation loss decreased (0.017929 --> 0.017462).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0191812\n",
      "\tspeed: 0.0393s/iter; left time: 791.6841s\n",
      "\titers: 200, epoch: 11 | loss: 0.0187980\n",
      "\tspeed: 0.0165s/iter; left time: 331.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0191906 Vali Loss: 0.0173062 Test Loss: 0.0184059\n",
      "Validation loss decreased (0.017462 --> 0.017306).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0182141\n",
      "\tspeed: 0.0501s/iter; left time: 997.6922s\n",
      "\titers: 200, epoch: 12 | loss: 0.0185133\n",
      "\tspeed: 0.0160s/iter; left time: 316.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 225 | Train Loss: 0.0188441 Vali Loss: 0.0172411 Test Loss: 0.0183969\n",
      "Validation loss decreased (0.017306 --> 0.017241).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0194464\n",
      "\tspeed: 0.0430s/iter; left time: 847.1020s\n",
      "\titers: 200, epoch: 13 | loss: 0.0186859\n",
      "\tspeed: 0.0170s/iter; left time: 333.6627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0186049 Vali Loss: 0.0170427 Test Loss: 0.0182708\n",
      "Validation loss decreased (0.017241 --> 0.017043).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0203162\n",
      "\tspeed: 0.0383s/iter; left time: 745.2474s\n",
      "\titers: 200, epoch: 14 | loss: 0.0189898\n",
      "\tspeed: 0.0213s/iter; left time: 412.9784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0185252 Vali Loss: 0.0170671 Test Loss: 0.0182412\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0181951\n",
      "\tspeed: 0.0438s/iter; left time: 843.1686s\n",
      "\titers: 200, epoch: 15 | loss: 0.0186964\n",
      "\tspeed: 0.0154s/iter; left time: 294.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 225 | Train Loss: 0.0185144 Vali Loss: 0.0168636 Test Loss: 0.0181672\n",
      "Validation loss decreased (0.017043 --> 0.016864).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0191887\n",
      "\tspeed: 0.0386s/iter; left time: 733.9795s\n",
      "\titers: 200, epoch: 16 | loss: 0.0185525\n",
      "\tspeed: 0.0161s/iter; left time: 304.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0181708 Vali Loss: 0.0168464 Test Loss: 0.0181170\n",
      "Validation loss decreased (0.016864 --> 0.016846).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0163151\n",
      "\tspeed: 0.0435s/iter; left time: 817.9885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0181100\n",
      "\tspeed: 0.0170s/iter; left time: 318.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0180505 Vali Loss: 0.0168423 Test Loss: 0.0181461\n",
      "Validation loss decreased (0.016846 --> 0.016842).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0194149\n",
      "\tspeed: 0.0385s/iter; left time: 714.3310s\n",
      "\titers: 200, epoch: 18 | loss: 0.0171451\n",
      "\tspeed: 0.0156s/iter; left time: 289.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 225 | Train Loss: 0.0181414 Vali Loss: 0.0169269 Test Loss: 0.0180586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0182438\n",
      "\tspeed: 0.0373s/iter; left time: 685.1473s\n",
      "\titers: 200, epoch: 19 | loss: 0.0176386\n",
      "\tspeed: 0.0194s/iter; left time: 354.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0179795 Vali Loss: 0.0167794 Test Loss: 0.0180080\n",
      "Validation loss decreased (0.016842 --> 0.016779).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0172766\n",
      "\tspeed: 0.0477s/iter; left time: 864.4272s\n",
      "\titers: 200, epoch: 20 | loss: 0.0182251\n",
      "\tspeed: 0.0157s/iter; left time: 283.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0178784 Vali Loss: 0.0166909 Test Loss: 0.0179906\n",
      "Validation loss decreased (0.016779 --> 0.016691).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0180581\n",
      "\tspeed: 0.0361s/iter; left time: 646.7739s\n",
      "\titers: 200, epoch: 21 | loss: 0.0151387\n",
      "\tspeed: 0.0185s/iter; left time: 329.9807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 225 | Train Loss: 0.0179008 Vali Loss: 0.0167441 Test Loss: 0.0179501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0192179\n",
      "\tspeed: 0.0394s/iter; left time: 697.1273s\n",
      "\titers: 200, epoch: 22 | loss: 0.0170067\n",
      "\tspeed: 0.0236s/iter; left time: 414.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0178270 Vali Loss: 0.0167418 Test Loss: 0.0179967\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0188884\n",
      "\tspeed: 0.0380s/iter; left time: 663.6254s\n",
      "\titers: 200, epoch: 23 | loss: 0.0179435\n",
      "\tspeed: 0.0155s/iter; left time: 269.5471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 225 | Train Loss: 0.0178563 Vali Loss: 0.0167881 Test Loss: 0.0179131\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0166721\n",
      "\tspeed: 0.0409s/iter; left time: 704.5206s\n",
      "\titers: 200, epoch: 24 | loss: 0.0167049\n",
      "\tspeed: 0.0182s/iter; left time: 311.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0177363 Vali Loss: 0.0166589 Test Loss: 0.0179240\n",
      "Validation loss decreased (0.016691 --> 0.016659).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0176328\n",
      "\tspeed: 0.0437s/iter; left time: 743.7240s\n",
      "\titers: 200, epoch: 25 | loss: 0.0188900\n",
      "\tspeed: 0.0169s/iter; left time: 285.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0177095 Vali Loss: 0.0166848 Test Loss: 0.0179018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0192010\n",
      "\tspeed: 0.0395s/iter; left time: 662.8999s\n",
      "\titers: 200, epoch: 26 | loss: 0.0169397\n",
      "\tspeed: 0.0162s/iter; left time: 270.7029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0176629 Vali Loss: 0.0166513 Test Loss: 0.0178868\n",
      "Validation loss decreased (0.016659 --> 0.016651).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0183525\n",
      "\tspeed: 0.0360s/iter; left time: 596.6274s\n",
      "\titers: 200, epoch: 27 | loss: 0.0177022\n",
      "\tspeed: 0.0161s/iter; left time: 265.6034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 225 | Train Loss: 0.0176258 Vali Loss: 0.0166351 Test Loss: 0.0179146\n",
      "Validation loss decreased (0.016651 --> 0.016635).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0178615\n",
      "\tspeed: 0.0470s/iter; left time: 767.7431s\n",
      "\titers: 200, epoch: 28 | loss: 0.0168865\n",
      "\tspeed: 0.0189s/iter; left time: 306.3214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.0176033 Vali Loss: 0.0166053 Test Loss: 0.0178937\n",
      "Validation loss decreased (0.016635 --> 0.016605).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0178555\n",
      "\tspeed: 0.0448s/iter; left time: 720.5228s\n",
      "\titers: 200, epoch: 29 | loss: 0.0161150\n",
      "\tspeed: 0.0198s/iter; left time: 316.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 225 | Train Loss: 0.0177332 Vali Loss: 0.0166127 Test Loss: 0.0179433\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0179884\n",
      "\tspeed: 0.0407s/iter; left time: 646.0243s\n",
      "\titers: 200, epoch: 30 | loss: 0.0178666\n",
      "\tspeed: 0.0174s/iter; left time: 274.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0176146 Vali Loss: 0.0166176 Test Loss: 0.0178403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0168105\n",
      "\tspeed: 0.0417s/iter; left time: 653.0652s\n",
      "\titers: 200, epoch: 31 | loss: 0.0173617\n",
      "\tspeed: 0.0166s/iter; left time: 258.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0176003 Vali Loss: 0.0166262 Test Loss: 0.0179176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0176612\n",
      "\tspeed: 0.0419s/iter; left time: 646.9951s\n",
      "\titers: 200, epoch: 32 | loss: 0.0180373\n",
      "\tspeed: 0.0186s/iter; left time: 285.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0175764 Vali Loss: 0.0165676 Test Loss: 0.0178750\n",
      "Validation loss decreased (0.016605 --> 0.016568).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0189767\n",
      "\tspeed: 0.0430s/iter; left time: 654.1170s\n",
      "\titers: 200, epoch: 33 | loss: 0.0189711\n",
      "\tspeed: 0.0186s/iter; left time: 280.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0175471 Vali Loss: 0.0165941 Test Loss: 0.0178602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0194196\n",
      "\tspeed: 0.0400s/iter; left time: 598.6058s\n",
      "\titers: 200, epoch: 34 | loss: 0.0171694\n",
      "\tspeed: 0.0188s/iter; left time: 279.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0177479 Vali Loss: 0.0165743 Test Loss: 0.0179026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0174454\n",
      "\tspeed: 0.0399s/iter; left time: 588.7410s\n",
      "\titers: 200, epoch: 35 | loss: 0.0170476\n",
      "\tspeed: 0.0169s/iter; left time: 248.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 225 | Train Loss: 0.0175278 Vali Loss: 0.0165909 Test Loss: 0.0178695\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0187867\n",
      "\tspeed: 0.0420s/iter; left time: 609.7748s\n",
      "\titers: 200, epoch: 36 | loss: 0.0183198\n",
      "\tspeed: 0.0179s/iter; left time: 257.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 225 | Train Loss: 0.0174957 Vali Loss: 0.0165789 Test Loss: 0.0178887\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0183138\n",
      "\tspeed: 0.0410s/iter; left time: 587.0511s\n",
      "\titers: 200, epoch: 37 | loss: 0.0150607\n",
      "\tspeed: 0.0162s/iter; left time: 229.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 225 | Train Loss: 0.0174517 Vali Loss: 0.0165912 Test Loss: 0.0178495\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0182852\n",
      "\tspeed: 0.0420s/iter; left time: 590.7422s\n",
      "\titers: 200, epoch: 38 | loss: 0.0169175\n",
      "\tspeed: 0.0171s/iter; left time: 238.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0175080 Vali Loss: 0.0166019 Test Loss: 0.0178501\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0156278\n",
      "\tspeed: 0.0421s/iter; left time: 582.4355s\n",
      "\titers: 200, epoch: 39 | loss: 0.0177135\n",
      "\tspeed: 0.0164s/iter; left time: 224.9442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 225 | Train Loss: 0.0174615 Vali Loss: 0.0165793 Test Loss: 0.0178496\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0160366\n",
      "\tspeed: 0.0396s/iter; left time: 539.8779s\n",
      "\titers: 200, epoch: 40 | loss: 0.0179165\n",
      "\tspeed: 0.0169s/iter; left time: 228.9658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 225 | Train Loss: 0.0175011 Vali Loss: 0.0165816 Test Loss: 0.0178705\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0154619\n",
      "\tspeed: 0.0416s/iter; left time: 557.3494s\n",
      "\titers: 200, epoch: 41 | loss: 0.0161167\n",
      "\tspeed: 0.0164s/iter; left time: 217.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 225 | Train Loss: 0.0175633 Vali Loss: 0.0166112 Test Loss: 0.0177791\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0202491\n",
      "\tspeed: 0.0427s/iter; left time: 562.0311s\n",
      "\titers: 200, epoch: 42 | loss: 0.0169839\n",
      "\tspeed: 0.0180s/iter; left time: 235.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0174733 Vali Loss: 0.0166012 Test Loss: 0.0178329\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01787497289478779, rmse:0.13369731605052948, mae:0.08597136288881302, rse:0.5055239796638489\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:16.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='no_revin_IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : no_revin_IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1453078\n",
      "\tspeed: 0.0322s/iter; left time: 721.7015s\n",
      "\titers: 200, epoch: 1 | loss: 0.1207458\n",
      "\tspeed: 0.0168s/iter; left time: 374.5495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.1447215 Vali Loss: 0.0810303 Test Loss: 0.0813294\n",
      "Validation loss decreased (inf --> 0.081030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0436250\n",
      "\tspeed: 0.0401s/iter; left time: 888.7858s\n",
      "\titers: 200, epoch: 2 | loss: 0.0376781\n",
      "\tspeed: 0.0192s/iter; left time: 424.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0535831 Vali Loss: 0.0297240 Test Loss: 0.0314284\n",
      "Validation loss decreased (0.081030 --> 0.029724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0338296\n",
      "\tspeed: 0.0488s/iter; left time: 1072.2832s\n",
      "\titers: 200, epoch: 3 | loss: 0.0325195\n",
      "\tspeed: 0.0248s/iter; left time: 542.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 225 | Train Loss: 0.0330422 Vali Loss: 0.0259590 Test Loss: 0.0272268\n",
      "Validation loss decreased (0.029724 --> 0.025959).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0318606\n",
      "\tspeed: 0.0404s/iter; left time: 878.8154s\n",
      "\titers: 200, epoch: 4 | loss: 0.0266739\n",
      "\tspeed: 0.0237s/iter; left time: 512.9830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 225 | Train Loss: 0.0283657 Vali Loss: 0.0227529 Test Loss: 0.0220421\n",
      "Validation loss decreased (0.025959 --> 0.022753).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0238208\n",
      "\tspeed: 0.0437s/iter; left time: 939.5025s\n",
      "\titers: 200, epoch: 5 | loss: 0.0228798\n",
      "\tspeed: 0.0200s/iter; left time: 427.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.78s\n",
      "Steps: 225 | Train Loss: 0.0252112 Vali Loss: 0.0213654 Test Loss: 0.0207886\n",
      "Validation loss decreased (0.022753 --> 0.021365).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0247101\n",
      "\tspeed: 0.0426s/iter; left time: 906.8229s\n",
      "\titers: 200, epoch: 6 | loss: 0.0228858\n",
      "\tspeed: 0.0168s/iter; left time: 356.5408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0235146 Vali Loss: 0.0199140 Test Loss: 0.0200730\n",
      "Validation loss decreased (0.021365 --> 0.019914).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0229948\n",
      "\tspeed: 0.0491s/iter; left time: 1032.5559s\n",
      "\titers: 200, epoch: 7 | loss: 0.0219986\n",
      "\tspeed: 0.0166s/iter; left time: 347.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0223978 Vali Loss: 0.0194992 Test Loss: 0.0198671\n",
      "Validation loss decreased (0.019914 --> 0.019499).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0198778\n",
      "\tspeed: 0.0511s/iter; left time: 1063.3477s\n",
      "\titers: 200, epoch: 8 | loss: 0.0218490\n",
      "\tspeed: 0.0171s/iter; left time: 353.7793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0218119 Vali Loss: 0.0193452 Test Loss: 0.0198867\n",
      "Validation loss decreased (0.019499 --> 0.019345).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0218882\n",
      "\tspeed: 0.0493s/iter; left time: 1016.2603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0207634\n",
      "\tspeed: 0.0166s/iter; left time: 340.7163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0212938 Vali Loss: 0.0188900 Test Loss: 0.0195716\n",
      "Validation loss decreased (0.019345 --> 0.018890).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0212140\n",
      "\tspeed: 0.0479s/iter; left time: 976.0093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0213589\n",
      "\tspeed: 0.0169s/iter; left time: 342.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0206631 Vali Loss: 0.0189463 Test Loss: 0.0195167\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0210216\n",
      "\tspeed: 0.0483s/iter; left time: 974.0693s\n",
      "\titers: 200, epoch: 11 | loss: 0.0209635\n",
      "\tspeed: 0.0175s/iter; left time: 350.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0201509 Vali Loss: 0.0184880 Test Loss: 0.0193298\n",
      "Validation loss decreased (0.018890 --> 0.018488).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0192917\n",
      "\tspeed: 0.0490s/iter; left time: 975.5385s\n",
      "\titers: 200, epoch: 12 | loss: 0.0195717\n",
      "\tspeed: 0.0210s/iter; left time: 417.1946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.81s\n",
      "Steps: 225 | Train Loss: 0.0199455 Vali Loss: 0.0186785 Test Loss: 0.0193164\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0193675\n",
      "\tspeed: 0.0428s/iter; left time: 843.9610s\n",
      "\titers: 200, epoch: 13 | loss: 0.0198724\n",
      "\tspeed: 0.0205s/iter; left time: 401.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 225 | Train Loss: 0.0204984 Vali Loss: 0.0184913 Test Loss: 0.0194524\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0189032\n",
      "\tspeed: 0.0437s/iter; left time: 851.2255s\n",
      "\titers: 200, epoch: 14 | loss: 0.0198566\n",
      "\tspeed: 0.0202s/iter; left time: 391.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0197242 Vali Loss: 0.0185386 Test Loss: 0.0192303\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0193591\n",
      "\tspeed: 0.0432s/iter; left time: 832.3689s\n",
      "\titers: 200, epoch: 15 | loss: 0.0191613\n",
      "\tspeed: 0.0223s/iter; left time: 426.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 225 | Train Loss: 0.0195737 Vali Loss: 0.0185342 Test Loss: 0.0192261\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0198897\n",
      "\tspeed: 0.0440s/iter; left time: 836.3660s\n",
      "\titers: 200, epoch: 16 | loss: 0.0210519\n",
      "\tspeed: 0.0204s/iter; left time: 386.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.0194667 Vali Loss: 0.0184915 Test Loss: 0.0191256\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0184417\n",
      "\tspeed: 0.0502s/iter; left time: 943.0232s\n",
      "\titers: 200, epoch: 17 | loss: 0.0198883\n",
      "\tspeed: 0.0249s/iter; left time: 465.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 225 | Train Loss: 0.0194164 Vali Loss: 0.0183380 Test Loss: 0.0191246\n",
      "Validation loss decreased (0.018488 --> 0.018338).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0193421\n",
      "\tspeed: 0.0507s/iter; left time: 940.9454s\n",
      "\titers: 200, epoch: 18 | loss: 0.0193089\n",
      "\tspeed: 0.0190s/iter; left time: 351.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 225 | Train Loss: 0.0193018 Vali Loss: 0.0183337 Test Loss: 0.0190956\n",
      "Validation loss decreased (0.018338 --> 0.018334).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0180100\n",
      "\tspeed: 0.0474s/iter; left time: 869.4505s\n",
      "\titers: 200, epoch: 19 | loss: 0.0208043\n",
      "\tspeed: 0.0218s/iter; left time: 397.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 225 | Train Loss: 0.0192760 Vali Loss: 0.0182659 Test Loss: 0.0190671\n",
      "Validation loss decreased (0.018334 --> 0.018266).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0189537\n",
      "\tspeed: 0.0390s/iter; left time: 707.0205s\n",
      "\titers: 200, epoch: 20 | loss: 0.0194589\n",
      "\tspeed: 0.0259s/iter; left time: 466.8717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0192607 Vali Loss: 0.0183959 Test Loss: 0.0191063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0189893\n",
      "\tspeed: 0.0404s/iter; left time: 723.1905s\n",
      "\titers: 200, epoch: 21 | loss: 0.0187753\n",
      "\tspeed: 0.0209s/iter; left time: 372.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 225 | Train Loss: 0.0192075 Vali Loss: 0.0182782 Test Loss: 0.0190127\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0194451\n",
      "\tspeed: 0.0424s/iter; left time: 749.5785s\n",
      "\titers: 200, epoch: 22 | loss: 0.0195122\n",
      "\tspeed: 0.0205s/iter; left time: 360.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.77s\n",
      "Steps: 225 | Train Loss: 0.0191497 Vali Loss: 0.0182339 Test Loss: 0.0190123\n",
      "Validation loss decreased (0.018266 --> 0.018234).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0185303\n",
      "\tspeed: 0.0445s/iter; left time: 776.8425s\n",
      "\titers: 200, epoch: 23 | loss: 0.0185139\n",
      "\tspeed: 0.0170s/iter; left time: 294.6427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0191384 Vali Loss: 0.0182579 Test Loss: 0.0190225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0191628\n",
      "\tspeed: 0.0482s/iter; left time: 830.7634s\n",
      "\titers: 200, epoch: 24 | loss: 0.0272066\n",
      "\tspeed: 0.0176s/iter; left time: 300.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0190796 Vali Loss: 0.0184180 Test Loss: 0.0190936\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0196890\n",
      "\tspeed: 0.0517s/iter; left time: 878.8391s\n",
      "\titers: 200, epoch: 25 | loss: 0.0194826\n",
      "\tspeed: 0.0183s/iter; left time: 309.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.87s\n",
      "Steps: 225 | Train Loss: 0.0190040 Vali Loss: 0.0181813 Test Loss: 0.0189833\n",
      "Validation loss decreased (0.018234 --> 0.018181).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0181253\n",
      "\tspeed: 0.0502s/iter; left time: 842.8770s\n",
      "\titers: 200, epoch: 26 | loss: 0.0187839\n",
      "\tspeed: 0.0165s/iter; left time: 274.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0189785 Vali Loss: 0.0181851 Test Loss: 0.0189863\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0186646\n",
      "\tspeed: 0.0527s/iter; left time: 872.7093s\n",
      "\titers: 200, epoch: 27 | loss: 0.0195630\n",
      "\tspeed: 0.0177s/iter; left time: 291.2806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0190600 Vali Loss: 0.0182300 Test Loss: 0.0189839\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0203652\n",
      "\tspeed: 0.0537s/iter; left time: 876.7723s\n",
      "\titers: 200, epoch: 28 | loss: 0.0199740\n",
      "\tspeed: 0.0169s/iter; left time: 273.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0189316 Vali Loss: 0.0181757 Test Loss: 0.0189563\n",
      "Validation loss decreased (0.018181 --> 0.018176).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0206350\n",
      "\tspeed: 0.0514s/iter; left time: 828.1764s\n",
      "\titers: 200, epoch: 29 | loss: 0.0181286\n",
      "\tspeed: 0.0175s/iter; left time: 280.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.74s\n",
      "Steps: 225 | Train Loss: 0.0188996 Vali Loss: 0.0181486 Test Loss: 0.0190109\n",
      "Validation loss decreased (0.018176 --> 0.018149).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0196977\n",
      "\tspeed: 0.0497s/iter; left time: 789.4193s\n",
      "\titers: 200, epoch: 30 | loss: 0.0200620\n",
      "\tspeed: 0.0175s/iter; left time: 275.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0189143 Vali Loss: 0.0181804 Test Loss: 0.0189311\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0180183\n",
      "\tspeed: 0.0516s/iter; left time: 807.7268s\n",
      "\titers: 200, epoch: 31 | loss: 0.0181029\n",
      "\tspeed: 0.0168s/iter; left time: 261.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0190194 Vali Loss: 0.0182616 Test Loss: 0.0189574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0182489\n",
      "\tspeed: 0.0499s/iter; left time: 769.0311s\n",
      "\titers: 200, epoch: 32 | loss: 0.0195527\n",
      "\tspeed: 0.0181s/iter; left time: 276.8467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.0190022 Vali Loss: 0.0181670 Test Loss: 0.0189566\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0196477\n",
      "\tspeed: 0.0528s/iter; left time: 802.3022s\n",
      "\titers: 200, epoch: 33 | loss: 0.0195144\n",
      "\tspeed: 0.0257s/iter; left time: 388.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0188667 Vali Loss: 0.0181575 Test Loss: 0.0189364\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0190932\n",
      "\tspeed: 0.0499s/iter; left time: 746.7050s\n",
      "\titers: 200, epoch: 34 | loss: 0.0182831\n",
      "\tspeed: 0.0291s/iter; left time: 433.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 225 | Train Loss: 0.0189012 Vali Loss: 0.0181455 Test Loss: 0.0189204\n",
      "Validation loss decreased (0.018149 --> 0.018145).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0182164\n",
      "\tspeed: 0.0487s/iter; left time: 719.0844s\n",
      "\titers: 200, epoch: 35 | loss: 0.0195959\n",
      "\tspeed: 0.0289s/iter; left time: 423.2001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 225 | Train Loss: 0.0188660 Vali Loss: 0.0181558 Test Loss: 0.0189215\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0192430\n",
      "\tspeed: 0.0424s/iter; left time: 615.8216s\n",
      "\titers: 200, epoch: 36 | loss: 0.0184059\n",
      "\tspeed: 0.0267s/iter; left time: 385.5996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 225 | Train Loss: 0.0188386 Vali Loss: 0.0181532 Test Loss: 0.0189139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0203774\n",
      "\tspeed: 0.0496s/iter; left time: 709.7479s\n",
      "\titers: 200, epoch: 37 | loss: 0.0187826\n",
      "\tspeed: 0.0264s/iter; left time: 375.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0188490 Vali Loss: 0.0180972 Test Loss: 0.0189571\n",
      "Validation loss decreased (0.018145 --> 0.018097).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0191643\n",
      "\tspeed: 0.0483s/iter; left time: 680.0791s\n",
      "\titers: 200, epoch: 38 | loss: 0.0181443\n",
      "\tspeed: 0.0251s/iter; left time: 350.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 225 | Train Loss: 0.0188056 Vali Loss: 0.0181692 Test Loss: 0.0188996\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0184905\n",
      "\tspeed: 0.0479s/iter; left time: 663.5101s\n",
      "\titers: 200, epoch: 39 | loss: 0.0178740\n",
      "\tspeed: 0.0257s/iter; left time: 354.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 225 | Train Loss: 0.0188431 Vali Loss: 0.0181344 Test Loss: 0.0189271\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0185107\n",
      "\tspeed: 0.0448s/iter; left time: 610.3057s\n",
      "\titers: 200, epoch: 40 | loss: 0.0184007\n",
      "\tspeed: 0.0244s/iter; left time: 330.5293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 225 | Train Loss: 0.0188096 Vali Loss: 0.0181285 Test Loss: 0.0189206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0174925\n",
      "\tspeed: 0.0467s/iter; left time: 625.9813s\n",
      "\titers: 200, epoch: 41 | loss: 0.0192582\n",
      "\tspeed: 0.0243s/iter; left time: 323.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 225 | Train Loss: 0.0187985 Vali Loss: 0.0181139 Test Loss: 0.0189121\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0177357\n",
      "\tspeed: 0.0449s/iter; left time: 591.2866s\n",
      "\titers: 200, epoch: 42 | loss: 0.0188432\n",
      "\tspeed: 0.0266s/iter; left time: 347.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 225 | Train Loss: 0.0188488 Vali Loss: 0.0180975 Test Loss: 0.0189411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0186121\n",
      "\tspeed: 0.0501s/iter; left time: 648.3163s\n",
      "\titers: 200, epoch: 43 | loss: 0.0201827\n",
      "\tspeed: 0.0275s/iter; left time: 353.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 225 | Train Loss: 0.0188482 Vali Loss: 0.0181299 Test Loss: 0.0189098\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0187149\n",
      "\tspeed: 0.0450s/iter; left time: 572.1567s\n",
      "\titers: 200, epoch: 44 | loss: 0.0181006\n",
      "\tspeed: 0.0281s/iter; left time: 354.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0187628 Vali Loss: 0.0180758 Test Loss: 0.0189177\n",
      "Validation loss decreased (0.018097 --> 0.018076).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0181435\n",
      "\tspeed: 0.0521s/iter; left time: 651.6721s\n",
      "\titers: 200, epoch: 45 | loss: 0.0196680\n",
      "\tspeed: 0.0259s/iter; left time: 320.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0187586 Vali Loss: 0.0181032 Test Loss: 0.0189198\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0186186\n",
      "\tspeed: 0.0465s/iter; left time: 570.3167s\n",
      "\titers: 200, epoch: 46 | loss: 0.0185255\n",
      "\tspeed: 0.0270s/iter; left time: 328.8205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 225 | Train Loss: 0.0187782 Vali Loss: 0.0180834 Test Loss: 0.0189319\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0172828\n",
      "\tspeed: 0.0475s/iter; left time: 572.9542s\n",
      "\titers: 200, epoch: 47 | loss: 0.0193958\n",
      "\tspeed: 0.0273s/iter; left time: 325.8086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 225 | Train Loss: 0.0187856 Vali Loss: 0.0181030 Test Loss: 0.0188926\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0187976\n",
      "\tspeed: 0.0485s/iter; left time: 573.2992s\n",
      "\titers: 200, epoch: 48 | loss: 0.0174188\n",
      "\tspeed: 0.0286s/iter; left time: 335.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 225 | Train Loss: 0.0187455 Vali Loss: 0.0180691 Test Loss: 0.0189094\n",
      "Validation loss decreased (0.018076 --> 0.018069).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0197352\n",
      "\tspeed: 0.0501s/iter; left time: 580.8285s\n",
      "\titers: 200, epoch: 49 | loss: 0.0174863\n",
      "\tspeed: 0.0289s/iter; left time: 332.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 225 | Train Loss: 0.0188050 Vali Loss: 0.0181176 Test Loss: 0.0188957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0180126\n",
      "\tspeed: 0.0503s/iter; left time: 572.6959s\n",
      "\titers: 200, epoch: 50 | loss: 0.0206608\n",
      "\tspeed: 0.0273s/iter; left time: 308.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0188263 Vali Loss: 0.0180650 Test Loss: 0.0188972\n",
      "Validation loss decreased (0.018069 --> 0.018065).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0170122\n",
      "\tspeed: 0.0449s/iter; left time: 500.5756s\n",
      "\titers: 200, epoch: 51 | loss: 0.0184574\n",
      "\tspeed: 0.0283s/iter; left time: 312.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.0188780 Vali Loss: 0.0181203 Test Loss: 0.0189263\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0204459\n",
      "\tspeed: 0.0498s/iter; left time: 543.9412s\n",
      "\titers: 200, epoch: 52 | loss: 0.0183172\n",
      "\tspeed: 0.0249s/iter; left time: 269.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 225 | Train Loss: 0.0187591 Vali Loss: 0.0180762 Test Loss: 0.0188945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0190909\n",
      "\tspeed: 0.0462s/iter; left time: 494.3914s\n",
      "\titers: 200, epoch: 53 | loss: 0.0182948\n",
      "\tspeed: 0.0249s/iter; left time: 264.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 225 | Train Loss: 0.0187505 Vali Loss: 0.0180655 Test Loss: 0.0189294\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0201165\n",
      "\tspeed: 0.0467s/iter; left time: 488.9342s\n",
      "\titers: 200, epoch: 54 | loss: 0.0195936\n",
      "\tspeed: 0.0162s/iter; left time: 167.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.59s\n",
      "Steps: 225 | Train Loss: 0.0187627 Vali Loss: 0.0180803 Test Loss: 0.0189013\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0197573\n",
      "\tspeed: 0.0428s/iter; left time: 439.1817s\n",
      "\titers: 200, epoch: 55 | loss: 0.0185649\n",
      "\tspeed: 0.0158s/iter; left time: 160.4360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 225 | Train Loss: 0.0187140 Vali Loss: 0.0180478 Test Loss: 0.0189054\n",
      "Validation loss decreased (0.018065 --> 0.018048).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0179772\n",
      "\tspeed: 0.0431s/iter; left time: 432.5783s\n",
      "\titers: 200, epoch: 56 | loss: 0.0185630\n",
      "\tspeed: 0.0171s/iter; left time: 170.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0189897 Vali Loss: 0.0180521 Test Loss: 0.0189287\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0185743\n",
      "\tspeed: 0.0437s/iter; left time: 428.2494s\n",
      "\titers: 200, epoch: 57 | loss: 0.0180025\n",
      "\tspeed: 0.0169s/iter; left time: 163.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0188075 Vali Loss: 0.0180966 Test Loss: 0.0189194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0188034\n",
      "\tspeed: 0.0438s/iter; left time: 419.4573s\n",
      "\titers: 200, epoch: 58 | loss: 0.0187247\n",
      "\tspeed: 0.0174s/iter; left time: 165.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0188204 Vali Loss: 0.0180457 Test Loss: 0.0189054\n",
      "Validation loss decreased (0.018048 --> 0.018046).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0192051\n",
      "\tspeed: 0.0436s/iter; left time: 407.8222s\n",
      "\titers: 200, epoch: 59 | loss: 0.0188715\n",
      "\tspeed: 0.0152s/iter; left time: 140.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0187089 Vali Loss: 0.0180814 Test Loss: 0.0189237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0189546\n",
      "\tspeed: 0.0413s/iter; left time: 377.1464s\n",
      "\titers: 200, epoch: 60 | loss: 0.0185984\n",
      "\tspeed: 0.0180s/iter; left time: 162.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0187344 Vali Loss: 0.0181039 Test Loss: 0.0189054\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0181787\n",
      "\tspeed: 0.0443s/iter; left time: 393.8750s\n",
      "\titers: 200, epoch: 61 | loss: 0.0182559\n",
      "\tspeed: 0.0164s/iter; left time: 144.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0187585 Vali Loss: 0.0180341 Test Loss: 0.0189171\n",
      "Validation loss decreased (0.018046 --> 0.018034).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0185583\n",
      "\tspeed: 0.0428s/iter; left time: 371.4303s\n",
      "\titers: 200, epoch: 62 | loss: 0.0187741\n",
      "\tspeed: 0.0184s/iter; left time: 158.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0187532 Vali Loss: 0.0180761 Test Loss: 0.0189095\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0177707\n",
      "\tspeed: 0.0457s/iter; left time: 386.6311s\n",
      "\titers: 200, epoch: 63 | loss: 0.0186384\n",
      "\tspeed: 0.0166s/iter; left time: 138.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:04.76s\n",
      "Steps: 225 | Train Loss: 0.0188340 Vali Loss: 0.0180893 Test Loss: 0.0189124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0192905\n",
      "\tspeed: 0.0433s/iter; left time: 356.1375s\n",
      "\titers: 200, epoch: 64 | loss: 0.0201995\n",
      "\tspeed: 0.0154s/iter; left time: 125.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0187623 Vali Loss: 0.0180487 Test Loss: 0.0189027\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0164961\n",
      "\tspeed: 0.0429s/iter; left time: 343.1238s\n",
      "\titers: 200, epoch: 65 | loss: 0.0189645\n",
      "\tspeed: 0.0171s/iter; left time: 135.4261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0187791 Vali Loss: 0.0180567 Test Loss: 0.0189105\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0186134\n",
      "\tspeed: 0.0441s/iter; left time: 342.9573s\n",
      "\titers: 200, epoch: 66 | loss: 0.0193064\n",
      "\tspeed: 0.0168s/iter; left time: 129.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0187621 Vali Loss: 0.0180707 Test Loss: 0.0189063\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0169868\n",
      "\tspeed: 0.0444s/iter; left time: 335.2970s\n",
      "\titers: 200, epoch: 67 | loss: 0.0187755\n",
      "\tspeed: 0.0172s/iter; left time: 127.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:04.62s\n",
      "Steps: 225 | Train Loss: 0.0187363 Vali Loss: 0.0180527 Test Loss: 0.0189101\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0205655\n",
      "\tspeed: 0.0429s/iter; left time: 314.0892s\n",
      "\titers: 200, epoch: 68 | loss: 0.0192052\n",
      "\tspeed: 0.0156s/iter; left time: 113.0725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0187399 Vali Loss: 0.0180342 Test Loss: 0.0189029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0181332\n",
      "\tspeed: 0.0467s/iter; left time: 331.9297s\n",
      "\titers: 200, epoch: 69 | loss: 0.0181357\n",
      "\tspeed: 0.0178s/iter; left time: 124.4025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.92s\n",
      "Steps: 225 | Train Loss: 0.0187259 Vali Loss: 0.0180604 Test Loss: 0.0189235\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0190984\n",
      "\tspeed: 0.0446s/iter; left time: 306.5891s\n",
      "\titers: 200, epoch: 70 | loss: 0.0191101\n",
      "\tspeed: 0.0157s/iter; left time: 106.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0187441 Vali Loss: 0.0180864 Test Loss: 0.0189139\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0190680\n",
      "\tspeed: 0.0418s/iter; left time: 277.8912s\n",
      "\titers: 200, epoch: 71 | loss: 0.0193501\n",
      "\tspeed: 0.0163s/iter; left time: 106.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0187691 Vali Loss: 0.0180732 Test Loss: 0.0188935\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : no_revin_IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.018917052075266838, rmse:0.13753926753997803, mae:0.08967844396829605, rse:0.520534098148346\n",
      "Intermediate time for IT and pred_len 168: 00h:08m:05.48s\n",
      "Intermediate time for IT: 00h:17m:32.23s\n",
      "Total time: 01h:34m:52.81s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"no_revin_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.2014</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0218  0.1477  0.0952\n",
       "        96        0.0363  0.1906  0.1306\n",
       "        168       0.0390  0.1975  0.1373\n",
       "ES      24        0.0184  0.1355  0.0841\n",
       "        96        0.0310  0.1761  0.1143\n",
       "        168       0.0329  0.1814  0.1212\n",
       "FR      24        0.0110  0.1048  0.0640\n",
       "        96        0.0194  0.1392  0.0873\n",
       "        168       0.0214  0.1465  0.0929\n",
       "GB      24        0.0266  0.1631  0.1095\n",
       "        96        0.0406  0.2014  0.1431\n",
       "        168       0.0482  0.2195  0.1556\n",
       "IT      24        0.0109  0.1042  0.0658\n",
       "        96        0.0179  0.1337  0.0860\n",
       "        168       0.0189  0.1375  0.0897"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n",
    "\n",
    "Since it converges fast, we reduced max number of epochs and patience.\n",
    "\n",
    "Complete results are in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1051457\n",
      "\tspeed: 0.1703s/iter; left time: 3781.7709s\n",
      "\titers: 200, epoch: 1 | loss: 0.0932204\n",
      "\tspeed: 0.1458s/iter; left time: 3221.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 223 | Train Loss: 0.1071621 Vali Loss: 0.1028725 Test Loss: 0.1150246\n",
      "Validation loss decreased (inf --> 0.102873).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0896473\n",
      "\tspeed: 0.2421s/iter; left time: 5320.6976s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852750\n",
      "\tspeed: 0.1465s/iter; left time: 3204.1615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0888812 Vali Loss: 0.1054194 Test Loss: 0.1180188\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0801186\n",
      "\tspeed: 0.2385s/iter; left time: 5189.3113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0752198\n",
      "\tspeed: 0.1471s/iter; left time: 3185.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 223 | Train Loss: 0.0808936 Vali Loss: 0.1088918 Test Loss: 0.1218244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764754\n",
      "\tspeed: 0.2386s/iter; left time: 5136.7827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0668249\n",
      "\tspeed: 0.1475s/iter; left time: 3162.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 223 | Train Loss: 0.0712032 Vali Loss: 0.1164811 Test Loss: 0.1314963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0584339\n",
      "\tspeed: 0.2388s/iter; left time: 5087.6700s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615544\n",
      "\tspeed: 0.1467s/iter; left time: 3111.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 223 | Train Loss: 0.0614232 Vali Loss: 0.1146671 Test Loss: 0.1260481\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0533759\n",
      "\tspeed: 0.2367s/iter; left time: 4990.1201s\n",
      "\titers: 200, epoch: 6 | loss: 0.0495681\n",
      "\tspeed: 0.1466s/iter; left time: 3077.0692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0537273 Vali Loss: 0.1115397 Test Loss: 0.1244299\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0473040\n",
      "\tspeed: 0.2379s/iter; left time: 4962.2669s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490480\n",
      "\tspeed: 0.1467s/iter; left time: 3046.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 223 | Train Loss: 0.0485017 Vali Loss: 0.1118774 Test Loss: 0.1266170\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0428582\n",
      "\tspeed: 0.2373s/iter; left time: 4897.0955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0423327\n",
      "\tspeed: 0.1464s/iter; left time: 3006.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 223 | Train Loss: 0.0436265 Vali Loss: 0.1113263 Test Loss: 0.1248961\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409019\n",
      "\tspeed: 0.2371s/iter; left time: 4841.5272s\n",
      "\titers: 200, epoch: 9 | loss: 0.0388029\n",
      "\tspeed: 0.1463s/iter; left time: 2971.7896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.73s\n",
      "Steps: 223 | Train Loss: 0.0416113 Vali Loss: 0.1129987 Test Loss: 0.1294562\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0386123\n",
      "\tspeed: 0.2363s/iter; left time: 4771.1943s\n",
      "\titers: 200, epoch: 10 | loss: 0.0380670\n",
      "\tspeed: 0.1463s/iter; left time: 2940.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0399942 Vali Loss: 0.1123616 Test Loss: 0.1261321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0382017\n",
      "\tspeed: 0.2373s/iter; left time: 4739.1549s\n",
      "\titers: 200, epoch: 11 | loss: 0.0367740\n",
      "\tspeed: 0.1463s/iter; left time: 2906.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0381936 Vali Loss: 0.1106567 Test Loss: 0.1257289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028743868693709373, rmse:0.1695401668548584, mae:0.11502459645271301, rse:0.5848655104637146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1056844\n",
      "\tspeed: 0.1474s/iter; left time: 3273.2981s\n",
      "\titers: 200, epoch: 1 | loss: 0.0887723\n",
      "\tspeed: 0.1462s/iter; left time: 3231.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 223 | Train Loss: 0.1076930 Vali Loss: 0.1034200 Test Loss: 0.1157358\n",
      "Validation loss decreased (inf --> 0.103420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871905\n",
      "\tspeed: 0.2427s/iter; left time: 5333.6320s\n",
      "\titers: 200, epoch: 2 | loss: 0.0820583\n",
      "\tspeed: 0.1465s/iter; left time: 3205.9718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0888926 Vali Loss: 0.1046297 Test Loss: 0.1171767\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0843876\n",
      "\tspeed: 0.2379s/iter; left time: 5175.5638s\n",
      "\titers: 200, epoch: 3 | loss: 0.0818222\n",
      "\tspeed: 0.1464s/iter; left time: 3169.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 223 | Train Loss: 0.0815588 Vali Loss: 0.1086011 Test Loss: 0.1196759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0724633\n",
      "\tspeed: 0.2380s/iter; left time: 5125.0562s\n",
      "\titers: 200, epoch: 4 | loss: 0.0665326\n",
      "\tspeed: 0.1466s/iter; left time: 3142.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 223 | Train Loss: 0.0715411 Vali Loss: 0.1171121 Test Loss: 0.1247998\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0588575\n",
      "\tspeed: 0.2378s/iter; left time: 5066.5772s\n",
      "\titers: 200, epoch: 5 | loss: 0.0584292\n",
      "\tspeed: 0.1465s/iter; left time: 3107.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0616918 Vali Loss: 0.1111074 Test Loss: 0.1225118\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505120\n",
      "\tspeed: 0.2374s/iter; left time: 5005.2128s\n",
      "\titers: 200, epoch: 6 | loss: 0.0511305\n",
      "\tspeed: 0.1461s/iter; left time: 3066.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0532696 Vali Loss: 0.1103224 Test Loss: 0.1216622\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0483326\n",
      "\tspeed: 0.2370s/iter; left time: 4944.9578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0455461\n",
      "\tspeed: 0.1462s/iter; left time: 3035.8085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.74s\n",
      "Steps: 223 | Train Loss: 0.0479013 Vali Loss: 0.1107165 Test Loss: 0.1228329\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0439964\n",
      "\tspeed: 0.2375s/iter; left time: 4902.2376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449820\n",
      "\tspeed: 0.1463s/iter; left time: 3004.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.75s\n",
      "Steps: 223 | Train Loss: 0.0444204 Vali Loss: 0.1109379 Test Loss: 0.1237228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418664\n",
      "\tspeed: 0.2376s/iter; left time: 4851.4845s\n",
      "\titers: 200, epoch: 9 | loss: 0.0413343\n",
      "\tspeed: 0.1464s/iter; left time: 2974.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0413205 Vali Loss: 0.1107434 Test Loss: 0.1236369\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0371369\n",
      "\tspeed: 0.2377s/iter; left time: 4800.6975s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389452\n",
      "\tspeed: 0.1463s/iter; left time: 2938.9695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 223 | Train Loss: 0.0396608 Vali Loss: 0.1118143 Test Loss: 0.1250867\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0370215\n",
      "\tspeed: 0.2380s/iter; left time: 4752.2605s\n",
      "\titers: 200, epoch: 11 | loss: 0.0395964\n",
      "\tspeed: 0.1465s/iter; left time: 2910.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 223 | Train Loss: 0.0381358 Vali Loss: 0.1105671 Test Loss: 0.1246427\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.029005983844399452, rmse:0.17031143605709076, mae:0.11573578417301178, rse:0.5875261425971985\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:21.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1156728\n",
      "\tspeed: 0.1709s/iter; left time: 3777.5477s\n",
      "\titers: 200, epoch: 1 | loss: 0.1047598\n",
      "\tspeed: 0.1498s/iter; left time: 3295.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.44s\n",
      "Steps: 222 | Train Loss: 0.1199832 Vali Loss: 0.1229378 Test Loss: 0.1452433\n",
      "Validation loss decreased (inf --> 0.122938).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1146321\n",
      "\tspeed: 0.2501s/iter; left time: 5472.0933s\n",
      "\titers: 200, epoch: 2 | loss: 0.0956471\n",
      "\tspeed: 0.1487s/iter; left time: 3238.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.31s\n",
      "Steps: 222 | Train Loss: 0.1067851 Vali Loss: 0.1402225 Test Loss: 0.1606241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0768545\n",
      "\tspeed: 0.2397s/iter; left time: 5190.7345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670673\n",
      "\tspeed: 0.1484s/iter; left time: 3198.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0784635 Vali Loss: 0.1549436 Test Loss: 0.1626762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615202\n",
      "\tspeed: 0.2398s/iter; left time: 5139.7258s\n",
      "\titers: 200, epoch: 4 | loss: 0.0553973\n",
      "\tspeed: 0.1484s/iter; left time: 3166.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0621905 Vali Loss: 0.1486871 Test Loss: 0.1585362\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0881757\n",
      "\tspeed: 0.2398s/iter; left time: 5086.7055s\n",
      "\titers: 200, epoch: 5 | loss: 0.0501511\n",
      "\tspeed: 0.1487s/iter; left time: 3139.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.12s\n",
      "Steps: 222 | Train Loss: 0.0527247 Vali Loss: 0.1394723 Test Loss: 0.1576203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0477496\n",
      "\tspeed: 0.2399s/iter; left time: 5035.0269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0474090\n",
      "\tspeed: 0.1484s/iter; left time: 3101.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.11s\n",
      "Steps: 222 | Train Loss: 0.0484712 Vali Loss: 0.1370355 Test Loss: 0.1556998\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412586\n",
      "\tspeed: 0.2400s/iter; left time: 4983.5867s\n",
      "\titers: 200, epoch: 7 | loss: 0.0407524\n",
      "\tspeed: 0.1485s/iter; left time: 3069.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0431573 Vali Loss: 0.1348506 Test Loss: 0.1544424\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0423980\n",
      "\tspeed: 0.2402s/iter; left time: 4935.6244s\n",
      "\titers: 200, epoch: 8 | loss: 0.0422410\n",
      "\tspeed: 0.1487s/iter; left time: 3039.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0418209 Vali Loss: 0.1379111 Test Loss: 0.1536960\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0395810\n",
      "\tspeed: 0.2392s/iter; left time: 4861.3254s\n",
      "\titers: 200, epoch: 9 | loss: 0.0401174\n",
      "\tspeed: 0.1485s/iter; left time: 3003.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.08s\n",
      "Steps: 222 | Train Loss: 0.0393178 Vali Loss: 0.1330695 Test Loss: 0.1526520\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0376254\n",
      "\tspeed: 0.2403s/iter; left time: 4830.8311s\n",
      "\titers: 200, epoch: 10 | loss: 0.0342666\n",
      "\tspeed: 0.1487s/iter; left time: 2974.0619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0370651 Vali Loss: 0.1324363 Test Loss: 0.1522708\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0352456\n",
      "\tspeed: 0.2408s/iter; left time: 4787.1133s\n",
      "\titers: 200, epoch: 11 | loss: 0.0371032\n",
      "\tspeed: 0.1487s/iter; left time: 2940.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.19s\n",
      "Steps: 222 | Train Loss: 0.0362890 Vali Loss: 0.1320634 Test Loss: 0.1527143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04341920092701912, rmse:0.20837274193763733, mae:0.1452433168888092, rse:0.7205820083618164\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1165444\n",
      "\tspeed: 0.1494s/iter; left time: 3302.5688s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111383\n",
      "\tspeed: 0.1485s/iter; left time: 3267.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.1201055 Vali Loss: 0.1230098 Test Loss: 0.1451796\n",
      "Validation loss decreased (inf --> 0.123010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108082\n",
      "\tspeed: 0.2554s/iter; left time: 5588.7955s\n",
      "\titers: 200, epoch: 2 | loss: 0.0935105\n",
      "\tspeed: 0.1486s/iter; left time: 3235.8232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 222 | Train Loss: 0.1068995 Vali Loss: 0.1398159 Test Loss: 0.1669322\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0784802\n",
      "\tspeed: 0.2413s/iter; left time: 5226.1157s\n",
      "\titers: 200, epoch: 3 | loss: 0.0735279\n",
      "\tspeed: 0.1487s/iter; left time: 3206.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.20s\n",
      "Steps: 222 | Train Loss: 0.0795587 Vali Loss: 0.1421815 Test Loss: 0.1656734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637211\n",
      "\tspeed: 0.2420s/iter; left time: 5186.7990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0617426\n",
      "\tspeed: 0.1487s/iter; left time: 3171.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0648935 Vali Loss: 0.1376564 Test Loss: 0.1604086\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0552284\n",
      "\tspeed: 0.2417s/iter; left time: 5127.4756s\n",
      "\titers: 200, epoch: 5 | loss: 0.0531027\n",
      "\tspeed: 0.1486s/iter; left time: 3137.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.17s\n",
      "Steps: 222 | Train Loss: 0.0553986 Vali Loss: 0.1340457 Test Loss: 0.1575819\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0478428\n",
      "\tspeed: 0.2412s/iter; left time: 5063.8890s\n",
      "\titers: 200, epoch: 6 | loss: 0.0523911\n",
      "\tspeed: 0.1486s/iter; left time: 3103.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0490555 Vali Loss: 0.1340929 Test Loss: 0.1550300\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459050\n",
      "\tspeed: 0.2413s/iter; left time: 5011.3346s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428679\n",
      "\tspeed: 0.1485s/iter; left time: 3069.9799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0447298 Vali Loss: 0.1341426 Test Loss: 0.1539580\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405288\n",
      "\tspeed: 0.2414s/iter; left time: 4960.5656s\n",
      "\titers: 200, epoch: 8 | loss: 0.0405174\n",
      "\tspeed: 0.1482s/iter; left time: 3030.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0419976 Vali Loss: 0.1378684 Test Loss: 0.1581065\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0382658\n",
      "\tspeed: 0.2406s/iter; left time: 4891.0947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0395453\n",
      "\tspeed: 0.1486s/iter; left time: 3005.1565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 222 | Train Loss: 0.0404064 Vali Loss: 0.1317059 Test Loss: 0.1522986\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0378837\n",
      "\tspeed: 0.2412s/iter; left time: 4848.7059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0369272\n",
      "\tspeed: 0.1485s/iter; left time: 2970.4434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 222 | Train Loss: 0.0381774 Vali Loss: 0.1314865 Test Loss: 0.1513584\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0358450\n",
      "\tspeed: 0.2409s/iter; left time: 4789.2445s\n",
      "\titers: 200, epoch: 11 | loss: 0.0374405\n",
      "\tspeed: 0.1488s/iter; left time: 2943.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.15s\n",
      "Steps: 222 | Train Loss: 0.0363881 Vali Loss: 0.1307979 Test Loss: 0.1516058\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04355882108211517, rmse:0.20870749652385712, mae:0.1451796293258667, rse:0.7217395901679993\n",
      "Intermediate time for GB and pred_len 96: 00h:14m:36.03s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1177407\n",
      "\tspeed: 0.1745s/iter; left time: 3857.2506s\n",
      "\titers: 200, epoch: 1 | loss: 0.1147017\n",
      "\tspeed: 0.1503s/iter; left time: 3306.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.78s\n",
      "Steps: 222 | Train Loss: 0.1225829 Vali Loss: 0.1266081 Test Loss: 0.1497908\n",
      "Validation loss decreased (inf --> 0.126608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1123300\n",
      "\tspeed: 0.2887s/iter; left time: 6315.4126s\n",
      "\titers: 200, epoch: 2 | loss: 0.0922024\n",
      "\tspeed: 0.1506s/iter; left time: 3280.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.1073465 Vali Loss: 0.1534391 Test Loss: 0.1633927\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0715112\n",
      "\tspeed: 0.2422s/iter; left time: 5244.5989s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678034\n",
      "\tspeed: 0.1507s/iter; left time: 3249.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.0751841 Vali Loss: 0.1467895 Test Loss: 0.1613366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0583339\n",
      "\tspeed: 0.2417s/iter; left time: 5180.5349s\n",
      "\titers: 200, epoch: 4 | loss: 0.0547504\n",
      "\tspeed: 0.1506s/iter; left time: 3213.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0591856 Vali Loss: 0.1385507 Test Loss: 0.1562234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0566366\n",
      "\tspeed: 0.2418s/iter; left time: 5129.7138s\n",
      "\titers: 200, epoch: 5 | loss: 0.0517352\n",
      "\tspeed: 0.1507s/iter; left time: 3182.7699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.61s\n",
      "Steps: 222 | Train Loss: 0.0521256 Vali Loss: 0.1398461 Test Loss: 0.1579931\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0485455\n",
      "\tspeed: 0.2414s/iter; left time: 5066.7254s\n",
      "\titers: 200, epoch: 6 | loss: 0.0483025\n",
      "\tspeed: 0.1508s/iter; left time: 3149.5819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0479918 Vali Loss: 0.1388285 Test Loss: 0.1559225\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412977\n",
      "\tspeed: 0.2417s/iter; left time: 5019.4109s\n",
      "\titers: 200, epoch: 7 | loss: 0.0430455\n",
      "\tspeed: 0.1509s/iter; left time: 3118.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0437611 Vali Loss: 0.1360448 Test Loss: 0.1562288\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0412615\n",
      "\tspeed: 0.2412s/iter; left time: 4956.3507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0435497\n",
      "\tspeed: 0.1508s/iter; left time: 3084.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0422933 Vali Loss: 0.1364408 Test Loss: 0.1566917\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0399560\n",
      "\tspeed: 0.2421s/iter; left time: 4920.5603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0365216\n",
      "\tspeed: 0.1508s/iter; left time: 3049.0123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.62s\n",
      "Steps: 222 | Train Loss: 0.0392865 Vali Loss: 0.1353271 Test Loss: 0.1550491\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0372904\n",
      "\tspeed: 0.2423s/iter; left time: 4869.9806s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402687\n",
      "\tspeed: 0.1511s/iter; left time: 3022.6342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.69s\n",
      "Steps: 222 | Train Loss: 0.0405217 Vali Loss: 0.1355167 Test Loss: 0.1553616\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355937\n",
      "\tspeed: 0.2413s/iter; left time: 4797.8155s\n",
      "\titers: 200, epoch: 11 | loss: 0.0380037\n",
      "\tspeed: 0.1509s/iter; left time: 2984.6356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 222 | Train Loss: 0.0374547 Vali Loss: 0.1346184 Test Loss: 0.1547808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045506544411182404, rmse:0.21332262456417084, mae:0.14979074895381927, rse:0.7396202087402344\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1164795\n",
      "\tspeed: 0.1520s/iter; left time: 3360.0338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1178308\n",
      "\tspeed: 0.1507s/iter; left time: 3315.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.64s\n",
      "Steps: 222 | Train Loss: 0.1227937 Vali Loss: 0.1269568 Test Loss: 0.1500853\n",
      "Validation loss decreased (inf --> 0.126957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1080633\n",
      "\tspeed: 0.2832s/iter; left time: 6196.1052s\n",
      "\titers: 200, epoch: 2 | loss: 0.0911027\n",
      "\tspeed: 0.1506s/iter; left time: 3279.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.63s\n",
      "Steps: 222 | Train Loss: 0.1069387 Vali Loss: 0.1472872 Test Loss: 0.1704258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0766009\n",
      "\tspeed: 0.2439s/iter; left time: 5282.7984s\n",
      "\titers: 200, epoch: 3 | loss: 0.0693914\n",
      "\tspeed: 0.1509s/iter; left time: 3253.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.70s\n",
      "Steps: 222 | Train Loss: 0.0753113 Vali Loss: 0.1423926 Test Loss: 0.1651071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579466\n",
      "\tspeed: 0.2448s/iter; left time: 5246.9351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602810\n",
      "\tspeed: 0.1509s/iter; left time: 3220.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0602860 Vali Loss: 0.1388860 Test Loss: 0.1613450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0529091\n",
      "\tspeed: 0.2440s/iter; left time: 5175.5351s\n",
      "\titers: 200, epoch: 5 | loss: 0.0478933\n",
      "\tspeed: 0.1510s/iter; left time: 3188.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0532050 Vali Loss: 0.1397931 Test Loss: 0.1621394\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488900\n",
      "\tspeed: 0.2441s/iter; left time: 5124.3289s\n",
      "\titers: 200, epoch: 6 | loss: 0.0479902\n",
      "\tspeed: 0.1508s/iter; left time: 3151.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0490049 Vali Loss: 0.1387042 Test Loss: 0.1603853\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0458506\n",
      "\tspeed: 0.2432s/iter; left time: 5051.5493s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413319\n",
      "\tspeed: 0.1508s/iter; left time: 3117.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0447227 Vali Loss: 0.1376807 Test Loss: 0.1579818\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406756\n",
      "\tspeed: 0.2439s/iter; left time: 5010.5233s\n",
      "\titers: 200, epoch: 8 | loss: 0.0401300\n",
      "\tspeed: 0.1510s/iter; left time: 3086.5883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0428238 Vali Loss: 0.1362697 Test Loss: 0.1593084\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0425120\n",
      "\tspeed: 0.2438s/iter; left time: 4955.0447s\n",
      "\titers: 200, epoch: 9 | loss: 0.0428176\n",
      "\tspeed: 0.1510s/iter; left time: 3053.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:33.67s\n",
      "Steps: 222 | Train Loss: 0.0406100 Vali Loss: 0.1351584 Test Loss: 0.1575931\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0391058\n",
      "\tspeed: 0.2447s/iter; left time: 4919.7646s\n",
      "\titers: 200, epoch: 10 | loss: 0.0359502\n",
      "\tspeed: 0.1509s/iter; left time: 3018.1160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.66s\n",
      "Steps: 222 | Train Loss: 0.0388262 Vali Loss: 0.1357430 Test Loss: 0.1580252\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0361103\n",
      "\tspeed: 0.2442s/iter; left time: 4854.2990s\n",
      "\titers: 200, epoch: 11 | loss: 0.0373988\n",
      "\tspeed: 0.1510s/iter; left time: 2987.8669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.68s\n",
      "Steps: 222 | Train Loss: 0.0368991 Vali Loss: 0.1348735 Test Loss: 0.1577474\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045674242079257965, rmse:0.2137153297662735, mae:0.15008527040481567, rse:0.7409817576408386\n",
      "Intermediate time for GB and pred_len 168: 00h:14m:55.51s\n",
      "Intermediate time for GB: 00h:43m:52.56s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1083394\n",
      "\tspeed: 0.0573s/iter; left time: 1277.9257s\n",
      "\titers: 200, epoch: 1 | loss: 0.0949330\n",
      "\tspeed: 0.0326s/iter; left time: 723.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.1146521 Vali Loss: 0.0854233 Test Loss: 0.0978887\n",
      "Validation loss decreased (inf --> 0.085423).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0694569\n",
      "\tspeed: 0.0622s/iter; left time: 1372.0866s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682702\n",
      "\tspeed: 0.0326s/iter; left time: 715.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0716935 Vali Loss: 0.0656114 Test Loss: 0.0731752\n",
      "Validation loss decreased (0.085423 --> 0.065611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638887\n",
      "\tspeed: 0.0622s/iter; left time: 1358.9573s\n",
      "\titers: 200, epoch: 3 | loss: 0.0625745\n",
      "\tspeed: 0.0326s/iter; left time: 709.3744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0642866 Vali Loss: 0.0630241 Test Loss: 0.0710565\n",
      "Validation loss decreased (0.065611 --> 0.063024).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611238\n",
      "\tspeed: 0.0620s/iter; left time: 1340.0211s\n",
      "\titers: 200, epoch: 4 | loss: 0.0643910\n",
      "\tspeed: 0.0325s/iter; left time: 699.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0619596 Vali Loss: 0.0643963 Test Loss: 0.0716253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0614629\n",
      "\tspeed: 0.0593s/iter; left time: 1268.8093s\n",
      "\titers: 200, epoch: 5 | loss: 0.0591143\n",
      "\tspeed: 0.0325s/iter; left time: 692.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 224 | Train Loss: 0.0598301 Vali Loss: 0.0612322 Test Loss: 0.0694189\n",
      "Validation loss decreased (0.063024 --> 0.061232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568408\n",
      "\tspeed: 0.0610s/iter; left time: 1292.2982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0567278\n",
      "\tspeed: 0.0325s/iter; left time: 685.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0577446 Vali Loss: 0.0609693 Test Loss: 0.0682407\n",
      "Validation loss decreased (0.061232 --> 0.060969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562621\n",
      "\tspeed: 0.0612s/iter; left time: 1282.4153s\n",
      "\titers: 200, epoch: 7 | loss: 0.0554868\n",
      "\tspeed: 0.0325s/iter; left time: 678.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0561681 Vali Loss: 0.0597783 Test Loss: 0.0675127\n",
      "Validation loss decreased (0.060969 --> 0.059778).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569908\n",
      "\tspeed: 0.0611s/iter; left time: 1266.2956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577169\n",
      "\tspeed: 0.0325s/iter; left time: 671.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0544420 Vali Loss: 0.0602443 Test Loss: 0.0683316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521781\n",
      "\tspeed: 0.0602s/iter; left time: 1235.5452s\n",
      "\titers: 200, epoch: 9 | loss: 0.0503141\n",
      "\tspeed: 0.0327s/iter; left time: 667.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0526811 Vali Loss: 0.0609316 Test Loss: 0.0681847\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519583\n",
      "\tspeed: 0.0596s/iter; left time: 1208.3835s\n",
      "\titers: 200, epoch: 10 | loss: 0.0487051\n",
      "\tspeed: 0.0329s/iter; left time: 664.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0512578 Vali Loss: 0.0613501 Test Loss: 0.0695660\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517822\n",
      "\tspeed: 0.0598s/iter; left time: 1200.4242s\n",
      "\titers: 200, epoch: 11 | loss: 0.0482223\n",
      "\tspeed: 0.0327s/iter; left time: 652.0808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0498223 Vali Loss: 0.0620379 Test Loss: 0.0702392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494305\n",
      "\tspeed: 0.0599s/iter; left time: 1188.9516s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481998\n",
      "\tspeed: 0.0327s/iter; left time: 645.6828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0483653 Vali Loss: 0.0612045 Test Loss: 0.0701841\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0462038\n",
      "\tspeed: 0.0607s/iter; left time: 1190.1800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461890\n",
      "\tspeed: 0.0328s/iter; left time: 639.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.0470476 Vali Loss: 0.0618377 Test Loss: 0.0701277\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0474969\n",
      "\tspeed: 0.0600s/iter; left time: 1164.1216s\n",
      "\titers: 200, epoch: 14 | loss: 0.0462358\n",
      "\tspeed: 0.0327s/iter; left time: 631.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0460021 Vali Loss: 0.0619138 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441642\n",
      "\tspeed: 0.0601s/iter; left time: 1152.4789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437523\n",
      "\tspeed: 0.0327s/iter; left time: 623.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.52s\n",
      "Steps: 224 | Train Loss: 0.0449358 Vali Loss: 0.0615214 Test Loss: 0.0704811\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440189\n",
      "\tspeed: 0.0606s/iter; left time: 1146.9950s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432764\n",
      "\tspeed: 0.0328s/iter; left time: 618.5290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0439870 Vali Loss: 0.0616211 Test Loss: 0.0707664\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423084\n",
      "\tspeed: 0.0598s/iter; left time: 1118.4282s\n",
      "\titers: 200, epoch: 17 | loss: 0.0415025\n",
      "\tspeed: 0.0328s/iter; left time: 610.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0431494 Vali Loss: 0.0620262 Test Loss: 0.0715410\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01133799646049738, rmse:0.10648002475500107, mae:0.06751272827386856, rse:0.3133578300476074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1059176\n",
      "\tspeed: 0.0346s/iter; left time: 772.7058s\n",
      "\titers: 200, epoch: 1 | loss: 0.0954594\n",
      "\tspeed: 0.0327s/iter; left time: 726.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 224 | Train Loss: 0.1132807 Vali Loss: 0.0858611 Test Loss: 0.0978220\n",
      "Validation loss decreased (inf --> 0.085861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0672946\n",
      "\tspeed: 0.0635s/iter; left time: 1401.7909s\n",
      "\titers: 200, epoch: 2 | loss: 0.0662497\n",
      "\tspeed: 0.0326s/iter; left time: 715.6569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 224 | Train Loss: 0.0716624 Vali Loss: 0.0645302 Test Loss: 0.0728868\n",
      "Validation loss decreased (0.085861 --> 0.064530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636461\n",
      "\tspeed: 0.0619s/iter; left time: 1352.4904s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644167\n",
      "\tspeed: 0.0328s/iter; left time: 712.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0639991 Vali Loss: 0.0630432 Test Loss: 0.0709006\n",
      "Validation loss decreased (0.064530 --> 0.063043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0621769\n",
      "\tspeed: 0.0621s/iter; left time: 1342.1702s\n",
      "\titers: 200, epoch: 4 | loss: 0.0600844\n",
      "\tspeed: 0.0326s/iter; left time: 701.0833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 224 | Train Loss: 0.0615069 Vali Loss: 0.0610647 Test Loss: 0.0695123\n",
      "Validation loss decreased (0.063043 --> 0.061065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0606961\n",
      "\tspeed: 0.0630s/iter; left time: 1348.5926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597096\n",
      "\tspeed: 0.0327s/iter; left time: 696.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0594661 Vali Loss: 0.0604619 Test Loss: 0.0694347\n",
      "Validation loss decreased (0.061065 --> 0.060462).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590119\n",
      "\tspeed: 0.0623s/iter; left time: 1319.7344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0569254\n",
      "\tspeed: 0.0327s/iter; left time: 690.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.59s\n",
      "Steps: 224 | Train Loss: 0.0579130 Vali Loss: 0.0610369 Test Loss: 0.0684163\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0548901\n",
      "\tspeed: 0.0603s/iter; left time: 1263.4103s\n",
      "\titers: 200, epoch: 7 | loss: 0.0539524\n",
      "\tspeed: 0.0327s/iter; left time: 680.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0559329 Vali Loss: 0.0594218 Test Loss: 0.0678336\n",
      "Validation loss decreased (0.060462 --> 0.059422).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0538018\n",
      "\tspeed: 0.0648s/iter; left time: 1344.4634s\n",
      "\titers: 200, epoch: 8 | loss: 0.0530818\n",
      "\tspeed: 0.0325s/iter; left time: 671.3128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0542583 Vali Loss: 0.0599612 Test Loss: 0.0689581\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552536\n",
      "\tspeed: 0.0601s/iter; left time: 1232.8386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516640\n",
      "\tspeed: 0.0325s/iter; left time: 663.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 224 | Train Loss: 0.0527426 Vali Loss: 0.0591997 Test Loss: 0.0679362\n",
      "Validation loss decreased (0.059422 --> 0.059200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536080\n",
      "\tspeed: 0.0617s/iter; left time: 1251.9853s\n",
      "\titers: 200, epoch: 10 | loss: 0.0499571\n",
      "\tspeed: 0.0325s/iter; left time: 656.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0512842 Vali Loss: 0.0599653 Test Loss: 0.0687808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0517187\n",
      "\tspeed: 0.0604s/iter; left time: 1210.6819s\n",
      "\titers: 200, epoch: 11 | loss: 0.0499973\n",
      "\tspeed: 0.0326s/iter; left time: 651.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 224 | Train Loss: 0.0497935 Vali Loss: 0.0604572 Test Loss: 0.0696274\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468627\n",
      "\tspeed: 0.0595s/iter; left time: 1181.2420s\n",
      "\titers: 200, epoch: 12 | loss: 0.0489540\n",
      "\tspeed: 0.0328s/iter; left time: 648.2592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0483913 Vali Loss: 0.0602030 Test Loss: 0.0697745\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0496078\n",
      "\tspeed: 0.0598s/iter; left time: 1172.5827s\n",
      "\titers: 200, epoch: 13 | loss: 0.0476634\n",
      "\tspeed: 0.0323s/iter; left time: 630.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0473625 Vali Loss: 0.0604081 Test Loss: 0.0700828\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464205\n",
      "\tspeed: 0.0594s/iter; left time: 1152.2500s\n",
      "\titers: 200, epoch: 14 | loss: 0.0435993\n",
      "\tspeed: 0.0323s/iter; left time: 623.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0461338 Vali Loss: 0.0605141 Test Loss: 0.0701649\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0460268\n",
      "\tspeed: 0.0599s/iter; left time: 1147.0383s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453027\n",
      "\tspeed: 0.0323s/iter; left time: 616.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0451875 Vali Loss: 0.0609419 Test Loss: 0.0697475\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0459039\n",
      "\tspeed: 0.0604s/iter; left time: 1143.9558s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434766\n",
      "\tspeed: 0.0326s/iter; left time: 614.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0443061 Vali Loss: 0.0615374 Test Loss: 0.0706668\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0443573\n",
      "\tspeed: 0.0599s/iter; left time: 1122.0651s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425250\n",
      "\tspeed: 0.0324s/iter; left time: 603.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0435606 Vali Loss: 0.0604851 Test Loss: 0.0707585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0413324\n",
      "\tspeed: 0.0602s/iter; left time: 1113.7053s\n",
      "\titers: 200, epoch: 18 | loss: 0.0445203\n",
      "\tspeed: 0.0325s/iter; left time: 598.5775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0428060 Vali Loss: 0.0611732 Test Loss: 0.0707645\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0436631\n",
      "\tspeed: 0.0596s/iter; left time: 1088.8430s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429139\n",
      "\tspeed: 0.0325s/iter; left time: 591.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 224 | Train Loss: 0.0421968 Vali Loss: 0.0612346 Test Loss: 0.0706914\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011598608456552029, rmse:0.10769683867692947, mae:0.06793618202209473, rse:0.31693875789642334\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:48.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1167209\n",
      "\tspeed: 0.0581s/iter; left time: 1296.1155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1056875\n",
      "\tspeed: 0.0331s/iter; left time: 735.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.1227398 Vali Loss: 0.0988195 Test Loss: 0.1124716\n",
      "Validation loss decreased (inf --> 0.098819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888136\n",
      "\tspeed: 0.0650s/iter; left time: 1434.6344s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841860\n",
      "\tspeed: 0.0332s/iter; left time: 730.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0888445 Vali Loss: 0.0866662 Test Loss: 0.0969930\n",
      "Validation loss decreased (0.098819 --> 0.086666).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807913\n",
      "\tspeed: 0.0628s/iter; left time: 1372.0226s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785247\n",
      "\tspeed: 0.0331s/iter; left time: 720.1775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0809936 Vali Loss: 0.0850435 Test Loss: 0.0962780\n",
      "Validation loss decreased (0.086666 --> 0.085044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0752124\n",
      "\tspeed: 0.0652s/iter; left time: 1409.4935s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712232\n",
      "\tspeed: 0.0332s/iter; left time: 714.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0751077 Vali Loss: 0.0873182 Test Loss: 0.0995040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689497\n",
      "\tspeed: 0.0621s/iter; left time: 1328.1937s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683093\n",
      "\tspeed: 0.0332s/iter; left time: 707.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.71s\n",
      "Steps: 224 | Train Loss: 0.0684474 Vali Loss: 0.0864051 Test Loss: 0.1003118\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626845\n",
      "\tspeed: 0.0614s/iter; left time: 1300.7891s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603980\n",
      "\tspeed: 0.0331s/iter; left time: 698.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0631113 Vali Loss: 0.0877236 Test Loss: 0.1011920\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590933\n",
      "\tspeed: 0.0609s/iter; left time: 1275.9670s\n",
      "\titers: 200, epoch: 7 | loss: 0.0597084\n",
      "\tspeed: 0.0331s/iter; left time: 690.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0589081 Vali Loss: 0.0872310 Test Loss: 0.1004953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0552450\n",
      "\tspeed: 0.0611s/iter; left time: 1265.8009s\n",
      "\titers: 200, epoch: 8 | loss: 0.0551953\n",
      "\tspeed: 0.0331s/iter; left time: 683.5963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0555059 Vali Loss: 0.0881087 Test Loss: 0.1008888\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0524991\n",
      "\tspeed: 0.0613s/iter; left time: 1257.9821s\n",
      "\titers: 200, epoch: 9 | loss: 0.0530768\n",
      "\tspeed: 0.0332s/iter; left time: 677.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0527471 Vali Loss: 0.0886423 Test Loss: 0.1020612\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515361\n",
      "\tspeed: 0.0615s/iter; left time: 1248.0465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495522\n",
      "\tspeed: 0.0333s/iter; left time: 672.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0506641 Vali Loss: 0.0878667 Test Loss: 0.1018857\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0495449\n",
      "\tspeed: 0.0622s/iter; left time: 1247.0062s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484085\n",
      "\tspeed: 0.0335s/iter; left time: 668.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0487303 Vali Loss: 0.0874963 Test Loss: 0.1018826\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460823\n",
      "\tspeed: 0.0613s/iter; left time: 1215.3686s\n",
      "\titers: 200, epoch: 12 | loss: 0.0487627\n",
      "\tspeed: 0.0331s/iter; left time: 653.6800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0472277 Vali Loss: 0.0875905 Test Loss: 0.1023017\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0471489\n",
      "\tspeed: 0.0612s/iter; left time: 1201.1524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0454935\n",
      "\tspeed: 0.0331s/iter; left time: 645.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0459133 Vali Loss: 0.0874007 Test Loss: 0.1019594\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021271303296089172, rmse:0.14584684371948242, mae:0.09627804905176163, rse:0.4284541606903076\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204117\n",
      "\tspeed: 0.0347s/iter; left time: 773.2841s\n",
      "\titers: 200, epoch: 1 | loss: 0.1046546\n",
      "\tspeed: 0.0330s/iter; left time: 733.2609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.1222082 Vali Loss: 0.0986339 Test Loss: 0.1127096\n",
      "Validation loss decreased (inf --> 0.098634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892475\n",
      "\tspeed: 0.0637s/iter; left time: 1405.5402s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875973\n",
      "\tspeed: 0.0331s/iter; left time: 727.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0889160 Vali Loss: 0.0860521 Test Loss: 0.0965959\n",
      "Validation loss decreased (0.098634 --> 0.086052).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820314\n",
      "\tspeed: 0.0746s/iter; left time: 1629.4846s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766245\n",
      "\tspeed: 0.0331s/iter; left time: 720.1125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 224 | Train Loss: 0.0810734 Vali Loss: 0.0846253 Test Loss: 0.0976963\n",
      "Validation loss decreased (0.086052 --> 0.084625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731675\n",
      "\tspeed: 0.0660s/iter; left time: 1426.5197s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741658\n",
      "\tspeed: 0.0335s/iter; left time: 721.5715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0754243 Vali Loss: 0.0878123 Test Loss: 0.1005267\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0716164\n",
      "\tspeed: 0.0616s/iter; left time: 1317.6022s\n",
      "\titers: 200, epoch: 5 | loss: 0.0671426\n",
      "\tspeed: 0.0331s/iter; left time: 705.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0690027 Vali Loss: 0.0878285 Test Loss: 0.1006422\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641997\n",
      "\tspeed: 0.0612s/iter; left time: 1295.4053s\n",
      "\titers: 200, epoch: 6 | loss: 0.0674796\n",
      "\tspeed: 0.0331s/iter; left time: 697.8527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0635019 Vali Loss: 0.0878592 Test Loss: 0.1024417\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591606\n",
      "\tspeed: 0.0615s/iter; left time: 1288.8847s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583029\n",
      "\tspeed: 0.0331s/iter; left time: 691.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0588996 Vali Loss: 0.0877868 Test Loss: 0.1020480\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553827\n",
      "\tspeed: 0.0614s/iter; left time: 1272.8050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554482\n",
      "\tspeed: 0.0332s/iter; left time: 684.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0554791 Vali Loss: 0.0881074 Test Loss: 0.1035934\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0541625\n",
      "\tspeed: 0.0616s/iter; left time: 1263.4282s\n",
      "\titers: 200, epoch: 9 | loss: 0.0502246\n",
      "\tspeed: 0.0332s/iter; left time: 676.8140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0527017 Vali Loss: 0.0881722 Test Loss: 0.1024241\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0498284\n",
      "\tspeed: 0.0612s/iter; left time: 1240.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489367\n",
      "\tspeed: 0.0331s/iter; left time: 668.2251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0506088 Vali Loss: 0.0888529 Test Loss: 0.1031139\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0476753\n",
      "\tspeed: 0.0623s/iter; left time: 1249.1649s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481353\n",
      "\tspeed: 0.0331s/iter; left time: 660.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0486823 Vali Loss: 0.0881064 Test Loss: 0.1029631\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0461587\n",
      "\tspeed: 0.0609s/iter; left time: 1208.6124s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474565\n",
      "\tspeed: 0.0330s/iter; left time: 650.9760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0471709 Vali Loss: 0.0887941 Test Loss: 0.1031620\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465209\n",
      "\tspeed: 0.0616s/iter; left time: 1207.6783s\n",
      "\titers: 200, epoch: 13 | loss: 0.0457823\n",
      "\tspeed: 0.0332s/iter; left time: 647.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.64s\n",
      "Steps: 224 | Train Loss: 0.0457775 Vali Loss: 0.0880506 Test Loss: 0.1036356\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021871840581297874, rmse:0.1478913128376007, mae:0.09769626706838608, rse:0.4344601631164551\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:21.86s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163252\n",
      "\tspeed: 0.0624s/iter; left time: 1385.7644s\n",
      "\titers: 200, epoch: 1 | loss: 0.1111509\n",
      "\tspeed: 0.0337s/iter; left time: 745.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1248032 Vali Loss: 0.1023557 Test Loss: 0.1157608\n",
      "Validation loss decreased (inf --> 0.102356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0920324\n",
      "\tspeed: 0.0733s/iter; left time: 1611.7066s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905396\n",
      "\tspeed: 0.0337s/iter; left time: 738.0070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0927347 Vali Loss: 0.0911596 Test Loss: 0.1026373\n",
      "Validation loss decreased (0.102356 --> 0.091160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0813993\n",
      "\tspeed: 0.0775s/iter; left time: 1685.0918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0804934\n",
      "\tspeed: 0.0338s/iter; left time: 732.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0837477 Vali Loss: 0.0901361 Test Loss: 0.1034494\n",
      "Validation loss decreased (0.091160 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0745005\n",
      "\tspeed: 0.0755s/iter; left time: 1625.6449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743757\n",
      "\tspeed: 0.0338s/iter; left time: 723.6099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 223 | Train Loss: 0.0773343 Vali Loss: 0.0920163 Test Loss: 0.1045371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717543\n",
      "\tspeed: 0.0623s/iter; left time: 1327.8117s\n",
      "\titers: 200, epoch: 5 | loss: 0.0683926\n",
      "\tspeed: 0.0339s/iter; left time: 717.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0706961 Vali Loss: 0.0927095 Test Loss: 0.1056051\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635267\n",
      "\tspeed: 0.0626s/iter; left time: 1319.7380s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626201\n",
      "\tspeed: 0.0338s/iter; left time: 709.7059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0648583 Vali Loss: 0.0928507 Test Loss: 0.1066073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594731\n",
      "\tspeed: 0.0620s/iter; left time: 1292.7169s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574201\n",
      "\tspeed: 0.0340s/iter; left time: 705.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 223 | Train Loss: 0.0604445 Vali Loss: 0.0937179 Test Loss: 0.1071184\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578186\n",
      "\tspeed: 0.0640s/iter; left time: 1321.4657s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562383\n",
      "\tspeed: 0.0338s/iter; left time: 694.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0571987 Vali Loss: 0.0920181 Test Loss: 0.1071269\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0552342\n",
      "\tspeed: 0.0626s/iter; left time: 1277.5305s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548123\n",
      "\tspeed: 0.0339s/iter; left time: 687.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0545950 Vali Loss: 0.0930666 Test Loss: 0.1075234\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0529762\n",
      "\tspeed: 0.0622s/iter; left time: 1255.6336s\n",
      "\titers: 200, epoch: 10 | loss: 0.0518859\n",
      "\tspeed: 0.0339s/iter; left time: 681.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0524777 Vali Loss: 0.0920488 Test Loss: 0.1072294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0511605\n",
      "\tspeed: 0.0620s/iter; left time: 1237.8479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0511627\n",
      "\tspeed: 0.0339s/iter; left time: 674.3273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0506818 Vali Loss: 0.0927317 Test Loss: 0.1083499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0496722\n",
      "\tspeed: 0.0624s/iter; left time: 1232.3483s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484021\n",
      "\tspeed: 0.0339s/iter; left time: 666.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0491604 Vali Loss: 0.0922555 Test Loss: 0.1075642\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480842\n",
      "\tspeed: 0.0623s/iter; left time: 1215.7753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0480131\n",
      "\tspeed: 0.0340s/iter; left time: 659.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0478748 Vali Loss: 0.0920726 Test Loss: 0.1082650\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0238569937646389, rmse:0.15445709228515625, mae:0.10344940423965454, rse:0.45378103852272034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175357\n",
      "\tspeed: 0.0360s/iter; left time: 799.3014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1085309\n",
      "\tspeed: 0.0339s/iter; left time: 749.2484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 223 | Train Loss: 0.1244877 Vali Loss: 0.1024658 Test Loss: 0.1162681\n",
      "Validation loss decreased (inf --> 0.102466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0892978\n",
      "\tspeed: 0.0724s/iter; left time: 1591.8888s\n",
      "\titers: 200, epoch: 2 | loss: 0.0858404\n",
      "\tspeed: 0.0339s/iter; left time: 742.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0925368 Vali Loss: 0.0931649 Test Loss: 0.1041178\n",
      "Validation loss decreased (0.102466 --> 0.093165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0832203\n",
      "\tspeed: 0.0679s/iter; left time: 1477.8758s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824200\n",
      "\tspeed: 0.0339s/iter; left time: 733.1185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 223 | Train Loss: 0.0840002 Vali Loss: 0.0918773 Test Loss: 0.1027539\n",
      "Validation loss decreased (0.093165 --> 0.091877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755718\n",
      "\tspeed: 0.0684s/iter; left time: 1473.3897s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789680\n",
      "\tspeed: 0.0340s/iter; left time: 728.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0778846 Vali Loss: 0.0915824 Test Loss: 0.1033742\n",
      "Validation loss decreased (0.091877 --> 0.091582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740893\n",
      "\tspeed: 0.0689s/iter; left time: 1468.1146s\n",
      "\titers: 200, epoch: 5 | loss: 0.0704942\n",
      "\tspeed: 0.0339s/iter; left time: 718.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 223 | Train Loss: 0.0719597 Vali Loss: 0.0934459 Test Loss: 0.1050283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0674252\n",
      "\tspeed: 0.0634s/iter; left time: 1336.3706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634718\n",
      "\tspeed: 0.0340s/iter; left time: 713.3638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0659032 Vali Loss: 0.0927102 Test Loss: 0.1051720\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0629653\n",
      "\tspeed: 0.0642s/iter; left time: 1338.9348s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605651\n",
      "\tspeed: 0.0342s/iter; left time: 709.2852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0613759 Vali Loss: 0.0924244 Test Loss: 0.1051302\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563948\n",
      "\tspeed: 0.0629s/iter; left time: 1297.6812s\n",
      "\titers: 200, epoch: 8 | loss: 0.0562144\n",
      "\tspeed: 0.0339s/iter; left time: 696.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 223 | Train Loss: 0.0577199 Vali Loss: 0.0931844 Test Loss: 0.1064090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559244\n",
      "\tspeed: 0.0636s/iter; left time: 1298.2004s\n",
      "\titers: 200, epoch: 9 | loss: 0.0532067\n",
      "\tspeed: 0.0339s/iter; left time: 689.7418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 223 | Train Loss: 0.0549016 Vali Loss: 0.0936035 Test Loss: 0.1066466\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514232\n",
      "\tspeed: 0.0628s/iter; left time: 1268.0533s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512180\n",
      "\tspeed: 0.0338s/iter; left time: 680.0949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 223 | Train Loss: 0.0526190 Vali Loss: 0.0929514 Test Loss: 0.1060959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514014\n",
      "\tspeed: 0.0625s/iter; left time: 1248.3156s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494085\n",
      "\tspeed: 0.0340s/iter; left time: 675.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 223 | Train Loss: 0.0508202 Vali Loss: 0.0938980 Test Loss: 0.1071277\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0495044\n",
      "\tspeed: 0.0643s/iter; left time: 1270.2817s\n",
      "\titers: 200, epoch: 12 | loss: 0.0483764\n",
      "\tspeed: 0.0339s/iter; left time: 666.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 223 | Train Loss: 0.0491536 Vali Loss: 0.0933724 Test Loss: 0.1070942\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0487324\n",
      "\tspeed: 0.0627s/iter; left time: 1224.8408s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466656\n",
      "\tspeed: 0.0339s/iter; left time: 658.3644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 223 | Train Loss: 0.0478594 Vali Loss: 0.0935658 Test Loss: 0.1077204\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0470098\n",
      "\tspeed: 0.0633s/iter; left time: 1221.3799s\n",
      "\titers: 200, epoch: 14 | loss: 0.0454411\n",
      "\tspeed: 0.0340s/iter; left time: 652.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 223 | Train Loss: 0.0467149 Vali Loss: 0.0932253 Test Loss: 0.1074122\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023433756083250046, rmse:0.15308088064193726, mae:0.10337422043085098, rse:0.44973787665367126\n",
      "Intermediate time for ES and pred_len 168: 00h:04m:41.40s\n",
      "Intermediate time for ES: 00h:14m:52.14s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0825739\n",
      "\tspeed: 0.0440s/iter; left time: 989.1272s\n",
      "\titers: 200, epoch: 1 | loss: 0.0720544\n",
      "\tspeed: 0.0179s/iter; left time: 400.4240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 226 | Train Loss: 0.0892576 Vali Loss: 0.0763335 Test Loss: 0.0833760\n",
      "Validation loss decreased (inf --> 0.076333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0519041\n",
      "\tspeed: 0.0395s/iter; left time: 879.1817s\n",
      "\titers: 200, epoch: 2 | loss: 0.0478711\n",
      "\tspeed: 0.0180s/iter; left time: 399.4832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0525726 Vali Loss: 0.0569420 Test Loss: 0.0612847\n",
      "Validation loss decreased (0.076333 --> 0.056942).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0440858\n",
      "\tspeed: 0.0394s/iter; left time: 868.8589s\n",
      "\titers: 200, epoch: 3 | loss: 0.0461644\n",
      "\tspeed: 0.0181s/iter; left time: 397.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0464609 Vali Loss: 0.0550702 Test Loss: 0.0593229\n",
      "Validation loss decreased (0.056942 --> 0.055070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0446937\n",
      "\tspeed: 0.0383s/iter; left time: 834.9939s\n",
      "\titers: 200, epoch: 4 | loss: 0.0430271\n",
      "\tspeed: 0.0185s/iter; left time: 402.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0446763 Vali Loss: 0.0546017 Test Loss: 0.0593835\n",
      "Validation loss decreased (0.055070 --> 0.054602).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0449143\n",
      "\tspeed: 0.0391s/iter; left time: 845.1750s\n",
      "\titers: 200, epoch: 5 | loss: 0.0423666\n",
      "\tspeed: 0.0179s/iter; left time: 384.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0431179 Vali Loss: 0.0536028 Test Loss: 0.0577287\n",
      "Validation loss decreased (0.054602 --> 0.053603).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0447902\n",
      "\tspeed: 0.0414s/iter; left time: 884.3643s\n",
      "\titers: 200, epoch: 6 | loss: 0.0402884\n",
      "\tspeed: 0.0179s/iter; left time: 380.7906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 226 | Train Loss: 0.0419177 Vali Loss: 0.0532793 Test Loss: 0.0576561\n",
      "Validation loss decreased (0.053603 --> 0.053279).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0400641\n",
      "\tspeed: 0.0380s/iter; left time: 803.0530s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413724\n",
      "\tspeed: 0.0180s/iter; left time: 377.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0406169 Vali Loss: 0.0529187 Test Loss: 0.0586069\n",
      "Validation loss decreased (0.053279 --> 0.052919).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0422125\n",
      "\tspeed: 0.0385s/iter; left time: 804.8030s\n",
      "\titers: 200, epoch: 8 | loss: 0.0390262\n",
      "\tspeed: 0.0177s/iter; left time: 368.7307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0396278 Vali Loss: 0.0532204 Test Loss: 0.0586753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396171\n",
      "\tspeed: 0.0362s/iter; left time: 749.2150s\n",
      "\titers: 200, epoch: 9 | loss: 0.0392884\n",
      "\tspeed: 0.0178s/iter; left time: 365.5394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0383368 Vali Loss: 0.0533056 Test Loss: 0.0592961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352243\n",
      "\tspeed: 0.0365s/iter; left time: 746.7584s\n",
      "\titers: 200, epoch: 10 | loss: 0.0382171\n",
      "\tspeed: 0.0178s/iter; left time: 361.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0371329 Vali Loss: 0.0542546 Test Loss: 0.0600371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0372575\n",
      "\tspeed: 0.0366s/iter; left time: 741.1142s\n",
      "\titers: 200, epoch: 11 | loss: 0.0357848\n",
      "\tspeed: 0.0179s/iter; left time: 359.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0361327 Vali Loss: 0.0540272 Test Loss: 0.0606850\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0339495\n",
      "\tspeed: 0.0370s/iter; left time: 740.6702s\n",
      "\titers: 200, epoch: 12 | loss: 0.0343725\n",
      "\tspeed: 0.0178s/iter; left time: 355.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0351717 Vali Loss: 0.0541665 Test Loss: 0.0607401\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0350991\n",
      "\tspeed: 0.0367s/iter; left time: 725.8432s\n",
      "\titers: 200, epoch: 13 | loss: 0.0356509\n",
      "\tspeed: 0.0182s/iter; left time: 358.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0342767 Vali Loss: 0.0543875 Test Loss: 0.0612607\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0323812\n",
      "\tspeed: 0.0368s/iter; left time: 719.6369s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324937\n",
      "\tspeed: 0.0178s/iter; left time: 347.1468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0336061 Vali Loss: 0.0549471 Test Loss: 0.0617569\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0328720\n",
      "\tspeed: 0.0369s/iter; left time: 712.8441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0327561\n",
      "\tspeed: 0.0177s/iter; left time: 341.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0329703 Vali Loss: 0.0550517 Test Loss: 0.0612711\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0303529\n",
      "\tspeed: 0.0369s/iter; left time: 705.4486s\n",
      "\titers: 200, epoch: 16 | loss: 0.0308379\n",
      "\tspeed: 0.0179s/iter; left time: 340.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0323310 Vali Loss: 0.0550910 Test Loss: 0.0609389\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0322276\n",
      "\tspeed: 0.0368s/iter; left time: 694.5076s\n",
      "\titers: 200, epoch: 17 | loss: 0.0307707\n",
      "\tspeed: 0.0177s/iter; left time: 333.4214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0318553 Vali Loss: 0.0549174 Test Loss: 0.0618004\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0108979232609272, rmse:0.1043931171298027, mae:0.05860685557126999, rse:0.4027457535266876\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0808246\n",
      "\tspeed: 0.0211s/iter; left time: 474.1064s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777871\n",
      "\tspeed: 0.0188s/iter; left time: 420.6441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0886302 Vali Loss: 0.0765412 Test Loss: 0.0835635\n",
      "Validation loss decreased (inf --> 0.076541).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0512616\n",
      "\tspeed: 0.0396s/iter; left time: 882.4648s\n",
      "\titers: 200, epoch: 2 | loss: 0.0489905\n",
      "\tspeed: 0.0178s/iter; left time: 394.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0525013 Vali Loss: 0.0562015 Test Loss: 0.0609805\n",
      "Validation loss decreased (0.076541 --> 0.056202).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472980\n",
      "\tspeed: 0.0394s/iter; left time: 867.7970s\n",
      "\titers: 200, epoch: 3 | loss: 0.0457077\n",
      "\tspeed: 0.0178s/iter; left time: 391.5989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0466549 Vali Loss: 0.0544775 Test Loss: 0.0589031\n",
      "Validation loss decreased (0.056202 --> 0.054478).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0453555\n",
      "\tspeed: 0.0389s/iter; left time: 849.9809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0427258\n",
      "\tspeed: 0.0181s/iter; left time: 392.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0447521 Vali Loss: 0.0536225 Test Loss: 0.0581660\n",
      "Validation loss decreased (0.054478 --> 0.053622).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0439419\n",
      "\tspeed: 0.0387s/iter; left time: 836.7352s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437575\n",
      "\tspeed: 0.0177s/iter; left time: 381.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0432652 Vali Loss: 0.0528611 Test Loss: 0.0578288\n",
      "Validation loss decreased (0.053622 --> 0.052861).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0424836\n",
      "\tspeed: 0.0397s/iter; left time: 849.0424s\n",
      "\titers: 200, epoch: 6 | loss: 0.0434853\n",
      "\tspeed: 0.0178s/iter; left time: 378.7619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0422494 Vali Loss: 0.0533285 Test Loss: 0.0580732\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0412046\n",
      "\tspeed: 0.0369s/iter; left time: 781.2850s\n",
      "\titers: 200, epoch: 7 | loss: 0.0417114\n",
      "\tspeed: 0.0178s/iter; left time: 373.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0411409 Vali Loss: 0.0528526 Test Loss: 0.0578768\n",
      "Validation loss decreased (0.052861 --> 0.052853).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0405956\n",
      "\tspeed: 0.0383s/iter; left time: 801.0011s\n",
      "\titers: 200, epoch: 8 | loss: 0.0414334\n",
      "\tspeed: 0.0178s/iter; left time: 370.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0399912 Vali Loss: 0.0526390 Test Loss: 0.0583228\n",
      "Validation loss decreased (0.052853 --> 0.052639).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0392249\n",
      "\tspeed: 0.0396s/iter; left time: 819.5750s\n",
      "\titers: 200, epoch: 9 | loss: 0.0397011\n",
      "\tspeed: 0.0177s/iter; left time: 364.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0390025 Vali Loss: 0.0525965 Test Loss: 0.0577715\n",
      "Validation loss decreased (0.052639 --> 0.052597).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0352390\n",
      "\tspeed: 0.0403s/iter; left time: 825.6378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0390021\n",
      "\tspeed: 0.0204s/iter; left time: 414.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 226 | Train Loss: 0.0378733 Vali Loss: 0.0526242 Test Loss: 0.0583718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0355981\n",
      "\tspeed: 0.0372s/iter; left time: 752.0537s\n",
      "\titers: 200, epoch: 11 | loss: 0.0361680\n",
      "\tspeed: 0.0180s/iter; left time: 362.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0368099 Vali Loss: 0.0531015 Test Loss: 0.0590410\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0343426\n",
      "\tspeed: 0.0373s/iter; left time: 745.7549s\n",
      "\titers: 200, epoch: 12 | loss: 0.0386787\n",
      "\tspeed: 0.0177s/iter; left time: 352.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0359604 Vali Loss: 0.0532657 Test Loss: 0.0590416\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0358210\n",
      "\tspeed: 0.0370s/iter; left time: 732.6723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0385372\n",
      "\tspeed: 0.0185s/iter; left time: 364.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 226 | Train Loss: 0.0351373 Vali Loss: 0.0539517 Test Loss: 0.0593859\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0342100\n",
      "\tspeed: 0.0372s/iter; left time: 728.1848s\n",
      "\titers: 200, epoch: 14 | loss: 0.0354560\n",
      "\tspeed: 0.0180s/iter; left time: 349.6016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0343315 Vali Loss: 0.0538370 Test Loss: 0.0604549\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0339227\n",
      "\tspeed: 0.0368s/iter; left time: 712.4510s\n",
      "\titers: 200, epoch: 15 | loss: 0.0324195\n",
      "\tspeed: 0.0177s/iter; left time: 341.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0336581 Vali Loss: 0.0539099 Test Loss: 0.0599087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0363340\n",
      "\tspeed: 0.0375s/iter; left time: 716.4222s\n",
      "\titers: 200, epoch: 16 | loss: 0.0296580\n",
      "\tspeed: 0.0178s/iter; left time: 338.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0331135 Vali Loss: 0.0539095 Test Loss: 0.0599806\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0320749\n",
      "\tspeed: 0.0379s/iter; left time: 714.9103s\n",
      "\titers: 200, epoch: 17 | loss: 0.0329088\n",
      "\tspeed: 0.0178s/iter; left time: 334.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0326186 Vali Loss: 0.0540928 Test Loss: 0.0603553\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0313287\n",
      "\tspeed: 0.0379s/iter; left time: 706.8323s\n",
      "\titers: 200, epoch: 18 | loss: 0.0325896\n",
      "\tspeed: 0.0179s/iter; left time: 331.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0321234 Vali Loss: 0.0542886 Test Loss: 0.0603496\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0324607\n",
      "\tspeed: 0.0366s/iter; left time: 674.4744s\n",
      "\titers: 200, epoch: 19 | loss: 0.0300568\n",
      "\tspeed: 0.0179s/iter; left time: 327.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0317324 Vali Loss: 0.0542460 Test Loss: 0.0601043\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010704690590500832, rmse:0.10346347838640213, mae:0.0577714666724205, rse:0.39915919303894043\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:33.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0949994\n",
      "\tspeed: 0.0456s/iter; left time: 1022.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.0818396\n",
      "\tspeed: 0.0181s/iter; left time: 404.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.61s\n",
      "Steps: 225 | Train Loss: 0.0984444 Vali Loss: 0.0880076 Test Loss: 0.0994513\n",
      "Validation loss decreased (inf --> 0.088008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0642481\n",
      "\tspeed: 0.0411s/iter; left time: 910.9899s\n",
      "\titers: 200, epoch: 2 | loss: 0.0622116\n",
      "\tspeed: 0.0182s/iter; left time: 400.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0677669 Vali Loss: 0.0737542 Test Loss: 0.0843380\n",
      "Validation loss decreased (0.088008 --> 0.073754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0635156\n",
      "\tspeed: 0.0402s/iter; left time: 883.3367s\n",
      "\titers: 200, epoch: 3 | loss: 0.0583343\n",
      "\tspeed: 0.0187s/iter; left time: 407.8178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0608415 Vali Loss: 0.0740786 Test Loss: 0.0821252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0573911\n",
      "\tspeed: 0.0384s/iter; left time: 834.2952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538883\n",
      "\tspeed: 0.0183s/iter; left time: 396.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0571251 Vali Loss: 0.0752631 Test Loss: 0.0843270\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0542980\n",
      "\tspeed: 0.0377s/iter; left time: 811.0578s\n",
      "\titers: 200, epoch: 5 | loss: 0.0494459\n",
      "\tspeed: 0.0181s/iter; left time: 386.6309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0532236 Vali Loss: 0.0759761 Test Loss: 0.0854147\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505165\n",
      "\tspeed: 0.0371s/iter; left time: 790.0507s\n",
      "\titers: 200, epoch: 6 | loss: 0.0506002\n",
      "\tspeed: 0.0183s/iter; left time: 387.8944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0501787 Vali Loss: 0.0768308 Test Loss: 0.0852290\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0480088\n",
      "\tspeed: 0.0382s/iter; left time: 804.1262s\n",
      "\titers: 200, epoch: 7 | loss: 0.0443931\n",
      "\tspeed: 0.0185s/iter; left time: 387.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0476712 Vali Loss: 0.0764843 Test Loss: 0.0855211\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0477575\n",
      "\tspeed: 0.0380s/iter; left time: 790.6320s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449111\n",
      "\tspeed: 0.0180s/iter; left time: 373.4726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0455909 Vali Loss: 0.0765070 Test Loss: 0.0847537\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444669\n",
      "\tspeed: 0.0380s/iter; left time: 782.3708s\n",
      "\titers: 200, epoch: 9 | loss: 0.0466012\n",
      "\tspeed: 0.0186s/iter; left time: 381.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0438265 Vali Loss: 0.0768355 Test Loss: 0.0856286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0435193\n",
      "\tspeed: 0.0379s/iter; left time: 772.4439s\n",
      "\titers: 200, epoch: 10 | loss: 0.0399701\n",
      "\tspeed: 0.0182s/iter; left time: 368.5660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0423801 Vali Loss: 0.0769819 Test Loss: 0.0855340\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0414985\n",
      "\tspeed: 0.0377s/iter; left time: 759.6218s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408975\n",
      "\tspeed: 0.0181s/iter; left time: 363.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0411706 Vali Loss: 0.0774362 Test Loss: 0.0854421\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397998\n",
      "\tspeed: 0.0381s/iter; left time: 759.1696s\n",
      "\titers: 200, epoch: 12 | loss: 0.0391970\n",
      "\tspeed: 0.0181s/iter; left time: 358.7041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0401057 Vali Loss: 0.0769203 Test Loss: 0.0855711\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020127102732658386, rmse:0.14187002182006836, mae:0.08433804661035538, rse:0.5487909913063049\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0942150\n",
      "\tspeed: 0.0202s/iter; left time: 453.1591s\n",
      "\titers: 200, epoch: 1 | loss: 0.0819090\n",
      "\tspeed: 0.0180s/iter; left time: 402.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0978670 Vali Loss: 0.0881797 Test Loss: 0.0994574\n",
      "Validation loss decreased (inf --> 0.088180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0664974\n",
      "\tspeed: 0.0413s/iter; left time: 916.2054s\n",
      "\titers: 200, epoch: 2 | loss: 0.0632625\n",
      "\tspeed: 0.0185s/iter; left time: 408.0923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0679474 Vali Loss: 0.0738612 Test Loss: 0.0836209\n",
      "Validation loss decreased (0.088180 --> 0.073861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0601718\n",
      "\tspeed: 0.0442s/iter; left time: 969.4626s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622078\n",
      "\tspeed: 0.0184s/iter; left time: 401.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0612250 Vali Loss: 0.0731753 Test Loss: 0.0819078\n",
      "Validation loss decreased (0.073861 --> 0.073175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0579952\n",
      "\tspeed: 0.0398s/iter; left time: 865.2752s\n",
      "\titers: 200, epoch: 4 | loss: 0.0564419\n",
      "\tspeed: 0.0181s/iter; left time: 392.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0574971 Vali Loss: 0.0752813 Test Loss: 0.0844468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0572532\n",
      "\tspeed: 0.0377s/iter; left time: 810.4702s\n",
      "\titers: 200, epoch: 5 | loss: 0.0534076\n",
      "\tspeed: 0.0181s/iter; left time: 387.7646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0539225 Vali Loss: 0.0754249 Test Loss: 0.0834574\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0501882\n",
      "\tspeed: 0.0380s/iter; left time: 808.8260s\n",
      "\titers: 200, epoch: 6 | loss: 0.0494513\n",
      "\tspeed: 0.0181s/iter; left time: 384.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0507724 Vali Loss: 0.0762898 Test Loss: 0.0839536\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0474354\n",
      "\tspeed: 0.0397s/iter; left time: 835.1748s\n",
      "\titers: 200, epoch: 7 | loss: 0.0489970\n",
      "\tspeed: 0.0190s/iter; left time: 397.3916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0482603 Vali Loss: 0.0765327 Test Loss: 0.0842737\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0459890\n",
      "\tspeed: 0.0381s/iter; left time: 793.1110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0453775\n",
      "\tspeed: 0.0185s/iter; left time: 382.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0462406 Vali Loss: 0.0767720 Test Loss: 0.0844933\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0424829\n",
      "\tspeed: 0.0380s/iter; left time: 782.5921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439030\n",
      "\tspeed: 0.0182s/iter; left time: 372.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0444618 Vali Loss: 0.0772027 Test Loss: 0.0855004\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0433870\n",
      "\tspeed: 0.0380s/iter; left time: 773.6652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0414537\n",
      "\tspeed: 0.0183s/iter; left time: 370.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0430081 Vali Loss: 0.0774466 Test Loss: 0.0858750\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424098\n",
      "\tspeed: 0.0394s/iter; left time: 794.0385s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408237\n",
      "\tspeed: 0.0181s/iter; left time: 362.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0417295 Vali Loss: 0.0773811 Test Loss: 0.0860263\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0397430\n",
      "\tspeed: 0.0383s/iter; left time: 763.8141s\n",
      "\titers: 200, epoch: 12 | loss: 0.0397619\n",
      "\tspeed: 0.0187s/iter; left time: 371.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0406975 Vali Loss: 0.0766426 Test Loss: 0.0861305\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0392018\n",
      "\tspeed: 0.0395s/iter; left time: 777.6916s\n",
      "\titers: 200, epoch: 13 | loss: 0.0406257\n",
      "\tspeed: 0.0182s/iter; left time: 356.3085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0398008 Vali Loss: 0.0765993 Test Loss: 0.0865211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018997935578227043, rmse:0.13783299922943115, mae:0.08190777897834778, rse:0.5331746935844421\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:35.62s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0908656\n",
      "\tspeed: 0.0445s/iter; left time: 996.9496s\n",
      "\titers: 200, epoch: 1 | loss: 0.0891940\n",
      "\tspeed: 0.0186s/iter; left time: 415.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.71s\n",
      "Steps: 225 | Train Loss: 0.1014871 Vali Loss: 0.0917853 Test Loss: 0.1026675\n",
      "Validation loss decreased (inf --> 0.091785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0684629\n",
      "\tspeed: 0.0409s/iter; left time: 906.4908s\n",
      "\titers: 200, epoch: 2 | loss: 0.0672442\n",
      "\tspeed: 0.0185s/iter; left time: 407.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0723063 Vali Loss: 0.0782374 Test Loss: 0.0879902\n",
      "Validation loss decreased (0.091785 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0619121\n",
      "\tspeed: 0.0438s/iter; left time: 961.5666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0598689\n",
      "\tspeed: 0.0185s/iter; left time: 404.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0647034 Vali Loss: 0.0780730 Test Loss: 0.0865445\n",
      "Validation loss decreased (0.078237 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0606524\n",
      "\tspeed: 0.0486s/iter; left time: 1056.8225s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594136\n",
      "\tspeed: 0.0188s/iter; left time: 407.3998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0603122 Vali Loss: 0.0804714 Test Loss: 0.0876513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0565531\n",
      "\tspeed: 0.0382s/iter; left time: 822.2550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0558551\n",
      "\tspeed: 0.0184s/iter; left time: 394.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0566340 Vali Loss: 0.0817166 Test Loss: 0.0889156\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0553974\n",
      "\tspeed: 0.0387s/iter; left time: 823.8927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0514911\n",
      "\tspeed: 0.0193s/iter; left time: 407.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0532845 Vali Loss: 0.0825787 Test Loss: 0.0885907\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0522775\n",
      "\tspeed: 0.0385s/iter; left time: 810.6988s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490751\n",
      "\tspeed: 0.0184s/iter; left time: 385.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0506605 Vali Loss: 0.0819513 Test Loss: 0.0896498\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0481883\n",
      "\tspeed: 0.0389s/iter; left time: 811.1528s\n",
      "\titers: 200, epoch: 8 | loss: 0.0474817\n",
      "\tspeed: 0.0192s/iter; left time: 397.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.0484786 Vali Loss: 0.0840234 Test Loss: 0.0901825\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0470933\n",
      "\tspeed: 0.0400s/iter; left time: 824.1000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0446422\n",
      "\tspeed: 0.0185s/iter; left time: 378.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0467293 Vali Loss: 0.0832497 Test Loss: 0.0904056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0455585\n",
      "\tspeed: 0.0399s/iter; left time: 811.9973s\n",
      "\titers: 200, epoch: 10 | loss: 0.0460681\n",
      "\tspeed: 0.0197s/iter; left time: 398.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.82s\n",
      "Steps: 225 | Train Loss: 0.0453248 Vali Loss: 0.0837281 Test Loss: 0.0903833\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0434859\n",
      "\tspeed: 0.0419s/iter; left time: 845.1868s\n",
      "\titers: 200, epoch: 11 | loss: 0.0438852\n",
      "\tspeed: 0.0185s/iter; left time: 369.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0440360 Vali Loss: 0.0829143 Test Loss: 0.0909697\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0423885\n",
      "\tspeed: 0.0382s/iter; left time: 760.2230s\n",
      "\titers: 200, epoch: 12 | loss: 0.0401541\n",
      "\tspeed: 0.0184s/iter; left time: 365.4141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0429602 Vali Loss: 0.0840859 Test Loss: 0.0908408\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0415776\n",
      "\tspeed: 0.0390s/iter; left time: 768.8135s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405993\n",
      "\tspeed: 0.0192s/iter; left time: 377.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0420540 Vali Loss: 0.0836687 Test Loss: 0.0909934\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020075254142284393, rmse:0.14168716967105865, mae:0.08654448390007019, rse:0.5487678050994873\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0945257\n",
      "\tspeed: 0.0207s/iter; left time: 463.0542s\n",
      "\titers: 200, epoch: 1 | loss: 0.0830759\n",
      "\tspeed: 0.0186s/iter; left time: 414.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.1009076 Vali Loss: 0.0917944 Test Loss: 0.1025656\n",
      "Validation loss decreased (inf --> 0.091794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0700706\n",
      "\tspeed: 0.0414s/iter; left time: 918.4545s\n",
      "\titers: 200, epoch: 2 | loss: 0.0660276\n",
      "\tspeed: 0.0185s/iter; left time: 408.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0723461 Vali Loss: 0.0790639 Test Loss: 0.0894321\n",
      "Validation loss decreased (0.091794 --> 0.079064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0639853\n",
      "\tspeed: 0.0431s/iter; left time: 945.4431s\n",
      "\titers: 200, epoch: 3 | loss: 0.0622231\n",
      "\tspeed: 0.0191s/iter; left time: 416.4922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0647785 Vali Loss: 0.0787261 Test Loss: 0.0880830\n",
      "Validation loss decreased (0.079064 --> 0.078726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630164\n",
      "\tspeed: 0.0558s/iter; left time: 1212.8221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0602266\n",
      "\tspeed: 0.0184s/iter; left time: 397.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0603927 Vali Loss: 0.0806556 Test Loss: 0.0891107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562662\n",
      "\tspeed: 0.0392s/iter; left time: 842.6537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0541140\n",
      "\tspeed: 0.0185s/iter; left time: 395.2849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0563509 Vali Loss: 0.0811103 Test Loss: 0.0888919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0523157\n",
      "\tspeed: 0.0392s/iter; left time: 833.0026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0513288\n",
      "\tspeed: 0.0185s/iter; left time: 391.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0530924 Vali Loss: 0.0807032 Test Loss: 0.0897623\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0500884\n",
      "\tspeed: 0.0394s/iter; left time: 829.3137s\n",
      "\titers: 200, epoch: 7 | loss: 0.0500115\n",
      "\tspeed: 0.0184s/iter; left time: 385.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0504590 Vali Loss: 0.0820986 Test Loss: 0.0894578\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0479878\n",
      "\tspeed: 0.0385s/iter; left time: 801.4588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0484171\n",
      "\tspeed: 0.0185s/iter; left time: 383.4373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0482995 Vali Loss: 0.0821091 Test Loss: 0.0903916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0458567\n",
      "\tspeed: 0.0394s/iter; left time: 810.6843s\n",
      "\titers: 200, epoch: 9 | loss: 0.0477157\n",
      "\tspeed: 0.0187s/iter; left time: 382.5386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0466534 Vali Loss: 0.0833053 Test Loss: 0.0899950\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0471632\n",
      "\tspeed: 0.0392s/iter; left time: 799.0429s\n",
      "\titers: 200, epoch: 10 | loss: 0.0469389\n",
      "\tspeed: 0.0185s/iter; left time: 374.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0452414 Vali Loss: 0.0830634 Test Loss: 0.0917294\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0441526\n",
      "\tspeed: 0.0392s/iter; left time: 789.5945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0439629\n",
      "\tspeed: 0.0190s/iter; left time: 380.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0440587 Vali Loss: 0.0837354 Test Loss: 0.0909154\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436273\n",
      "\tspeed: 0.0405s/iter; left time: 806.6968s\n",
      "\titers: 200, epoch: 12 | loss: 0.0430317\n",
      "\tspeed: 0.0185s/iter; left time: 366.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0430000 Vali Loss: 0.0836592 Test Loss: 0.0912588\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0423120\n",
      "\tspeed: 0.0397s/iter; left time: 782.0449s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426837\n",
      "\tspeed: 0.0190s/iter; left time: 371.5052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0421225 Vali Loss: 0.0831803 Test Loss: 0.0908114\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020790696144104004, rmse:0.14418978989124298, mae:0.08808299899101257, rse:0.5584607124328613\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:47.11s\n",
      "Intermediate time for FR: 00h:08m:56.14s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1186669\n",
      "\tspeed: 0.0437s/iter; left time: 982.3349s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038871\n",
      "\tspeed: 0.0177s/iter; left time: 396.2217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.58s\n",
      "Steps: 226 | Train Loss: 0.1271104 Vali Loss: 0.0885935 Test Loss: 0.0908134\n",
      "Validation loss decreased (inf --> 0.088594).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0683111\n",
      "\tspeed: 0.0396s/iter; left time: 881.0199s\n",
      "\titers: 200, epoch: 2 | loss: 0.0647918\n",
      "\tspeed: 0.0177s/iter; left time: 392.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0725847 Vali Loss: 0.0627410 Test Loss: 0.0653730\n",
      "Validation loss decreased (0.088594 --> 0.062741).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0620086\n",
      "\tspeed: 0.0401s/iter; left time: 883.9944s\n",
      "\titers: 200, epoch: 3 | loss: 0.0679798\n",
      "\tspeed: 0.0178s/iter; left time: 391.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0636721 Vali Loss: 0.0587901 Test Loss: 0.0619358\n",
      "Validation loss decreased (0.062741 --> 0.058790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620091\n",
      "\tspeed: 0.0391s/iter; left time: 853.6076s\n",
      "\titers: 200, epoch: 4 | loss: 0.0562509\n",
      "\tspeed: 0.0180s/iter; left time: 390.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0611027 Vali Loss: 0.0581652 Test Loss: 0.0608983\n",
      "Validation loss decreased (0.058790 --> 0.058165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0612355\n",
      "\tspeed: 0.0396s/iter; left time: 854.9812s\n",
      "\titers: 200, epoch: 5 | loss: 0.0565420\n",
      "\tspeed: 0.0177s/iter; left time: 380.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0594019 Vali Loss: 0.0568237 Test Loss: 0.0601146\n",
      "Validation loss decreased (0.058165 --> 0.056824).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579325\n",
      "\tspeed: 0.0383s/iter; left time: 818.7290s\n",
      "\titers: 200, epoch: 6 | loss: 0.0553782\n",
      "\tspeed: 0.0180s/iter; left time: 382.6175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0578790 Vali Loss: 0.0563135 Test Loss: 0.0592824\n",
      "Validation loss decreased (0.056824 --> 0.056313).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590282\n",
      "\tspeed: 0.0389s/iter; left time: 823.2705s\n",
      "\titers: 200, epoch: 7 | loss: 0.0608191\n",
      "\tspeed: 0.0177s/iter; left time: 372.5048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0567683 Vali Loss: 0.0565626 Test Loss: 0.0589534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570408\n",
      "\tspeed: 0.0363s/iter; left time: 758.6925s\n",
      "\titers: 200, epoch: 8 | loss: 0.0567258\n",
      "\tspeed: 0.0178s/iter; left time: 369.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0555047 Vali Loss: 0.0565501 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539403\n",
      "\tspeed: 0.0378s/iter; left time: 783.1071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558067\n",
      "\tspeed: 0.0177s/iter; left time: 364.0247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0543611 Vali Loss: 0.0559711 Test Loss: 0.0584920\n",
      "Validation loss decreased (0.056313 --> 0.055971).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0480541\n",
      "\tspeed: 0.0391s/iter; left time: 799.4237s\n",
      "\titers: 200, epoch: 10 | loss: 0.0515454\n",
      "\tspeed: 0.0177s/iter; left time: 361.0255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0533515 Vali Loss: 0.0562107 Test Loss: 0.0589197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0505390\n",
      "\tspeed: 0.0366s/iter; left time: 740.7503s\n",
      "\titers: 200, epoch: 11 | loss: 0.0505183\n",
      "\tspeed: 0.0177s/iter; left time: 356.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0523736 Vali Loss: 0.0565854 Test Loss: 0.0583816\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0493615\n",
      "\tspeed: 0.0362s/iter; left time: 725.0631s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513223\n",
      "\tspeed: 0.0176s/iter; left time: 351.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 226 | Train Loss: 0.0513761 Vali Loss: 0.0566836 Test Loss: 0.0582515\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0495898\n",
      "\tspeed: 0.0363s/iter; left time: 717.7518s\n",
      "\titers: 200, epoch: 13 | loss: 0.0460916\n",
      "\tspeed: 0.0177s/iter; left time: 348.7666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0502435 Vali Loss: 0.0569636 Test Loss: 0.0586153\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0491502\n",
      "\tspeed: 0.0368s/iter; left time: 720.7901s\n",
      "\titers: 200, epoch: 14 | loss: 0.0497240\n",
      "\tspeed: 0.0177s/iter; left time: 343.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0493753 Vali Loss: 0.0566386 Test Loss: 0.0585247\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0487527\n",
      "\tspeed: 0.0360s/iter; left time: 695.8543s\n",
      "\titers: 200, epoch: 15 | loss: 0.0464090\n",
      "\tspeed: 0.0177s/iter; left time: 340.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0485031 Vali Loss: 0.0565502 Test Loss: 0.0588691\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0486492\n",
      "\tspeed: 0.0370s/iter; left time: 706.4464s\n",
      "\titers: 200, epoch: 16 | loss: 0.0468850\n",
      "\tspeed: 0.0176s/iter; left time: 335.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0476619 Vali Loss: 0.0570641 Test Loss: 0.0588286\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0484204\n",
      "\tspeed: 0.0361s/iter; left time: 681.3553s\n",
      "\titers: 200, epoch: 17 | loss: 0.0457373\n",
      "\tspeed: 0.0177s/iter; left time: 332.1292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 226 | Train Loss: 0.0469115 Vali Loss: 0.0571258 Test Loss: 0.0593243\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0459390\n",
      "\tspeed: 0.0377s/iter; left time: 704.2634s\n",
      "\titers: 200, epoch: 18 | loss: 0.0463988\n",
      "\tspeed: 0.0177s/iter; left time: 328.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0463835 Vali Loss: 0.0574036 Test Loss: 0.0591414\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0449952\n",
      "\tspeed: 0.0376s/iter; left time: 693.2720s\n",
      "\titers: 200, epoch: 19 | loss: 0.0478959\n",
      "\tspeed: 0.0178s/iter; left time: 326.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0457615 Vali Loss: 0.0572451 Test Loss: 0.0597154\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010480063036084175, rmse:0.1023721769452095, mae:0.058492016047239304, rse:0.38681402802467346\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1183293\n",
      "\tspeed: 0.0199s/iter; left time: 446.9918s\n",
      "\titers: 200, epoch: 1 | loss: 0.1023478\n",
      "\tspeed: 0.0182s/iter; left time: 408.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.1252369 Vali Loss: 0.0887429 Test Loss: 0.0913487\n",
      "Validation loss decreased (inf --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0721573\n",
      "\tspeed: 0.0391s/iter; left time: 870.0501s\n",
      "\titers: 200, epoch: 2 | loss: 0.0695804\n",
      "\tspeed: 0.0188s/iter; left time: 417.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0725251 Vali Loss: 0.0620892 Test Loss: 0.0651353\n",
      "Validation loss decreased (0.088743 --> 0.062089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0637120\n",
      "\tspeed: 0.0395s/iter; left time: 870.4122s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642457\n",
      "\tspeed: 0.0177s/iter; left time: 387.5393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0637578 Vali Loss: 0.0588995 Test Loss: 0.0622270\n",
      "Validation loss decreased (0.062089 --> 0.058899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0622228\n",
      "\tspeed: 0.0378s/iter; left time: 825.3745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0597051\n",
      "\tspeed: 0.0177s/iter; left time: 383.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 226 | Train Loss: 0.0611976 Vali Loss: 0.0583031 Test Loss: 0.0612591\n",
      "Validation loss decreased (0.058899 --> 0.058303).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569705\n",
      "\tspeed: 0.0424s/iter; left time: 915.5773s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624648\n",
      "\tspeed: 0.0178s/iter; left time: 381.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 226 | Train Loss: 0.0594146 Vali Loss: 0.0572613 Test Loss: 0.0605500\n",
      "Validation loss decreased (0.058303 --> 0.057261).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574250\n",
      "\tspeed: 0.0397s/iter; left time: 848.6427s\n",
      "\titers: 200, epoch: 6 | loss: 0.0574117\n",
      "\tspeed: 0.0176s/iter; left time: 374.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0580177 Vali Loss: 0.0570326 Test Loss: 0.0598851\n",
      "Validation loss decreased (0.057261 --> 0.057033).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562002\n",
      "\tspeed: 0.0383s/iter; left time: 809.9356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0591149\n",
      "\tspeed: 0.0184s/iter; left time: 387.6689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0568774 Vali Loss: 0.0560135 Test Loss: 0.0586588\n",
      "Validation loss decreased (0.057033 --> 0.056013).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573453\n",
      "\tspeed: 0.0382s/iter; left time: 798.0599s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589271\n",
      "\tspeed: 0.0178s/iter; left time: 371.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0557198 Vali Loss: 0.0562147 Test Loss: 0.0584597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0532231\n",
      "\tspeed: 0.0377s/iter; left time: 781.0276s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533374\n",
      "\tspeed: 0.0180s/iter; left time: 369.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0546067 Vali Loss: 0.0557521 Test Loss: 0.0584721\n",
      "Validation loss decreased (0.056013 --> 0.055752).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554328\n",
      "\tspeed: 0.0385s/iter; left time: 787.5572s\n",
      "\titers: 200, epoch: 10 | loss: 0.0529305\n",
      "\tspeed: 0.0177s/iter; left time: 359.6853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0534864 Vali Loss: 0.0556840 Test Loss: 0.0580632\n",
      "Validation loss decreased (0.055752 --> 0.055684).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0490568\n",
      "\tspeed: 0.0381s/iter; left time: 772.0579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579109\n",
      "\tspeed: 0.0181s/iter; left time: 364.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0524901 Vali Loss: 0.0556808 Test Loss: 0.0582837\n",
      "Validation loss decreased (0.055684 --> 0.055681).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0545119\n",
      "\tspeed: 0.0384s/iter; left time: 769.3993s\n",
      "\titers: 200, epoch: 12 | loss: 0.0526492\n",
      "\tspeed: 0.0177s/iter; left time: 351.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0515282 Vali Loss: 0.0556845 Test Loss: 0.0587237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0512061\n",
      "\tspeed: 0.0370s/iter; left time: 731.6856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0485435\n",
      "\tspeed: 0.0177s/iter; left time: 348.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0505559 Vali Loss: 0.0561550 Test Loss: 0.0583473\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505487\n",
      "\tspeed: 0.0368s/iter; left time: 719.7775s\n",
      "\titers: 200, epoch: 14 | loss: 0.0488571\n",
      "\tspeed: 0.0179s/iter; left time: 349.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0496760 Vali Loss: 0.0567544 Test Loss: 0.0589902\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0486834\n",
      "\tspeed: 0.0374s/iter; left time: 722.9436s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485694\n",
      "\tspeed: 0.0177s/iter; left time: 340.2375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0489163 Vali Loss: 0.0564030 Test Loss: 0.0587402\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0472454\n",
      "\tspeed: 0.0367s/iter; left time: 700.4890s\n",
      "\titers: 200, epoch: 16 | loss: 0.0488778\n",
      "\tspeed: 0.0177s/iter; left time: 336.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0480489 Vali Loss: 0.0567949 Test Loss: 0.0590802\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0461510\n",
      "\tspeed: 0.0385s/iter; left time: 727.4193s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470704\n",
      "\tspeed: 0.0194s/iter; left time: 364.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.0474308 Vali Loss: 0.0565297 Test Loss: 0.0589807\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0475236\n",
      "\tspeed: 0.0371s/iter; left time: 692.2523s\n",
      "\titers: 200, epoch: 18 | loss: 0.0432625\n",
      "\tspeed: 0.0176s/iter; left time: 327.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 226 | Train Loss: 0.0467678 Vali Loss: 0.0568878 Test Loss: 0.0593559\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0432556\n",
      "\tspeed: 0.0365s/iter; left time: 673.2113s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448248\n",
      "\tspeed: 0.0179s/iter; left time: 328.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0461628 Vali Loss: 0.0567260 Test Loss: 0.0594797\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0493075\n",
      "\tspeed: 0.0376s/iter; left time: 684.2777s\n",
      "\titers: 200, epoch: 20 | loss: 0.0476661\n",
      "\tspeed: 0.0177s/iter; left time: 319.8866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0458511 Vali Loss: 0.0567330 Test Loss: 0.0594195\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0462077\n",
      "\tspeed: 0.0365s/iter; left time: 656.7331s\n",
      "\titers: 200, epoch: 21 | loss: 0.0431399\n",
      "\tspeed: 0.0177s/iter; left time: 316.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 226 | Train Loss: 0.0453313 Vali Loss: 0.0569593 Test Loss: 0.0592954\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010335121303796768, rmse:0.1016618013381958, mae:0.058283690363168716, rse:0.3841298818588257\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:54.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1310730\n",
      "\tspeed: 0.0441s/iter; left time: 988.4177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159046\n",
      "\tspeed: 0.0181s/iter; left time: 402.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 225 | Train Loss: 0.1386889 Vali Loss: 0.1017228 Test Loss: 0.1046455\n",
      "Validation loss decreased (inf --> 0.101723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922018\n",
      "\tspeed: 0.0404s/iter; left time: 895.4513s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875287\n",
      "\tspeed: 0.0180s/iter; left time: 398.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0913242 Vali Loss: 0.0810804 Test Loss: 0.0859926\n",
      "Validation loss decreased (0.101723 --> 0.081080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851930\n",
      "\tspeed: 0.0403s/iter; left time: 884.8194s\n",
      "\titers: 200, epoch: 3 | loss: 0.0848009\n",
      "\tspeed: 0.0181s/iter; left time: 396.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0831508 Vali Loss: 0.0784393 Test Loss: 0.0841096\n",
      "Validation loss decreased (0.081080 --> 0.078439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810510\n",
      "\tspeed: 0.0400s/iter; left time: 868.2449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0782053\n",
      "\tspeed: 0.0180s/iter; left time: 389.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0795676 Vali Loss: 0.0784156 Test Loss: 0.0839126\n",
      "Validation loss decreased (0.078439 --> 0.078416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0816101\n",
      "\tspeed: 0.0390s/iter; left time: 839.4009s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721341\n",
      "\tspeed: 0.0180s/iter; left time: 385.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0762387 Vali Loss: 0.0790260 Test Loss: 0.0830072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0740837\n",
      "\tspeed: 0.0371s/iter; left time: 789.8721s\n",
      "\titers: 200, epoch: 6 | loss: 0.0762524\n",
      "\tspeed: 0.0187s/iter; left time: 395.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0728276 Vali Loss: 0.0801343 Test Loss: 0.0841383\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0702368\n",
      "\tspeed: 0.0367s/iter; left time: 773.1533s\n",
      "\titers: 200, epoch: 7 | loss: 0.0654386\n",
      "\tspeed: 0.0181s/iter; left time: 378.4053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 225 | Train Loss: 0.0698180 Vali Loss: 0.0802404 Test Loss: 0.0828267\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0711698\n",
      "\tspeed: 0.0373s/iter; left time: 776.2859s\n",
      "\titers: 200, epoch: 8 | loss: 0.0639507\n",
      "\tspeed: 0.0180s/iter; left time: 374.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0670037 Vali Loss: 0.0815448 Test Loss: 0.0840982\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627414\n",
      "\tspeed: 0.0377s/iter; left time: 776.9450s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609370\n",
      "\tspeed: 0.0181s/iter; left time: 370.0913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0644941 Vali Loss: 0.0811407 Test Loss: 0.0839700\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0619954\n",
      "\tspeed: 0.0373s/iter; left time: 760.0455s\n",
      "\titers: 200, epoch: 10 | loss: 0.0627662\n",
      "\tspeed: 0.0182s/iter; left time: 369.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0622920 Vali Loss: 0.0826805 Test Loss: 0.0853803\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642111\n",
      "\tspeed: 0.0370s/iter; left time: 745.9526s\n",
      "\titers: 200, epoch: 11 | loss: 0.0608653\n",
      "\tspeed: 0.0181s/iter; left time: 363.4407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0603079 Vali Loss: 0.0826404 Test Loss: 0.0851099\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0570892\n",
      "\tspeed: 0.0370s/iter; left time: 737.3791s\n",
      "\titers: 200, epoch: 12 | loss: 0.0618150\n",
      "\tspeed: 0.0180s/iter; left time: 357.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0586184 Vali Loss: 0.0831143 Test Loss: 0.0854465\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0575813\n",
      "\tspeed: 0.0384s/iter; left time: 756.6247s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571408\n",
      "\tspeed: 0.0191s/iter; left time: 374.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0572359 Vali Loss: 0.0832216 Test Loss: 0.0854676\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0556617\n",
      "\tspeed: 0.0372s/iter; left time: 723.8908s\n",
      "\titers: 200, epoch: 14 | loss: 0.0540459\n",
      "\tspeed: 0.0182s/iter; left time: 353.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0558948 Vali Loss: 0.0837388 Test Loss: 0.0862194\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954498514533043, rmse:0.13980337977409363, mae:0.08391264081001282, rse:0.5286116600036621\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1263471\n",
      "\tspeed: 0.0199s/iter; left time: 444.9298s\n",
      "\titers: 200, epoch: 1 | loss: 0.1159365\n",
      "\tspeed: 0.0182s/iter; left time: 404.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.1380923 Vali Loss: 0.1020415 Test Loss: 0.1047741\n",
      "Validation loss decreased (inf --> 0.102042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0909317\n",
      "\tspeed: 0.0410s/iter; left time: 908.6552s\n",
      "\titers: 200, epoch: 2 | loss: 0.0883571\n",
      "\tspeed: 0.0184s/iter; left time: 407.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0914261 Vali Loss: 0.0803037 Test Loss: 0.0852146\n",
      "Validation loss decreased (0.102042 --> 0.080304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0859512\n",
      "\tspeed: 0.0417s/iter; left time: 914.5156s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811047\n",
      "\tspeed: 0.0181s/iter; left time: 395.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0831277 Vali Loss: 0.0784896 Test Loss: 0.0827625\n",
      "Validation loss decreased (0.080304 --> 0.078490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0767060\n",
      "\tspeed: 0.0399s/iter; left time: 867.1353s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806868\n",
      "\tspeed: 0.0180s/iter; left time: 389.6694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 225 | Train Loss: 0.0796888 Vali Loss: 0.0783908 Test Loss: 0.0829460\n",
      "Validation loss decreased (0.078490 --> 0.078391).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777936\n",
      "\tspeed: 0.0400s/iter; left time: 859.3647s\n",
      "\titers: 200, epoch: 5 | loss: 0.0772324\n",
      "\tspeed: 0.0180s/iter; left time: 385.5814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0760393 Vali Loss: 0.0800801 Test Loss: 0.0835676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0714719\n",
      "\tspeed: 0.0381s/iter; left time: 809.8240s\n",
      "\titers: 200, epoch: 6 | loss: 0.0720436\n",
      "\tspeed: 0.0184s/iter; left time: 390.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0725466 Vali Loss: 0.0804555 Test Loss: 0.0829974\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0696251\n",
      "\tspeed: 0.0378s/iter; left time: 794.7793s\n",
      "\titers: 200, epoch: 7 | loss: 0.0676035\n",
      "\tspeed: 0.0182s/iter; left time: 381.2569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0692073 Vali Loss: 0.0817006 Test Loss: 0.0846338\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0691494\n",
      "\tspeed: 0.0382s/iter; left time: 796.2091s\n",
      "\titers: 200, epoch: 8 | loss: 0.0647662\n",
      "\tspeed: 0.0180s/iter; left time: 373.8621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0662966 Vali Loss: 0.0818667 Test Loss: 0.0849675\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623415\n",
      "\tspeed: 0.0374s/iter; left time: 770.5469s\n",
      "\titers: 200, epoch: 9 | loss: 0.0608835\n",
      "\tspeed: 0.0181s/iter; left time: 372.0792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0637759 Vali Loss: 0.0822691 Test Loss: 0.0853241\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0635078\n",
      "\tspeed: 0.0382s/iter; left time: 778.6474s\n",
      "\titers: 200, epoch: 10 | loss: 0.0581507\n",
      "\tspeed: 0.0181s/iter; left time: 366.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 225 | Train Loss: 0.0615833 Vali Loss: 0.0827696 Test Loss: 0.0859685\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572104\n",
      "\tspeed: 0.0378s/iter; left time: 761.9479s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578615\n",
      "\tspeed: 0.0183s/iter; left time: 367.3211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0598117 Vali Loss: 0.0834219 Test Loss: 0.0876955\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567229\n",
      "\tspeed: 0.0373s/iter; left time: 743.5879s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560101\n",
      "\tspeed: 0.0181s/iter; left time: 358.4102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 225 | Train Loss: 0.0581680 Vali Loss: 0.0832148 Test Loss: 0.0870609\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569095\n",
      "\tspeed: 0.0401s/iter; left time: 790.2327s\n",
      "\titers: 200, epoch: 13 | loss: 0.0528492\n",
      "\tspeed: 0.0182s/iter; left time: 356.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.54s\n",
      "Steps: 225 | Train Loss: 0.0568319 Vali Loss: 0.0832953 Test Loss: 0.0874218\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592510\n",
      "\tspeed: 0.0389s/iter; left time: 757.8687s\n",
      "\titers: 200, epoch: 14 | loss: 0.0547856\n",
      "\tspeed: 0.0185s/iter; left time: 358.7852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0558380 Vali Loss: 0.0831213 Test Loss: 0.0874076\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01917097717523575, rmse:0.13845929503440857, mae:0.08294600993394852, rse:0.5235295295715332\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:50.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1275234\n",
      "\tspeed: 0.0489s/iter; left time: 1095.7558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189954\n",
      "\tspeed: 0.0184s/iter; left time: 410.1009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.70s\n",
      "Steps: 225 | Train Loss: 0.1412950 Vali Loss: 0.1040635 Test Loss: 0.1070162\n",
      "Validation loss decreased (inf --> 0.104064).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964050\n",
      "\tspeed: 0.0446s/iter; left time: 988.6547s\n",
      "\titers: 200, epoch: 2 | loss: 0.0886111\n",
      "\tspeed: 0.0186s/iter; left time: 411.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0955518 Vali Loss: 0.0854652 Test Loss: 0.0895273\n",
      "Validation loss decreased (0.104064 --> 0.085465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0866833\n",
      "\tspeed: 0.0403s/iter; left time: 884.2453s\n",
      "\titers: 200, epoch: 3 | loss: 0.0814698\n",
      "\tspeed: 0.0184s/iter; left time: 401.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0871050 Vali Loss: 0.0848689 Test Loss: 0.0877781\n",
      "Validation loss decreased (0.085465 --> 0.084869).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0808554\n",
      "\tspeed: 0.0399s/iter; left time: 867.7698s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826341\n",
      "\tspeed: 0.0184s/iter; left time: 398.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0828756 Vali Loss: 0.0852374 Test Loss: 0.0874300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0791364\n",
      "\tspeed: 0.0395s/iter; left time: 849.4162s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785064\n",
      "\tspeed: 0.0188s/iter; left time: 402.0365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0790885 Vali Loss: 0.0861373 Test Loss: 0.0885819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774719\n",
      "\tspeed: 0.0388s/iter; left time: 826.0458s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751552\n",
      "\tspeed: 0.0185s/iter; left time: 391.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0760913 Vali Loss: 0.0866237 Test Loss: 0.0889733\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0741134\n",
      "\tspeed: 0.0385s/iter; left time: 811.0575s\n",
      "\titers: 200, epoch: 7 | loss: 0.0721804\n",
      "\tspeed: 0.0184s/iter; left time: 385.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0732284 Vali Loss: 0.0865928 Test Loss: 0.0902340\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724975\n",
      "\tspeed: 0.0382s/iter; left time: 795.6113s\n",
      "\titers: 200, epoch: 8 | loss: 0.0668545\n",
      "\tspeed: 0.0187s/iter; left time: 388.2034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0703631 Vali Loss: 0.0864248 Test Loss: 0.0899004\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685533\n",
      "\tspeed: 0.0388s/iter; left time: 799.9027s\n",
      "\titers: 200, epoch: 9 | loss: 0.0653959\n",
      "\tspeed: 0.0185s/iter; left time: 378.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0678736 Vali Loss: 0.0872525 Test Loss: 0.0919391\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666165\n",
      "\tspeed: 0.0386s/iter; left time: 787.0395s\n",
      "\titers: 200, epoch: 10 | loss: 0.0637973\n",
      "\tspeed: 0.0184s/iter; left time: 372.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0657089 Vali Loss: 0.0874528 Test Loss: 0.0922164\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0632579\n",
      "\tspeed: 0.0385s/iter; left time: 775.3910s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619213\n",
      "\tspeed: 0.0184s/iter; left time: 369.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0639057 Vali Loss: 0.0867941 Test Loss: 0.0914731\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624109\n",
      "\tspeed: 0.0389s/iter; left time: 774.8493s\n",
      "\titers: 200, epoch: 12 | loss: 0.0628552\n",
      "\tspeed: 0.0188s/iter; left time: 372.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0624616 Vali Loss: 0.0871244 Test Loss: 0.0930709\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0590759\n",
      "\tspeed: 0.0386s/iter; left time: 760.5655s\n",
      "\titers: 200, epoch: 13 | loss: 0.0594228\n",
      "\tspeed: 0.0184s/iter; left time: 360.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0609735 Vali Loss: 0.0873015 Test Loss: 0.0925411\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02027822844684124, rmse:0.14240165054798126, mae:0.0877780169248581, rse:0.5389363169670105\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1299536\n",
      "\tspeed: 0.0203s/iter; left time: 454.0323s\n",
      "\titers: 200, epoch: 1 | loss: 0.1161951\n",
      "\tspeed: 0.0184s/iter; left time: 410.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.1414682 Vali Loss: 0.1044085 Test Loss: 0.1074294\n",
      "Validation loss decreased (inf --> 0.104409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0972994\n",
      "\tspeed: 0.0414s/iter; left time: 918.8161s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901106\n",
      "\tspeed: 0.0184s/iter; left time: 406.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0957896 Vali Loss: 0.0854568 Test Loss: 0.0893396\n",
      "Validation loss decreased (0.104409 --> 0.085457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0885999\n",
      "\tspeed: 0.0417s/iter; left time: 915.1863s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868260\n",
      "\tspeed: 0.0189s/iter; left time: 414.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0873431 Vali Loss: 0.0845915 Test Loss: 0.0883179\n",
      "Validation loss decreased (0.085457 --> 0.084591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0882138\n",
      "\tspeed: 0.0415s/iter; left time: 901.0840s\n",
      "\titers: 200, epoch: 4 | loss: 0.0833410\n",
      "\tspeed: 0.0188s/iter; left time: 406.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0834392 Vali Loss: 0.0851915 Test Loss: 0.0894194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0792511\n",
      "\tspeed: 0.0394s/iter; left time: 846.8447s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755284\n",
      "\tspeed: 0.0187s/iter; left time: 400.5799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0796267 Vali Loss: 0.0848287 Test Loss: 0.0895064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0772265\n",
      "\tspeed: 0.0386s/iter; left time: 820.3110s\n",
      "\titers: 200, epoch: 6 | loss: 0.0731446\n",
      "\tspeed: 0.0184s/iter; left time: 389.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0765081 Vali Loss: 0.0859261 Test Loss: 0.0894576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0733916\n",
      "\tspeed: 0.0391s/iter; left time: 822.9563s\n",
      "\titers: 200, epoch: 7 | loss: 0.0741833\n",
      "\tspeed: 0.0184s/iter; left time: 386.3229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0736420 Vali Loss: 0.0860845 Test Loss: 0.0922697\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725332\n",
      "\tspeed: 0.0392s/iter; left time: 815.8906s\n",
      "\titers: 200, epoch: 8 | loss: 0.0704023\n",
      "\tspeed: 0.0184s/iter; left time: 380.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0709409 Vali Loss: 0.0858436 Test Loss: 0.0913357\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0673422\n",
      "\tspeed: 0.0397s/iter; left time: 817.1669s\n",
      "\titers: 200, epoch: 9 | loss: 0.0649461\n",
      "\tspeed: 0.0186s/iter; left time: 381.4714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.48s\n",
      "Steps: 225 | Train Loss: 0.0682619 Vali Loss: 0.0864067 Test Loss: 0.0929804\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0666464\n",
      "\tspeed: 0.0399s/iter; left time: 812.7487s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675855\n",
      "\tspeed: 0.0185s/iter; left time: 374.4364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0661923 Vali Loss: 0.0862028 Test Loss: 0.0925525\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0661159\n",
      "\tspeed: 0.0393s/iter; left time: 792.4639s\n",
      "\titers: 200, epoch: 11 | loss: 0.0636477\n",
      "\tspeed: 0.0185s/iter; left time: 371.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0644045 Vali Loss: 0.0867072 Test Loss: 0.0929461\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0620243\n",
      "\tspeed: 0.0391s/iter; left time: 779.0745s\n",
      "\titers: 200, epoch: 12 | loss: 0.0625289\n",
      "\tspeed: 0.0184s/iter; left time: 363.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.37s\n",
      "Steps: 225 | Train Loss: 0.0629564 Vali Loss: 0.0861273 Test Loss: 0.0923139\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0624796\n",
      "\tspeed: 0.0387s/iter; left time: 762.3120s\n",
      "\titers: 200, epoch: 13 | loss: 0.0605377\n",
      "\tspeed: 0.0184s/iter; left time: 360.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0615932 Vali Loss: 0.0867980 Test Loss: 0.0913889\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020756619051098824, rmse:0.1440715789794922, mae:0.08831792324781418, rse:0.5452563762664795\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:43.78s\n",
      "Intermediate time for IT: 00h:09m:29.43s\n",
      "Total time: 01h:17m:10.27s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            model_id = f\"channel_mixing_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0264  0.1626  0.1055\n",
       "        96        0.0448  0.2117  0.1447\n",
       "        168       0.0443  0.2104  0.1441\n",
       "ES      24        0.0115  0.1071  0.0677\n",
       "        96        0.0216  0.1469  0.0970\n",
       "        168       0.0236  0.1538  0.1034\n",
       "FR      24        0.0108  0.1039  0.0582\n",
       "        96        0.0196  0.1399  0.0831\n",
       "        168       0.0204  0.1429  0.0873\n",
       "GB      24        0.0289  0.1699  0.1154\n",
       "        96        0.0435  0.2085  0.1452\n",
       "        168       0.0456  0.2135  0.1499\n",
       "IT      24        0.0104  0.1020  0.0584\n",
       "        96        0.0194  0.1391  0.0834\n",
       "        168       0.0205  0.1432  0.0880"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1107970\n",
      "\tspeed: 0.0794s/iter; left time: 1787.3521s\n",
      "\titers: 200, epoch: 1 | loss: 0.0986829\n",
      "\tspeed: 0.0535s/iter; left time: 1199.0304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 226 | Train Loss: 0.1157395 Vali Loss: 0.1076960 Test Loss: 0.1105589\n",
      "Validation loss decreased (inf --> 0.107696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0841662\n",
      "\tspeed: 0.0998s/iter; left time: 2223.5783s\n",
      "\titers: 200, epoch: 2 | loss: 0.0774007\n",
      "\tspeed: 0.0536s/iter; left time: 1189.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.34s\n",
      "Steps: 226 | Train Loss: 0.0834303 Vali Loss: 0.0951717 Test Loss: 0.0983893\n",
      "Validation loss decreased (0.107696 --> 0.095172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795393\n",
      "\tspeed: 0.0999s/iter; left time: 2202.1801s\n",
      "\titers: 200, epoch: 3 | loss: 0.0760526\n",
      "\tspeed: 0.0537s/iter; left time: 1178.0717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.32s\n",
      "Steps: 226 | Train Loss: 0.0750043 Vali Loss: 0.0966898 Test Loss: 0.1009059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0720751\n",
      "\tspeed: 0.0951s/iter; left time: 2075.5827s\n",
      "\titers: 200, epoch: 4 | loss: 0.0661474\n",
      "\tspeed: 0.0536s/iter; left time: 1164.9304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.35s\n",
      "Steps: 226 | Train Loss: 0.0688003 Vali Loss: 0.0998325 Test Loss: 0.1049393\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602776\n",
      "\tspeed: 0.0952s/iter; left time: 2055.1461s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615162\n",
      "\tspeed: 0.0537s/iter; left time: 1153.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 226 | Train Loss: 0.0612638 Vali Loss: 0.1016257 Test Loss: 0.1059316\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0569761\n",
      "\tspeed: 0.0955s/iter; left time: 2040.9632s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536489\n",
      "\tspeed: 0.0544s/iter; left time: 1157.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0556323 Vali Loss: 0.1015170 Test Loss: 0.1060266\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0515332\n",
      "\tspeed: 0.0951s/iter; left time: 2010.9353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0494139\n",
      "\tspeed: 0.0541s/iter; left time: 1138.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0510429 Vali Loss: 0.1021425 Test Loss: 0.1076099\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0495531\n",
      "\tspeed: 0.0952s/iter; left time: 1992.1008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448377\n",
      "\tspeed: 0.0541s/iter; left time: 1127.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0476645 Vali Loss: 0.1027132 Test Loss: 0.1065381\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0459595\n",
      "\tspeed: 0.0953s/iter; left time: 1972.3700s\n",
      "\titers: 200, epoch: 9 | loss: 0.0421387\n",
      "\tspeed: 0.0542s/iter; left time: 1116.0509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0448068 Vali Loss: 0.1028465 Test Loss: 0.1067780\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0415524\n",
      "\tspeed: 0.0951s/iter; left time: 1946.3540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0411832\n",
      "\tspeed: 0.0541s/iter; left time: 1102.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0425342 Vali Loss: 0.1018840 Test Loss: 0.1059912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0416039\n",
      "\tspeed: 0.0952s/iter; left time: 1927.1704s\n",
      "\titers: 200, epoch: 11 | loss: 0.0400221\n",
      "\tspeed: 0.0541s/iter; left time: 1090.4274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0406519 Vali Loss: 0.1015919 Test Loss: 0.1061520\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0380639\n",
      "\tspeed: 0.0954s/iter; left time: 1909.5089s\n",
      "\titers: 200, epoch: 12 | loss: 0.0371491\n",
      "\tspeed: 0.0542s/iter; left time: 1079.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0392447 Vali Loss: 0.1015829 Test Loss: 0.1071503\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02388782985508442, rmse:0.15455688536167145, mae:0.09838932752609253, rse:0.5454525947570801\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1082842\n",
      "\tspeed: 0.0561s/iter; left time: 1263.0431s\n",
      "\titers: 200, epoch: 1 | loss: 0.0992054\n",
      "\tspeed: 0.0540s/iter; left time: 1210.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 226 | Train Loss: 0.1151996 Vali Loss: 0.1069883 Test Loss: 0.1096331\n",
      "Validation loss decreased (inf --> 0.106988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0803967\n",
      "\tspeed: 0.1008s/iter; left time: 2244.7057s\n",
      "\titers: 200, epoch: 2 | loss: 0.0791126\n",
      "\tspeed: 0.0540s/iter; left time: 1198.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0834008 Vali Loss: 0.0945991 Test Loss: 0.0977492\n",
      "Validation loss decreased (0.106988 --> 0.094599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714960\n",
      "\tspeed: 0.1030s/iter; left time: 2271.0061s\n",
      "\titers: 200, epoch: 3 | loss: 0.0756860\n",
      "\tspeed: 0.0540s/iter; left time: 1185.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0754395 Vali Loss: 0.0975378 Test Loss: 0.1006314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0673068\n",
      "\tspeed: 0.0954s/iter; left time: 2080.9198s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649566\n",
      "\tspeed: 0.0540s/iter; left time: 1174.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0687112 Vali Loss: 0.0975886 Test Loss: 0.1047010\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0601761\n",
      "\tspeed: 0.0953s/iter; left time: 2057.2955s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578993\n",
      "\tspeed: 0.0541s/iter; left time: 1163.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0612437 Vali Loss: 0.1002051 Test Loss: 0.1077436\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0574794\n",
      "\tspeed: 0.0961s/iter; left time: 2053.4366s\n",
      "\titers: 200, epoch: 6 | loss: 0.0536630\n",
      "\tspeed: 0.0539s/iter; left time: 1147.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0554973 Vali Loss: 0.1027811 Test Loss: 0.1079550\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504069\n",
      "\tspeed: 0.0958s/iter; left time: 2024.7226s\n",
      "\titers: 200, epoch: 7 | loss: 0.0509556\n",
      "\tspeed: 0.0539s/iter; left time: 1134.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0511312 Vali Loss: 0.1025358 Test Loss: 0.1072150\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0472141\n",
      "\tspeed: 0.0962s/iter; left time: 2012.6802s\n",
      "\titers: 200, epoch: 8 | loss: 0.0481741\n",
      "\tspeed: 0.0540s/iter; left time: 1123.5094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0475666 Vali Loss: 0.1019304 Test Loss: 0.1083649\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0450273\n",
      "\tspeed: 0.0969s/iter; left time: 2004.3318s\n",
      "\titers: 200, epoch: 9 | loss: 0.0434829\n",
      "\tspeed: 0.0541s/iter; left time: 1113.2474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.49s\n",
      "Steps: 226 | Train Loss: 0.0448368 Vali Loss: 0.1018909 Test Loss: 0.1080132\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0430186\n",
      "\tspeed: 0.0957s/iter; left time: 1958.0993s\n",
      "\titers: 200, epoch: 10 | loss: 0.0416615\n",
      "\tspeed: 0.0539s/iter; left time: 1098.7068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0426283 Vali Loss: 0.1012360 Test Loss: 0.1075009\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417660\n",
      "\tspeed: 0.0956s/iter; left time: 1935.5663s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401521\n",
      "\tspeed: 0.0539s/iter; left time: 1085.3783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0407016 Vali Loss: 0.1029636 Test Loss: 0.1072257\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0372848\n",
      "\tspeed: 0.0954s/iter; left time: 1908.5510s\n",
      "\titers: 200, epoch: 12 | loss: 0.0385782\n",
      "\tspeed: 0.0541s/iter; left time: 1077.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0391586 Vali Loss: 0.1025802 Test Loss: 0.1081261\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.023594284430146217, rmse:0.15360431373119354, mae:0.09774922579526901, rse:0.5420908331871033\n",
      "Intermediate time for DE and pred_len 24: 00h:06m:13.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1333143\n",
      "\tspeed: 0.0806s/iter; left time: 1805.6530s\n",
      "\titers: 200, epoch: 1 | loss: 0.1251937\n",
      "\tspeed: 0.0548s/iter; left time: 1222.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 225 | Train Loss: 0.1350754 Vali Loss: 0.1330616 Test Loss: 0.1428668\n",
      "Validation loss decreased (inf --> 0.133062).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1077519\n",
      "\tspeed: 0.1036s/iter; left time: 2297.4763s\n",
      "\titers: 200, epoch: 2 | loss: 0.0975782\n",
      "\tspeed: 0.0544s/iter; left time: 1200.9055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 225 | Train Loss: 0.1053988 Vali Loss: 0.1278307 Test Loss: 0.1397810\n",
      "Validation loss decreased (0.133062 --> 0.127831).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860106\n",
      "\tspeed: 0.1036s/iter; left time: 2274.4440s\n",
      "\titers: 200, epoch: 3 | loss: 0.0802355\n",
      "\tspeed: 0.0545s/iter; left time: 1190.4863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0869836 Vali Loss: 0.1320381 Test Loss: 0.1464900\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0748803\n",
      "\tspeed: 0.0968s/iter; left time: 2104.0879s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696452\n",
      "\tspeed: 0.0545s/iter; left time: 1178.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.49s\n",
      "Steps: 225 | Train Loss: 0.0740799 Vali Loss: 0.1308142 Test Loss: 0.1466282\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0646656\n",
      "\tspeed: 0.0961s/iter; left time: 2066.0537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0625145\n",
      "\tspeed: 0.0546s/iter; left time: 1167.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0652217 Vali Loss: 0.1311752 Test Loss: 0.1460544\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605387\n",
      "\tspeed: 0.0965s/iter; left time: 2053.7771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0579678\n",
      "\tspeed: 0.0544s/iter; left time: 1151.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 225 | Train Loss: 0.0588902 Vali Loss: 0.1316790 Test Loss: 0.1448181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0562061\n",
      "\tspeed: 0.0966s/iter; left time: 2034.3241s\n",
      "\titers: 200, epoch: 7 | loss: 0.0527901\n",
      "\tspeed: 0.0546s/iter; left time: 1144.2604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0545442 Vali Loss: 0.1316228 Test Loss: 0.1457958\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0522657\n",
      "\tspeed: 0.0965s/iter; left time: 2008.8307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0514421\n",
      "\tspeed: 0.0547s/iter; left time: 1134.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0511548 Vali Loss: 0.1304799 Test Loss: 0.1432248\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0498829\n",
      "\tspeed: 0.0962s/iter; left time: 1982.7809s\n",
      "\titers: 200, epoch: 9 | loss: 0.0493235\n",
      "\tspeed: 0.0547s/iter; left time: 1121.2013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0482738 Vali Loss: 0.1298701 Test Loss: 0.1443696\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0474373\n",
      "\tspeed: 0.0965s/iter; left time: 1966.1923s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442286\n",
      "\tspeed: 0.0548s/iter; left time: 1110.2221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0461018 Vali Loss: 0.1297597 Test Loss: 0.1427234\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0449542\n",
      "\tspeed: 0.0969s/iter; left time: 1952.0446s\n",
      "\titers: 200, epoch: 11 | loss: 0.0443833\n",
      "\tspeed: 0.0547s/iter; left time: 1096.9436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0443575 Vali Loss: 0.1303327 Test Loss: 0.1435535\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0436924\n",
      "\tspeed: 0.0974s/iter; left time: 1941.4671s\n",
      "\titers: 200, epoch: 12 | loss: 0.0425764\n",
      "\tspeed: 0.0548s/iter; left time: 1086.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0428586 Vali Loss: 0.1291575 Test Loss: 0.1419588\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044566426426172256, rmse:0.21110761165618896, mae:0.1397809535264969, rse:0.7475747466087341\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1305004\n",
      "\tspeed: 0.0564s/iter; left time: 1263.9093s\n",
      "\titers: 200, epoch: 1 | loss: 0.1234168\n",
      "\tspeed: 0.0547s/iter; left time: 1219.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.1356182 Vali Loss: 0.1333102 Test Loss: 0.1427393\n",
      "Validation loss decreased (inf --> 0.133310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052246\n",
      "\tspeed: 0.1048s/iter; left time: 2325.0453s\n",
      "\titers: 200, epoch: 2 | loss: 0.0998564\n",
      "\tspeed: 0.0545s/iter; left time: 1203.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 225 | Train Loss: 0.1051226 Vali Loss: 0.1262625 Test Loss: 0.1385605\n",
      "Validation loss decreased (0.133310 --> 0.126263).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0880758\n",
      "\tspeed: 0.1062s/iter; left time: 2331.4872s\n",
      "\titers: 200, epoch: 3 | loss: 0.0775143\n",
      "\tspeed: 0.0546s/iter; left time: 1194.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.88s\n",
      "Steps: 225 | Train Loss: 0.0872053 Vali Loss: 0.1273492 Test Loss: 0.1457350\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774589\n",
      "\tspeed: 0.0975s/iter; left time: 2117.5109s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696527\n",
      "\tspeed: 0.0545s/iter; left time: 1178.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0750550 Vali Loss: 0.1297122 Test Loss: 0.1456257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0676311\n",
      "\tspeed: 0.0973s/iter; left time: 2091.6429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0631000\n",
      "\tspeed: 0.0545s/iter; left time: 1167.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0665385 Vali Loss: 0.1299191 Test Loss: 0.1467704\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0633564\n",
      "\tspeed: 0.0966s/iter; left time: 2056.2984s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616689\n",
      "\tspeed: 0.0545s/iter; left time: 1153.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.48s\n",
      "Steps: 225 | Train Loss: 0.0604947 Vali Loss: 0.1298159 Test Loss: 0.1456453\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0547417\n",
      "\tspeed: 0.0975s/iter; left time: 2052.0712s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547419\n",
      "\tspeed: 0.0547s/iter; left time: 1145.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0559934 Vali Loss: 0.1316791 Test Loss: 0.1468673\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542285\n",
      "\tspeed: 0.0974s/iter; left time: 2028.6788s\n",
      "\titers: 200, epoch: 8 | loss: 0.0505886\n",
      "\tspeed: 0.0546s/iter; left time: 1132.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0523586 Vali Loss: 0.1305334 Test Loss: 0.1449758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0514340\n",
      "\tspeed: 0.0974s/iter; left time: 2007.4988s\n",
      "\titers: 200, epoch: 9 | loss: 0.0490581\n",
      "\tspeed: 0.0547s/iter; left time: 1120.5801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0495374 Vali Loss: 0.1299654 Test Loss: 0.1441714\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0458724\n",
      "\tspeed: 0.0978s/iter; left time: 1992.7452s\n",
      "\titers: 200, epoch: 10 | loss: 0.0471989\n",
      "\tspeed: 0.0545s/iter; left time: 1104.7199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0471732 Vali Loss: 0.1310883 Test Loss: 0.1436499\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0456801\n",
      "\tspeed: 0.0969s/iter; left time: 1952.2006s\n",
      "\titers: 200, epoch: 11 | loss: 0.0444907\n",
      "\tspeed: 0.0547s/iter; left time: 1096.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 225 | Train Loss: 0.0452869 Vali Loss: 0.1306960 Test Loss: 0.1433874\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460896\n",
      "\tspeed: 0.0975s/iter; left time: 1942.0439s\n",
      "\titers: 200, epoch: 12 | loss: 0.0449634\n",
      "\tspeed: 0.0547s/iter; left time: 1083.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.50s\n",
      "Steps: 225 | Train Loss: 0.0437059 Vali Loss: 0.1303346 Test Loss: 0.1430011\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043655913323163986, rmse:0.20893996953964233, mae:0.13856051862239838, rse:0.739898681640625\n",
      "Intermediate time for DE and pred_len 96: 00h:06m:20.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1406612\n",
      "\tspeed: 0.0813s/iter; left time: 1821.9597s\n",
      "\titers: 200, epoch: 1 | loss: 0.1266166\n",
      "\tspeed: 0.0553s/iter; left time: 1232.1315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.01s\n",
      "Steps: 225 | Train Loss: 0.1407489 Vali Loss: 0.1362887 Test Loss: 0.1475281\n",
      "Validation loss decreased (inf --> 0.136289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1123547\n",
      "\tspeed: 0.1060s/iter; left time: 2350.5852s\n",
      "\titers: 200, epoch: 2 | loss: 0.0998369\n",
      "\tspeed: 0.0553s/iter; left time: 1220.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.67s\n",
      "Steps: 225 | Train Loss: 0.1102064 Vali Loss: 0.1288327 Test Loss: 0.1476617\n",
      "Validation loss decreased (0.136289 --> 0.128833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0934906\n",
      "\tspeed: 0.1184s/iter; left time: 2598.1191s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850151\n",
      "\tspeed: 0.0554s/iter; left time: 1210.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 225 | Train Loss: 0.0920240 Vali Loss: 0.1323475 Test Loss: 0.1512921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0801055\n",
      "\tspeed: 0.0994s/iter; left time: 2160.4869s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753021\n",
      "\tspeed: 0.0555s/iter; left time: 1200.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0791172 Vali Loss: 0.1329665 Test Loss: 0.1495522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0717403\n",
      "\tspeed: 0.0992s/iter; left time: 2132.2386s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685390\n",
      "\tspeed: 0.0556s/iter; left time: 1189.6771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 225 | Train Loss: 0.0701019 Vali Loss: 0.1331651 Test Loss: 0.1500273\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647874\n",
      "\tspeed: 0.0989s/iter; left time: 2103.4644s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620601\n",
      "\tspeed: 0.0556s/iter; left time: 1178.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0636788 Vali Loss: 0.1325531 Test Loss: 0.1488694\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585716\n",
      "\tspeed: 0.0991s/iter; left time: 2085.4736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0574709\n",
      "\tspeed: 0.0557s/iter; left time: 1167.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0588663 Vali Loss: 0.1338743 Test Loss: 0.1497303\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0562231\n",
      "\tspeed: 0.0985s/iter; left time: 2050.5653s\n",
      "\titers: 200, epoch: 8 | loss: 0.0539397\n",
      "\tspeed: 0.0556s/iter; left time: 1151.5509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0549779 Vali Loss: 0.1326314 Test Loss: 0.1489142\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546246\n",
      "\tspeed: 0.0988s/iter; left time: 2035.7260s\n",
      "\titers: 200, epoch: 9 | loss: 0.0511219\n",
      "\tspeed: 0.0557s/iter; left time: 1141.8989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0518904 Vali Loss: 0.1327110 Test Loss: 0.1492718\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0489933\n",
      "\tspeed: 0.0993s/iter; left time: 2023.4093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495632\n",
      "\tspeed: 0.0563s/iter; left time: 1141.1064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.0496443 Vali Loss: 0.1329360 Test Loss: 0.1487178\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491020\n",
      "\tspeed: 0.0983s/iter; left time: 1981.3276s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463657\n",
      "\tspeed: 0.0554s/iter; left time: 1111.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.69s\n",
      "Steps: 225 | Train Loss: 0.0475663 Vali Loss: 0.1323775 Test Loss: 0.1490079\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0458864\n",
      "\tspeed: 0.0993s/iter; left time: 1979.5693s\n",
      "\titers: 200, epoch: 12 | loss: 0.0459646\n",
      "\tspeed: 0.0557s/iter; left time: 1103.9773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0460691 Vali Loss: 0.1317336 Test Loss: 0.1486037\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04906906932592392, rmse:0.22151538729667664, mae:0.1476617008447647, rse:0.7846253514289856\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1341049\n",
      "\tspeed: 0.0573s/iter; left time: 1284.2875s\n",
      "\titers: 200, epoch: 1 | loss: 0.1229856\n",
      "\tspeed: 0.0554s/iter; left time: 1235.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.1405741 Vali Loss: 0.1368361 Test Loss: 0.1474738\n",
      "Validation loss decreased (inf --> 0.136836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093229\n",
      "\tspeed: 0.1060s/iter; left time: 2349.5772s\n",
      "\titers: 200, epoch: 2 | loss: 0.1050066\n",
      "\tspeed: 0.0555s/iter; left time: 1225.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.1096052 Vali Loss: 0.1309860 Test Loss: 0.1463656\n",
      "Validation loss decreased (0.136836 --> 0.130986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0980805\n",
      "\tspeed: 0.1082s/iter; left time: 2375.5044s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870968\n",
      "\tspeed: 0.0556s/iter; left time: 1214.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0911647 Vali Loss: 0.1292951 Test Loss: 0.1477515\n",
      "Validation loss decreased (0.130986 --> 0.129295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790136\n",
      "\tspeed: 0.1057s/iter; left time: 2297.1184s\n",
      "\titers: 200, epoch: 4 | loss: 0.0775671\n",
      "\tspeed: 0.0553s/iter; left time: 1195.1313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0795131 Vali Loss: 0.1314423 Test Loss: 0.1489823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0720552\n",
      "\tspeed: 0.0998s/iter; left time: 2145.9261s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685515\n",
      "\tspeed: 0.0556s/iter; left time: 1190.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0707013 Vali Loss: 0.1314861 Test Loss: 0.1465668\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0642642\n",
      "\tspeed: 0.1004s/iter; left time: 2136.9772s\n",
      "\titers: 200, epoch: 6 | loss: 0.0629607\n",
      "\tspeed: 0.0557s/iter; left time: 1179.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.81s\n",
      "Steps: 225 | Train Loss: 0.0642900 Vali Loss: 0.1314789 Test Loss: 0.1468510\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0586436\n",
      "\tspeed: 0.0995s/iter; left time: 2094.8741s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583489\n",
      "\tspeed: 0.0557s/iter; left time: 1167.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.75s\n",
      "Steps: 225 | Train Loss: 0.0594529 Vali Loss: 0.1322349 Test Loss: 0.1468181\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0529839\n",
      "\tspeed: 0.1001s/iter; left time: 2084.4608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0555473\n",
      "\tspeed: 0.0558s/iter; left time: 1156.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0556102 Vali Loss: 0.1325815 Test Loss: 0.1473669\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0529180\n",
      "\tspeed: 0.1001s/iter; left time: 2062.4197s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533149\n",
      "\tspeed: 0.0557s/iter; left time: 1141.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.79s\n",
      "Steps: 225 | Train Loss: 0.0525686 Vali Loss: 0.1319998 Test Loss: 0.1462125\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0504318\n",
      "\tspeed: 0.1009s/iter; left time: 2055.8093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495035\n",
      "\tspeed: 0.0558s/iter; left time: 1131.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0500964 Vali Loss: 0.1321188 Test Loss: 0.1462528\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0475139\n",
      "\tspeed: 0.1005s/iter; left time: 2025.5498s\n",
      "\titers: 200, epoch: 11 | loss: 0.0480725\n",
      "\tspeed: 0.0558s/iter; left time: 1119.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 225 | Train Loss: 0.0480424 Vali Loss: 0.1319406 Test Loss: 0.1465782\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0473353\n",
      "\tspeed: 0.0999s/iter; left time: 1991.1849s\n",
      "\titers: 200, epoch: 12 | loss: 0.0451364\n",
      "\tspeed: 0.0557s/iter; left time: 1104.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0465250 Vali Loss: 0.1323243 Test Loss: 0.1460133\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0460064\n",
      "\tspeed: 0.0999s/iter; left time: 1968.4834s\n",
      "\titers: 200, epoch: 13 | loss: 0.0453575\n",
      "\tspeed: 0.0558s/iter; left time: 1093.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.0450981 Vali Loss: 0.1323807 Test Loss: 0.1469318\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048308685421943665, rmse:0.21979236602783203, mae:0.14775153994560242, rse:0.778522253036499\n",
      "Intermediate time for DE and pred_len 168: 00h:06m:46.33s\n",
      "Intermediate time for DE: 00h:19m:20.46s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1072044\n",
      "\tspeed: 0.0786s/iter; left time: 1767.6743s\n",
      "\titers: 200, epoch: 1 | loss: 0.0951643\n",
      "\tspeed: 0.0540s/iter; left time: 1209.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 226 | Train Loss: 0.1079968 Vali Loss: 0.1030718 Test Loss: 0.1146087\n",
      "Validation loss decreased (inf --> 0.103072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0816555\n",
      "\tspeed: 0.0995s/iter; left time: 2217.3235s\n",
      "\titers: 200, epoch: 2 | loss: 0.0808995\n",
      "\tspeed: 0.0537s/iter; left time: 1190.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0827446 Vali Loss: 0.0940444 Test Loss: 0.1063824\n",
      "Validation loss decreased (0.103072 --> 0.094044).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0760829\n",
      "\tspeed: 0.1000s/iter; left time: 2205.3408s\n",
      "\titers: 200, epoch: 3 | loss: 0.0732299\n",
      "\tspeed: 0.0539s/iter; left time: 1184.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.35s\n",
      "Steps: 226 | Train Loss: 0.0766084 Vali Loss: 0.0963815 Test Loss: 0.1070990\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731442\n",
      "\tspeed: 0.0958s/iter; left time: 2090.6086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649460\n",
      "\tspeed: 0.0538s/iter; left time: 1169.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0708761 Vali Loss: 0.1001709 Test Loss: 0.1115133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0635758\n",
      "\tspeed: 0.0943s/iter; left time: 2036.2944s\n",
      "\titers: 200, epoch: 5 | loss: 0.0592086\n",
      "\tspeed: 0.0538s/iter; left time: 1157.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.37s\n",
      "Steps: 226 | Train Loss: 0.0635158 Vali Loss: 0.1023092 Test Loss: 0.1153543\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608806\n",
      "\tspeed: 0.0952s/iter; left time: 2034.2306s\n",
      "\titers: 200, epoch: 6 | loss: 0.0543686\n",
      "\tspeed: 0.0538s/iter; left time: 1144.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.38s\n",
      "Steps: 226 | Train Loss: 0.0576630 Vali Loss: 0.1039233 Test Loss: 0.1179941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0538294\n",
      "\tspeed: 0.0950s/iter; left time: 2009.7429s\n",
      "\titers: 200, epoch: 7 | loss: 0.0526221\n",
      "\tspeed: 0.0539s/iter; left time: 1134.9935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.41s\n",
      "Steps: 226 | Train Loss: 0.0529325 Vali Loss: 0.1035913 Test Loss: 0.1165399\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0469315\n",
      "\tspeed: 0.0957s/iter; left time: 2001.8665s\n",
      "\titers: 200, epoch: 8 | loss: 0.0458908\n",
      "\tspeed: 0.0539s/iter; left time: 1122.2282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.41s\n",
      "Steps: 226 | Train Loss: 0.0494196 Vali Loss: 0.1039378 Test Loss: 0.1181313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0466256\n",
      "\tspeed: 0.0954s/iter; left time: 1975.0582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0455476\n",
      "\tspeed: 0.0539s/iter; left time: 1110.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.39s\n",
      "Steps: 226 | Train Loss: 0.0467545 Vali Loss: 0.1043459 Test Loss: 0.1177842\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0431702\n",
      "\tspeed: 0.0952s/iter; left time: 1948.8309s\n",
      "\titers: 200, epoch: 10 | loss: 0.0449245\n",
      "\tspeed: 0.0539s/iter; left time: 1098.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0445734 Vali Loss: 0.1038292 Test Loss: 0.1176439\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0421189\n",
      "\tspeed: 0.0948s/iter; left time: 1919.5672s\n",
      "\titers: 200, epoch: 11 | loss: 0.0424473\n",
      "\tspeed: 0.0538s/iter; left time: 1083.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.36s\n",
      "Steps: 226 | Train Loss: 0.0426050 Vali Loss: 0.1039291 Test Loss: 0.1180243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0409853\n",
      "\tspeed: 0.0952s/iter; left time: 1904.4688s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414068\n",
      "\tspeed: 0.0539s/iter; left time: 1073.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.40s\n",
      "Steps: 226 | Train Loss: 0.0411548 Vali Loss: 0.1045172 Test Loss: 0.1169467\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026635607704520226, rmse:0.16320419311523438, mae:0.10638243705034256, rse:0.563008189201355\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1042103\n",
      "\tspeed: 0.0561s/iter; left time: 1261.4758s\n",
      "\titers: 200, epoch: 1 | loss: 0.0932506\n",
      "\tspeed: 0.0539s/iter; left time: 1206.5628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.1075098 Vali Loss: 0.1026871 Test Loss: 0.1146050\n",
      "Validation loss decreased (inf --> 0.102687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0827916\n",
      "\tspeed: 0.1014s/iter; left time: 2257.7162s\n",
      "\titers: 200, epoch: 2 | loss: 0.0818547\n",
      "\tspeed: 0.0539s/iter; left time: 1194.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0825427 Vali Loss: 0.0944417 Test Loss: 0.1071549\n",
      "Validation loss decreased (0.102687 --> 0.094442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0784460\n",
      "\tspeed: 0.1054s/iter; left time: 2323.6474s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800908\n",
      "\tspeed: 0.0542s/iter; left time: 1188.9930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 226 | Train Loss: 0.0764160 Vali Loss: 0.0986362 Test Loss: 0.1106796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0702497\n",
      "\tspeed: 0.0965s/iter; left time: 2105.3325s\n",
      "\titers: 200, epoch: 4 | loss: 0.0669691\n",
      "\tspeed: 0.0545s/iter; left time: 1183.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.47s\n",
      "Steps: 226 | Train Loss: 0.0708451 Vali Loss: 0.1004043 Test Loss: 0.1111616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0623640\n",
      "\tspeed: 0.0961s/iter; left time: 2075.6338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600077\n",
      "\tspeed: 0.0539s/iter; left time: 1158.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 226 | Train Loss: 0.0637427 Vali Loss: 0.1038250 Test Loss: 0.1157895\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0550858\n",
      "\tspeed: 0.0959s/iter; left time: 2050.1717s\n",
      "\titers: 200, epoch: 6 | loss: 0.0539705\n",
      "\tspeed: 0.0539s/iter; left time: 1146.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0573438 Vali Loss: 0.1033683 Test Loss: 0.1150562\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0536134\n",
      "\tspeed: 0.0968s/iter; left time: 2047.0676s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535443\n",
      "\tspeed: 0.0541s/iter; left time: 1138.5853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 226 | Train Loss: 0.0528843 Vali Loss: 0.1041554 Test Loss: 0.1172957\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0484644\n",
      "\tspeed: 0.0965s/iter; left time: 2019.0239s\n",
      "\titers: 200, epoch: 8 | loss: 0.0483736\n",
      "\tspeed: 0.0540s/iter; left time: 1123.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.44s\n",
      "Steps: 226 | Train Loss: 0.0493472 Vali Loss: 0.1026578 Test Loss: 0.1171316\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0469961\n",
      "\tspeed: 0.0967s/iter; left time: 2000.5807s\n",
      "\titers: 200, epoch: 9 | loss: 0.0460768\n",
      "\tspeed: 0.0540s/iter; left time: 1112.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 226 | Train Loss: 0.0465694 Vali Loss: 0.1035185 Test Loss: 0.1190842\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0451379\n",
      "\tspeed: 0.0964s/iter; left time: 1972.4274s\n",
      "\titers: 200, epoch: 10 | loss: 0.0406100\n",
      "\tspeed: 0.0539s/iter; left time: 1096.7785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.42s\n",
      "Steps: 226 | Train Loss: 0.0443786 Vali Loss: 0.1039430 Test Loss: 0.1190374\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0438192\n",
      "\tspeed: 0.0959s/iter; left time: 1940.1868s\n",
      "\titers: 200, epoch: 11 | loss: 0.0421218\n",
      "\tspeed: 0.0555s/iter; left time: 1117.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.57s\n",
      "Steps: 226 | Train Loss: 0.0426470 Vali Loss: 0.1028817 Test Loss: 0.1179599\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0415459\n",
      "\tspeed: 0.0964s/iter; left time: 1929.2857s\n",
      "\titers: 200, epoch: 12 | loss: 0.0380141\n",
      "\tspeed: 0.0539s/iter; left time: 1073.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.43s\n",
      "Steps: 226 | Train Loss: 0.0410800 Vali Loss: 0.1028472 Test Loss: 0.1175687\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02711082622408867, rmse:0.16465365886688232, mae:0.10715489089488983, rse:0.5680084228515625\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:14.38s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1224959\n",
      "\tspeed: 0.0794s/iter; left time: 1778.2693s\n",
      "\titers: 200, epoch: 1 | loss: 0.1160363\n",
      "\tspeed: 0.0544s/iter; left time: 1212.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.80s\n",
      "Steps: 225 | Train Loss: 0.1264180 Vali Loss: 0.1264964 Test Loss: 0.1495192\n",
      "Validation loss decreased (inf --> 0.126496).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1015343\n",
      "\tspeed: 0.1027s/iter; left time: 2276.9056s\n",
      "\titers: 200, epoch: 2 | loss: 0.0967856\n",
      "\tspeed: 0.0543s/iter; left time: 1198.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.45s\n",
      "Steps: 225 | Train Loss: 0.1042453 Vali Loss: 0.1274836 Test Loss: 0.1481230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0864128\n",
      "\tspeed: 0.0965s/iter; left time: 2117.5043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0791574\n",
      "\tspeed: 0.0546s/iter; left time: 1192.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0861891 Vali Loss: 0.1317791 Test Loss: 0.1499434\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0738536\n",
      "\tspeed: 0.0977s/iter; left time: 2123.5571s\n",
      "\titers: 200, epoch: 4 | loss: 0.0709162\n",
      "\tspeed: 0.0548s/iter; left time: 1184.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 225 | Train Loss: 0.0740018 Vali Loss: 0.1332169 Test Loss: 0.1512938\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0641737\n",
      "\tspeed: 0.0975s/iter; left time: 2096.8685s\n",
      "\titers: 200, epoch: 5 | loss: 0.0619924\n",
      "\tspeed: 0.0556s/iter; left time: 1190.2015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.60s\n",
      "Steps: 225 | Train Loss: 0.0658201 Vali Loss: 0.1321504 Test Loss: 0.1486785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0650147\n",
      "\tspeed: 0.0968s/iter; left time: 2059.4686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0601501\n",
      "\tspeed: 0.0548s/iter; left time: 1159.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.62s\n",
      "Steps: 225 | Train Loss: 0.0600249 Vali Loss: 0.1300616 Test Loss: 0.1472222\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0559322\n",
      "\tspeed: 0.0976s/iter; left time: 2055.4552s\n",
      "\titers: 200, epoch: 7 | loss: 0.0548691\n",
      "\tspeed: 0.0547s/iter; left time: 1146.2895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 225 | Train Loss: 0.0557527 Vali Loss: 0.1297588 Test Loss: 0.1476926\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0536059\n",
      "\tspeed: 0.0980s/iter; left time: 2040.6234s\n",
      "\titers: 200, epoch: 8 | loss: 0.0512451\n",
      "\tspeed: 0.0548s/iter; left time: 1136.0909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.59s\n",
      "Steps: 225 | Train Loss: 0.0522174 Vali Loss: 0.1293977 Test Loss: 0.1473823\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0519575\n",
      "\tspeed: 0.0965s/iter; left time: 1988.2710s\n",
      "\titers: 200, epoch: 9 | loss: 0.0481727\n",
      "\tspeed: 0.0548s/iter; left time: 1122.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.52s\n",
      "Steps: 225 | Train Loss: 0.0496511 Vali Loss: 0.1290194 Test Loss: 0.1478664\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0496600\n",
      "\tspeed: 0.0967s/iter; left time: 1970.9368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0457158\n",
      "\tspeed: 0.0547s/iter; left time: 1108.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0476154 Vali Loss: 0.1298917 Test Loss: 0.1480776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0454857\n",
      "\tspeed: 0.0976s/iter; left time: 1966.1850s\n",
      "\titers: 200, epoch: 11 | loss: 0.0459605\n",
      "\tspeed: 0.0544s/iter; left time: 1090.8823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.46s\n",
      "Steps: 225 | Train Loss: 0.0456645 Vali Loss: 0.1294558 Test Loss: 0.1472701\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04690314456820488, rmse:0.21657133102416992, mae:0.1495191603899002, rse:0.7489338517189026\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1204169\n",
      "\tspeed: 0.0564s/iter; left time: 1263.7660s\n",
      "\titers: 200, epoch: 1 | loss: 0.1210315\n",
      "\tspeed: 0.0548s/iter; left time: 1221.2591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.1264303 Vali Loss: 0.1267682 Test Loss: 0.1500666\n",
      "Validation loss decreased (inf --> 0.126768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038851\n",
      "\tspeed: 0.1034s/iter; left time: 2292.6868s\n",
      "\titers: 200, epoch: 2 | loss: 0.0967694\n",
      "\tspeed: 0.0547s/iter; left time: 1206.6265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.1041979 Vali Loss: 0.1256004 Test Loss: 0.1480494\n",
      "Validation loss decreased (0.126768 --> 0.125600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878237\n",
      "\tspeed: 0.1064s/iter; left time: 2336.6296s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822762\n",
      "\tspeed: 0.0550s/iter; left time: 1200.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.58s\n",
      "Steps: 225 | Train Loss: 0.0872704 Vali Loss: 0.1323572 Test Loss: 0.1491212\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0741254\n",
      "\tspeed: 0.0977s/iter; left time: 2122.8647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0698530\n",
      "\tspeed: 0.0547s/iter; left time: 1183.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.55s\n",
      "Steps: 225 | Train Loss: 0.0750340 Vali Loss: 0.1311133 Test Loss: 0.1477416\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693829\n",
      "\tspeed: 0.0972s/iter; left time: 2089.9905s\n",
      "\titers: 200, epoch: 5 | loss: 0.0645594\n",
      "\tspeed: 0.0548s/iter; left time: 1173.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.0664887 Vali Loss: 0.1336191 Test Loss: 0.1488445\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612510\n",
      "\tspeed: 0.0973s/iter; left time: 2069.5119s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586281\n",
      "\tspeed: 0.0548s/iter; left time: 1160.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0607296 Vali Loss: 0.1320561 Test Loss: 0.1481156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588017\n",
      "\tspeed: 0.0973s/iter; left time: 2049.2679s\n",
      "\titers: 200, epoch: 7 | loss: 0.0571976\n",
      "\tspeed: 0.0550s/iter; left time: 1151.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 225 | Train Loss: 0.0563253 Vali Loss: 0.1312302 Test Loss: 0.1483136\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0542190\n",
      "\tspeed: 0.0971s/iter; left time: 2022.5554s\n",
      "\titers: 200, epoch: 8 | loss: 0.0522542\n",
      "\tspeed: 0.0547s/iter; left time: 1134.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.53s\n",
      "Steps: 225 | Train Loss: 0.0530697 Vali Loss: 0.1308068 Test Loss: 0.1491268\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0506167\n",
      "\tspeed: 0.0973s/iter; left time: 2005.4254s\n",
      "\titers: 200, epoch: 9 | loss: 0.0504119\n",
      "\tspeed: 0.0548s/iter; left time: 1123.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.54s\n",
      "Steps: 225 | Train Loss: 0.0503541 Vali Loss: 0.1314857 Test Loss: 0.1501446\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0487696\n",
      "\tspeed: 0.0991s/iter; left time: 2018.6253s\n",
      "\titers: 200, epoch: 10 | loss: 0.0470511\n",
      "\tspeed: 0.0547s/iter; left time: 1109.0798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.61s\n",
      "Steps: 225 | Train Loss: 0.0481307 Vali Loss: 0.1304721 Test Loss: 0.1489927\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0467205\n",
      "\tspeed: 0.0985s/iter; left time: 1983.9773s\n",
      "\titers: 200, epoch: 11 | loss: 0.0455113\n",
      "\tspeed: 0.0554s/iter; left time: 1111.6115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.66s\n",
      "Steps: 225 | Train Loss: 0.0463793 Vali Loss: 0.1308019 Test Loss: 0.1496024\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0444195\n",
      "\tspeed: 0.0970s/iter; left time: 1932.3585s\n",
      "\titers: 200, epoch: 12 | loss: 0.0439973\n",
      "\tspeed: 0.0546s/iter; left time: 1081.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.51s\n",
      "Steps: 225 | Train Loss: 0.0448083 Vali Loss: 0.1303113 Test Loss: 0.1486246\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.050691790878772736, rmse:0.22514837980270386, mae:0.14804944396018982, rse:0.778594434261322\n",
      "Intermediate time for GB and pred_len 96: 00h:06m:04.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1288887\n",
      "\tspeed: 0.0696s/iter; left time: 1558.6362s\n",
      "\titers: 200, epoch: 1 | loss: 0.1188913\n",
      "\tspeed: 0.0553s/iter; left time: 1233.0159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:13.12s\n",
      "Steps: 225 | Train Loss: 0.1306679 Vali Loss: 0.1317371 Test Loss: 0.1554242\n",
      "Validation loss decreased (inf --> 0.131737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093038\n",
      "\tspeed: 0.1041s/iter; left time: 2309.5830s\n",
      "\titers: 200, epoch: 2 | loss: 0.1008310\n",
      "\tspeed: 0.0554s/iter; left time: 1222.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.1087003 Vali Loss: 0.1309559 Test Loss: 0.1525646\n",
      "Validation loss decreased (0.131737 --> 0.130956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0931468\n",
      "\tspeed: 0.1082s/iter; left time: 2375.5824s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867372\n",
      "\tspeed: 0.0554s/iter; left time: 1210.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0920048 Vali Loss: 0.1374218 Test Loss: 0.1584887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0782648\n",
      "\tspeed: 0.0990s/iter; left time: 2150.6331s\n",
      "\titers: 200, epoch: 4 | loss: 0.0778771\n",
      "\tspeed: 0.0552s/iter; left time: 1194.6539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 225 | Train Loss: 0.0791273 Vali Loss: 0.1383448 Test Loss: 0.1598979\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701911\n",
      "\tspeed: 0.0978s/iter; left time: 2102.4045s\n",
      "\titers: 200, epoch: 5 | loss: 0.0679734\n",
      "\tspeed: 0.0553s/iter; left time: 1182.9163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.65s\n",
      "Steps: 225 | Train Loss: 0.0701510 Vali Loss: 0.1353877 Test Loss: 0.1583329\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641981\n",
      "\tspeed: 0.0986s/iter; left time: 2096.9245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613489\n",
      "\tspeed: 0.0558s/iter; left time: 1180.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0640993 Vali Loss: 0.1362790 Test Loss: 0.1578299\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588057\n",
      "\tspeed: 0.0995s/iter; left time: 2094.6130s\n",
      "\titers: 200, epoch: 7 | loss: 0.0576348\n",
      "\tspeed: 0.0557s/iter; left time: 1166.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0595149 Vali Loss: 0.1357229 Test Loss: 0.1558924\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0553018\n",
      "\tspeed: 0.0984s/iter; left time: 2049.6087s\n",
      "\titers: 200, epoch: 8 | loss: 0.0570081\n",
      "\tspeed: 0.0556s/iter; left time: 1153.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.73s\n",
      "Steps: 225 | Train Loss: 0.0560118 Vali Loss: 0.1362291 Test Loss: 0.1570979\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0547959\n",
      "\tspeed: 0.0986s/iter; left time: 2030.8818s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533020\n",
      "\tspeed: 0.0556s/iter; left time: 1140.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0530366 Vali Loss: 0.1346605 Test Loss: 0.1572518\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0522824\n",
      "\tspeed: 0.0996s/iter; left time: 2030.3171s\n",
      "\titers: 200, epoch: 10 | loss: 0.0514619\n",
      "\tspeed: 0.0561s/iter; left time: 1137.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.81s\n",
      "Steps: 225 | Train Loss: 0.0510274 Vali Loss: 0.1349460 Test Loss: 0.1567449\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491573\n",
      "\tspeed: 0.0982s/iter; left time: 1978.8315s\n",
      "\titers: 200, epoch: 11 | loss: 0.0496059\n",
      "\tspeed: 0.0556s/iter; left time: 1114.6446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.0489246 Vali Loss: 0.1346077 Test Loss: 0.1561785\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0472633\n",
      "\tspeed: 0.0989s/iter; left time: 1969.7791s\n",
      "\titers: 200, epoch: 12 | loss: 0.0458323\n",
      "\tspeed: 0.0556s/iter; left time: 1103.2142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 225 | Train Loss: 0.0473697 Vali Loss: 0.1348265 Test Loss: 0.1564500\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0517885722219944, rmse:0.2275710254907608, mae:0.15256451070308685, rse:0.7890214323997498\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1248131\n",
      "\tspeed: 0.0573s/iter; left time: 1283.9049s\n",
      "\titers: 200, epoch: 1 | loss: 0.1162502\n",
      "\tspeed: 0.0554s/iter; left time: 1236.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.71s\n",
      "Steps: 225 | Train Loss: 0.1305182 Vali Loss: 0.1320111 Test Loss: 0.1555002\n",
      "Validation loss decreased (inf --> 0.132011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1084589\n",
      "\tspeed: 0.1100s/iter; left time: 2440.3032s\n",
      "\titers: 200, epoch: 2 | loss: 0.1009342\n",
      "\tspeed: 0.0555s/iter; left time: 1224.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.76s\n",
      "Steps: 225 | Train Loss: 0.1087005 Vali Loss: 0.1299949 Test Loss: 0.1539840\n",
      "Validation loss decreased (0.132011 --> 0.129995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0939816\n",
      "\tspeed: 0.1103s/iter; left time: 2420.6642s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884041\n",
      "\tspeed: 0.0556s/iter; left time: 1215.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 225 | Train Loss: 0.0910439 Vali Loss: 0.1361523 Test Loss: 0.1550590\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0779125\n",
      "\tspeed: 0.1028s/iter; left time: 2232.6311s\n",
      "\titers: 200, epoch: 4 | loss: 0.0742685\n",
      "\tspeed: 0.0557s/iter; left time: 1204.4145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0776980 Vali Loss: 0.1395256 Test Loss: 0.1581779\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0682881\n",
      "\tspeed: 0.0994s/iter; left time: 2136.5027s\n",
      "\titers: 200, epoch: 5 | loss: 0.0675382\n",
      "\tspeed: 0.0555s/iter; left time: 1188.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:12.70s\n",
      "Steps: 225 | Train Loss: 0.0694059 Vali Loss: 0.1372489 Test Loss: 0.1539304\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0626082\n",
      "\tspeed: 0.1008s/iter; left time: 2143.9269s\n",
      "\titers: 200, epoch: 6 | loss: 0.0620468\n",
      "\tspeed: 0.0560s/iter; left time: 1185.1264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.78s\n",
      "Steps: 225 | Train Loss: 0.0636043 Vali Loss: 0.1361786 Test Loss: 0.1553313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0572737\n",
      "\tspeed: 0.1002s/iter; left time: 2109.1299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601258\n",
      "\tspeed: 0.0556s/iter; left time: 1164.1710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.82s\n",
      "Steps: 225 | Train Loss: 0.0594467 Vali Loss: 0.1364768 Test Loss: 0.1566423\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0548176\n",
      "\tspeed: 0.1003s/iter; left time: 2088.0351s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569865\n",
      "\tspeed: 0.0557s/iter; left time: 1154.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.99s\n",
      "Steps: 225 | Train Loss: 0.0559141 Vali Loss: 0.1353940 Test Loss: 0.1561464\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0526453\n",
      "\tspeed: 0.1018s/iter; left time: 2097.4749s\n",
      "\titers: 200, epoch: 9 | loss: 0.0528355\n",
      "\tspeed: 0.0557s/iter; left time: 1141.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0528804 Vali Loss: 0.1361213 Test Loss: 0.1554508\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0506995\n",
      "\tspeed: 0.1013s/iter; left time: 2064.8186s\n",
      "\titers: 200, epoch: 10 | loss: 0.0504092\n",
      "\tspeed: 0.0557s/iter; left time: 1130.2357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:12.84s\n",
      "Steps: 225 | Train Loss: 0.0507411 Vali Loss: 0.1342339 Test Loss: 0.1568171\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0480116\n",
      "\tspeed: 0.1010s/iter; left time: 2035.4964s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484144\n",
      "\tspeed: 0.0557s/iter; left time: 1117.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:12.77s\n",
      "Steps: 225 | Train Loss: 0.0486653 Vali Loss: 0.1335320 Test Loss: 0.1558110\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0486329\n",
      "\tspeed: 0.1006s/iter; left time: 2004.8748s\n",
      "\titers: 200, epoch: 12 | loss: 0.0467156\n",
      "\tspeed: 0.0556s/iter; left time: 1103.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:12.83s\n",
      "Steps: 225 | Train Loss: 0.0471598 Vali Loss: 0.1340976 Test Loss: 0.1550207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05241897702217102, rmse:0.22895191609859467, mae:0.15398409962654114, rse:0.793809175491333\n",
      "Intermediate time for GB and pred_len 168: 00h:06m:26.76s\n",
      "Intermediate time for GB: 00h:18m:45.32s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1124842\n",
      "\tspeed: 0.0435s/iter; left time: 977.6714s\n",
      "\titers: 200, epoch: 1 | loss: 0.1009502\n",
      "\tspeed: 0.0179s/iter; left time: 399.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.57s\n",
      "Steps: 226 | Train Loss: 0.1213686 Vali Loss: 0.0879941 Test Loss: 0.0994127\n",
      "Validation loss decreased (inf --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707472\n",
      "\tspeed: 0.0431s/iter; left time: 959.2595s\n",
      "\titers: 200, epoch: 2 | loss: 0.0645977\n",
      "\tspeed: 0.0183s/iter; left time: 405.0563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 226 | Train Loss: 0.0720836 Vali Loss: 0.0634934 Test Loss: 0.0713428\n",
      "Validation loss decreased (0.087994 --> 0.063493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0628835\n",
      "\tspeed: 0.0401s/iter; left time: 884.4265s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655793\n",
      "\tspeed: 0.0179s/iter; left time: 393.4010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0632510 Vali Loss: 0.0608880 Test Loss: 0.0694066\n",
      "Validation loss decreased (0.063493 --> 0.060888).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0623999\n",
      "\tspeed: 0.0389s/iter; left time: 848.0771s\n",
      "\titers: 200, epoch: 4 | loss: 0.0592492\n",
      "\tspeed: 0.0187s/iter; left time: 405.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 226 | Train Loss: 0.0605673 Vali Loss: 0.0586846 Test Loss: 0.0669195\n",
      "Validation loss decreased (0.060888 --> 0.058685).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610170\n",
      "\tspeed: 0.0385s/iter; left time: 831.3171s\n",
      "\titers: 200, epoch: 5 | loss: 0.0594257\n",
      "\tspeed: 0.0178s/iter; left time: 382.3242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0587278 Vali Loss: 0.0585923 Test Loss: 0.0662567\n",
      "Validation loss decreased (0.058685 --> 0.058592).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0599013\n",
      "\tspeed: 0.0387s/iter; left time: 826.1073s\n",
      "\titers: 200, epoch: 6 | loss: 0.0568876\n",
      "\tspeed: 0.0177s/iter; left time: 377.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0571984 Vali Loss: 0.0573838 Test Loss: 0.0652744\n",
      "Validation loss decreased (0.058592 --> 0.057384).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0586293\n",
      "\tspeed: 0.0387s/iter; left time: 818.6383s\n",
      "\titers: 200, epoch: 7 | loss: 0.0559175\n",
      "\tspeed: 0.0177s/iter; left time: 372.1594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0558528 Vali Loss: 0.0571522 Test Loss: 0.0649240\n",
      "Validation loss decreased (0.057384 --> 0.057152).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0558720\n",
      "\tspeed: 0.0383s/iter; left time: 802.0610s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558167\n",
      "\tspeed: 0.0177s/iter; left time: 368.5870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0545714 Vali Loss: 0.0568685 Test Loss: 0.0653187\n",
      "Validation loss decreased (0.057152 --> 0.056869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0553593\n",
      "\tspeed: 0.0401s/iter; left time: 829.8921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0535859\n",
      "\tspeed: 0.0177s/iter; left time: 364.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0533603 Vali Loss: 0.0568295 Test Loss: 0.0647412\n",
      "Validation loss decreased (0.056869 --> 0.056830).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0508198\n",
      "\tspeed: 0.0381s/iter; left time: 779.0923s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548194\n",
      "\tspeed: 0.0177s/iter; left time: 361.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0524042 Vali Loss: 0.0572606 Test Loss: 0.0660838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0531354\n",
      "\tspeed: 0.0367s/iter; left time: 742.2749s\n",
      "\titers: 200, epoch: 11 | loss: 0.0466009\n",
      "\tspeed: 0.0185s/iter; left time: 373.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0513938 Vali Loss: 0.0570663 Test Loss: 0.0655558\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0510062\n",
      "\tspeed: 0.0373s/iter; left time: 746.1600s\n",
      "\titers: 200, epoch: 12 | loss: 0.0492757\n",
      "\tspeed: 0.0177s/iter; left time: 353.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0503798 Vali Loss: 0.0571216 Test Loss: 0.0652722\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0488996\n",
      "\tspeed: 0.0369s/iter; left time: 729.9008s\n",
      "\titers: 200, epoch: 13 | loss: 0.0487254\n",
      "\tspeed: 0.0178s/iter; left time: 351.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 226 | Train Loss: 0.0494039 Vali Loss: 0.0569635 Test Loss: 0.0654164\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0505270\n",
      "\tspeed: 0.0371s/iter; left time: 725.8340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0481179\n",
      "\tspeed: 0.0178s/iter; left time: 345.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0486680 Vali Loss: 0.0574444 Test Loss: 0.0659121\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0461680\n",
      "\tspeed: 0.0373s/iter; left time: 720.8922s\n",
      "\titers: 200, epoch: 15 | loss: 0.0467860\n",
      "\tspeed: 0.0182s/iter; left time: 349.3139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0477979 Vali Loss: 0.0575305 Test Loss: 0.0660432\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0470566\n",
      "\tspeed: 0.0371s/iter; left time: 709.7160s\n",
      "\titers: 200, epoch: 16 | loss: 0.0462770\n",
      "\tspeed: 0.0177s/iter; left time: 336.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0470584 Vali Loss: 0.0576381 Test Loss: 0.0664225\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0478649\n",
      "\tspeed: 0.0371s/iter; left time: 701.2459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0425138\n",
      "\tspeed: 0.0179s/iter; left time: 335.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 226 | Train Loss: 0.0464450 Vali Loss: 0.0574624 Test Loss: 0.0663594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0444574\n",
      "\tspeed: 0.0374s/iter; left time: 698.2273s\n",
      "\titers: 200, epoch: 18 | loss: 0.0454440\n",
      "\tspeed: 0.0178s/iter; left time: 330.8416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0458276 Vali Loss: 0.0578417 Test Loss: 0.0663731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0459243\n",
      "\tspeed: 0.0370s/iter; left time: 682.8415s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441686\n",
      "\tspeed: 0.0177s/iter; left time: 324.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 226 | Train Loss: 0.0454053 Vali Loss: 0.0574835 Test Loss: 0.0664394\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011007036082446575, rmse:0.10491441935300827, mae:0.06474124640226364, rse:0.3087504804134369\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1162311\n",
      "\tspeed: 0.0199s/iter; left time: 446.6532s\n",
      "\titers: 200, epoch: 1 | loss: 0.1004892\n",
      "\tspeed: 0.0177s/iter; left time: 396.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.1192099 Vali Loss: 0.0875229 Test Loss: 0.0998294\n",
      "Validation loss decreased (inf --> 0.087523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0695417\n",
      "\tspeed: 0.0394s/iter; left time: 877.8776s\n",
      "\titers: 200, epoch: 2 | loss: 0.0663097\n",
      "\tspeed: 0.0177s/iter; left time: 393.5928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0719416 Vali Loss: 0.0630254 Test Loss: 0.0715464\n",
      "Validation loss decreased (0.087523 --> 0.063025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0648911\n",
      "\tspeed: 0.0409s/iter; left time: 901.0587s\n",
      "\titers: 200, epoch: 3 | loss: 0.0603960\n",
      "\tspeed: 0.0179s/iter; left time: 393.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0634335 Vali Loss: 0.0601272 Test Loss: 0.0680579\n",
      "Validation loss decreased (0.063025 --> 0.060127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0630488\n",
      "\tspeed: 0.0405s/iter; left time: 883.9154s\n",
      "\titers: 200, epoch: 4 | loss: 0.0593784\n",
      "\tspeed: 0.0178s/iter; left time: 387.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0606399 Vali Loss: 0.0588839 Test Loss: 0.0669874\n",
      "Validation loss decreased (0.060127 --> 0.058884).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0567448\n",
      "\tspeed: 0.0398s/iter; left time: 858.8286s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588744\n",
      "\tspeed: 0.0177s/iter; left time: 380.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0587466 Vali Loss: 0.0579996 Test Loss: 0.0665329\n",
      "Validation loss decreased (0.058884 --> 0.058000).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0600855\n",
      "\tspeed: 0.0410s/iter; left time: 876.9776s\n",
      "\titers: 200, epoch: 6 | loss: 0.0577135\n",
      "\tspeed: 0.0183s/iter; left time: 389.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 226 | Train Loss: 0.0572608 Vali Loss: 0.0569367 Test Loss: 0.0653062\n",
      "Validation loss decreased (0.058000 --> 0.056937).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542247\n",
      "\tspeed: 0.0402s/iter; left time: 850.3942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0564543\n",
      "\tspeed: 0.0187s/iter; left time: 393.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 226 | Train Loss: 0.0559290 Vali Loss: 0.0568971 Test Loss: 0.0651867\n",
      "Validation loss decreased (0.056937 --> 0.056897).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0523716\n",
      "\tspeed: 0.0396s/iter; left time: 828.9344s\n",
      "\titers: 200, epoch: 8 | loss: 0.0535895\n",
      "\tspeed: 0.0178s/iter; left time: 369.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 226 | Train Loss: 0.0547411 Vali Loss: 0.0569282 Test Loss: 0.0659702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0539846\n",
      "\tspeed: 0.0388s/iter; left time: 803.4854s\n",
      "\titers: 200, epoch: 9 | loss: 0.0507050\n",
      "\tspeed: 0.0177s/iter; left time: 365.3535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0535003 Vali Loss: 0.0565453 Test Loss: 0.0662685\n",
      "Validation loss decreased (0.056897 --> 0.056545).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0525033\n",
      "\tspeed: 0.0397s/iter; left time: 811.6616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0521336\n",
      "\tspeed: 0.0178s/iter; left time: 361.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0524343 Vali Loss: 0.0562809 Test Loss: 0.0650042\n",
      "Validation loss decreased (0.056545 --> 0.056281).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0512471\n",
      "\tspeed: 0.0393s/iter; left time: 796.4033s\n",
      "\titers: 200, epoch: 11 | loss: 0.0523231\n",
      "\tspeed: 0.0178s/iter; left time: 359.4099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 226 | Train Loss: 0.0514645 Vali Loss: 0.0561214 Test Loss: 0.0655144\n",
      "Validation loss decreased (0.056281 --> 0.056121).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0517867\n",
      "\tspeed: 0.0397s/iter; left time: 793.6812s\n",
      "\titers: 200, epoch: 12 | loss: 0.0496815\n",
      "\tspeed: 0.0178s/iter; left time: 353.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0505630 Vali Loss: 0.0565962 Test Loss: 0.0661952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0490189\n",
      "\tspeed: 0.0378s/iter; left time: 748.0168s\n",
      "\titers: 200, epoch: 13 | loss: 0.0488397\n",
      "\tspeed: 0.0180s/iter; left time: 354.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 226 | Train Loss: 0.0496286 Vali Loss: 0.0564829 Test Loss: 0.0664086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0473826\n",
      "\tspeed: 0.0378s/iter; left time: 739.7137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0479432\n",
      "\tspeed: 0.0177s/iter; left time: 345.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0488122 Vali Loss: 0.0564987 Test Loss: 0.0658618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0467108\n",
      "\tspeed: 0.0380s/iter; left time: 733.8844s\n",
      "\titers: 200, epoch: 15 | loss: 0.0534318\n",
      "\tspeed: 0.0178s/iter; left time: 342.2381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0481202 Vali Loss: 0.0566211 Test Loss: 0.0662000\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0479798\n",
      "\tspeed: 0.0381s/iter; left time: 727.2640s\n",
      "\titers: 200, epoch: 16 | loss: 0.0490280\n",
      "\tspeed: 0.0179s/iter; left time: 339.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 226 | Train Loss: 0.0474466 Vali Loss: 0.0568491 Test Loss: 0.0672643\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0487071\n",
      "\tspeed: 0.0384s/iter; left time: 724.7280s\n",
      "\titers: 200, epoch: 17 | loss: 0.0477347\n",
      "\tspeed: 0.0177s/iter; left time: 332.8640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 226 | Train Loss: 0.0468248 Vali Loss: 0.0567821 Test Loss: 0.0669147\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0470071\n",
      "\tspeed: 0.0376s/iter; left time: 701.5360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0450384\n",
      "\tspeed: 0.0177s/iter; left time: 328.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 226 | Train Loss: 0.0463054 Vali Loss: 0.0566044 Test Loss: 0.0665685\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0442794\n",
      "\tspeed: 0.0379s/iter; left time: 697.6948s\n",
      "\titers: 200, epoch: 19 | loss: 0.0452530\n",
      "\tspeed: 0.0177s/iter; left time: 325.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0456901 Vali Loss: 0.0570509 Test Loss: 0.0667313\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0469251\n",
      "\tspeed: 0.0378s/iter; left time: 688.1240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0443603\n",
      "\tspeed: 0.0178s/iter; left time: 321.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 226 | Train Loss: 0.0453321 Vali Loss: 0.0570785 Test Loss: 0.0672699\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0464923\n",
      "\tspeed: 0.0395s/iter; left time: 710.5409s\n",
      "\titers: 200, epoch: 21 | loss: 0.0467124\n",
      "\tspeed: 0.0178s/iter; left time: 317.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 226 | Train Loss: 0.0448378 Vali Loss: 0.0569400 Test Loss: 0.0673984\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01132641639560461, rmse:0.10642563551664352, mae:0.06551436334848404, rse:0.3131977915763855\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:57.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1237152\n",
      "\tspeed: 0.0436s/iter; left time: 976.1799s\n",
      "\titers: 200, epoch: 1 | loss: 0.1135411\n",
      "\tspeed: 0.0186s/iter; left time: 414.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.66s\n",
      "Steps: 225 | Train Loss: 0.1316227 Vali Loss: 0.1026748 Test Loss: 0.1170933\n",
      "Validation loss decreased (inf --> 0.102675).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0875041\n",
      "\tspeed: 0.0407s/iter; left time: 901.4934s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861476\n",
      "\tspeed: 0.0181s/iter; left time: 399.4828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0908247 Vali Loss: 0.0837092 Test Loss: 0.0957223\n",
      "Validation loss decreased (0.102675 --> 0.083709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821024\n",
      "\tspeed: 0.0412s/iter; left time: 905.3291s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819545\n",
      "\tspeed: 0.0181s/iter; left time: 394.8010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0828895 Vali Loss: 0.0808105 Test Loss: 0.0938665\n",
      "Validation loss decreased (0.083709 --> 0.080810).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0780354\n",
      "\tspeed: 0.0406s/iter; left time: 881.6916s\n",
      "\titers: 200, epoch: 4 | loss: 0.0805350\n",
      "\tspeed: 0.0181s/iter; left time: 391.3739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 225 | Train Loss: 0.0786676 Vali Loss: 0.0803954 Test Loss: 0.0944282\n",
      "Validation loss decreased (0.080810 --> 0.080395).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0761563\n",
      "\tspeed: 0.0422s/iter; left time: 907.5458s\n",
      "\titers: 200, epoch: 5 | loss: 0.0708133\n",
      "\tspeed: 0.0182s/iter; left time: 389.9596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0744769 Vali Loss: 0.0815953 Test Loss: 0.0971340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0679881\n",
      "\tspeed: 0.0390s/iter; left time: 829.9477s\n",
      "\titers: 200, epoch: 6 | loss: 0.0705811\n",
      "\tspeed: 0.0182s/iter; left time: 384.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.36s\n",
      "Steps: 225 | Train Loss: 0.0704299 Vali Loss: 0.0820850 Test Loss: 0.0969924\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0701797\n",
      "\tspeed: 0.0390s/iter; left time: 822.0239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0629454\n",
      "\tspeed: 0.0182s/iter; left time: 381.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0666835 Vali Loss: 0.0815112 Test Loss: 0.0976271\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0647407\n",
      "\tspeed: 0.0389s/iter; left time: 809.6054s\n",
      "\titers: 200, epoch: 8 | loss: 0.0622736\n",
      "\tspeed: 0.0181s/iter; left time: 375.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0637334 Vali Loss: 0.0830895 Test Loss: 0.0994646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0603530\n",
      "\tspeed: 0.0386s/iter; left time: 796.0952s\n",
      "\titers: 200, epoch: 9 | loss: 0.0603974\n",
      "\tspeed: 0.0184s/iter; left time: 376.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0611769 Vali Loss: 0.0817545 Test Loss: 0.0993861\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0600764\n",
      "\tspeed: 0.0393s/iter; left time: 800.1095s\n",
      "\titers: 200, epoch: 10 | loss: 0.0582973\n",
      "\tspeed: 0.0181s/iter; left time: 367.6679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 225 | Train Loss: 0.0590898 Vali Loss: 0.0832220 Test Loss: 0.0996093\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0572594\n",
      "\tspeed: 0.0396s/iter; left time: 797.3015s\n",
      "\titers: 200, epoch: 11 | loss: 0.0569117\n",
      "\tspeed: 0.0182s/iter; left time: 365.0839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0574465 Vali Loss: 0.0824588 Test Loss: 0.0995272\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0568082\n",
      "\tspeed: 0.0390s/iter; left time: 778.0359s\n",
      "\titers: 200, epoch: 12 | loss: 0.0554572\n",
      "\tspeed: 0.0181s/iter; left time: 358.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0559205 Vali Loss: 0.0839447 Test Loss: 0.1002958\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0544536\n",
      "\tspeed: 0.0384s/iter; left time: 757.4816s\n",
      "\titers: 200, epoch: 13 | loss: 0.0557813\n",
      "\tspeed: 0.0181s/iter; left time: 354.3705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0547010 Vali Loss: 0.0828165 Test Loss: 0.1006012\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0549239\n",
      "\tspeed: 0.0381s/iter; left time: 741.0889s\n",
      "\titers: 200, epoch: 14 | loss: 0.0532466\n",
      "\tspeed: 0.0181s/iter; left time: 350.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 225 | Train Loss: 0.0537058 Vali Loss: 0.0825675 Test Loss: 0.1002479\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021064607426524162, rmse:0.1451365202665329, mae:0.09442825615406036, rse:0.4263674020767212\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1220162\n",
      "\tspeed: 0.0208s/iter; left time: 465.4625s\n",
      "\titers: 200, epoch: 1 | loss: 0.1103479\n",
      "\tspeed: 0.0181s/iter; left time: 403.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.1313584 Vali Loss: 0.1028219 Test Loss: 0.1171752\n",
      "Validation loss decreased (inf --> 0.102822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938511\n",
      "\tspeed: 0.0462s/iter; left time: 1025.0942s\n",
      "\titers: 200, epoch: 2 | loss: 0.0861422\n",
      "\tspeed: 0.0181s/iter; left time: 399.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0909858 Vali Loss: 0.0838486 Test Loss: 0.0959260\n",
      "Validation loss decreased (0.102822 --> 0.083849).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0862403\n",
      "\tspeed: 0.0410s/iter; left time: 899.4305s\n",
      "\titers: 200, epoch: 3 | loss: 0.0830001\n",
      "\tspeed: 0.0181s/iter; left time: 394.8757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0832866 Vali Loss: 0.0825980 Test Loss: 0.0954908\n",
      "Validation loss decreased (0.083849 --> 0.082598).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0782939\n",
      "\tspeed: 0.0447s/iter; left time: 970.1137s\n",
      "\titers: 200, epoch: 4 | loss: 0.0814964\n",
      "\tspeed: 0.0183s/iter; left time: 396.6409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.35s\n",
      "Steps: 225 | Train Loss: 0.0790398 Vali Loss: 0.0809088 Test Loss: 0.0939019\n",
      "Validation loss decreased (0.082598 --> 0.080909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0739339\n",
      "\tspeed: 0.0410s/iter; left time: 881.4071s\n",
      "\titers: 200, epoch: 5 | loss: 0.0742741\n",
      "\tspeed: 0.0192s/iter; left time: 411.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.0746791 Vali Loss: 0.0811581 Test Loss: 0.0951832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0697818\n",
      "\tspeed: 0.0400s/iter; left time: 851.9782s\n",
      "\titers: 200, epoch: 6 | loss: 0.0695777\n",
      "\tspeed: 0.0181s/iter; left time: 383.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 225 | Train Loss: 0.0705332 Vali Loss: 0.0822380 Test Loss: 0.0965868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0687213\n",
      "\tspeed: 0.0394s/iter; left time: 828.7732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0651451\n",
      "\tspeed: 0.0187s/iter; left time: 391.3867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0670268 Vali Loss: 0.0823335 Test Loss: 0.0984485\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0624922\n",
      "\tspeed: 0.0392s/iter; left time: 816.0951s\n",
      "\titers: 200, epoch: 8 | loss: 0.0625210\n",
      "\tspeed: 0.0181s/iter; left time: 374.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 225 | Train Loss: 0.0640895 Vali Loss: 0.0825310 Test Loss: 0.0988109\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0615293\n",
      "\tspeed: 0.0414s/iter; left time: 852.2990s\n",
      "\titers: 200, epoch: 9 | loss: 0.0610103\n",
      "\tspeed: 0.0186s/iter; left time: 381.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0614805 Vali Loss: 0.0837530 Test Loss: 0.1001917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0645037\n",
      "\tspeed: 0.0391s/iter; left time: 796.7527s\n",
      "\titers: 200, epoch: 10 | loss: 0.0587965\n",
      "\tspeed: 0.0181s/iter; left time: 367.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0593795 Vali Loss: 0.0845202 Test Loss: 0.1010247\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0599034\n",
      "\tspeed: 0.0404s/iter; left time: 814.9790s\n",
      "\titers: 200, epoch: 11 | loss: 0.0571154\n",
      "\tspeed: 0.0182s/iter; left time: 365.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0577073 Vali Loss: 0.0837538 Test Loss: 0.1006436\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0575076\n",
      "\tspeed: 0.0393s/iter; left time: 783.5601s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553799\n",
      "\tspeed: 0.0181s/iter; left time: 358.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 225 | Train Loss: 0.0562136 Vali Loss: 0.0842879 Test Loss: 0.0998713\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0551629\n",
      "\tspeed: 0.0408s/iter; left time: 804.5305s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547108\n",
      "\tspeed: 0.0182s/iter; left time: 356.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0549982 Vali Loss: 0.0848953 Test Loss: 0.1000355\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0544534\n",
      "\tspeed: 0.0392s/iter; left time: 764.0534s\n",
      "\titers: 200, epoch: 14 | loss: 0.0545231\n",
      "\tspeed: 0.0185s/iter; left time: 357.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0539025 Vali Loss: 0.0854289 Test Loss: 0.1009187\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02059120684862137, rmse:0.14349636435508728, mae:0.09390184283256531, rse:0.42154911160469055\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:54.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1247540\n",
      "\tspeed: 0.0417s/iter; left time: 934.3843s\n",
      "\titers: 200, epoch: 1 | loss: 0.1150539\n",
      "\tspeed: 0.0185s/iter; left time: 411.4751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.67s\n",
      "Steps: 225 | Train Loss: 0.1349855 Vali Loss: 0.1072181 Test Loss: 0.1212277\n",
      "Validation loss decreased (inf --> 0.107218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0952868\n",
      "\tspeed: 0.0420s/iter; left time: 931.5524s\n",
      "\titers: 200, epoch: 2 | loss: 0.0945520\n",
      "\tspeed: 0.0184s/iter; left time: 406.0207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0958055 Vali Loss: 0.0891325 Test Loss: 0.1016404\n",
      "Validation loss decreased (0.107218 --> 0.089133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0861062\n",
      "\tspeed: 0.0429s/iter; left time: 941.9152s\n",
      "\titers: 200, epoch: 3 | loss: 0.0842636\n",
      "\tspeed: 0.0185s/iter; left time: 404.4816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0874688 Vali Loss: 0.0875926 Test Loss: 0.1009574\n",
      "Validation loss decreased (0.089133 --> 0.087593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0803422\n",
      "\tspeed: 0.0418s/iter; left time: 908.7489s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789519\n",
      "\tspeed: 0.0186s/iter; left time: 402.9947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.40s\n",
      "Steps: 225 | Train Loss: 0.0826494 Vali Loss: 0.0869722 Test Loss: 0.0999192\n",
      "Validation loss decreased (0.087593 --> 0.086972).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0803686\n",
      "\tspeed: 0.0433s/iter; left time: 930.7006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0769203\n",
      "\tspeed: 0.0186s/iter; left time: 397.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0780406 Vali Loss: 0.0878041 Test Loss: 0.1009314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0742448\n",
      "\tspeed: 0.0400s/iter; left time: 851.7574s\n",
      "\titers: 200, epoch: 6 | loss: 0.0705056\n",
      "\tspeed: 0.0186s/iter; left time: 394.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0740998 Vali Loss: 0.0874714 Test Loss: 0.1005987\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0713059\n",
      "\tspeed: 0.0399s/iter; left time: 840.1154s\n",
      "\titers: 200, epoch: 7 | loss: 0.0685161\n",
      "\tspeed: 0.0185s/iter; left time: 388.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0705341 Vali Loss: 0.0876008 Test Loss: 0.1009772\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0688173\n",
      "\tspeed: 0.0397s/iter; left time: 826.6628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0669033\n",
      "\tspeed: 0.0184s/iter; left time: 382.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0674322 Vali Loss: 0.0876953 Test Loss: 0.1018889\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0656546\n",
      "\tspeed: 0.0389s/iter; left time: 801.6893s\n",
      "\titers: 200, epoch: 9 | loss: 0.0625771\n",
      "\tspeed: 0.0184s/iter; left time: 377.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0648954 Vali Loss: 0.0878862 Test Loss: 0.1018234\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0636433\n",
      "\tspeed: 0.0392s/iter; left time: 798.7257s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610861\n",
      "\tspeed: 0.0184s/iter; left time: 373.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0627834 Vali Loss: 0.0887654 Test Loss: 0.1025015\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0597898\n",
      "\tspeed: 0.0389s/iter; left time: 783.6606s\n",
      "\titers: 200, epoch: 11 | loss: 0.0603452\n",
      "\tspeed: 0.0184s/iter; left time: 369.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0609051 Vali Loss: 0.0891276 Test Loss: 0.1031746\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0595660\n",
      "\tspeed: 0.0390s/iter; left time: 776.9338s\n",
      "\titers: 200, epoch: 12 | loss: 0.0583236\n",
      "\tspeed: 0.0198s/iter; left time: 393.0724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.52s\n",
      "Steps: 225 | Train Loss: 0.0593992 Vali Loss: 0.0889052 Test Loss: 0.1035037\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0561858\n",
      "\tspeed: 0.0401s/iter; left time: 790.2838s\n",
      "\titers: 200, epoch: 13 | loss: 0.0568517\n",
      "\tspeed: 0.0184s/iter; left time: 361.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 225 | Train Loss: 0.0581817 Vali Loss: 0.0892176 Test Loss: 0.1029303\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560341\n",
      "\tspeed: 0.0390s/iter; left time: 758.7934s\n",
      "\titers: 200, epoch: 14 | loss: 0.0573181\n",
      "\tspeed: 0.0185s/iter; left time: 358.3559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.38s\n",
      "Steps: 225 | Train Loss: 0.0570184 Vali Loss: 0.0896377 Test Loss: 0.1037195\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023037901148200035, rmse:0.15178240835666656, mae:0.09991918504238129, rse:0.4459230601787567\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1261791\n",
      "\tspeed: 0.0208s/iter; left time: 466.4094s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139913\n",
      "\tspeed: 0.0185s/iter; left time: 412.5177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 225 | Train Loss: 0.1350769 Vali Loss: 0.1071121 Test Loss: 0.1210380\n",
      "Validation loss decreased (inf --> 0.107112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0985186\n",
      "\tspeed: 0.0463s/iter; left time: 1027.7213s\n",
      "\titers: 200, epoch: 2 | loss: 0.0899919\n",
      "\tspeed: 0.0189s/iter; left time: 416.3461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0956979 Vali Loss: 0.0897057 Test Loss: 0.1010741\n",
      "Validation loss decreased (0.107112 --> 0.089706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888578\n",
      "\tspeed: 0.0429s/iter; left time: 940.8254s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896617\n",
      "\tspeed: 0.0184s/iter; left time: 402.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 225 | Train Loss: 0.0872689 Vali Loss: 0.0875277 Test Loss: 0.0992018\n",
      "Validation loss decreased (0.089706 --> 0.087528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0816071\n",
      "\tspeed: 0.0427s/iter; left time: 927.3661s\n",
      "\titers: 200, epoch: 4 | loss: 0.0820200\n",
      "\tspeed: 0.0185s/iter; left time: 400.2018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.46s\n",
      "Steps: 225 | Train Loss: 0.0821305 Vali Loss: 0.0869310 Test Loss: 0.0992053\n",
      "Validation loss decreased (0.087528 --> 0.086931).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769678\n",
      "\tspeed: 0.0441s/iter; left time: 947.7166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741023\n",
      "\tspeed: 0.0186s/iter; left time: 399.0523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.53s\n",
      "Steps: 225 | Train Loss: 0.0775248 Vali Loss: 0.0868163 Test Loss: 0.1004667\n",
      "Validation loss decreased (0.086931 --> 0.086816).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0732511\n",
      "\tspeed: 0.0428s/iter; left time: 909.7394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729547\n",
      "\tspeed: 0.0185s/iter; left time: 392.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.50s\n",
      "Steps: 225 | Train Loss: 0.0734757 Vali Loss: 0.0884040 Test Loss: 0.1026382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0714987\n",
      "\tspeed: 0.0422s/iter; left time: 887.5784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0705451\n",
      "\tspeed: 0.0187s/iter; left time: 391.1128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0700019 Vali Loss: 0.0890642 Test Loss: 0.1035616\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0675946\n",
      "\tspeed: 0.0408s/iter; left time: 849.9255s\n",
      "\titers: 200, epoch: 8 | loss: 0.0666065\n",
      "\tspeed: 0.0185s/iter; left time: 382.7006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0670320 Vali Loss: 0.0886770 Test Loss: 0.1047017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663665\n",
      "\tspeed: 0.0404s/iter; left time: 831.4488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0656349\n",
      "\tspeed: 0.0188s/iter; left time: 384.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 225 | Train Loss: 0.0646494 Vali Loss: 0.0893991 Test Loss: 0.1041597\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633635\n",
      "\tspeed: 0.0408s/iter; left time: 832.2636s\n",
      "\titers: 200, epoch: 10 | loss: 0.0617162\n",
      "\tspeed: 0.0185s/iter; left time: 374.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0626202 Vali Loss: 0.0899764 Test Loss: 0.1048512\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0605506\n",
      "\tspeed: 0.0432s/iter; left time: 870.9245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0613867\n",
      "\tspeed: 0.0190s/iter; left time: 381.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.55s\n",
      "Steps: 225 | Train Loss: 0.0609869 Vali Loss: 0.0901252 Test Loss: 0.1047130\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0587517\n",
      "\tspeed: 0.0401s/iter; left time: 798.9508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584610\n",
      "\tspeed: 0.0185s/iter; left time: 367.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 225 | Train Loss: 0.0595634 Vali Loss: 0.0902548 Test Loss: 0.1046337\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0595968\n",
      "\tspeed: 0.0406s/iter; left time: 800.3465s\n",
      "\titers: 200, epoch: 13 | loss: 0.0577132\n",
      "\tspeed: 0.0186s/iter; left time: 363.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0583364 Vali Loss: 0.0901216 Test Loss: 0.1052209\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0553474\n",
      "\tspeed: 0.0416s/iter; left time: 809.8766s\n",
      "\titers: 200, epoch: 14 | loss: 0.0580140\n",
      "\tspeed: 0.0190s/iter; left time: 368.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.56s\n",
      "Steps: 225 | Train Loss: 0.0572883 Vali Loss: 0.0903224 Test Loss: 0.1053021\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0561897\n",
      "\tspeed: 0.0431s/iter; left time: 829.4671s\n",
      "\titers: 200, epoch: 15 | loss: 0.0561889\n",
      "\tspeed: 0.0185s/iter; left time: 355.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.51s\n",
      "Steps: 225 | Train Loss: 0.0563494 Vali Loss: 0.0904639 Test Loss: 0.1047017\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023621639236807823, rmse:0.1536933332681656, mae:0.10046669095754623, rse:0.45153719186782837\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:05.16s\n",
      "Intermediate time for ES: 00h:09m:57.10s\n",
      "Total time: 00h:48m:02.89s\n"
     ]
    }
   ],
   "source": [
    "countries = ['DE', 'GB', 'ES']\n",
    "num_cols = [5, 5, 3]\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_168.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            seq_len=168\n",
    "\n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.1541</td>\n",
       "      <td>0.0981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.0651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>0.1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>0.1533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0237  0.1541  0.0981\n",
       "        96        0.0441  0.2100  0.1392\n",
       "        168       0.0487  0.2207  0.1477\n",
       "ES      24        0.0112  0.1057  0.0651\n",
       "        96        0.0208  0.1443  0.0942\n",
       "        168       0.0233  0.1527  0.1002\n",
       "GB      24        0.0269  0.1639  0.1068\n",
       "        96        0.0488  0.2209  0.1488\n",
       "        168       0.0521  0.2283  0.1533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_168.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1261505\n",
      "\tspeed: 0.0389s/iter; left time: 876.2598s\n",
      "\titers: 200, epoch: 1 | loss: 0.1045834\n",
      "\tspeed: 0.0158s/iter; left time: 354.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 226 | Train Loss: 0.1294775 Vali Loss: 0.0948400 Test Loss: 0.1050907\n",
      "Validation loss decreased (inf --> 0.094840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0767076\n",
      "\tspeed: 0.0357s/iter; left time: 794.5104s\n",
      "\titers: 200, epoch: 2 | loss: 0.0721143\n",
      "\tspeed: 0.0164s/iter; left time: 362.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 226 | Train Loss: 0.0756046 Vali Loss: 0.0646964 Test Loss: 0.0728172\n",
      "Validation loss decreased (0.094840 --> 0.064696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656266\n",
      "\tspeed: 0.0360s/iter; left time: 794.7223s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644903\n",
      "\tspeed: 0.0142s/iter; left time: 310.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.56s\n",
      "Steps: 226 | Train Loss: 0.0656169 Vali Loss: 0.0608506 Test Loss: 0.0695716\n",
      "Validation loss decreased (0.064696 --> 0.060851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0650443\n",
      "\tspeed: 0.0367s/iter; left time: 801.7225s\n",
      "\titers: 200, epoch: 4 | loss: 0.0637198\n",
      "\tspeed: 0.0167s/iter; left time: 361.8758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 226 | Train Loss: 0.0626084 Vali Loss: 0.0608452 Test Loss: 0.0687740\n",
      "Validation loss decreased (0.060851 --> 0.060845).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0605330\n",
      "\tspeed: 0.0353s/iter; left time: 763.2295s\n",
      "\titers: 200, epoch: 5 | loss: 0.0562332\n",
      "\tspeed: 0.0169s/iter; left time: 363.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 226 | Train Loss: 0.0605957 Vali Loss: 0.0582919 Test Loss: 0.0657650\n",
      "Validation loss decreased (0.060845 --> 0.058292).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0593838\n",
      "\tspeed: 0.0358s/iter; left time: 765.0646s\n",
      "\titers: 200, epoch: 6 | loss: 0.0554853\n",
      "\tspeed: 0.0164s/iter; left time: 348.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 226 | Train Loss: 0.0590788 Vali Loss: 0.0575854 Test Loss: 0.0654073\n",
      "Validation loss decreased (0.058292 --> 0.057585).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0577590\n",
      "\tspeed: 0.0321s/iter; left time: 678.2140s\n",
      "\titers: 200, epoch: 7 | loss: 0.0586321\n",
      "\tspeed: 0.0141s/iter; left time: 297.7379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0578153 Vali Loss: 0.0572474 Test Loss: 0.0652406\n",
      "Validation loss decreased (0.057585 --> 0.057247).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573788\n",
      "\tspeed: 0.0356s/iter; left time: 745.1546s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589646\n",
      "\tspeed: 0.0164s/iter; left time: 341.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 226 | Train Loss: 0.0568043 Vali Loss: 0.0566638 Test Loss: 0.0647745\n",
      "Validation loss decreased (0.057247 --> 0.056664).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554692\n",
      "\tspeed: 0.0365s/iter; left time: 755.1849s\n",
      "\titers: 200, epoch: 9 | loss: 0.0569972\n",
      "\tspeed: 0.0172s/iter; left time: 354.9682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 226 | Train Loss: 0.0557859 Vali Loss: 0.0563612 Test Loss: 0.0648253\n",
      "Validation loss decreased (0.056664 --> 0.056361).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0549635\n",
      "\tspeed: 0.0345s/iter; left time: 706.5124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576599\n",
      "\tspeed: 0.0129s/iter; left time: 262.3400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0550394 Vali Loss: 0.0565279 Test Loss: 0.0645595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0579597\n",
      "\tspeed: 0.0299s/iter; left time: 604.7598s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546923\n",
      "\tspeed: 0.0143s/iter; left time: 288.0998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.49s\n",
      "Steps: 226 | Train Loss: 0.0542206 Vali Loss: 0.0558687 Test Loss: 0.0643536\n",
      "Validation loss decreased (0.056361 --> 0.055869).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553063\n",
      "\tspeed: 0.0326s/iter; left time: 653.1234s\n",
      "\titers: 200, epoch: 12 | loss: 0.0562879\n",
      "\tspeed: 0.0149s/iter; left time: 296.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.57s\n",
      "Steps: 226 | Train Loss: 0.0535740 Vali Loss: 0.0560607 Test Loss: 0.0641855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0526274\n",
      "\tspeed: 0.0299s/iter; left time: 590.9643s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506134\n",
      "\tspeed: 0.0128s/iter; left time: 251.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.0528816 Vali Loss: 0.0558748 Test Loss: 0.0646109\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0523458\n",
      "\tspeed: 0.0321s/iter; left time: 627.7665s\n",
      "\titers: 200, epoch: 14 | loss: 0.0522553\n",
      "\tspeed: 0.0155s/iter; left time: 300.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.67s\n",
      "Steps: 226 | Train Loss: 0.0523581 Vali Loss: 0.0556833 Test Loss: 0.0639260\n",
      "Validation loss decreased (0.055869 --> 0.055683).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533797\n",
      "\tspeed: 0.0303s/iter; left time: 585.9764s\n",
      "\titers: 200, epoch: 15 | loss: 0.0527787\n",
      "\tspeed: 0.0120s/iter; left time: 231.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 226 | Train Loss: 0.0518446 Vali Loss: 0.0558065 Test Loss: 0.0639597\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0511821\n",
      "\tspeed: 0.0288s/iter; left time: 550.8147s\n",
      "\titers: 200, epoch: 16 | loss: 0.0503562\n",
      "\tspeed: 0.0133s/iter; left time: 253.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0513143 Vali Loss: 0.0557360 Test Loss: 0.0640105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0486537\n",
      "\tspeed: 0.0308s/iter; left time: 581.3351s\n",
      "\titers: 200, epoch: 17 | loss: 0.0476101\n",
      "\tspeed: 0.0140s/iter; left time: 263.7673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0508641 Vali Loss: 0.0559398 Test Loss: 0.0641717\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0485818\n",
      "\tspeed: 0.0283s/iter; left time: 527.6909s\n",
      "\titers: 200, epoch: 18 | loss: 0.0535065\n",
      "\tspeed: 0.0132s/iter; left time: 245.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 226 | Train Loss: 0.0504648 Vali Loss: 0.0556975 Test Loss: 0.0639090\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0510360\n",
      "\tspeed: 0.0291s/iter; left time: 535.9671s\n",
      "\titers: 200, epoch: 19 | loss: 0.0510751\n",
      "\tspeed: 0.0132s/iter; left time: 241.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 226 | Train Loss: 0.0500255 Vali Loss: 0.0555788 Test Loss: 0.0645798\n",
      "Validation loss decreased (0.055683 --> 0.055579).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0480228\n",
      "\tspeed: 0.0310s/iter; left time: 564.2647s\n",
      "\titers: 200, epoch: 20 | loss: 0.0486701\n",
      "\tspeed: 0.0118s/iter; left time: 213.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 226 | Train Loss: 0.0497338 Vali Loss: 0.0556655 Test Loss: 0.0640523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0508732\n",
      "\tspeed: 0.0293s/iter; left time: 526.7977s\n",
      "\titers: 200, epoch: 21 | loss: 0.0497380\n",
      "\tspeed: 0.0135s/iter; left time: 241.2224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0494304 Vali Loss: 0.0556795 Test Loss: 0.0643621\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0473585\n",
      "\tspeed: 0.0334s/iter; left time: 592.9831s\n",
      "\titers: 200, epoch: 22 | loss: 0.0472204\n",
      "\tspeed: 0.0148s/iter; left time: 260.6466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 226 | Train Loss: 0.0491408 Vali Loss: 0.0556646 Test Loss: 0.0639770\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0470456\n",
      "\tspeed: 0.0300s/iter; left time: 526.3448s\n",
      "\titers: 200, epoch: 23 | loss: 0.0475197\n",
      "\tspeed: 0.0148s/iter; left time: 258.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 226 | Train Loss: 0.0488609 Vali Loss: 0.0553888 Test Loss: 0.0642007\n",
      "Validation loss decreased (0.055579 --> 0.055389).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0455110\n",
      "\tspeed: 0.0339s/iter; left time: 586.5159s\n",
      "\titers: 200, epoch: 24 | loss: 0.0500478\n",
      "\tspeed: 0.0153s/iter; left time: 262.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0485892 Vali Loss: 0.0554823 Test Loss: 0.0642269\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0482877\n",
      "\tspeed: 0.0303s/iter; left time: 516.6942s\n",
      "\titers: 200, epoch: 25 | loss: 0.0474017\n",
      "\tspeed: 0.0148s/iter; left time: 251.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.47s\n",
      "Steps: 226 | Train Loss: 0.0484185 Vali Loss: 0.0555517 Test Loss: 0.0643024\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0463871\n",
      "\tspeed: 0.0333s/iter; left time: 561.9433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0504324\n",
      "\tspeed: 0.0159s/iter; left time: 266.0565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 226 | Train Loss: 0.0482816 Vali Loss: 0.0555996 Test Loss: 0.0643811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0485109\n",
      "\tspeed: 0.0312s/iter; left time: 518.3908s\n",
      "\titers: 200, epoch: 27 | loss: 0.0479224\n",
      "\tspeed: 0.0161s/iter; left time: 265.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0481291 Vali Loss: 0.0556127 Test Loss: 0.0646453\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0471330\n",
      "\tspeed: 0.0312s/iter; left time: 511.5807s\n",
      "\titers: 200, epoch: 28 | loss: 0.0518033\n",
      "\tspeed: 0.0156s/iter; left time: 254.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 226 | Train Loss: 0.0478540 Vali Loss: 0.0555018 Test Loss: 0.0644240\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0485359\n",
      "\tspeed: 0.0317s/iter; left time: 512.2523s\n",
      "\titers: 200, epoch: 29 | loss: 0.0488524\n",
      "\tspeed: 0.0142s/iter; left time: 228.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0477066 Vali Loss: 0.0556953 Test Loss: 0.0644282\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0472911\n",
      "\tspeed: 0.0326s/iter; left time: 519.5575s\n",
      "\titers: 200, epoch: 30 | loss: 0.0448027\n",
      "\tspeed: 0.0156s/iter; left time: 247.6315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0477078 Vali Loss: 0.0554871 Test Loss: 0.0643446\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0477228\n",
      "\tspeed: 0.0299s/iter; left time: 470.5082s\n",
      "\titers: 200, epoch: 31 | loss: 0.0498036\n",
      "\tspeed: 0.0130s/iter; left time: 202.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0475542 Vali Loss: 0.0556037 Test Loss: 0.0645968\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0483816\n",
      "\tspeed: 0.0294s/iter; left time: 455.6521s\n",
      "\titers: 200, epoch: 32 | loss: 0.0490651\n",
      "\tspeed: 0.0134s/iter; left time: 206.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0474598 Vali Loss: 0.0556020 Test Loss: 0.0645061\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0466786\n",
      "\tspeed: 0.0300s/iter; left time: 457.3069s\n",
      "\titers: 200, epoch: 33 | loss: 0.0476728\n",
      "\tspeed: 0.0124s/iter; left time: 187.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0473318 Vali Loss: 0.0555336 Test Loss: 0.0645604\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01109654363244772, rmse:0.1053401306271553, mae:0.06420067697763443, rse:0.31000328063964844\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1298355\n",
      "\tspeed: 0.0189s/iter; left time: 425.7097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1092459\n",
      "\tspeed: 0.0153s/iter; left time: 342.7972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 226 | Train Loss: 0.1324643 Vali Loss: 0.0952392 Test Loss: 0.1059600\n",
      "Validation loss decreased (inf --> 0.095239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0745378\n",
      "\tspeed: 0.0320s/iter; left time: 712.1988s\n",
      "\titers: 200, epoch: 2 | loss: 0.0710034\n",
      "\tspeed: 0.0136s/iter; left time: 302.1962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.24s\n",
      "Steps: 226 | Train Loss: 0.0758506 Vali Loss: 0.0649607 Test Loss: 0.0730545\n",
      "Validation loss decreased (0.095239 --> 0.064961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0650133\n",
      "\tspeed: 0.0351s/iter; left time: 774.2808s\n",
      "\titers: 200, epoch: 3 | loss: 0.0632060\n",
      "\tspeed: 0.0136s/iter; left time: 298.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0659857 Vali Loss: 0.0615382 Test Loss: 0.0692593\n",
      "Validation loss decreased (0.064961 --> 0.061538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0613484\n",
      "\tspeed: 0.0309s/iter; left time: 673.9615s\n",
      "\titers: 200, epoch: 4 | loss: 0.0615166\n",
      "\tspeed: 0.0142s/iter; left time: 308.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0627952 Vali Loss: 0.0601462 Test Loss: 0.0677789\n",
      "Validation loss decreased (0.061538 --> 0.060146).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0595133\n",
      "\tspeed: 0.0305s/iter; left time: 657.7044s\n",
      "\titers: 200, epoch: 5 | loss: 0.0604066\n",
      "\tspeed: 0.0118s/iter; left time: 254.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0607027 Vali Loss: 0.0585906 Test Loss: 0.0664334\n",
      "Validation loss decreased (0.060146 --> 0.058591).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588046\n",
      "\tspeed: 0.0304s/iter; left time: 650.1725s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616833\n",
      "\tspeed: 0.0139s/iter; left time: 295.2668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 226 | Train Loss: 0.0592085 Vali Loss: 0.0581986 Test Loss: 0.0663687\n",
      "Validation loss decreased (0.058591 --> 0.058199).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566846\n",
      "\tspeed: 0.0319s/iter; left time: 674.6914s\n",
      "\titers: 200, epoch: 7 | loss: 0.0594041\n",
      "\tspeed: 0.0122s/iter; left time: 256.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.09s\n",
      "Steps: 226 | Train Loss: 0.0580842 Vali Loss: 0.0571749 Test Loss: 0.0646432\n",
      "Validation loss decreased (0.058199 --> 0.057175).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0596626\n",
      "\tspeed: 0.0308s/iter; left time: 643.8406s\n",
      "\titers: 200, epoch: 8 | loss: 0.0549480\n",
      "\tspeed: 0.0120s/iter; left time: 250.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 226 | Train Loss: 0.0569831 Vali Loss: 0.0570697 Test Loss: 0.0655890\n",
      "Validation loss decreased (0.057175 --> 0.057070).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571199\n",
      "\tspeed: 0.0340s/iter; left time: 704.3797s\n",
      "\titers: 200, epoch: 9 | loss: 0.0551791\n",
      "\tspeed: 0.0145s/iter; left time: 298.5578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 226 | Train Loss: 0.0560735 Vali Loss: 0.0568773 Test Loss: 0.0646910\n",
      "Validation loss decreased (0.057070 --> 0.056877).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0538923\n",
      "\tspeed: 0.0361s/iter; left time: 738.6884s\n",
      "\titers: 200, epoch: 10 | loss: 0.0502976\n",
      "\tspeed: 0.0173s/iter; left time: 353.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 226 | Train Loss: 0.0553372 Vali Loss: 0.0559911 Test Loss: 0.0639011\n",
      "Validation loss decreased (0.056877 --> 0.055991).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518299\n",
      "\tspeed: 0.0320s/iter; left time: 647.9743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0548057\n",
      "\tspeed: 0.0135s/iter; left time: 271.6938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.23s\n",
      "Steps: 226 | Train Loss: 0.0545444 Vali Loss: 0.0561786 Test Loss: 0.0642171\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0532315\n",
      "\tspeed: 0.0327s/iter; left time: 653.5227s\n",
      "\titers: 200, epoch: 12 | loss: 0.0545195\n",
      "\tspeed: 0.0154s/iter; left time: 305.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0539367 Vali Loss: 0.0557110 Test Loss: 0.0638198\n",
      "Validation loss decreased (0.055991 --> 0.055711).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0550689\n",
      "\tspeed: 0.0336s/iter; left time: 665.3167s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506262\n",
      "\tspeed: 0.0156s/iter; left time: 308.0019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 226 | Train Loss: 0.0532882 Vali Loss: 0.0560654 Test Loss: 0.0642667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0530066\n",
      "\tspeed: 0.0319s/iter; left time: 624.1550s\n",
      "\titers: 200, epoch: 14 | loss: 0.0509835\n",
      "\tspeed: 0.0143s/iter; left time: 278.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0528216 Vali Loss: 0.0559201 Test Loss: 0.0640503\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0481569\n",
      "\tspeed: 0.0304s/iter; left time: 588.7109s\n",
      "\titers: 200, epoch: 15 | loss: 0.0519428\n",
      "\tspeed: 0.0135s/iter; left time: 258.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0522880 Vali Loss: 0.0557858 Test Loss: 0.0635273\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0518527\n",
      "\tspeed: 0.0325s/iter; left time: 620.8857s\n",
      "\titers: 200, epoch: 16 | loss: 0.0541126\n",
      "\tspeed: 0.0142s/iter; left time: 270.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 226 | Train Loss: 0.0517717 Vali Loss: 0.0556043 Test Loss: 0.0634354\n",
      "Validation loss decreased (0.055711 --> 0.055604).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0538259\n",
      "\tspeed: 0.0307s/iter; left time: 579.5287s\n",
      "\titers: 200, epoch: 17 | loss: 0.0533093\n",
      "\tspeed: 0.0138s/iter; left time: 259.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.25s\n",
      "Steps: 226 | Train Loss: 0.0513273 Vali Loss: 0.0558820 Test Loss: 0.0638887\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0541670\n",
      "\tspeed: 0.0319s/iter; left time: 595.8923s\n",
      "\titers: 200, epoch: 18 | loss: 0.0492889\n",
      "\tspeed: 0.0124s/iter; left time: 229.5877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.0509906 Vali Loss: 0.0556682 Test Loss: 0.0640585\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0498789\n",
      "\tspeed: 0.0312s/iter; left time: 575.9430s\n",
      "\titers: 200, epoch: 19 | loss: 0.0512803\n",
      "\tspeed: 0.0144s/iter; left time: 264.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0505361 Vali Loss: 0.0561285 Test Loss: 0.0637186\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0488083\n",
      "\tspeed: 0.0305s/iter; left time: 555.3996s\n",
      "\titers: 200, epoch: 20 | loss: 0.0509687\n",
      "\tspeed: 0.0133s/iter; left time: 241.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 226 | Train Loss: 0.0502637 Vali Loss: 0.0555708 Test Loss: 0.0644000\n",
      "Validation loss decreased (0.055604 --> 0.055571).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0504927\n",
      "\tspeed: 0.0320s/iter; left time: 574.8542s\n",
      "\titers: 200, epoch: 21 | loss: 0.0481941\n",
      "\tspeed: 0.0137s/iter; left time: 245.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.48s\n",
      "Steps: 226 | Train Loss: 0.0500186 Vali Loss: 0.0558671 Test Loss: 0.0642352\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0490446\n",
      "\tspeed: 0.0318s/iter; left time: 563.8117s\n",
      "\titers: 200, epoch: 22 | loss: 0.0513775\n",
      "\tspeed: 0.0134s/iter; left time: 237.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0496050 Vali Loss: 0.0556694 Test Loss: 0.0642141\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0491438\n",
      "\tspeed: 0.0342s/iter; left time: 599.4655s\n",
      "\titers: 200, epoch: 23 | loss: 0.0535126\n",
      "\tspeed: 0.0130s/iter; left time: 226.0735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 226 | Train Loss: 0.0493393 Vali Loss: 0.0558761 Test Loss: 0.0642837\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0496071\n",
      "\tspeed: 0.0326s/iter; left time: 564.8397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0509492\n",
      "\tspeed: 0.0143s/iter; left time: 246.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.60s\n",
      "Steps: 226 | Train Loss: 0.0491453 Vali Loss: 0.0557350 Test Loss: 0.0642155\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0496965\n",
      "\tspeed: 0.0297s/iter; left time: 506.4310s\n",
      "\titers: 200, epoch: 25 | loss: 0.0495152\n",
      "\tspeed: 0.0124s/iter; left time: 209.7593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 226 | Train Loss: 0.0489119 Vali Loss: 0.0559967 Test Loss: 0.0642766\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0475527\n",
      "\tspeed: 0.0321s/iter; left time: 540.4320s\n",
      "\titers: 200, epoch: 26 | loss: 0.0487427\n",
      "\tspeed: 0.0136s/iter; left time: 226.9980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 226 | Train Loss: 0.0487386 Vali Loss: 0.0557482 Test Loss: 0.0642316\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0473309\n",
      "\tspeed: 0.0309s/iter; left time: 514.3980s\n",
      "\titers: 200, epoch: 27 | loss: 0.0468213\n",
      "\tspeed: 0.0132s/iter; left time: 217.7825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0485303 Vali Loss: 0.0559879 Test Loss: 0.0644699\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0497085\n",
      "\tspeed: 0.0308s/iter; left time: 505.2457s\n",
      "\titers: 200, epoch: 28 | loss: 0.0488404\n",
      "\tspeed: 0.0148s/iter; left time: 241.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0484617 Vali Loss: 0.0557874 Test Loss: 0.0643525\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0455155\n",
      "\tspeed: 0.0312s/iter; left time: 505.2553s\n",
      "\titers: 200, epoch: 29 | loss: 0.0474569\n",
      "\tspeed: 0.0147s/iter; left time: 235.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 226 | Train Loss: 0.0482477 Vali Loss: 0.0557425 Test Loss: 0.0644637\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0483084\n",
      "\tspeed: 0.0304s/iter; left time: 484.4458s\n",
      "\titers: 200, epoch: 30 | loss: 0.0468907\n",
      "\tspeed: 0.0156s/iter; left time: 246.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 226 | Train Loss: 0.0481475 Vali Loss: 0.0558674 Test Loss: 0.0642240\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_PatchTST_custom_ftM_sl96_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010962837375700474, rmse:0.10470356792211533, mae:0.06440004706382751, rse:0.3081299364566803\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:01.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1432228\n",
      "\tspeed: 0.0375s/iter; left time: 844.2336s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238714\n",
      "\tspeed: 0.0121s/iter; left time: 270.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.29s\n",
      "Steps: 226 | Train Loss: 0.1447640 Vali Loss: 0.1137416 Test Loss: 0.1272953\n",
      "Validation loss decreased (inf --> 0.113742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0955269\n",
      "\tspeed: 0.0311s/iter; left time: 693.2394s\n",
      "\titers: 200, epoch: 2 | loss: 0.0884188\n",
      "\tspeed: 0.0121s/iter; left time: 267.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 226 | Train Loss: 0.0972566 Vali Loss: 0.0874725 Test Loss: 0.0984257\n",
      "Validation loss decreased (0.113742 --> 0.087473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874788\n",
      "\tspeed: 0.0343s/iter; left time: 756.1255s\n",
      "\titers: 200, epoch: 3 | loss: 0.0853608\n",
      "\tspeed: 0.0121s/iter; left time: 264.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0877492 Vali Loss: 0.0840045 Test Loss: 0.0956733\n",
      "Validation loss decreased (0.087473 --> 0.084005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0824275\n",
      "\tspeed: 0.0313s/iter; left time: 683.2757s\n",
      "\titers: 200, epoch: 4 | loss: 0.0819495\n",
      "\tspeed: 0.0128s/iter; left time: 278.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 226 | Train Loss: 0.0845370 Vali Loss: 0.0823604 Test Loss: 0.0942157\n",
      "Validation loss decreased (0.084005 --> 0.082360).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856093\n",
      "\tspeed: 0.0314s/iter; left time: 677.1721s\n",
      "\titers: 200, epoch: 5 | loss: 0.0815057\n",
      "\tspeed: 0.0120s/iter; left time: 258.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 226 | Train Loss: 0.0815562 Vali Loss: 0.0824928 Test Loss: 0.0947016\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0787110\n",
      "\tspeed: 0.0292s/iter; left time: 624.6523s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779605\n",
      "\tspeed: 0.0148s/iter; left time: 313.8805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 226 | Train Loss: 0.0789403 Vali Loss: 0.0824665 Test Loss: 0.0950766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0765377\n",
      "\tspeed: 0.0288s/iter; left time: 608.9540s\n",
      "\titers: 200, epoch: 7 | loss: 0.0757090\n",
      "\tspeed: 0.0120s/iter; left time: 253.5146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 226 | Train Loss: 0.0764177 Vali Loss: 0.0838538 Test Loss: 0.0960459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758968\n",
      "\tspeed: 0.0298s/iter; left time: 622.6874s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748915\n",
      "\tspeed: 0.0123s/iter; left time: 255.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 226 | Train Loss: 0.0743212 Vali Loss: 0.0835326 Test Loss: 0.0956333\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0723564\n",
      "\tspeed: 0.0323s/iter; left time: 668.2648s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717292\n",
      "\tspeed: 0.0130s/iter; left time: 268.1406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0723764 Vali Loss: 0.0837987 Test Loss: 0.0963536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0709493\n",
      "\tspeed: 0.0319s/iter; left time: 652.8430s\n",
      "\titers: 200, epoch: 10 | loss: 0.0682494\n",
      "\tspeed: 0.0149s/iter; left time: 304.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 226 | Train Loss: 0.0706405 Vali Loss: 0.0848424 Test Loss: 0.0975980\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0689652\n",
      "\tspeed: 0.0302s/iter; left time: 611.0070s\n",
      "\titers: 200, epoch: 11 | loss: 0.0698718\n",
      "\tspeed: 0.0139s/iter; left time: 280.4228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0692242 Vali Loss: 0.0848600 Test Loss: 0.0973191\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0669707\n",
      "\tspeed: 0.0334s/iter; left time: 668.7953s\n",
      "\titers: 200, epoch: 12 | loss: 0.0676858\n",
      "\tspeed: 0.0125s/iter; left time: 248.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.36s\n",
      "Steps: 226 | Train Loss: 0.0678661 Vali Loss: 0.0850040 Test Loss: 0.0981115\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0670570\n",
      "\tspeed: 0.0316s/iter; left time: 625.9350s\n",
      "\titers: 200, epoch: 13 | loss: 0.0671279\n",
      "\tspeed: 0.0162s/iter; left time: 318.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.66s\n",
      "Steps: 226 | Train Loss: 0.0667887 Vali Loss: 0.0848042 Test Loss: 0.0973745\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0669436\n",
      "\tspeed: 0.0334s/iter; left time: 653.2888s\n",
      "\titers: 200, epoch: 14 | loss: 0.0658115\n",
      "\tspeed: 0.0144s/iter; left time: 279.4000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 226 | Train Loss: 0.0658884 Vali Loss: 0.0851748 Test Loss: 0.0982291\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020591821521520615, rmse:0.1434985101222992, mae:0.0942157432436943, rse:0.42155542969703674\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1458973\n",
      "\tspeed: 0.0149s/iter; left time: 335.3484s\n",
      "\titers: 200, epoch: 1 | loss: 0.1209050\n",
      "\tspeed: 0.0142s/iter; left time: 318.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 226 | Train Loss: 0.1446354 Vali Loss: 0.1140107 Test Loss: 0.1272782\n",
      "Validation loss decreased (inf --> 0.114011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0968597\n",
      "\tspeed: 0.0334s/iter; left time: 744.4784s\n",
      "\titers: 200, epoch: 2 | loss: 0.0873625\n",
      "\tspeed: 0.0129s/iter; left time: 286.8013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.19s\n",
      "Steps: 226 | Train Loss: 0.0971026 Vali Loss: 0.0873974 Test Loss: 0.0980609\n",
      "Validation loss decreased (0.114011 --> 0.087397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0936810\n",
      "\tspeed: 0.0346s/iter; left time: 763.4749s\n",
      "\titers: 200, epoch: 3 | loss: 0.0887708\n",
      "\tspeed: 0.0121s/iter; left time: 265.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.31s\n",
      "Steps: 226 | Train Loss: 0.0877442 Vali Loss: 0.0846649 Test Loss: 0.0955773\n",
      "Validation loss decreased (0.087397 --> 0.084665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853073\n",
      "\tspeed: 0.0322s/iter; left time: 701.7743s\n",
      "\titers: 200, epoch: 4 | loss: 0.0844880\n",
      "\tspeed: 0.0130s/iter; left time: 281.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 226 | Train Loss: 0.0845925 Vali Loss: 0.0829113 Test Loss: 0.0943428\n",
      "Validation loss decreased (0.084665 --> 0.082911).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0805078\n",
      "\tspeed: 0.0340s/iter; left time: 735.0449s\n",
      "\titers: 200, epoch: 5 | loss: 0.0772731\n",
      "\tspeed: 0.0121s/iter; left time: 259.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0814723 Vali Loss: 0.0831335 Test Loss: 0.0940529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0790438\n",
      "\tspeed: 0.0297s/iter; left time: 634.9107s\n",
      "\titers: 200, epoch: 6 | loss: 0.0774079\n",
      "\tspeed: 0.0133s/iter; left time: 282.0125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.20s\n",
      "Steps: 226 | Train Loss: 0.0787769 Vali Loss: 0.0828503 Test Loss: 0.0941699\n",
      "Validation loss decreased (0.082911 --> 0.082850).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0791036\n",
      "\tspeed: 0.0360s/iter; left time: 761.4989s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773327\n",
      "\tspeed: 0.0121s/iter; left time: 255.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0765849 Vali Loss: 0.0825221 Test Loss: 0.0944187\n",
      "Validation loss decreased (0.082850 --> 0.082522).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0779414\n",
      "\tspeed: 0.0327s/iter; left time: 683.6074s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706040\n",
      "\tspeed: 0.0122s/iter; left time: 253.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0744081 Vali Loss: 0.0831409 Test Loss: 0.0952084\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0727267\n",
      "\tspeed: 0.0301s/iter; left time: 622.7415s\n",
      "\titers: 200, epoch: 9 | loss: 0.0713194\n",
      "\tspeed: 0.0122s/iter; left time: 251.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 226 | Train Loss: 0.0726735 Vali Loss: 0.0840194 Test Loss: 0.0958889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0725458\n",
      "\tspeed: 0.0300s/iter; left time: 614.5744s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699228\n",
      "\tspeed: 0.0125s/iter; left time: 255.5549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 226 | Train Loss: 0.0708986 Vali Loss: 0.0840858 Test Loss: 0.0967213\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0693088\n",
      "\tspeed: 0.0320s/iter; left time: 647.0917s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708501\n",
      "\tspeed: 0.0138s/iter; left time: 278.7495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 226 | Train Loss: 0.0695247 Vali Loss: 0.0847357 Test Loss: 0.0971731\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692687\n",
      "\tspeed: 0.0311s/iter; left time: 623.4164s\n",
      "\titers: 200, epoch: 12 | loss: 0.0692844\n",
      "\tspeed: 0.0127s/iter; left time: 252.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 226 | Train Loss: 0.0683685 Vali Loss: 0.0849097 Test Loss: 0.0971900\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0708801\n",
      "\tspeed: 0.0320s/iter; left time: 632.2764s\n",
      "\titers: 200, epoch: 13 | loss: 0.0673890\n",
      "\tspeed: 0.0139s/iter; left time: 272.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 226 | Train Loss: 0.0673383 Vali Loss: 0.0847755 Test Loss: 0.0972421\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652700\n",
      "\tspeed: 0.0307s/iter; left time: 601.1893s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669420\n",
      "\tspeed: 0.0121s/iter; left time: 235.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.10s\n",
      "Steps: 226 | Train Loss: 0.0663956 Vali Loss: 0.0847587 Test Loss: 0.0976123\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0656001\n",
      "\tspeed: 0.0311s/iter; left time: 601.3867s\n",
      "\titers: 200, epoch: 15 | loss: 0.0670249\n",
      "\tspeed: 0.0144s/iter; left time: 276.1674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 226 | Train Loss: 0.0655526 Vali Loss: 0.0848967 Test Loss: 0.0976898\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0640606\n",
      "\tspeed: 0.0311s/iter; left time: 593.9456s\n",
      "\titers: 200, epoch: 16 | loss: 0.0629133\n",
      "\tspeed: 0.0140s/iter; left time: 265.2833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 226 | Train Loss: 0.0648504 Vali Loss: 0.0846819 Test Loss: 0.0984848\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0639562\n",
      "\tspeed: 0.0316s/iter; left time: 596.9246s\n",
      "\titers: 200, epoch: 17 | loss: 0.0628385\n",
      "\tspeed: 0.0161s/iter; left time: 302.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.63s\n",
      "Steps: 226 | Train Loss: 0.0641896 Vali Loss: 0.0848450 Test Loss: 0.0986550\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_PatchTST_custom_ftM_sl96_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021078813821077347, rmse:0.1451854407787323, mae:0.09441870450973511, rse:0.42651116847991943\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:30.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1440123\n",
      "\tspeed: 0.0397s/iter; left time: 890.1723s\n",
      "\titers: 200, epoch: 1 | loss: 0.1219980\n",
      "\tspeed: 0.0133s/iter; left time: 296.1898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.52s\n",
      "Steps: 225 | Train Loss: 0.1466884 Vali Loss: 0.1161049 Test Loss: 0.1299156\n",
      "Validation loss decreased (inf --> 0.116105).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1040402\n",
      "\tspeed: 0.0313s/iter; left time: 694.4444s\n",
      "\titers: 200, epoch: 2 | loss: 0.0966882\n",
      "\tspeed: 0.0123s/iter; left time: 271.7903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.1010600 Vali Loss: 0.0921646 Test Loss: 0.1041240\n",
      "Validation loss decreased (0.116105 --> 0.092165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899361\n",
      "\tspeed: 0.0352s/iter; left time: 772.0819s\n",
      "\titers: 200, epoch: 3 | loss: 0.0950214\n",
      "\tspeed: 0.0134s/iter; left time: 291.8156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.40s\n",
      "Steps: 225 | Train Loss: 0.0926913 Vali Loss: 0.0893897 Test Loss: 0.1015893\n",
      "Validation loss decreased (0.092165 --> 0.089390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0892411\n",
      "\tspeed: 0.0339s/iter; left time: 736.4591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0930670\n",
      "\tspeed: 0.0168s/iter; left time: 362.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 225 | Train Loss: 0.0895183 Vali Loss: 0.0888302 Test Loss: 0.1012411\n",
      "Validation loss decreased (0.089390 --> 0.088830).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0884369\n",
      "\tspeed: 0.0357s/iter; left time: 768.1049s\n",
      "\titers: 200, epoch: 5 | loss: 0.0872802\n",
      "\tspeed: 0.0168s/iter; left time: 359.5232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 225 | Train Loss: 0.0865985 Vali Loss: 0.0877893 Test Loss: 0.1004086\n",
      "Validation loss decreased (0.088830 --> 0.087789).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0840330\n",
      "\tspeed: 0.0336s/iter; left time: 715.4638s\n",
      "\titers: 200, epoch: 6 | loss: 0.0823128\n",
      "\tspeed: 0.0128s/iter; left time: 270.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 225 | Train Loss: 0.0838192 Vali Loss: 0.0887944 Test Loss: 0.1016514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832603\n",
      "\tspeed: 0.0337s/iter; left time: 708.5193s\n",
      "\titers: 200, epoch: 7 | loss: 0.0816261\n",
      "\tspeed: 0.0129s/iter; left time: 270.8425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 225 | Train Loss: 0.0813194 Vali Loss: 0.0879882 Test Loss: 0.1014727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0812962\n",
      "\tspeed: 0.0341s/iter; left time: 710.9541s\n",
      "\titers: 200, epoch: 8 | loss: 0.0808096\n",
      "\tspeed: 0.0144s/iter; left time: 299.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 225 | Train Loss: 0.0792205 Vali Loss: 0.0892362 Test Loss: 0.1027877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0788369\n",
      "\tspeed: 0.0346s/iter; left time: 712.5531s\n",
      "\titers: 200, epoch: 9 | loss: 0.0769801\n",
      "\tspeed: 0.0138s/iter; left time: 282.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.50s\n",
      "Steps: 225 | Train Loss: 0.0775114 Vali Loss: 0.0888906 Test Loss: 0.1026241\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0758829\n",
      "\tspeed: 0.0308s/iter; left time: 628.2834s\n",
      "\titers: 200, epoch: 10 | loss: 0.0748430\n",
      "\tspeed: 0.0126s/iter; left time: 255.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 225 | Train Loss: 0.0759378 Vali Loss: 0.0889411 Test Loss: 0.1016021\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736376\n",
      "\tspeed: 0.0361s/iter; left time: 728.2056s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769293\n",
      "\tspeed: 0.0181s/iter; left time: 362.5480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 225 | Train Loss: 0.0745113 Vali Loss: 0.0889894 Test Loss: 0.1026308\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0737329\n",
      "\tspeed: 0.0324s/iter; left time: 646.1770s\n",
      "\titers: 200, epoch: 12 | loss: 0.0753965\n",
      "\tspeed: 0.0147s/iter; left time: 292.2608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.43s\n",
      "Steps: 225 | Train Loss: 0.0733924 Vali Loss: 0.0899609 Test Loss: 0.1038212\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0697909\n",
      "\tspeed: 0.0341s/iter; left time: 672.1620s\n",
      "\titers: 200, epoch: 13 | loss: 0.0727018\n",
      "\tspeed: 0.0164s/iter; left time: 321.5129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 225 | Train Loss: 0.0723242 Vali Loss: 0.0899475 Test Loss: 0.1035086\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0750063\n",
      "\tspeed: 0.0315s/iter; left time: 613.9311s\n",
      "\titers: 200, epoch: 14 | loss: 0.0676442\n",
      "\tspeed: 0.0123s/iter; left time: 238.2339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 225 | Train Loss: 0.0714187 Vali Loss: 0.0898940 Test Loss: 0.1037310\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717596\n",
      "\tspeed: 0.0300s/iter; left time: 577.3359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0693328\n",
      "\tspeed: 0.0126s/iter; left time: 240.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 225 | Train Loss: 0.0705878 Vali Loss: 0.0899751 Test Loss: 0.1043542\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02318292111158371, rmse:0.15225939452648163, mae:0.10040855407714844, rse:0.44732439517974854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1436104\n",
      "\tspeed: 0.0164s/iter; left time: 368.1913s\n",
      "\titers: 200, epoch: 1 | loss: 0.1193593\n",
      "\tspeed: 0.0136s/iter; left time: 303.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.37s\n",
      "Steps: 225 | Train Loss: 0.1461999 Vali Loss: 0.1158600 Test Loss: 0.1296075\n",
      "Validation loss decreased (inf --> 0.115860).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1006850\n",
      "\tspeed: 0.0330s/iter; left time: 731.5806s\n",
      "\titers: 200, epoch: 2 | loss: 0.0938409\n",
      "\tspeed: 0.0140s/iter; left time: 309.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.39s\n",
      "Steps: 225 | Train Loss: 0.1011552 Vali Loss: 0.0925210 Test Loss: 0.1042791\n",
      "Validation loss decreased (0.115860 --> 0.092521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930860\n",
      "\tspeed: 0.0365s/iter; left time: 800.1507s\n",
      "\titers: 200, epoch: 3 | loss: 0.0923619\n",
      "\tspeed: 0.0149s/iter; left time: 324.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 225 | Train Loss: 0.0927644 Vali Loss: 0.0893844 Test Loss: 0.1019361\n",
      "Validation loss decreased (0.092521 --> 0.089384).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0871660\n",
      "\tspeed: 0.0340s/iter; left time: 737.7469s\n",
      "\titers: 200, epoch: 4 | loss: 0.0888119\n",
      "\tspeed: 0.0135s/iter; left time: 292.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.34s\n",
      "Steps: 225 | Train Loss: 0.0894383 Vali Loss: 0.0884936 Test Loss: 0.1005468\n",
      "Validation loss decreased (0.089384 --> 0.088494).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867392\n",
      "\tspeed: 0.0351s/iter; left time: 754.3810s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861428\n",
      "\tspeed: 0.0127s/iter; left time: 272.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.35s\n",
      "Steps: 225 | Train Loss: 0.0864125 Vali Loss: 0.0877658 Test Loss: 0.1002546\n",
      "Validation loss decreased (0.088494 --> 0.087766).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0862639\n",
      "\tspeed: 0.0359s/iter; left time: 763.1126s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836816\n",
      "\tspeed: 0.0172s/iter; left time: 364.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 225 | Train Loss: 0.0836745 Vali Loss: 0.0889044 Test Loss: 0.1009149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0794809\n",
      "\tspeed: 0.0328s/iter; left time: 690.1293s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806813\n",
      "\tspeed: 0.0153s/iter; left time: 320.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.46s\n",
      "Steps: 225 | Train Loss: 0.0812870 Vali Loss: 0.0894548 Test Loss: 0.1015984\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774965\n",
      "\tspeed: 0.0304s/iter; left time: 632.9189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797873\n",
      "\tspeed: 0.0131s/iter; left time: 270.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 225 | Train Loss: 0.0792019 Vali Loss: 0.0893858 Test Loss: 0.1016538\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0790205\n",
      "\tspeed: 0.0304s/iter; left time: 627.2970s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798370\n",
      "\tspeed: 0.0129s/iter; left time: 264.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 225 | Train Loss: 0.0773558 Vali Loss: 0.0895552 Test Loss: 0.1018691\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0766863\n",
      "\tspeed: 0.0304s/iter; left time: 619.8486s\n",
      "\titers: 200, epoch: 10 | loss: 0.0779208\n",
      "\tspeed: 0.0123s/iter; left time: 249.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 225 | Train Loss: 0.0758604 Vali Loss: 0.0904989 Test Loss: 0.1023914\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0734509\n",
      "\tspeed: 0.0304s/iter; left time: 612.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0725524\n",
      "\tspeed: 0.0123s/iter; left time: 246.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 225 | Train Loss: 0.0744450 Vali Loss: 0.0893395 Test Loss: 0.1021138\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720939\n",
      "\tspeed: 0.0315s/iter; left time: 627.2959s\n",
      "\titers: 200, epoch: 12 | loss: 0.0722905\n",
      "\tspeed: 0.0174s/iter; left time: 344.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 225 | Train Loss: 0.0732077 Vali Loss: 0.0904308 Test Loss: 0.1031738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749435\n",
      "\tspeed: 0.0346s/iter; left time: 681.6041s\n",
      "\titers: 200, epoch: 13 | loss: 0.0711577\n",
      "\tspeed: 0.0164s/iter; left time: 321.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 225 | Train Loss: 0.0722044 Vali Loss: 0.0908698 Test Loss: 0.1039440\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742032\n",
      "\tspeed: 0.0339s/iter; left time: 660.8271s\n",
      "\titers: 200, epoch: 14 | loss: 0.0721227\n",
      "\tspeed: 0.0135s/iter; left time: 261.5623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.41s\n",
      "Steps: 225 | Train Loss: 0.0711550 Vali Loss: 0.0902325 Test Loss: 0.1029459\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0705779\n",
      "\tspeed: 0.0327s/iter; left time: 629.7867s\n",
      "\titers: 200, epoch: 15 | loss: 0.0729217\n",
      "\tspeed: 0.0127s/iter; left time: 242.2724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.30s\n",
      "Steps: 225 | Train Loss: 0.0703936 Vali Loss: 0.0904472 Test Loss: 0.1037747\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_PatchTST_custom_ftM_sl96_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023172199726104736, rmse:0.15222418308258057, mae:0.10025465488433838, rse:0.44722095131874084\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:33.42s\n",
      "Intermediate time for ES: 00h:10m:05.58s\n",
      "Total time: 00h:10m:05.58s\n"
     ]
    }
   ],
   "source": [
    "countries = ['ES']\n",
    "num_cols = [3]\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_96.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            seq_len=96\n",
    "\n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.0643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "ES      24        0.0110  0.1050  0.0643\n",
       "        96        0.0208  0.1443  0.0943\n",
       "        168       0.0232  0.1522  0.1003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_96.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0766317\n",
      "\tspeed: 0.1594s/iter; left time: 704.8764s\n",
      "\titers: 200, epoch: 1 | loss: 0.0695265\n",
      "\tspeed: 0.1316s/iter; left time: 568.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.51s\n",
      "Steps: 226 | Train Loss: 0.0817155 Vali Loss: 0.0705644 Test Loss: 0.0732726\n",
      "Validation loss decreased (inf --> 0.070564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0562303\n",
      "\tspeed: 0.2236s/iter; left time: 938.0175s\n",
      "\titers: 200, epoch: 2 | loss: 0.0503308\n",
      "\tspeed: 0.1293s/iter; left time: 529.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 226 | Train Loss: 0.0548762 Vali Loss: 0.0606296 Test Loss: 0.0633584\n",
      "Validation loss decreased (0.070564 --> 0.060630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0513493\n",
      "\tspeed: 0.2205s/iter; left time: 875.1299s\n",
      "\titers: 200, epoch: 3 | loss: 0.0548947\n",
      "\tspeed: 0.1285s/iter; left time: 497.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0505532 Vali Loss: 0.0587098 Test Loss: 0.0624320\n",
      "Validation loss decreased (0.060630 --> 0.058710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0527826\n",
      "\tspeed: 0.2214s/iter; left time: 828.5555s\n",
      "\titers: 200, epoch: 4 | loss: 0.0514440\n",
      "\tspeed: 0.1308s/iter; left time: 476.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 226 | Train Loss: 0.0490150 Vali Loss: 0.0584218 Test Loss: 0.0620288\n",
      "Validation loss decreased (0.058710 --> 0.058422).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478798\n",
      "\tspeed: 0.2201s/iter; left time: 773.9429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0479713\n",
      "\tspeed: 0.1288s/iter; left time: 440.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 226 | Train Loss: 0.0479430 Vali Loss: 0.0563894 Test Loss: 0.0599632\n",
      "Validation loss decreased (0.058422 --> 0.056389).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0510816\n",
      "\tspeed: 0.2214s/iter; left time: 728.4802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0462048\n",
      "\tspeed: 0.1288s/iter; left time: 410.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0474372 Vali Loss: 0.0566435 Test Loss: 0.0606992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0459774\n",
      "\tspeed: 0.2215s/iter; left time: 679.0356s\n",
      "\titers: 200, epoch: 7 | loss: 0.0513296\n",
      "\tspeed: 0.1256s/iter; left time: 372.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.97s\n",
      "Steps: 226 | Train Loss: 0.0469073 Vali Loss: 0.0559441 Test Loss: 0.0600186\n",
      "Validation loss decreased (0.056389 --> 0.055944).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0457944\n",
      "\tspeed: 0.2160s/iter; left time: 613.3527s\n",
      "\titers: 200, epoch: 8 | loss: 0.0448213\n",
      "\tspeed: 0.1306s/iter; left time: 357.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 226 | Train Loss: 0.0464634 Vali Loss: 0.0558273 Test Loss: 0.0593858\n",
      "Validation loss decreased (0.055944 --> 0.055827).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463735\n",
      "\tspeed: 0.2207s/iter; left time: 576.7132s\n",
      "\titers: 200, epoch: 9 | loss: 0.0489007\n",
      "\tspeed: 0.1280s/iter; left time: 321.7713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.29s\n",
      "Steps: 226 | Train Loss: 0.0461754 Vali Loss: 0.0556516 Test Loss: 0.0595443\n",
      "Validation loss decreased (0.055827 --> 0.055652).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0466776\n",
      "\tspeed: 0.2180s/iter; left time: 520.3154s\n",
      "\titers: 200, epoch: 10 | loss: 0.0459872\n",
      "\tspeed: 0.1278s/iter; left time: 292.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0457334 Vali Loss: 0.0548611 Test Loss: 0.0585909\n",
      "Validation loss decreased (0.055652 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0433881\n",
      "\tspeed: 0.2203s/iter; left time: 476.1144s\n",
      "\titers: 200, epoch: 11 | loss: 0.0430847\n",
      "\tspeed: 0.1303s/iter; left time: 268.5118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0453992 Vali Loss: 0.0553987 Test Loss: 0.0589465\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0467320\n",
      "\tspeed: 0.2355s/iter; left time: 455.6640s\n",
      "\titers: 200, epoch: 12 | loss: 0.0414491\n",
      "\tspeed: 0.1276s/iter; left time: 234.2293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.63s\n",
      "Steps: 226 | Train Loss: 0.0452521 Vali Loss: 0.0548284 Test Loss: 0.0586648\n",
      "Validation loss decreased (0.054861 --> 0.054828).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.2175s/iter; left time: 371.7388s\n",
      "\titers: 200, epoch: 13 | loss: 0.0478617\n",
      "\tspeed: 0.1292s/iter; left time: 207.9196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 226 | Train Loss: 0.0450395 Vali Loss: 0.0549135 Test Loss: 0.0585464\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0442970\n",
      "\tspeed: 0.2223s/iter; left time: 329.6137s\n",
      "\titers: 200, epoch: 14 | loss: 0.0503605\n",
      "\tspeed: 0.1325s/iter; left time: 183.2741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 226 | Train Loss: 0.0447735 Vali Loss: 0.0546823 Test Loss: 0.0583076\n",
      "Validation loss decreased (0.054828 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0424463\n",
      "\tspeed: 0.2271s/iter; left time: 285.4459s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444540\n",
      "\tspeed: 0.1271s/iter; left time: 147.1046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0446773 Vali Loss: 0.0546821 Test Loss: 0.0582906\n",
      "Validation loss decreased (0.054682 --> 0.054682).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0437147\n",
      "\tspeed: 0.2197s/iter; left time: 226.5216s\n",
      "\titers: 200, epoch: 16 | loss: 0.0457383\n",
      "\tspeed: 0.1265s/iter; left time: 117.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.24s\n",
      "Steps: 226 | Train Loss: 0.0444284 Vali Loss: 0.0544112 Test Loss: 0.0578407\n",
      "Validation loss decreased (0.054682 --> 0.054411).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0409016\n",
      "\tspeed: 0.2172s/iter; left time: 174.8492s\n",
      "\titers: 200, epoch: 17 | loss: 0.0478386\n",
      "\tspeed: 0.1298s/iter; left time: 91.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 226 | Train Loss: 0.0443060 Vali Loss: 0.0542591 Test Loss: 0.0578918\n",
      "Validation loss decreased (0.054411 --> 0.054259).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0443076\n",
      "\tspeed: 0.2171s/iter; left time: 125.7041s\n",
      "\titers: 200, epoch: 18 | loss: 0.0450188\n",
      "\tspeed: 0.1293s/iter; left time: 61.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 226 | Train Loss: 0.0441691 Vali Loss: 0.0540334 Test Loss: 0.0580545\n",
      "Validation loss decreased (0.054259 --> 0.054033).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0454062\n",
      "\tspeed: 0.2185s/iter; left time: 77.1218s\n",
      "\titers: 200, epoch: 19 | loss: 0.0424051\n",
      "\tspeed: 0.1292s/iter; left time: 32.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.50s\n",
      "Steps: 226 | Train Loss: 0.0440228 Vali Loss: 0.0539079 Test Loss: 0.0574121\n",
      "Validation loss decreased (0.054033 --> 0.053908).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0425628\n",
      "\tspeed: 0.2249s/iter; left time: 28.5604s\n",
      "\titers: 200, epoch: 20 | loss: 0.0424072\n",
      "\tspeed: 0.1289s/iter; left time: 3.4791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 226 | Train Loss: 0.0439709 Vali Loss: 0.0540611 Test Loss: 0.0577443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010757667943835258, rmse:0.10371917486190796, mae:0.057412099093198776, rse:0.4001457095146179\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0778962\n",
      "\tspeed: 0.1302s/iter; left time: 575.4611s\n",
      "\titers: 200, epoch: 1 | loss: 0.0747243\n",
      "\tspeed: 0.1281s/iter; left time: 553.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 226 | Train Loss: 0.0831907 Vali Loss: 0.0704090 Test Loss: 0.0729090\n",
      "Validation loss decreased (inf --> 0.070409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0543477\n",
      "\tspeed: 0.2208s/iter; left time: 926.2374s\n",
      "\titers: 200, epoch: 2 | loss: 0.0524221\n",
      "\tspeed: 0.1277s/iter; left time: 523.0096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 226 | Train Loss: 0.0553467 Vali Loss: 0.0607321 Test Loss: 0.0636736\n",
      "Validation loss decreased (0.070409 --> 0.060732).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0470920\n",
      "\tspeed: 0.2191s/iter; left time: 869.6660s\n",
      "\titers: 200, epoch: 3 | loss: 0.0494604\n",
      "\tspeed: 0.1267s/iter; left time: 490.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.01s\n",
      "Steps: 226 | Train Loss: 0.0507888 Vali Loss: 0.0581976 Test Loss: 0.0614593\n",
      "Validation loss decreased (0.060732 --> 0.058198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0472974\n",
      "\tspeed: 0.2199s/iter; left time: 823.1736s\n",
      "\titers: 200, epoch: 4 | loss: 0.0468269\n",
      "\tspeed: 0.1290s/iter; left time: 469.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.37s\n",
      "Steps: 226 | Train Loss: 0.0489967 Vali Loss: 0.0577703 Test Loss: 0.0621285\n",
      "Validation loss decreased (0.058198 --> 0.057770).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0490690\n",
      "\tspeed: 0.2222s/iter; left time: 781.3646s\n",
      "\titers: 200, epoch: 5 | loss: 0.0480625\n",
      "\tspeed: 0.1290s/iter; left time: 440.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 226 | Train Loss: 0.0481537 Vali Loss: 0.0568581 Test Loss: 0.0606220\n",
      "Validation loss decreased (0.057770 --> 0.056858).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454466\n",
      "\tspeed: 0.2245s/iter; left time: 738.7034s\n",
      "\titers: 200, epoch: 6 | loss: 0.0472364\n",
      "\tspeed: 0.1300s/iter; left time: 414.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.66s\n",
      "Steps: 226 | Train Loss: 0.0473543 Vali Loss: 0.0561352 Test Loss: 0.0599884\n",
      "Validation loss decreased (0.056858 --> 0.056135).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0457151\n",
      "\tspeed: 0.2253s/iter; left time: 690.5855s\n",
      "\titers: 200, epoch: 7 | loss: 0.0485219\n",
      "\tspeed: 0.1273s/iter; left time: 377.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.23s\n",
      "Steps: 226 | Train Loss: 0.0469531 Vali Loss: 0.0555767 Test Loss: 0.0595131\n",
      "Validation loss decreased (0.056135 --> 0.055577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0456666\n",
      "\tspeed: 0.2198s/iter; left time: 624.1087s\n",
      "\titers: 200, epoch: 8 | loss: 0.0436416\n",
      "\tspeed: 0.1267s/iter; left time: 347.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 226 | Train Loss: 0.0464396 Vali Loss: 0.0560706 Test Loss: 0.0598718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0451892\n",
      "\tspeed: 0.2140s/iter; left time: 559.1509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0475388\n",
      "\tspeed: 0.1279s/iter; left time: 321.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 226 | Train Loss: 0.0460145 Vali Loss: 0.0551534 Test Loss: 0.0584895\n",
      "Validation loss decreased (0.055577 --> 0.055153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0418452\n",
      "\tspeed: 0.2255s/iter; left time: 538.1840s\n",
      "\titers: 200, epoch: 10 | loss: 0.0461544\n",
      "\tspeed: 0.1294s/iter; left time: 295.8721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 226 | Train Loss: 0.0457849 Vali Loss: 0.0551798 Test Loss: 0.0594885\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0420638\n",
      "\tspeed: 0.2259s/iter; left time: 488.2519s\n",
      "\titers: 200, epoch: 11 | loss: 0.0461470\n",
      "\tspeed: 0.1284s/iter; left time: 264.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.36s\n",
      "Steps: 226 | Train Loss: 0.0454104 Vali Loss: 0.0548973 Test Loss: 0.0588777\n",
      "Validation loss decreased (0.055153 --> 0.054897).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0470574\n",
      "\tspeed: 0.2291s/iter; left time: 443.3602s\n",
      "\titers: 200, epoch: 12 | loss: 0.0454375\n",
      "\tspeed: 0.1288s/iter; left time: 236.2726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 226 | Train Loss: 0.0451413 Vali Loss: 0.0549472 Test Loss: 0.0585421\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0454469\n",
      "\tspeed: 0.2142s/iter; left time: 366.1507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0446453\n",
      "\tspeed: 0.1260s/iter; left time: 202.6874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 226 | Train Loss: 0.0450150 Vali Loss: 0.0546606 Test Loss: 0.0587026\n",
      "Validation loss decreased (0.054897 --> 0.054661).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0417745\n",
      "\tspeed: 0.2182s/iter; left time: 323.5572s\n",
      "\titers: 200, epoch: 14 | loss: 0.0470195\n",
      "\tspeed: 0.1297s/iter; left time: 179.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 226 | Train Loss: 0.0447190 Vali Loss: 0.0546096 Test Loss: 0.0580985\n",
      "Validation loss decreased (0.054661 --> 0.054610).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0412011\n",
      "\tspeed: 0.2209s/iter; left time: 277.6884s\n",
      "\titers: 200, epoch: 15 | loss: 0.0458716\n",
      "\tspeed: 0.1267s/iter; left time: 146.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.73s\n",
      "Steps: 226 | Train Loss: 0.0445536 Vali Loss: 0.0544069 Test Loss: 0.0583128\n",
      "Validation loss decreased (0.054610 --> 0.054407).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0444622\n",
      "\tspeed: 0.2213s/iter; left time: 228.1786s\n",
      "\titers: 200, epoch: 16 | loss: 0.0436480\n",
      "\tspeed: 0.1282s/iter; left time: 119.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 226 | Train Loss: 0.0444886 Vali Loss: 0.0541725 Test Loss: 0.0580277\n",
      "Validation loss decreased (0.054407 --> 0.054172).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0422892\n",
      "\tspeed: 0.2222s/iter; left time: 178.8709s\n",
      "\titers: 200, epoch: 17 | loss: 0.0470878\n",
      "\tspeed: 0.1280s/iter; left time: 90.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 226 | Train Loss: 0.0442781 Vali Loss: 0.0540447 Test Loss: 0.0577816\n",
      "Validation loss decreased (0.054172 --> 0.054045).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0428621\n",
      "\tspeed: 0.2221s/iter; left time: 128.6126s\n",
      "\titers: 200, epoch: 18 | loss: 0.0420758\n",
      "\tspeed: 0.1283s/iter; left time: 61.4677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 226 | Train Loss: 0.0441897 Vali Loss: 0.0538316 Test Loss: 0.0574501\n",
      "Validation loss decreased (0.054045 --> 0.053832).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0450100\n",
      "\tspeed: 0.2262s/iter; left time: 79.8356s\n",
      "\titers: 200, epoch: 19 | loss: 0.0438370\n",
      "\tspeed: 0.1301s/iter; left time: 32.9164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 226 | Train Loss: 0.0440705 Vali Loss: 0.0542827 Test Loss: 0.0579725\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0456248\n",
      "\tspeed: 0.2326s/iter; left time: 29.5355s\n",
      "\titers: 200, epoch: 20 | loss: 0.0453012\n",
      "\tspeed: 0.1281s/iter; left time: 3.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.80s\n",
      "Steps: 226 | Train Loss: 0.0439894 Vali Loss: 0.0539670 Test Loss: 0.0578357\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010744874365627766, rmse:0.10365748405456543, mae:0.057450130581855774, rse:0.3999077081680298\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:39.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0821435\n",
      "\tspeed: 0.1545s/iter; left time: 679.7485s\n",
      "\titers: 200, epoch: 1 | loss: 0.0831200\n",
      "\tspeed: 0.1290s/iter; left time: 554.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.47s\n",
      "Steps: 225 | Train Loss: 0.0913107 Vali Loss: 0.0835734 Test Loss: 0.0922536\n",
      "Validation loss decreased (inf --> 0.083573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0678073\n",
      "\tspeed: 0.2200s/iter; left time: 918.6109s\n",
      "\titers: 200, epoch: 2 | loss: 0.0694359\n",
      "\tspeed: 0.1323s/iter; left time: 539.0511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 225 | Train Loss: 0.0713360 Vali Loss: 0.0779968 Test Loss: 0.0871771\n",
      "Validation loss decreased (0.083573 --> 0.077997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693156\n",
      "\tspeed: 0.2307s/iter; left time: 911.5833s\n",
      "\titers: 200, epoch: 3 | loss: 0.0701405\n",
      "\tspeed: 0.1332s/iter; left time: 512.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.04s\n",
      "Steps: 225 | Train Loss: 0.0673879 Vali Loss: 0.0758549 Test Loss: 0.0862915\n",
      "Validation loss decreased (0.077997 --> 0.075855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0674907\n",
      "\tspeed: 0.2312s/iter; left time: 861.4394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0651132\n",
      "\tspeed: 0.1320s/iter; left time: 478.5976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.88s\n",
      "Steps: 225 | Train Loss: 0.0659649 Vali Loss: 0.0749174 Test Loss: 0.0851213\n",
      "Validation loss decreased (0.075855 --> 0.074917).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0647665\n",
      "\tspeed: 0.2353s/iter; left time: 823.8602s\n",
      "\titers: 200, epoch: 5 | loss: 0.0680801\n",
      "\tspeed: 0.1313s/iter; left time: 446.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0647660 Vali Loss: 0.0744220 Test Loss: 0.0845276\n",
      "Validation loss decreased (0.074917 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638947\n",
      "\tspeed: 0.2260s/iter; left time: 740.4066s\n",
      "\titers: 200, epoch: 6 | loss: 0.0613103\n",
      "\tspeed: 0.1293s/iter; left time: 410.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.40s\n",
      "Steps: 225 | Train Loss: 0.0637174 Vali Loss: 0.0733305 Test Loss: 0.0838157\n",
      "Validation loss decreased (0.074422 --> 0.073331).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639387\n",
      "\tspeed: 0.2250s/iter; left time: 686.4712s\n",
      "\titers: 200, epoch: 7 | loss: 0.0675600\n",
      "\tspeed: 0.1322s/iter; left time: 390.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.76s\n",
      "Steps: 225 | Train Loss: 0.0629273 Vali Loss: 0.0727968 Test Loss: 0.0837717\n",
      "Validation loss decreased (0.073331 --> 0.072797).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0639801\n",
      "\tspeed: 0.2265s/iter; left time: 639.9718s\n",
      "\titers: 200, epoch: 8 | loss: 0.0635716\n",
      "\tspeed: 0.1335s/iter; left time: 363.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.93s\n",
      "Steps: 225 | Train Loss: 0.0625018 Vali Loss: 0.0732585 Test Loss: 0.0833542\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613126\n",
      "\tspeed: 0.2306s/iter; left time: 599.6642s\n",
      "\titers: 200, epoch: 9 | loss: 0.0657632\n",
      "\tspeed: 0.1333s/iter; left time: 333.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.36s\n",
      "Steps: 225 | Train Loss: 0.0620127 Vali Loss: 0.0723178 Test Loss: 0.0833246\n",
      "Validation loss decreased (0.072797 --> 0.072318).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0602790\n",
      "\tspeed: 0.2521s/iter; left time: 599.0509s\n",
      "\titers: 200, epoch: 10 | loss: 0.0600664\n",
      "\tspeed: 0.1314s/iter; left time: 299.0723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:30.65s\n",
      "Steps: 225 | Train Loss: 0.0616372 Vali Loss: 0.0726278 Test Loss: 0.0831672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0597956\n",
      "\tspeed: 0.2272s/iter; left time: 488.7564s\n",
      "\titers: 200, epoch: 11 | loss: 0.0623358\n",
      "\tspeed: 0.1313s/iter; left time: 269.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.38s\n",
      "Steps: 225 | Train Loss: 0.0612253 Vali Loss: 0.0724789 Test Loss: 0.0828953\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646971\n",
      "\tspeed: 0.2234s/iter; left time: 430.1962s\n",
      "\titers: 200, epoch: 12 | loss: 0.0596059\n",
      "\tspeed: 0.1309s/iter; left time: 239.0566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 225 | Train Loss: 0.0609990 Vali Loss: 0.0719485 Test Loss: 0.0828231\n",
      "Validation loss decreased (0.072318 --> 0.071948).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0582323\n",
      "\tspeed: 0.2297s/iter; left time: 390.7735s\n",
      "\titers: 200, epoch: 13 | loss: 0.0634934\n",
      "\tspeed: 0.1343s/iter; left time: 215.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.37s\n",
      "Steps: 225 | Train Loss: 0.0607619 Vali Loss: 0.0720306 Test Loss: 0.0829450\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0619525\n",
      "\tspeed: 0.2277s/iter; left time: 336.1307s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590660\n",
      "\tspeed: 0.1288s/iter; left time: 177.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.32s\n",
      "Steps: 225 | Train Loss: 0.0605827 Vali Loss: 0.0714336 Test Loss: 0.0823739\n",
      "Validation loss decreased (0.071948 --> 0.071434).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0587442\n",
      "\tspeed: 0.2352s/iter; left time: 294.2492s\n",
      "\titers: 200, epoch: 15 | loss: 0.0619651\n",
      "\tspeed: 0.1357s/iter; left time: 156.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.52s\n",
      "Steps: 225 | Train Loss: 0.0603027 Vali Loss: 0.0718620 Test Loss: 0.0827420\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584721\n",
      "\tspeed: 0.2438s/iter; left time: 250.1415s\n",
      "\titers: 200, epoch: 16 | loss: 0.0555041\n",
      "\tspeed: 0.1298s/iter; left time: 120.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.02s\n",
      "Steps: 225 | Train Loss: 0.0602388 Vali Loss: 0.0716047 Test Loss: 0.0822622\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0603823\n",
      "\tspeed: 0.2270s/iter; left time: 181.8549s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582806\n",
      "\tspeed: 0.1320s/iter; left time: 92.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0599569 Vali Loss: 0.0717798 Test Loss: 0.0822858\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0589450\n",
      "\tspeed: 0.2184s/iter; left time: 125.7864s\n",
      "\titers: 200, epoch: 18 | loss: 0.0634137\n",
      "\tspeed: 0.1286s/iter; left time: 61.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.28s\n",
      "Steps: 225 | Train Loss: 0.0598509 Vali Loss: 0.0716802 Test Loss: 0.0823941\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0584398\n",
      "\tspeed: 0.2293s/iter; left time: 80.4760s\n",
      "\titers: 200, epoch: 19 | loss: 0.0588430\n",
      "\tspeed: 0.1327s/iter; left time: 33.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0596980 Vali Loss: 0.0715777 Test Loss: 0.0823717\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020205451175570488, rmse:0.14214588701725006, mae:0.08237384259700775, rse:0.549858033657074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0894169\n",
      "\tspeed: 0.1355s/iter; left time: 596.4210s\n",
      "\titers: 200, epoch: 1 | loss: 0.0878222\n",
      "\tspeed: 0.1323s/iter; left time: 568.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0921728 Vali Loss: 0.0833592 Test Loss: 0.0920192\n",
      "Validation loss decreased (inf --> 0.083359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0669506\n",
      "\tspeed: 0.2316s/iter; left time: 967.1961s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688249\n",
      "\tspeed: 0.1379s/iter; left time: 562.2376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.68s\n",
      "Steps: 225 | Train Loss: 0.0714438 Vali Loss: 0.0777502 Test Loss: 0.0868886\n",
      "Validation loss decreased (0.083359 --> 0.077750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638473\n",
      "\tspeed: 0.2275s/iter; left time: 898.6594s\n",
      "\titers: 200, epoch: 3 | loss: 0.0689979\n",
      "\tspeed: 0.1291s/iter; left time: 497.1331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 225 | Train Loss: 0.0672572 Vali Loss: 0.0760684 Test Loss: 0.0863736\n",
      "Validation loss decreased (0.077750 --> 0.076068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672900\n",
      "\tspeed: 0.2176s/iter; left time: 810.6828s\n",
      "\titers: 200, epoch: 4 | loss: 0.0639855\n",
      "\tspeed: 0.1278s/iter; left time: 463.2600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.98s\n",
      "Steps: 225 | Train Loss: 0.0658523 Vali Loss: 0.0749936 Test Loss: 0.0854241\n",
      "Validation loss decreased (0.076068 --> 0.074994).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0626215\n",
      "\tspeed: 0.2190s/iter; left time: 766.5479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626608\n",
      "\tspeed: 0.1280s/iter; left time: 435.2641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0646476 Vali Loss: 0.0739110 Test Loss: 0.0846380\n",
      "Validation loss decreased (0.074994 --> 0.073911).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0641698\n",
      "\tspeed: 0.2408s/iter; left time: 788.9978s\n",
      "\titers: 200, epoch: 6 | loss: 0.0627856\n",
      "\tspeed: 0.1388s/iter; left time: 440.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.55s\n",
      "Steps: 225 | Train Loss: 0.0639034 Vali Loss: 0.0747545 Test Loss: 0.0855872\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0652396\n",
      "\tspeed: 0.2333s/iter; left time: 711.9271s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667626\n",
      "\tspeed: 0.1315s/iter; left time: 387.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 225 | Train Loss: 0.0631427 Vali Loss: 0.0732717 Test Loss: 0.0834854\n",
      "Validation loss decreased (0.073911 --> 0.073272).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0631166\n",
      "\tspeed: 0.2220s/iter; left time: 627.4747s\n",
      "\titers: 200, epoch: 8 | loss: 0.0626838\n",
      "\tspeed: 0.1296s/iter; left time: 353.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.34s\n",
      "Steps: 225 | Train Loss: 0.0625255 Vali Loss: 0.0733401 Test Loss: 0.0836931\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0613080\n",
      "\tspeed: 0.2264s/iter; left time: 588.7666s\n",
      "\titers: 200, epoch: 9 | loss: 0.0632498\n",
      "\tspeed: 0.1335s/iter; left time: 333.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.98s\n",
      "Steps: 225 | Train Loss: 0.0621014 Vali Loss: 0.0734221 Test Loss: 0.0835117\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0624017\n",
      "\tspeed: 0.2320s/iter; left time: 551.2138s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701763\n",
      "\tspeed: 0.1306s/iter; left time: 297.2850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 225 | Train Loss: 0.0616782 Vali Loss: 0.0723835 Test Loss: 0.0828523\n",
      "Validation loss decreased (0.073272 --> 0.072383).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0656709\n",
      "\tspeed: 0.2371s/iter; left time: 510.0696s\n",
      "\titers: 200, epoch: 11 | loss: 0.0620192\n",
      "\tspeed: 0.1364s/iter; left time: 279.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0613649 Vali Loss: 0.0728863 Test Loss: 0.0833074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611714\n",
      "\tspeed: 0.2154s/iter; left time: 414.8459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0589759\n",
      "\tspeed: 0.1288s/iter; left time: 235.1587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.04s\n",
      "Steps: 225 | Train Loss: 0.0611654 Vali Loss: 0.0720310 Test Loss: 0.0828215\n",
      "Validation loss decreased (0.072383 --> 0.072031).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0601530\n",
      "\tspeed: 0.2293s/iter; left time: 390.0917s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627939\n",
      "\tspeed: 0.1299s/iter; left time: 207.9448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0608504 Vali Loss: 0.0722075 Test Loss: 0.0826092\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0604201\n",
      "\tspeed: 0.2315s/iter; left time: 341.7533s\n",
      "\titers: 200, epoch: 14 | loss: 0.0634251\n",
      "\tspeed: 0.1313s/iter; left time: 180.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0606327 Vali Loss: 0.0726777 Test Loss: 0.0831189\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0640372\n",
      "\tspeed: 0.2379s/iter; left time: 297.5685s\n",
      "\titers: 200, epoch: 15 | loss: 0.0630407\n",
      "\tspeed: 0.1352s/iter; left time: 155.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0604669 Vali Loss: 0.0721378 Test Loss: 0.0825559\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0591577\n",
      "\tspeed: 0.2499s/iter; left time: 256.4079s\n",
      "\titers: 200, epoch: 16 | loss: 0.0630949\n",
      "\tspeed: 0.1303s/iter; left time: 120.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 225 | Train Loss: 0.0602721 Vali Loss: 0.0723365 Test Loss: 0.0823819\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0585780\n",
      "\tspeed: 0.2232s/iter; left time: 178.7965s\n",
      "\titers: 200, epoch: 17 | loss: 0.0607349\n",
      "\tspeed: 0.1285s/iter; left time: 90.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 225 | Train Loss: 0.0601261 Vali Loss: 0.0719406 Test Loss: 0.0822569\n",
      "Validation loss decreased (0.072031 --> 0.071941).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0573446\n",
      "\tspeed: 0.2356s/iter; left time: 135.7109s\n",
      "\titers: 200, epoch: 18 | loss: 0.0599148\n",
      "\tspeed: 0.1314s/iter; left time: 62.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:29.67s\n",
      "Steps: 225 | Train Loss: 0.0599890 Vali Loss: 0.0719018 Test Loss: 0.0822290\n",
      "Validation loss decreased (0.071941 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0560430\n",
      "\tspeed: 0.2310s/iter; left time: 81.0980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0599572\n",
      "\tspeed: 0.1354s/iter; left time: 33.9758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:30.13s\n",
      "Steps: 225 | Train Loss: 0.0598794 Vali Loss: 0.0721454 Test Loss: 0.0823054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0642339\n",
      "\tspeed: 0.2471s/iter; left time: 31.1371s\n",
      "\titers: 200, epoch: 20 | loss: 0.0639723\n",
      "\tspeed: 0.1287s/iter; left time: 3.3475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 225 | Train Loss: 0.0597939 Vali Loss: 0.0717466 Test Loss: 0.0819931\n",
      "Validation loss decreased (0.071902 --> 0.071747).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019991254433989525, rmse:0.14139042794704437, mae:0.08199303597211838, rse:0.5469357967376709\n",
      "Intermediate time for FR and pred_len 96: 00h:23m:48.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0916881\n",
      "\tspeed: 0.1560s/iter; left time: 686.5020s\n",
      "\titers: 200, epoch: 1 | loss: 0.0869237\n",
      "\tspeed: 0.1299s/iter; left time: 558.7424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.70s\n",
      "Steps: 225 | Train Loss: 0.0946456 Vali Loss: 0.0873302 Test Loss: 0.0960933\n",
      "Validation loss decreased (inf --> 0.087330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765944\n",
      "\tspeed: 0.2283s/iter; left time: 953.3026s\n",
      "\titers: 200, epoch: 2 | loss: 0.0703099\n",
      "\tspeed: 0.1304s/iter; left time: 531.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.74s\n",
      "Steps: 225 | Train Loss: 0.0755584 Vali Loss: 0.0817829 Test Loss: 0.0917741\n",
      "Validation loss decreased (0.087330 --> 0.081783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0746351\n",
      "\tspeed: 0.2314s/iter; left time: 914.1378s\n",
      "\titers: 200, epoch: 3 | loss: 0.0698561\n",
      "\tspeed: 0.1303s/iter; left time: 501.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.53s\n",
      "Steps: 225 | Train Loss: 0.0723485 Vali Loss: 0.0802219 Test Loss: 0.0911483\n",
      "Validation loss decreased (0.081783 --> 0.080222).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0729910\n",
      "\tspeed: 0.2407s/iter; left time: 896.8529s\n",
      "\titers: 200, epoch: 4 | loss: 0.0687222\n",
      "\tspeed: 0.1320s/iter; left time: 478.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 225 | Train Loss: 0.0707458 Vali Loss: 0.0792043 Test Loss: 0.0905273\n",
      "Validation loss decreased (0.080222 --> 0.079204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0712522\n",
      "\tspeed: 0.2426s/iter; left time: 849.1715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0685331\n",
      "\tspeed: 0.1376s/iter; left time: 468.0457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.85s\n",
      "Steps: 225 | Train Loss: 0.0694804 Vali Loss: 0.0787229 Test Loss: 0.0898371\n",
      "Validation loss decreased (0.079204 --> 0.078723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0689771\n",
      "\tspeed: 0.2448s/iter; left time: 802.0766s\n",
      "\titers: 200, epoch: 6 | loss: 0.0695027\n",
      "\tspeed: 0.1285s/iter; left time: 408.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 225 | Train Loss: 0.0686404 Vali Loss: 0.0781113 Test Loss: 0.0888023\n",
      "Validation loss decreased (0.078723 --> 0.078111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0682323\n",
      "\tspeed: 0.2350s/iter; left time: 717.0457s\n",
      "\titers: 200, epoch: 7 | loss: 0.0699818\n",
      "\tspeed: 0.1299s/iter; left time: 383.3049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.94s\n",
      "Steps: 225 | Train Loss: 0.0679058 Vali Loss: 0.0782345 Test Loss: 0.0895413\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0707153\n",
      "\tspeed: 0.2300s/iter; left time: 649.8795s\n",
      "\titers: 200, epoch: 8 | loss: 0.0695843\n",
      "\tspeed: 0.1323s/iter; left time: 360.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.95s\n",
      "Steps: 225 | Train Loss: 0.0674135 Vali Loss: 0.0771264 Test Loss: 0.0888884\n",
      "Validation loss decreased (0.078111 --> 0.077126).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0653303\n",
      "\tspeed: 0.2277s/iter; left time: 592.3061s\n",
      "\titers: 200, epoch: 9 | loss: 0.0724449\n",
      "\tspeed: 0.1330s/iter; left time: 332.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0669095 Vali Loss: 0.0773865 Test Loss: 0.0887160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0634143\n",
      "\tspeed: 0.2379s/iter; left time: 565.1939s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633310\n",
      "\tspeed: 0.1394s/iter; left time: 317.1841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 225 | Train Loss: 0.0665528 Vali Loss: 0.0775114 Test Loss: 0.0891376\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0642596\n",
      "\tspeed: 0.2275s/iter; left time: 489.4264s\n",
      "\titers: 200, epoch: 11 | loss: 0.0683906\n",
      "\tspeed: 0.1276s/iter; left time: 261.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:29.03s\n",
      "Steps: 225 | Train Loss: 0.0662428 Vali Loss: 0.0768049 Test Loss: 0.0883481\n",
      "Validation loss decreased (0.077126 --> 0.076805).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0624630\n",
      "\tspeed: 0.2224s/iter; left time: 428.3307s\n",
      "\titers: 200, epoch: 12 | loss: 0.0640266\n",
      "\tspeed: 0.1273s/iter; left time: 232.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:29.06s\n",
      "Steps: 225 | Train Loss: 0.0660178 Vali Loss: 0.0770547 Test Loss: 0.0880818\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0683184\n",
      "\tspeed: 0.2192s/iter; left time: 372.8130s\n",
      "\titers: 200, epoch: 13 | loss: 0.0646703\n",
      "\tspeed: 0.1305s/iter; left time: 208.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.52s\n",
      "Steps: 225 | Train Loss: 0.0657393 Vali Loss: 0.0767636 Test Loss: 0.0878029\n",
      "Validation loss decreased (0.076805 --> 0.076764).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0680823\n",
      "\tspeed: 0.2324s/iter; left time: 343.0095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0666962\n",
      "\tspeed: 0.1327s/iter; left time: 182.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.85s\n",
      "Steps: 225 | Train Loss: 0.0655135 Vali Loss: 0.0769423 Test Loss: 0.0880894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0665233\n",
      "\tspeed: 0.2246s/iter; left time: 281.0342s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659037\n",
      "\tspeed: 0.1345s/iter; left time: 154.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.31s\n",
      "Steps: 225 | Train Loss: 0.0653375 Vali Loss: 0.0765706 Test Loss: 0.0880015\n",
      "Validation loss decreased (0.076764 --> 0.076571).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0669951\n",
      "\tspeed: 0.2355s/iter; left time: 241.6049s\n",
      "\titers: 200, epoch: 16 | loss: 0.0666725\n",
      "\tspeed: 0.1388s/iter; left time: 128.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 225 | Train Loss: 0.0651356 Vali Loss: 0.0767214 Test Loss: 0.0881702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0642989\n",
      "\tspeed: 0.2467s/iter; left time: 197.5974s\n",
      "\titers: 200, epoch: 17 | loss: 0.0637477\n",
      "\tspeed: 0.1343s/iter; left time: 94.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:30.53s\n",
      "Steps: 225 | Train Loss: 0.0649981 Vali Loss: 0.0762711 Test Loss: 0.0878609\n",
      "Validation loss decreased (0.076571 --> 0.076271).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0646516\n",
      "\tspeed: 0.2447s/iter; left time: 140.9559s\n",
      "\titers: 200, epoch: 18 | loss: 0.0679890\n",
      "\tspeed: 0.1346s/iter; left time: 64.0479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.47s\n",
      "Steps: 225 | Train Loss: 0.0648507 Vali Loss: 0.0767555 Test Loss: 0.0878701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0642924\n",
      "\tspeed: 0.2296s/iter; left time: 80.5763s\n",
      "\titers: 200, epoch: 19 | loss: 0.0647242\n",
      "\tspeed: 0.1311s/iter; left time: 32.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.71s\n",
      "Steps: 225 | Train Loss: 0.0647024 Vali Loss: 0.0764668 Test Loss: 0.0877801\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0624535\n",
      "\tspeed: 0.2363s/iter; left time: 29.7705s\n",
      "\titers: 200, epoch: 20 | loss: 0.0675110\n",
      "\tspeed: 0.1368s/iter; left time: 3.5563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.79s\n",
      "Steps: 225 | Train Loss: 0.0646263 Vali Loss: 0.0767285 Test Loss: 0.0880821\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02186432108283043, rmse:0.147865891456604, mae:0.08786085247993469, rse:0.5726985931396484\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0919613\n",
      "\tspeed: 0.1358s/iter; left time: 597.7374s\n",
      "\titers: 200, epoch: 1 | loss: 0.0867113\n",
      "\tspeed: 0.1342s/iter; left time: 577.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.35s\n",
      "Steps: 225 | Train Loss: 0.0940161 Vali Loss: 0.0871972 Test Loss: 0.0960238\n",
      "Validation loss decreased (inf --> 0.087197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0713059\n",
      "\tspeed: 0.2526s/iter; left time: 1054.7877s\n",
      "\titers: 200, epoch: 2 | loss: 0.0714525\n",
      "\tspeed: 0.1323s/iter; left time: 539.3826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.07s\n",
      "Steps: 225 | Train Loss: 0.0757864 Vali Loss: 0.0823225 Test Loss: 0.0925486\n",
      "Validation loss decreased (0.087197 --> 0.082323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0671578\n",
      "\tspeed: 0.2375s/iter; left time: 938.2541s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709672\n",
      "\tspeed: 0.1327s/iter; left time: 511.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 225 | Train Loss: 0.0723406 Vali Loss: 0.0810314 Test Loss: 0.0920664\n",
      "Validation loss decreased (0.082323 --> 0.081031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0700649\n",
      "\tspeed: 0.2308s/iter; left time: 859.8207s\n",
      "\titers: 200, epoch: 4 | loss: 0.0703632\n",
      "\tspeed: 0.1333s/iter; left time: 483.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.08s\n",
      "Steps: 225 | Train Loss: 0.0707206 Vali Loss: 0.0790750 Test Loss: 0.0903970\n",
      "Validation loss decreased (0.081031 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0656126\n",
      "\tspeed: 0.2482s/iter; left time: 869.1222s\n",
      "\titers: 200, epoch: 5 | loss: 0.0692182\n",
      "\tspeed: 0.1333s/iter; left time: 453.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 225 | Train Loss: 0.0694477 Vali Loss: 0.0789509 Test Loss: 0.0901828\n",
      "Validation loss decreased (0.079075 --> 0.078951).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0686687\n",
      "\tspeed: 0.2328s/iter; left time: 762.7674s\n",
      "\titers: 200, epoch: 6 | loss: 0.0678676\n",
      "\tspeed: 0.1305s/iter; left time: 414.3539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.92s\n",
      "Steps: 225 | Train Loss: 0.0686255 Vali Loss: 0.0783217 Test Loss: 0.0896430\n",
      "Validation loss decreased (0.078951 --> 0.078322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0661045\n",
      "\tspeed: 0.2638s/iter; left time: 804.9863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0682785\n",
      "\tspeed: 0.1376s/iter; left time: 406.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.81s\n",
      "Steps: 225 | Train Loss: 0.0678917 Vali Loss: 0.0783234 Test Loss: 0.0887447\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0683451\n",
      "\tspeed: 0.2095s/iter; left time: 591.9777s\n",
      "\titers: 200, epoch: 8 | loss: 0.0687753\n",
      "\tspeed: 0.1242s/iter; left time: 338.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0673855 Vali Loss: 0.0778848 Test Loss: 0.0888012\n",
      "Validation loss decreased (0.078322 --> 0.077885).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0657038\n",
      "\tspeed: 0.2074s/iter; left time: 539.5108s\n",
      "\titers: 200, epoch: 9 | loss: 0.0665707\n",
      "\tspeed: 0.1242s/iter; left time: 310.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 225 | Train Loss: 0.0668863 Vali Loss: 0.0776036 Test Loss: 0.0886073\n",
      "Validation loss decreased (0.077885 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0667441\n",
      "\tspeed: 0.2228s/iter; left time: 529.2991s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633583\n",
      "\tspeed: 0.1245s/iter; left time: 283.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0664838 Vali Loss: 0.0774441 Test Loss: 0.0883286\n",
      "Validation loss decreased (0.077604 --> 0.077444).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0627698\n",
      "\tspeed: 0.2068s/iter; left time: 444.8338s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660751\n",
      "\tspeed: 0.1249s/iter; left time: 256.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0662418 Vali Loss: 0.0770156 Test Loss: 0.0887772\n",
      "Validation loss decreased (0.077444 --> 0.077016).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683075\n",
      "\tspeed: 0.2137s/iter; left time: 411.6625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0689828\n",
      "\tspeed: 0.1246s/iter; left time: 227.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0658903 Vali Loss: 0.0768637 Test Loss: 0.0878356\n",
      "Validation loss decreased (0.077016 --> 0.076864).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0688406\n",
      "\tspeed: 0.2060s/iter; left time: 350.4884s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636687\n",
      "\tspeed: 0.1243s/iter; left time: 199.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0656338 Vali Loss: 0.0767962 Test Loss: 0.0876834\n",
      "Validation loss decreased (0.076864 --> 0.076796).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0652549\n",
      "\tspeed: 0.2430s/iter; left time: 358.6146s\n",
      "\titers: 200, epoch: 14 | loss: 0.0669380\n",
      "\tspeed: 0.1244s/iter; left time: 171.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0654096 Vali Loss: 0.0768992 Test Loss: 0.0880054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0605805\n",
      "\tspeed: 0.2051s/iter; left time: 256.5708s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669335\n",
      "\tspeed: 0.1242s/iter; left time: 142.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0652253 Vali Loss: 0.0767318 Test Loss: 0.0878261\n",
      "Validation loss decreased (0.076796 --> 0.076732).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0649559\n",
      "\tspeed: 0.2810s/iter; left time: 288.3519s\n",
      "\titers: 200, epoch: 16 | loss: 0.0645573\n",
      "\tspeed: 0.1239s/iter; left time: 114.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 225 | Train Loss: 0.0650691 Vali Loss: 0.0766515 Test Loss: 0.0880999\n",
      "Validation loss decreased (0.076732 --> 0.076652).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0705975\n",
      "\tspeed: 0.2069s/iter; left time: 165.6977s\n",
      "\titers: 200, epoch: 17 | loss: 0.0659833\n",
      "\tspeed: 0.1246s/iter; left time: 87.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0648604 Vali Loss: 0.0765938 Test Loss: 0.0877360\n",
      "Validation loss decreased (0.076652 --> 0.076594).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0670262\n",
      "\tspeed: 0.2088s/iter; left time: 120.2704s\n",
      "\titers: 200, epoch: 18 | loss: 0.0629649\n",
      "\tspeed: 0.1242s/iter; left time: 59.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0647039 Vali Loss: 0.0767391 Test Loss: 0.0876653\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0651461\n",
      "\tspeed: 0.2065s/iter; left time: 72.4737s\n",
      "\titers: 200, epoch: 19 | loss: 0.0666738\n",
      "\tspeed: 0.1247s/iter; left time: 31.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0646175 Vali Loss: 0.0765972 Test Loss: 0.0876592\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0639071\n",
      "\tspeed: 0.2063s/iter; left time: 25.9905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0667633\n",
      "\tspeed: 0.1248s/iter; left time: 3.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 225 | Train Loss: 0.0645528 Vali Loss: 0.0764963 Test Loss: 0.0876327\n",
      "Validation loss decreased (0.076594 --> 0.076496).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021848367527127266, rmse:0.14781193435192108, mae:0.08763277530670166, rse:0.5724896192550659\n",
      "Intermediate time for FR and pred_len 168: 00h:24m:15.00s\n",
      "Intermediate time for FR: 01h:11m:43.09s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1121790\n",
      "\tspeed: 0.1485s/iter; left time: 656.3155s\n",
      "\titers: 200, epoch: 1 | loss: 0.1071127\n",
      "\tspeed: 0.1232s/iter; left time: 532.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.1183522 Vali Loss: 0.0811168 Test Loss: 0.0823932\n",
      "Validation loss decreased (inf --> 0.081117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0740139\n",
      "\tspeed: 0.2044s/iter; left time: 857.5001s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693383\n",
      "\tspeed: 0.1233s/iter; left time: 504.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0758895 Vali Loss: 0.0661073 Test Loss: 0.0684309\n",
      "Validation loss decreased (0.081117 --> 0.066107).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0692373\n",
      "\tspeed: 0.2102s/iter; left time: 834.3075s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680119\n",
      "\tspeed: 0.1235s/iter; left time: 477.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 226 | Train Loss: 0.0688669 Vali Loss: 0.0632555 Test Loss: 0.0659584\n",
      "Validation loss decreased (0.066107 --> 0.063256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691024\n",
      "\tspeed: 0.2072s/iter; left time: 775.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.0713159\n",
      "\tspeed: 0.1235s/iter; left time: 449.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0659160 Vali Loss: 0.0616597 Test Loss: 0.0638568\n",
      "Validation loss decreased (0.063256 --> 0.061660).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0636145\n",
      "\tspeed: 0.2046s/iter; left time: 719.5598s\n",
      "\titers: 200, epoch: 5 | loss: 0.0682091\n",
      "\tspeed: 0.1239s/iter; left time: 423.2400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.14s\n",
      "Steps: 226 | Train Loss: 0.0640215 Vali Loss: 0.0601045 Test Loss: 0.0630680\n",
      "Validation loss decreased (0.061660 --> 0.060105).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645924\n",
      "\tspeed: 0.2080s/iter; left time: 684.6706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0623100\n",
      "\tspeed: 0.1244s/iter; left time: 396.8996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0623804 Vali Loss: 0.0589569 Test Loss: 0.0620875\n",
      "Validation loss decreased (0.060105 --> 0.058957).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0597447\n",
      "\tspeed: 0.2059s/iter; left time: 631.1167s\n",
      "\titers: 200, epoch: 7 | loss: 0.0645506\n",
      "\tspeed: 0.1241s/iter; left time: 368.0582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 226 | Train Loss: 0.0614329 Vali Loss: 0.0588587 Test Loss: 0.0619362\n",
      "Validation loss decreased (0.058957 --> 0.058859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0571509\n",
      "\tspeed: 0.2078s/iter; left time: 589.9646s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552820\n",
      "\tspeed: 0.1242s/iter; left time: 340.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 226 | Train Loss: 0.0606643 Vali Loss: 0.0580877 Test Loss: 0.0607174\n",
      "Validation loss decreased (0.058859 --> 0.058088).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0629100\n",
      "\tspeed: 0.2072s/iter; left time: 541.3866s\n",
      "\titers: 200, epoch: 9 | loss: 0.0620225\n",
      "\tspeed: 0.1241s/iter; left time: 311.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 226 | Train Loss: 0.0599683 Vali Loss: 0.0578587 Test Loss: 0.0605800\n",
      "Validation loss decreased (0.058088 --> 0.057859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0574319\n",
      "\tspeed: 0.2074s/iter; left time: 495.0400s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602710\n",
      "\tspeed: 0.1243s/iter; left time: 284.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 226 | Train Loss: 0.0595075 Vali Loss: 0.0576037 Test Loss: 0.0601031\n",
      "Validation loss decreased (0.057859 --> 0.057604).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0606948\n",
      "\tspeed: 0.2064s/iter; left time: 446.0991s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578572\n",
      "\tspeed: 0.1242s/iter; left time: 255.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 226 | Train Loss: 0.0590668 Vali Loss: 0.0575622 Test Loss: 0.0603818\n",
      "Validation loss decreased (0.057604 --> 0.057562).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0614702\n",
      "\tspeed: 0.2109s/iter; left time: 408.0815s\n",
      "\titers: 200, epoch: 12 | loss: 0.0576249\n",
      "\tspeed: 0.1240s/iter; left time: 227.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 226 | Train Loss: 0.0588322 Vali Loss: 0.0570690 Test Loss: 0.0595613\n",
      "Validation loss decreased (0.057562 --> 0.057069).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536879\n",
      "\tspeed: 0.2054s/iter; left time: 350.9909s\n",
      "\titers: 200, epoch: 13 | loss: 0.0548065\n",
      "\tspeed: 0.1238s/iter; left time: 199.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 226 | Train Loss: 0.0584687 Vali Loss: 0.0568619 Test Loss: 0.0593011\n",
      "Validation loss decreased (0.057069 --> 0.056862).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0570590\n",
      "\tspeed: 0.2051s/iter; left time: 304.2340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0629808\n",
      "\tspeed: 0.1233s/iter; left time: 170.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0580641 Vali Loss: 0.0568366 Test Loss: 0.0590742\n",
      "Validation loss decreased (0.056862 --> 0.056837).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571397\n",
      "\tspeed: 0.2038s/iter; left time: 256.1308s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618289\n",
      "\tspeed: 0.1230s/iter; left time: 142.3411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0577726 Vali Loss: 0.0567835 Test Loss: 0.0589230\n",
      "Validation loss decreased (0.056837 --> 0.056783).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0589630\n",
      "\tspeed: 0.2039s/iter; left time: 210.1841s\n",
      "\titers: 200, epoch: 16 | loss: 0.0573150\n",
      "\tspeed: 0.1231s/iter; left time: 114.5785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0576216 Vali Loss: 0.0564624 Test Loss: 0.0587323\n",
      "Validation loss decreased (0.056783 --> 0.056462).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0625905\n",
      "\tspeed: 0.2044s/iter; left time: 164.5188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0577565\n",
      "\tspeed: 0.1232s/iter; left time: 86.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 226 | Train Loss: 0.0573842 Vali Loss: 0.0568271 Test Loss: 0.0590868\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0595494\n",
      "\tspeed: 0.2032s/iter; left time: 117.6542s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563744\n",
      "\tspeed: 0.1231s/iter; left time: 58.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0572813 Vali Loss: 0.0563119 Test Loss: 0.0589350\n",
      "Validation loss decreased (0.056462 --> 0.056312).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0563603\n",
      "\tspeed: 0.2111s/iter; left time: 74.5156s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545016\n",
      "\tspeed: 0.1231s/iter; left time: 31.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0570930 Vali Loss: 0.0561932 Test Loss: 0.0585328\n",
      "Validation loss decreased (0.056312 --> 0.056193).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0566096\n",
      "\tspeed: 0.2045s/iter; left time: 25.9745s\n",
      "\titers: 200, epoch: 20 | loss: 0.0562457\n",
      "\tspeed: 0.1232s/iter; left time: 3.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0569631 Vali Loss: 0.0565658 Test Loss: 0.0586333\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010333484970033169, rmse:0.10165374726057053, mae:0.05853284150362015, rse:0.38409945368766785\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1148740\n",
      "\tspeed: 0.1241s/iter; left time: 548.5404s\n",
      "\titers: 200, epoch: 1 | loss: 0.1035100\n",
      "\tspeed: 0.1231s/iter; left time: 531.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.1211798 Vali Loss: 0.0813818 Test Loss: 0.0824983\n",
      "Validation loss decreased (inf --> 0.081382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0743233\n",
      "\tspeed: 0.2036s/iter; left time: 854.1455s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723142\n",
      "\tspeed: 0.1233s/iter; left time: 504.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 226 | Train Loss: 0.0766999 Vali Loss: 0.0664761 Test Loss: 0.0689256\n",
      "Validation loss decreased (0.081382 --> 0.066476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662167\n",
      "\tspeed: 0.2042s/iter; left time: 810.5253s\n",
      "\titers: 200, epoch: 3 | loss: 0.0662025\n",
      "\tspeed: 0.1231s/iter; left time: 476.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0688360 Vali Loss: 0.0637087 Test Loss: 0.0665311\n",
      "Validation loss decreased (0.066476 --> 0.063709).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0641758\n",
      "\tspeed: 0.2029s/iter; left time: 759.5616s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634328\n",
      "\tspeed: 0.1232s/iter; left time: 448.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.95s\n",
      "Steps: 226 | Train Loss: 0.0661288 Vali Loss: 0.0619317 Test Loss: 0.0649719\n",
      "Validation loss decreased (0.063709 --> 0.061932).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0694065\n",
      "\tspeed: 0.2036s/iter; left time: 716.1528s\n",
      "\titers: 200, epoch: 5 | loss: 0.0643803\n",
      "\tspeed: 0.1230s/iter; left time: 420.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.89s\n",
      "Steps: 226 | Train Loss: 0.0639748 Vali Loss: 0.0606104 Test Loss: 0.0633659\n",
      "Validation loss decreased (0.061932 --> 0.060610).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637849\n",
      "\tspeed: 0.2024s/iter; left time: 666.0609s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608316\n",
      "\tspeed: 0.1231s/iter; left time: 392.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.91s\n",
      "Steps: 226 | Train Loss: 0.0624958 Vali Loss: 0.0588577 Test Loss: 0.0615097\n",
      "Validation loss decreased (0.060610 --> 0.058858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0591928\n",
      "\tspeed: 0.2033s/iter; left time: 623.0883s\n",
      "\titers: 200, epoch: 7 | loss: 0.0583320\n",
      "\tspeed: 0.1233s/iter; left time: 365.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 226 | Train Loss: 0.0614027 Vali Loss: 0.0586346 Test Loss: 0.0618780\n",
      "Validation loss decreased (0.058858 --> 0.058635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0588122\n",
      "\tspeed: 0.2059s/iter; left time: 584.6852s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603447\n",
      "\tspeed: 0.1233s/iter; left time: 337.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0605622 Vali Loss: 0.0581572 Test Loss: 0.0613240\n",
      "Validation loss decreased (0.058635 --> 0.058157).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0627868\n",
      "\tspeed: 0.2067s/iter; left time: 540.1944s\n",
      "\titers: 200, epoch: 9 | loss: 0.0602490\n",
      "\tspeed: 0.1235s/iter; left time: 310.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.09s\n",
      "Steps: 226 | Train Loss: 0.0599007 Vali Loss: 0.0575575 Test Loss: 0.0602312\n",
      "Validation loss decreased (0.058157 --> 0.057558).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0568765\n",
      "\tspeed: 0.2092s/iter; left time: 499.3861s\n",
      "\titers: 200, epoch: 10 | loss: 0.0624954\n",
      "\tspeed: 0.1240s/iter; left time: 283.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.25s\n",
      "Steps: 226 | Train Loss: 0.0593471 Vali Loss: 0.0574005 Test Loss: 0.0601187\n",
      "Validation loss decreased (0.057558 --> 0.057400).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596192\n",
      "\tspeed: 0.2111s/iter; left time: 456.0823s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592127\n",
      "\tspeed: 0.1240s/iter; left time: 255.4822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 226 | Train Loss: 0.0590144 Vali Loss: 0.0572044 Test Loss: 0.0598468\n",
      "Validation loss decreased (0.057400 --> 0.057204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0615893\n",
      "\tspeed: 0.2488s/iter; left time: 481.3734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559695\n",
      "\tspeed: 0.1233s/iter; left time: 226.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.07s\n",
      "Steps: 226 | Train Loss: 0.0584624 Vali Loss: 0.0569848 Test Loss: 0.0595079\n",
      "Validation loss decreased (0.057204 --> 0.056985).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0584085\n",
      "\tspeed: 0.2060s/iter; left time: 352.1014s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579237\n",
      "\tspeed: 0.1232s/iter; left time: 198.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 226 | Train Loss: 0.0582000 Vali Loss: 0.0570694 Test Loss: 0.0599025\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592260\n",
      "\tspeed: 0.2046s/iter; left time: 303.4499s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572892\n",
      "\tspeed: 0.1232s/iter; left time: 170.3585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0580283 Vali Loss: 0.0570102 Test Loss: 0.0598739\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0573419\n",
      "\tspeed: 0.2042s/iter; left time: 256.6187s\n",
      "\titers: 200, epoch: 15 | loss: 0.0580359\n",
      "\tspeed: 0.1232s/iter; left time: 142.5573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 226 | Train Loss: 0.0577937 Vali Loss: 0.0566747 Test Loss: 0.0594992\n",
      "Validation loss decreased (0.056985 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0595963\n",
      "\tspeed: 0.2052s/iter; left time: 211.5397s\n",
      "\titers: 200, epoch: 16 | loss: 0.0581507\n",
      "\tspeed: 0.1232s/iter; left time: 114.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0575645 Vali Loss: 0.0563853 Test Loss: 0.0590242\n",
      "Validation loss decreased (0.056675 --> 0.056385).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537569\n",
      "\tspeed: 0.2030s/iter; left time: 163.3863s\n",
      "\titers: 200, epoch: 17 | loss: 0.0591558\n",
      "\tspeed: 0.1232s/iter; left time: 86.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 226 | Train Loss: 0.0572866 Vali Loss: 0.0562514 Test Loss: 0.0589677\n",
      "Validation loss decreased (0.056385 --> 0.056251).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0616697\n",
      "\tspeed: 0.2047s/iter; left time: 118.5172s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598275\n",
      "\tspeed: 0.1234s/iter; left time: 59.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 226 | Train Loss: 0.0571565 Vali Loss: 0.0560796 Test Loss: 0.0589612\n",
      "Validation loss decreased (0.056251 --> 0.056080).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0564034\n",
      "\tspeed: 0.2039s/iter; left time: 71.9723s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553540\n",
      "\tspeed: 0.1234s/iter; left time: 31.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 226 | Train Loss: 0.0570096 Vali Loss: 0.0560311 Test Loss: 0.0588667\n",
      "Validation loss decreased (0.056080 --> 0.056031).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543480\n",
      "\tspeed: 0.2057s/iter; left time: 26.1271s\n",
      "\titers: 200, epoch: 20 | loss: 0.0582589\n",
      "\tspeed: 0.1231s/iter; left time: 3.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 226 | Train Loss: 0.0568625 Vali Loss: 0.0558932 Test Loss: 0.0588943\n",
      "Validation loss decreased (0.056031 --> 0.055893).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010509154759347439, rmse:0.10251417011022568, mae:0.058894332498311996, rse:0.38735058903694153\n",
      "Intermediate time for IT and pred_len 24: 00h:22m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1246291\n",
      "\tspeed: 0.1502s/iter; left time: 661.2296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1170714\n",
      "\tspeed: 0.1238s/iter; left time: 532.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1307737 Vali Loss: 0.0961518 Test Loss: 0.0997427\n",
      "Validation loss decreased (inf --> 0.096152).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0948495\n",
      "\tspeed: 0.2148s/iter; left time: 896.9106s\n",
      "\titers: 200, epoch: 2 | loss: 0.0954342\n",
      "\tspeed: 0.1237s/iter; left time: 504.1970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0978327 Vali Loss: 0.0849951 Test Loss: 0.0893700\n",
      "Validation loss decreased (0.096152 --> 0.084995).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0911742\n",
      "\tspeed: 0.2054s/iter; left time: 811.6634s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884128\n",
      "\tspeed: 0.1237s/iter; left time: 476.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0892406 Vali Loss: 0.0825536 Test Loss: 0.0875067\n",
      "Validation loss decreased (0.084995 --> 0.082554).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0867200\n",
      "\tspeed: 0.2058s/iter; left time: 766.8796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0846905\n",
      "\tspeed: 0.1239s/iter; left time: 449.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0855845 Vali Loss: 0.0808799 Test Loss: 0.0862431\n",
      "Validation loss decreased (0.082554 --> 0.080880).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0797206\n",
      "\tspeed: 0.2094s/iter; left time: 733.1353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888789\n",
      "\tspeed: 0.1238s/iter; left time: 421.2037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0834375 Vali Loss: 0.0790271 Test Loss: 0.0843552\n",
      "Validation loss decreased (0.080880 --> 0.079027).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0826562\n",
      "\tspeed: 0.2102s/iter; left time: 688.7716s\n",
      "\titers: 200, epoch: 6 | loss: 0.0778374\n",
      "\tspeed: 0.1240s/iter; left time: 393.7166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0821521 Vali Loss: 0.0782054 Test Loss: 0.0836802\n",
      "Validation loss decreased (0.079027 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0799794\n",
      "\tspeed: 0.2217s/iter; left time: 676.3642s\n",
      "\titers: 200, epoch: 7 | loss: 0.0788258\n",
      "\tspeed: 0.1239s/iter; left time: 365.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0813023 Vali Loss: 0.0782941 Test Loss: 0.0837826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0789111\n",
      "\tspeed: 0.2070s/iter; left time: 585.0643s\n",
      "\titers: 200, epoch: 8 | loss: 0.0816973\n",
      "\tspeed: 0.1240s/iter; left time: 338.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0806553 Vali Loss: 0.0778118 Test Loss: 0.0829287\n",
      "Validation loss decreased (0.078205 --> 0.077812).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0801560\n",
      "\tspeed: 0.2108s/iter; left time: 548.3920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835952\n",
      "\tspeed: 0.1246s/iter; left time: 311.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0801367 Vali Loss: 0.0776850 Test Loss: 0.0827472\n",
      "Validation loss decreased (0.077812 --> 0.077685).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0809377\n",
      "\tspeed: 0.2122s/iter; left time: 504.1102s\n",
      "\titers: 200, epoch: 10 | loss: 0.0785008\n",
      "\tspeed: 0.1244s/iter; left time: 283.1045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0797318 Vali Loss: 0.0775685 Test Loss: 0.0825838\n",
      "Validation loss decreased (0.077685 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773143\n",
      "\tspeed: 0.2090s/iter; left time: 449.5153s\n",
      "\titers: 200, epoch: 11 | loss: 0.0786918\n",
      "\tspeed: 0.1238s/iter; left time: 253.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0793911 Vali Loss: 0.0773214 Test Loss: 0.0821988\n",
      "Validation loss decreased (0.077569 --> 0.077321).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0843383\n",
      "\tspeed: 0.2057s/iter; left time: 396.2053s\n",
      "\titers: 200, epoch: 12 | loss: 0.0793643\n",
      "\tspeed: 0.1236s/iter; left time: 225.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0790657 Vali Loss: 0.0772528 Test Loss: 0.0820618\n",
      "Validation loss decreased (0.077321 --> 0.077253).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0776302\n",
      "\tspeed: 0.2073s/iter; left time: 352.5856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800399\n",
      "\tspeed: 0.1238s/iter; left time: 198.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 225 | Train Loss: 0.0787998 Vali Loss: 0.0769798 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.077253 --> 0.076980).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797844\n",
      "\tspeed: 0.2163s/iter; left time: 319.2716s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793766\n",
      "\tspeed: 0.1239s/iter; left time: 170.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0785462 Vali Loss: 0.0769688 Test Loss: 0.0817476\n",
      "Validation loss decreased (0.076980 --> 0.076969).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755080\n",
      "\tspeed: 0.2114s/iter; left time: 264.5179s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763225\n",
      "\tspeed: 0.1237s/iter; left time: 142.3853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0783976 Vali Loss: 0.0769022 Test Loss: 0.0815266\n",
      "Validation loss decreased (0.076969 --> 0.076902).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0759583\n",
      "\tspeed: 0.2252s/iter; left time: 231.1064s\n",
      "\titers: 200, epoch: 16 | loss: 0.0809015\n",
      "\tspeed: 0.1237s/iter; left time: 114.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.00s\n",
      "Steps: 225 | Train Loss: 0.0782896 Vali Loss: 0.0767670 Test Loss: 0.0815434\n",
      "Validation loss decreased (0.076902 --> 0.076767).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807900\n",
      "\tspeed: 0.2069s/iter; left time: 165.7560s\n",
      "\titers: 200, epoch: 17 | loss: 0.0796471\n",
      "\tspeed: 0.1236s/iter; left time: 86.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0780911 Vali Loss: 0.0765583 Test Loss: 0.0813489\n",
      "Validation loss decreased (0.076767 --> 0.076558).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0750794\n",
      "\tspeed: 0.2082s/iter; left time: 119.9227s\n",
      "\titers: 200, epoch: 18 | loss: 0.0804618\n",
      "\tspeed: 0.1238s/iter; left time: 58.9253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0778818 Vali Loss: 0.0766912 Test Loss: 0.0816509\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0737888\n",
      "\tspeed: 0.2070s/iter; left time: 72.6420s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769352\n",
      "\tspeed: 0.1236s/iter; left time: 31.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0777152 Vali Loss: 0.0764046 Test Loss: 0.0812570\n",
      "Validation loss decreased (0.076558 --> 0.076405).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0773344\n",
      "\tspeed: 0.2066s/iter; left time: 26.0332s\n",
      "\titers: 200, epoch: 20 | loss: 0.0809498\n",
      "\tspeed: 0.1237s/iter; left time: 3.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0776153 Vali Loss: 0.0764732 Test Loss: 0.0810120\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018536528572440147, rmse:0.13614891469478607, mae:0.08125697821378708, rse:0.5147936940193176\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1274510\n",
      "\tspeed: 0.1244s/iter; left time: 547.5407s\n",
      "\titers: 200, epoch: 1 | loss: 0.1164847\n",
      "\tspeed: 0.1235s/iter; left time: 531.1899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.1317651 Vali Loss: 0.0965845 Test Loss: 0.1001872\n",
      "Validation loss decreased (inf --> 0.096585).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0931384\n",
      "\tspeed: 0.2059s/iter; left time: 859.8003s\n",
      "\titers: 200, epoch: 2 | loss: 0.0937748\n",
      "\tspeed: 0.1237s/iter; left time: 504.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0983610 Vali Loss: 0.0854578 Test Loss: 0.0899371\n",
      "Validation loss decreased (0.096585 --> 0.085458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0879004\n",
      "\tspeed: 0.2064s/iter; left time: 815.6114s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821228\n",
      "\tspeed: 0.1238s/iter; left time: 476.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0891939 Vali Loss: 0.0823376 Test Loss: 0.0874421\n",
      "Validation loss decreased (0.085458 --> 0.082338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863800\n",
      "\tspeed: 0.2064s/iter; left time: 769.2313s\n",
      "\titers: 200, epoch: 4 | loss: 0.0839542\n",
      "\tspeed: 0.1237s/iter; left time: 448.7139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.97s\n",
      "Steps: 225 | Train Loss: 0.0857099 Vali Loss: 0.0812594 Test Loss: 0.0861944\n",
      "Validation loss decreased (0.082338 --> 0.081259).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0866721\n",
      "\tspeed: 0.2086s/iter; left time: 730.2604s\n",
      "\titers: 200, epoch: 5 | loss: 0.0816669\n",
      "\tspeed: 0.1237s/iter; left time: 420.6107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0838621 Vali Loss: 0.0807487 Test Loss: 0.0857736\n",
      "Validation loss decreased (0.081259 --> 0.080749).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839811\n",
      "\tspeed: 0.2056s/iter; left time: 673.5906s\n",
      "\titers: 200, epoch: 6 | loss: 0.0856897\n",
      "\tspeed: 0.1236s/iter; left time: 392.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.01s\n",
      "Steps: 225 | Train Loss: 0.0824806 Vali Loss: 0.0787402 Test Loss: 0.0840767\n",
      "Validation loss decreased (0.080749 --> 0.078740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0824418\n",
      "\tspeed: 0.2073s/iter; left time: 632.4306s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837693\n",
      "\tspeed: 0.1236s/iter; left time: 364.8143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.02s\n",
      "Steps: 225 | Train Loss: 0.0817001 Vali Loss: 0.0782434 Test Loss: 0.0841690\n",
      "Validation loss decreased (0.078740 --> 0.078243).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798583\n",
      "\tspeed: 0.2053s/iter; left time: 580.1476s\n",
      "\titers: 200, epoch: 8 | loss: 0.0807079\n",
      "\tspeed: 0.1237s/iter; left time: 337.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0809182 Vali Loss: 0.0780490 Test Loss: 0.0831145\n",
      "Validation loss decreased (0.078243 --> 0.078049).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792143\n",
      "\tspeed: 0.2077s/iter; left time: 540.2567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0885995\n",
      "\tspeed: 0.1240s/iter; left time: 310.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.05s\n",
      "Steps: 225 | Train Loss: 0.0805063 Vali Loss: 0.0778816 Test Loss: 0.0831148\n",
      "Validation loss decreased (0.078049 --> 0.077882).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0826082\n",
      "\tspeed: 0.2055s/iter; left time: 488.1716s\n",
      "\titers: 200, epoch: 10 | loss: 0.0805768\n",
      "\tspeed: 0.1239s/iter; left time: 282.1076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.08s\n",
      "Steps: 225 | Train Loss: 0.0798953 Vali Loss: 0.0776451 Test Loss: 0.0828241\n",
      "Validation loss decreased (0.077882 --> 0.077645).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783376\n",
      "\tspeed: 0.2062s/iter; left time: 443.5818s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749998\n",
      "\tspeed: 0.1243s/iter; left time: 254.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0794778 Vali Loss: 0.0775692 Test Loss: 0.0823288\n",
      "Validation loss decreased (0.077645 --> 0.077569).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0794503\n",
      "\tspeed: 0.2062s/iter; left time: 397.2318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0762411\n",
      "\tspeed: 0.1248s/iter; left time: 227.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 225 | Train Loss: 0.0791353 Vali Loss: 0.0772091 Test Loss: 0.0826240\n",
      "Validation loss decreased (0.077569 --> 0.077209).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0795701\n",
      "\tspeed: 0.2074s/iter; left time: 352.7250s\n",
      "\titers: 200, epoch: 13 | loss: 0.0782318\n",
      "\tspeed: 0.1243s/iter; left time: 198.9789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0788803 Vali Loss: 0.0770195 Test Loss: 0.0825596\n",
      "Validation loss decreased (0.077209 --> 0.077020).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0823900\n",
      "\tspeed: 0.2073s/iter; left time: 305.9652s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794970\n",
      "\tspeed: 0.1244s/iter; left time: 171.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0786027 Vali Loss: 0.0769410 Test Loss: 0.0823892\n",
      "Validation loss decreased (0.077020 --> 0.076941).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766661\n",
      "\tspeed: 0.2087s/iter; left time: 261.0253s\n",
      "\titers: 200, epoch: 15 | loss: 0.0806809\n",
      "\tspeed: 0.1242s/iter; left time: 142.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.13s\n",
      "Steps: 225 | Train Loss: 0.0783255 Vali Loss: 0.0767500 Test Loss: 0.0819774\n",
      "Validation loss decreased (0.076941 --> 0.076750).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0756244\n",
      "\tspeed: 0.2075s/iter; left time: 212.9265s\n",
      "\titers: 200, epoch: 16 | loss: 0.0810186\n",
      "\tspeed: 0.1237s/iter; left time: 114.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0781282 Vali Loss: 0.0768651 Test Loss: 0.0821056\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0807884\n",
      "\tspeed: 0.2031s/iter; left time: 162.7110s\n",
      "\titers: 200, epoch: 17 | loss: 0.0767048\n",
      "\tspeed: 0.1235s/iter; left time: 86.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 225 | Train Loss: 0.0778863 Vali Loss: 0.0768578 Test Loss: 0.0821329\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0774752\n",
      "\tspeed: 0.2075s/iter; left time: 119.5412s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812058\n",
      "\tspeed: 0.1238s/iter; left time: 58.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.10s\n",
      "Steps: 225 | Train Loss: 0.0777132 Vali Loss: 0.0766468 Test Loss: 0.0820385\n",
      "Validation loss decreased (0.076750 --> 0.076647).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0832625\n",
      "\tspeed: 0.2046s/iter; left time: 71.8297s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773597\n",
      "\tspeed: 0.1242s/iter; left time: 31.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 225 | Train Loss: 0.0775751 Vali Loss: 0.0764721 Test Loss: 0.0817944\n",
      "Validation loss decreased (0.076647 --> 0.076472).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0786291\n",
      "\tspeed: 0.2056s/iter; left time: 25.9106s\n",
      "\titers: 200, epoch: 20 | loss: 0.0785749\n",
      "\tspeed: 0.1248s/iter; left time: 3.2458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0774495 Vali Loss: 0.0764009 Test Loss: 0.0816955\n",
      "Validation loss decreased (0.076472 --> 0.076401).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018820010125637054, rmse:0.13718603551387787, mae:0.08169551938772202, rse:0.5187152028083801\n",
      "Intermediate time for IT and pred_len 96: 00h:22m:26.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1274062\n",
      "\tspeed: 0.1487s/iter; left time: 654.5295s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201956\n",
      "\tspeed: 0.1255s/iter; left time: 539.6477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.1337667 Vali Loss: 0.0992412 Test Loss: 0.1025607\n",
      "Validation loss decreased (inf --> 0.099241).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0999286\n",
      "\tspeed: 0.2093s/iter; left time: 874.2423s\n",
      "\titers: 200, epoch: 2 | loss: 0.0971880\n",
      "\tspeed: 0.1240s/iter; left time: 505.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.1026157 Vali Loss: 0.0904709 Test Loss: 0.0948137\n",
      "Validation loss decreased (0.099241 --> 0.090471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945068\n",
      "\tspeed: 0.2068s/iter; left time: 817.0345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920321\n",
      "\tspeed: 0.1240s/iter; left time: 477.4222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.15s\n",
      "Steps: 225 | Train Loss: 0.0944772 Vali Loss: 0.0859233 Test Loss: 0.0916047\n",
      "Validation loss decreased (0.090471 --> 0.085923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0924504\n",
      "\tspeed: 0.2065s/iter; left time: 769.5238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887412\n",
      "\tspeed: 0.1243s/iter; left time: 450.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.12s\n",
      "Steps: 225 | Train Loss: 0.0908827 Vali Loss: 0.0868275 Test Loss: 0.0906128\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0887746\n",
      "\tspeed: 0.2071s/iter; left time: 724.9291s\n",
      "\titers: 200, epoch: 5 | loss: 0.0888827\n",
      "\tspeed: 0.1252s/iter; left time: 425.7346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0887758 Vali Loss: 0.0842572 Test Loss: 0.0898299\n",
      "Validation loss decreased (0.085923 --> 0.084257).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0897459\n",
      "\tspeed: 0.2071s/iter; left time: 678.5198s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841771\n",
      "\tspeed: 0.1247s/iter; left time: 396.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.21s\n",
      "Steps: 225 | Train Loss: 0.0874938 Vali Loss: 0.0833510 Test Loss: 0.0876509\n",
      "Validation loss decreased (0.084257 --> 0.083351).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0841005\n",
      "\tspeed: 0.2065s/iter; left time: 629.8886s\n",
      "\titers: 200, epoch: 7 | loss: 0.0883561\n",
      "\tspeed: 0.1246s/iter; left time: 367.6888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0864298 Vali Loss: 0.0829024 Test Loss: 0.0872512\n",
      "Validation loss decreased (0.083351 --> 0.082902).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0864878\n",
      "\tspeed: 0.2065s/iter; left time: 583.5700s\n",
      "\titers: 200, epoch: 8 | loss: 0.0836292\n",
      "\tspeed: 0.1244s/iter; left time: 339.0295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 225 | Train Loss: 0.0858088 Vali Loss: 0.0824455 Test Loss: 0.0869225\n",
      "Validation loss decreased (0.082902 --> 0.082446).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0883054\n",
      "\tspeed: 0.2067s/iter; left time: 537.6703s\n",
      "\titers: 200, epoch: 9 | loss: 0.0835050\n",
      "\tspeed: 0.1243s/iter; left time: 310.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.16s\n",
      "Steps: 225 | Train Loss: 0.0852685 Vali Loss: 0.0827654 Test Loss: 0.0869103\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0833669\n",
      "\tspeed: 0.2058s/iter; left time: 489.0270s\n",
      "\titers: 200, epoch: 10 | loss: 0.0865522\n",
      "\tspeed: 0.1248s/iter; left time: 283.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0848592 Vali Loss: 0.0819396 Test Loss: 0.0861626\n",
      "Validation loss decreased (0.082446 --> 0.081940).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0845838\n",
      "\tspeed: 0.2060s/iter; left time: 443.1676s\n",
      "\titers: 200, epoch: 11 | loss: 0.0861566\n",
      "\tspeed: 0.1244s/iter; left time: 255.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 225 | Train Loss: 0.0845001 Vali Loss: 0.0820744 Test Loss: 0.0859507\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0851333\n",
      "\tspeed: 0.2081s/iter; left time: 400.7558s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838776\n",
      "\tspeed: 0.1247s/iter; left time: 227.7526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0842150 Vali Loss: 0.0822200 Test Loss: 0.0856628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0833532\n",
      "\tspeed: 0.2085s/iter; left time: 354.6808s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793798\n",
      "\tspeed: 0.1250s/iter; left time: 200.0957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0838517 Vali Loss: 0.0816093 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.081940 --> 0.081609).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0838834\n",
      "\tspeed: 0.2074s/iter; left time: 306.1636s\n",
      "\titers: 200, epoch: 14 | loss: 0.0833073\n",
      "\tspeed: 0.1246s/iter; left time: 171.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 225 | Train Loss: 0.0836320 Vali Loss: 0.0817205 Test Loss: 0.0854512\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0802528\n",
      "\tspeed: 0.2063s/iter; left time: 258.0424s\n",
      "\titers: 200, epoch: 15 | loss: 0.0804740\n",
      "\tspeed: 0.1245s/iter; left time: 143.2631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0834320 Vali Loss: 0.0816327 Test Loss: 0.0855313\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0829816\n",
      "\tspeed: 0.2053s/iter; left time: 210.6108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0838366\n",
      "\tspeed: 0.1250s/iter; left time: 115.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0831726 Vali Loss: 0.0816667 Test Loss: 0.0854638\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814890\n",
      "\tspeed: 0.2073s/iter; left time: 166.0414s\n",
      "\titers: 200, epoch: 17 | loss: 0.0822350\n",
      "\tspeed: 0.1256s/iter; left time: 88.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 225 | Train Loss: 0.0829919 Vali Loss: 0.0820202 Test Loss: 0.0856585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0839811\n",
      "\tspeed: 0.2077s/iter; left time: 119.6551s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843205\n",
      "\tspeed: 0.1256s/iter; left time: 59.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0828663 Vali Loss: 0.0817814 Test Loss: 0.0856330\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0196785070002079, rmse:0.1402800977230072, mae:0.08546759188175201, rse:0.5309070944786072\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1252874\n",
      "\tspeed: 0.1258s/iter; left time: 553.5807s\n",
      "\titers: 200, epoch: 1 | loss: 0.1240589\n",
      "\tspeed: 0.1251s/iter; left time: 537.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.1343383 Vali Loss: 0.0994309 Test Loss: 0.1027002\n",
      "Validation loss decreased (inf --> 0.099431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1012369\n",
      "\tspeed: 0.2111s/iter; left time: 881.4227s\n",
      "\titers: 200, epoch: 2 | loss: 0.0978683\n",
      "\tspeed: 0.1247s/iter; left time: 508.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.1025567 Vali Loss: 0.0899358 Test Loss: 0.0946148\n",
      "Validation loss decreased (0.099431 --> 0.089936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0953144\n",
      "\tspeed: 0.2091s/iter; left time: 825.9906s\n",
      "\titers: 200, epoch: 3 | loss: 0.0942210\n",
      "\tspeed: 0.1250s/iter; left time: 481.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0939962 Vali Loss: 0.0862187 Test Loss: 0.0924182\n",
      "Validation loss decreased (0.089936 --> 0.086219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886576\n",
      "\tspeed: 0.2070s/iter; left time: 771.3484s\n",
      "\titers: 200, epoch: 4 | loss: 0.0866066\n",
      "\tspeed: 0.1250s/iter; left time: 453.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.30s\n",
      "Steps: 225 | Train Loss: 0.0907466 Vali Loss: 0.0852378 Test Loss: 0.0902182\n",
      "Validation loss decreased (0.086219 --> 0.085238).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0886593\n",
      "\tspeed: 0.2072s/iter; left time: 725.5006s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915526\n",
      "\tspeed: 0.1247s/iter; left time: 424.1730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0887809 Vali Loss: 0.0845530 Test Loss: 0.0897828\n",
      "Validation loss decreased (0.085238 --> 0.084553).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0855750\n",
      "\tspeed: 0.2105s/iter; left time: 689.7385s\n",
      "\titers: 200, epoch: 6 | loss: 0.0881630\n",
      "\tspeed: 0.1254s/iter; left time: 398.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 225 | Train Loss: 0.0876069 Vali Loss: 0.0839415 Test Loss: 0.0886852\n",
      "Validation loss decreased (0.084553 --> 0.083941).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855649\n",
      "\tspeed: 0.2094s/iter; left time: 638.9149s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861583\n",
      "\tspeed: 0.1251s/iter; left time: 369.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0867376 Vali Loss: 0.0830761 Test Loss: 0.0885835\n",
      "Validation loss decreased (0.083941 --> 0.083076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0900731\n",
      "\tspeed: 0.2115s/iter; left time: 597.7728s\n",
      "\titers: 200, epoch: 8 | loss: 0.0837901\n",
      "\tspeed: 0.1249s/iter; left time: 340.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 225 | Train Loss: 0.0862249 Vali Loss: 0.0828923 Test Loss: 0.0886307\n",
      "Validation loss decreased (0.083076 --> 0.082892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0850363\n",
      "\tspeed: 0.2107s/iter; left time: 548.1492s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847476\n",
      "\tspeed: 0.1255s/iter; left time: 313.9175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 225 | Train Loss: 0.0856819 Vali Loss: 0.0822114 Test Loss: 0.0875634\n",
      "Validation loss decreased (0.082892 --> 0.082211).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0865811\n",
      "\tspeed: 0.2078s/iter; left time: 493.7087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0885911\n",
      "\tspeed: 0.1250s/iter; left time: 284.5643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0852687 Vali Loss: 0.0822291 Test Loss: 0.0871013\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0820281\n",
      "\tspeed: 0.2088s/iter; left time: 449.0294s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828203\n",
      "\tspeed: 0.1248s/iter; left time: 255.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 225 | Train Loss: 0.0847809 Vali Loss: 0.0817572 Test Loss: 0.0870292\n",
      "Validation loss decreased (0.082211 --> 0.081757).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0821820\n",
      "\tspeed: 0.2064s/iter; left time: 397.4723s\n",
      "\titers: 200, epoch: 12 | loss: 0.0837839\n",
      "\tspeed: 0.1249s/iter; left time: 228.0093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 225 | Train Loss: 0.0845500 Vali Loss: 0.0819127 Test Loss: 0.0866175\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0802262\n",
      "\tspeed: 0.2076s/iter; left time: 353.1202s\n",
      "\titers: 200, epoch: 13 | loss: 0.0826065\n",
      "\tspeed: 0.1251s/iter; left time: 200.2906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 225 | Train Loss: 0.0842274 Vali Loss: 0.0817468 Test Loss: 0.0864959\n",
      "Validation loss decreased (0.081757 --> 0.081747).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0841475\n",
      "\tspeed: 0.2083s/iter; left time: 307.4843s\n",
      "\titers: 200, epoch: 14 | loss: 0.0823566\n",
      "\tspeed: 0.1249s/iter; left time: 171.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.26s\n",
      "Steps: 225 | Train Loss: 0.0840051 Vali Loss: 0.0814703 Test Loss: 0.0864162\n",
      "Validation loss decreased (0.081747 --> 0.081470).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0832792\n",
      "\tspeed: 0.2078s/iter; left time: 259.9452s\n",
      "\titers: 200, epoch: 15 | loss: 0.0832064\n",
      "\tspeed: 0.1246s/iter; left time: 143.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.29s\n",
      "Steps: 225 | Train Loss: 0.0837586 Vali Loss: 0.0815400 Test Loss: 0.0859518\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0816924\n",
      "\tspeed: 0.2051s/iter; left time: 210.4502s\n",
      "\titers: 200, epoch: 16 | loss: 0.0879495\n",
      "\tspeed: 0.1248s/iter; left time: 115.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.19s\n",
      "Steps: 225 | Train Loss: 0.0834792 Vali Loss: 0.0814463 Test Loss: 0.0862716\n",
      "Validation loss decreased (0.081470 --> 0.081446).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0814074\n",
      "\tspeed: 0.2072s/iter; left time: 165.9816s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830946\n",
      "\tspeed: 0.1248s/iter; left time: 87.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.27s\n",
      "Steps: 225 | Train Loss: 0.0833982 Vali Loss: 0.0813847 Test Loss: 0.0859058\n",
      "Validation loss decreased (0.081446 --> 0.081385).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0828545\n",
      "\tspeed: 0.2064s/iter; left time: 118.8758s\n",
      "\titers: 200, epoch: 18 | loss: 0.0824811\n",
      "\tspeed: 0.1247s/iter; left time: 59.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 225 | Train Loss: 0.0832192 Vali Loss: 0.0813554 Test Loss: 0.0859548\n",
      "Validation loss decreased (0.081385 --> 0.081355).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0864082\n",
      "\tspeed: 0.2073s/iter; left time: 72.7458s\n",
      "\titers: 200, epoch: 19 | loss: 0.0809942\n",
      "\tspeed: 0.1252s/iter; left time: 31.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 225 | Train Loss: 0.0830247 Vali Loss: 0.0809955 Test Loss: 0.0858491\n",
      "Validation loss decreased (0.081355 --> 0.080996).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0841437\n",
      "\tspeed: 0.2081s/iter; left time: 26.2232s\n",
      "\titers: 200, epoch: 20 | loss: 0.0797103\n",
      "\tspeed: 0.1254s/iter; left time: 3.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 225 | Train Loss: 0.0828929 Vali Loss: 0.0811498 Test Loss: 0.0856923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020069275051355362, rmse:0.14166606962680817, mae:0.08584906160831451, rse:0.5361524224281311\n",
      "Intermediate time for IT and pred_len 168: 00h:21m:19.68s\n",
      "Intermediate time for IT: 01h:06m:01.95s\n",
      "Total time: 02h:17m:45.04s\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "\n",
    "            if country == 'DE' and pred_len == 24:\n",
    "                seq_len=336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "\n",
    "            if seq_len == 512:\n",
    "                batch_size = 64\n",
    "            else:\n",
    "                batch_size = 128\n",
    "                \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"no_patching_{country}_data.csv\"\n",
    "\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.0822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0365  0.1910  0.1267\n",
       "        168       0.0384  0.1959  0.1325\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1037  0.0574\n",
       "        96        0.0201  0.1418  0.0822\n",
       "        168       0.0219  0.1478  0.0877\n",
       "GB      24        0.0263  0.1621  0.1036\n",
       "        96        0.0425  0.2061  0.1391\n",
       "        168       0.0442  0.2102  0.1445\n",
       "IT      24        0.0104  0.1021  0.0587\n",
       "        96        0.0187  0.1367  0.0815\n",
       "        168       0.0199  0.1410  0.0857"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1467022\n",
      "\tspeed: 0.1228s/iter; left time: 2738.2303s\n",
      "\titers: 200, epoch: 1 | loss: 0.1380337\n",
      "\tspeed: 0.0523s/iter; left time: 1161.8565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:17.55s\n",
      "Steps: 224 | Train Loss: 0.1492598 Vali Loss: 0.1491447 Test Loss: 0.1573455\n",
      "Validation loss decreased (inf --> 0.149145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0933916\n",
      "\tspeed: 0.0933s/iter; left time: 2059.6937s\n",
      "\titers: 200, epoch: 2 | loss: 0.0793409\n",
      "\tspeed: 0.0520s/iter; left time: 1143.6026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0958381 Vali Loss: 0.0959918 Test Loss: 0.0965967\n",
      "Validation loss decreased (0.149145 --> 0.095992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804107\n",
      "\tspeed: 0.0927s/iter; left time: 2026.3754s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822360\n",
      "\tspeed: 0.0521s/iter; left time: 1133.9835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0800409 Vali Loss: 0.0911792 Test Loss: 0.0924903\n",
      "Validation loss decreased (0.095992 --> 0.091179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721088\n",
      "\tspeed: 0.0919s/iter; left time: 1988.3672s\n",
      "\titers: 200, epoch: 4 | loss: 0.0784065\n",
      "\tspeed: 0.0521s/iter; left time: 1121.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0768202 Vali Loss: 0.0894785 Test Loss: 0.0912090\n",
      "Validation loss decreased (0.091179 --> 0.089479).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0701359\n",
      "\tspeed: 0.0919s/iter; left time: 1968.0610s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721674\n",
      "\tspeed: 0.0520s/iter; left time: 1108.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0751275 Vali Loss: 0.0886305 Test Loss: 0.0903440\n",
      "Validation loss decreased (0.089479 --> 0.088631).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0747568\n",
      "\tspeed: 0.0922s/iter; left time: 1952.3521s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739783\n",
      "\tspeed: 0.0520s/iter; left time: 1095.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0740978 Vali Loss: 0.0879776 Test Loss: 0.0896847\n",
      "Validation loss decreased (0.088631 --> 0.087978).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773371\n",
      "\tspeed: 0.0916s/iter; left time: 1918.9129s\n",
      "\titers: 200, epoch: 7 | loss: 0.0693570\n",
      "\tspeed: 0.0521s/iter; left time: 1085.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0731795 Vali Loss: 0.0878054 Test Loss: 0.0894686\n",
      "Validation loss decreased (0.087978 --> 0.087805).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742184\n",
      "\tspeed: 0.0920s/iter; left time: 1907.8917s\n",
      "\titers: 200, epoch: 8 | loss: 0.0694305\n",
      "\tspeed: 0.0520s/iter; left time: 1073.5789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0726620 Vali Loss: 0.0872411 Test Loss: 0.0890743\n",
      "Validation loss decreased (0.087805 --> 0.087241).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730793\n",
      "\tspeed: 0.0919s/iter; left time: 1884.5651s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740317\n",
      "\tspeed: 0.0521s/iter; left time: 1063.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0721427 Vali Loss: 0.0873636 Test Loss: 0.0895516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0651195\n",
      "\tspeed: 0.0912s/iter; left time: 1849.6289s\n",
      "\titers: 200, epoch: 10 | loss: 0.0683019\n",
      "\tspeed: 0.0520s/iter; left time: 1049.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0717890 Vali Loss: 0.0870031 Test Loss: 0.0891616\n",
      "Validation loss decreased (0.087241 --> 0.087003).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0714403\n",
      "\tspeed: 0.0917s/iter; left time: 1840.4068s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766668\n",
      "\tspeed: 0.0522s/iter; left time: 1042.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0714359 Vali Loss: 0.0870827 Test Loss: 0.0894357\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0713613\n",
      "\tspeed: 0.0918s/iter; left time: 1821.7477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0730791\n",
      "\tspeed: 0.0520s/iter; left time: 1027.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0711605 Vali Loss: 0.0868916 Test Loss: 0.0890513\n",
      "Validation loss decreased (0.087003 --> 0.086892).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0658389\n",
      "\tspeed: 0.0923s/iter; left time: 1810.5726s\n",
      "\titers: 200, epoch: 13 | loss: 0.0685006\n",
      "\tspeed: 0.0522s/iter; left time: 1017.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0708652 Vali Loss: 0.0865712 Test Loss: 0.0891132\n",
      "Validation loss decreased (0.086892 --> 0.086571).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742952\n",
      "\tspeed: 0.0923s/iter; left time: 1790.4333s\n",
      "\titers: 200, epoch: 14 | loss: 0.0701290\n",
      "\tspeed: 0.0522s/iter; left time: 1007.3169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0706609 Vali Loss: 0.0864862 Test Loss: 0.0889904\n",
      "Validation loss decreased (0.086571 --> 0.086486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0725446\n",
      "\tspeed: 0.0918s/iter; left time: 1759.3193s\n",
      "\titers: 200, epoch: 15 | loss: 0.0695209\n",
      "\tspeed: 0.0521s/iter; left time: 994.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0704827 Vali Loss: 0.0864452 Test Loss: 0.0889387\n",
      "Validation loss decreased (0.086486 --> 0.086445).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0676632\n",
      "\tspeed: 0.0926s/iter; left time: 1754.8505s\n",
      "\titers: 200, epoch: 16 | loss: 0.0735662\n",
      "\tspeed: 0.0522s/iter; left time: 983.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0703078 Vali Loss: 0.0865087 Test Loss: 0.0890939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669014\n",
      "\tspeed: 0.0913s/iter; left time: 1709.1642s\n",
      "\titers: 200, epoch: 17 | loss: 0.0692772\n",
      "\tspeed: 0.0520s/iter; left time: 968.4467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0701388 Vali Loss: 0.0867771 Test Loss: 0.0890331\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0704841\n",
      "\tspeed: 0.0918s/iter; left time: 1698.3764s\n",
      "\titers: 200, epoch: 18 | loss: 0.0685036\n",
      "\tspeed: 0.0520s/iter; left time: 956.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0699684 Vali Loss: 0.0864049 Test Loss: 0.0891183\n",
      "Validation loss decreased (0.086445 --> 0.086405).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693344\n",
      "\tspeed: 0.0918s/iter; left time: 1677.6074s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699148\n",
      "\tspeed: 0.0520s/iter; left time: 945.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0698359 Vali Loss: 0.0864480 Test Loss: 0.0891146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0743156\n",
      "\tspeed: 0.0915s/iter; left time: 1651.0797s\n",
      "\titers: 200, epoch: 20 | loss: 0.0695782\n",
      "\tspeed: 0.0522s/iter; left time: 935.9140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0698212 Vali Loss: 0.0862729 Test Loss: 0.0889007\n",
      "Validation loss decreased (0.086405 --> 0.086273).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642834\n",
      "\tspeed: 0.0928s/iter; left time: 1653.1337s\n",
      "\titers: 200, epoch: 21 | loss: 0.0729156\n",
      "\tspeed: 0.0522s/iter; left time: 924.9015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0696815 Vali Loss: 0.0863191 Test Loss: 0.0889219\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0668081\n",
      "\tspeed: 0.0917s/iter; left time: 1614.1587s\n",
      "\titers: 200, epoch: 22 | loss: 0.0675850\n",
      "\tspeed: 0.0519s/iter; left time: 908.8251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0696013 Vali Loss: 0.0863717 Test Loss: 0.0890059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0662554\n",
      "\tspeed: 0.0918s/iter; left time: 1595.3221s\n",
      "\titers: 200, epoch: 23 | loss: 0.0715963\n",
      "\tspeed: 0.0523s/iter; left time: 902.7860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0694505 Vali Loss: 0.0862607 Test Loss: 0.0890646\n",
      "Validation loss decreased (0.086273 --> 0.086261).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0695211\n",
      "\tspeed: 0.0919s/iter; left time: 1576.1074s\n",
      "\titers: 200, epoch: 24 | loss: 0.0653179\n",
      "\tspeed: 0.0521s/iter; left time: 888.1903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0693793 Vali Loss: 0.0863263 Test Loss: 0.0889909\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0677006\n",
      "\tspeed: 0.0917s/iter; left time: 1551.5624s\n",
      "\titers: 200, epoch: 25 | loss: 0.0705059\n",
      "\tspeed: 0.0521s/iter; left time: 876.4930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0693588 Vali Loss: 0.0863821 Test Loss: 0.0890807\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0654885\n",
      "\tspeed: 0.0909s/iter; left time: 1518.4668s\n",
      "\titers: 200, epoch: 26 | loss: 0.0649945\n",
      "\tspeed: 0.0522s/iter; left time: 867.3155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0692742 Vali Loss: 0.0864751 Test Loss: 0.0893381\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0677808\n",
      "\tspeed: 0.0915s/iter; left time: 1507.1605s\n",
      "\titers: 200, epoch: 27 | loss: 0.0714075\n",
      "\tspeed: 0.0521s/iter; left time: 853.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0692092 Vali Loss: 0.0862476 Test Loss: 0.0890449\n",
      "Validation loss decreased (0.086261 --> 0.086248).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0650818\n",
      "\tspeed: 0.0932s/iter; left time: 1515.3784s\n",
      "\titers: 200, epoch: 28 | loss: 0.0720823\n",
      "\tspeed: 0.0523s/iter; left time: 844.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0691955 Vali Loss: 0.0863042 Test Loss: 0.0889602\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0675507\n",
      "\tspeed: 0.0913s/iter; left time: 1463.5355s\n",
      "\titers: 200, epoch: 29 | loss: 0.0689953\n",
      "\tspeed: 0.0522s/iter; left time: 832.1837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0691315 Vali Loss: 0.0862055 Test Loss: 0.0891577\n",
      "Validation loss decreased (0.086248 --> 0.086206).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0723119\n",
      "\tspeed: 0.0921s/iter; left time: 1456.2687s\n",
      "\titers: 200, epoch: 30 | loss: 0.0689444\n",
      "\tspeed: 0.0522s/iter; left time: 819.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0690726 Vali Loss: 0.0864122 Test Loss: 0.0891799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0699471\n",
      "\tspeed: 0.0913s/iter; left time: 1422.4287s\n",
      "\titers: 200, epoch: 31 | loss: 0.0650906\n",
      "\tspeed: 0.0520s/iter; left time: 805.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.82s\n",
      "Steps: 224 | Train Loss: 0.0690898 Vali Loss: 0.0861617 Test Loss: 0.0890982\n",
      "Validation loss decreased (0.086206 --> 0.086162).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0697123\n",
      "\tspeed: 0.0923s/iter; left time: 1417.4605s\n",
      "\titers: 200, epoch: 32 | loss: 0.0689837\n",
      "\tspeed: 0.0522s/iter; left time: 796.3078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0690290 Vali Loss: 0.0862783 Test Loss: 0.0891600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689367\n",
      "\tspeed: 0.0921s/iter; left time: 1393.5575s\n",
      "\titers: 200, epoch: 33 | loss: 0.0651389\n",
      "\tspeed: 0.0521s/iter; left time: 783.5860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0689599 Vali Loss: 0.0864315 Test Loss: 0.0891968\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0703542\n",
      "\tspeed: 0.0922s/iter; left time: 1374.2428s\n",
      "\titers: 200, epoch: 34 | loss: 0.0736774\n",
      "\tspeed: 0.0523s/iter; left time: 774.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0689449 Vali Loss: 0.0863892 Test Loss: 0.0892073\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694088\n",
      "\tspeed: 0.0920s/iter; left time: 1350.4302s\n",
      "\titers: 200, epoch: 35 | loss: 0.0643488\n",
      "\tspeed: 0.0521s/iter; left time: 760.2767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0689930 Vali Loss: 0.0862459 Test Loss: 0.0891558\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0662179\n",
      "\tspeed: 0.0917s/iter; left time: 1326.3345s\n",
      "\titers: 200, epoch: 36 | loss: 0.0716586\n",
      "\tspeed: 0.0522s/iter; left time: 750.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0689090 Vali Loss: 0.0862916 Test Loss: 0.0891562\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0689815\n",
      "\tspeed: 0.0918s/iter; left time: 1306.4955s\n",
      "\titers: 200, epoch: 37 | loss: 0.0692148\n",
      "\tspeed: 0.0521s/iter; left time: 736.6002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0688933 Vali Loss: 0.0864036 Test Loss: 0.0891469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0756959\n",
      "\tspeed: 0.0920s/iter; left time: 1288.5300s\n",
      "\titers: 200, epoch: 38 | loss: 0.0706713\n",
      "\tspeed: 0.0522s/iter; left time: 726.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0689504 Vali Loss: 0.0863323 Test Loss: 0.0891482\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0717678\n",
      "\tspeed: 0.0921s/iter; left time: 1269.8383s\n",
      "\titers: 200, epoch: 39 | loss: 0.0696688\n",
      "\tspeed: 0.0523s/iter; left time: 715.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0688292 Vali Loss: 0.0862189 Test Loss: 0.0891291\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669256\n",
      "\tspeed: 0.0917s/iter; left time: 1243.5590s\n",
      "\titers: 200, epoch: 40 | loss: 0.0677449\n",
      "\tspeed: 0.0520s/iter; left time: 700.3289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0688930 Vali Loss: 0.0861876 Test Loss: 0.0891016\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0648098\n",
      "\tspeed: 0.0914s/iter; left time: 1219.2675s\n",
      "\titers: 200, epoch: 41 | loss: 0.0646161\n",
      "\tspeed: 0.0523s/iter; left time: 693.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688258 Vali Loss: 0.0862216 Test Loss: 0.0891206\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021291740238666534, rmse:0.1459168940782547, mae:0.08909820020198822, rse:0.5149609446525574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1485177\n",
      "\tspeed: 0.0536s/iter; left time: 1194.7774s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372107\n",
      "\tspeed: 0.0520s/iter; left time: 1155.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.1479508 Vali Loss: 0.1469130 Test Loss: 0.1552787\n",
      "Validation loss decreased (inf --> 0.146913).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0860679\n",
      "\tspeed: 0.0933s/iter; left time: 2058.9109s\n",
      "\titers: 200, epoch: 2 | loss: 0.0842555\n",
      "\tspeed: 0.0523s/iter; left time: 1149.7879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:11.96s\n",
      "Steps: 224 | Train Loss: 0.0963806 Vali Loss: 0.0965345 Test Loss: 0.0970062\n",
      "Validation loss decreased (0.146913 --> 0.096534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792745\n",
      "\tspeed: 0.0931s/iter; left time: 2033.9156s\n",
      "\titers: 200, epoch: 3 | loss: 0.0799089\n",
      "\tspeed: 0.0524s/iter; left time: 1140.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0806034 Vali Loss: 0.0915469 Test Loss: 0.0932558\n",
      "Validation loss decreased (0.096534 --> 0.091547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0692745\n",
      "\tspeed: 0.0931s/iter; left time: 2013.9274s\n",
      "\titers: 200, epoch: 4 | loss: 0.0753272\n",
      "\tspeed: 0.0524s/iter; left time: 1129.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:11.97s\n",
      "Steps: 224 | Train Loss: 0.0771334 Vali Loss: 0.0894109 Test Loss: 0.0913275\n",
      "Validation loss decreased (0.091547 --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780892\n",
      "\tspeed: 0.0933s/iter; left time: 1996.3633s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733127\n",
      "\tspeed: 0.0521s/iter; left time: 1110.4064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0752457 Vali Loss: 0.0887977 Test Loss: 0.0907949\n",
      "Validation loss decreased (0.089411 --> 0.088798).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0735669\n",
      "\tspeed: 0.0927s/iter; left time: 1964.5271s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754406\n",
      "\tspeed: 0.0521s/iter; left time: 1098.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0741429 Vali Loss: 0.0879942 Test Loss: 0.0900813\n",
      "Validation loss decreased (0.088798 --> 0.087994).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0708586\n",
      "\tspeed: 0.0925s/iter; left time: 1939.5686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0723750\n",
      "\tspeed: 0.0520s/iter; left time: 1084.7077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0733710 Vali Loss: 0.0877222 Test Loss: 0.0897023\n",
      "Validation loss decreased (0.087994 --> 0.087722).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0735653\n",
      "\tspeed: 0.0931s/iter; left time: 1931.0122s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752200\n",
      "\tspeed: 0.0523s/iter; left time: 1079.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:11.94s\n",
      "Steps: 224 | Train Loss: 0.0726825 Vali Loss: 0.0871324 Test Loss: 0.0893786\n",
      "Validation loss decreased (0.087722 --> 0.087132).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738944\n",
      "\tspeed: 0.0928s/iter; left time: 1903.5217s\n",
      "\titers: 200, epoch: 9 | loss: 0.0740931\n",
      "\tspeed: 0.0521s/iter; left time: 1063.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0721897 Vali Loss: 0.0869960 Test Loss: 0.0890788\n",
      "Validation loss decreased (0.087132 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751932\n",
      "\tspeed: 0.0925s/iter; left time: 1875.5854s\n",
      "\titers: 200, epoch: 10 | loss: 0.0673028\n",
      "\tspeed: 0.0521s/iter; left time: 1052.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0717408 Vali Loss: 0.0867880 Test Loss: 0.0891405\n",
      "Validation loss decreased (0.086996 --> 0.086788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667565\n",
      "\tspeed: 0.0930s/iter; left time: 1865.8693s\n",
      "\titers: 200, epoch: 11 | loss: 0.0711614\n",
      "\tspeed: 0.0522s/iter; left time: 1041.6901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0714507 Vali Loss: 0.0870664 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710983\n",
      "\tspeed: 0.0923s/iter; left time: 1831.1766s\n",
      "\titers: 200, epoch: 12 | loss: 0.0680309\n",
      "\tspeed: 0.0521s/iter; left time: 1027.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0711380 Vali Loss: 0.0867219 Test Loss: 0.0890017\n",
      "Validation loss decreased (0.086788 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719549\n",
      "\tspeed: 0.0936s/iter; left time: 1836.1844s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728736\n",
      "\tspeed: 0.0522s/iter; left time: 1017.8660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0709379 Vali Loss: 0.0864662 Test Loss: 0.0890279\n",
      "Validation loss decreased (0.086722 --> 0.086466).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0695809\n",
      "\tspeed: 0.0939s/iter; left time: 1819.8176s\n",
      "\titers: 200, epoch: 14 | loss: 0.0691624\n",
      "\tspeed: 0.0524s/iter; left time: 1010.3812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:11.92s\n",
      "Steps: 224 | Train Loss: 0.0707244 Vali Loss: 0.0867192 Test Loss: 0.0890669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662107\n",
      "\tspeed: 0.0920s/iter; left time: 1763.4149s\n",
      "\titers: 200, epoch: 15 | loss: 0.0770034\n",
      "\tspeed: 0.0523s/iter; left time: 996.6752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0704650 Vali Loss: 0.0864952 Test Loss: 0.0890869\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746670\n",
      "\tspeed: 0.0919s/iter; left time: 1740.9086s\n",
      "\titers: 200, epoch: 16 | loss: 0.0751349\n",
      "\tspeed: 0.0521s/iter; left time: 981.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0703478 Vali Loss: 0.0866213 Test Loss: 0.0890552\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0691212\n",
      "\tspeed: 0.0920s/iter; left time: 1722.2517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0701027\n",
      "\tspeed: 0.0521s/iter; left time: 969.6255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0701723 Vali Loss: 0.0864791 Test Loss: 0.0890113\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0723499\n",
      "\tspeed: 0.0919s/iter; left time: 1700.2176s\n",
      "\titers: 200, epoch: 18 | loss: 0.0661663\n",
      "\tspeed: 0.0517s/iter; left time: 951.0878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0700250 Vali Loss: 0.0864334 Test Loss: 0.0889767\n",
      "Validation loss decreased (0.086466 --> 0.086433).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0676247\n",
      "\tspeed: 0.0937s/iter; left time: 1712.6457s\n",
      "\titers: 200, epoch: 19 | loss: 0.0656377\n",
      "\tspeed: 0.0520s/iter; left time: 945.4837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:11.85s\n",
      "Steps: 224 | Train Loss: 0.0698972 Vali Loss: 0.0863700 Test Loss: 0.0890557\n",
      "Validation loss decreased (0.086433 --> 0.086370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0731429\n",
      "\tspeed: 0.0929s/iter; left time: 1675.8486s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692441\n",
      "\tspeed: 0.0521s/iter; left time: 935.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0697965 Vali Loss: 0.0862033 Test Loss: 0.0890447\n",
      "Validation loss decreased (0.086370 --> 0.086203).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0687015\n",
      "\tspeed: 0.0925s/iter; left time: 1647.6947s\n",
      "\titers: 200, epoch: 21 | loss: 0.0658207\n",
      "\tspeed: 0.0522s/iter; left time: 924.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0696816 Vali Loss: 0.0863567 Test Loss: 0.0893161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0706210\n",
      "\tspeed: 0.0920s/iter; left time: 1619.2148s\n",
      "\titers: 200, epoch: 22 | loss: 0.0746962\n",
      "\tspeed: 0.0521s/iter; left time: 912.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0696258 Vali Loss: 0.0863918 Test Loss: 0.0891025\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0717456\n",
      "\tspeed: 0.0924s/iter; left time: 1604.8759s\n",
      "\titers: 200, epoch: 23 | loss: 0.0713271\n",
      "\tspeed: 0.0521s/iter; left time: 899.6638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0695054 Vali Loss: 0.0861524 Test Loss: 0.0890253\n",
      "Validation loss decreased (0.086203 --> 0.086152).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0754816\n",
      "\tspeed: 0.0929s/iter; left time: 1593.2847s\n",
      "\titers: 200, epoch: 24 | loss: 0.0685918\n",
      "\tspeed: 0.0522s/iter; left time: 889.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0694104 Vali Loss: 0.0862667 Test Loss: 0.0890559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633278\n",
      "\tspeed: 0.0919s/iter; left time: 1556.0090s\n",
      "\titers: 200, epoch: 25 | loss: 0.0648984\n",
      "\tspeed: 0.0520s/iter; left time: 875.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0693590 Vali Loss: 0.0861933 Test Loss: 0.0891097\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0697152\n",
      "\tspeed: 0.0922s/iter; left time: 1539.2391s\n",
      "\titers: 200, epoch: 26 | loss: 0.0684530\n",
      "\tspeed: 0.0521s/iter; left time: 864.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0692901 Vali Loss: 0.0861402 Test Loss: 0.0891699\n",
      "Validation loss decreased (0.086152 --> 0.086140).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680913\n",
      "\tspeed: 0.0929s/iter; left time: 1530.7129s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710975\n",
      "\tspeed: 0.0520s/iter; left time: 851.4128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0692415 Vali Loss: 0.0861493 Test Loss: 0.0890312\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662386\n",
      "\tspeed: 0.0922s/iter; left time: 1498.0141s\n",
      "\titers: 200, epoch: 28 | loss: 0.0694833\n",
      "\tspeed: 0.0521s/iter; left time: 841.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0691602 Vali Loss: 0.0861183 Test Loss: 0.0892049\n",
      "Validation loss decreased (0.086140 --> 0.086118).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725555\n",
      "\tspeed: 0.0936s/iter; left time: 1500.0613s\n",
      "\titers: 200, epoch: 29 | loss: 0.0715661\n",
      "\tspeed: 0.0524s/iter; left time: 835.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0691908 Vali Loss: 0.0860879 Test Loss: 0.0891321\n",
      "Validation loss decreased (0.086118 --> 0.086088).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0675764\n",
      "\tspeed: 0.0936s/iter; left time: 1478.5720s\n",
      "\titers: 200, epoch: 30 | loss: 0.0685819\n",
      "\tspeed: 0.0521s/iter; left time: 817.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:11.88s\n",
      "Steps: 224 | Train Loss: 0.0691524 Vali Loss: 0.0860893 Test Loss: 0.0891131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0705770\n",
      "\tspeed: 0.0921s/iter; left time: 1435.6957s\n",
      "\titers: 200, epoch: 31 | loss: 0.0713090\n",
      "\tspeed: 0.0520s/iter; left time: 805.1706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0691323 Vali Loss: 0.0861251 Test Loss: 0.0891209\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725021\n",
      "\tspeed: 0.0919s/iter; left time: 1411.8306s\n",
      "\titers: 200, epoch: 32 | loss: 0.0674104\n",
      "\tspeed: 0.0522s/iter; left time: 796.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0690699 Vali Loss: 0.0860819 Test Loss: 0.0890955\n",
      "Validation loss decreased (0.086088 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0671740\n",
      "\tspeed: 0.0930s/iter; left time: 1406.7771s\n",
      "\titers: 200, epoch: 33 | loss: 0.0640508\n",
      "\tspeed: 0.0522s/iter; left time: 784.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0690287 Vali Loss: 0.0861212 Test Loss: 0.0891954\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0705414\n",
      "\tspeed: 0.0917s/iter; left time: 1367.8583s\n",
      "\titers: 200, epoch: 34 | loss: 0.0681740\n",
      "\tspeed: 0.0521s/iter; left time: 771.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0689596 Vali Loss: 0.0862194 Test Loss: 0.0890935\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0701695\n",
      "\tspeed: 0.0923s/iter; left time: 1354.8329s\n",
      "\titers: 200, epoch: 35 | loss: 0.0673041\n",
      "\tspeed: 0.0521s/iter; left time: 760.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.91s\n",
      "Steps: 224 | Train Loss: 0.0689486 Vali Loss: 0.0861580 Test Loss: 0.0891037\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0642554\n",
      "\tspeed: 0.0935s/iter; left time: 1352.7820s\n",
      "\titers: 200, epoch: 36 | loss: 0.0672532\n",
      "\tspeed: 0.0520s/iter; left time: 747.0960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0689205 Vali Loss: 0.0860491 Test Loss: 0.0890471\n",
      "Validation loss decreased (0.086082 --> 0.086049).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744950\n",
      "\tspeed: 0.0928s/iter; left time: 1321.7060s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638594\n",
      "\tspeed: 0.0523s/iter; left time: 740.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0689579 Vali Loss: 0.0861269 Test Loss: 0.0891083\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700178\n",
      "\tspeed: 0.0924s/iter; left time: 1294.5238s\n",
      "\titers: 200, epoch: 38 | loss: 0.0661885\n",
      "\tspeed: 0.0520s/iter; left time: 723.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688744 Vali Loss: 0.0861560 Test Loss: 0.0891225\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0645115\n",
      "\tspeed: 0.0922s/iter; left time: 1271.8806s\n",
      "\titers: 200, epoch: 39 | loss: 0.0643578\n",
      "\tspeed: 0.0522s/iter; left time: 714.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0689252 Vali Loss: 0.0861439 Test Loss: 0.0890523\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0712911\n",
      "\tspeed: 0.0919s/iter; left time: 1246.2058s\n",
      "\titers: 200, epoch: 40 | loss: 0.0740808\n",
      "\tspeed: 0.0520s/iter; left time: 700.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.84s\n",
      "Steps: 224 | Train Loss: 0.0688536 Vali Loss: 0.0859760 Test Loss: 0.0890604\n",
      "Validation loss decreased (0.086049 --> 0.085976).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0645042\n",
      "\tspeed: 0.0949s/iter; left time: 1265.5498s\n",
      "\titers: 200, epoch: 41 | loss: 0.0700506\n",
      "\tspeed: 0.0519s/iter; left time: 687.2646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.79s\n",
      "Steps: 224 | Train Loss: 0.0688851 Vali Loss: 0.0861665 Test Loss: 0.0890974\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0722492\n",
      "\tspeed: 0.0919s/iter; left time: 1204.9191s\n",
      "\titers: 200, epoch: 42 | loss: 0.0705930\n",
      "\tspeed: 0.0520s/iter; left time: 677.1929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0688321 Vali Loss: 0.0860264 Test Loss: 0.0891213\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0742681\n",
      "\tspeed: 0.0919s/iter; left time: 1185.2241s\n",
      "\titers: 200, epoch: 43 | loss: 0.0690211\n",
      "\tspeed: 0.0524s/iter; left time: 669.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0688786 Vali Loss: 0.0860898 Test Loss: 0.0890831\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0646683\n",
      "\tspeed: 0.0920s/iter; left time: 1165.0368s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692453\n",
      "\tspeed: 0.0520s/iter; left time: 654.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0688329 Vali Loss: 0.0861044 Test Loss: 0.0890925\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0659040\n",
      "\tspeed: 0.0919s/iter; left time: 1144.2450s\n",
      "\titers: 200, epoch: 45 | loss: 0.0643121\n",
      "\tspeed: 0.0521s/iter; left time: 643.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0688306 Vali Loss: 0.0860788 Test Loss: 0.0891090\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0707033\n",
      "\tspeed: 0.0924s/iter; left time: 1129.4004s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666583\n",
      "\tspeed: 0.0520s/iter; left time: 630.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0687669 Vali Loss: 0.0861802 Test Loss: 0.0891388\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0668203\n",
      "\tspeed: 0.0921s/iter; left time: 1104.7161s\n",
      "\titers: 200, epoch: 47 | loss: 0.0678259\n",
      "\tspeed: 0.0520s/iter; left time: 618.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0687843 Vali Loss: 0.0860328 Test Loss: 0.0891000\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0671443\n",
      "\tspeed: 0.0922s/iter; left time: 1085.1757s\n",
      "\titers: 200, epoch: 48 | loss: 0.0705720\n",
      "\tspeed: 0.0522s/iter; left time: 609.3206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:11.89s\n",
      "Steps: 224 | Train Loss: 0.0687883 Vali Loss: 0.0860063 Test Loss: 0.0891141\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0660993\n",
      "\tspeed: 0.0924s/iter; left time: 1066.6538s\n",
      "\titers: 200, epoch: 49 | loss: 0.0729448\n",
      "\tspeed: 0.0520s/iter; left time: 595.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:11.83s\n",
      "Steps: 224 | Train Loss: 0.0687500 Vali Loss: 0.0861000 Test Loss: 0.0891243\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0677664\n",
      "\tspeed: 0.0920s/iter; left time: 1041.5790s\n",
      "\titers: 200, epoch: 50 | loss: 0.0669769\n",
      "\tspeed: 0.0520s/iter; left time: 584.2153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:11.87s\n",
      "Steps: 224 | Train Loss: 0.0687967 Vali Loss: 0.0861120 Test Loss: 0.0891771\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02123580500483513, rmse:0.1457251012325287, mae:0.08906044065952301, rse:0.514284074306488\n",
      "Intermediate time for DE and pred_len 24: 00h:22m:10.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1454190\n",
      "\tspeed: 0.1060s/iter; left time: 2343.0393s\n",
      "\titers: 200, epoch: 1 | loss: 0.1458661\n",
      "\tspeed: 0.0810s/iter; left time: 1782.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 222 | Train Loss: 0.1548092 Vali Loss: 0.1579965 Test Loss: 0.1693504\n",
      "Validation loss decreased (inf --> 0.157997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1108921\n",
      "\tspeed: 0.1399s/iter; left time: 3061.5215s\n",
      "\titers: 200, epoch: 2 | loss: 0.1092338\n",
      "\tspeed: 0.0808s/iter; left time: 1758.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.1152091 Vali Loss: 0.1214901 Test Loss: 0.1276618\n",
      "Validation loss decreased (0.157997 --> 0.121490).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1038423\n",
      "\tspeed: 0.1501s/iter; left time: 3251.0604s\n",
      "\titers: 200, epoch: 3 | loss: 0.1005785\n",
      "\tspeed: 0.0808s/iter; left time: 1742.5413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1043968 Vali Loss: 0.1193286 Test Loss: 0.1262590\n",
      "Validation loss decreased (0.121490 --> 0.119329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1001219\n",
      "\tspeed: 0.1419s/iter; left time: 3042.1401s\n",
      "\titers: 200, epoch: 4 | loss: 0.1055598\n",
      "\tspeed: 0.0809s/iter; left time: 1725.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.1018228 Vali Loss: 0.1181283 Test Loss: 0.1252880\n",
      "Validation loss decreased (0.119329 --> 0.118128).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0935889\n",
      "\tspeed: 0.1394s/iter; left time: 2956.1491s\n",
      "\titers: 200, epoch: 5 | loss: 0.1000896\n",
      "\tspeed: 0.0809s/iter; left time: 1707.1809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.1001162 Vali Loss: 0.1181318 Test Loss: 0.1253805\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0993517\n",
      "\tspeed: 0.1377s/iter; left time: 2891.3916s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011612\n",
      "\tspeed: 0.0807s/iter; left time: 1685.7866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0986901 Vali Loss: 0.1178792 Test Loss: 0.1254846\n",
      "Validation loss decreased (0.118128 --> 0.117879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1014253\n",
      "\tspeed: 0.1398s/iter; left time: 2903.2043s\n",
      "\titers: 200, epoch: 7 | loss: 0.0973408\n",
      "\tspeed: 0.0807s/iter; left time: 1668.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0973229 Vali Loss: 0.1176305 Test Loss: 0.1256454\n",
      "Validation loss decreased (0.117879 --> 0.117631).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0960878\n",
      "\tspeed: 0.1392s/iter; left time: 2860.8441s\n",
      "\titers: 200, epoch: 8 | loss: 0.0905648\n",
      "\tspeed: 0.0808s/iter; left time: 1651.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 222 | Train Loss: 0.0960914 Vali Loss: 0.1177847 Test Loss: 0.1265147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0934249\n",
      "\tspeed: 0.1380s/iter; left time: 2805.6270s\n",
      "\titers: 200, epoch: 9 | loss: 0.0898847\n",
      "\tspeed: 0.0809s/iter; left time: 1635.9969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0949588 Vali Loss: 0.1184804 Test Loss: 0.1269547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0914064\n",
      "\tspeed: 0.1383s/iter; left time: 2779.6687s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934437\n",
      "\tspeed: 0.0809s/iter; left time: 1618.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0937266 Vali Loss: 0.1183242 Test Loss: 0.1279009\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0910332\n",
      "\tspeed: 0.1389s/iter; left time: 2761.5205s\n",
      "\titers: 200, epoch: 11 | loss: 0.0906390\n",
      "\tspeed: 0.0808s/iter; left time: 1598.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0926955 Vali Loss: 0.1190470 Test Loss: 0.1288897\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0865961\n",
      "\tspeed: 0.1382s/iter; left time: 2716.9350s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923659\n",
      "\tspeed: 0.0808s/iter; left time: 1580.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0917330 Vali Loss: 0.1193468 Test Loss: 0.1290237\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0886916\n",
      "\tspeed: 0.1380s/iter; left time: 2682.3713s\n",
      "\titers: 200, epoch: 13 | loss: 0.0926560\n",
      "\tspeed: 0.0809s/iter; left time: 1563.7415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0908295 Vali Loss: 0.1193039 Test Loss: 0.1281978\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0902207\n",
      "\tspeed: 0.1387s/iter; left time: 2665.8168s\n",
      "\titers: 200, epoch: 14 | loss: 0.0890490\n",
      "\tspeed: 0.0808s/iter; left time: 1544.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0901019 Vali Loss: 0.1200060 Test Loss: 0.1297680\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0905493\n",
      "\tspeed: 0.1390s/iter; left time: 2640.8043s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844494\n",
      "\tspeed: 0.0808s/iter; left time: 1526.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0892479 Vali Loss: 0.1205788 Test Loss: 0.1293451\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0887716\n",
      "\tspeed: 0.1386s/iter; left time: 2600.8186s\n",
      "\titers: 200, epoch: 16 | loss: 0.0878107\n",
      "\tspeed: 0.0809s/iter; left time: 1509.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 222 | Train Loss: 0.0886576 Vali Loss: 0.1206160 Test Loss: 0.1295768\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0838581\n",
      "\tspeed: 0.1381s/iter; left time: 2560.9219s\n",
      "\titers: 200, epoch: 17 | loss: 0.0864668\n",
      "\tspeed: 0.0809s/iter; left time: 1493.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0880864 Vali Loss: 0.1208832 Test Loss: 0.1299632\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03595266863703728, rmse:0.18961189687252045, mae:0.12564539909362793, rse:0.6714540719985962\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1529302\n",
      "\tspeed: 0.0823s/iter; left time: 1819.1837s\n",
      "\titers: 200, epoch: 1 | loss: 0.1456952\n",
      "\tspeed: 0.0807s/iter; left time: 1775.4831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 222 | Train Loss: 0.1547636 Vali Loss: 0.1578183 Test Loss: 0.1693984\n",
      "Validation loss decreased (inf --> 0.157818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156026\n",
      "\tspeed: 0.1422s/iter; left time: 3110.5332s\n",
      "\titers: 200, epoch: 2 | loss: 0.1080172\n",
      "\tspeed: 0.0806s/iter; left time: 1756.3528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1157705 Vali Loss: 0.1214437 Test Loss: 0.1283181\n",
      "Validation loss decreased (0.157818 --> 0.121444).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046785\n",
      "\tspeed: 0.1411s/iter; left time: 3055.6022s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011220\n",
      "\tspeed: 0.0808s/iter; left time: 1741.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.1044551 Vali Loss: 0.1195383 Test Loss: 0.1268237\n",
      "Validation loss decreased (0.121444 --> 0.119538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991604\n",
      "\tspeed: 0.1420s/iter; left time: 3042.9044s\n",
      "\titers: 200, epoch: 4 | loss: 0.0966208\n",
      "\tspeed: 0.0807s/iter; left time: 1722.6233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.1019964 Vali Loss: 0.1182762 Test Loss: 0.1255367\n",
      "Validation loss decreased (0.119538 --> 0.118276).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0979637\n",
      "\tspeed: 0.1461s/iter; left time: 3099.3415s\n",
      "\titers: 200, epoch: 5 | loss: 0.0931982\n",
      "\tspeed: 0.0807s/iter; left time: 1704.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.1001509 Vali Loss: 0.1182702 Test Loss: 0.1250817\n",
      "Validation loss decreased (0.118276 --> 0.118270).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1015567\n",
      "\tspeed: 0.1399s/iter; left time: 2936.0198s\n",
      "\titers: 200, epoch: 6 | loss: 0.0909793\n",
      "\tspeed: 0.0807s/iter; left time: 1686.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0985937 Vali Loss: 0.1180413 Test Loss: 0.1251034\n",
      "Validation loss decreased (0.118270 --> 0.118041).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0943053\n",
      "\tspeed: 0.1410s/iter; left time: 2928.7755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0968980\n",
      "\tspeed: 0.0808s/iter; left time: 1669.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0970384 Vali Loss: 0.1180715 Test Loss: 0.1261100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0952572\n",
      "\tspeed: 0.1399s/iter; left time: 2875.3100s\n",
      "\titers: 200, epoch: 8 | loss: 0.0973560\n",
      "\tspeed: 0.0812s/iter; left time: 1659.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0955456 Vali Loss: 0.1184433 Test Loss: 0.1263607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0947614\n",
      "\tspeed: 0.1394s/iter; left time: 2833.1742s\n",
      "\titers: 200, epoch: 9 | loss: 0.0937324\n",
      "\tspeed: 0.0808s/iter; left time: 1633.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0941390 Vali Loss: 0.1191633 Test Loss: 0.1275874\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920048\n",
      "\tspeed: 0.1395s/iter; left time: 2803.6539s\n",
      "\titers: 200, epoch: 10 | loss: 0.0914769\n",
      "\tspeed: 0.0809s/iter; left time: 1618.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0928133 Vali Loss: 0.1188206 Test Loss: 0.1281140\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0923302\n",
      "\tspeed: 0.1401s/iter; left time: 2784.9030s\n",
      "\titers: 200, epoch: 11 | loss: 0.0908889\n",
      "\tspeed: 0.0807s/iter; left time: 1596.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0917612 Vali Loss: 0.1195217 Test Loss: 0.1288757\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0973572\n",
      "\tspeed: 0.1393s/iter; left time: 2737.8168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0875574\n",
      "\tspeed: 0.0807s/iter; left time: 1578.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0908663 Vali Loss: 0.1199547 Test Loss: 0.1287506\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0962057\n",
      "\tspeed: 0.1405s/iter; left time: 2731.7486s\n",
      "\titers: 200, epoch: 13 | loss: 0.0874106\n",
      "\tspeed: 0.0806s/iter; left time: 1559.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0899556 Vali Loss: 0.1201837 Test Loss: 0.1298474\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0878442\n",
      "\tspeed: 0.1396s/iter; left time: 2682.5639s\n",
      "\titers: 200, epoch: 14 | loss: 0.0867968\n",
      "\tspeed: 0.0808s/iter; left time: 1544.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0893488 Vali Loss: 0.1203016 Test Loss: 0.1307302\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0855336\n",
      "\tspeed: 0.1405s/iter; left time: 2668.3176s\n",
      "\titers: 200, epoch: 15 | loss: 0.0859972\n",
      "\tspeed: 0.0809s/iter; left time: 1528.1479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0885958 Vali Loss: 0.1204547 Test Loss: 0.1307303\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0880300\n",
      "\tspeed: 0.1401s/iter; left time: 2629.8427s\n",
      "\titers: 200, epoch: 16 | loss: 0.0898835\n",
      "\tspeed: 0.0809s/iter; left time: 1509.6834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 222 | Train Loss: 0.0880733 Vali Loss: 0.1205709 Test Loss: 0.1303698\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0352337621152401, rmse:0.1877065896987915, mae:0.1251034140586853, rse:0.6647070050239563\n",
      "Intermediate time for DE and pred_len 96: 00h:12m:23.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1567775\n",
      "\tspeed: 0.1087s/iter; left time: 2401.5694s\n",
      "\titers: 200, epoch: 1 | loss: 0.1513248\n",
      "\tspeed: 0.0813s/iter; left time: 1789.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 222 | Train Loss: 0.1564996 Vali Loss: 0.1594110 Test Loss: 0.1722484\n",
      "Validation loss decreased (inf --> 0.159411).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169308\n",
      "\tspeed: 0.1407s/iter; left time: 3077.4090s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121136\n",
      "\tspeed: 0.0813s/iter; left time: 1770.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1197778 Vali Loss: 0.1248173 Test Loss: 0.1331121\n",
      "Validation loss decreased (0.159411 --> 0.124817).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1040951\n",
      "\tspeed: 0.1408s/iter; left time: 3048.7281s\n",
      "\titers: 200, epoch: 3 | loss: 0.1140926\n",
      "\tspeed: 0.0813s/iter; left time: 1752.5344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.1098576 Vali Loss: 0.1228079 Test Loss: 0.1325458\n",
      "Validation loss decreased (0.124817 --> 0.122808).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032582\n",
      "\tspeed: 0.1414s/iter; left time: 3030.1456s\n",
      "\titers: 200, epoch: 4 | loss: 0.1121941\n",
      "\tspeed: 0.0816s/iter; left time: 1740.1548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.1072469 Vali Loss: 0.1222584 Test Loss: 0.1313323\n",
      "Validation loss decreased (0.122808 --> 0.122258).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1076371\n",
      "\tspeed: 0.1408s/iter; left time: 2987.7798s\n",
      "\titers: 200, epoch: 5 | loss: 0.1119657\n",
      "\tspeed: 0.0813s/iter; left time: 1717.2104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.1051176 Vali Loss: 0.1217997 Test Loss: 0.1318150\n",
      "Validation loss decreased (0.122258 --> 0.121800).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1028062\n",
      "\tspeed: 0.1410s/iter; left time: 2958.8591s\n",
      "\titers: 200, epoch: 6 | loss: 0.1075840\n",
      "\tspeed: 0.0814s/iter; left time: 1701.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.1031791 Vali Loss: 0.1216158 Test Loss: 0.1321796\n",
      "Validation loss decreased (0.121800 --> 0.121616).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020667\n",
      "\tspeed: 0.1414s/iter; left time: 2936.5526s\n",
      "\titers: 200, epoch: 7 | loss: 0.0999745\n",
      "\tspeed: 0.0814s/iter; left time: 1683.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1012984 Vali Loss: 0.1222705 Test Loss: 0.1328824\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1024710\n",
      "\tspeed: 0.1410s/iter; left time: 2896.9789s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013188\n",
      "\tspeed: 0.0814s/iter; left time: 1664.7842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0996514 Vali Loss: 0.1231942 Test Loss: 0.1332751\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1011731\n",
      "\tspeed: 0.1396s/iter; left time: 2838.1328s\n",
      "\titers: 200, epoch: 9 | loss: 0.0969350\n",
      "\tspeed: 0.0814s/iter; left time: 1645.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.0980915 Vali Loss: 0.1237174 Test Loss: 0.1340225\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0941293\n",
      "\tspeed: 0.1408s/iter; left time: 2830.0382s\n",
      "\titers: 200, epoch: 10 | loss: 0.0965152\n",
      "\tspeed: 0.0814s/iter; left time: 1627.4495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0967392 Vali Loss: 0.1234175 Test Loss: 0.1346313\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0937904\n",
      "\tspeed: 0.1406s/iter; left time: 2794.5166s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946716\n",
      "\tspeed: 0.0812s/iter; left time: 1606.5533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0955147 Vali Loss: 0.1240949 Test Loss: 0.1351768\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0918052\n",
      "\tspeed: 0.1399s/iter; left time: 2749.6484s\n",
      "\titers: 200, epoch: 12 | loss: 0.0966095\n",
      "\tspeed: 0.0811s/iter; left time: 1586.5761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0943976 Vali Loss: 0.1244152 Test Loss: 0.1353770\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0908815\n",
      "\tspeed: 0.1399s/iter; left time: 2719.8300s\n",
      "\titers: 200, epoch: 13 | loss: 0.0946134\n",
      "\tspeed: 0.0815s/iter; left time: 1576.4029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0934874 Vali Loss: 0.1243682 Test Loss: 0.1359254\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0948062\n",
      "\tspeed: 0.1404s/iter; left time: 2698.6876s\n",
      "\titers: 200, epoch: 14 | loss: 0.0925005\n",
      "\tspeed: 0.0813s/iter; left time: 1553.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0926105 Vali Loss: 0.1244345 Test Loss: 0.1361633\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0930774\n",
      "\tspeed: 0.1415s/iter; left time: 2688.0997s\n",
      "\titers: 200, epoch: 15 | loss: 0.0914964\n",
      "\tspeed: 0.0813s/iter; left time: 1535.2321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.30s\n",
      "Steps: 222 | Train Loss: 0.0918648 Vali Loss: 0.1247319 Test Loss: 0.1368228\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0891043\n",
      "\tspeed: 0.1399s/iter; left time: 2625.6884s\n",
      "\titers: 200, epoch: 16 | loss: 0.0967203\n",
      "\tspeed: 0.0812s/iter; left time: 1516.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0910989 Vali Loss: 0.1251153 Test Loss: 0.1371230\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03817787021398544, rmse:0.19539158046245575, mae:0.13217949867248535, rse:0.6920927166938782\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1584320\n",
      "\tspeed: 0.0829s/iter; left time: 1832.6007s\n",
      "\titers: 200, epoch: 1 | loss: 0.1539989\n",
      "\tspeed: 0.0812s/iter; left time: 1786.4277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.1572925 Vali Loss: 0.1603549 Test Loss: 0.1732188\n",
      "Validation loss decreased (inf --> 0.160355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1229231\n",
      "\tspeed: 0.1451s/iter; left time: 3175.2502s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093951\n",
      "\tspeed: 0.0813s/iter; left time: 1771.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1213124 Vali Loss: 0.1254657 Test Loss: 0.1345205\n",
      "Validation loss decreased (0.160355 --> 0.125466).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1082131\n",
      "\tspeed: 0.1441s/iter; left time: 3120.6045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1081986\n",
      "\tspeed: 0.0813s/iter; left time: 1753.1902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.1101862 Vali Loss: 0.1233200 Test Loss: 0.1328761\n",
      "Validation loss decreased (0.125466 --> 0.123320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1075606\n",
      "\tspeed: 0.1422s/iter; left time: 3047.8200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056124\n",
      "\tspeed: 0.0812s/iter; left time: 1732.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.1071764 Vali Loss: 0.1220768 Test Loss: 0.1326651\n",
      "Validation loss decreased (0.123320 --> 0.122077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1011877\n",
      "\tspeed: 0.1426s/iter; left time: 3024.5506s\n",
      "\titers: 200, epoch: 5 | loss: 0.1052904\n",
      "\tspeed: 0.0814s/iter; left time: 1717.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.1050479 Vali Loss: 0.1229597 Test Loss: 0.1319391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1010514\n",
      "\tspeed: 0.1400s/iter; left time: 2939.7290s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084885\n",
      "\tspeed: 0.0813s/iter; left time: 1699.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.1031179 Vali Loss: 0.1229192 Test Loss: 0.1332220\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1013987\n",
      "\tspeed: 0.1416s/iter; left time: 2940.6401s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027911\n",
      "\tspeed: 0.0813s/iter; left time: 1681.0609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.1015164 Vali Loss: 0.1232137 Test Loss: 0.1343062\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0949016\n",
      "\tspeed: 0.1407s/iter; left time: 2891.6230s\n",
      "\titers: 200, epoch: 8 | loss: 0.1015967\n",
      "\tspeed: 0.0813s/iter; left time: 1662.8910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0998196 Vali Loss: 0.1241509 Test Loss: 0.1345583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0980298\n",
      "\tspeed: 0.1413s/iter; left time: 2871.6177s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990568\n",
      "\tspeed: 0.0814s/iter; left time: 1645.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 222 | Train Loss: 0.0983526 Vali Loss: 0.1248584 Test Loss: 0.1345823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0965817\n",
      "\tspeed: 0.1408s/iter; left time: 2829.6648s\n",
      "\titers: 200, epoch: 10 | loss: 0.0910069\n",
      "\tspeed: 0.0813s/iter; left time: 1625.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0969771 Vali Loss: 0.1248797 Test Loss: 0.1352504\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0921308\n",
      "\tspeed: 0.1422s/iter; left time: 2826.9040s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946201\n",
      "\tspeed: 0.0815s/iter; left time: 1611.3782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.39s\n",
      "Steps: 222 | Train Loss: 0.0957095 Vali Loss: 0.1254821 Test Loss: 0.1363082\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0953712\n",
      "\tspeed: 0.1419s/iter; left time: 2790.2231s\n",
      "\titers: 200, epoch: 12 | loss: 0.0938992\n",
      "\tspeed: 0.0815s/iter; left time: 1594.4512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 222 | Train Loss: 0.0945926 Vali Loss: 0.1264368 Test Loss: 0.1374227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0939670\n",
      "\tspeed: 0.1418s/iter; left time: 2756.9232s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957235\n",
      "\tspeed: 0.0817s/iter; left time: 1579.5557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 222 | Train Loss: 0.0935417 Vali Loss: 0.1268010 Test Loss: 0.1383561\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0911809\n",
      "\tspeed: 0.1416s/iter; left time: 2720.8860s\n",
      "\titers: 200, epoch: 14 | loss: 0.0954952\n",
      "\tspeed: 0.0814s/iter; left time: 1556.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0926690 Vali Loss: 0.1271380 Test Loss: 0.1381323\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03783639147877693, rmse:0.19451579451560974, mae:0.1326650083065033, rse:0.688990592956543\n",
      "Intermediate time for DE and pred_len 168: 00h:11m:24.64s\n",
      "Intermediate time for DE: 00h:45m:59.02s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1348483\n",
      "\tspeed: 0.1062s/iter; left time: 2357.5424s\n",
      "\titers: 200, epoch: 1 | loss: 0.1235475\n",
      "\tspeed: 0.0804s/iter; left time: 1777.8606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.41s\n",
      "Steps: 223 | Train Loss: 0.1346395 Vali Loss: 0.1334999 Test Loss: 0.1537496\n",
      "Validation loss decreased (inf --> 0.133500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0891610\n",
      "\tspeed: 0.1383s/iter; left time: 3038.5504s\n",
      "\titers: 200, epoch: 2 | loss: 0.0834034\n",
      "\tspeed: 0.0801s/iter; left time: 1753.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0898294 Vali Loss: 0.0928724 Test Loss: 0.1040984\n",
      "Validation loss decreased (0.133500 --> 0.092872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818716\n",
      "\tspeed: 0.1388s/iter; left time: 3019.7473s\n",
      "\titers: 200, epoch: 3 | loss: 0.0716305\n",
      "\tspeed: 0.0803s/iter; left time: 1738.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0784626 Vali Loss: 0.0912489 Test Loss: 0.1033492\n",
      "Validation loss decreased (0.092872 --> 0.091249).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0787505\n",
      "\tspeed: 0.1394s/iter; left time: 3001.9322s\n",
      "\titers: 200, epoch: 4 | loss: 0.0758759\n",
      "\tspeed: 0.0802s/iter; left time: 1719.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0766306 Vali Loss: 0.0901929 Test Loss: 0.1032344\n",
      "Validation loss decreased (0.091249 --> 0.090193).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788459\n",
      "\tspeed: 0.1387s/iter; left time: 2955.4293s\n",
      "\titers: 200, epoch: 5 | loss: 0.0738315\n",
      "\tspeed: 0.0802s/iter; left time: 1700.6017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0755506 Vali Loss: 0.0901071 Test Loss: 0.1029200\n",
      "Validation loss decreased (0.090193 --> 0.090107).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0759309\n",
      "\tspeed: 0.1395s/iter; left time: 2941.6222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739040\n",
      "\tspeed: 0.0803s/iter; left time: 1684.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0746222 Vali Loss: 0.0896171 Test Loss: 0.1028844\n",
      "Validation loss decreased (0.090107 --> 0.089617).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0724300\n",
      "\tspeed: 0.1397s/iter; left time: 2913.8349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0740469\n",
      "\tspeed: 0.0802s/iter; left time: 1665.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 223 | Train Loss: 0.0740470 Vali Loss: 0.0890901 Test Loss: 0.1023908\n",
      "Validation loss decreased (0.089617 --> 0.089090).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761165\n",
      "\tspeed: 0.1392s/iter; left time: 2873.1964s\n",
      "\titers: 200, epoch: 8 | loss: 0.0689072\n",
      "\tspeed: 0.0802s/iter; left time: 1647.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0734278 Vali Loss: 0.0891402 Test Loss: 0.1023248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0715905\n",
      "\tspeed: 0.1382s/iter; left time: 2821.7113s\n",
      "\titers: 200, epoch: 9 | loss: 0.0787396\n",
      "\tspeed: 0.0803s/iter; left time: 1630.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0729763 Vali Loss: 0.0887639 Test Loss: 0.1022937\n",
      "Validation loss decreased (0.089090 --> 0.088764).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738042\n",
      "\tspeed: 0.1395s/iter; left time: 2816.8249s\n",
      "\titers: 200, epoch: 10 | loss: 0.0750337\n",
      "\tspeed: 0.0804s/iter; left time: 1614.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0725319 Vali Loss: 0.0888586 Test Loss: 0.1019429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0752971\n",
      "\tspeed: 0.1385s/iter; left time: 2766.3056s\n",
      "\titers: 200, epoch: 11 | loss: 0.0718730\n",
      "\tspeed: 0.0804s/iter; left time: 1598.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 223 | Train Loss: 0.0722108 Vali Loss: 0.0887466 Test Loss: 0.1020114\n",
      "Validation loss decreased (0.088764 --> 0.088747).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0683566\n",
      "\tspeed: 0.1395s/iter; left time: 2755.8191s\n",
      "\titers: 200, epoch: 12 | loss: 0.0716865\n",
      "\tspeed: 0.0803s/iter; left time: 1576.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0718465 Vali Loss: 0.0886935 Test Loss: 0.1024904\n",
      "Validation loss decreased (0.088747 --> 0.088694).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749665\n",
      "\tspeed: 0.1396s/iter; left time: 2726.3606s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728019\n",
      "\tspeed: 0.0802s/iter; left time: 1558.2728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0715018 Vali Loss: 0.0887555 Test Loss: 0.1022899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0727171\n",
      "\tspeed: 0.1387s/iter; left time: 2676.8611s\n",
      "\titers: 200, epoch: 14 | loss: 0.0698338\n",
      "\tspeed: 0.0802s/iter; left time: 1540.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0712557 Vali Loss: 0.0884080 Test Loss: 0.1021220\n",
      "Validation loss decreased (0.088694 --> 0.088408).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0738606\n",
      "\tspeed: 0.1397s/iter; left time: 2665.5034s\n",
      "\titers: 200, epoch: 15 | loss: 0.0688558\n",
      "\tspeed: 0.0802s/iter; left time: 1522.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0710802 Vali Loss: 0.0886561 Test Loss: 0.1022697\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734921\n",
      "\tspeed: 0.1387s/iter; left time: 2616.1925s\n",
      "\titers: 200, epoch: 16 | loss: 0.0693150\n",
      "\tspeed: 0.0802s/iter; left time: 1505.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0707799 Vali Loss: 0.0886526 Test Loss: 0.1023837\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0721558\n",
      "\tspeed: 0.1386s/iter; left time: 2583.4339s\n",
      "\titers: 200, epoch: 17 | loss: 0.0740197\n",
      "\tspeed: 0.0803s/iter; left time: 1487.3542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0706303 Vali Loss: 0.0882642 Test Loss: 0.1022535\n",
      "Validation loss decreased (0.088408 --> 0.088264).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0711871\n",
      "\tspeed: 0.1388s/iter; left time: 2555.7726s\n",
      "\titers: 200, epoch: 18 | loss: 0.0816860\n",
      "\tspeed: 0.0802s/iter; left time: 1469.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0703854 Vali Loss: 0.0883601 Test Loss: 0.1020565\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0741602\n",
      "\tspeed: 0.1383s/iter; left time: 2515.3679s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713896\n",
      "\tspeed: 0.0802s/iter; left time: 1451.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0702685 Vali Loss: 0.0881388 Test Loss: 0.1022986\n",
      "Validation loss decreased (0.088264 --> 0.088139).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0719018\n",
      "\tspeed: 0.1403s/iter; left time: 2520.0933s\n",
      "\titers: 200, epoch: 20 | loss: 0.0690474\n",
      "\tspeed: 0.0802s/iter; left time: 1433.5442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0700933 Vali Loss: 0.0881721 Test Loss: 0.1021070\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0712346\n",
      "\tspeed: 0.1392s/iter; left time: 2470.4293s\n",
      "\titers: 200, epoch: 21 | loss: 0.0659650\n",
      "\tspeed: 0.0801s/iter; left time: 1413.2624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0699631 Vali Loss: 0.0881782 Test Loss: 0.1021644\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0652486\n",
      "\tspeed: 0.1388s/iter; left time: 2431.3012s\n",
      "\titers: 200, epoch: 22 | loss: 0.0682071\n",
      "\tspeed: 0.0803s/iter; left time: 1399.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0698734 Vali Loss: 0.0880684 Test Loss: 0.1022999\n",
      "Validation loss decreased (0.088139 --> 0.088068).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0746235\n",
      "\tspeed: 0.1391s/iter; left time: 2406.4139s\n",
      "\titers: 200, epoch: 23 | loss: 0.0693815\n",
      "\tspeed: 0.0803s/iter; left time: 1380.4914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0696701 Vali Loss: 0.0879686 Test Loss: 0.1021321\n",
      "Validation loss decreased (0.088068 --> 0.087969).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0730705\n",
      "\tspeed: 0.1390s/iter; left time: 2373.1870s\n",
      "\titers: 200, epoch: 24 | loss: 0.0711131\n",
      "\tspeed: 0.0803s/iter; left time: 1363.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0696299 Vali Loss: 0.0878839 Test Loss: 0.1022739\n",
      "Validation loss decreased (0.087969 --> 0.087884).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0689954\n",
      "\tspeed: 0.1394s/iter; left time: 2349.2926s\n",
      "\titers: 200, epoch: 25 | loss: 0.0713015\n",
      "\tspeed: 0.0802s/iter; left time: 1343.8483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0695589 Vali Loss: 0.0881440 Test Loss: 0.1023520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0637646\n",
      "\tspeed: 0.1388s/iter; left time: 2307.1585s\n",
      "\titers: 200, epoch: 26 | loss: 0.0662034\n",
      "\tspeed: 0.0804s/iter; left time: 1328.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 223 | Train Loss: 0.0695231 Vali Loss: 0.0880633 Test Loss: 0.1021806\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0698196\n",
      "\tspeed: 0.1379s/iter; left time: 2261.5097s\n",
      "\titers: 200, epoch: 27 | loss: 0.0658523\n",
      "\tspeed: 0.0802s/iter; left time: 1308.2035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0694681 Vali Loss: 0.0880745 Test Loss: 0.1022816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0673808\n",
      "\tspeed: 0.1387s/iter; left time: 2244.1304s\n",
      "\titers: 200, epoch: 28 | loss: 0.0676038\n",
      "\tspeed: 0.0802s/iter; left time: 1289.0261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0692791 Vali Loss: 0.0880488 Test Loss: 0.1023436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751908\n",
      "\tspeed: 0.1378s/iter; left time: 2199.1928s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731162\n",
      "\tspeed: 0.0803s/iter; left time: 1273.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0692822 Vali Loss: 0.0880311 Test Loss: 0.1022699\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0660743\n",
      "\tspeed: 0.1380s/iter; left time: 2171.2260s\n",
      "\titers: 200, epoch: 30 | loss: 0.0733489\n",
      "\tspeed: 0.0796s/iter; left time: 1244.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0692286 Vali Loss: 0.0880953 Test Loss: 0.1023546\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0704500\n",
      "\tspeed: 0.1379s/iter; left time: 2138.8533s\n",
      "\titers: 200, epoch: 31 | loss: 0.0656725\n",
      "\tspeed: 0.0801s/iter; left time: 1234.0000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0691443 Vali Loss: 0.0880416 Test Loss: 0.1022984\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0761222\n",
      "\tspeed: 0.1380s/iter; left time: 2109.0803s\n",
      "\titers: 200, epoch: 32 | loss: 0.0687318\n",
      "\tspeed: 0.0801s/iter; left time: 1216.4699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0690752 Vali Loss: 0.0879020 Test Loss: 0.1023048\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0661833\n",
      "\tspeed: 0.1376s/iter; left time: 2072.8011s\n",
      "\titers: 200, epoch: 33 | loss: 0.0732448\n",
      "\tspeed: 0.0801s/iter; left time: 1198.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0690798 Vali Loss: 0.0878879 Test Loss: 0.1023647\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0719190\n",
      "\tspeed: 0.1375s/iter; left time: 2040.4420s\n",
      "\titers: 200, epoch: 34 | loss: 0.0688583\n",
      "\tspeed: 0.0805s/iter; left time: 1187.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0690935 Vali Loss: 0.0880725 Test Loss: 0.1024172\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025716405361890793, rmse:0.1603633612394333, mae:0.10227393358945847, rse:0.5532081127166748\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1366708\n",
      "\tspeed: 0.0817s/iter; left time: 1813.9799s\n",
      "\titers: 200, epoch: 1 | loss: 0.1241749\n",
      "\tspeed: 0.0801s/iter; left time: 1770.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.1342851 Vali Loss: 0.1348039 Test Loss: 0.1549900\n",
      "Validation loss decreased (inf --> 0.134804).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0886100\n",
      "\tspeed: 0.1390s/iter; left time: 3054.6923s\n",
      "\titers: 200, epoch: 2 | loss: 0.0809548\n",
      "\tspeed: 0.0797s/iter; left time: 1743.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0914494 Vali Loss: 0.0932200 Test Loss: 0.1052101\n",
      "Validation loss decreased (0.134804 --> 0.093220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0700615\n",
      "\tspeed: 0.1392s/iter; left time: 3028.0525s\n",
      "\titers: 200, epoch: 3 | loss: 0.0744769\n",
      "\tspeed: 0.0801s/iter; left time: 1733.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 223 | Train Loss: 0.0786488 Vali Loss: 0.0908873 Test Loss: 0.1033789\n",
      "Validation loss decreased (0.093220 --> 0.090887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0741743\n",
      "\tspeed: 0.1380s/iter; left time: 2972.0448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743613\n",
      "\tspeed: 0.0795s/iter; left time: 1704.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 223 | Train Loss: 0.0766186 Vali Loss: 0.0908253 Test Loss: 0.1032803\n",
      "Validation loss decreased (0.090887 --> 0.090825).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0684796\n",
      "\tspeed: 0.1381s/iter; left time: 2941.8794s\n",
      "\titers: 200, epoch: 5 | loss: 0.0779562\n",
      "\tspeed: 0.0799s/iter; left time: 1694.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 223 | Train Loss: 0.0753809 Vali Loss: 0.0893297 Test Loss: 0.1028940\n",
      "Validation loss decreased (0.090825 --> 0.089330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0696775\n",
      "\tspeed: 0.1389s/iter; left time: 2927.9471s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745337\n",
      "\tspeed: 0.0800s/iter; left time: 1679.3151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0745349 Vali Loss: 0.0894449 Test Loss: 0.1024341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785604\n",
      "\tspeed: 0.1381s/iter; left time: 2880.6686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0679719\n",
      "\tspeed: 0.0800s/iter; left time: 1660.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0739043 Vali Loss: 0.0892957 Test Loss: 0.1023731\n",
      "Validation loss decreased (0.089330 --> 0.089296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774263\n",
      "\tspeed: 0.1385s/iter; left time: 2859.5245s\n",
      "\titers: 200, epoch: 8 | loss: 0.0668307\n",
      "\tspeed: 0.0801s/iter; left time: 1645.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0733547 Vali Loss: 0.0889244 Test Loss: 0.1024472\n",
      "Validation loss decreased (0.089296 --> 0.088924).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746945\n",
      "\tspeed: 0.1387s/iter; left time: 2831.6787s\n",
      "\titers: 200, epoch: 9 | loss: 0.0714779\n",
      "\tspeed: 0.0800s/iter; left time: 1626.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0729554 Vali Loss: 0.0887235 Test Loss: 0.1022474\n",
      "Validation loss decreased (0.088924 --> 0.088724).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0718831\n",
      "\tspeed: 0.1401s/iter; left time: 2829.1447s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704201\n",
      "\tspeed: 0.0800s/iter; left time: 1607.2016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.21s\n",
      "Steps: 223 | Train Loss: 0.0724501 Vali Loss: 0.0885421 Test Loss: 0.1020218\n",
      "Validation loss decreased (0.088724 --> 0.088542).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0733186\n",
      "\tspeed: 0.1394s/iter; left time: 2784.5216s\n",
      "\titers: 200, epoch: 11 | loss: 0.0735558\n",
      "\tspeed: 0.0800s/iter; left time: 1588.9534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0721375 Vali Loss: 0.0884050 Test Loss: 0.1017645\n",
      "Validation loss decreased (0.088542 --> 0.088405).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0722721\n",
      "\tspeed: 0.1382s/iter; left time: 2728.4261s\n",
      "\titers: 200, epoch: 12 | loss: 0.0696643\n",
      "\tspeed: 0.0801s/iter; left time: 1573.6468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0718774 Vali Loss: 0.0883413 Test Loss: 0.1020326\n",
      "Validation loss decreased (0.088405 --> 0.088341).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729654\n",
      "\tspeed: 0.1392s/iter; left time: 2716.9914s\n",
      "\titers: 200, epoch: 13 | loss: 0.0749668\n",
      "\tspeed: 0.0800s/iter; left time: 1553.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0715923 Vali Loss: 0.0884434 Test Loss: 0.1023562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0688052\n",
      "\tspeed: 0.1381s/iter; left time: 2666.1109s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697273\n",
      "\tspeed: 0.0801s/iter; left time: 1538.4669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0713526 Vali Loss: 0.0883750 Test Loss: 0.1020522\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0679391\n",
      "\tspeed: 0.1384s/iter; left time: 2641.0054s\n",
      "\titers: 200, epoch: 15 | loss: 0.0700785\n",
      "\tspeed: 0.0801s/iter; left time: 1520.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0710252 Vali Loss: 0.0881383 Test Loss: 0.1018744\n",
      "Validation loss decreased (0.088341 --> 0.088138).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715094\n",
      "\tspeed: 0.1404s/iter; left time: 2646.9341s\n",
      "\titers: 200, epoch: 16 | loss: 0.0719865\n",
      "\tspeed: 0.0802s/iter; left time: 1503.9750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 223 | Train Loss: 0.0708653 Vali Loss: 0.0879714 Test Loss: 0.1020792\n",
      "Validation loss decreased (0.088138 --> 0.087971).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748008\n",
      "\tspeed: 0.1389s/iter; left time: 2588.8541s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705557\n",
      "\tspeed: 0.0800s/iter; left time: 1481.7785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0707088 Vali Loss: 0.0880462 Test Loss: 0.1023607\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0679809\n",
      "\tspeed: 0.1384s/iter; left time: 2547.2937s\n",
      "\titers: 200, epoch: 18 | loss: 0.0725685\n",
      "\tspeed: 0.0801s/iter; left time: 1466.1961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0704286 Vali Loss: 0.0880920 Test Loss: 0.1020400\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0667965\n",
      "\tspeed: 0.1383s/iter; left time: 2514.7743s\n",
      "\titers: 200, epoch: 19 | loss: 0.0677409\n",
      "\tspeed: 0.0801s/iter; left time: 1448.8163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0702506 Vali Loss: 0.0880540 Test Loss: 0.1022111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685981\n",
      "\tspeed: 0.1385s/iter; left time: 2487.7643s\n",
      "\titers: 200, epoch: 20 | loss: 0.0648524\n",
      "\tspeed: 0.0801s/iter; left time: 1431.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0701828 Vali Loss: 0.0880403 Test Loss: 0.1022138\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684365\n",
      "\tspeed: 0.1380s/iter; left time: 2447.5438s\n",
      "\titers: 200, epoch: 21 | loss: 0.0661878\n",
      "\tspeed: 0.0799s/iter; left time: 1410.0784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:18.03s\n",
      "Steps: 223 | Train Loss: 0.0699923 Vali Loss: 0.0880152 Test Loss: 0.1020563\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0721140\n",
      "\tspeed: 0.1389s/iter; left time: 2433.8766s\n",
      "\titers: 200, epoch: 22 | loss: 0.0700619\n",
      "\tspeed: 0.0801s/iter; left time: 1395.7775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0698893 Vali Loss: 0.0880357 Test Loss: 0.1022364\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0723281\n",
      "\tspeed: 0.1383s/iter; left time: 2391.6151s\n",
      "\titers: 200, epoch: 23 | loss: 0.0717652\n",
      "\tspeed: 0.0801s/iter; left time: 1376.6324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0697248 Vali Loss: 0.0880475 Test Loss: 0.1022223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0668357\n",
      "\tspeed: 0.1382s/iter; left time: 2358.5072s\n",
      "\titers: 200, epoch: 24 | loss: 0.0756700\n",
      "\tspeed: 0.0800s/iter; left time: 1358.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0696926 Vali Loss: 0.0879637 Test Loss: 0.1021364\n",
      "Validation loss decreased (0.087971 --> 0.087964).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0724150\n",
      "\tspeed: 0.1396s/iter; left time: 2352.7915s\n",
      "\titers: 200, epoch: 25 | loss: 0.0723249\n",
      "\tspeed: 0.0802s/iter; left time: 1343.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0695450 Vali Loss: 0.0879783 Test Loss: 0.1022011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0680662\n",
      "\tspeed: 0.1386s/iter; left time: 2304.0037s\n",
      "\titers: 200, epoch: 26 | loss: 0.0669919\n",
      "\tspeed: 0.0802s/iter; left time: 1326.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0695108 Vali Loss: 0.0880587 Test Loss: 0.1021642\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0691096\n",
      "\tspeed: 0.1388s/iter; left time: 2276.4538s\n",
      "\titers: 200, epoch: 27 | loss: 0.0648874\n",
      "\tspeed: 0.0801s/iter; left time: 1306.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0694146 Vali Loss: 0.0879691 Test Loss: 0.1022430\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0681378\n",
      "\tspeed: 0.1389s/iter; left time: 2247.8991s\n",
      "\titers: 200, epoch: 28 | loss: 0.0642104\n",
      "\tspeed: 0.0801s/iter; left time: 1287.5123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0693545 Vali Loss: 0.0879410 Test Loss: 0.1022402\n",
      "Validation loss decreased (0.087964 --> 0.087941).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0667084\n",
      "\tspeed: 0.1392s/iter; left time: 2221.3044s\n",
      "\titers: 200, epoch: 29 | loss: 0.0688164\n",
      "\tspeed: 0.0801s/iter; left time: 1269.8224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0693225 Vali Loss: 0.0880652 Test Loss: 0.1022794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0681703\n",
      "\tspeed: 0.1385s/iter; left time: 2178.9509s\n",
      "\titers: 200, epoch: 30 | loss: 0.0693843\n",
      "\tspeed: 0.0801s/iter; left time: 1252.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0692618 Vali Loss: 0.0880007 Test Loss: 0.1023244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0670438\n",
      "\tspeed: 0.1385s/iter; left time: 2148.6375s\n",
      "\titers: 200, epoch: 31 | loss: 0.0717225\n",
      "\tspeed: 0.0800s/iter; left time: 1233.0719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 223 | Train Loss: 0.0691872 Vali Loss: 0.0879294 Test Loss: 0.1023856\n",
      "Validation loss decreased (0.087941 --> 0.087929).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0682997\n",
      "\tspeed: 0.1394s/iter; left time: 2131.2663s\n",
      "\titers: 200, epoch: 32 | loss: 0.0684763\n",
      "\tspeed: 0.0802s/iter; left time: 1217.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0690877 Vali Loss: 0.0880422 Test Loss: 0.1023571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0701336\n",
      "\tspeed: 0.1382s/iter; left time: 2082.1144s\n",
      "\titers: 200, epoch: 33 | loss: 0.0700182\n",
      "\tspeed: 0.0802s/iter; left time: 1200.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:18.14s\n",
      "Steps: 223 | Train Loss: 0.0690832 Vali Loss: 0.0879702 Test Loss: 0.1022660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0709029\n",
      "\tspeed: 0.1384s/iter; left time: 2054.6799s\n",
      "\titers: 200, epoch: 34 | loss: 0.0640473\n",
      "\tspeed: 0.0802s/iter; left time: 1182.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0690259 Vali Loss: 0.0879758 Test Loss: 0.1023446\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0705968\n",
      "\tspeed: 0.1383s/iter; left time: 2022.2637s\n",
      "\titers: 200, epoch: 35 | loss: 0.0717035\n",
      "\tspeed: 0.0800s/iter; left time: 1161.9997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0689972 Vali Loss: 0.0879484 Test Loss: 0.1023216\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0669579\n",
      "\tspeed: 0.1385s/iter; left time: 1993.3011s\n",
      "\titers: 200, epoch: 36 | loss: 0.0741236\n",
      "\tspeed: 0.0801s/iter; left time: 1145.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0689777 Vali Loss: 0.0880503 Test Loss: 0.1023325\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0677079\n",
      "\tspeed: 0.1390s/iter; left time: 1970.0005s\n",
      "\titers: 200, epoch: 37 | loss: 0.0674071\n",
      "\tspeed: 0.0803s/iter; left time: 1129.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 223 | Train Loss: 0.0689180 Vali Loss: 0.0880585 Test Loss: 0.1023927\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0700749\n",
      "\tspeed: 0.1387s/iter; left time: 1934.5878s\n",
      "\titers: 200, epoch: 38 | loss: 0.0709952\n",
      "\tspeed: 0.0800s/iter; left time: 1108.6246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0689011 Vali Loss: 0.0879418 Test Loss: 0.1023480\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0670714\n",
      "\tspeed: 0.1392s/iter; left time: 1911.0750s\n",
      "\titers: 200, epoch: 39 | loss: 0.0700057\n",
      "\tspeed: 0.0801s/iter; left time: 1091.5956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 223 | Train Loss: 0.0688655 Vali Loss: 0.0879522 Test Loss: 0.1023728\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0683985\n",
      "\tspeed: 0.1385s/iter; left time: 1870.5270s\n",
      "\titers: 200, epoch: 40 | loss: 0.0715017\n",
      "\tspeed: 0.0801s/iter; left time: 1073.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 223 | Train Loss: 0.0688567 Vali Loss: 0.0879054 Test Loss: 0.1023428\n",
      "Validation loss decreased (0.087929 --> 0.087905).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0670869\n",
      "\tspeed: 0.1408s/iter; left time: 1869.5676s\n",
      "\titers: 200, epoch: 41 | loss: 0.0683611\n",
      "\tspeed: 0.0801s/iter; left time: 1055.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0688425 Vali Loss: 0.0879598 Test Loss: 0.1023723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0749719\n",
      "\tspeed: 0.1380s/iter; left time: 1802.5750s\n",
      "\titers: 200, epoch: 42 | loss: 0.0689353\n",
      "\tspeed: 0.0800s/iter; left time: 1036.3447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0687792 Vali Loss: 0.0879433 Test Loss: 0.1024432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0679562\n",
      "\tspeed: 0.1378s/iter; left time: 1768.9955s\n",
      "\titers: 200, epoch: 43 | loss: 0.0753458\n",
      "\tspeed: 0.0800s/iter; left time: 1019.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 223 | Train Loss: 0.0688359 Vali Loss: 0.0879439 Test Loss: 0.1023748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0721654\n",
      "\tspeed: 0.1376s/iter; left time: 1736.0321s\n",
      "\titers: 200, epoch: 44 | loss: 0.0668151\n",
      "\tspeed: 0.0799s/iter; left time: 1000.2783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0687932 Vali Loss: 0.0879905 Test Loss: 0.1023978\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0727886\n",
      "\tspeed: 0.1376s/iter; left time: 1704.9246s\n",
      "\titers: 200, epoch: 45 | loss: 0.0697393\n",
      "\tspeed: 0.0800s/iter; left time: 982.7047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 223 | Train Loss: 0.0688187 Vali Loss: 0.0879540 Test Loss: 0.1023846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0716208\n",
      "\tspeed: 0.1375s/iter; left time: 1672.3700s\n",
      "\titers: 200, epoch: 46 | loss: 0.0696595\n",
      "\tspeed: 0.0799s/iter; left time: 963.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:18.04s\n",
      "Steps: 223 | Train Loss: 0.0687803 Vali Loss: 0.0879580 Test Loss: 0.1024324\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0673338\n",
      "\tspeed: 0.1380s/iter; left time: 1648.2307s\n",
      "\titers: 200, epoch: 47 | loss: 0.0685025\n",
      "\tspeed: 0.0799s/iter; left time: 946.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0687667 Vali Loss: 0.0880418 Test Loss: 0.1024176\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0642225\n",
      "\tspeed: 0.1379s/iter; left time: 1616.3080s\n",
      "\titers: 200, epoch: 48 | loss: 0.0709631\n",
      "\tspeed: 0.0800s/iter; left time: 929.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 223 | Train Loss: 0.0687600 Vali Loss: 0.0879649 Test Loss: 0.1024027\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0651251\n",
      "\tspeed: 0.1385s/iter; left time: 1592.5670s\n",
      "\titers: 200, epoch: 49 | loss: 0.0700690\n",
      "\tspeed: 0.0800s/iter; left time: 911.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 223 | Train Loss: 0.0687423 Vali Loss: 0.0880024 Test Loss: 0.1024056\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0694808\n",
      "\tspeed: 0.1386s/iter; left time: 1562.3954s\n",
      "\titers: 200, epoch: 50 | loss: 0.0728666\n",
      "\tspeed: 0.0801s/iter; left time: 895.3182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 223 | Train Loss: 0.0687120 Vali Loss: 0.0880527 Test Loss: 0.1024245\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025694113224744797, rmse:0.1602938324213028, mae:0.10234277695417404, rse:0.5529683232307434\n",
      "Intermediate time for GB and pred_len 24: 00h:30m:52.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1358091\n",
      "\tspeed: 0.1060s/iter; left time: 2342.1521s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349047\n",
      "\tspeed: 0.0807s/iter; left time: 1775.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.37s\n",
      "Steps: 222 | Train Loss: 0.1414604 Vali Loss: 0.1448565 Test Loss: 0.1698220\n",
      "Validation loss decreased (inf --> 0.144856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1088362\n",
      "\tspeed: 0.1409s/iter; left time: 3082.2045s\n",
      "\titers: 200, epoch: 2 | loss: 0.1076481\n",
      "\tspeed: 0.0808s/iter; left time: 1759.2820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.1105519 Vali Loss: 0.1171972 Test Loss: 0.1389077\n",
      "Validation loss decreased (0.144856 --> 0.117197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0983290\n",
      "\tspeed: 0.1403s/iter; left time: 3038.4772s\n",
      "\titers: 200, epoch: 3 | loss: 0.1036651\n",
      "\tspeed: 0.0807s/iter; left time: 1740.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.1017730 Vali Loss: 0.1162336 Test Loss: 0.1390613\n",
      "Validation loss decreased (0.117197 --> 0.116234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1023673\n",
      "\tspeed: 0.1401s/iter; left time: 3002.8141s\n",
      "\titers: 200, epoch: 4 | loss: 0.0994180\n",
      "\tspeed: 0.0809s/iter; left time: 1726.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0996428 Vali Loss: 0.1154969 Test Loss: 0.1391144\n",
      "Validation loss decreased (0.116234 --> 0.115497).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971655\n",
      "\tspeed: 0.1406s/iter; left time: 2982.7213s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963834\n",
      "\tspeed: 0.0807s/iter; left time: 1702.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0980626 Vali Loss: 0.1158063 Test Loss: 0.1411522\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0982594\n",
      "\tspeed: 0.1378s/iter; left time: 2893.0686s\n",
      "\titers: 200, epoch: 6 | loss: 0.0976275\n",
      "\tspeed: 0.0806s/iter; left time: 1683.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0965680 Vali Loss: 0.1155324 Test Loss: 0.1414398\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0927428\n",
      "\tspeed: 0.1393s/iter; left time: 2893.1079s\n",
      "\titers: 200, epoch: 7 | loss: 0.0932568\n",
      "\tspeed: 0.0808s/iter; left time: 1669.0278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0951679 Vali Loss: 0.1151066 Test Loss: 0.1423663\n",
      "Validation loss decreased (0.115497 --> 0.115107).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0970360\n",
      "\tspeed: 0.1407s/iter; left time: 2890.8038s\n",
      "\titers: 200, epoch: 8 | loss: 0.0886637\n",
      "\tspeed: 0.0807s/iter; left time: 1650.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0936608 Vali Loss: 0.1151603 Test Loss: 0.1438675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0899512\n",
      "\tspeed: 0.1384s/iter; left time: 2812.3019s\n",
      "\titers: 200, epoch: 9 | loss: 0.0887586\n",
      "\tspeed: 0.0805s/iter; left time: 1628.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 222 | Train Loss: 0.0923841 Vali Loss: 0.1151062 Test Loss: 0.1445265\n",
      "Validation loss decreased (0.115107 --> 0.115106).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0902266\n",
      "\tspeed: 0.1405s/iter; left time: 2824.7093s\n",
      "\titers: 200, epoch: 10 | loss: 0.0846719\n",
      "\tspeed: 0.0805s/iter; left time: 1610.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0910080 Vali Loss: 0.1150696 Test Loss: 0.1448590\n",
      "Validation loss decreased (0.115106 --> 0.115070).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0889520\n",
      "\tspeed: 0.1400s/iter; left time: 2783.6996s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883325\n",
      "\tspeed: 0.0806s/iter; left time: 1593.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.0897821 Vali Loss: 0.1159446 Test Loss: 0.1465855\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0860249\n",
      "\tspeed: 0.1388s/iter; left time: 2729.6262s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861240\n",
      "\tspeed: 0.0805s/iter; left time: 1573.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.06s\n",
      "Steps: 222 | Train Loss: 0.0884889 Vali Loss: 0.1161465 Test Loss: 0.1472885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0880837\n",
      "\tspeed: 0.1396s/iter; left time: 2712.7592s\n",
      "\titers: 200, epoch: 13 | loss: 0.0861884\n",
      "\tspeed: 0.0806s/iter; left time: 1558.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0875239 Vali Loss: 0.1165294 Test Loss: 0.1474077\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0887766\n",
      "\tspeed: 0.1381s/iter; left time: 2654.2521s\n",
      "\titers: 200, epoch: 14 | loss: 0.0835006\n",
      "\tspeed: 0.0807s/iter; left time: 1541.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0865451 Vali Loss: 0.1182222 Test Loss: 0.1485320\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0906235\n",
      "\tspeed: 0.1395s/iter; left time: 2649.9562s\n",
      "\titers: 200, epoch: 15 | loss: 0.0860536\n",
      "\tspeed: 0.0808s/iter; left time: 1525.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.0857539 Vali Loss: 0.1185830 Test Loss: 0.1495188\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0864211\n",
      "\tspeed: 0.1382s/iter; left time: 2594.7448s\n",
      "\titers: 200, epoch: 16 | loss: 0.0855064\n",
      "\tspeed: 0.0806s/iter; left time: 1504.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 222 | Train Loss: 0.0849867 Vali Loss: 0.1185916 Test Loss: 0.1497924\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0849342\n",
      "\tspeed: 0.1388s/iter; left time: 2575.5074s\n",
      "\titers: 200, epoch: 17 | loss: 0.0859643\n",
      "\tspeed: 0.0808s/iter; left time: 1489.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0844976 Vali Loss: 0.1189754 Test Loss: 0.1503125\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0867529\n",
      "\tspeed: 0.1384s/iter; left time: 2536.3141s\n",
      "\titers: 200, epoch: 18 | loss: 0.0841190\n",
      "\tspeed: 0.0807s/iter; left time: 1470.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 222 | Train Loss: 0.0838787 Vali Loss: 0.1192779 Test Loss: 0.1504883\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0843950\n",
      "\tspeed: 0.1382s/iter; left time: 2502.7071s\n",
      "\titers: 200, epoch: 19 | loss: 0.0836716\n",
      "\tspeed: 0.0801s/iter; left time: 1442.5115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:17.98s\n",
      "Steps: 222 | Train Loss: 0.0833456 Vali Loss: 0.1201275 Test Loss: 0.1502754\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815062\n",
      "\tspeed: 0.1380s/iter; left time: 2467.2989s\n",
      "\titers: 200, epoch: 20 | loss: 0.0901580\n",
      "\tspeed: 0.0806s/iter; left time: 1432.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0829971 Vali Loss: 0.1198272 Test Loss: 0.1505910\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04585912451148033, rmse:0.2141474336385727, mae:0.1448589712381363, rse:0.7405516505241394\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1389547\n",
      "\tspeed: 0.0823s/iter; left time: 1818.7680s\n",
      "\titers: 200, epoch: 1 | loss: 0.1327076\n",
      "\tspeed: 0.0808s/iter; left time: 1776.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 222 | Train Loss: 0.1421077 Vali Loss: 0.1456874 Test Loss: 0.1706855\n",
      "Validation loss decreased (inf --> 0.145687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122408\n",
      "\tspeed: 0.1409s/iter; left time: 3083.2981s\n",
      "\titers: 200, epoch: 2 | loss: 0.1036625\n",
      "\tspeed: 0.0807s/iter; left time: 1758.1235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 222 | Train Loss: 0.1115317 Vali Loss: 0.1174392 Test Loss: 0.1394317\n",
      "Validation loss decreased (0.145687 --> 0.117439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1019299\n",
      "\tspeed: 0.1456s/iter; left time: 3152.2284s\n",
      "\titers: 200, epoch: 3 | loss: 0.0972814\n",
      "\tspeed: 0.0806s/iter; left time: 1737.7109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.1020559 Vali Loss: 0.1162187 Test Loss: 0.1396693\n",
      "Validation loss decreased (0.117439 --> 0.116219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993500\n",
      "\tspeed: 0.1412s/iter; left time: 3027.4768s\n",
      "\titers: 200, epoch: 4 | loss: 0.0995188\n",
      "\tspeed: 0.0806s/iter; left time: 1720.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0997396 Vali Loss: 0.1157485 Test Loss: 0.1406896\n",
      "Validation loss decreased (0.116219 --> 0.115749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0968165\n",
      "\tspeed: 0.1424s/iter; left time: 3019.9645s\n",
      "\titers: 200, epoch: 5 | loss: 0.1007464\n",
      "\tspeed: 0.0807s/iter; left time: 1704.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0979422 Vali Loss: 0.1149712 Test Loss: 0.1407970\n",
      "Validation loss decreased (0.115749 --> 0.114971).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0946351\n",
      "\tspeed: 0.1417s/iter; left time: 2975.4706s\n",
      "\titers: 200, epoch: 6 | loss: 0.0939036\n",
      "\tspeed: 0.0806s/iter; left time: 1683.3310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0962292 Vali Loss: 0.1152229 Test Loss: 0.1415257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0939565\n",
      "\tspeed: 0.1403s/iter; left time: 2913.3856s\n",
      "\titers: 200, epoch: 7 | loss: 0.0928832\n",
      "\tspeed: 0.0806s/iter; left time: 1665.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 222 | Train Loss: 0.0945780 Vali Loss: 0.1153166 Test Loss: 0.1427085\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0905723\n",
      "\tspeed: 0.1396s/iter; left time: 2869.2149s\n",
      "\titers: 200, epoch: 8 | loss: 0.0928991\n",
      "\tspeed: 0.0805s/iter; left time: 1646.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0930087 Vali Loss: 0.1158621 Test Loss: 0.1432852\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0974457\n",
      "\tspeed: 0.1389s/iter; left time: 2823.7890s\n",
      "\titers: 200, epoch: 9 | loss: 0.0915007\n",
      "\tspeed: 0.0806s/iter; left time: 1629.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0914214 Vali Loss: 0.1161837 Test Loss: 0.1440141\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0934651\n",
      "\tspeed: 0.1391s/iter; left time: 2795.6718s\n",
      "\titers: 200, epoch: 10 | loss: 0.0912926\n",
      "\tspeed: 0.0805s/iter; left time: 1609.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 222 | Train Loss: 0.0901336 Vali Loss: 0.1175008 Test Loss: 0.1453111\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0854642\n",
      "\tspeed: 0.1395s/iter; left time: 2773.6587s\n",
      "\titers: 200, epoch: 11 | loss: 0.0908249\n",
      "\tspeed: 0.0806s/iter; left time: 1593.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.12s\n",
      "Steps: 222 | Train Loss: 0.0889183 Vali Loss: 0.1184011 Test Loss: 0.1458802\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0828760\n",
      "\tspeed: 0.1387s/iter; left time: 2727.2699s\n",
      "\titers: 200, epoch: 12 | loss: 0.0861469\n",
      "\tspeed: 0.0808s/iter; left time: 1579.4885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 222 | Train Loss: 0.0878806 Vali Loss: 0.1183724 Test Loss: 0.1460292\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0887259\n",
      "\tspeed: 0.1397s/iter; left time: 2715.6352s\n",
      "\titers: 200, epoch: 13 | loss: 0.0837332\n",
      "\tspeed: 0.0809s/iter; left time: 1563.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0869470 Vali Loss: 0.1185323 Test Loss: 0.1464543\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0832796\n",
      "\tspeed: 0.1391s/iter; left time: 2671.9162s\n",
      "\titers: 200, epoch: 14 | loss: 0.0869908\n",
      "\tspeed: 0.0803s/iter; left time: 1534.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 222 | Train Loss: 0.0861373 Vali Loss: 0.1191460 Test Loss: 0.1477436\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0838692\n",
      "\tspeed: 0.1386s/iter; left time: 2632.5983s\n",
      "\titers: 200, epoch: 15 | loss: 0.0864395\n",
      "\tspeed: 0.0807s/iter; left time: 1524.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 222 | Train Loss: 0.0854612 Vali Loss: 0.1197591 Test Loss: 0.1484080\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0425884984433651, rmse:0.2063698172569275, mae:0.14079692959785461, rse:0.7136555910110474\n",
      "Intermediate time for GB and pred_len 96: 00h:13m:06.20s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1398706\n",
      "\tspeed: 0.1068s/iter; left time: 2361.2180s\n",
      "\titers: 200, epoch: 1 | loss: 0.1382439\n",
      "\tspeed: 0.0814s/iter; left time: 1791.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 222 | Train Loss: 0.1429146 Vali Loss: 0.1471829 Test Loss: 0.1729666\n",
      "Validation loss decreased (inf --> 0.147183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1098959\n",
      "\tspeed: 0.1408s/iter; left time: 3081.3877s\n",
      "\titers: 200, epoch: 2 | loss: 0.1087988\n",
      "\tspeed: 0.0812s/iter; left time: 1769.1272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.1143142 Vali Loss: 0.1217393 Test Loss: 0.1444807\n",
      "Validation loss decreased (0.147183 --> 0.121739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1046128\n",
      "\tspeed: 0.1406s/iter; left time: 3044.6341s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066747\n",
      "\tspeed: 0.0816s/iter; left time: 1758.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1060163 Vali Loss: 0.1199054 Test Loss: 0.1455345\n",
      "Validation loss decreased (0.121739 --> 0.119905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1033576\n",
      "\tspeed: 0.1419s/iter; left time: 3041.1615s\n",
      "\titers: 200, epoch: 4 | loss: 0.1030032\n",
      "\tspeed: 0.0814s/iter; left time: 1737.4647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1033712 Vali Loss: 0.1203927 Test Loss: 0.1471462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1010814\n",
      "\tspeed: 0.1393s/iter; left time: 2954.4741s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997352\n",
      "\tspeed: 0.0814s/iter; left time: 1718.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 222 | Train Loss: 0.1010653 Vali Loss: 0.1205869 Test Loss: 0.1493505\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0962149\n",
      "\tspeed: 0.1406s/iter; left time: 2950.9309s\n",
      "\titers: 200, epoch: 6 | loss: 0.1000016\n",
      "\tspeed: 0.0811s/iter; left time: 1694.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 222 | Train Loss: 0.0988993 Vali Loss: 0.1206984 Test Loss: 0.1489712\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0959983\n",
      "\tspeed: 0.1398s/iter; left time: 2904.1469s\n",
      "\titers: 200, epoch: 7 | loss: 0.0942835\n",
      "\tspeed: 0.0813s/iter; left time: 1679.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 222 | Train Loss: 0.0969016 Vali Loss: 0.1214482 Test Loss: 0.1511385\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0948653\n",
      "\tspeed: 0.1389s/iter; left time: 2854.4583s\n",
      "\titers: 200, epoch: 8 | loss: 0.0935265\n",
      "\tspeed: 0.0811s/iter; left time: 1658.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.0950081 Vali Loss: 0.1208681 Test Loss: 0.1513408\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0944575\n",
      "\tspeed: 0.1397s/iter; left time: 2840.0386s\n",
      "\titers: 200, epoch: 9 | loss: 0.0945373\n",
      "\tspeed: 0.0814s/iter; left time: 1646.6899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0932375 Vali Loss: 0.1216507 Test Loss: 0.1517617\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0912117\n",
      "\tspeed: 0.1400s/iter; left time: 2814.2967s\n",
      "\titers: 200, epoch: 10 | loss: 0.0915381\n",
      "\tspeed: 0.0812s/iter; left time: 1623.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 222 | Train Loss: 0.0916975 Vali Loss: 0.1230478 Test Loss: 0.1538335\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0911945\n",
      "\tspeed: 0.1395s/iter; left time: 2774.2939s\n",
      "\titers: 200, epoch: 11 | loss: 0.0884001\n",
      "\tspeed: 0.0813s/iter; left time: 1607.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0903979 Vali Loss: 0.1235992 Test Loss: 0.1541341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0880264\n",
      "\tspeed: 0.1391s/iter; left time: 2735.3835s\n",
      "\titers: 200, epoch: 12 | loss: 0.0866772\n",
      "\tspeed: 0.0815s/iter; left time: 1594.7638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0892005 Vali Loss: 0.1242566 Test Loss: 0.1546974\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0874250\n",
      "\tspeed: 0.1387s/iter; left time: 2696.3822s\n",
      "\titers: 200, epoch: 13 | loss: 0.0880191\n",
      "\tspeed: 0.0812s/iter; left time: 1570.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0882589 Vali Loss: 0.1245862 Test Loss: 0.1551056\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04369062930345535, rmse:0.20902302861213684, mae:0.14553453028202057, rse:0.7247128486633301\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1419638\n",
      "\tspeed: 0.0828s/iter; left time: 1830.3672s\n",
      "\titers: 200, epoch: 1 | loss: 0.1385796\n",
      "\tspeed: 0.0813s/iter; left time: 1787.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1434565 Vali Loss: 0.1476240 Test Loss: 0.1734360\n",
      "Validation loss decreased (inf --> 0.147624).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1124867\n",
      "\tspeed: 0.1419s/iter; left time: 3105.6768s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091222\n",
      "\tspeed: 0.0811s/iter; left time: 1765.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.1151475 Vali Loss: 0.1221997 Test Loss: 0.1450011\n",
      "Validation loss decreased (0.147624 --> 0.122200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1074508\n",
      "\tspeed: 0.1404s/iter; left time: 3041.6527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1105702\n",
      "\tspeed: 0.0811s/iter; left time: 1748.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.1062980 Vali Loss: 0.1204826 Test Loss: 0.1468059\n",
      "Validation loss decreased (0.122200 --> 0.120483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1053387\n",
      "\tspeed: 0.1405s/iter; left time: 3011.8811s\n",
      "\titers: 200, epoch: 4 | loss: 0.1039608\n",
      "\tspeed: 0.0811s/iter; left time: 1730.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.26s\n",
      "Steps: 222 | Train Loss: 0.1037557 Vali Loss: 0.1203048 Test Loss: 0.1477481\n",
      "Validation loss decreased (0.120483 --> 0.120305).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036354\n",
      "\tspeed: 0.1408s/iter; left time: 2987.0007s\n",
      "\titers: 200, epoch: 5 | loss: 0.0983951\n",
      "\tspeed: 0.0811s/iter; left time: 1712.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.1015428 Vali Loss: 0.1195792 Test Loss: 0.1480534\n",
      "Validation loss decreased (0.120305 --> 0.119579).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994660\n",
      "\tspeed: 0.1418s/iter; left time: 2976.3285s\n",
      "\titers: 200, epoch: 6 | loss: 0.0961423\n",
      "\tspeed: 0.0814s/iter; left time: 1700.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0993276 Vali Loss: 0.1202111 Test Loss: 0.1496725\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958781\n",
      "\tspeed: 0.1395s/iter; left time: 2897.0162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959541\n",
      "\tspeed: 0.0811s/iter; left time: 1675.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0972312 Vali Loss: 0.1203471 Test Loss: 0.1500919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0944401\n",
      "\tspeed: 0.1396s/iter; left time: 2867.4243s\n",
      "\titers: 200, epoch: 8 | loss: 0.0966303\n",
      "\tspeed: 0.0811s/iter; left time: 1658.0043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 222 | Train Loss: 0.0954563 Vali Loss: 0.1199050 Test Loss: 0.1506354\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0943413\n",
      "\tspeed: 0.1409s/iter; left time: 2863.6914s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965194\n",
      "\tspeed: 0.0815s/iter; left time: 1647.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 222 | Train Loss: 0.0937926 Vali Loss: 0.1209276 Test Loss: 0.1508951\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920365\n",
      "\tspeed: 0.1400s/iter; left time: 2815.2283s\n",
      "\titers: 200, epoch: 10 | loss: 0.0944835\n",
      "\tspeed: 0.0811s/iter; left time: 1621.6555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0923184 Vali Loss: 0.1216158 Test Loss: 0.1523672\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0890176\n",
      "\tspeed: 0.1395s/iter; left time: 2772.7185s\n",
      "\titers: 200, epoch: 11 | loss: 0.0903773\n",
      "\tspeed: 0.0813s/iter; left time: 1607.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 222 | Train Loss: 0.0910789 Vali Loss: 0.1217306 Test Loss: 0.1521261\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0872232\n",
      "\tspeed: 0.1396s/iter; left time: 2744.6620s\n",
      "\titers: 200, epoch: 12 | loss: 0.0923500\n",
      "\tspeed: 0.0811s/iter; left time: 1586.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 222 | Train Loss: 0.0899829 Vali Loss: 0.1231703 Test Loss: 0.1537110\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0872186\n",
      "\tspeed: 0.1397s/iter; left time: 2714.4259s\n",
      "\titers: 200, epoch: 13 | loss: 0.0887902\n",
      "\tspeed: 0.0811s/iter; left time: 1567.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 222 | Train Loss: 0.0890337 Vali Loss: 0.1235894 Test Loss: 0.1542339\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0884640\n",
      "\tspeed: 0.1395s/iter; left time: 2681.4181s\n",
      "\titers: 200, epoch: 14 | loss: 0.0870688\n",
      "\tspeed: 0.0810s/iter; left time: 1549.1268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 222 | Train Loss: 0.0882041 Vali Loss: 0.1238865 Test Loss: 0.1543076\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0922166\n",
      "\tspeed: 0.1408s/iter; left time: 2674.9680s\n",
      "\titers: 200, epoch: 15 | loss: 0.0888370\n",
      "\tspeed: 0.0813s/iter; left time: 1535.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 222 | Train Loss: 0.0873947 Vali Loss: 0.1243513 Test Loss: 0.1549856\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04569704458117485, rmse:0.21376867592334747, mae:0.1480533480644226, rse:0.7411666512489319\n",
      "Intermediate time for GB and pred_len 168: 00h:10m:36.44s\n",
      "Intermediate time for GB: 00h:54m:35.29s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1526842\n",
      "\tspeed: 0.0609s/iter; left time: 1358.8946s\n",
      "\titers: 200, epoch: 1 | loss: 0.1366305\n",
      "\tspeed: 0.0341s/iter; left time: 757.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.1550454 Vali Loss: 0.1393994 Test Loss: 0.1681718\n",
      "Validation loss decreased (inf --> 0.139399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0732484\n",
      "\tspeed: 0.0644s/iter; left time: 1422.6868s\n",
      "\titers: 200, epoch: 2 | loss: 0.0723599\n",
      "\tspeed: 0.0342s/iter; left time: 751.8843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0805116 Vali Loss: 0.0647224 Test Loss: 0.0717992\n",
      "Validation loss decreased (0.139399 --> 0.064722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0670712\n",
      "\tspeed: 0.0665s/iter; left time: 1454.2014s\n",
      "\titers: 200, epoch: 3 | loss: 0.0631713\n",
      "\tspeed: 0.0341s/iter; left time: 742.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0640164 Vali Loss: 0.0604511 Test Loss: 0.0675387\n",
      "Validation loss decreased (0.064722 --> 0.060451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615953\n",
      "\tspeed: 0.0642s/iter; left time: 1387.7785s\n",
      "\titers: 200, epoch: 4 | loss: 0.0594863\n",
      "\tspeed: 0.0341s/iter; left time: 734.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0607313 Vali Loss: 0.0585351 Test Loss: 0.0652289\n",
      "Validation loss decreased (0.060451 --> 0.058535).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0582284\n",
      "\tspeed: 0.0640s/iter; left time: 1370.6194s\n",
      "\titers: 200, epoch: 5 | loss: 0.0548869\n",
      "\tspeed: 0.0344s/iter; left time: 733.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0586365 Vali Loss: 0.0571023 Test Loss: 0.0640453\n",
      "Validation loss decreased (0.058535 --> 0.057102).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0568549\n",
      "\tspeed: 0.0643s/iter; left time: 1361.1592s\n",
      "\titers: 200, epoch: 6 | loss: 0.0545233\n",
      "\tspeed: 0.0339s/iter; left time: 714.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0572533 Vali Loss: 0.0562853 Test Loss: 0.0630265\n",
      "Validation loss decreased (0.057102 --> 0.056285).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588305\n",
      "\tspeed: 0.0646s/iter; left time: 1353.0178s\n",
      "\titers: 200, epoch: 7 | loss: 0.0523065\n",
      "\tspeed: 0.0346s/iter; left time: 721.7980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0561701 Vali Loss: 0.0557691 Test Loss: 0.0625740\n",
      "Validation loss decreased (0.056285 --> 0.055769).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549896\n",
      "\tspeed: 0.0646s/iter; left time: 1340.1382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590127\n",
      "\tspeed: 0.0340s/iter; left time: 702.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0555243 Vali Loss: 0.0552860 Test Loss: 0.0622382\n",
      "Validation loss decreased (0.055769 --> 0.055286).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538663\n",
      "\tspeed: 0.0661s/iter; left time: 1355.4103s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581174\n",
      "\tspeed: 0.0357s/iter; left time: 728.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0549856 Vali Loss: 0.0547778 Test Loss: 0.0615789\n",
      "Validation loss decreased (0.055286 --> 0.054778).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0544842\n",
      "\tspeed: 0.0644s/iter; left time: 1305.6717s\n",
      "\titers: 200, epoch: 10 | loss: 0.0509822\n",
      "\tspeed: 0.0341s/iter; left time: 687.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0545583 Vali Loss: 0.0547986 Test Loss: 0.0614929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541769\n",
      "\tspeed: 0.0625s/iter; left time: 1253.8060s\n",
      "\titers: 200, epoch: 11 | loss: 0.0549371\n",
      "\tspeed: 0.0340s/iter; left time: 677.6949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0541390 Vali Loss: 0.0542580 Test Loss: 0.0609762\n",
      "Validation loss decreased (0.054778 --> 0.054258).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0538365\n",
      "\tspeed: 0.0638s/iter; left time: 1265.0536s\n",
      "\titers: 200, epoch: 12 | loss: 0.0529875\n",
      "\tspeed: 0.0344s/iter; left time: 678.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0538779 Vali Loss: 0.0541497 Test Loss: 0.0608541\n",
      "Validation loss decreased (0.054258 --> 0.054150).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0556539\n",
      "\tspeed: 0.0631s/iter; left time: 1238.1737s\n",
      "\titers: 200, epoch: 13 | loss: 0.0526646\n",
      "\tspeed: 0.0344s/iter; left time: 670.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0536023 Vali Loss: 0.0540321 Test Loss: 0.0606161\n",
      "Validation loss decreased (0.054150 --> 0.054032).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0543625\n",
      "\tspeed: 0.0645s/iter; left time: 1250.2886s\n",
      "\titers: 200, epoch: 14 | loss: 0.0530023\n",
      "\tspeed: 0.0348s/iter; left time: 670.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0533630 Vali Loss: 0.0541184 Test Loss: 0.0608187\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0521512\n",
      "\tspeed: 0.0630s/iter; left time: 1208.2481s\n",
      "\titers: 200, epoch: 15 | loss: 0.0521281\n",
      "\tspeed: 0.0344s/iter; left time: 656.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0531000 Vali Loss: 0.0539720 Test Loss: 0.0605283\n",
      "Validation loss decreased (0.054032 --> 0.053972).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0509178\n",
      "\tspeed: 0.0627s/iter; left time: 1187.9921s\n",
      "\titers: 200, epoch: 16 | loss: 0.0512274\n",
      "\tspeed: 0.0337s/iter; left time: 635.2819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0529989 Vali Loss: 0.0536041 Test Loss: 0.0602776\n",
      "Validation loss decreased (0.053972 --> 0.053604).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0513468\n",
      "\tspeed: 0.0627s/iter; left time: 1173.1582s\n",
      "\titers: 200, epoch: 17 | loss: 0.0483066\n",
      "\tspeed: 0.0340s/iter; left time: 632.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0528339 Vali Loss: 0.0536399 Test Loss: 0.0601474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0508105\n",
      "\tspeed: 0.0629s/iter; left time: 1163.3793s\n",
      "\titers: 200, epoch: 18 | loss: 0.0472548\n",
      "\tspeed: 0.0337s/iter; left time: 620.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0526830 Vali Loss: 0.0535131 Test Loss: 0.0600573\n",
      "Validation loss decreased (0.053604 --> 0.053513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543427\n",
      "\tspeed: 0.0631s/iter; left time: 1151.9394s\n",
      "\titers: 200, epoch: 19 | loss: 0.0539975\n",
      "\tspeed: 0.0339s/iter; left time: 615.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0526239 Vali Loss: 0.0534467 Test Loss: 0.0600467\n",
      "Validation loss decreased (0.053513 --> 0.053447).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0512956\n",
      "\tspeed: 0.0633s/iter; left time: 1142.3240s\n",
      "\titers: 200, epoch: 20 | loss: 0.0518979\n",
      "\tspeed: 0.0338s/iter; left time: 605.6957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0524580 Vali Loss: 0.0534504 Test Loss: 0.0601290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0516894\n",
      "\tspeed: 0.0625s/iter; left time: 1114.1185s\n",
      "\titers: 200, epoch: 21 | loss: 0.0514001\n",
      "\tspeed: 0.0340s/iter; left time: 601.7961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0533231 Test Loss: 0.0599976\n",
      "Validation loss decreased (0.053447 --> 0.053323).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0483420\n",
      "\tspeed: 0.0626s/iter; left time: 1102.2952s\n",
      "\titers: 200, epoch: 22 | loss: 0.0524221\n",
      "\tspeed: 0.0337s/iter; left time: 590.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0522725 Vali Loss: 0.0532108 Test Loss: 0.0598633\n",
      "Validation loss decreased (0.053323 --> 0.053211).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0503389\n",
      "\tspeed: 0.0628s/iter; left time: 1090.2020s\n",
      "\titers: 200, epoch: 23 | loss: 0.0539414\n",
      "\tspeed: 0.0338s/iter; left time: 583.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0522263 Vali Loss: 0.0532671 Test Loss: 0.0599022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0542046\n",
      "\tspeed: 0.0624s/iter; left time: 1070.4008s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510984\n",
      "\tspeed: 0.0338s/iter; left time: 575.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0521891 Vali Loss: 0.0531939 Test Loss: 0.0597542\n",
      "Validation loss decreased (0.053211 --> 0.053194).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0514270\n",
      "\tspeed: 0.0627s/iter; left time: 1060.7629s\n",
      "\titers: 200, epoch: 25 | loss: 0.0550747\n",
      "\tspeed: 0.0337s/iter; left time: 567.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0520553 Vali Loss: 0.0530766 Test Loss: 0.0597279\n",
      "Validation loss decreased (0.053194 --> 0.053077).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0486141\n",
      "\tspeed: 0.0628s/iter; left time: 1048.8454s\n",
      "\titers: 200, epoch: 26 | loss: 0.0538085\n",
      "\tspeed: 0.0338s/iter; left time: 560.6971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0519923 Vali Loss: 0.0531875 Test Loss: 0.0597662\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0524277\n",
      "\tspeed: 0.0620s/iter; left time: 1021.1319s\n",
      "\titers: 200, epoch: 27 | loss: 0.0521245\n",
      "\tspeed: 0.0338s/iter; left time: 553.4254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0520323 Vali Loss: 0.0530715 Test Loss: 0.0596598\n",
      "Validation loss decreased (0.053077 --> 0.053071).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0528489\n",
      "\tspeed: 0.0631s/iter; left time: 1025.7348s\n",
      "\titers: 200, epoch: 28 | loss: 0.0528272\n",
      "\tspeed: 0.0338s/iter; left time: 546.2785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0519045 Vali Loss: 0.0530310 Test Loss: 0.0596944\n",
      "Validation loss decreased (0.053071 --> 0.053031).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0494530\n",
      "\tspeed: 0.0629s/iter; left time: 1007.4482s\n",
      "\titers: 200, epoch: 29 | loss: 0.0549773\n",
      "\tspeed: 0.0337s/iter; left time: 537.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0518919 Vali Loss: 0.0531214 Test Loss: 0.0597658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509516\n",
      "\tspeed: 0.0626s/iter; left time: 990.1646s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541899\n",
      "\tspeed: 0.0339s/iter; left time: 531.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0518665 Vali Loss: 0.0530275 Test Loss: 0.0596586\n",
      "Validation loss decreased (0.053031 --> 0.053028).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0517120\n",
      "\tspeed: 0.0628s/iter; left time: 978.0485s\n",
      "\titers: 200, epoch: 31 | loss: 0.0504429\n",
      "\tspeed: 0.0337s/iter; left time: 521.0384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0518409 Vali Loss: 0.0530472 Test Loss: 0.0595775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0496667\n",
      "\tspeed: 0.0625s/iter; left time: 960.1056s\n",
      "\titers: 200, epoch: 32 | loss: 0.0514431\n",
      "\tspeed: 0.0342s/iter; left time: 521.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0518175 Vali Loss: 0.0530794 Test Loss: 0.0596468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0489944\n",
      "\tspeed: 0.0622s/iter; left time: 941.2344s\n",
      "\titers: 200, epoch: 33 | loss: 0.0532939\n",
      "\tspeed: 0.0338s/iter; left time: 508.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0517973 Vali Loss: 0.0530503 Test Loss: 0.0596521\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0528417\n",
      "\tspeed: 0.0626s/iter; left time: 932.9459s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519611\n",
      "\tspeed: 0.0338s/iter; left time: 500.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0517021 Vali Loss: 0.0530652 Test Loss: 0.0594816\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0530752\n",
      "\tspeed: 0.0628s/iter; left time: 922.1408s\n",
      "\titers: 200, epoch: 35 | loss: 0.0518166\n",
      "\tspeed: 0.0339s/iter; left time: 494.1251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0517347 Vali Loss: 0.0528620 Test Loss: 0.0595123\n",
      "Validation loss decreased (0.053028 --> 0.052862).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0506464\n",
      "\tspeed: 0.0645s/iter; left time: 932.4568s\n",
      "\titers: 200, epoch: 36 | loss: 0.0517927\n",
      "\tspeed: 0.0338s/iter; left time: 484.9614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516731 Vali Loss: 0.0529967 Test Loss: 0.0596204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0519233\n",
      "\tspeed: 0.0623s/iter; left time: 887.4264s\n",
      "\titers: 200, epoch: 37 | loss: 0.0506047\n",
      "\tspeed: 0.0340s/iter; left time: 480.4417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0516810 Vali Loss: 0.0530068 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0507490\n",
      "\tspeed: 0.0625s/iter; left time: 876.1894s\n",
      "\titers: 200, epoch: 38 | loss: 0.0562936\n",
      "\tspeed: 0.0340s/iter; left time: 472.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516737 Vali Loss: 0.0529319 Test Loss: 0.0594970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0492359\n",
      "\tspeed: 0.0624s/iter; left time: 860.4935s\n",
      "\titers: 200, epoch: 39 | loss: 0.0538159\n",
      "\tspeed: 0.0338s/iter; left time: 462.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516829 Vali Loss: 0.0529696 Test Loss: 0.0594831\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0513327\n",
      "\tspeed: 0.0620s/iter; left time: 841.4094s\n",
      "\titers: 200, epoch: 40 | loss: 0.0514433\n",
      "\tspeed: 0.0338s/iter; left time: 455.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0516562 Vali Loss: 0.0530150 Test Loss: 0.0596243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0518598\n",
      "\tspeed: 0.0629s/iter; left time: 839.1156s\n",
      "\titers: 200, epoch: 41 | loss: 0.0497989\n",
      "\tspeed: 0.0340s/iter; left time: 450.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0516688 Vali Loss: 0.0528681 Test Loss: 0.0594650\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0497980\n",
      "\tspeed: 0.0624s/iter; left time: 818.5636s\n",
      "\titers: 200, epoch: 42 | loss: 0.0535568\n",
      "\tspeed: 0.0343s/iter; left time: 446.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0516297 Vali Loss: 0.0529409 Test Loss: 0.0594555\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0522472\n",
      "\tspeed: 0.0625s/iter; left time: 805.6177s\n",
      "\titers: 200, epoch: 43 | loss: 0.0489027\n",
      "\tspeed: 0.0339s/iter; left time: 433.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516606 Vali Loss: 0.0529695 Test Loss: 0.0595177\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0520200\n",
      "\tspeed: 0.0623s/iter; left time: 789.8724s\n",
      "\titers: 200, epoch: 44 | loss: 0.0508248\n",
      "\tspeed: 0.0339s/iter; left time: 426.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0515849 Vali Loss: 0.0529528 Test Loss: 0.0595244\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0524924\n",
      "\tspeed: 0.0621s/iter; left time: 773.0018s\n",
      "\titers: 200, epoch: 45 | loss: 0.0509926\n",
      "\tspeed: 0.0337s/iter; left time: 415.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0515887 Vali Loss: 0.0530027 Test Loss: 0.0595490\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009823016822338104, rmse:0.09911113232374191, mae:0.05951228737831116, rse:0.2916720509529114\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1579360\n",
      "\tspeed: 0.0362s/iter; left time: 806.2461s\n",
      "\titers: 200, epoch: 1 | loss: 0.1345574\n",
      "\tspeed: 0.0341s/iter; left time: 756.1026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.1544287 Vali Loss: 0.1378902 Test Loss: 0.1664125\n",
      "Validation loss decreased (inf --> 0.137890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0723953\n",
      "\tspeed: 0.0643s/iter; left time: 1420.1447s\n",
      "\titers: 200, epoch: 2 | loss: 0.0673680\n",
      "\tspeed: 0.0338s/iter; left time: 741.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0807752 Vali Loss: 0.0640944 Test Loss: 0.0714371\n",
      "Validation loss decreased (0.137890 --> 0.064094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0664814\n",
      "\tspeed: 0.0635s/iter; left time: 1388.3982s\n",
      "\titers: 200, epoch: 3 | loss: 0.0602823\n",
      "\tspeed: 0.0342s/iter; left time: 743.4186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0644568 Vali Loss: 0.0613151 Test Loss: 0.0682127\n",
      "Validation loss decreased (0.064094 --> 0.061315).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619137\n",
      "\tspeed: 0.0636s/iter; left time: 1376.4854s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629501\n",
      "\tspeed: 0.0343s/iter; left time: 739.5180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0613793 Vali Loss: 0.0588372 Test Loss: 0.0659621\n",
      "Validation loss decreased (0.061315 --> 0.058837).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0599205\n",
      "\tspeed: 0.0638s/iter; left time: 1365.4802s\n",
      "\titers: 200, epoch: 5 | loss: 0.0566143\n",
      "\tspeed: 0.0340s/iter; left time: 724.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0592500 Vali Loss: 0.0577281 Test Loss: 0.0648115\n",
      "Validation loss decreased (0.058837 --> 0.057728).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0587412\n",
      "\tspeed: 0.0641s/iter; left time: 1357.6046s\n",
      "\titers: 200, epoch: 6 | loss: 0.0555555\n",
      "\tspeed: 0.0344s/iter; left time: 724.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0577187 Vali Loss: 0.0565377 Test Loss: 0.0634899\n",
      "Validation loss decreased (0.057728 --> 0.056538).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582398\n",
      "\tspeed: 0.0631s/iter; left time: 1322.1493s\n",
      "\titers: 200, epoch: 7 | loss: 0.0569732\n",
      "\tspeed: 0.0343s/iter; left time: 714.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0565804 Vali Loss: 0.0560253 Test Loss: 0.0630894\n",
      "Validation loss decreased (0.056538 --> 0.056025).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0576674\n",
      "\tspeed: 0.0637s/iter; left time: 1321.0784s\n",
      "\titers: 200, epoch: 8 | loss: 0.0565004\n",
      "\tspeed: 0.0342s/iter; left time: 704.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0557787 Vali Loss: 0.0554661 Test Loss: 0.0624663\n",
      "Validation loss decreased (0.056025 --> 0.055466).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0545671\n",
      "\tspeed: 0.0638s/iter; left time: 1307.7506s\n",
      "\titers: 200, epoch: 9 | loss: 0.0577309\n",
      "\tspeed: 0.0345s/iter; left time: 703.1860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0551741 Vali Loss: 0.0550627 Test Loss: 0.0620055\n",
      "Validation loss decreased (0.055466 --> 0.055063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0536375\n",
      "\tspeed: 0.0641s/iter; left time: 1300.5337s\n",
      "\titers: 200, epoch: 10 | loss: 0.0555455\n",
      "\tspeed: 0.0344s/iter; left time: 693.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0547537 Vali Loss: 0.0550868 Test Loss: 0.0618774\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0518436\n",
      "\tspeed: 0.0626s/iter; left time: 1256.4904s\n",
      "\titers: 200, epoch: 11 | loss: 0.0547084\n",
      "\tspeed: 0.0338s/iter; left time: 674.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0543565 Vali Loss: 0.0546177 Test Loss: 0.0611843\n",
      "Validation loss decreased (0.055063 --> 0.054618).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0567422\n",
      "\tspeed: 0.0640s/iter; left time: 1268.7299s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523581\n",
      "\tspeed: 0.0338s/iter; left time: 667.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.83s\n",
      "Steps: 224 | Train Loss: 0.0540275 Vali Loss: 0.0544829 Test Loss: 0.0609822\n",
      "Validation loss decreased (0.054618 --> 0.054483).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0552673\n",
      "\tspeed: 0.0639s/iter; left time: 1252.5990s\n",
      "\titers: 200, epoch: 13 | loss: 0.0510562\n",
      "\tspeed: 0.0341s/iter; left time: 665.4395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0537494 Vali Loss: 0.0542448 Test Loss: 0.0610533\n",
      "Validation loss decreased (0.054483 --> 0.054245).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0562548\n",
      "\tspeed: 0.0634s/iter; left time: 1228.8678s\n",
      "\titers: 200, epoch: 14 | loss: 0.0558280\n",
      "\tspeed: 0.0339s/iter; left time: 654.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0534659 Vali Loss: 0.0541800 Test Loss: 0.0609532\n",
      "Validation loss decreased (0.054245 --> 0.054180).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0524575\n",
      "\tspeed: 0.0637s/iter; left time: 1221.5597s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552186\n",
      "\tspeed: 0.0342s/iter; left time: 651.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0533038 Vali Loss: 0.0540752 Test Loss: 0.0606174\n",
      "Validation loss decreased (0.054180 --> 0.054075).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0530639\n",
      "\tspeed: 0.0639s/iter; left time: 1210.1429s\n",
      "\titers: 200, epoch: 16 | loss: 0.0518307\n",
      "\tspeed: 0.0340s/iter; left time: 639.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0531068 Vali Loss: 0.0539237 Test Loss: 0.0606197\n",
      "Validation loss decreased (0.054075 --> 0.053924).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0549129\n",
      "\tspeed: 0.0640s/iter; left time: 1198.4220s\n",
      "\titers: 200, epoch: 17 | loss: 0.0486911\n",
      "\tspeed: 0.0339s/iter; left time: 630.6953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0529943 Vali Loss: 0.0538352 Test Loss: 0.0604584\n",
      "Validation loss decreased (0.053924 --> 0.053835).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0533815\n",
      "\tspeed: 0.0632s/iter; left time: 1168.3594s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563068\n",
      "\tspeed: 0.0339s/iter; left time: 624.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0528632 Vali Loss: 0.0536740 Test Loss: 0.0603638\n",
      "Validation loss decreased (0.053835 --> 0.053674).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0529857\n",
      "\tspeed: 0.0641s/iter; left time: 1171.2782s\n",
      "\titers: 200, epoch: 19 | loss: 0.0518051\n",
      "\tspeed: 0.0361s/iter; left time: 655.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.0526865 Vali Loss: 0.0534223 Test Loss: 0.0601238\n",
      "Validation loss decreased (0.053674 --> 0.053422).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0509609\n",
      "\tspeed: 0.0648s/iter; left time: 1169.1304s\n",
      "\titers: 200, epoch: 20 | loss: 0.0505578\n",
      "\tspeed: 0.0342s/iter; left time: 613.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0526346 Vali Loss: 0.0535342 Test Loss: 0.0601085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0515755\n",
      "\tspeed: 0.0631s/iter; left time: 1125.0728s\n",
      "\titers: 200, epoch: 21 | loss: 0.0507104\n",
      "\tspeed: 0.0336s/iter; left time: 595.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0525259 Vali Loss: 0.0534651 Test Loss: 0.0600710\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0511437\n",
      "\tspeed: 0.0626s/iter; left time: 1102.4177s\n",
      "\titers: 200, epoch: 22 | loss: 0.0498561\n",
      "\tspeed: 0.0337s/iter; left time: 588.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0524205 Vali Loss: 0.0534762 Test Loss: 0.0601843\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535026\n",
      "\tspeed: 0.0636s/iter; left time: 1104.5741s\n",
      "\titers: 200, epoch: 23 | loss: 0.0500406\n",
      "\tspeed: 0.0343s/iter; left time: 592.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0523597 Vali Loss: 0.0534131 Test Loss: 0.0600998\n",
      "Validation loss decreased (0.053422 --> 0.053413).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0492497\n",
      "\tspeed: 0.0639s/iter; left time: 1096.5966s\n",
      "\titers: 200, epoch: 24 | loss: 0.0506229\n",
      "\tspeed: 0.0339s/iter; left time: 578.1455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0522823 Vali Loss: 0.0532963 Test Loss: 0.0599198\n",
      "Validation loss decreased (0.053413 --> 0.053296).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0521318\n",
      "\tspeed: 0.0655s/iter; left time: 1108.0073s\n",
      "\titers: 200, epoch: 25 | loss: 0.0511510\n",
      "\tspeed: 0.0344s/iter; left time: 578.6880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0522033 Vali Loss: 0.0533299 Test Loss: 0.0599659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0504086\n",
      "\tspeed: 0.0631s/iter; left time: 1053.2769s\n",
      "\titers: 200, epoch: 26 | loss: 0.0505698\n",
      "\tspeed: 0.0338s/iter; left time: 560.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0521587 Vali Loss: 0.0533623 Test Loss: 0.0599633\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0529970\n",
      "\tspeed: 0.0633s/iter; left time: 1042.1823s\n",
      "\titers: 200, epoch: 27 | loss: 0.0493081\n",
      "\tspeed: 0.0339s/iter; left time: 555.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 224 | Train Loss: 0.0521429 Vali Loss: 0.0534271 Test Loss: 0.0600620\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0561010\n",
      "\tspeed: 0.0628s/iter; left time: 1019.8882s\n",
      "\titers: 200, epoch: 28 | loss: 0.0526673\n",
      "\tspeed: 0.0338s/iter; left time: 546.3516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0520879 Vali Loss: 0.0532309 Test Loss: 0.0596975\n",
      "Validation loss decreased (0.053296 --> 0.053231).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0538653\n",
      "\tspeed: 0.0641s/iter; left time: 1027.4060s\n",
      "\titers: 200, epoch: 29 | loss: 0.0507462\n",
      "\tspeed: 0.0343s/iter; left time: 546.1889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0520182 Vali Loss: 0.0532914 Test Loss: 0.0598624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0564779\n",
      "\tspeed: 0.0626s/iter; left time: 989.2602s\n",
      "\titers: 200, epoch: 30 | loss: 0.0513206\n",
      "\tspeed: 0.0338s/iter; left time: 531.3166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0519411 Vali Loss: 0.0531523 Test Loss: 0.0597022\n",
      "Validation loss decreased (0.053231 --> 0.053152).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0504823\n",
      "\tspeed: 0.0635s/iter; left time: 989.2336s\n",
      "\titers: 200, epoch: 31 | loss: 0.0540285\n",
      "\tspeed: 0.0338s/iter; left time: 522.4879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 224 | Train Loss: 0.0519207 Vali Loss: 0.0531699 Test Loss: 0.0596743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0498894\n",
      "\tspeed: 0.0639s/iter; left time: 981.5846s\n",
      "\titers: 200, epoch: 32 | loss: 0.0540251\n",
      "\tspeed: 0.0350s/iter; left time: 534.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0519015 Vali Loss: 0.0531963 Test Loss: 0.0597262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0543305\n",
      "\tspeed: 0.0640s/iter; left time: 969.1034s\n",
      "\titers: 200, epoch: 33 | loss: 0.0495824\n",
      "\tspeed: 0.0344s/iter; left time: 517.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0518915 Vali Loss: 0.0531901 Test Loss: 0.0596950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0508410\n",
      "\tspeed: 0.0630s/iter; left time: 939.0433s\n",
      "\titers: 200, epoch: 34 | loss: 0.0491989\n",
      "\tspeed: 0.0337s/iter; left time: 498.7927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.77s\n",
      "Steps: 224 | Train Loss: 0.0518669 Vali Loss: 0.0531966 Test Loss: 0.0597255\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0490082\n",
      "\tspeed: 0.0639s/iter; left time: 939.1057s\n",
      "\titers: 200, epoch: 35 | loss: 0.0526008\n",
      "\tspeed: 0.0341s/iter; left time: 497.2151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0518020 Vali Loss: 0.0531861 Test Loss: 0.0596925\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0554945\n",
      "\tspeed: 0.0623s/iter; left time: 901.4166s\n",
      "\titers: 200, epoch: 36 | loss: 0.0519463\n",
      "\tspeed: 0.0338s/iter; left time: 485.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0518643 Vali Loss: 0.0531078 Test Loss: 0.0596932\n",
      "Validation loss decreased (0.053152 --> 0.053108).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0496504\n",
      "\tspeed: 0.0652s/iter; left time: 928.4305s\n",
      "\titers: 200, epoch: 37 | loss: 0.0498719\n",
      "\tspeed: 0.0340s/iter; left time: 480.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0518462 Vali Loss: 0.0531845 Test Loss: 0.0596469\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0510170\n",
      "\tspeed: 0.0629s/iter; left time: 880.7925s\n",
      "\titers: 200, epoch: 38 | loss: 0.0542504\n",
      "\tspeed: 0.0338s/iter; left time: 470.3769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0518217 Vali Loss: 0.0531203 Test Loss: 0.0596973\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0488454\n",
      "\tspeed: 0.0628s/iter; left time: 865.2811s\n",
      "\titers: 200, epoch: 39 | loss: 0.0506440\n",
      "\tspeed: 0.0340s/iter; left time: 465.7097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0517673 Vali Loss: 0.0530957 Test Loss: 0.0596440\n",
      "Validation loss decreased (0.053108 --> 0.053096).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0500557\n",
      "\tspeed: 0.0645s/iter; left time: 874.3162s\n",
      "\titers: 200, epoch: 40 | loss: 0.0513093\n",
      "\tspeed: 0.0343s/iter; left time: 461.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0517291 Vali Loss: 0.0530914 Test Loss: 0.0595172\n",
      "Validation loss decreased (0.053096 --> 0.053091).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0547261\n",
      "\tspeed: 0.0645s/iter; left time: 859.9562s\n",
      "\titers: 200, epoch: 41 | loss: 0.0481549\n",
      "\tspeed: 0.0336s/iter; left time: 445.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0517457 Vali Loss: 0.0530916 Test Loss: 0.0596419\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0524280\n",
      "\tspeed: 0.0636s/iter; left time: 834.1583s\n",
      "\titers: 200, epoch: 42 | loss: 0.0527511\n",
      "\tspeed: 0.0340s/iter; left time: 442.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 224 | Train Loss: 0.0517541 Vali Loss: 0.0532012 Test Loss: 0.0597727\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0527208\n",
      "\tspeed: 0.0632s/iter; left time: 815.1594s\n",
      "\titers: 200, epoch: 43 | loss: 0.0518980\n",
      "\tspeed: 0.0339s/iter; left time: 433.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0517267 Vali Loss: 0.0529711 Test Loss: 0.0595133\n",
      "Validation loss decreased (0.053091 --> 0.052971).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0536714\n",
      "\tspeed: 0.0631s/iter; left time: 798.7845s\n",
      "\titers: 200, epoch: 44 | loss: 0.0551635\n",
      "\tspeed: 0.0339s/iter; left time: 425.6511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.80s\n",
      "Steps: 224 | Train Loss: 0.0517666 Vali Loss: 0.0530981 Test Loss: 0.0596632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0518254\n",
      "\tspeed: 0.0627s/iter; left time: 780.7698s\n",
      "\titers: 200, epoch: 45 | loss: 0.0512678\n",
      "\tspeed: 0.0338s/iter; left time: 417.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516751 Vali Loss: 0.0531732 Test Loss: 0.0596597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0521856\n",
      "\tspeed: 0.0633s/iter; left time: 773.5642s\n",
      "\titers: 200, epoch: 46 | loss: 0.0487361\n",
      "\tspeed: 0.0343s/iter; left time: 415.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0516208 Vali Loss: 0.0530561 Test Loss: 0.0595802\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0530450\n",
      "\tspeed: 0.0633s/iter; left time: 759.7925s\n",
      "\titers: 200, epoch: 47 | loss: 0.0445639\n",
      "\tspeed: 0.0342s/iter; left time: 406.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0516959 Vali Loss: 0.0531059 Test Loss: 0.0596224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0539990\n",
      "\tspeed: 0.0626s/iter; left time: 737.1421s\n",
      "\titers: 200, epoch: 48 | loss: 0.0513229\n",
      "\tspeed: 0.0338s/iter; left time: 394.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0516967 Vali Loss: 0.0530909 Test Loss: 0.0596255\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0525027\n",
      "\tspeed: 0.0627s/iter; left time: 724.6279s\n",
      "\titers: 200, epoch: 49 | loss: 0.0530085\n",
      "\tspeed: 0.0339s/iter; left time: 387.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0516743 Vali Loss: 0.0531389 Test Loss: 0.0596946\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0477419\n",
      "\tspeed: 0.0629s/iter; left time: 712.5456s\n",
      "\titers: 200, epoch: 50 | loss: 0.0513889\n",
      "\tspeed: 0.0344s/iter; left time: 386.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0516918 Vali Loss: 0.0530067 Test Loss: 0.0595521\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0530295\n",
      "\tspeed: 0.0628s/iter; left time: 697.4549s\n",
      "\titers: 200, epoch: 51 | loss: 0.0510417\n",
      "\tspeed: 0.0348s/iter; left time: 383.3383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0516617 Vali Loss: 0.0531040 Test Loss: 0.0595510\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517732\n",
      "\tspeed: 0.0634s/iter; left time: 689.7686s\n",
      "\titers: 200, epoch: 52 | loss: 0.0523332\n",
      "\tspeed: 0.0343s/iter; left time: 369.3020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0517148 Vali Loss: 0.0530957 Test Loss: 0.0596316\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0531154\n",
      "\tspeed: 0.0635s/iter; left time: 676.7211s\n",
      "\titers: 200, epoch: 53 | loss: 0.0505686\n",
      "\tspeed: 0.0338s/iter; left time: 356.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 224 | Train Loss: 0.0516867 Vali Loss: 0.0530429 Test Loss: 0.0595754\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00980827771127224, rmse:0.09903674572706223, mae:0.059513285756111145, rse:0.29145318269729614\n",
      "Intermediate time for ES and pred_len 24: 00h:16m:07.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1583152\n",
      "\tspeed: 0.0612s/iter; left time: 1364.4116s\n",
      "\titers: 200, epoch: 1 | loss: 0.1448403\n",
      "\tspeed: 0.0347s/iter; left time: 769.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.1628648 Vali Loss: 0.1497765 Test Loss: 0.1801975\n",
      "Validation loss decreased (inf --> 0.149776).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0921436\n",
      "\tspeed: 0.0656s/iter; left time: 1448.2323s\n",
      "\titers: 200, epoch: 2 | loss: 0.0816166\n",
      "\tspeed: 0.0347s/iter; left time: 763.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0972727 Vali Loss: 0.0838135 Test Loss: 0.0948474\n",
      "Validation loss decreased (0.149776 --> 0.083813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829061\n",
      "\tspeed: 0.0658s/iter; left time: 1437.4137s\n",
      "\titers: 200, epoch: 3 | loss: 0.0841351\n",
      "\tspeed: 0.0345s/iter; left time: 751.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0835706 Vali Loss: 0.0805995 Test Loss: 0.0918064\n",
      "Validation loss decreased (0.083813 --> 0.080599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0807449\n",
      "\tspeed: 0.0665s/iter; left time: 1437.7731s\n",
      "\titers: 200, epoch: 4 | loss: 0.0770914\n",
      "\tspeed: 0.0350s/iter; left time: 753.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0804804 Vali Loss: 0.0785825 Test Loss: 0.0897993\n",
      "Validation loss decreased (0.080599 --> 0.078583).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813333\n",
      "\tspeed: 0.0674s/iter; left time: 1442.3017s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801107\n",
      "\tspeed: 0.0342s/iter; left time: 728.3903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0785711 Vali Loss: 0.0776296 Test Loss: 0.0890472\n",
      "Validation loss decreased (0.078583 --> 0.077630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0758659\n",
      "\tspeed: 0.0673s/iter; left time: 1424.6065s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811755\n",
      "\tspeed: 0.0345s/iter; left time: 727.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0773020 Vali Loss: 0.0770908 Test Loss: 0.0882573\n",
      "Validation loss decreased (0.077630 --> 0.077091).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0749255\n",
      "\tspeed: 0.0656s/iter; left time: 1374.6973s\n",
      "\titers: 200, epoch: 7 | loss: 0.0767308\n",
      "\tspeed: 0.0344s/iter; left time: 717.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0764460 Vali Loss: 0.0769096 Test Loss: 0.0878721\n",
      "Validation loss decreased (0.077091 --> 0.076910).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756682\n",
      "\tspeed: 0.0659s/iter; left time: 1366.1915s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762002\n",
      "\tspeed: 0.0346s/iter; left time: 714.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0758666 Vali Loss: 0.0765788 Test Loss: 0.0876366\n",
      "Validation loss decreased (0.076910 --> 0.076579).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0734542\n",
      "\tspeed: 0.0664s/iter; left time: 1362.4641s\n",
      "\titers: 200, epoch: 9 | loss: 0.0735278\n",
      "\tspeed: 0.0343s/iter; left time: 700.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0753596 Vali Loss: 0.0765925 Test Loss: 0.0876100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0753230\n",
      "\tspeed: 0.0648s/iter; left time: 1315.0359s\n",
      "\titers: 200, epoch: 10 | loss: 0.0781913\n",
      "\tspeed: 0.0352s/iter; left time: 710.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.0748802 Vali Loss: 0.0762593 Test Loss: 0.0871955\n",
      "Validation loss decreased (0.076579 --> 0.076259).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0749062\n",
      "\tspeed: 0.0663s/iter; left time: 1329.3207s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777845\n",
      "\tspeed: 0.0346s/iter; left time: 689.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0745766 Vali Loss: 0.0759519 Test Loss: 0.0867373\n",
      "Validation loss decreased (0.076259 --> 0.075952).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0746499\n",
      "\tspeed: 0.0654s/iter; left time: 1297.0991s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707181\n",
      "\tspeed: 0.0344s/iter; left time: 679.4859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0741716 Vali Loss: 0.0759469 Test Loss: 0.0867018\n",
      "Validation loss decreased (0.075952 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738060\n",
      "\tspeed: 0.0657s/iter; left time: 1288.3863s\n",
      "\titers: 200, epoch: 13 | loss: 0.0733494\n",
      "\tspeed: 0.0344s/iter; left time: 672.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0739369 Vali Loss: 0.0760515 Test Loss: 0.0871067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706884\n",
      "\tspeed: 0.0645s/iter; left time: 1249.8551s\n",
      "\titers: 200, epoch: 14 | loss: 0.0737723\n",
      "\tspeed: 0.0347s/iter; left time: 668.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0736894 Vali Loss: 0.0760189 Test Loss: 0.0869981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755268\n",
      "\tspeed: 0.0648s/iter; left time: 1241.5654s\n",
      "\titers: 200, epoch: 15 | loss: 0.0732484\n",
      "\tspeed: 0.0344s/iter; left time: 656.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0733935 Vali Loss: 0.0757354 Test Loss: 0.0867739\n",
      "Validation loss decreased (0.075947 --> 0.075735).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715213\n",
      "\tspeed: 0.0668s/iter; left time: 1265.6637s\n",
      "\titers: 200, epoch: 16 | loss: 0.0740862\n",
      "\tspeed: 0.0351s/iter; left time: 660.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0732062 Vali Loss: 0.0755924 Test Loss: 0.0867386\n",
      "Validation loss decreased (0.075735 --> 0.075592).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0706640\n",
      "\tspeed: 0.0664s/iter; left time: 1242.7653s\n",
      "\titers: 200, epoch: 17 | loss: 0.0721274\n",
      "\tspeed: 0.0349s/iter; left time: 648.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0730183 Vali Loss: 0.0758885 Test Loss: 0.0868945\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0740165\n",
      "\tspeed: 0.0648s/iter; left time: 1199.0903s\n",
      "\titers: 200, epoch: 18 | loss: 0.0715243\n",
      "\tspeed: 0.0344s/iter; left time: 633.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0728788 Vali Loss: 0.0759454 Test Loss: 0.0867216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0722490\n",
      "\tspeed: 0.0652s/iter; left time: 1191.9980s\n",
      "\titers: 200, epoch: 19 | loss: 0.0700200\n",
      "\tspeed: 0.0364s/iter; left time: 661.1964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0728002 Vali Loss: 0.0754850 Test Loss: 0.0865807\n",
      "Validation loss decreased (0.075592 --> 0.075485).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0729250\n",
      "\tspeed: 0.0663s/iter; left time: 1196.3559s\n",
      "\titers: 200, epoch: 20 | loss: 0.0730267\n",
      "\tspeed: 0.0345s/iter; left time: 619.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0726108 Vali Loss: 0.0756786 Test Loss: 0.0865085\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0720294\n",
      "\tspeed: 0.0651s/iter; left time: 1160.8490s\n",
      "\titers: 200, epoch: 21 | loss: 0.0724624\n",
      "\tspeed: 0.0344s/iter; left time: 610.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0724719 Vali Loss: 0.0756035 Test Loss: 0.0865330\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0717145\n",
      "\tspeed: 0.0653s/iter; left time: 1149.9067s\n",
      "\titers: 200, epoch: 22 | loss: 0.0705282\n",
      "\tspeed: 0.0351s/iter; left time: 614.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0723564 Vali Loss: 0.0755396 Test Loss: 0.0866191\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0681314\n",
      "\tspeed: 0.0642s/iter; left time: 1115.5540s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691133\n",
      "\tspeed: 0.0344s/iter; left time: 595.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0722308 Vali Loss: 0.0756375 Test Loss: 0.0867327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0723156\n",
      "\tspeed: 0.0658s/iter; left time: 1127.7112s\n",
      "\titers: 200, epoch: 24 | loss: 0.0737724\n",
      "\tspeed: 0.0348s/iter; left time: 592.6772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0722322 Vali Loss: 0.0753499 Test Loss: 0.0864964\n",
      "Validation loss decreased (0.075485 --> 0.075350).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0734103\n",
      "\tspeed: 0.0667s/iter; left time: 1128.6299s\n",
      "\titers: 200, epoch: 25 | loss: 0.0698764\n",
      "\tspeed: 0.0343s/iter; left time: 577.0296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0721284 Vali Loss: 0.0755213 Test Loss: 0.0866127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0749125\n",
      "\tspeed: 0.0646s/iter; left time: 1079.6370s\n",
      "\titers: 200, epoch: 26 | loss: 0.0681941\n",
      "\tspeed: 0.0342s/iter; left time: 568.3343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0720451 Vali Loss: 0.0755095 Test Loss: 0.0866491\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0748759\n",
      "\tspeed: 0.0645s/iter; left time: 1063.2388s\n",
      "\titers: 200, epoch: 27 | loss: 0.0692100\n",
      "\tspeed: 0.0343s/iter; left time: 561.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0719510 Vali Loss: 0.0755535 Test Loss: 0.0866617\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0701714\n",
      "\tspeed: 0.0656s/iter; left time: 1066.7963s\n",
      "\titers: 200, epoch: 28 | loss: 0.0740284\n",
      "\tspeed: 0.0366s/iter; left time: 590.5655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0718891 Vali Loss: 0.0755887 Test Loss: 0.0867537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0725884\n",
      "\tspeed: 0.0676s/iter; left time: 1083.1938s\n",
      "\titers: 200, epoch: 29 | loss: 0.0677367\n",
      "\tspeed: 0.0343s/iter; left time: 546.9958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0718561 Vali Loss: 0.0753443 Test Loss: 0.0863624\n",
      "Validation loss decreased (0.075350 --> 0.075344).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0719654\n",
      "\tspeed: 0.0654s/iter; left time: 1033.4551s\n",
      "\titers: 200, epoch: 30 | loss: 0.0742018\n",
      "\tspeed: 0.0342s/iter; left time: 537.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0718349 Vali Loss: 0.0753530 Test Loss: 0.0864401\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0718995\n",
      "\tspeed: 0.0646s/iter; left time: 1006.3866s\n",
      "\titers: 200, epoch: 31 | loss: 0.0726714\n",
      "\tspeed: 0.0341s/iter; left time: 528.4695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0716989 Vali Loss: 0.0755160 Test Loss: 0.0866547\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725034\n",
      "\tspeed: 0.0645s/iter; left time: 991.1844s\n",
      "\titers: 200, epoch: 32 | loss: 0.0703748\n",
      "\tspeed: 0.0347s/iter; left time: 528.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0716934 Vali Loss: 0.0754083 Test Loss: 0.0864467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0715083\n",
      "\tspeed: 0.0648s/iter; left time: 980.6246s\n",
      "\titers: 200, epoch: 33 | loss: 0.0704834\n",
      "\tspeed: 0.0344s/iter; left time: 517.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0716789 Vali Loss: 0.0755103 Test Loss: 0.0866822\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697350\n",
      "\tspeed: 0.0651s/iter; left time: 970.2827s\n",
      "\titers: 200, epoch: 34 | loss: 0.0721267\n",
      "\tspeed: 0.0348s/iter; left time: 515.9512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0716551 Vali Loss: 0.0756040 Test Loss: 0.0869137\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0750437\n",
      "\tspeed: 0.0646s/iter; left time: 948.6420s\n",
      "\titers: 200, epoch: 35 | loss: 0.0722882\n",
      "\tspeed: 0.0343s/iter; left time: 499.5850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0716405 Vali Loss: 0.0754976 Test Loss: 0.0866905\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0708376\n",
      "\tspeed: 0.0649s/iter; left time: 938.6410s\n",
      "\titers: 200, epoch: 36 | loss: 0.0717003\n",
      "\tspeed: 0.0345s/iter; left time: 495.1747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0715762 Vali Loss: 0.0754502 Test Loss: 0.0866363\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0710196\n",
      "\tspeed: 0.0645s/iter; left time: 917.8728s\n",
      "\titers: 200, epoch: 37 | loss: 0.0715786\n",
      "\tspeed: 0.0344s/iter; left time: 485.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0715935 Vali Loss: 0.0754666 Test Loss: 0.0865808\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0731768\n",
      "\tspeed: 0.0647s/iter; left time: 906.7087s\n",
      "\titers: 200, epoch: 38 | loss: 0.0697412\n",
      "\tspeed: 0.0345s/iter; left time: 480.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0715302 Vali Loss: 0.0754760 Test Loss: 0.0866731\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0720512\n",
      "\tspeed: 0.0647s/iter; left time: 892.7129s\n",
      "\titers: 200, epoch: 39 | loss: 0.0706587\n",
      "\tspeed: 0.0344s/iter; left time: 470.9681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0715180 Vali Loss: 0.0755162 Test Loss: 0.0867972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0185981597751379, rmse:0.1363750696182251, mae:0.08636235445737839, rse:0.4006288945674896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1582830\n",
      "\tspeed: 0.0364s/iter; left time: 811.6288s\n",
      "\titers: 200, epoch: 1 | loss: 0.1536793\n",
      "\tspeed: 0.0350s/iter; left time: 776.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1618317 Vali Loss: 0.1495777 Test Loss: 0.1801662\n",
      "Validation loss decreased (inf --> 0.149578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0939178\n",
      "\tspeed: 0.0683s/iter; left time: 1507.8242s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864733\n",
      "\tspeed: 0.0345s/iter; left time: 758.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0985453 Vali Loss: 0.0839609 Test Loss: 0.0956050\n",
      "Validation loss decreased (0.149578 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878430\n",
      "\tspeed: 0.0662s/iter; left time: 1446.6138s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782254\n",
      "\tspeed: 0.0345s/iter; left time: 751.0563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0840291 Vali Loss: 0.0807863 Test Loss: 0.0920472\n",
      "Validation loss decreased (0.083961 --> 0.080786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0836028\n",
      "\tspeed: 0.0658s/iter; left time: 1423.3504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806706\n",
      "\tspeed: 0.0342s/iter; left time: 737.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0807939 Vali Loss: 0.0788258 Test Loss: 0.0900378\n",
      "Validation loss decreased (0.080786 --> 0.078826).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0788435\n",
      "\tspeed: 0.0655s/iter; left time: 1401.4825s\n",
      "\titers: 200, epoch: 5 | loss: 0.0807367\n",
      "\tspeed: 0.0340s/iter; left time: 723.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0788217 Vali Loss: 0.0780139 Test Loss: 0.0892532\n",
      "Validation loss decreased (0.078826 --> 0.078014).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773067\n",
      "\tspeed: 0.0669s/iter; left time: 1415.9893s\n",
      "\titers: 200, epoch: 6 | loss: 0.0772312\n",
      "\tspeed: 0.0345s/iter; left time: 726.9079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0775746 Vali Loss: 0.0777914 Test Loss: 0.0886277\n",
      "Validation loss decreased (0.078014 --> 0.077791).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0767768\n",
      "\tspeed: 0.0664s/iter; left time: 1390.6157s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746151\n",
      "\tspeed: 0.0342s/iter; left time: 713.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0767128 Vali Loss: 0.0770210 Test Loss: 0.0880919\n",
      "Validation loss decreased (0.077791 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0772053\n",
      "\tspeed: 0.0665s/iter; left time: 1377.8853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728543\n",
      "\tspeed: 0.0343s/iter; left time: 707.0327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0759991 Vali Loss: 0.0769128 Test Loss: 0.0879381\n",
      "Validation loss decreased (0.077021 --> 0.076913).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0746797\n",
      "\tspeed: 0.0663s/iter; left time: 1359.5577s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793813\n",
      "\tspeed: 0.0342s/iter; left time: 698.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0754255 Vali Loss: 0.0765287 Test Loss: 0.0876836\n",
      "Validation loss decreased (0.076913 --> 0.076529).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0778281\n",
      "\tspeed: 0.0659s/iter; left time: 1336.2387s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760081\n",
      "\tspeed: 0.0346s/iter; left time: 697.8025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0749424 Vali Loss: 0.0765791 Test Loss: 0.0876946\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0761849\n",
      "\tspeed: 0.0649s/iter; left time: 1301.6645s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759281\n",
      "\tspeed: 0.0341s/iter; left time: 679.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0745479 Vali Loss: 0.0765141 Test Loss: 0.0871809\n",
      "Validation loss decreased (0.076529 --> 0.076514).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0740213\n",
      "\tspeed: 0.0658s/iter; left time: 1304.3973s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729842\n",
      "\tspeed: 0.0345s/iter; left time: 680.1971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0742243 Vali Loss: 0.0766330 Test Loss: 0.0873586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0739172\n",
      "\tspeed: 0.0656s/iter; left time: 1285.6386s\n",
      "\titers: 200, epoch: 13 | loss: 0.0755008\n",
      "\tspeed: 0.0347s/iter; left time: 677.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0739385 Vali Loss: 0.0763564 Test Loss: 0.0872647\n",
      "Validation loss decreased (0.076514 --> 0.076356).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0703849\n",
      "\tspeed: 0.0672s/iter; left time: 1303.7925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0713772\n",
      "\tspeed: 0.0343s/iter; left time: 661.0950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0736357 Vali Loss: 0.0765072 Test Loss: 0.0869802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0685526\n",
      "\tspeed: 0.0641s/iter; left time: 1229.4245s\n",
      "\titers: 200, epoch: 15 | loss: 0.0744490\n",
      "\tspeed: 0.0343s/iter; left time: 654.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0733645 Vali Loss: 0.0765096 Test Loss: 0.0869906\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0745860\n",
      "\tspeed: 0.0650s/iter; left time: 1231.3518s\n",
      "\titers: 200, epoch: 16 | loss: 0.0714565\n",
      "\tspeed: 0.0344s/iter; left time: 647.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0731870 Vali Loss: 0.0763907 Test Loss: 0.0867740\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0767808\n",
      "\tspeed: 0.0648s/iter; left time: 1213.3498s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734670\n",
      "\tspeed: 0.0340s/iter; left time: 632.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0729853 Vali Loss: 0.0765046 Test Loss: 0.0869768\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0747071\n",
      "\tspeed: 0.0656s/iter; left time: 1212.3278s\n",
      "\titers: 200, epoch: 18 | loss: 0.0728723\n",
      "\tspeed: 0.0343s/iter; left time: 631.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0727439 Vali Loss: 0.0765303 Test Loss: 0.0870398\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0708978\n",
      "\tspeed: 0.0658s/iter; left time: 1202.2714s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723809\n",
      "\tspeed: 0.0346s/iter; left time: 629.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0725793 Vali Loss: 0.0764471 Test Loss: 0.0870042\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0734421\n",
      "\tspeed: 0.0691s/iter; left time: 1246.2761s\n",
      "\titers: 200, epoch: 20 | loss: 0.0769663\n",
      "\tspeed: 0.0345s/iter; left time: 618.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0725307 Vali Loss: 0.0765048 Test Loss: 0.0870345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0716774\n",
      "\tspeed: 0.0658s/iter; left time: 1173.5035s\n",
      "\titers: 200, epoch: 21 | loss: 0.0718850\n",
      "\tspeed: 0.0345s/iter; left time: 612.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.0723870 Vali Loss: 0.0766452 Test Loss: 0.0869602\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0720396\n",
      "\tspeed: 0.0649s/iter; left time: 1142.3563s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696126\n",
      "\tspeed: 0.0343s/iter; left time: 600.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0722414 Vali Loss: 0.0765089 Test Loss: 0.0867656\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0730018\n",
      "\tspeed: 0.0649s/iter; left time: 1127.8702s\n",
      "\titers: 200, epoch: 23 | loss: 0.0753521\n",
      "\tspeed: 0.0343s/iter; left time: 592.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0721670 Vali Loss: 0.0766542 Test Loss: 0.0870228\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018632538616657257, rmse:0.13650105893611908, mae:0.08726463466882706, rse:0.4009990394115448\n",
      "Intermediate time for ES and pred_len 96: 00h:10m:34.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1581242\n",
      "\tspeed: 0.0689s/iter; left time: 1528.7480s\n",
      "\titers: 200, epoch: 1 | loss: 0.1507171\n",
      "\tspeed: 0.0361s/iter; left time: 797.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.1638708 Vali Loss: 0.1523550 Test Loss: 0.1819388\n",
      "Validation loss decreased (inf --> 0.152355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986643\n",
      "\tspeed: 0.0680s/iter; left time: 1495.1640s\n",
      "\titers: 200, epoch: 2 | loss: 0.0934433\n",
      "\tspeed: 0.0354s/iter; left time: 773.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.1013446 Vali Loss: 0.0890421 Test Loss: 0.1011388\n",
      "Validation loss decreased (0.152355 --> 0.089042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0940395\n",
      "\tspeed: 0.0664s/iter; left time: 1444.6917s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868575\n",
      "\tspeed: 0.0351s/iter; left time: 760.9128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0888059 Vali Loss: 0.0860402 Test Loss: 0.0980579\n",
      "Validation loss decreased (0.089042 --> 0.086040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0851304\n",
      "\tspeed: 0.0673s/iter; left time: 1448.8477s\n",
      "\titers: 200, epoch: 4 | loss: 0.0841597\n",
      "\tspeed: 0.0352s/iter; left time: 753.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0857711 Vali Loss: 0.0841981 Test Loss: 0.0959112\n",
      "Validation loss decreased (0.086040 --> 0.084198).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0825492\n",
      "\tspeed: 0.0667s/iter; left time: 1422.2021s\n",
      "\titers: 200, epoch: 5 | loss: 0.0825241\n",
      "\tspeed: 0.0346s/iter; left time: 734.7796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.0838901 Vali Loss: 0.0835975 Test Loss: 0.0951364\n",
      "Validation loss decreased (0.084198 --> 0.083597).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0831312\n",
      "\tspeed: 0.0664s/iter; left time: 1399.8241s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821218\n",
      "\tspeed: 0.0349s/iter; left time: 731.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0827609 Vali Loss: 0.0835203 Test Loss: 0.0949269\n",
      "Validation loss decreased (0.083597 --> 0.083520).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847962\n",
      "\tspeed: 0.0669s/iter; left time: 1395.8924s\n",
      "\titers: 200, epoch: 7 | loss: 0.0801695\n",
      "\tspeed: 0.0350s/iter; left time: 725.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0820128 Vali Loss: 0.0828906 Test Loss: 0.0942042\n",
      "Validation loss decreased (0.083520 --> 0.082891).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826582\n",
      "\tspeed: 0.0661s/iter; left time: 1364.9834s\n",
      "\titers: 200, epoch: 8 | loss: 0.0829372\n",
      "\tspeed: 0.0352s/iter; left time: 722.1369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0813807 Vali Loss: 0.0829064 Test Loss: 0.0940305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785602\n",
      "\tspeed: 0.0651s/iter; left time: 1328.5128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0813846\n",
      "\tspeed: 0.0358s/iter; left time: 726.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0808702 Vali Loss: 0.0826419 Test Loss: 0.0939117\n",
      "Validation loss decreased (0.082891 --> 0.082642).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0784310\n",
      "\tspeed: 0.0666s/iter; left time: 1345.3745s\n",
      "\titers: 200, epoch: 10 | loss: 0.0772360\n",
      "\tspeed: 0.0347s/iter; left time: 696.9522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0803654 Vali Loss: 0.0824731 Test Loss: 0.0937046\n",
      "Validation loss decreased (0.082642 --> 0.082473).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0798821\n",
      "\tspeed: 0.0671s/iter; left time: 1340.7770s\n",
      "\titers: 200, epoch: 11 | loss: 0.0784780\n",
      "\tspeed: 0.0350s/iter; left time: 695.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.0799386 Vali Loss: 0.0822538 Test Loss: 0.0935915\n",
      "Validation loss decreased (0.082473 --> 0.082254).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0809544\n",
      "\tspeed: 0.0677s/iter; left time: 1336.4860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0804690\n",
      "\tspeed: 0.0349s/iter; left time: 685.9779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0795472 Vali Loss: 0.0822670 Test Loss: 0.0936214\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796984\n",
      "\tspeed: 0.0661s/iter; left time: 1289.7716s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766402\n",
      "\tspeed: 0.0346s/iter; left time: 671.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0792191 Vali Loss: 0.0818180 Test Loss: 0.0939182\n",
      "Validation loss decreased (0.082254 --> 0.081818).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0797491\n",
      "\tspeed: 0.0672s/iter; left time: 1296.1919s\n",
      "\titers: 200, epoch: 14 | loss: 0.0768970\n",
      "\tspeed: 0.0350s/iter; left time: 671.4356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0789267 Vali Loss: 0.0818768 Test Loss: 0.0939726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0793521\n",
      "\tspeed: 0.0655s/iter; left time: 1250.5548s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760051\n",
      "\tspeed: 0.0346s/iter; left time: 657.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0786685 Vali Loss: 0.0820166 Test Loss: 0.0940066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786998\n",
      "\tspeed: 0.0658s/iter; left time: 1240.9156s\n",
      "\titers: 200, epoch: 16 | loss: 0.0790844\n",
      "\tspeed: 0.0347s/iter; left time: 651.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0784924 Vali Loss: 0.0818277 Test Loss: 0.0944564\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0776468\n",
      "\tspeed: 0.0665s/iter; left time: 1238.5488s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762781\n",
      "\tspeed: 0.0347s/iter; left time: 642.6656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0782404 Vali Loss: 0.0818648 Test Loss: 0.0947103\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0797928\n",
      "\tspeed: 0.0657s/iter; left time: 1208.8282s\n",
      "\titers: 200, epoch: 18 | loss: 0.0767054\n",
      "\tspeed: 0.0349s/iter; left time: 638.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0780503 Vali Loss: 0.0820865 Test Loss: 0.0952556\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0800530\n",
      "\tspeed: 0.0672s/iter; left time: 1222.8283s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773672\n",
      "\tspeed: 0.0348s/iter; left time: 629.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.0779013 Vali Loss: 0.0819001 Test Loss: 0.0952660\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0764023\n",
      "\tspeed: 0.0654s/iter; left time: 1175.2099s\n",
      "\titers: 200, epoch: 20 | loss: 0.0789287\n",
      "\tspeed: 0.0346s/iter; left time: 618.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0777259 Vali Loss: 0.0817606 Test Loss: 0.0951863\n",
      "Validation loss decreased (0.081818 --> 0.081761).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766384\n",
      "\tspeed: 0.0676s/iter; left time: 1199.6317s\n",
      "\titers: 200, epoch: 21 | loss: 0.0782197\n",
      "\tspeed: 0.0358s/iter; left time: 630.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 223 | Train Loss: 0.0775856 Vali Loss: 0.0819180 Test Loss: 0.0953271\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756970\n",
      "\tspeed: 0.0652s/iter; left time: 1142.9382s\n",
      "\titers: 200, epoch: 22 | loss: 0.0782074\n",
      "\tspeed: 0.0346s/iter; left time: 603.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0774701 Vali Loss: 0.0816166 Test Loss: 0.0955943\n",
      "Validation loss decreased (0.081761 --> 0.081617).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767044\n",
      "\tspeed: 0.0682s/iter; left time: 1179.0716s\n",
      "\titers: 200, epoch: 23 | loss: 0.0780989\n",
      "\tspeed: 0.0353s/iter; left time: 607.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0773348 Vali Loss: 0.0818224 Test Loss: 0.0957033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0800862\n",
      "\tspeed: 0.0649s/iter; left time: 1107.8149s\n",
      "\titers: 200, epoch: 24 | loss: 0.0712628\n",
      "\tspeed: 0.0354s/iter; left time: 600.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 223 | Train Loss: 0.0772094 Vali Loss: 0.0816642 Test Loss: 0.0957151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0788048\n",
      "\tspeed: 0.0697s/iter; left time: 1174.6549s\n",
      "\titers: 200, epoch: 25 | loss: 0.0728152\n",
      "\tspeed: 0.0392s/iter; left time: 656.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 223 | Train Loss: 0.0771515 Vali Loss: 0.0817642 Test Loss: 0.0957897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0781624\n",
      "\tspeed: 0.0662s/iter; left time: 1101.1165s\n",
      "\titers: 200, epoch: 26 | loss: 0.0739947\n",
      "\tspeed: 0.0346s/iter; left time: 571.0519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0770992 Vali Loss: 0.0816698 Test Loss: 0.0958092\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0785158\n",
      "\tspeed: 0.0653s/iter; left time: 1070.8971s\n",
      "\titers: 200, epoch: 27 | loss: 0.0776058\n",
      "\tspeed: 0.0345s/iter; left time: 562.8449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0770031 Vali Loss: 0.0817289 Test Loss: 0.0957823\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0762650\n",
      "\tspeed: 0.0649s/iter; left time: 1049.7568s\n",
      "\titers: 200, epoch: 28 | loss: 0.0730262\n",
      "\tspeed: 0.0349s/iter; left time: 560.7453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0769375 Vali Loss: 0.0817190 Test Loss: 0.0960716\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0779013\n",
      "\tspeed: 0.0660s/iter; left time: 1053.8148s\n",
      "\titers: 200, epoch: 29 | loss: 0.0780241\n",
      "\tspeed: 0.0346s/iter; left time: 548.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.0768650 Vali Loss: 0.0818699 Test Loss: 0.0961976\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0775625\n",
      "\tspeed: 0.0662s/iter; left time: 1042.0484s\n",
      "\titers: 200, epoch: 30 | loss: 0.0751118\n",
      "\tspeed: 0.0356s/iter; left time: 556.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0768085 Vali Loss: 0.0818688 Test Loss: 0.0963391\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0737045\n",
      "\tspeed: 0.0660s/iter; left time: 1023.8356s\n",
      "\titers: 200, epoch: 31 | loss: 0.0770995\n",
      "\tspeed: 0.0350s/iter; left time: 539.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0767635 Vali Loss: 0.0816762 Test Loss: 0.0960850\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781929\n",
      "\tspeed: 0.0657s/iter; left time: 1004.8351s\n",
      "\titers: 200, epoch: 32 | loss: 0.0797998\n",
      "\tspeed: 0.0346s/iter; left time: 525.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0767546 Vali Loss: 0.0817475 Test Loss: 0.0963959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02126566879451275, rmse:0.1458275318145752, mae:0.0955943912267685, rse:0.42842817306518555\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1622073\n",
      "\tspeed: 0.0371s/iter; left time: 824.2287s\n",
      "\titers: 200, epoch: 1 | loss: 0.1511776\n",
      "\tspeed: 0.0348s/iter; left time: 770.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1635544 Vali Loss: 0.1513875 Test Loss: 0.1804619\n",
      "Validation loss decreased (inf --> 0.151388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0963681\n",
      "\tspeed: 0.0682s/iter; left time: 1497.9875s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897276\n",
      "\tspeed: 0.0349s/iter; left time: 764.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1009506 Vali Loss: 0.0887425 Test Loss: 0.1008672\n",
      "Validation loss decreased (0.151388 --> 0.088743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0909871\n",
      "\tspeed: 0.0707s/iter; left time: 1537.4113s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840339\n",
      "\tspeed: 0.0377s/iter; left time: 815.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0886917 Vali Loss: 0.0861339 Test Loss: 0.0982522\n",
      "Validation loss decreased (0.088743 --> 0.086134).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863238\n",
      "\tspeed: 0.0692s/iter; left time: 1489.5158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863077\n",
      "\tspeed: 0.0350s/iter; left time: 749.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0857665 Vali Loss: 0.0844378 Test Loss: 0.0962862\n",
      "Validation loss decreased (0.086134 --> 0.084438).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852887\n",
      "\tspeed: 0.0684s/iter; left time: 1457.8487s\n",
      "\titers: 200, epoch: 5 | loss: 0.0826804\n",
      "\tspeed: 0.0353s/iter; left time: 747.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 223 | Train Loss: 0.0839180 Vali Loss: 0.0839240 Test Loss: 0.0957661\n",
      "Validation loss decreased (0.084438 --> 0.083924).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0836342\n",
      "\tspeed: 0.0703s/iter; left time: 1482.6421s\n",
      "\titers: 200, epoch: 6 | loss: 0.0806390\n",
      "\tspeed: 0.0373s/iter; left time: 783.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 223 | Train Loss: 0.0828160 Vali Loss: 0.0837571 Test Loss: 0.0950037\n",
      "Validation loss decreased (0.083924 --> 0.083757).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0857420\n",
      "\tspeed: 0.0682s/iter; left time: 1423.2851s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848666\n",
      "\tspeed: 0.0350s/iter; left time: 727.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0820557 Vali Loss: 0.0831144 Test Loss: 0.0942615\n",
      "Validation loss decreased (0.083757 --> 0.083114).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0834368\n",
      "\tspeed: 0.0696s/iter; left time: 1435.6608s\n",
      "\titers: 200, epoch: 8 | loss: 0.0797058\n",
      "\tspeed: 0.0350s/iter; left time: 719.8850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 223 | Train Loss: 0.0814393 Vali Loss: 0.0832333 Test Loss: 0.0942153\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0792525\n",
      "\tspeed: 0.0665s/iter; left time: 1357.0644s\n",
      "\titers: 200, epoch: 9 | loss: 0.0831456\n",
      "\tspeed: 0.0354s/iter; left time: 718.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0809265 Vali Loss: 0.0834103 Test Loss: 0.0940458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0839281\n",
      "\tspeed: 0.0671s/iter; left time: 1355.8758s\n",
      "\titers: 200, epoch: 10 | loss: 0.0820906\n",
      "\tspeed: 0.0354s/iter; left time: 711.1119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.0804400 Vali Loss: 0.0831343 Test Loss: 0.0936590\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0800651\n",
      "\tspeed: 0.0672s/iter; left time: 1342.3950s\n",
      "\titers: 200, epoch: 11 | loss: 0.0795596\n",
      "\tspeed: 0.0351s/iter; left time: 696.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.14s\n",
      "Steps: 223 | Train Loss: 0.0799918 Vali Loss: 0.0829600 Test Loss: 0.0931671\n",
      "Validation loss decreased (0.083114 --> 0.082960).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0811823\n",
      "\tspeed: 0.0679s/iter; left time: 1341.1906s\n",
      "\titers: 200, epoch: 12 | loss: 0.0830218\n",
      "\tspeed: 0.0348s/iter; left time: 684.0976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0796409 Vali Loss: 0.0829638 Test Loss: 0.0932920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763461\n",
      "\tspeed: 0.0661s/iter; left time: 1291.0902s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818228\n",
      "\tspeed: 0.0344s/iter; left time: 667.3773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0793178 Vali Loss: 0.0828459 Test Loss: 0.0931148\n",
      "Validation loss decreased (0.082960 --> 0.082846).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0800062\n",
      "\tspeed: 0.0671s/iter; left time: 1294.3812s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819832\n",
      "\tspeed: 0.0345s/iter; left time: 663.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0789994 Vali Loss: 0.0825182 Test Loss: 0.0933117\n",
      "Validation loss decreased (0.082846 --> 0.082518).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0812188\n",
      "\tspeed: 0.0680s/iter; left time: 1297.1837s\n",
      "\titers: 200, epoch: 15 | loss: 0.0769876\n",
      "\tspeed: 0.0345s/iter; left time: 654.2046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0787149 Vali Loss: 0.0826182 Test Loss: 0.0934537\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786891\n",
      "\tspeed: 0.0665s/iter; left time: 1254.5914s\n",
      "\titers: 200, epoch: 16 | loss: 0.0829321\n",
      "\tspeed: 0.0346s/iter; left time: 648.0698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0785222 Vali Loss: 0.0824578 Test Loss: 0.0933246\n",
      "Validation loss decreased (0.082518 --> 0.082458).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766105\n",
      "\tspeed: 0.0660s/iter; left time: 1228.8647s\n",
      "\titers: 200, epoch: 17 | loss: 0.0775430\n",
      "\tspeed: 0.0345s/iter; left time: 639.5157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0782164 Vali Loss: 0.0823364 Test Loss: 0.0936304\n",
      "Validation loss decreased (0.082458 --> 0.082336).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0737783\n",
      "\tspeed: 0.0679s/iter; left time: 1249.5334s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795119\n",
      "\tspeed: 0.0345s/iter; left time: 631.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0780388 Vali Loss: 0.0823434 Test Loss: 0.0939227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779562\n",
      "\tspeed: 0.0664s/iter; left time: 1207.5432s\n",
      "\titers: 200, epoch: 19 | loss: 0.0744572\n",
      "\tspeed: 0.0346s/iter; left time: 625.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0778180 Vali Loss: 0.0823256 Test Loss: 0.0938507\n",
      "Validation loss decreased (0.082336 --> 0.082326).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0811709\n",
      "\tspeed: 0.0665s/iter; left time: 1194.6992s\n",
      "\titers: 200, epoch: 20 | loss: 0.0786681\n",
      "\tspeed: 0.0345s/iter; left time: 615.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 223 | Train Loss: 0.0775951 Vali Loss: 0.0823114 Test Loss: 0.0941019\n",
      "Validation loss decreased (0.082326 --> 0.082311).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0748576\n",
      "\tspeed: 0.0672s/iter; left time: 1193.0233s\n",
      "\titers: 200, epoch: 21 | loss: 0.0787515\n",
      "\tspeed: 0.0348s/iter; left time: 613.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.0774586 Vali Loss: 0.0820314 Test Loss: 0.0940175\n",
      "Validation loss decreased (0.082311 --> 0.082031).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0802003\n",
      "\tspeed: 0.0674s/iter; left time: 1180.7295s\n",
      "\titers: 200, epoch: 22 | loss: 0.0754237\n",
      "\tspeed: 0.0348s/iter; left time: 606.5265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0773000 Vali Loss: 0.0820159 Test Loss: 0.0942531\n",
      "Validation loss decreased (0.082031 --> 0.082016).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0779743\n",
      "\tspeed: 0.0678s/iter; left time: 1172.8826s\n",
      "\titers: 200, epoch: 23 | loss: 0.0747215\n",
      "\tspeed: 0.0350s/iter; left time: 601.5548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.0772234 Vali Loss: 0.0822244 Test Loss: 0.0947550\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0775924\n",
      "\tspeed: 0.0665s/iter; left time: 1135.0784s\n",
      "\titers: 200, epoch: 24 | loss: 0.0774336\n",
      "\tspeed: 0.0345s/iter; left time: 585.2632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.0770066 Vali Loss: 0.0819901 Test Loss: 0.0946638\n",
      "Validation loss decreased (0.082016 --> 0.081990).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0765772\n",
      "\tspeed: 0.0670s/iter; left time: 1128.2230s\n",
      "\titers: 200, epoch: 25 | loss: 0.0774296\n",
      "\tspeed: 0.0347s/iter; left time: 580.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0769184 Vali Loss: 0.0818508 Test Loss: 0.0945564\n",
      "Validation loss decreased (0.081990 --> 0.081851).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0752274\n",
      "\tspeed: 0.0670s/iter; left time: 1114.0727s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780611\n",
      "\tspeed: 0.0348s/iter; left time: 574.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0768677 Vali Loss: 0.0820124 Test Loss: 0.0949415\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0767367\n",
      "\tspeed: 0.0670s/iter; left time: 1098.4792s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761459\n",
      "\tspeed: 0.0363s/iter; left time: 591.3927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 223 | Train Loss: 0.0767765 Vali Loss: 0.0820813 Test Loss: 0.0948841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0743221\n",
      "\tspeed: 0.0684s/iter; left time: 1107.3506s\n",
      "\titers: 200, epoch: 28 | loss: 0.0752958\n",
      "\tspeed: 0.0351s/iter; left time: 564.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 223 | Train Loss: 0.0767860 Vali Loss: 0.0819307 Test Loss: 0.0946716\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0782983\n",
      "\tspeed: 0.0666s/iter; left time: 1063.0058s\n",
      "\titers: 200, epoch: 29 | loss: 0.0778854\n",
      "\tspeed: 0.0357s/iter; left time: 566.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 223 | Train Loss: 0.0766185 Vali Loss: 0.0818122 Test Loss: 0.0950429\n",
      "Validation loss decreased (0.081851 --> 0.081812).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0740042\n",
      "\tspeed: 0.0673s/iter; left time: 1059.5981s\n",
      "\titers: 200, epoch: 30 | loss: 0.0801981\n",
      "\tspeed: 0.0345s/iter; left time: 538.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 223 | Train Loss: 0.0765305 Vali Loss: 0.0820920 Test Loss: 0.0952042\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0767182\n",
      "\tspeed: 0.0653s/iter; left time: 1013.0907s\n",
      "\titers: 200, epoch: 31 | loss: 0.0758625\n",
      "\tspeed: 0.0346s/iter; left time: 532.5713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0765871 Vali Loss: 0.0818485 Test Loss: 0.0951992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0781168\n",
      "\tspeed: 0.0670s/iter; left time: 1024.4357s\n",
      "\titers: 200, epoch: 32 | loss: 0.0793877\n",
      "\tspeed: 0.0352s/iter; left time: 535.2964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.0764493 Vali Loss: 0.0820237 Test Loss: 0.0955673\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0740315\n",
      "\tspeed: 0.0654s/iter; left time: 985.6079s\n",
      "\titers: 200, epoch: 33 | loss: 0.0757111\n",
      "\tspeed: 0.0347s/iter; left time: 519.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 223 | Train Loss: 0.0763936 Vali Loss: 0.0819379 Test Loss: 0.0954416\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0753173\n",
      "\tspeed: 0.0657s/iter; left time: 974.7022s\n",
      "\titers: 200, epoch: 34 | loss: 0.0706699\n",
      "\tspeed: 0.0352s/iter; left time: 518.4988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.0763890 Vali Loss: 0.0819006 Test Loss: 0.0955024\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0773871\n",
      "\tspeed: 0.0655s/iter; left time: 957.2772s\n",
      "\titers: 200, epoch: 35 | loss: 0.0741799\n",
      "\tspeed: 0.0349s/iter; left time: 507.1043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.0763201 Vali Loss: 0.0818680 Test Loss: 0.0954335\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0785499\n",
      "\tspeed: 0.0652s/iter; left time: 938.3553s\n",
      "\titers: 200, epoch: 36 | loss: 0.0738299\n",
      "\tspeed: 0.0345s/iter; left time: 493.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 223 | Train Loss: 0.0762440 Vali Loss: 0.0819575 Test Loss: 0.0954877\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0755313\n",
      "\tspeed: 0.0655s/iter; left time: 927.8703s\n",
      "\titers: 200, epoch: 37 | loss: 0.0735468\n",
      "\tspeed: 0.0346s/iter; left time: 487.5966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.0762236 Vali Loss: 0.0820155 Test Loss: 0.0955825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0732269\n",
      "\tspeed: 0.0676s/iter; left time: 943.2274s\n",
      "\titers: 200, epoch: 38 | loss: 0.0770698\n",
      "\tspeed: 0.0344s/iter; left time: 476.4420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.0762167 Vali Loss: 0.0818996 Test Loss: 0.0954762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0765640\n",
      "\tspeed: 0.0662s/iter; left time: 908.9614s\n",
      "\titers: 200, epoch: 39 | loss: 0.0754804\n",
      "\tspeed: 0.0351s/iter; left time: 478.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.0761922 Vali Loss: 0.0818792 Test Loss: 0.0953627\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02110309898853302, rmse:0.14526905119419098, mae:0.09504284709692001, rse:0.42678743600845337\n",
      "Intermediate time for ES and pred_len 168: 00h:12m:17.38s\n",
      "Intermediate time for ES: 00h:38m:58.75s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1181538\n",
      "\tspeed: 0.0512s/iter; left time: 1151.7002s\n",
      "\titers: 200, epoch: 1 | loss: 0.1003178\n",
      "\tspeed: 0.0244s/iter; left time: 547.6969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.1170270 Vali Loss: 0.1172993 Test Loss: 0.1302999\n",
      "Validation loss decreased (inf --> 0.117299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0619097\n",
      "\tspeed: 0.0472s/iter; left time: 1051.0409s\n",
      "\titers: 200, epoch: 2 | loss: 0.0544771\n",
      "\tspeed: 0.0240s/iter; left time: 531.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 226 | Train Loss: 0.0654789 Vali Loss: 0.0618007 Test Loss: 0.0638786\n",
      "Validation loss decreased (0.117299 --> 0.061801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0528410\n",
      "\tspeed: 0.0478s/iter; left time: 1052.9309s\n",
      "\titers: 200, epoch: 3 | loss: 0.0507370\n",
      "\tspeed: 0.0283s/iter; left time: 620.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0510558 Vali Loss: 0.0580366 Test Loss: 0.0603052\n",
      "Validation loss decreased (0.061801 --> 0.058037).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0520147\n",
      "\tspeed: 0.0497s/iter; left time: 1085.1892s\n",
      "\titers: 200, epoch: 4 | loss: 0.0432217\n",
      "\tspeed: 0.0323s/iter; left time: 700.9857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0484834 Vali Loss: 0.0563872 Test Loss: 0.0588450\n",
      "Validation loss decreased (0.058037 --> 0.056387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0448531\n",
      "\tspeed: 0.0473s/iter; left time: 1022.4748s\n",
      "\titers: 200, epoch: 5 | loss: 0.0467714\n",
      "\tspeed: 0.0289s/iter; left time: 621.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0468747 Vali Loss: 0.0547840 Test Loss: 0.0575932\n",
      "Validation loss decreased (0.056387 --> 0.054784).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0465157\n",
      "\tspeed: 0.0549s/iter; left time: 1172.4276s\n",
      "\titers: 200, epoch: 6 | loss: 0.0471361\n",
      "\tspeed: 0.0298s/iter; left time: 633.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 226 | Train Loss: 0.0456765 Vali Loss: 0.0538354 Test Loss: 0.0568870\n",
      "Validation loss decreased (0.054784 --> 0.053835).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0464228\n",
      "\tspeed: 0.0506s/iter; left time: 1070.3317s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428562\n",
      "\tspeed: 0.0207s/iter; left time: 434.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 226 | Train Loss: 0.0448067 Vali Loss: 0.0531672 Test Loss: 0.0561855\n",
      "Validation loss decreased (0.053835 --> 0.053167).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0414287\n",
      "\tspeed: 0.0514s/iter; left time: 1075.8979s\n",
      "\titers: 200, epoch: 8 | loss: 0.0414663\n",
      "\tspeed: 0.0231s/iter; left time: 480.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 226 | Train Loss: 0.0441156 Vali Loss: 0.0528043 Test Loss: 0.0558938\n",
      "Validation loss decreased (0.053167 --> 0.052804).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0396454\n",
      "\tspeed: 0.0497s/iter; left time: 1027.8371s\n",
      "\titers: 200, epoch: 9 | loss: 0.0445222\n",
      "\tspeed: 0.0263s/iter; left time: 541.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 226 | Train Loss: 0.0437219 Vali Loss: 0.0524473 Test Loss: 0.0555881\n",
      "Validation loss decreased (0.052804 --> 0.052447).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465342\n",
      "\tspeed: 0.0490s/iter; left time: 1003.1988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0447787\n",
      "\tspeed: 0.0282s/iter; left time: 574.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0433464 Vali Loss: 0.0524429 Test Loss: 0.0555543\n",
      "Validation loss decreased (0.052447 --> 0.052443).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0463950\n",
      "\tspeed: 0.0465s/iter; left time: 941.8945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0471261\n",
      "\tspeed: 0.0262s/iter; left time: 527.7628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 226 | Train Loss: 0.0430885 Vali Loss: 0.0520855 Test Loss: 0.0553389\n",
      "Validation loss decreased (0.052443 --> 0.052086).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0440239\n",
      "\tspeed: 0.0500s/iter; left time: 1000.4495s\n",
      "\titers: 200, epoch: 12 | loss: 0.0431861\n",
      "\tspeed: 0.0253s/iter; left time: 503.8990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0427594 Vali Loss: 0.0520969 Test Loss: 0.0552671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0460427\n",
      "\tspeed: 0.0483s/iter; left time: 955.3089s\n",
      "\titers: 200, epoch: 13 | loss: 0.0407886\n",
      "\tspeed: 0.0235s/iter; left time: 462.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 226 | Train Loss: 0.0425987 Vali Loss: 0.0519302 Test Loss: 0.0550461\n",
      "Validation loss decreased (0.052086 --> 0.051930).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0436107\n",
      "\tspeed: 0.0523s/iter; left time: 1022.8773s\n",
      "\titers: 200, epoch: 14 | loss: 0.0460468\n",
      "\tspeed: 0.0294s/iter; left time: 573.0106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0424552 Vali Loss: 0.0518532 Test Loss: 0.0550036\n",
      "Validation loss decreased (0.051930 --> 0.051853).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0402645\n",
      "\tspeed: 0.0567s/iter; left time: 1095.9107s\n",
      "\titers: 200, epoch: 15 | loss: 0.0445272\n",
      "\tspeed: 0.0292s/iter; left time: 561.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0422743 Vali Loss: 0.0517325 Test Loss: 0.0548619\n",
      "Validation loss decreased (0.051853 --> 0.051732).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0438543\n",
      "\tspeed: 0.0456s/iter; left time: 871.5470s\n",
      "\titers: 200, epoch: 16 | loss: 0.0432302\n",
      "\tspeed: 0.0214s/iter; left time: 406.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 226 | Train Loss: 0.0421779 Vali Loss: 0.0516198 Test Loss: 0.0546895\n",
      "Validation loss decreased (0.051732 --> 0.051620).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0420478\n",
      "\tspeed: 0.0502s/iter; left time: 948.6092s\n",
      "\titers: 200, epoch: 17 | loss: 0.0416950\n",
      "\tspeed: 0.0257s/iter; left time: 482.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0420557 Vali Loss: 0.0514453 Test Loss: 0.0546779\n",
      "Validation loss decreased (0.051620 --> 0.051445).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0412639\n",
      "\tspeed: 0.0495s/iter; left time: 923.9595s\n",
      "\titers: 200, epoch: 18 | loss: 0.0401191\n",
      "\tspeed: 0.0261s/iter; left time: 483.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0419732 Vali Loss: 0.0515109 Test Loss: 0.0546205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0420400\n",
      "\tspeed: 0.0477s/iter; left time: 878.9548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0422216\n",
      "\tspeed: 0.0273s/iter; left time: 500.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0418645 Vali Loss: 0.0514373 Test Loss: 0.0545614\n",
      "Validation loss decreased (0.051445 --> 0.051437).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0434768\n",
      "\tspeed: 0.0474s/iter; left time: 862.3987s\n",
      "\titers: 200, epoch: 20 | loss: 0.0388558\n",
      "\tspeed: 0.0210s/iter; left time: 380.7805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 226 | Train Loss: 0.0417754 Vali Loss: 0.0513995 Test Loss: 0.0544768\n",
      "Validation loss decreased (0.051437 --> 0.051399).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0394034\n",
      "\tspeed: 0.0493s/iter; left time: 885.8111s\n",
      "\titers: 200, epoch: 21 | loss: 0.0404570\n",
      "\tspeed: 0.0265s/iter; left time: 473.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0417436 Vali Loss: 0.0513565 Test Loss: 0.0544110\n",
      "Validation loss decreased (0.051399 --> 0.051356).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0408854\n",
      "\tspeed: 0.0488s/iter; left time: 866.0392s\n",
      "\titers: 200, epoch: 22 | loss: 0.0402349\n",
      "\tspeed: 0.0264s/iter; left time: 465.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 226 | Train Loss: 0.0416521 Vali Loss: 0.0513761 Test Loss: 0.0544329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0412479\n",
      "\tspeed: 0.0558s/iter; left time: 977.2998s\n",
      "\titers: 200, epoch: 23 | loss: 0.0419215\n",
      "\tspeed: 0.0300s/iter; left time: 522.4368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 226 | Train Loss: 0.0416237 Vali Loss: 0.0514683 Test Loss: 0.0544846\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0403025\n",
      "\tspeed: 0.0490s/iter; left time: 847.3580s\n",
      "\titers: 200, epoch: 24 | loss: 0.0403031\n",
      "\tspeed: 0.0186s/iter; left time: 320.7997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 226 | Train Loss: 0.0415419 Vali Loss: 0.0513075 Test Loss: 0.0543513\n",
      "Validation loss decreased (0.051356 --> 0.051307).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0388115\n",
      "\tspeed: 0.0412s/iter; left time: 703.9726s\n",
      "\titers: 200, epoch: 25 | loss: 0.0417404\n",
      "\tspeed: 0.0260s/iter; left time: 441.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 226 | Train Loss: 0.0415224 Vali Loss: 0.0511409 Test Loss: 0.0542526\n",
      "Validation loss decreased (0.051307 --> 0.051141).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0413413\n",
      "\tspeed: 0.0429s/iter; left time: 722.6165s\n",
      "\titers: 200, epoch: 26 | loss: 0.0387699\n",
      "\tspeed: 0.0256s/iter; left time: 428.5616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 226 | Train Loss: 0.0415136 Vali Loss: 0.0512980 Test Loss: 0.0542906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0426343\n",
      "\tspeed: 0.0534s/iter; left time: 887.9830s\n",
      "\titers: 200, epoch: 27 | loss: 0.0408687\n",
      "\tspeed: 0.0277s/iter; left time: 458.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0414671 Vali Loss: 0.0512499 Test Loss: 0.0542798\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0407607\n",
      "\tspeed: 0.0511s/iter; left time: 837.4815s\n",
      "\titers: 200, epoch: 28 | loss: 0.0404382\n",
      "\tspeed: 0.0244s/iter; left time: 396.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0414232 Vali Loss: 0.0511967 Test Loss: 0.0542340\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0418660\n",
      "\tspeed: 0.0486s/iter; left time: 785.9019s\n",
      "\titers: 200, epoch: 29 | loss: 0.0461494\n",
      "\tspeed: 0.0233s/iter; left time: 374.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0414108 Vali Loss: 0.0511942 Test Loss: 0.0542963\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0387321\n",
      "\tspeed: 0.0491s/iter; left time: 782.7273s\n",
      "\titers: 200, epoch: 30 | loss: 0.0443478\n",
      "\tspeed: 0.0236s/iter; left time: 373.7893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 226 | Train Loss: 0.0413687 Vali Loss: 0.0511919 Test Loss: 0.0541996\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0386426\n",
      "\tspeed: 0.0491s/iter; left time: 772.4493s\n",
      "\titers: 200, epoch: 31 | loss: 0.0406933\n",
      "\tspeed: 0.0250s/iter; left time: 389.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0413150 Vali Loss: 0.0510859 Test Loss: 0.0542480\n",
      "Validation loss decreased (0.051141 --> 0.051086).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0413825\n",
      "\tspeed: 0.0497s/iter; left time: 769.9086s\n",
      "\titers: 200, epoch: 32 | loss: 0.0430385\n",
      "\tspeed: 0.0265s/iter; left time: 407.9187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0413569 Vali Loss: 0.0511404 Test Loss: 0.0542026\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0414003\n",
      "\tspeed: 0.0488s/iter; left time: 744.4190s\n",
      "\titers: 200, epoch: 33 | loss: 0.0416502\n",
      "\tspeed: 0.0220s/iter; left time: 333.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 226 | Train Loss: 0.0413078 Vali Loss: 0.0511158 Test Loss: 0.0542135\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0440531\n",
      "\tspeed: 0.0431s/iter; left time: 648.1282s\n",
      "\titers: 200, epoch: 34 | loss: 0.0423279\n",
      "\tspeed: 0.0262s/iter; left time: 391.0081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0413079 Vali Loss: 0.0510071 Test Loss: 0.0541874\n",
      "Validation loss decreased (0.051086 --> 0.051007).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0438803\n",
      "\tspeed: 0.0531s/iter; left time: 787.0705s\n",
      "\titers: 200, epoch: 35 | loss: 0.0389386\n",
      "\tspeed: 0.0279s/iter; left time: 410.7558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 226 | Train Loss: 0.0413145 Vali Loss: 0.0511008 Test Loss: 0.0541847\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0472102\n",
      "\tspeed: 0.0507s/iter; left time: 740.2141s\n",
      "\titers: 200, epoch: 36 | loss: 0.0386646\n",
      "\tspeed: 0.0298s/iter; left time: 432.5491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 226 | Train Loss: 0.0413326 Vali Loss: 0.0509946 Test Loss: 0.0541957\n",
      "Validation loss decreased (0.051007 --> 0.050995).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0415711\n",
      "\tspeed: 0.0471s/iter; left time: 676.7013s\n",
      "\titers: 200, epoch: 37 | loss: 0.0403833\n",
      "\tspeed: 0.0231s/iter; left time: 330.1552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 226 | Train Loss: 0.0412730 Vali Loss: 0.0510368 Test Loss: 0.0541667\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0435312\n",
      "\tspeed: 0.0512s/iter; left time: 723.3549s\n",
      "\titers: 200, epoch: 38 | loss: 0.0391161\n",
      "\tspeed: 0.0284s/iter; left time: 399.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 226 | Train Loss: 0.0412630 Vali Loss: 0.0510862 Test Loss: 0.0541457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0423625\n",
      "\tspeed: 0.0543s/iter; left time: 755.9302s\n",
      "\titers: 200, epoch: 39 | loss: 0.0436461\n",
      "\tspeed: 0.0306s/iter; left time: 422.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 226 | Train Loss: 0.0412700 Vali Loss: 0.0510823 Test Loss: 0.0541865\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0388188\n",
      "\tspeed: 0.0464s/iter; left time: 635.6226s\n",
      "\titers: 200, epoch: 40 | loss: 0.0421896\n",
      "\tspeed: 0.0201s/iter; left time: 273.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 226 | Train Loss: 0.0412645 Vali Loss: 0.0511344 Test Loss: 0.0541581\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0416249\n",
      "\tspeed: 0.0444s/iter; left time: 597.6767s\n",
      "\titers: 200, epoch: 41 | loss: 0.0399476\n",
      "\tspeed: 0.0208s/iter; left time: 277.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 226 | Train Loss: 0.0412606 Vali Loss: 0.0511338 Test Loss: 0.0541512\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0414979\n",
      "\tspeed: 0.0523s/iter; left time: 692.3976s\n",
      "\titers: 200, epoch: 42 | loss: 0.0431815\n",
      "\tspeed: 0.0277s/iter; left time: 363.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 226 | Train Loss: 0.0412452 Vali Loss: 0.0511097 Test Loss: 0.0541572\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0408163\n",
      "\tspeed: 0.0463s/iter; left time: 601.8237s\n",
      "\titers: 200, epoch: 43 | loss: 0.0406738\n",
      "\tspeed: 0.0194s/iter; left time: 250.0092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 226 | Train Loss: 0.0412199 Vali Loss: 0.0510517 Test Loss: 0.0541587\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0390890\n",
      "\tspeed: 0.0490s/iter; left time: 626.5797s\n",
      "\titers: 200, epoch: 44 | loss: 0.0395521\n",
      "\tspeed: 0.0295s/iter; left time: 374.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.84s\n",
      "Steps: 226 | Train Loss: 0.0412448 Vali Loss: 0.0510430 Test Loss: 0.0541468\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0431649\n",
      "\tspeed: 0.0496s/iter; left time: 622.6231s\n",
      "\titers: 200, epoch: 45 | loss: 0.0421387\n",
      "\tspeed: 0.0296s/iter; left time: 369.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0412236 Vali Loss: 0.0510134 Test Loss: 0.0541102\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0387131\n",
      "\tspeed: 0.0555s/iter; left time: 684.3485s\n",
      "\titers: 200, epoch: 46 | loss: 0.0402467\n",
      "\tspeed: 0.0338s/iter; left time: 412.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 226 | Train Loss: 0.0412133 Vali Loss: 0.0508858 Test Loss: 0.0541043\n",
      "Validation loss decreased (0.050995 --> 0.050886).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0409243\n",
      "\tspeed: 0.0519s/iter; left time: 628.6759s\n",
      "\titers: 200, epoch: 47 | loss: 0.0427487\n",
      "\tspeed: 0.0292s/iter; left time: 351.0371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0411864 Vali Loss: 0.0510773 Test Loss: 0.0541381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0411739\n",
      "\tspeed: 0.0529s/iter; left time: 628.8035s\n",
      "\titers: 200, epoch: 48 | loss: 0.0400346\n",
      "\tspeed: 0.0298s/iter; left time: 350.6919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 226 | Train Loss: 0.0412303 Vali Loss: 0.0510280 Test Loss: 0.0541061\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0392074\n",
      "\tspeed: 0.0514s/iter; left time: 599.3333s\n",
      "\titers: 200, epoch: 49 | loss: 0.0425270\n",
      "\tspeed: 0.0232s/iter; left time: 268.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0412285 Vali Loss: 0.0510358 Test Loss: 0.0541527\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0410978\n",
      "\tspeed: 0.0429s/iter; left time: 490.1766s\n",
      "\titers: 200, epoch: 50 | loss: 0.0380185\n",
      "\tspeed: 0.0237s/iter; left time: 268.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 226 | Train Loss: 0.0411887 Vali Loss: 0.0510428 Test Loss: 0.0541054\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0409625\n",
      "\tspeed: 0.0551s/iter; left time: 616.6258s\n",
      "\titers: 200, epoch: 51 | loss: 0.0422957\n",
      "\tspeed: 0.0266s/iter; left time: 295.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0412051 Vali Loss: 0.0510952 Test Loss: 0.0541243\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0445837\n",
      "\tspeed: 0.0482s/iter; left time: 528.4640s\n",
      "\titers: 200, epoch: 52 | loss: 0.0395759\n",
      "\tspeed: 0.0237s/iter; left time: 257.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0411853 Vali Loss: 0.0510290 Test Loss: 0.0541174\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0417441\n",
      "\tspeed: 0.0433s/iter; left time: 465.5154s\n",
      "\titers: 200, epoch: 53 | loss: 0.0429232\n",
      "\tspeed: 0.0207s/iter; left time: 220.8348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 226 | Train Loss: 0.0411807 Vali Loss: 0.0510417 Test Loss: 0.0541382\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0413381\n",
      "\tspeed: 0.0488s/iter; left time: 513.9451s\n",
      "\titers: 200, epoch: 54 | loss: 0.0414263\n",
      "\tspeed: 0.0249s/iter; left time: 259.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 226 | Train Loss: 0.0412373 Vali Loss: 0.0510291 Test Loss: 0.0541415\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0415313\n",
      "\tspeed: 0.0495s/iter; left time: 510.0006s\n",
      "\titers: 200, epoch: 55 | loss: 0.0427520\n",
      "\tspeed: 0.0299s/iter; left time: 305.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 226 | Train Loss: 0.0411794 Vali Loss: 0.0510427 Test Loss: 0.0541164\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0402257\n",
      "\tspeed: 0.0542s/iter; left time: 546.0304s\n",
      "\titers: 200, epoch: 56 | loss: 0.0419502\n",
      "\tspeed: 0.0322s/iter; left time: 320.7520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 226 | Train Loss: 0.0411687 Vali Loss: 0.0510630 Test Loss: 0.0541254\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009846783243119717, rmse:0.09923096001148224, mae:0.0541042760014534, rse:0.38283032178878784\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1182429\n",
      "\tspeed: 0.0258s/iter; left time: 580.9970s\n",
      "\titers: 200, epoch: 1 | loss: 0.1087598\n",
      "\tspeed: 0.0242s/iter; left time: 542.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.1173186 Vali Loss: 0.1173352 Test Loss: 0.1300844\n",
      "Validation loss decreased (inf --> 0.117335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0651111\n",
      "\tspeed: 0.0555s/iter; left time: 1237.0380s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529706\n",
      "\tspeed: 0.0243s/iter; left time: 538.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 226 | Train Loss: 0.0664123 Vali Loss: 0.0623895 Test Loss: 0.0646706\n",
      "Validation loss decreased (0.117335 --> 0.062389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472664\n",
      "\tspeed: 0.0492s/iter; left time: 1085.5112s\n",
      "\titers: 200, epoch: 3 | loss: 0.0473599\n",
      "\tspeed: 0.0245s/iter; left time: 538.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0515785 Vali Loss: 0.0584495 Test Loss: 0.0607335\n",
      "Validation loss decreased (0.062389 --> 0.058449).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0478847\n",
      "\tspeed: 0.0472s/iter; left time: 1029.1145s\n",
      "\titers: 200, epoch: 4 | loss: 0.0477668\n",
      "\tspeed: 0.0285s/iter; left time: 618.3240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0488677 Vali Loss: 0.0565804 Test Loss: 0.0591537\n",
      "Validation loss decreased (0.058449 --> 0.056580).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0465839\n",
      "\tspeed: 0.0506s/iter; left time: 1092.4474s\n",
      "\titers: 200, epoch: 5 | loss: 0.0449112\n",
      "\tspeed: 0.0235s/iter; left time: 505.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0472675 Vali Loss: 0.0552322 Test Loss: 0.0579919\n",
      "Validation loss decreased (0.056580 --> 0.055232).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0488357\n",
      "\tspeed: 0.0505s/iter; left time: 1079.7151s\n",
      "\titers: 200, epoch: 6 | loss: 0.0461491\n",
      "\tspeed: 0.0239s/iter; left time: 507.7448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.62s\n",
      "Steps: 226 | Train Loss: 0.0460159 Vali Loss: 0.0541305 Test Loss: 0.0573544\n",
      "Validation loss decreased (0.055232 --> 0.054131).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0451231\n",
      "\tspeed: 0.0485s/iter; left time: 1026.0216s\n",
      "\titers: 200, epoch: 7 | loss: 0.0468216\n",
      "\tspeed: 0.0275s/iter; left time: 579.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0450794 Vali Loss: 0.0535126 Test Loss: 0.0566724\n",
      "Validation loss decreased (0.054131 --> 0.053513).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0442903\n",
      "\tspeed: 0.0458s/iter; left time: 958.7857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449988\n",
      "\tspeed: 0.0257s/iter; left time: 535.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 226 | Train Loss: 0.0443544 Vali Loss: 0.0528316 Test Loss: 0.0561518\n",
      "Validation loss decreased (0.053513 --> 0.052832).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0455078\n",
      "\tspeed: 0.0480s/iter; left time: 992.5128s\n",
      "\titers: 200, epoch: 9 | loss: 0.0443731\n",
      "\tspeed: 0.0271s/iter; left time: 558.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 226 | Train Loss: 0.0438602 Vali Loss: 0.0526205 Test Loss: 0.0557751\n",
      "Validation loss decreased (0.052832 --> 0.052621).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0415070\n",
      "\tspeed: 0.0528s/iter; left time: 1080.2887s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402026\n",
      "\tspeed: 0.0226s/iter; left time: 459.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0434354 Vali Loss: 0.0523072 Test Loss: 0.0554496\n",
      "Validation loss decreased (0.052621 --> 0.052307).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0426357\n",
      "\tspeed: 0.0524s/iter; left time: 1061.3547s\n",
      "\titers: 200, epoch: 11 | loss: 0.0414191\n",
      "\tspeed: 0.0273s/iter; left time: 549.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0431586 Vali Loss: 0.0521097 Test Loss: 0.0554314\n",
      "Validation loss decreased (0.052307 --> 0.052110).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0400768\n",
      "\tspeed: 0.0488s/iter; left time: 977.7067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0436677\n",
      "\tspeed: 0.0195s/iter; left time: 387.6644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 226 | Train Loss: 0.0429084 Vali Loss: 0.0518410 Test Loss: 0.0551395\n",
      "Validation loss decreased (0.052110 --> 0.051841).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0407224\n",
      "\tspeed: 0.0497s/iter; left time: 982.5913s\n",
      "\titers: 200, epoch: 13 | loss: 0.0394750\n",
      "\tspeed: 0.0295s/iter; left time: 580.2304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0426601 Vali Loss: 0.0517847 Test Loss: 0.0551147\n",
      "Validation loss decreased (0.051841 --> 0.051785).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0423878\n",
      "\tspeed: 0.0554s/iter; left time: 1083.0515s\n",
      "\titers: 200, epoch: 14 | loss: 0.0439840\n",
      "\tspeed: 0.0218s/iter; left time: 424.4968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 226 | Train Loss: 0.0424838 Vali Loss: 0.0516804 Test Loss: 0.0550191\n",
      "Validation loss decreased (0.051785 --> 0.051680).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0434851\n",
      "\tspeed: 0.0508s/iter; left time: 982.9505s\n",
      "\titers: 200, epoch: 15 | loss: 0.0416624\n",
      "\tspeed: 0.0192s/iter; left time: 368.4748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0423361 Vali Loss: 0.0515615 Test Loss: 0.0548344\n",
      "Validation loss decreased (0.051680 --> 0.051562).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0426293\n",
      "\tspeed: 0.0509s/iter; left time: 973.3632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0461580\n",
      "\tspeed: 0.0269s/iter; left time: 510.9818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 226 | Train Loss: 0.0422033 Vali Loss: 0.0514735 Test Loss: 0.0548638\n",
      "Validation loss decreased (0.051562 --> 0.051473).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0383031\n",
      "\tspeed: 0.0477s/iter; left time: 900.5786s\n",
      "\titers: 200, epoch: 17 | loss: 0.0399342\n",
      "\tspeed: 0.0239s/iter; left time: 448.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0421454 Vali Loss: 0.0513158 Test Loss: 0.0547536\n",
      "Validation loss decreased (0.051473 --> 0.051316).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0412194\n",
      "\tspeed: 0.0499s/iter; left time: 931.5355s\n",
      "\titers: 200, epoch: 18 | loss: 0.0429672\n",
      "\tspeed: 0.0252s/iter; left time: 467.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0419960 Vali Loss: 0.0514539 Test Loss: 0.0548421\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0393095\n",
      "\tspeed: 0.0492s/iter; left time: 906.4209s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441770\n",
      "\tspeed: 0.0209s/iter; left time: 383.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 226 | Train Loss: 0.0419091 Vali Loss: 0.0512217 Test Loss: 0.0546638\n",
      "Validation loss decreased (0.051316 --> 0.051222).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0420669\n",
      "\tspeed: 0.0570s/iter; left time: 1037.0022s\n",
      "\titers: 200, epoch: 20 | loss: 0.0409727\n",
      "\tspeed: 0.0306s/iter; left time: 553.8873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0417591 Vali Loss: 0.0512575 Test Loss: 0.0545752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0456082\n",
      "\tspeed: 0.0517s/iter; left time: 928.8116s\n",
      "\titers: 200, epoch: 21 | loss: 0.0407613\n",
      "\tspeed: 0.0256s/iter; left time: 457.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 226 | Train Loss: 0.0417115 Vali Loss: 0.0513524 Test Loss: 0.0546071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0430730\n",
      "\tspeed: 0.0533s/iter; left time: 947.2073s\n",
      "\titers: 200, epoch: 22 | loss: 0.0423018\n",
      "\tspeed: 0.0247s/iter; left time: 436.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0416839 Vali Loss: 0.0512003 Test Loss: 0.0545036\n",
      "Validation loss decreased (0.051222 --> 0.051200).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0401441\n",
      "\tspeed: 0.0477s/iter; left time: 835.3917s\n",
      "\titers: 200, epoch: 23 | loss: 0.0436835\n",
      "\tspeed: 0.0237s/iter; left time: 413.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0416036 Vali Loss: 0.0512747 Test Loss: 0.0545001\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0411001\n",
      "\tspeed: 0.0452s/iter; left time: 781.6859s\n",
      "\titers: 200, epoch: 24 | loss: 0.0383674\n",
      "\tspeed: 0.0266s/iter; left time: 457.6856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 226 | Train Loss: 0.0415666 Vali Loss: 0.0512336 Test Loss: 0.0545423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0430113\n",
      "\tspeed: 0.0445s/iter; left time: 759.6149s\n",
      "\titers: 200, epoch: 25 | loss: 0.0411178\n",
      "\tspeed: 0.0244s/iter; left time: 413.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 226 | Train Loss: 0.0415223 Vali Loss: 0.0511620 Test Loss: 0.0545256\n",
      "Validation loss decreased (0.051200 --> 0.051162).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0394535\n",
      "\tspeed: 0.0501s/iter; left time: 844.7345s\n",
      "\titers: 200, epoch: 26 | loss: 0.0408899\n",
      "\tspeed: 0.0298s/iter; left time: 499.5723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 226 | Train Loss: 0.0414990 Vali Loss: 0.0510829 Test Loss: 0.0545045\n",
      "Validation loss decreased (0.051162 --> 0.051083).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0401787\n",
      "\tspeed: 0.0518s/iter; left time: 861.5923s\n",
      "\titers: 200, epoch: 27 | loss: 0.0434536\n",
      "\tspeed: 0.0226s/iter; left time: 374.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 226 | Train Loss: 0.0414874 Vali Loss: 0.0511563 Test Loss: 0.0544282\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0423668\n",
      "\tspeed: 0.0451s/iter; left time: 739.7172s\n",
      "\titers: 200, epoch: 28 | loss: 0.0422014\n",
      "\tspeed: 0.0186s/iter; left time: 303.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 226 | Train Loss: 0.0414652 Vali Loss: 0.0510324 Test Loss: 0.0544592\n",
      "Validation loss decreased (0.051083 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0407290\n",
      "\tspeed: 0.0492s/iter; left time: 795.3732s\n",
      "\titers: 200, epoch: 29 | loss: 0.0407079\n",
      "\tspeed: 0.0246s/iter; left time: 395.4301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0413912 Vali Loss: 0.0510565 Test Loss: 0.0544063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0460965\n",
      "\tspeed: 0.0446s/iter; left time: 711.5648s\n",
      "\titers: 200, epoch: 30 | loss: 0.0401905\n",
      "\tspeed: 0.0221s/iter; left time: 350.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 226 | Train Loss: 0.0414160 Vali Loss: 0.0510849 Test Loss: 0.0543769\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0401029\n",
      "\tspeed: 0.0462s/iter; left time: 725.5853s\n",
      "\titers: 200, epoch: 31 | loss: 0.0418141\n",
      "\tspeed: 0.0265s/iter; left time: 414.2903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0413730 Vali Loss: 0.0510531 Test Loss: 0.0543816\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0405486\n",
      "\tspeed: 0.0467s/iter; left time: 723.0925s\n",
      "\titers: 200, epoch: 32 | loss: 0.0379125\n",
      "\tspeed: 0.0274s/iter; left time: 422.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0413438 Vali Loss: 0.0510413 Test Loss: 0.0543643\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0401707\n",
      "\tspeed: 0.0492s/iter; left time: 751.4719s\n",
      "\titers: 200, epoch: 33 | loss: 0.0397618\n",
      "\tspeed: 0.0252s/iter; left time: 381.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 226 | Train Loss: 0.0412806 Vali Loss: 0.0511042 Test Loss: 0.0544257\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0418254\n",
      "\tspeed: 0.0465s/iter; left time: 699.6537s\n",
      "\titers: 200, epoch: 34 | loss: 0.0396528\n",
      "\tspeed: 0.0255s/iter; left time: 381.6757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 226 | Train Loss: 0.0413203 Vali Loss: 0.0510538 Test Loss: 0.0543853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0423622\n",
      "\tspeed: 0.0486s/iter; left time: 719.4765s\n",
      "\titers: 200, epoch: 35 | loss: 0.0448219\n",
      "\tspeed: 0.0281s/iter; left time: 413.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 226 | Train Loss: 0.0412818 Vali Loss: 0.0510316 Test Loss: 0.0543432\n",
      "Validation loss decreased (0.051032 --> 0.051032).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0420344\n",
      "\tspeed: 0.0547s/iter; left time: 798.0869s\n",
      "\titers: 200, epoch: 36 | loss: 0.0410500\n",
      "\tspeed: 0.0263s/iter; left time: 381.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 226 | Train Loss: 0.0412932 Vali Loss: 0.0510304 Test Loss: 0.0543913\n",
      "Validation loss decreased (0.051032 --> 0.051030).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0428056\n",
      "\tspeed: 0.0535s/iter; left time: 769.0850s\n",
      "\titers: 200, epoch: 37 | loss: 0.0405213\n",
      "\tspeed: 0.0230s/iter; left time: 328.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 226 | Train Loss: 0.0412726 Vali Loss: 0.0510981 Test Loss: 0.0543641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0408890\n",
      "\tspeed: 0.0434s/iter; left time: 613.9895s\n",
      "\titers: 200, epoch: 38 | loss: 0.0412078\n",
      "\tspeed: 0.0234s/iter; left time: 328.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0412846 Vali Loss: 0.0510122 Test Loss: 0.0544314\n",
      "Validation loss decreased (0.051030 --> 0.051012).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0425402\n",
      "\tspeed: 0.0501s/iter; left time: 696.6970s\n",
      "\titers: 200, epoch: 39 | loss: 0.0458580\n",
      "\tspeed: 0.0236s/iter; left time: 325.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 226 | Train Loss: 0.0412711 Vali Loss: 0.0510318 Test Loss: 0.0543933\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0436337\n",
      "\tspeed: 0.0519s/iter; left time: 710.7051s\n",
      "\titers: 200, epoch: 40 | loss: 0.0391848\n",
      "\tspeed: 0.0300s/iter; left time: 407.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 226 | Train Loss: 0.0412898 Vali Loss: 0.0510104 Test Loss: 0.0543356\n",
      "Validation loss decreased (0.051012 --> 0.051010).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0438826\n",
      "\tspeed: 0.0456s/iter; left time: 614.2154s\n",
      "\titers: 200, epoch: 41 | loss: 0.0409017\n",
      "\tspeed: 0.0187s/iter; left time: 249.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.84s\n",
      "Steps: 226 | Train Loss: 0.0412321 Vali Loss: 0.0510284 Test Loss: 0.0543539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0392837\n",
      "\tspeed: 0.0455s/iter; left time: 602.4075s\n",
      "\titers: 200, epoch: 42 | loss: 0.0423266\n",
      "\tspeed: 0.0228s/iter; left time: 300.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 226 | Train Loss: 0.0412172 Vali Loss: 0.0510499 Test Loss: 0.0544103\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0420753\n",
      "\tspeed: 0.0577s/iter; left time: 749.9806s\n",
      "\titers: 200, epoch: 43 | loss: 0.0390433\n",
      "\tspeed: 0.0305s/iter; left time: 393.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 226 | Train Loss: 0.0412348 Vali Loss: 0.0509948 Test Loss: 0.0543997\n",
      "Validation loss decreased (0.051010 --> 0.050995).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0427173\n",
      "\tspeed: 0.0566s/iter; left time: 723.5453s\n",
      "\titers: 200, epoch: 44 | loss: 0.0422384\n",
      "\tspeed: 0.0244s/iter; left time: 309.3547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0411777 Vali Loss: 0.0510399 Test Loss: 0.0543750\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0430857\n",
      "\tspeed: 0.0509s/iter; left time: 638.6249s\n",
      "\titers: 200, epoch: 45 | loss: 0.0400429\n",
      "\tspeed: 0.0284s/iter; left time: 353.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0412277 Vali Loss: 0.0510145 Test Loss: 0.0543994\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0385433\n",
      "\tspeed: 0.0490s/iter; left time: 604.5331s\n",
      "\titers: 200, epoch: 46 | loss: 0.0414090\n",
      "\tspeed: 0.0317s/iter; left time: 387.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 226 | Train Loss: 0.0412204 Vali Loss: 0.0509589 Test Loss: 0.0543231\n",
      "Validation loss decreased (0.050995 --> 0.050959).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0402943\n",
      "\tspeed: 0.0489s/iter; left time: 592.0995s\n",
      "\titers: 200, epoch: 47 | loss: 0.0385111\n",
      "\tspeed: 0.0248s/iter; left time: 298.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0412128 Vali Loss: 0.0509588 Test Loss: 0.0543431\n",
      "Validation loss decreased (0.050959 --> 0.050959).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0420539\n",
      "\tspeed: 0.0471s/iter; left time: 559.4235s\n",
      "\titers: 200, epoch: 48 | loss: 0.0414722\n",
      "\tspeed: 0.0186s/iter; left time: 219.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 226 | Train Loss: 0.0411918 Vali Loss: 0.0509552 Test Loss: 0.0543449\n",
      "Validation loss decreased (0.050959 --> 0.050955).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0404456\n",
      "\tspeed: 0.0518s/iter; left time: 604.1721s\n",
      "\titers: 200, epoch: 49 | loss: 0.0390682\n",
      "\tspeed: 0.0295s/iter; left time: 340.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0412032 Vali Loss: 0.0510119 Test Loss: 0.0543529\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0413699\n",
      "\tspeed: 0.0543s/iter; left time: 620.2605s\n",
      "\titers: 200, epoch: 50 | loss: 0.0430498\n",
      "\tspeed: 0.0252s/iter; left time: 285.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0411565 Vali Loss: 0.0509348 Test Loss: 0.0543352\n",
      "Validation loss decreased (0.050955 --> 0.050935).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0433248\n",
      "\tspeed: 0.0452s/iter; left time: 506.5995s\n",
      "\titers: 200, epoch: 51 | loss: 0.0433756\n",
      "\tspeed: 0.0254s/iter; left time: 281.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 226 | Train Loss: 0.0412128 Vali Loss: 0.0509672 Test Loss: 0.0543227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0455864\n",
      "\tspeed: 0.0459s/iter; left time: 503.9862s\n",
      "\titers: 200, epoch: 52 | loss: 0.0373759\n",
      "\tspeed: 0.0268s/iter; left time: 291.5502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0412307 Vali Loss: 0.0510274 Test Loss: 0.0543177\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0362533\n",
      "\tspeed: 0.0469s/iter; left time: 503.7876s\n",
      "\titers: 200, epoch: 53 | loss: 0.0392829\n",
      "\tspeed: 0.0276s/iter; left time: 293.7810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 226 | Train Loss: 0.0412029 Vali Loss: 0.0509258 Test Loss: 0.0543313\n",
      "Validation loss decreased (0.050935 --> 0.050926).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0384007\n",
      "\tspeed: 0.0484s/iter; left time: 509.8368s\n",
      "\titers: 200, epoch: 54 | loss: 0.0386209\n",
      "\tspeed: 0.0294s/iter; left time: 306.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 226 | Train Loss: 0.0411951 Vali Loss: 0.0510010 Test Loss: 0.0543542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0395590\n",
      "\tspeed: 0.0477s/iter; left time: 491.3463s\n",
      "\titers: 200, epoch: 55 | loss: 0.0431799\n",
      "\tspeed: 0.0259s/iter; left time: 263.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0411490 Vali Loss: 0.0509527 Test Loss: 0.0543082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0409292\n",
      "\tspeed: 0.0512s/iter; left time: 515.4983s\n",
      "\titers: 200, epoch: 56 | loss: 0.0384964\n",
      "\tspeed: 0.0277s/iter; left time: 276.3543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 226 | Train Loss: 0.0411532 Vali Loss: 0.0508853 Test Loss: 0.0543533\n",
      "Validation loss decreased (0.050926 --> 0.050885).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0408892\n",
      "\tspeed: 0.0503s/iter; left time: 495.1290s\n",
      "\titers: 200, epoch: 57 | loss: 0.0383844\n",
      "\tspeed: 0.0280s/iter; left time: 273.0488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 226 | Train Loss: 0.0412010 Vali Loss: 0.0509888 Test Loss: 0.0543061\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0397936\n",
      "\tspeed: 0.0512s/iter; left time: 492.7793s\n",
      "\titers: 200, epoch: 58 | loss: 0.0405686\n",
      "\tspeed: 0.0279s/iter; left time: 265.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0411393 Vali Loss: 0.0508974 Test Loss: 0.0543278\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0416370\n",
      "\tspeed: 0.0476s/iter; left time: 447.1507s\n",
      "\titers: 200, epoch: 59 | loss: 0.0448846\n",
      "\tspeed: 0.0263s/iter; left time: 244.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 226 | Train Loss: 0.0412174 Vali Loss: 0.0509768 Test Loss: 0.0543235\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0410431\n",
      "\tspeed: 0.0477s/iter; left time: 437.0455s\n",
      "\titers: 200, epoch: 60 | loss: 0.0403395\n",
      "\tspeed: 0.0270s/iter; left time: 244.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.27s\n",
      "Steps: 226 | Train Loss: 0.0412172 Vali Loss: 0.0509386 Test Loss: 0.0543214\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0416200\n",
      "\tspeed: 0.0455s/iter; left time: 406.6081s\n",
      "\titers: 200, epoch: 61 | loss: 0.0424872\n",
      "\tspeed: 0.0223s/iter; left time: 197.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 226 | Train Loss: 0.0411801 Vali Loss: 0.0509546 Test Loss: 0.0543453\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0361256\n",
      "\tspeed: 0.0446s/iter; left time: 388.9664s\n",
      "\titers: 200, epoch: 62 | loss: 0.0402691\n",
      "\tspeed: 0.0269s/iter; left time: 231.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 226 | Train Loss: 0.0411739 Vali Loss: 0.0509681 Test Loss: 0.0543445\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0424508\n",
      "\tspeed: 0.0484s/iter; left time: 410.6147s\n",
      "\titers: 200, epoch: 63 | loss: 0.0425622\n",
      "\tspeed: 0.0201s/iter; left time: 168.3736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 226 | Train Loss: 0.0411551 Vali Loss: 0.0509861 Test Loss: 0.0543499\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0397099\n",
      "\tspeed: 0.0458s/iter; left time: 378.0383s\n",
      "\titers: 200, epoch: 64 | loss: 0.0410833\n",
      "\tspeed: 0.0263s/iter; left time: 214.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 226 | Train Loss: 0.0411703 Vali Loss: 0.0509164 Test Loss: 0.0543010\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0404438\n",
      "\tspeed: 0.0504s/iter; left time: 404.9438s\n",
      "\titers: 200, epoch: 65 | loss: 0.0409320\n",
      "\tspeed: 0.0250s/iter; left time: 198.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 226 | Train Loss: 0.0411614 Vali Loss: 0.0509447 Test Loss: 0.0543172\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0451697\n",
      "\tspeed: 0.0468s/iter; left time: 365.8001s\n",
      "\titers: 200, epoch: 66 | loss: 0.0403475\n",
      "\tspeed: 0.0238s/iter; left time: 183.2684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 226 | Train Loss: 0.0411995 Vali Loss: 0.0509420 Test Loss: 0.0543792\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_24_FR_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009954087436199188, rmse:0.09977017343044281, mae:0.05435333773493767, rse:0.384910523891449\n",
      "Intermediate time for FR and pred_len 24: 00h:15m:26.60s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1220741\n",
      "\tspeed: 0.0506s/iter; left time: 1132.7418s\n",
      "\titers: 200, epoch: 1 | loss: 0.1146931\n",
      "\tspeed: 0.0247s/iter; left time: 550.5026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.1229160 Vali Loss: 0.1261277 Test Loss: 0.1432174\n",
      "Validation loss decreased (inf --> 0.126128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0742138\n",
      "\tspeed: 0.0462s/iter; left time: 1025.1202s\n",
      "\titers: 200, epoch: 2 | loss: 0.0697527\n",
      "\tspeed: 0.0254s/iter; left time: 560.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 225 | Train Loss: 0.0799607 Vali Loss: 0.0787864 Test Loss: 0.0867982\n",
      "Validation loss decreased (0.126128 --> 0.078786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0669011\n",
      "\tspeed: 0.0531s/iter; left time: 1165.8389s\n",
      "\titers: 200, epoch: 3 | loss: 0.0681493\n",
      "\tspeed: 0.0295s/iter; left time: 645.3308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 225 | Train Loss: 0.0672110 Vali Loss: 0.0753967 Test Loss: 0.0838328\n",
      "Validation loss decreased (0.078786 --> 0.075397).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0665823\n",
      "\tspeed: 0.0642s/iter; left time: 1395.3642s\n",
      "\titers: 200, epoch: 4 | loss: 0.0666709\n",
      "\tspeed: 0.0319s/iter; left time: 689.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 225 | Train Loss: 0.0649054 Vali Loss: 0.0735958 Test Loss: 0.0825490\n",
      "Validation loss decreased (0.075397 --> 0.073596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616264\n",
      "\tspeed: 0.0541s/iter; left time: 1163.2913s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608241\n",
      "\tspeed: 0.0308s/iter; left time: 659.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0630447 Vali Loss: 0.0720382 Test Loss: 0.0814225\n",
      "Validation loss decreased (0.073596 --> 0.072038).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0619600\n",
      "\tspeed: 0.0512s/iter; left time: 1089.5306s\n",
      "\titers: 200, epoch: 6 | loss: 0.0598352\n",
      "\tspeed: 0.0283s/iter; left time: 599.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 225 | Train Loss: 0.0616488 Vali Loss: 0.0713768 Test Loss: 0.0808180\n",
      "Validation loss decreased (0.072038 --> 0.071377).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0632396\n",
      "\tspeed: 0.0498s/iter; left time: 1047.4369s\n",
      "\titers: 200, epoch: 7 | loss: 0.0662241\n",
      "\tspeed: 0.0253s/iter; left time: 529.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 225 | Train Loss: 0.0608829 Vali Loss: 0.0711699 Test Loss: 0.0803994\n",
      "Validation loss decreased (0.071377 --> 0.071170).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0579971\n",
      "\tspeed: 0.0586s/iter; left time: 1220.6730s\n",
      "\titers: 200, epoch: 8 | loss: 0.0584228\n",
      "\tspeed: 0.0273s/iter; left time: 566.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0603736 Vali Loss: 0.0708177 Test Loss: 0.0803240\n",
      "Validation loss decreased (0.071170 --> 0.070818).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604323\n",
      "\tspeed: 0.0503s/iter; left time: 1035.4719s\n",
      "\titers: 200, epoch: 9 | loss: 0.0596516\n",
      "\tspeed: 0.0285s/iter; left time: 584.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0599084 Vali Loss: 0.0707924 Test Loss: 0.0800577\n",
      "Validation loss decreased (0.070818 --> 0.070792).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0582479\n",
      "\tspeed: 0.0528s/iter; left time: 1075.2759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610579\n",
      "\tspeed: 0.0278s/iter; left time: 563.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0596372 Vali Loss: 0.0706747 Test Loss: 0.0800745\n",
      "Validation loss decreased (0.070792 --> 0.070675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0596562\n",
      "\tspeed: 0.0558s/iter; left time: 1124.3311s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598316\n",
      "\tspeed: 0.0301s/iter; left time: 602.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0593520 Vali Loss: 0.0706221 Test Loss: 0.0800105\n",
      "Validation loss decreased (0.070675 --> 0.070622).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0540255\n",
      "\tspeed: 0.0559s/iter; left time: 1114.6240s\n",
      "\titers: 200, epoch: 12 | loss: 0.0580481\n",
      "\tspeed: 0.0296s/iter; left time: 586.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0591023 Vali Loss: 0.0705149 Test Loss: 0.0799026\n",
      "Validation loss decreased (0.070622 --> 0.070515).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586757\n",
      "\tspeed: 0.0499s/iter; left time: 983.4344s\n",
      "\titers: 200, epoch: 13 | loss: 0.0574660\n",
      "\tspeed: 0.0304s/iter; left time: 595.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 225 | Train Loss: 0.0588783 Vali Loss: 0.0703367 Test Loss: 0.0797316\n",
      "Validation loss decreased (0.070515 --> 0.070337).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603708\n",
      "\tspeed: 0.0524s/iter; left time: 1020.4457s\n",
      "\titers: 200, epoch: 14 | loss: 0.0608521\n",
      "\tspeed: 0.0194s/iter; left time: 375.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.0587461 Vali Loss: 0.0703455 Test Loss: 0.0796405\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571587\n",
      "\tspeed: 0.0535s/iter; left time: 1029.8471s\n",
      "\titers: 200, epoch: 15 | loss: 0.0585860\n",
      "\tspeed: 0.0312s/iter; left time: 597.8993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0585486 Vali Loss: 0.0702861 Test Loss: 0.0797806\n",
      "Validation loss decreased (0.070337 --> 0.070286).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569398\n",
      "\tspeed: 0.0452s/iter; left time: 860.1652s\n",
      "\titers: 200, epoch: 16 | loss: 0.0590494\n",
      "\tspeed: 0.0310s/iter; left time: 586.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.0584513 Vali Loss: 0.0702889 Test Loss: 0.0797580\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571058\n",
      "\tspeed: 0.0610s/iter; left time: 1146.5135s\n",
      "\titers: 200, epoch: 17 | loss: 0.0555347\n",
      "\tspeed: 0.0322s/iter; left time: 601.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 225 | Train Loss: 0.0583301 Vali Loss: 0.0702149 Test Loss: 0.0796651\n",
      "Validation loss decreased (0.070286 --> 0.070215).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0558115\n",
      "\tspeed: 0.0539s/iter; left time: 1000.5664s\n",
      "\titers: 200, epoch: 18 | loss: 0.0614593\n",
      "\tspeed: 0.0274s/iter; left time: 506.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0582152 Vali Loss: 0.0701965 Test Loss: 0.0797421\n",
      "Validation loss decreased (0.070215 --> 0.070197).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0578019\n",
      "\tspeed: 0.0522s/iter; left time: 958.7890s\n",
      "\titers: 200, epoch: 19 | loss: 0.0571534\n",
      "\tspeed: 0.0249s/iter; left time: 454.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0581612 Vali Loss: 0.0701740 Test Loss: 0.0796154\n",
      "Validation loss decreased (0.070197 --> 0.070174).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0603194\n",
      "\tspeed: 0.0489s/iter; left time: 886.1364s\n",
      "\titers: 200, epoch: 20 | loss: 0.0608253\n",
      "\tspeed: 0.0273s/iter; left time: 492.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0580238 Vali Loss: 0.0701691 Test Loss: 0.0796968\n",
      "Validation loss decreased (0.070174 --> 0.070169).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0547900\n",
      "\tspeed: 0.0572s/iter; left time: 1023.4929s\n",
      "\titers: 200, epoch: 21 | loss: 0.0575892\n",
      "\tspeed: 0.0322s/iter; left time: 573.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 225 | Train Loss: 0.0579985 Vali Loss: 0.0702100 Test Loss: 0.0796268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0571349\n",
      "\tspeed: 0.0518s/iter; left time: 915.5777s\n",
      "\titers: 200, epoch: 22 | loss: 0.0592960\n",
      "\tspeed: 0.0316s/iter; left time: 555.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 225 | Train Loss: 0.0579128 Vali Loss: 0.0701129 Test Loss: 0.0797642\n",
      "Validation loss decreased (0.070169 --> 0.070113).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0567881\n",
      "\tspeed: 0.0533s/iter; left time: 930.3161s\n",
      "\titers: 200, epoch: 23 | loss: 0.0578356\n",
      "\tspeed: 0.0288s/iter; left time: 500.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0578414 Vali Loss: 0.0700759 Test Loss: 0.0796640\n",
      "Validation loss decreased (0.070113 --> 0.070076).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0588220\n",
      "\tspeed: 0.0577s/iter; left time: 994.4895s\n",
      "\titers: 200, epoch: 24 | loss: 0.0592831\n",
      "\tspeed: 0.0311s/iter; left time: 532.0358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 225 | Train Loss: 0.0577965 Vali Loss: 0.0700834 Test Loss: 0.0796844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0585203\n",
      "\tspeed: 0.0563s/iter; left time: 957.3886s\n",
      "\titers: 200, epoch: 25 | loss: 0.0556729\n",
      "\tspeed: 0.0304s/iter; left time: 513.2272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0577600 Vali Loss: 0.0701371 Test Loss: 0.0798421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0540029\n",
      "\tspeed: 0.0559s/iter; left time: 938.3910s\n",
      "\titers: 200, epoch: 26 | loss: 0.0571991\n",
      "\tspeed: 0.0257s/iter; left time: 427.7577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0577176 Vali Loss: 0.0700682 Test Loss: 0.0797211\n",
      "Validation loss decreased (0.070076 --> 0.070068).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0591816\n",
      "\tspeed: 0.0537s/iter; left time: 889.0366s\n",
      "\titers: 200, epoch: 27 | loss: 0.0545728\n",
      "\tspeed: 0.0280s/iter; left time: 460.2271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0576992 Vali Loss: 0.0700617 Test Loss: 0.0797237\n",
      "Validation loss decreased (0.070068 --> 0.070062).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0617053\n",
      "\tspeed: 0.0534s/iter; left time: 871.1085s\n",
      "\titers: 200, epoch: 28 | loss: 0.0574315\n",
      "\tspeed: 0.0274s/iter; left time: 444.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0576387 Vali Loss: 0.0700271 Test Loss: 0.0797314\n",
      "Validation loss decreased (0.070062 --> 0.070027).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0517652\n",
      "\tspeed: 0.0552s/iter; left time: 887.9829s\n",
      "\titers: 200, epoch: 29 | loss: 0.0597316\n",
      "\tspeed: 0.0286s/iter; left time: 456.9283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0576450 Vali Loss: 0.0700293 Test Loss: 0.0797632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0542691\n",
      "\tspeed: 0.0518s/iter; left time: 822.4959s\n",
      "\titers: 200, epoch: 30 | loss: 0.0595843\n",
      "\tspeed: 0.0253s/iter; left time: 399.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0575834 Vali Loss: 0.0700706 Test Loss: 0.0796918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0550818\n",
      "\tspeed: 0.0505s/iter; left time: 790.4459s\n",
      "\titers: 200, epoch: 31 | loss: 0.0559612\n",
      "\tspeed: 0.0271s/iter; left time: 420.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0575502 Vali Loss: 0.0700366 Test Loss: 0.0797195\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0598395\n",
      "\tspeed: 0.0529s/iter; left time: 816.2085s\n",
      "\titers: 200, epoch: 32 | loss: 0.0588521\n",
      "\tspeed: 0.0297s/iter; left time: 454.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0575711 Vali Loss: 0.0700139 Test Loss: 0.0796878\n",
      "Validation loss decreased (0.070027 --> 0.070014).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0565253\n",
      "\tspeed: 0.0533s/iter; left time: 810.5258s\n",
      "\titers: 200, epoch: 33 | loss: 0.0593845\n",
      "\tspeed: 0.0256s/iter; left time: 385.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0575217 Vali Loss: 0.0700382 Test Loss: 0.0797146\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0580082\n",
      "\tspeed: 0.0488s/iter; left time: 730.6147s\n",
      "\titers: 200, epoch: 34 | loss: 0.0597742\n",
      "\tspeed: 0.0203s/iter; left time: 301.8981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 225 | Train Loss: 0.0575363 Vali Loss: 0.0700428 Test Loss: 0.0797535\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0547218\n",
      "\tspeed: 0.0572s/iter; left time: 843.9688s\n",
      "\titers: 200, epoch: 35 | loss: 0.0592895\n",
      "\tspeed: 0.0302s/iter; left time: 442.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 225 | Train Loss: 0.0575481 Vali Loss: 0.0700124 Test Loss: 0.0797147\n",
      "Validation loss decreased (0.070014 --> 0.070012).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0589458\n",
      "\tspeed: 0.0492s/iter; left time: 714.6912s\n",
      "\titers: 200, epoch: 36 | loss: 0.0574722\n",
      "\tspeed: 0.0271s/iter; left time: 390.6720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 225 | Train Loss: 0.0574943 Vali Loss: 0.0700254 Test Loss: 0.0796877\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0615762\n",
      "\tspeed: 0.0544s/iter; left time: 778.2482s\n",
      "\titers: 200, epoch: 37 | loss: 0.0569741\n",
      "\tspeed: 0.0307s/iter; left time: 436.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0575015 Vali Loss: 0.0700170 Test Loss: 0.0797144\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0595051\n",
      "\tspeed: 0.0534s/iter; left time: 751.0762s\n",
      "\titers: 200, epoch: 38 | loss: 0.0563165\n",
      "\tspeed: 0.0305s/iter; left time: 426.4737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.10s\n",
      "Steps: 225 | Train Loss: 0.0574755 Vali Loss: 0.0700329 Test Loss: 0.0796785\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0547463\n",
      "\tspeed: 0.0601s/iter; left time: 831.9454s\n",
      "\titers: 200, epoch: 39 | loss: 0.0586968\n",
      "\tspeed: 0.0290s/iter; left time: 399.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 225 | Train Loss: 0.0574457 Vali Loss: 0.0700329 Test Loss: 0.0797462\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0591344\n",
      "\tspeed: 0.0483s/iter; left time: 657.5722s\n",
      "\titers: 200, epoch: 40 | loss: 0.0548586\n",
      "\tspeed: 0.0255s/iter; left time: 345.1851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0574429 Vali Loss: 0.0700195 Test Loss: 0.0797313\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0567012\n",
      "\tspeed: 0.0506s/iter; left time: 678.6717s\n",
      "\titers: 200, epoch: 41 | loss: 0.0549469\n",
      "\tspeed: 0.0301s/iter; left time: 400.3929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 225 | Train Loss: 0.0574303 Vali Loss: 0.0700485 Test Loss: 0.0798056\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0558322\n",
      "\tspeed: 0.0493s/iter; left time: 649.7967s\n",
      "\titers: 200, epoch: 42 | loss: 0.0558083\n",
      "\tspeed: 0.0290s/iter; left time: 379.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0574319 Vali Loss: 0.0700218 Test Loss: 0.0797209\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0572975\n",
      "\tspeed: 0.0488s/iter; left time: 631.9960s\n",
      "\titers: 200, epoch: 43 | loss: 0.0564682\n",
      "\tspeed: 0.0298s/iter; left time: 383.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0574159 Vali Loss: 0.0700373 Test Loss: 0.0797657\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0559593\n",
      "\tspeed: 0.0524s/iter; left time: 666.7368s\n",
      "\titers: 200, epoch: 44 | loss: 0.0582130\n",
      "\tspeed: 0.0252s/iter; left time: 317.8728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 225 | Train Loss: 0.0575009 Vali Loss: 0.0700108 Test Loss: 0.0797607\n",
      "Validation loss decreased (0.070012 --> 0.070011).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0571633\n",
      "\tspeed: 0.0543s/iter; left time: 678.7832s\n",
      "\titers: 200, epoch: 45 | loss: 0.0607090\n",
      "\tspeed: 0.0271s/iter; left time: 336.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.82s\n",
      "Steps: 225 | Train Loss: 0.0573783 Vali Loss: 0.0700036 Test Loss: 0.0797414\n",
      "Validation loss decreased (0.070011 --> 0.070004).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0591639\n",
      "\tspeed: 0.0495s/iter; left time: 607.8419s\n",
      "\titers: 200, epoch: 46 | loss: 0.0576543\n",
      "\tspeed: 0.0278s/iter; left time: 338.9153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 225 | Train Loss: 0.0574136 Vali Loss: 0.0700246 Test Loss: 0.0797608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0583863\n",
      "\tspeed: 0.0452s/iter; left time: 544.7970s\n",
      "\titers: 200, epoch: 47 | loss: 0.0595122\n",
      "\tspeed: 0.0280s/iter; left time: 334.9496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0573917 Vali Loss: 0.0700042 Test Loss: 0.0797391\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0520317\n",
      "\tspeed: 0.0527s/iter; left time: 623.2045s\n",
      "\titers: 200, epoch: 48 | loss: 0.0569255\n",
      "\tspeed: 0.0293s/iter; left time: 343.9272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0574080 Vali Loss: 0.0700144 Test Loss: 0.0796876\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0556890\n",
      "\tspeed: 0.0519s/iter; left time: 602.1130s\n",
      "\titers: 200, epoch: 49 | loss: 0.0603984\n",
      "\tspeed: 0.0259s/iter; left time: 298.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0574180 Vali Loss: 0.0700193 Test Loss: 0.0797447\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0552318\n",
      "\tspeed: 0.0528s/iter; left time: 600.4019s\n",
      "\titers: 200, epoch: 50 | loss: 0.0560904\n",
      "\tspeed: 0.0289s/iter; left time: 326.2247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0574346 Vali Loss: 0.0700277 Test Loss: 0.0797751\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0584236\n",
      "\tspeed: 0.0511s/iter; left time: 569.8983s\n",
      "\titers: 200, epoch: 51 | loss: 0.0596774\n",
      "\tspeed: 0.0255s/iter; left time: 281.4862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 225 | Train Loss: 0.0573538 Vali Loss: 0.0700491 Test Loss: 0.0797373\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0565288\n",
      "\tspeed: 0.0456s/iter; left time: 498.3488s\n",
      "\titers: 200, epoch: 52 | loss: 0.0591236\n",
      "\tspeed: 0.0250s/iter; left time: 270.1462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0573672 Vali Loss: 0.0700128 Test Loss: 0.0797444\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0560007\n",
      "\tspeed: 0.0509s/iter; left time: 544.5816s\n",
      "\titers: 200, epoch: 53 | loss: 0.0553082\n",
      "\tspeed: 0.0247s/iter; left time: 261.8469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 225 | Train Loss: 0.0573963 Vali Loss: 0.0700233 Test Loss: 0.0797055\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0592167\n",
      "\tspeed: 0.0430s/iter; left time: 450.3846s\n",
      "\titers: 200, epoch: 54 | loss: 0.0581175\n",
      "\tspeed: 0.0195s/iter; left time: 202.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.63s\n",
      "Steps: 225 | Train Loss: 0.0573610 Vali Loss: 0.0700269 Test Loss: 0.0797300\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0579432\n",
      "\tspeed: 0.0521s/iter; left time: 534.3785s\n",
      "\titers: 200, epoch: 55 | loss: 0.0573726\n",
      "\tspeed: 0.0284s/iter; left time: 288.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0573706 Vali Loss: 0.0700055 Test Loss: 0.0796857\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019379083067178726, rmse:0.13920877873897552, mae:0.07974138855934143, rse:0.5384965538978577\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1284621\n",
      "\tspeed: 0.0301s/iter; left time: 673.6003s\n",
      "\titers: 200, epoch: 1 | loss: 0.1147969\n",
      "\tspeed: 0.0293s/iter; left time: 652.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.1244091 Vali Loss: 0.1269917 Test Loss: 0.1441622\n",
      "Validation loss decreased (inf --> 0.126992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0759071\n",
      "\tspeed: 0.0556s/iter; left time: 1232.0012s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726768\n",
      "\tspeed: 0.0306s/iter; left time: 676.0831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0806701 Vali Loss: 0.0787315 Test Loss: 0.0870802\n",
      "Validation loss decreased (0.126992 --> 0.078731).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0691525\n",
      "\tspeed: 0.0518s/iter; left time: 1138.1042s\n",
      "\titers: 200, epoch: 3 | loss: 0.0614118\n",
      "\tspeed: 0.0302s/iter; left time: 659.7355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0671516 Vali Loss: 0.0750944 Test Loss: 0.0837143\n",
      "Validation loss decreased (0.078731 --> 0.075094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0640854\n",
      "\tspeed: 0.0522s/iter; left time: 1134.8101s\n",
      "\titers: 200, epoch: 4 | loss: 0.0640907\n",
      "\tspeed: 0.0267s/iter; left time: 576.8637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0647488 Vali Loss: 0.0734687 Test Loss: 0.0827292\n",
      "Validation loss decreased (0.075094 --> 0.073469).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0653637\n",
      "\tspeed: 0.0531s/iter; left time: 1142.4148s\n",
      "\titers: 200, epoch: 5 | loss: 0.0636200\n",
      "\tspeed: 0.0277s/iter; left time: 593.6523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 225 | Train Loss: 0.0630474 Vali Loss: 0.0722945 Test Loss: 0.0813779\n",
      "Validation loss decreased (0.073469 --> 0.072295).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0613186\n",
      "\tspeed: 0.0523s/iter; left time: 1113.6826s\n",
      "\titers: 200, epoch: 6 | loss: 0.0656116\n",
      "\tspeed: 0.0230s/iter; left time: 485.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0617380 Vali Loss: 0.0719124 Test Loss: 0.0807780\n",
      "Validation loss decreased (0.072295 --> 0.071912).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0582949\n",
      "\tspeed: 0.0482s/iter; left time: 1015.1316s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590653\n",
      "\tspeed: 0.0243s/iter; left time: 509.8308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 225 | Train Loss: 0.0609772 Vali Loss: 0.0714316 Test Loss: 0.0802214\n",
      "Validation loss decreased (0.071912 --> 0.071432).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0644874\n",
      "\tspeed: 0.0540s/iter; left time: 1123.6149s\n",
      "\titers: 200, epoch: 8 | loss: 0.0571645\n",
      "\tspeed: 0.0250s/iter; left time: 518.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0604138 Vali Loss: 0.0711555 Test Loss: 0.0802579\n",
      "Validation loss decreased (0.071432 --> 0.071155).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0587581\n",
      "\tspeed: 0.0511s/iter; left time: 1053.6666s\n",
      "\titers: 200, epoch: 9 | loss: 0.0600904\n",
      "\tspeed: 0.0257s/iter; left time: 526.2326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0599643 Vali Loss: 0.0709659 Test Loss: 0.0799562\n",
      "Validation loss decreased (0.071155 --> 0.070966).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0593112\n",
      "\tspeed: 0.0501s/iter; left time: 1021.1228s\n",
      "\titers: 200, epoch: 10 | loss: 0.0603072\n",
      "\tspeed: 0.0285s/iter; left time: 578.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.0596653 Vali Loss: 0.0708955 Test Loss: 0.0799527\n",
      "Validation loss decreased (0.070966 --> 0.070895).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0589053\n",
      "\tspeed: 0.0753s/iter; left time: 1518.2250s\n",
      "\titers: 200, epoch: 11 | loss: 0.0562900\n",
      "\tspeed: 0.0291s/iter; left time: 583.6261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0594109 Vali Loss: 0.0705119 Test Loss: 0.0796882\n",
      "Validation loss decreased (0.070895 --> 0.070512).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0573642\n",
      "\tspeed: 0.0528s/iter; left time: 1052.9812s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584696\n",
      "\tspeed: 0.0276s/iter; left time: 547.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 225 | Train Loss: 0.0591482 Vali Loss: 0.0705204 Test Loss: 0.0793874\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0638459\n",
      "\tspeed: 0.0578s/iter; left time: 1138.3965s\n",
      "\titers: 200, epoch: 13 | loss: 0.0607723\n",
      "\tspeed: 0.0283s/iter; left time: 554.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.81s\n",
      "Steps: 225 | Train Loss: 0.0589823 Vali Loss: 0.0704869 Test Loss: 0.0795223\n",
      "Validation loss decreased (0.070512 --> 0.070487).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577675\n",
      "\tspeed: 0.0509s/iter; left time: 991.3312s\n",
      "\titers: 200, epoch: 14 | loss: 0.0588133\n",
      "\tspeed: 0.0295s/iter; left time: 570.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 225 | Train Loss: 0.0587557 Vali Loss: 0.0704164 Test Loss: 0.0794338\n",
      "Validation loss decreased (0.070487 --> 0.070416).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0598332\n",
      "\tspeed: 0.0492s/iter; left time: 947.8349s\n",
      "\titers: 200, epoch: 15 | loss: 0.0523763\n",
      "\tspeed: 0.0297s/iter; left time: 568.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0586058 Vali Loss: 0.0703930 Test Loss: 0.0794698\n",
      "Validation loss decreased (0.070416 --> 0.070393).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569543\n",
      "\tspeed: 0.0554s/iter; left time: 1053.8308s\n",
      "\titers: 200, epoch: 16 | loss: 0.0575018\n",
      "\tspeed: 0.0263s/iter; left time: 497.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0584718 Vali Loss: 0.0702827 Test Loss: 0.0793067\n",
      "Validation loss decreased (0.070393 --> 0.070283).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0598423\n",
      "\tspeed: 0.0545s/iter; left time: 1024.7249s\n",
      "\titers: 200, epoch: 17 | loss: 0.0599144\n",
      "\tspeed: 0.0320s/iter; left time: 597.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 225 | Train Loss: 0.0583535 Vali Loss: 0.0702744 Test Loss: 0.0794939\n",
      "Validation loss decreased (0.070283 --> 0.070274).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0531501\n",
      "\tspeed: 0.0524s/iter; left time: 973.4115s\n",
      "\titers: 200, epoch: 18 | loss: 0.0583698\n",
      "\tspeed: 0.0240s/iter; left time: 443.3663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0582279 Vali Loss: 0.0703069 Test Loss: 0.0795386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0582662\n",
      "\tspeed: 0.0537s/iter; left time: 986.2555s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538871\n",
      "\tspeed: 0.0289s/iter; left time: 528.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 225 | Train Loss: 0.0581021 Vali Loss: 0.0702676 Test Loss: 0.0794995\n",
      "Validation loss decreased (0.070274 --> 0.070268).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0593301\n",
      "\tspeed: 0.0517s/iter; left time: 936.3111s\n",
      "\titers: 200, epoch: 20 | loss: 0.0557304\n",
      "\tspeed: 0.0262s/iter; left time: 473.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0580808 Vali Loss: 0.0702839 Test Loss: 0.0793468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0583406\n",
      "\tspeed: 0.0525s/iter; left time: 939.9182s\n",
      "\titers: 200, epoch: 21 | loss: 0.0572454\n",
      "\tspeed: 0.0188s/iter; left time: 335.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 225 | Train Loss: 0.0579334 Vali Loss: 0.0701692 Test Loss: 0.0793286\n",
      "Validation loss decreased (0.070268 --> 0.070169).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0610274\n",
      "\tspeed: 0.0550s/iter; left time: 972.2716s\n",
      "\titers: 200, epoch: 22 | loss: 0.0577461\n",
      "\tspeed: 0.0284s/iter; left time: 499.9411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0579323 Vali Loss: 0.0701289 Test Loss: 0.0793362\n",
      "Validation loss decreased (0.070169 --> 0.070129).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0563439\n",
      "\tspeed: 0.0517s/iter; left time: 901.9143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0545914\n",
      "\tspeed: 0.0307s/iter; left time: 533.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0578198 Vali Loss: 0.0702303 Test Loss: 0.0793536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0573807\n",
      "\tspeed: 0.0552s/iter; left time: 951.4206s\n",
      "\titers: 200, epoch: 24 | loss: 0.0569326\n",
      "\tspeed: 0.0321s/iter; left time: 549.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0577844 Vali Loss: 0.0701173 Test Loss: 0.0793296\n",
      "Validation loss decreased (0.070129 --> 0.070117).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0571284\n",
      "\tspeed: 0.0541s/iter; left time: 919.4589s\n",
      "\titers: 200, epoch: 25 | loss: 0.0566554\n",
      "\tspeed: 0.0280s/iter; left time: 473.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0577751 Vali Loss: 0.0701227 Test Loss: 0.0793326\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0563635\n",
      "\tspeed: 0.0589s/iter; left time: 988.5113s\n",
      "\titers: 200, epoch: 26 | loss: 0.0566110\n",
      "\tspeed: 0.0304s/iter; left time: 506.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 225 | Train Loss: 0.0576640 Vali Loss: 0.0701074 Test Loss: 0.0793666\n",
      "Validation loss decreased (0.070117 --> 0.070107).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0553515\n",
      "\tspeed: 0.0546s/iter; left time: 903.8048s\n",
      "\titers: 200, epoch: 27 | loss: 0.0582195\n",
      "\tspeed: 0.0268s/iter; left time: 440.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0576551 Vali Loss: 0.0701082 Test Loss: 0.0793718\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0614190\n",
      "\tspeed: 0.0477s/iter; left time: 779.2414s\n",
      "\titers: 200, epoch: 28 | loss: 0.0561958\n",
      "\tspeed: 0.0244s/iter; left time: 396.5185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.64s\n",
      "Steps: 225 | Train Loss: 0.0576140 Vali Loss: 0.0701166 Test Loss: 0.0793634\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0606842\n",
      "\tspeed: 0.0532s/iter; left time: 856.1724s\n",
      "\titers: 200, epoch: 29 | loss: 0.0555556\n",
      "\tspeed: 0.0203s/iter; left time: 325.2840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0576270 Vali Loss: 0.0701248 Test Loss: 0.0793313\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0551578\n",
      "\tspeed: 0.0521s/iter; left time: 826.7042s\n",
      "\titers: 200, epoch: 30 | loss: 0.0541448\n",
      "\tspeed: 0.0280s/iter; left time: 442.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0575290 Vali Loss: 0.0701014 Test Loss: 0.0793224\n",
      "Validation loss decreased (0.070107 --> 0.070101).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0569532\n",
      "\tspeed: 0.0501s/iter; left time: 784.1890s\n",
      "\titers: 200, epoch: 31 | loss: 0.0590402\n",
      "\tspeed: 0.0277s/iter; left time: 431.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.48s\n",
      "Steps: 225 | Train Loss: 0.0575341 Vali Loss: 0.0701293 Test Loss: 0.0792899\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0571844\n",
      "\tspeed: 0.0447s/iter; left time: 689.1812s\n",
      "\titers: 200, epoch: 32 | loss: 0.0565367\n",
      "\tspeed: 0.0187s/iter; left time: 286.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0574716 Vali Loss: 0.0701118 Test Loss: 0.0792886\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0614607\n",
      "\tspeed: 0.0485s/iter; left time: 737.1822s\n",
      "\titers: 200, epoch: 33 | loss: 0.0585503\n",
      "\tspeed: 0.0253s/iter; left time: 382.1650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.0574797 Vali Loss: 0.0701058 Test Loss: 0.0793323\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0620264\n",
      "\tspeed: 0.0463s/iter; left time: 692.9268s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566741\n",
      "\tspeed: 0.0228s/iter; left time: 339.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 225 | Train Loss: 0.0574723 Vali Loss: 0.0701067 Test Loss: 0.0793584\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0640683\n",
      "\tspeed: 0.0486s/iter; left time: 717.0495s\n",
      "\titers: 200, epoch: 35 | loss: 0.0572892\n",
      "\tspeed: 0.0245s/iter; left time: 358.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0574351 Vali Loss: 0.0700687 Test Loss: 0.0792865\n",
      "Validation loss decreased (0.070101 --> 0.070069).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0570007\n",
      "\tspeed: 0.0449s/iter; left time: 652.3359s\n",
      "\titers: 200, epoch: 36 | loss: 0.0618043\n",
      "\tspeed: 0.0222s/iter; left time: 319.6043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 225 | Train Loss: 0.0574811 Vali Loss: 0.0700867 Test Loss: 0.0792830\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0605867\n",
      "\tspeed: 0.0494s/iter; left time: 706.4138s\n",
      "\titers: 200, epoch: 37 | loss: 0.0583223\n",
      "\tspeed: 0.0269s/iter; left time: 382.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0573955 Vali Loss: 0.0701139 Test Loss: 0.0793523\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0590914\n",
      "\tspeed: 0.0483s/iter; left time: 679.5609s\n",
      "\titers: 200, epoch: 38 | loss: 0.0547826\n",
      "\tspeed: 0.0215s/iter; left time: 300.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0574274 Vali Loss: 0.0700677 Test Loss: 0.0793074\n",
      "Validation loss decreased (0.070069 --> 0.070068).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0589866\n",
      "\tspeed: 0.0537s/iter; left time: 743.1880s\n",
      "\titers: 200, epoch: 39 | loss: 0.0568881\n",
      "\tspeed: 0.0281s/iter; left time: 385.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 225 | Train Loss: 0.0574272 Vali Loss: 0.0700669 Test Loss: 0.0793272\n",
      "Validation loss decreased (0.070068 --> 0.070067).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0543563\n",
      "\tspeed: 0.0558s/iter; left time: 760.0782s\n",
      "\titers: 200, epoch: 40 | loss: 0.0559064\n",
      "\tspeed: 0.0312s/iter; left time: 422.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0573883 Vali Loss: 0.0700760 Test Loss: 0.0793200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0552888\n",
      "\tspeed: 0.0556s/iter; left time: 745.0874s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582908\n",
      "\tspeed: 0.0330s/iter; left time: 438.3193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 225 | Train Loss: 0.0573937 Vali Loss: 0.0700766 Test Loss: 0.0793160\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0573349\n",
      "\tspeed: 0.0530s/iter; left time: 697.8380s\n",
      "\titers: 200, epoch: 42 | loss: 0.0566573\n",
      "\tspeed: 0.0235s/iter; left time: 307.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0573726 Vali Loss: 0.0700556 Test Loss: 0.0793327\n",
      "Validation loss decreased (0.070067 --> 0.070056).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0567332\n",
      "\tspeed: 0.0516s/iter; left time: 668.2099s\n",
      "\titers: 200, epoch: 43 | loss: 0.0599545\n",
      "\tspeed: 0.0292s/iter; left time: 375.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0574122 Vali Loss: 0.0700747 Test Loss: 0.0793403\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0567316\n",
      "\tspeed: 0.0564s/iter; left time: 717.8145s\n",
      "\titers: 200, epoch: 44 | loss: 0.0537350\n",
      "\tspeed: 0.0276s/iter; left time: 348.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0573724 Vali Loss: 0.0700628 Test Loss: 0.0793382\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0551076\n",
      "\tspeed: 0.0511s/iter; left time: 638.9937s\n",
      "\titers: 200, epoch: 45 | loss: 0.0591606\n",
      "\tspeed: 0.0308s/iter; left time: 382.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0573695 Vali Loss: 0.0700636 Test Loss: 0.0793459\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0604501\n",
      "\tspeed: 0.0471s/iter; left time: 578.1376s\n",
      "\titers: 200, epoch: 46 | loss: 0.0595160\n",
      "\tspeed: 0.0240s/iter; left time: 292.3925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 225 | Train Loss: 0.0574024 Vali Loss: 0.0700707 Test Loss: 0.0793402\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0571790\n",
      "\tspeed: 0.0522s/iter; left time: 628.4848s\n",
      "\titers: 200, epoch: 47 | loss: 0.0627229\n",
      "\tspeed: 0.0254s/iter; left time: 303.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0573691 Vali Loss: 0.0700772 Test Loss: 0.0793330\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578066\n",
      "\tspeed: 0.0527s/iter; left time: 622.7475s\n",
      "\titers: 200, epoch: 48 | loss: 0.0608316\n",
      "\tspeed: 0.0285s/iter; left time: 333.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 225 | Train Loss: 0.0573581 Vali Loss: 0.0700874 Test Loss: 0.0793788\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0570433\n",
      "\tspeed: 0.0465s/iter; left time: 538.8687s\n",
      "\titers: 200, epoch: 49 | loss: 0.0553163\n",
      "\tspeed: 0.0188s/iter; left time: 216.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.75s\n",
      "Steps: 225 | Train Loss: 0.0573690 Vali Loss: 0.0700815 Test Loss: 0.0793844\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0559578\n",
      "\tspeed: 0.0503s/iter; left time: 572.5681s\n",
      "\titers: 200, epoch: 50 | loss: 0.0611283\n",
      "\tspeed: 0.0302s/iter; left time: 340.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.93s\n",
      "Steps: 225 | Train Loss: 0.0573608 Vali Loss: 0.0700669 Test Loss: 0.0792996\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0546972\n",
      "\tspeed: 0.0510s/iter; left time: 568.5301s\n",
      "\titers: 200, epoch: 51 | loss: 0.0589048\n",
      "\tspeed: 0.0247s/iter; left time: 273.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0573474 Vali Loss: 0.0700608 Test Loss: 0.0793011\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0557716\n",
      "\tspeed: 0.0488s/iter; left time: 532.8271s\n",
      "\titers: 200, epoch: 52 | loss: 0.0602678\n",
      "\tspeed: 0.0254s/iter; left time: 274.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0573041 Vali Loss: 0.0700850 Test Loss: 0.0793761\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_96_FR_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018991485238075256, rmse:0.1378096044063568, mae:0.07933271676301956, rse:0.5330842137336731\n",
      "Intermediate time for FR and pred_len 96: 00h:14m:24.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_168_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1272520\n",
      "\tspeed: 0.0492s/iter; left time: 1101.5652s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139134\n",
      "\tspeed: 0.0240s/iter; left time: 536.2550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.1276170 Vali Loss: 0.1304395 Test Loss: 0.1474907\n",
      "Validation loss decreased (inf --> 0.130440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0772742\n",
      "\tspeed: 0.0501s/iter; left time: 1111.2304s\n",
      "\titers: 200, epoch: 2 | loss: 0.0683886\n",
      "\tspeed: 0.0213s/iter; left time: 470.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0839309 Vali Loss: 0.0828477 Test Loss: 0.0916202\n",
      "Validation loss decreased (0.130440 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0726576\n",
      "\tspeed: 0.0470s/iter; left time: 1030.6752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0670449\n",
      "\tspeed: 0.0214s/iter; left time: 466.5992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 225 | Train Loss: 0.0717557 Vali Loss: 0.0794046 Test Loss: 0.0888894\n",
      "Validation loss decreased (0.082848 --> 0.079405).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0673546\n",
      "\tspeed: 0.0447s/iter; left time: 970.9455s\n",
      "\titers: 200, epoch: 4 | loss: 0.0745090\n",
      "\tspeed: 0.0269s/iter; left time: 581.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 225 | Train Loss: 0.0693919 Vali Loss: 0.0777480 Test Loss: 0.0877899\n",
      "Validation loss decreased (0.079405 --> 0.077748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0681390\n",
      "\tspeed: 0.0503s/iter; left time: 1081.6265s\n",
      "\titers: 200, epoch: 5 | loss: 0.0653466\n",
      "\tspeed: 0.0202s/iter; left time: 433.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0677026 Vali Loss: 0.0764982 Test Loss: 0.0866170\n",
      "Validation loss decreased (0.077748 --> 0.076498).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0675271\n",
      "\tspeed: 0.0541s/iter; left time: 1151.7150s\n",
      "\titers: 200, epoch: 6 | loss: 0.0634571\n",
      "\tspeed: 0.0293s/iter; left time: 620.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 225 | Train Loss: 0.0665270 Vali Loss: 0.0759238 Test Loss: 0.0860975\n",
      "Validation loss decreased (0.076498 --> 0.075924).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0627982\n",
      "\tspeed: 0.0459s/iter; left time: 966.3228s\n",
      "\titers: 200, epoch: 7 | loss: 0.0680622\n",
      "\tspeed: 0.0213s/iter; left time: 446.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0657958 Vali Loss: 0.0757242 Test Loss: 0.0859290\n",
      "Validation loss decreased (0.075924 --> 0.075724).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0685889\n",
      "\tspeed: 0.0441s/iter; left time: 919.0819s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655987\n",
      "\tspeed: 0.0221s/iter; left time: 458.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0653262 Vali Loss: 0.0755243 Test Loss: 0.0856274\n",
      "Validation loss decreased (0.075724 --> 0.075524).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654939\n",
      "\tspeed: 0.0492s/iter; left time: 1014.3947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0621993\n",
      "\tspeed: 0.0216s/iter; left time: 443.1129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 225 | Train Loss: 0.0648884 Vali Loss: 0.0751519 Test Loss: 0.0856586\n",
      "Validation loss decreased (0.075524 --> 0.075152).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0643409\n",
      "\tspeed: 0.0482s/iter; left time: 982.9063s\n",
      "\titers: 200, epoch: 10 | loss: 0.0636073\n",
      "\tspeed: 0.0191s/iter; left time: 387.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0645998 Vali Loss: 0.0750313 Test Loss: 0.0854118\n",
      "Validation loss decreased (0.075152 --> 0.075031).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0610782\n",
      "\tspeed: 0.0507s/iter; left time: 1020.8416s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642931\n",
      "\tspeed: 0.0244s/iter; left time: 489.6179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0643136 Vali Loss: 0.0749084 Test Loss: 0.0854673\n",
      "Validation loss decreased (0.075031 --> 0.074908).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0623670\n",
      "\tspeed: 0.0474s/iter; left time: 944.3121s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672583\n",
      "\tspeed: 0.0233s/iter; left time: 461.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.0640396 Vali Loss: 0.0749552 Test Loss: 0.0856013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0622854\n",
      "\tspeed: 0.0489s/iter; left time: 963.3810s\n",
      "\titers: 200, epoch: 13 | loss: 0.0659144\n",
      "\tspeed: 0.0277s/iter; left time: 542.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0638592 Vali Loss: 0.0748083 Test Loss: 0.0855789\n",
      "Validation loss decreased (0.074908 --> 0.074808).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0620585\n",
      "\tspeed: 0.0479s/iter; left time: 932.4632s\n",
      "\titers: 200, epoch: 14 | loss: 0.0654317\n",
      "\tspeed: 0.0222s/iter; left time: 430.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 225 | Train Loss: 0.0636821 Vali Loss: 0.0747042 Test Loss: 0.0855131\n",
      "Validation loss decreased (0.074808 --> 0.074704).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0631975\n",
      "\tspeed: 0.0508s/iter; left time: 977.2015s\n",
      "\titers: 200, epoch: 15 | loss: 0.0654471\n",
      "\tspeed: 0.0243s/iter; left time: 465.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 225 | Train Loss: 0.0635583 Vali Loss: 0.0747427 Test Loss: 0.0856473\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0613949\n",
      "\tspeed: 0.0538s/iter; left time: 1022.7058s\n",
      "\titers: 200, epoch: 16 | loss: 0.0665923\n",
      "\tspeed: 0.0234s/iter; left time: 442.3252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0633783 Vali Loss: 0.0747351 Test Loss: 0.0856458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0659078\n",
      "\tspeed: 0.0548s/iter; left time: 1029.4383s\n",
      "\titers: 200, epoch: 17 | loss: 0.0635712\n",
      "\tspeed: 0.0291s/iter; left time: 543.3666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0632849 Vali Loss: 0.0746098 Test Loss: 0.0856807\n",
      "Validation loss decreased (0.074704 --> 0.074610).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638385\n",
      "\tspeed: 0.0540s/iter; left time: 1003.2143s\n",
      "\titers: 200, epoch: 18 | loss: 0.0646904\n",
      "\tspeed: 0.0318s/iter; left time: 588.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 225 | Train Loss: 0.0632165 Vali Loss: 0.0746178 Test Loss: 0.0858439\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0635223\n",
      "\tspeed: 0.0513s/iter; left time: 941.2106s\n",
      "\titers: 200, epoch: 19 | loss: 0.0610002\n",
      "\tspeed: 0.0265s/iter; left time: 483.1220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 225 | Train Loss: 0.0631096 Vali Loss: 0.0746138 Test Loss: 0.0857874\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0613484\n",
      "\tspeed: 0.0492s/iter; left time: 892.2471s\n",
      "\titers: 200, epoch: 20 | loss: 0.0664193\n",
      "\tspeed: 0.0285s/iter; left time: 513.5429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.32s\n",
      "Steps: 225 | Train Loss: 0.0630244 Vali Loss: 0.0746466 Test Loss: 0.0857259\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0656793\n",
      "\tspeed: 0.0478s/iter; left time: 856.4265s\n",
      "\titers: 200, epoch: 21 | loss: 0.0620232\n",
      "\tspeed: 0.0270s/iter; left time: 481.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 225 | Train Loss: 0.0629531 Vali Loss: 0.0745882 Test Loss: 0.0856962\n",
      "Validation loss decreased (0.074610 --> 0.074588).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0627351\n",
      "\tspeed: 0.0517s/iter; left time: 914.3328s\n",
      "\titers: 200, epoch: 22 | loss: 0.0617253\n",
      "\tspeed: 0.0257s/iter; left time: 451.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 225 | Train Loss: 0.0628690 Vali Loss: 0.0744990 Test Loss: 0.0857268\n",
      "Validation loss decreased (0.074588 --> 0.074499).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0635282\n",
      "\tspeed: 0.0510s/iter; left time: 889.9966s\n",
      "\titers: 200, epoch: 23 | loss: 0.0617497\n",
      "\tspeed: 0.0231s/iter; left time: 400.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0627902 Vali Loss: 0.0745341 Test Loss: 0.0856929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0596462\n",
      "\tspeed: 0.0512s/iter; left time: 882.2671s\n",
      "\titers: 200, epoch: 24 | loss: 0.0616790\n",
      "\tspeed: 0.0272s/iter; left time: 466.0478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0627450 Vali Loss: 0.0746024 Test Loss: 0.0857222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0621714\n",
      "\tspeed: 0.0543s/iter; left time: 922.7509s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623515\n",
      "\tspeed: 0.0305s/iter; left time: 514.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 225 | Train Loss: 0.0626844 Vali Loss: 0.0744575 Test Loss: 0.0859434\n",
      "Validation loss decreased (0.074499 --> 0.074457).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0606405\n",
      "\tspeed: 0.0497s/iter; left time: 833.4542s\n",
      "\titers: 200, epoch: 26 | loss: 0.0639716\n",
      "\tspeed: 0.0273s/iter; left time: 454.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0626402 Vali Loss: 0.0744846 Test Loss: 0.0857622\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0605102\n",
      "\tspeed: 0.0492s/iter; left time: 814.8225s\n",
      "\titers: 200, epoch: 27 | loss: 0.0630375\n",
      "\tspeed: 0.0220s/iter; left time: 362.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0626157 Vali Loss: 0.0744742 Test Loss: 0.0858825\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0621221\n",
      "\tspeed: 0.0460s/iter; left time: 751.6802s\n",
      "\titers: 200, epoch: 28 | loss: 0.0587539\n",
      "\tspeed: 0.0286s/iter; left time: 464.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0625750 Vali Loss: 0.0745418 Test Loss: 0.0858210\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0625541\n",
      "\tspeed: 0.0584s/iter; left time: 940.5929s\n",
      "\titers: 200, epoch: 29 | loss: 0.0623563\n",
      "\tspeed: 0.0256s/iter; left time: 408.8591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0625338 Vali Loss: 0.0744981 Test Loss: 0.0858277\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0661957\n",
      "\tspeed: 0.0467s/iter; left time: 740.7239s\n",
      "\titers: 200, epoch: 30 | loss: 0.0639525\n",
      "\tspeed: 0.0234s/iter; left time: 369.6245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0625691 Vali Loss: 0.0744574 Test Loss: 0.0858844\n",
      "Validation loss decreased (0.074457 --> 0.074457).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0596946\n",
      "\tspeed: 0.0532s/iter; left time: 833.3101s\n",
      "\titers: 200, epoch: 31 | loss: 0.0621399\n",
      "\tspeed: 0.0269s/iter; left time: 418.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0625227 Vali Loss: 0.0745119 Test Loss: 0.0858060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0618315\n",
      "\tspeed: 0.0503s/iter; left time: 775.1976s\n",
      "\titers: 200, epoch: 32 | loss: 0.0648636\n",
      "\tspeed: 0.0241s/iter; left time: 369.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0624774 Vali Loss: 0.0744580 Test Loss: 0.0859242\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0618293\n",
      "\tspeed: 0.0489s/iter; left time: 743.9601s\n",
      "\titers: 200, epoch: 33 | loss: 0.0698456\n",
      "\tspeed: 0.0279s/iter; left time: 421.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0624404 Vali Loss: 0.0744743 Test Loss: 0.0858578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0602348\n",
      "\tspeed: 0.0474s/iter; left time: 710.4054s\n",
      "\titers: 200, epoch: 34 | loss: 0.0632259\n",
      "\tspeed: 0.0262s/iter; left time: 389.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0624635 Vali Loss: 0.0745623 Test Loss: 0.0858491\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0614640\n",
      "\tspeed: 0.0456s/iter; left time: 672.8144s\n",
      "\titers: 200, epoch: 35 | loss: 0.0617883\n",
      "\tspeed: 0.0226s/iter; left time: 331.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 225 | Train Loss: 0.0624872 Vali Loss: 0.0745251 Test Loss: 0.0858337\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0650040\n",
      "\tspeed: 0.0510s/iter; left time: 740.1499s\n",
      "\titers: 200, epoch: 36 | loss: 0.0643411\n",
      "\tspeed: 0.0277s/iter; left time: 398.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0624353 Vali Loss: 0.0746154 Test Loss: 0.0858895\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0628083\n",
      "\tspeed: 0.0474s/iter; left time: 678.1016s\n",
      "\titers: 200, epoch: 37 | loss: 0.0638829\n",
      "\tspeed: 0.0210s/iter; left time: 298.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 225 | Train Loss: 0.0624339 Vali Loss: 0.0744218 Test Loss: 0.0858261\n",
      "Validation loss decreased (0.074457 --> 0.074422).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0617154\n",
      "\tspeed: 0.0473s/iter; left time: 666.3509s\n",
      "\titers: 200, epoch: 38 | loss: 0.0624265\n",
      "\tspeed: 0.0191s/iter; left time: 267.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 225 | Train Loss: 0.0623945 Vali Loss: 0.0745134 Test Loss: 0.0858380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0633624\n",
      "\tspeed: 0.0533s/iter; left time: 738.4684s\n",
      "\titers: 200, epoch: 39 | loss: 0.0634164\n",
      "\tspeed: 0.0320s/iter; left time: 440.2722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0623897 Vali Loss: 0.0745301 Test Loss: 0.0859188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0604515\n",
      "\tspeed: 0.0538s/iter; left time: 733.2661s\n",
      "\titers: 200, epoch: 40 | loss: 0.0654750\n",
      "\tspeed: 0.0271s/iter; left time: 366.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 225 | Train Loss: 0.0623177 Vali Loss: 0.0744232 Test Loss: 0.0858311\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0626954\n",
      "\tspeed: 0.0497s/iter; left time: 666.4850s\n",
      "\titers: 200, epoch: 41 | loss: 0.0635799\n",
      "\tspeed: 0.0300s/iter; left time: 398.7194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 225 | Train Loss: 0.0623073 Vali Loss: 0.0744998 Test Loss: 0.0858700\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0620622\n",
      "\tspeed: 0.0491s/iter; left time: 647.1998s\n",
      "\titers: 200, epoch: 42 | loss: 0.0633982\n",
      "\tspeed: 0.0269s/iter; left time: 351.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0623295 Vali Loss: 0.0744531 Test Loss: 0.0858385\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0635427\n",
      "\tspeed: 0.0539s/iter; left time: 697.7081s\n",
      "\titers: 200, epoch: 43 | loss: 0.0640768\n",
      "\tspeed: 0.0264s/iter; left time: 339.8718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0623399 Vali Loss: 0.0745088 Test Loss: 0.0858960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0627989\n",
      "\tspeed: 0.0455s/iter; left time: 578.7728s\n",
      "\titers: 200, epoch: 44 | loss: 0.0654221\n",
      "\tspeed: 0.0256s/iter; left time: 323.1330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 225 | Train Loss: 0.0623654 Vali Loss: 0.0744741 Test Loss: 0.0858343\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0631965\n",
      "\tspeed: 0.0537s/iter; left time: 671.3306s\n",
      "\titers: 200, epoch: 45 | loss: 0.0595206\n",
      "\tspeed: 0.0276s/iter; left time: 341.8205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0623582 Vali Loss: 0.0745196 Test Loss: 0.0859488\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618657\n",
      "\tspeed: 0.0501s/iter; left time: 614.9053s\n",
      "\titers: 200, epoch: 46 | loss: 0.0618082\n",
      "\tspeed: 0.0288s/iter; left time: 350.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0623630 Vali Loss: 0.0744667 Test Loss: 0.0858532\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0612222\n",
      "\tspeed: 0.0483s/iter; left time: 582.4565s\n",
      "\titers: 200, epoch: 47 | loss: 0.0634084\n",
      "\tspeed: 0.0282s/iter; left time: 336.6874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0623304 Vali Loss: 0.0743896 Test Loss: 0.0858907\n",
      "Validation loss decreased (0.074422 --> 0.074390).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0600213\n",
      "\tspeed: 0.0463s/iter; left time: 547.6210s\n",
      "\titers: 200, epoch: 48 | loss: 0.0635485\n",
      "\tspeed: 0.0218s/iter; left time: 255.9984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0623316 Vali Loss: 0.0745217 Test Loss: 0.0859320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0597138\n",
      "\tspeed: 0.0468s/iter; left time: 543.1816s\n",
      "\titers: 200, epoch: 49 | loss: 0.0602840\n",
      "\tspeed: 0.0246s/iter; left time: 282.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0622687 Vali Loss: 0.0744689 Test Loss: 0.0859321\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0644672\n",
      "\tspeed: 0.0547s/iter; left time: 622.2777s\n",
      "\titers: 200, epoch: 50 | loss: 0.0601074\n",
      "\tspeed: 0.0278s/iter; left time: 313.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 225 | Train Loss: 0.0623085 Vali Loss: 0.0744889 Test Loss: 0.0859750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0590142\n",
      "\tspeed: 0.0469s/iter; left time: 522.4444s\n",
      "\titers: 200, epoch: 51 | loss: 0.0604234\n",
      "\tspeed: 0.0206s/iter; left time: 227.9378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 225 | Train Loss: 0.0623346 Vali Loss: 0.0745170 Test Loss: 0.0859061\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0625177\n",
      "\tspeed: 0.0490s/iter; left time: 535.5851s\n",
      "\titers: 200, epoch: 52 | loss: 0.0613102\n",
      "\tspeed: 0.0248s/iter; left time: 268.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0623311 Vali Loss: 0.0744508 Test Loss: 0.0859454\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0623345\n",
      "\tspeed: 0.0513s/iter; left time: 548.7204s\n",
      "\titers: 200, epoch: 53 | loss: 0.0620558\n",
      "\tspeed: 0.0272s/iter; left time: 288.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0623070 Vali Loss: 0.0744105 Test Loss: 0.0859452\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0626286\n",
      "\tspeed: 0.0458s/iter; left time: 479.8098s\n",
      "\titers: 200, epoch: 54 | loss: 0.0602639\n",
      "\tspeed: 0.0213s/iter; left time: 220.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 225 | Train Loss: 0.0622840 Vali Loss: 0.0744894 Test Loss: 0.0858701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0637947\n",
      "\tspeed: 0.0510s/iter; left time: 522.4412s\n",
      "\titers: 200, epoch: 55 | loss: 0.0634702\n",
      "\tspeed: 0.0207s/iter; left time: 209.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 225 | Train Loss: 0.0623053 Vali Loss: 0.0744373 Test Loss: 0.0858628\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0606350\n",
      "\tspeed: 0.0500s/iter; left time: 501.1912s\n",
      "\titers: 200, epoch: 56 | loss: 0.0630527\n",
      "\tspeed: 0.0237s/iter; left time: 235.5508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0623080 Vali Loss: 0.0744589 Test Loss: 0.0859321\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0608659\n",
      "\tspeed: 0.0516s/iter; left time: 505.3181s\n",
      "\titers: 200, epoch: 57 | loss: 0.0651965\n",
      "\tspeed: 0.0244s/iter; left time: 236.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0622864 Vali Loss: 0.0745124 Test Loss: 0.0859003\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020789824426174164, rmse:0.14418676495552063, mae:0.08589069545269012, rse:0.5584490299224854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1283359\n",
      "\tspeed: 0.0253s/iter; left time: 567.8639s\n",
      "\titers: 200, epoch: 1 | loss: 0.1182079\n",
      "\tspeed: 0.0241s/iter; left time: 536.7329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 225 | Train Loss: 0.1275120 Vali Loss: 0.1307549 Test Loss: 0.1478369\n",
      "Validation loss decreased (inf --> 0.130755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0830578\n",
      "\tspeed: 0.0536s/iter; left time: 1188.3188s\n",
      "\titers: 200, epoch: 2 | loss: 0.0782976\n",
      "\tspeed: 0.0232s/iter; left time: 513.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 225 | Train Loss: 0.0844567 Vali Loss: 0.0833374 Test Loss: 0.0920598\n",
      "Validation loss decreased (0.130755 --> 0.083337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0738854\n",
      "\tspeed: 0.0475s/iter; left time: 1042.2190s\n",
      "\titers: 200, epoch: 3 | loss: 0.0730405\n",
      "\tspeed: 0.0205s/iter; left time: 448.3451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 225 | Train Loss: 0.0719282 Vali Loss: 0.0796686 Test Loss: 0.0888616\n",
      "Validation loss decreased (0.083337 --> 0.079669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0686242\n",
      "\tspeed: 0.0538s/iter; left time: 1168.8054s\n",
      "\titers: 200, epoch: 4 | loss: 0.0633135\n",
      "\tspeed: 0.0308s/iter; left time: 665.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0690934 Vali Loss: 0.0779210 Test Loss: 0.0876197\n",
      "Validation loss decreased (0.079669 --> 0.077921).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0696057\n",
      "\tspeed: 0.0542s/iter; left time: 1166.2125s\n",
      "\titers: 200, epoch: 5 | loss: 0.0686394\n",
      "\tspeed: 0.0275s/iter; left time: 588.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 225 | Train Loss: 0.0673277 Vali Loss: 0.0770012 Test Loss: 0.0867868\n",
      "Validation loss decreased (0.077921 --> 0.077001).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0645938\n",
      "\tspeed: 0.0586s/iter; left time: 1247.3115s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635069\n",
      "\tspeed: 0.0252s/iter; left time: 533.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 225 | Train Loss: 0.0663026 Vali Loss: 0.0762333 Test Loss: 0.0860183\n",
      "Validation loss decreased (0.077001 --> 0.076233).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630857\n",
      "\tspeed: 0.0557s/iter; left time: 1172.5905s\n",
      "\titers: 200, epoch: 7 | loss: 0.0592810\n",
      "\tspeed: 0.0300s/iter; left time: 628.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0656490 Vali Loss: 0.0758989 Test Loss: 0.0859655\n",
      "Validation loss decreased (0.076233 --> 0.075899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0623031\n",
      "\tspeed: 0.0531s/iter; left time: 1106.6912s\n",
      "\titers: 200, epoch: 8 | loss: 0.0678525\n",
      "\tspeed: 0.0237s/iter; left time: 490.8001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0652322 Vali Loss: 0.0758925 Test Loss: 0.0854810\n",
      "Validation loss decreased (0.075899 --> 0.075892).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667703\n",
      "\tspeed: 0.0525s/iter; left time: 1080.7308s\n",
      "\titers: 200, epoch: 9 | loss: 0.0680243\n",
      "\tspeed: 0.0266s/iter; left time: 546.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0648445 Vali Loss: 0.0756965 Test Loss: 0.0852528\n",
      "Validation loss decreased (0.075892 --> 0.075697).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0628252\n",
      "\tspeed: 0.0517s/iter; left time: 1053.5825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0643737\n",
      "\tspeed: 0.0204s/iter; left time: 414.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 225 | Train Loss: 0.0644856 Vali Loss: 0.0754460 Test Loss: 0.0854238\n",
      "Validation loss decreased (0.075697 --> 0.075446).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0658455\n",
      "\tspeed: 0.0526s/iter; left time: 1060.0858s\n",
      "\titers: 200, epoch: 11 | loss: 0.0642555\n",
      "\tspeed: 0.0284s/iter; left time: 569.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0642728 Vali Loss: 0.0753982 Test Loss: 0.0853674\n",
      "Validation loss decreased (0.075446 --> 0.075398).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0610631\n",
      "\tspeed: 0.0514s/iter; left time: 1023.2376s\n",
      "\titers: 200, epoch: 12 | loss: 0.0644557\n",
      "\tspeed: 0.0273s/iter; left time: 542.0686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 225 | Train Loss: 0.0640375 Vali Loss: 0.0751443 Test Loss: 0.0850488\n",
      "Validation loss decreased (0.075398 --> 0.075144).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0640642\n",
      "\tspeed: 0.0513s/iter; left time: 1010.9889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0608970\n",
      "\tspeed: 0.0247s/iter; left time: 484.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0638459 Vali Loss: 0.0751370 Test Loss: 0.0852346\n",
      "Validation loss decreased (0.075144 --> 0.075137).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0636537\n",
      "\tspeed: 0.0544s/iter; left time: 1059.7232s\n",
      "\titers: 200, epoch: 14 | loss: 0.0641293\n",
      "\tspeed: 0.0259s/iter; left time: 500.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0636891 Vali Loss: 0.0751352 Test Loss: 0.0852650\n",
      "Validation loss decreased (0.075137 --> 0.075135).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0652704\n",
      "\tspeed: 0.0478s/iter; left time: 921.0010s\n",
      "\titers: 200, epoch: 15 | loss: 0.0603209\n",
      "\tspeed: 0.0259s/iter; left time: 496.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 225 | Train Loss: 0.0634916 Vali Loss: 0.0751293 Test Loss: 0.0853076\n",
      "Validation loss decreased (0.075135 --> 0.075129).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0600324\n",
      "\tspeed: 0.0561s/iter; left time: 1066.4254s\n",
      "\titers: 200, epoch: 16 | loss: 0.0660657\n",
      "\tspeed: 0.0233s/iter; left time: 441.8419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0633372 Vali Loss: 0.0751984 Test Loss: 0.0854423\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0680200\n",
      "\tspeed: 0.0532s/iter; left time: 1000.0359s\n",
      "\titers: 200, epoch: 17 | loss: 0.0648509\n",
      "\tspeed: 0.0287s/iter; left time: 536.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0632565 Vali Loss: 0.0749803 Test Loss: 0.0854133\n",
      "Validation loss decreased (0.075129 --> 0.074980).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0647032\n",
      "\tspeed: 0.0552s/iter; left time: 1025.1044s\n",
      "\titers: 200, epoch: 18 | loss: 0.0598428\n",
      "\tspeed: 0.0306s/iter; left time: 566.0337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0631523 Vali Loss: 0.0749387 Test Loss: 0.0854822\n",
      "Validation loss decreased (0.074980 --> 0.074939).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668046\n",
      "\tspeed: 0.0576s/iter; left time: 1056.8033s\n",
      "\titers: 200, epoch: 19 | loss: 0.0596661\n",
      "\tspeed: 0.0292s/iter; left time: 532.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0630589 Vali Loss: 0.0750222 Test Loss: 0.0852431\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0618846\n",
      "\tspeed: 0.0544s/iter; left time: 985.2407s\n",
      "\titers: 200, epoch: 20 | loss: 0.0643297\n",
      "\tspeed: 0.0274s/iter; left time: 493.7162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0629882 Vali Loss: 0.0749454 Test Loss: 0.0854134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0642228\n",
      "\tspeed: 0.0521s/iter; left time: 932.0568s\n",
      "\titers: 200, epoch: 21 | loss: 0.0603757\n",
      "\tspeed: 0.0299s/iter; left time: 532.6462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0629317 Vali Loss: 0.0750512 Test Loss: 0.0852952\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0606580\n",
      "\tspeed: 0.0556s/iter; left time: 982.8903s\n",
      "\titers: 200, epoch: 22 | loss: 0.0608251\n",
      "\tspeed: 0.0271s/iter; left time: 476.8428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0628622 Vali Loss: 0.0750110 Test Loss: 0.0853213\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0661985\n",
      "\tspeed: 0.0522s/iter; left time: 911.2059s\n",
      "\titers: 200, epoch: 23 | loss: 0.0606835\n",
      "\tspeed: 0.0288s/iter; left time: 499.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 225 | Train Loss: 0.0627658 Vali Loss: 0.0750056 Test Loss: 0.0853894\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0657220\n",
      "\tspeed: 0.0499s/iter; left time: 859.2146s\n",
      "\titers: 200, epoch: 24 | loss: 0.0632927\n",
      "\tspeed: 0.0215s/iter; left time: 368.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 225 | Train Loss: 0.0627181 Vali Loss: 0.0750028 Test Loss: 0.0853932\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0642134\n",
      "\tspeed: 0.0522s/iter; left time: 887.1616s\n",
      "\titers: 200, epoch: 25 | loss: 0.0661637\n",
      "\tspeed: 0.0252s/iter; left time: 425.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 225 | Train Loss: 0.0626534 Vali Loss: 0.0749225 Test Loss: 0.0854760\n",
      "Validation loss decreased (0.074939 --> 0.074923).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0633271\n",
      "\tspeed: 0.0608s/iter; left time: 1020.3258s\n",
      "\titers: 200, epoch: 26 | loss: 0.0659848\n",
      "\tspeed: 0.0302s/iter; left time: 504.2699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 225 | Train Loss: 0.0625923 Vali Loss: 0.0750195 Test Loss: 0.0855144\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0615869\n",
      "\tspeed: 0.0571s/iter; left time: 945.8798s\n",
      "\titers: 200, epoch: 27 | loss: 0.0625416\n",
      "\tspeed: 0.0302s/iter; left time: 496.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0625670 Vali Loss: 0.0749205 Test Loss: 0.0854166\n",
      "Validation loss decreased (0.074923 --> 0.074920).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0610086\n",
      "\tspeed: 0.0563s/iter; left time: 919.6652s\n",
      "\titers: 200, epoch: 28 | loss: 0.0594363\n",
      "\tspeed: 0.0270s/iter; left time: 438.3991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0625560 Vali Loss: 0.0749292 Test Loss: 0.0854552\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0659877\n",
      "\tspeed: 0.0512s/iter; left time: 824.3693s\n",
      "\titers: 200, epoch: 29 | loss: 0.0670725\n",
      "\tspeed: 0.0267s/iter; left time: 427.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 225 | Train Loss: 0.0625343 Vali Loss: 0.0749282 Test Loss: 0.0854419\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0629614\n",
      "\tspeed: 0.0547s/iter; left time: 867.9643s\n",
      "\titers: 200, epoch: 30 | loss: 0.0623289\n",
      "\tspeed: 0.0320s/iter; left time: 504.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0625158 Vali Loss: 0.0750068 Test Loss: 0.0855481\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0619467\n",
      "\tspeed: 0.0529s/iter; left time: 827.8931s\n",
      "\titers: 200, epoch: 31 | loss: 0.0611455\n",
      "\tspeed: 0.0338s/iter; left time: 525.0281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0624699 Vali Loss: 0.0748934 Test Loss: 0.0854585\n",
      "Validation loss decreased (0.074920 --> 0.074893).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0635809\n",
      "\tspeed: 0.0514s/iter; left time: 793.1488s\n",
      "\titers: 200, epoch: 32 | loss: 0.0642294\n",
      "\tspeed: 0.0251s/iter; left time: 384.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 225 | Train Loss: 0.0624576 Vali Loss: 0.0749186 Test Loss: 0.0854044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0611105\n",
      "\tspeed: 0.0558s/iter; left time: 847.7393s\n",
      "\titers: 200, epoch: 33 | loss: 0.0619674\n",
      "\tspeed: 0.0229s/iter; left time: 345.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0623846 Vali Loss: 0.0749059 Test Loss: 0.0854875\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0613588\n",
      "\tspeed: 0.0480s/iter; left time: 719.3883s\n",
      "\titers: 200, epoch: 34 | loss: 0.0637927\n",
      "\tspeed: 0.0273s/iter; left time: 406.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0623770 Vali Loss: 0.0749009 Test Loss: 0.0855714\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0653247\n",
      "\tspeed: 0.0487s/iter; left time: 718.1310s\n",
      "\titers: 200, epoch: 35 | loss: 0.0641193\n",
      "\tspeed: 0.0208s/iter; left time: 304.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0624001 Vali Loss: 0.0749931 Test Loss: 0.0855564\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0618253\n",
      "\tspeed: 0.0563s/iter; left time: 817.7947s\n",
      "\titers: 200, epoch: 36 | loss: 0.0606291\n",
      "\tspeed: 0.0273s/iter; left time: 394.3527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 225 | Train Loss: 0.0624052 Vali Loss: 0.0748966 Test Loss: 0.0855036\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0611519\n",
      "\tspeed: 0.0557s/iter; left time: 797.2574s\n",
      "\titers: 200, epoch: 37 | loss: 0.0656925\n",
      "\tspeed: 0.0257s/iter; left time: 365.1492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0623474 Vali Loss: 0.0749378 Test Loss: 0.0855539\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0610135\n",
      "\tspeed: 0.0491s/iter; left time: 690.7544s\n",
      "\titers: 200, epoch: 38 | loss: 0.0591451\n",
      "\tspeed: 0.0266s/iter; left time: 371.7748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 225 | Train Loss: 0.0623356 Vali Loss: 0.0747937 Test Loss: 0.0855813\n",
      "Validation loss decreased (0.074893 --> 0.074794).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0592215\n",
      "\tspeed: 0.0573s/iter; left time: 792.9953s\n",
      "\titers: 200, epoch: 39 | loss: 0.0593245\n",
      "\tspeed: 0.0242s/iter; left time: 333.3300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0623109 Vali Loss: 0.0748570 Test Loss: 0.0854844\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0583931\n",
      "\tspeed: 0.0539s/iter; left time: 733.9690s\n",
      "\titers: 200, epoch: 40 | loss: 0.0640757\n",
      "\tspeed: 0.0304s/iter; left time: 410.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 225 | Train Loss: 0.0623167 Vali Loss: 0.0748829 Test Loss: 0.0856129\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0629319\n",
      "\tspeed: 0.0576s/iter; left time: 771.7637s\n",
      "\titers: 200, epoch: 41 | loss: 0.0639222\n",
      "\tspeed: 0.0299s/iter; left time: 397.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0623059 Vali Loss: 0.0749194 Test Loss: 0.0854952\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0605636\n",
      "\tspeed: 0.0492s/iter; left time: 648.6852s\n",
      "\titers: 200, epoch: 42 | loss: 0.0606836\n",
      "\tspeed: 0.0221s/iter; left time: 288.7386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 225 | Train Loss: 0.0622782 Vali Loss: 0.0748565 Test Loss: 0.0855952\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0565898\n",
      "\tspeed: 0.0493s/iter; left time: 638.6200s\n",
      "\titers: 200, epoch: 43 | loss: 0.0611770\n",
      "\tspeed: 0.0267s/iter; left time: 343.0978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 225 | Train Loss: 0.0622456 Vali Loss: 0.0748971 Test Loss: 0.0854784\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0642892\n",
      "\tspeed: 0.0528s/iter; left time: 672.1934s\n",
      "\titers: 200, epoch: 44 | loss: 0.0683638\n",
      "\tspeed: 0.0276s/iter; left time: 348.4717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 225 | Train Loss: 0.0622681 Vali Loss: 0.0748256 Test Loss: 0.0855006\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0622593\n",
      "\tspeed: 0.0586s/iter; left time: 732.2586s\n",
      "\titers: 200, epoch: 45 | loss: 0.0605665\n",
      "\tspeed: 0.0210s/iter; left time: 260.8392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 225 | Train Loss: 0.0622936 Vali Loss: 0.0749247 Test Loss: 0.0855703\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0600760\n",
      "\tspeed: 0.0542s/iter; left time: 665.7845s\n",
      "\titers: 200, epoch: 46 | loss: 0.0623929\n",
      "\tspeed: 0.0317s/iter; left time: 385.6824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 225 | Train Loss: 0.0622719 Vali Loss: 0.0749354 Test Loss: 0.0855073\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0639851\n",
      "\tspeed: 0.0575s/iter; left time: 693.2281s\n",
      "\titers: 200, epoch: 47 | loss: 0.0602245\n",
      "\tspeed: 0.0274s/iter; left time: 327.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0622702 Vali Loss: 0.0748706 Test Loss: 0.0856402\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0641665\n",
      "\tspeed: 0.0577s/iter; left time: 682.3878s\n",
      "\titers: 200, epoch: 48 | loss: 0.0633397\n",
      "\tspeed: 0.0325s/iter; left time: 380.8967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 225 | Train Loss: 0.0622914 Vali Loss: 0.0749426 Test Loss: 0.0856176\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_168_168_FR_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02059786766767502, rmse:0.1435195654630661, mae:0.08558127284049988, rse:0.5558649301528931\n",
      "Intermediate time for FR and pred_len 168: 00h:13m:45.48s\n",
      "Intermediate time for FR: 00h:43m:36.30s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1722920\n",
      "\tspeed: 0.0466s/iter; left time: 1047.7932s\n",
      "\titers: 200, epoch: 1 | loss: 0.1587587\n",
      "\tspeed: 0.0224s/iter; left time: 501.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 226 | Train Loss: 0.1734702 Vali Loss: 0.1441364 Test Loss: 0.1518556\n",
      "Validation loss decreased (inf --> 0.144136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0838304\n",
      "\tspeed: 0.0500s/iter; left time: 1114.3519s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688653\n",
      "\tspeed: 0.0273s/iter; left time: 606.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0924439 Vali Loss: 0.0667544 Test Loss: 0.0691170\n",
      "Validation loss decreased (0.144136 --> 0.066754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0699428\n",
      "\tspeed: 0.0429s/iter; left time: 945.4149s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663636\n",
      "\tspeed: 0.0254s/iter; left time: 557.5768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 226 | Train Loss: 0.0682073 Vali Loss: 0.0617783 Test Loss: 0.0642480\n",
      "Validation loss decreased (0.066754 --> 0.061778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0656166\n",
      "\tspeed: 0.0501s/iter; left time: 1093.3949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616566\n",
      "\tspeed: 0.0250s/iter; left time: 543.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 226 | Train Loss: 0.0641598 Vali Loss: 0.0599115 Test Loss: 0.0625490\n",
      "Validation loss decreased (0.061778 --> 0.059912).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0607398\n",
      "\tspeed: 0.0443s/iter; left time: 955.7134s\n",
      "\titers: 200, epoch: 5 | loss: 0.0655872\n",
      "\tspeed: 0.0279s/iter; left time: 598.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 226 | Train Loss: 0.0618616 Vali Loss: 0.0581040 Test Loss: 0.0608326\n",
      "Validation loss decreased (0.059912 --> 0.058104).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637230\n",
      "\tspeed: 0.0475s/iter; left time: 1015.6593s\n",
      "\titers: 200, epoch: 6 | loss: 0.0615989\n",
      "\tspeed: 0.0289s/iter; left time: 614.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 226 | Train Loss: 0.0603513 Vali Loss: 0.0577327 Test Loss: 0.0602143\n",
      "Validation loss decreased (0.058104 --> 0.057733).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0560802\n",
      "\tspeed: 0.0466s/iter; left time: 984.3494s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570829\n",
      "\tspeed: 0.0317s/iter; left time: 667.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 226 | Train Loss: 0.0592524 Vali Loss: 0.0567816 Test Loss: 0.0594649\n",
      "Validation loss decreased (0.057733 --> 0.056782).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0586033\n",
      "\tspeed: 0.0470s/iter; left time: 983.8485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537227\n",
      "\tspeed: 0.0195s/iter; left time: 406.5318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 226 | Train Loss: 0.0584231 Vali Loss: 0.0563781 Test Loss: 0.0590088\n",
      "Validation loss decreased (0.056782 --> 0.056378).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0586339\n",
      "\tspeed: 0.0498s/iter; left time: 1029.9858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584896\n",
      "\tspeed: 0.0298s/iter; left time: 614.0062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 226 | Train Loss: 0.0579411 Vali Loss: 0.0559900 Test Loss: 0.0586146\n",
      "Validation loss decreased (0.056378 --> 0.055990).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0551709\n",
      "\tspeed: 0.0517s/iter; left time: 1057.3368s\n",
      "\titers: 200, epoch: 10 | loss: 0.0587578\n",
      "\tspeed: 0.0208s/iter; left time: 424.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0574679 Vali Loss: 0.0560114 Test Loss: 0.0584769\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0585615\n",
      "\tspeed: 0.0438s/iter; left time: 885.7086s\n",
      "\titers: 200, epoch: 11 | loss: 0.0552630\n",
      "\tspeed: 0.0261s/iter; left time: 525.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 226 | Train Loss: 0.0570903 Vali Loss: 0.0556922 Test Loss: 0.0582576\n",
      "Validation loss decreased (0.055990 --> 0.055692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560762\n",
      "\tspeed: 0.0485s/iter; left time: 971.5498s\n",
      "\titers: 200, epoch: 12 | loss: 0.0558196\n",
      "\tspeed: 0.0290s/iter; left time: 577.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0568057 Vali Loss: 0.0554588 Test Loss: 0.0579993\n",
      "Validation loss decreased (0.055692 --> 0.055459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569666\n",
      "\tspeed: 0.0505s/iter; left time: 998.4718s\n",
      "\titers: 200, epoch: 13 | loss: 0.0555747\n",
      "\tspeed: 0.0255s/iter; left time: 502.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0565981 Vali Loss: 0.0552518 Test Loss: 0.0578913\n",
      "Validation loss decreased (0.055459 --> 0.055252).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0558258\n",
      "\tspeed: 0.0509s/iter; left time: 996.5387s\n",
      "\titers: 200, epoch: 14 | loss: 0.0579629\n",
      "\tspeed: 0.0196s/iter; left time: 381.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0563426 Vali Loss: 0.0551944 Test Loss: 0.0578140\n",
      "Validation loss decreased (0.055252 --> 0.055194).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0586618\n",
      "\tspeed: 0.0513s/iter; left time: 992.2145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0583563\n",
      "\tspeed: 0.0296s/iter; left time: 568.8735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0561090 Vali Loss: 0.0550931 Test Loss: 0.0576744\n",
      "Validation loss decreased (0.055194 --> 0.055093).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0574588\n",
      "\tspeed: 0.0494s/iter; left time: 944.9844s\n",
      "\titers: 200, epoch: 16 | loss: 0.0512447\n",
      "\tspeed: 0.0280s/iter; left time: 531.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 226 | Train Loss: 0.0560246 Vali Loss: 0.0552220 Test Loss: 0.0576568\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0553269\n",
      "\tspeed: 0.0545s/iter; left time: 1028.7640s\n",
      "\titers: 200, epoch: 17 | loss: 0.0531824\n",
      "\tspeed: 0.0291s/iter; left time: 546.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0558568 Vali Loss: 0.0548910 Test Loss: 0.0575386\n",
      "Validation loss decreased (0.055093 --> 0.054891).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0555530\n",
      "\tspeed: 0.0485s/iter; left time: 905.6786s\n",
      "\titers: 200, epoch: 18 | loss: 0.0592249\n",
      "\tspeed: 0.0299s/iter; left time: 554.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 226 | Train Loss: 0.0557835 Vali Loss: 0.0549858 Test Loss: 0.0574695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0562326\n",
      "\tspeed: 0.0516s/iter; left time: 951.0332s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540442\n",
      "\tspeed: 0.0234s/iter; left time: 429.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 226 | Train Loss: 0.0556622 Vali Loss: 0.0548263 Test Loss: 0.0574125\n",
      "Validation loss decreased (0.054891 --> 0.054826).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0553453\n",
      "\tspeed: 0.0493s/iter; left time: 896.8754s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546516\n",
      "\tspeed: 0.0309s/iter; left time: 560.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0555707 Vali Loss: 0.0548711 Test Loss: 0.0573735\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0602217\n",
      "\tspeed: 0.0543s/iter; left time: 976.2457s\n",
      "\titers: 200, epoch: 21 | loss: 0.0515214\n",
      "\tspeed: 0.0303s/iter; left time: 542.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0555040 Vali Loss: 0.0547479 Test Loss: 0.0572697\n",
      "Validation loss decreased (0.054826 --> 0.054748).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0548368\n",
      "\tspeed: 0.0490s/iter; left time: 869.7081s\n",
      "\titers: 200, epoch: 22 | loss: 0.0516110\n",
      "\tspeed: 0.0297s/iter; left time: 524.4647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 226 | Train Loss: 0.0554181 Vali Loss: 0.0548270 Test Loss: 0.0573799\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0535216\n",
      "\tspeed: 0.0572s/iter; left time: 1001.8378s\n",
      "\titers: 200, epoch: 23 | loss: 0.0567808\n",
      "\tspeed: 0.0306s/iter; left time: 532.5706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0553467 Vali Loss: 0.0547003 Test Loss: 0.0572244\n",
      "Validation loss decreased (0.054748 --> 0.054700).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0522848\n",
      "\tspeed: 0.0513s/iter; left time: 886.9823s\n",
      "\titers: 200, epoch: 24 | loss: 0.0531534\n",
      "\tspeed: 0.0287s/iter; left time: 493.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 226 | Train Loss: 0.0552633 Vali Loss: 0.0546938 Test Loss: 0.0571732\n",
      "Validation loss decreased (0.054700 --> 0.054694).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0584335\n",
      "\tspeed: 0.0545s/iter; left time: 931.1691s\n",
      "\titers: 200, epoch: 25 | loss: 0.0563863\n",
      "\tspeed: 0.0304s/iter; left time: 516.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.94s\n",
      "Steps: 226 | Train Loss: 0.0552093 Vali Loss: 0.0546483 Test Loss: 0.0571411\n",
      "Validation loss decreased (0.054694 --> 0.054648).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0581013\n",
      "\tspeed: 0.0514s/iter; left time: 865.4150s\n",
      "\titers: 200, epoch: 26 | loss: 0.0515195\n",
      "\tspeed: 0.0283s/iter; left time: 473.6914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.66s\n",
      "Steps: 226 | Train Loss: 0.0551662 Vali Loss: 0.0545866 Test Loss: 0.0570727\n",
      "Validation loss decreased (0.054648 --> 0.054587).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0555983\n",
      "\tspeed: 0.0481s/iter; left time: 799.5362s\n",
      "\titers: 200, epoch: 27 | loss: 0.0571013\n",
      "\tspeed: 0.0303s/iter; left time: 501.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 226 | Train Loss: 0.0551253 Vali Loss: 0.0545346 Test Loss: 0.0570563\n",
      "Validation loss decreased (0.054587 --> 0.054535).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532165\n",
      "\tspeed: 0.0503s/iter; left time: 824.6423s\n",
      "\titers: 200, epoch: 28 | loss: 0.0537188\n",
      "\tspeed: 0.0241s/iter; left time: 393.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0550665 Vali Loss: 0.0546836 Test Loss: 0.0571266\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0546076\n",
      "\tspeed: 0.0458s/iter; left time: 740.2816s\n",
      "\titers: 200, epoch: 29 | loss: 0.0585144\n",
      "\tspeed: 0.0245s/iter; left time: 393.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0550691 Vali Loss: 0.0546326 Test Loss: 0.0570762\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0592289\n",
      "\tspeed: 0.0426s/iter; left time: 679.7488s\n",
      "\titers: 200, epoch: 30 | loss: 0.0554572\n",
      "\tspeed: 0.0330s/iter; left time: 522.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0550708 Vali Loss: 0.0545608 Test Loss: 0.0570226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0518227\n",
      "\tspeed: 0.0511s/iter; left time: 803.5668s\n",
      "\titers: 200, epoch: 31 | loss: 0.0575283\n",
      "\tspeed: 0.0294s/iter; left time: 459.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 226 | Train Loss: 0.0550102 Vali Loss: 0.0545234 Test Loss: 0.0570084\n",
      "Validation loss decreased (0.054535 --> 0.054523).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0551268\n",
      "\tspeed: 0.0558s/iter; left time: 864.4731s\n",
      "\titers: 200, epoch: 32 | loss: 0.0559603\n",
      "\tspeed: 0.0302s/iter; left time: 464.1937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0549271 Vali Loss: 0.0546177 Test Loss: 0.0570088\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0536180\n",
      "\tspeed: 0.0521s/iter; left time: 796.1268s\n",
      "\titers: 200, epoch: 33 | loss: 0.0540531\n",
      "\tspeed: 0.0296s/iter; left time: 448.5280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 226 | Train Loss: 0.0549197 Vali Loss: 0.0544921 Test Loss: 0.0569974\n",
      "Validation loss decreased (0.054523 --> 0.054492).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0579632\n",
      "\tspeed: 0.0514s/iter; left time: 773.7752s\n",
      "\titers: 200, epoch: 34 | loss: 0.0566074\n",
      "\tspeed: 0.0262s/iter; left time: 390.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 226 | Train Loss: 0.0549317 Vali Loss: 0.0544925 Test Loss: 0.0569959\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0546267\n",
      "\tspeed: 0.0516s/iter; left time: 764.8886s\n",
      "\titers: 200, epoch: 35 | loss: 0.0580821\n",
      "\tspeed: 0.0243s/iter; left time: 358.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 226 | Train Loss: 0.0549422 Vali Loss: 0.0544724 Test Loss: 0.0569728\n",
      "Validation loss decreased (0.054492 --> 0.054472).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0530931\n",
      "\tspeed: 0.0505s/iter; left time: 736.4218s\n",
      "\titers: 200, epoch: 36 | loss: 0.0523850\n",
      "\tspeed: 0.0223s/iter; left time: 322.4283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 226 | Train Loss: 0.0548634 Vali Loss: 0.0546212 Test Loss: 0.0570231\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0563350\n",
      "\tspeed: 0.0461s/iter; left time: 662.9176s\n",
      "\titers: 200, epoch: 37 | loss: 0.0529748\n",
      "\tspeed: 0.0329s/iter; left time: 468.6977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0548978 Vali Loss: 0.0544274 Test Loss: 0.0569539\n",
      "Validation loss decreased (0.054472 --> 0.054427).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0526294\n",
      "\tspeed: 0.0495s/iter; left time: 699.7500s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548050\n",
      "\tspeed: 0.0354s/iter; left time: 496.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0548673 Vali Loss: 0.0545272 Test Loss: 0.0569506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0569979\n",
      "\tspeed: 0.0497s/iter; left time: 691.1512s\n",
      "\titers: 200, epoch: 39 | loss: 0.0576798\n",
      "\tspeed: 0.0314s/iter; left time: 434.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.79s\n",
      "Steps: 226 | Train Loss: 0.0548625 Vali Loss: 0.0545892 Test Loss: 0.0569690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0517860\n",
      "\tspeed: 0.0542s/iter; left time: 741.9817s\n",
      "\titers: 200, epoch: 40 | loss: 0.0570342\n",
      "\tspeed: 0.0272s/iter; left time: 368.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 226 | Train Loss: 0.0549097 Vali Loss: 0.0545502 Test Loss: 0.0569394\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0541265\n",
      "\tspeed: 0.0490s/iter; left time: 659.3394s\n",
      "\titers: 200, epoch: 41 | loss: 0.0543137\n",
      "\tspeed: 0.0264s/iter; left time: 352.4425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.08s\n",
      "Steps: 226 | Train Loss: 0.0548209 Vali Loss: 0.0545009 Test Loss: 0.0569344\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0553848\n",
      "\tspeed: 0.0529s/iter; left time: 700.2816s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538818\n",
      "\tspeed: 0.0264s/iter; left time: 347.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 226 | Train Loss: 0.0548243 Vali Loss: 0.0544250 Test Loss: 0.0569128\n",
      "Validation loss decreased (0.054427 --> 0.054425).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0578758\n",
      "\tspeed: 0.0505s/iter; left time: 657.2047s\n",
      "\titers: 200, epoch: 43 | loss: 0.0521547\n",
      "\tspeed: 0.0264s/iter; left time: 341.3297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 226 | Train Loss: 0.0548192 Vali Loss: 0.0545450 Test Loss: 0.0569434\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0543596\n",
      "\tspeed: 0.0520s/iter; left time: 664.4097s\n",
      "\titers: 200, epoch: 44 | loss: 0.0613788\n",
      "\tspeed: 0.0302s/iter; left time: 383.5083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.96s\n",
      "Steps: 226 | Train Loss: 0.0548261 Vali Loss: 0.0545051 Test Loss: 0.0569404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0508029\n",
      "\tspeed: 0.0467s/iter; left time: 586.5224s\n",
      "\titers: 200, epoch: 45 | loss: 0.0506523\n",
      "\tspeed: 0.0215s/iter; left time: 267.8139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0547926 Vali Loss: 0.0544245 Test Loss: 0.0569008\n",
      "Validation loss decreased (0.054425 --> 0.054424).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0520498\n",
      "\tspeed: 0.0457s/iter; left time: 563.7957s\n",
      "\titers: 200, epoch: 46 | loss: 0.0523044\n",
      "\tspeed: 0.0221s/iter; left time: 269.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 226 | Train Loss: 0.0547682 Vali Loss: 0.0545463 Test Loss: 0.0569156\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0574238\n",
      "\tspeed: 0.0451s/iter; left time: 545.7565s\n",
      "\titers: 200, epoch: 47 | loss: 0.0556269\n",
      "\tspeed: 0.0276s/iter; left time: 331.1451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 226 | Train Loss: 0.0547832 Vali Loss: 0.0544947 Test Loss: 0.0569419\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0618061\n",
      "\tspeed: 0.0454s/iter; left time: 539.6410s\n",
      "\titers: 200, epoch: 48 | loss: 0.0510770\n",
      "\tspeed: 0.0298s/iter; left time: 351.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 226 | Train Loss: 0.0548322 Vali Loss: 0.0544690 Test Loss: 0.0568793\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0573816\n",
      "\tspeed: 0.0459s/iter; left time: 534.9754s\n",
      "\titers: 200, epoch: 49 | loss: 0.0587271\n",
      "\tspeed: 0.0252s/iter; left time: 291.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 226 | Train Loss: 0.0547939 Vali Loss: 0.0544452 Test Loss: 0.0569674\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0538436\n",
      "\tspeed: 0.0431s/iter; left time: 492.2387s\n",
      "\titers: 200, epoch: 50 | loss: 0.0507912\n",
      "\tspeed: 0.0268s/iter; left time: 303.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 226 | Train Loss: 0.0547728 Vali Loss: 0.0544759 Test Loss: 0.0569447\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0565758\n",
      "\tspeed: 0.0428s/iter; left time: 479.3246s\n",
      "\titers: 200, epoch: 51 | loss: 0.0539639\n",
      "\tspeed: 0.0260s/iter; left time: 288.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 226 | Train Loss: 0.0547863 Vali Loss: 0.0544789 Test Loss: 0.0569067\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0600716\n",
      "\tspeed: 0.0518s/iter; left time: 568.2397s\n",
      "\titers: 200, epoch: 52 | loss: 0.0530268\n",
      "\tspeed: 0.0310s/iter; left time: 337.3292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 226 | Train Loss: 0.0547739 Vali Loss: 0.0543961 Test Loss: 0.0568873\n",
      "Validation loss decreased (0.054424 --> 0.054396).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0557316\n",
      "\tspeed: 0.0501s/iter; left time: 538.2353s\n",
      "\titers: 200, epoch: 53 | loss: 0.0533673\n",
      "\tspeed: 0.0220s/iter; left time: 233.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 226 | Train Loss: 0.0547588 Vali Loss: 0.0544179 Test Loss: 0.0568861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0528737\n",
      "\tspeed: 0.0453s/iter; left time: 477.1364s\n",
      "\titers: 200, epoch: 54 | loss: 0.0514013\n",
      "\tspeed: 0.0207s/iter; left time: 215.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 226 | Train Loss: 0.0547772 Vali Loss: 0.0544544 Test Loss: 0.0569195\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0569595\n",
      "\tspeed: 0.0494s/iter; left time: 508.9980s\n",
      "\titers: 200, epoch: 55 | loss: 0.0540732\n",
      "\tspeed: 0.0237s/iter; left time: 241.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 226 | Train Loss: 0.0547515 Vali Loss: 0.0544371 Test Loss: 0.0569214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0545762\n",
      "\tspeed: 0.0452s/iter; left time: 454.9849s\n",
      "\titers: 200, epoch: 56 | loss: 0.0546318\n",
      "\tspeed: 0.0221s/iter; left time: 220.3745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 226 | Train Loss: 0.0547518 Vali Loss: 0.0543805 Test Loss: 0.0568706\n",
      "Validation loss decreased (0.054396 --> 0.054381).  Saving model ...\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0596362\n",
      "\tspeed: 0.0507s/iter; left time: 499.5512s\n",
      "\titers: 200, epoch: 57 | loss: 0.0530986\n",
      "\tspeed: 0.0297s/iter; left time: 289.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 226 | Train Loss: 0.0547073 Vali Loss: 0.0545350 Test Loss: 0.0569560\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0566301\n",
      "\tspeed: 0.0502s/iter; left time: 483.0940s\n",
      "\titers: 200, epoch: 58 | loss: 0.0558193\n",
      "\tspeed: 0.0268s/iter; left time: 255.3150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0547780 Vali Loss: 0.0544352 Test Loss: 0.0569023\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0588209\n",
      "\tspeed: 0.0423s/iter; left time: 397.2868s\n",
      "\titers: 200, epoch: 59 | loss: 0.0527758\n",
      "\tspeed: 0.0186s/iter; left time: 172.5327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 226 | Train Loss: 0.0547590 Vali Loss: 0.0545020 Test Loss: 0.0569208\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0533794\n",
      "\tspeed: 0.0433s/iter; left time: 396.5315s\n",
      "\titers: 200, epoch: 60 | loss: 0.0580118\n",
      "\tspeed: 0.0199s/iter; left time: 180.3084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 226 | Train Loss: 0.0547262 Vali Loss: 0.0543509 Test Loss: 0.0568823\n",
      "Validation loss decreased (0.054381 --> 0.054351).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0560286\n",
      "\tspeed: 0.0508s/iter; left time: 454.0303s\n",
      "\titers: 200, epoch: 61 | loss: 0.0526540\n",
      "\tspeed: 0.0268s/iter; left time: 236.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 226 | Train Loss: 0.0547945 Vali Loss: 0.0544580 Test Loss: 0.0569107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0547675\n",
      "\tspeed: 0.0444s/iter; left time: 386.6227s\n",
      "\titers: 200, epoch: 62 | loss: 0.0543976\n",
      "\tspeed: 0.0278s/iter; left time: 239.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 226 | Train Loss: 0.0547692 Vali Loss: 0.0543560 Test Loss: 0.0568702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0511734\n",
      "\tspeed: 0.0480s/iter; left time: 407.2850s\n",
      "\titers: 200, epoch: 63 | loss: 0.0591709\n",
      "\tspeed: 0.0257s/iter; left time: 215.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 226 | Train Loss: 0.0547693 Vali Loss: 0.0545519 Test Loss: 0.0569671\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0564905\n",
      "\tspeed: 0.0493s/iter; left time: 407.1880s\n",
      "\titers: 200, epoch: 64 | loss: 0.0595020\n",
      "\tspeed: 0.0235s/iter; left time: 192.1071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0548079 Vali Loss: 0.0545252 Test Loss: 0.0569238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0577908\n",
      "\tspeed: 0.0478s/iter; left time: 384.2557s\n",
      "\titers: 200, epoch: 65 | loss: 0.0582348\n",
      "\tspeed: 0.0254s/iter; left time: 201.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 226 | Train Loss: 0.0547158 Vali Loss: 0.0544442 Test Loss: 0.0568673\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0521134\n",
      "\tspeed: 0.0458s/iter; left time: 357.9288s\n",
      "\titers: 200, epoch: 66 | loss: 0.0571456\n",
      "\tspeed: 0.0281s/iter; left time: 216.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 226 | Train Loss: 0.0547606 Vali Loss: 0.0544804 Test Loss: 0.0569185\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0545808\n",
      "\tspeed: 0.0533s/iter; left time: 404.3548s\n",
      "\titers: 200, epoch: 67 | loss: 0.0523171\n",
      "\tspeed: 0.0185s/iter; left time: 138.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0547814 Vali Loss: 0.0545069 Test Loss: 0.0568956\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0553125\n",
      "\tspeed: 0.0504s/iter; left time: 370.9870s\n",
      "\titers: 200, epoch: 68 | loss: 0.0524824\n",
      "\tspeed: 0.0286s/iter; left time: 207.2805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 226 | Train Loss: 0.0547916 Vali Loss: 0.0544979 Test Loss: 0.0569650\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0552361\n",
      "\tspeed: 0.0490s/iter; left time: 349.8172s\n",
      "\titers: 200, epoch: 69 | loss: 0.0531105\n",
      "\tspeed: 0.0279s/iter; left time: 196.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 226 | Train Loss: 0.0547940 Vali Loss: 0.0545501 Test Loss: 0.0569191\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0555499\n",
      "\tspeed: 0.0491s/iter; left time: 339.4557s\n",
      "\titers: 200, epoch: 70 | loss: 0.0586882\n",
      "\tspeed: 0.0284s/iter; left time: 193.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:06.57s\n",
      "Steps: 226 | Train Loss: 0.0547468 Vali Loss: 0.0544531 Test Loss: 0.0568987\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010126727633178234, rmse:0.10063164681196213, mae:0.056882333010435104, rse:0.3802374303340912\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1671183\n",
      "\tspeed: 0.0261s/iter; left time: 586.3574s\n",
      "\titers: 200, epoch: 1 | loss: 0.1493597\n",
      "\tspeed: 0.0254s/iter; left time: 569.7711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 226 | Train Loss: 0.1708172 Vali Loss: 0.1430496 Test Loss: 0.1509800\n",
      "Validation loss decreased (inf --> 0.143050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894919\n",
      "\tspeed: 0.0462s/iter; left time: 1029.5477s\n",
      "\titers: 200, epoch: 2 | loss: 0.0741505\n",
      "\tspeed: 0.0246s/iter; left time: 546.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0934774 Vali Loss: 0.0673926 Test Loss: 0.0698875\n",
      "Validation loss decreased (0.143050 --> 0.067393).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0690908\n",
      "\tspeed: 0.0469s/iter; left time: 1033.7647s\n",
      "\titers: 200, epoch: 3 | loss: 0.0651288\n",
      "\tspeed: 0.0231s/iter; left time: 506.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 226 | Train Loss: 0.0686555 Vali Loss: 0.0616349 Test Loss: 0.0644420\n",
      "Validation loss decreased (0.067393 --> 0.061635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637166\n",
      "\tspeed: 0.0464s/iter; left time: 1013.4318s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618543\n",
      "\tspeed: 0.0244s/iter; left time: 530.8369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 226 | Train Loss: 0.0643276 Vali Loss: 0.0595802 Test Loss: 0.0624841\n",
      "Validation loss decreased (0.061635 --> 0.059580).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620772\n",
      "\tspeed: 0.0497s/iter; left time: 1072.8426s\n",
      "\titers: 200, epoch: 5 | loss: 0.0610805\n",
      "\tspeed: 0.0261s/iter; left time: 560.9989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 226 | Train Loss: 0.0621152 Vali Loss: 0.0583595 Test Loss: 0.0613081\n",
      "Validation loss decreased (0.059580 --> 0.058359).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0622094\n",
      "\tspeed: 0.0528s/iter; left time: 1128.4955s\n",
      "\titers: 200, epoch: 6 | loss: 0.0586622\n",
      "\tspeed: 0.0242s/iter; left time: 515.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 226 | Train Loss: 0.0608144 Vali Loss: 0.0577665 Test Loss: 0.0608487\n",
      "Validation loss decreased (0.058359 --> 0.057767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0609338\n",
      "\tspeed: 0.0520s/iter; left time: 1098.6852s\n",
      "\titers: 200, epoch: 7 | loss: 0.0570468\n",
      "\tspeed: 0.0278s/iter; left time: 585.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 226 | Train Loss: 0.0597690 Vali Loss: 0.0570377 Test Loss: 0.0599500\n",
      "Validation loss decreased (0.057767 --> 0.057038).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0550718\n",
      "\tspeed: 0.0537s/iter; left time: 1123.7628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0665458\n",
      "\tspeed: 0.0316s/iter; left time: 658.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0589198 Vali Loss: 0.0561305 Test Loss: 0.0592737\n",
      "Validation loss decreased (0.057038 --> 0.056130).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0612751\n",
      "\tspeed: 0.0578s/iter; left time: 1195.5991s\n",
      "\titers: 200, epoch: 9 | loss: 0.0568842\n",
      "\tspeed: 0.0259s/iter; left time: 533.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 226 | Train Loss: 0.0583483 Vali Loss: 0.0559387 Test Loss: 0.0588987\n",
      "Validation loss decreased (0.056130 --> 0.055939).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585441\n",
      "\tspeed: 0.0504s/iter; left time: 1032.3465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0598325\n",
      "\tspeed: 0.0311s/iter; left time: 632.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.85s\n",
      "Steps: 226 | Train Loss: 0.0578611 Vali Loss: 0.0558667 Test Loss: 0.0586031\n",
      "Validation loss decreased (0.055939 --> 0.055867).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0586685\n",
      "\tspeed: 0.0520s/iter; left time: 1053.2859s\n",
      "\titers: 200, epoch: 11 | loss: 0.0560532\n",
      "\tspeed: 0.0302s/iter; left time: 607.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 226 | Train Loss: 0.0575143 Vali Loss: 0.0555754 Test Loss: 0.0584051\n",
      "Validation loss decreased (0.055867 --> 0.055575).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553717\n",
      "\tspeed: 0.0561s/iter; left time: 1122.0926s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553700\n",
      "\tspeed: 0.0303s/iter; left time: 602.6951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0572109 Vali Loss: 0.0554275 Test Loss: 0.0582681\n",
      "Validation loss decreased (0.055575 --> 0.055428).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0546830\n",
      "\tspeed: 0.0471s/iter; left time: 932.7866s\n",
      "\titers: 200, epoch: 13 | loss: 0.0599364\n",
      "\tspeed: 0.0243s/iter; left time: 478.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 226 | Train Loss: 0.0569612 Vali Loss: 0.0553732 Test Loss: 0.0580842\n",
      "Validation loss decreased (0.055428 --> 0.055373).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0562301\n",
      "\tspeed: 0.0466s/iter; left time: 911.1899s\n",
      "\titers: 200, epoch: 14 | loss: 0.0562018\n",
      "\tspeed: 0.0246s/iter; left time: 479.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 226 | Train Loss: 0.0566864 Vali Loss: 0.0550656 Test Loss: 0.0577854\n",
      "Validation loss decreased (0.055373 --> 0.055066).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0606462\n",
      "\tspeed: 0.0469s/iter; left time: 907.4004s\n",
      "\titers: 200, epoch: 15 | loss: 0.0547147\n",
      "\tspeed: 0.0238s/iter; left time: 457.4420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0564601 Vali Loss: 0.0550560 Test Loss: 0.0578406\n",
      "Validation loss decreased (0.055066 --> 0.055056).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0586123\n",
      "\tspeed: 0.0513s/iter; left time: 979.4401s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542631\n",
      "\tspeed: 0.0231s/iter; left time: 439.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 226 | Train Loss: 0.0563156 Vali Loss: 0.0549847 Test Loss: 0.0577916\n",
      "Validation loss decreased (0.055056 --> 0.054985).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0525569\n",
      "\tspeed: 0.0496s/iter; left time: 935.9065s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540291\n",
      "\tspeed: 0.0231s/iter; left time: 434.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 226 | Train Loss: 0.0561593 Vali Loss: 0.0548957 Test Loss: 0.0575398\n",
      "Validation loss decreased (0.054985 --> 0.054896).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549057\n",
      "\tspeed: 0.0475s/iter; left time: 887.1360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0582623\n",
      "\tspeed: 0.0250s/iter; left time: 463.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 226 | Train Loss: 0.0560078 Vali Loss: 0.0548554 Test Loss: 0.0574899\n",
      "Validation loss decreased (0.054896 --> 0.054855).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0570154\n",
      "\tspeed: 0.0509s/iter; left time: 937.5739s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589034\n",
      "\tspeed: 0.0250s/iter; left time: 457.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 226 | Train Loss: 0.0559835 Vali Loss: 0.0548761 Test Loss: 0.0575250\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0533867\n",
      "\tspeed: 0.0475s/iter; left time: 864.4540s\n",
      "\titers: 200, epoch: 20 | loss: 0.0564308\n",
      "\tspeed: 0.0233s/iter; left time: 421.5848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 226 | Train Loss: 0.0559020 Vali Loss: 0.0548729 Test Loss: 0.0574068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0547154\n",
      "\tspeed: 0.0516s/iter; left time: 928.5613s\n",
      "\titers: 200, epoch: 21 | loss: 0.0591372\n",
      "\tspeed: 0.0225s/iter; left time: 402.5486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 226 | Train Loss: 0.0557124 Vali Loss: 0.0547077 Test Loss: 0.0573593\n",
      "Validation loss decreased (0.054855 --> 0.054708).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0538523\n",
      "\tspeed: 0.0493s/iter; left time: 874.8137s\n",
      "\titers: 200, epoch: 22 | loss: 0.0558532\n",
      "\tspeed: 0.0250s/iter; left time: 440.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 226 | Train Loss: 0.0556812 Vali Loss: 0.0545233 Test Loss: 0.0572733\n",
      "Validation loss decreased (0.054708 --> 0.054523).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0537412\n",
      "\tspeed: 0.0435s/iter; left time: 762.9864s\n",
      "\titers: 200, epoch: 23 | loss: 0.0565237\n",
      "\tspeed: 0.0247s/iter; left time: 430.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0555625 Vali Loss: 0.0545978 Test Loss: 0.0572175\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0569870\n",
      "\tspeed: 0.0462s/iter; left time: 798.5345s\n",
      "\titers: 200, epoch: 24 | loss: 0.0586887\n",
      "\tspeed: 0.0263s/iter; left time: 452.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 226 | Train Loss: 0.0555227 Vali Loss: 0.0545563 Test Loss: 0.0572211\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0559320\n",
      "\tspeed: 0.0506s/iter; left time: 864.7210s\n",
      "\titers: 200, epoch: 25 | loss: 0.0623908\n",
      "\tspeed: 0.0269s/iter; left time: 455.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 226 | Train Loss: 0.0554853 Vali Loss: 0.0546439 Test Loss: 0.0572556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0572326\n",
      "\tspeed: 0.0439s/iter; left time: 739.7119s\n",
      "\titers: 200, epoch: 26 | loss: 0.0553266\n",
      "\tspeed: 0.0240s/iter; left time: 402.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 226 | Train Loss: 0.0554122 Vali Loss: 0.0546292 Test Loss: 0.0572165\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0557066\n",
      "\tspeed: 0.0495s/iter; left time: 822.2588s\n",
      "\titers: 200, epoch: 27 | loss: 0.0552947\n",
      "\tspeed: 0.0286s/iter; left time: 473.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 226 | Train Loss: 0.0553655 Vali Loss: 0.0545335 Test Loss: 0.0571195\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0536001\n",
      "\tspeed: 0.0491s/iter; left time: 805.8637s\n",
      "\titers: 200, epoch: 28 | loss: 0.0544457\n",
      "\tspeed: 0.0239s/iter; left time: 389.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0553575 Vali Loss: 0.0545017 Test Loss: 0.0571133\n",
      "Validation loss decreased (0.054523 --> 0.054502).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0525365\n",
      "\tspeed: 0.0543s/iter; left time: 878.0734s\n",
      "\titers: 200, epoch: 29 | loss: 0.0512349\n",
      "\tspeed: 0.0298s/iter; left time: 479.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.08s\n",
      "Steps: 226 | Train Loss: 0.0552837 Vali Loss: 0.0545020 Test Loss: 0.0571912\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0555779\n",
      "\tspeed: 0.0465s/iter; left time: 741.3302s\n",
      "\titers: 200, epoch: 30 | loss: 0.0550966\n",
      "\tspeed: 0.0264s/iter; left time: 418.0493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 226 | Train Loss: 0.0552685 Vali Loss: 0.0545906 Test Loss: 0.0571831\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0581115\n",
      "\tspeed: 0.0475s/iter; left time: 746.4065s\n",
      "\titers: 200, epoch: 31 | loss: 0.0507683\n",
      "\tspeed: 0.0244s/iter; left time: 381.3370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 226 | Train Loss: 0.0552550 Vali Loss: 0.0545533 Test Loss: 0.0571081\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0543378\n",
      "\tspeed: 0.0421s/iter; left time: 651.6769s\n",
      "\titers: 200, epoch: 32 | loss: 0.0567470\n",
      "\tspeed: 0.0265s/iter; left time: 407.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 226 | Train Loss: 0.0552130 Vali Loss: 0.0544021 Test Loss: 0.0570437\n",
      "Validation loss decreased (0.054502 --> 0.054402).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0533559\n",
      "\tspeed: 0.0460s/iter; left time: 702.7662s\n",
      "\titers: 200, epoch: 33 | loss: 0.0527099\n",
      "\tspeed: 0.0248s/iter; left time: 375.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0551895 Vali Loss: 0.0543914 Test Loss: 0.0570647\n",
      "Validation loss decreased (0.054402 --> 0.054391).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0556570\n",
      "\tspeed: 0.0515s/iter; left time: 775.0225s\n",
      "\titers: 200, epoch: 34 | loss: 0.0527466\n",
      "\tspeed: 0.0312s/iter; left time: 466.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 226 | Train Loss: 0.0552035 Vali Loss: 0.0546156 Test Loss: 0.0571556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0529002\n",
      "\tspeed: 0.0532s/iter; left time: 788.1281s\n",
      "\titers: 200, epoch: 35 | loss: 0.0546057\n",
      "\tspeed: 0.0319s/iter; left time: 469.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 226 | Train Loss: 0.0551364 Vali Loss: 0.0545817 Test Loss: 0.0571406\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0545301\n",
      "\tspeed: 0.0494s/iter; left time: 720.7291s\n",
      "\titers: 200, epoch: 36 | loss: 0.0542963\n",
      "\tspeed: 0.0225s/iter; left time: 326.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 226 | Train Loss: 0.0551355 Vali Loss: 0.0544014 Test Loss: 0.0570049\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0592082\n",
      "\tspeed: 0.0446s/iter; left time: 641.3640s\n",
      "\titers: 200, epoch: 37 | loss: 0.0578923\n",
      "\tspeed: 0.0233s/iter; left time: 332.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 226 | Train Loss: 0.0550899 Vali Loss: 0.0544372 Test Loss: 0.0570175\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0575181\n",
      "\tspeed: 0.0439s/iter; left time: 620.9215s\n",
      "\titers: 200, epoch: 38 | loss: 0.0554402\n",
      "\tspeed: 0.0245s/iter; left time: 344.6493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 226 | Train Loss: 0.0551337 Vali Loss: 0.0544084 Test Loss: 0.0569866\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0539549\n",
      "\tspeed: 0.0505s/iter; left time: 703.2806s\n",
      "\titers: 200, epoch: 39 | loss: 0.0599985\n",
      "\tspeed: 0.0298s/iter; left time: 412.0970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 226 | Train Loss: 0.0550835 Vali Loss: 0.0544412 Test Loss: 0.0569934\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0555178\n",
      "\tspeed: 0.0540s/iter; left time: 739.5891s\n",
      "\titers: 200, epoch: 40 | loss: 0.0535621\n",
      "\tspeed: 0.0301s/iter; left time: 408.5093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 226 | Train Loss: 0.0551042 Vali Loss: 0.0544443 Test Loss: 0.0570305\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0544481\n",
      "\tspeed: 0.0544s/iter; left time: 731.8295s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571609\n",
      "\tspeed: 0.0271s/iter; left time: 361.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 226 | Train Loss: 0.0550469 Vali Loss: 0.0544577 Test Loss: 0.0570496\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0541435\n",
      "\tspeed: 0.0496s/iter; left time: 656.0533s\n",
      "\titers: 200, epoch: 42 | loss: 0.0584221\n",
      "\tspeed: 0.0276s/iter; left time: 361.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 226 | Train Loss: 0.0550190 Vali Loss: 0.0543569 Test Loss: 0.0569765\n",
      "Validation loss decreased (0.054391 --> 0.054357).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0570098\n",
      "\tspeed: 0.0517s/iter; left time: 672.3974s\n",
      "\titers: 200, epoch: 43 | loss: 0.0529481\n",
      "\tspeed: 0.0281s/iter; left time: 362.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0550399 Vali Loss: 0.0543499 Test Loss: 0.0569851\n",
      "Validation loss decreased (0.054357 --> 0.054350).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0537824\n",
      "\tspeed: 0.0617s/iter; left time: 788.2781s\n",
      "\titers: 200, epoch: 44 | loss: 0.0584286\n",
      "\tspeed: 0.0307s/iter; left time: 389.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0549981 Vali Loss: 0.0545196 Test Loss: 0.0570577\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0544152\n",
      "\tspeed: 0.0522s/iter; left time: 655.7470s\n",
      "\titers: 200, epoch: 45 | loss: 0.0531305\n",
      "\tspeed: 0.0272s/iter; left time: 339.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 226 | Train Loss: 0.0550469 Vali Loss: 0.0544084 Test Loss: 0.0569764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0552234\n",
      "\tspeed: 0.0528s/iter; left time: 650.7892s\n",
      "\titers: 200, epoch: 46 | loss: 0.0589482\n",
      "\tspeed: 0.0335s/iter; left time: 409.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.0550391 Vali Loss: 0.0543831 Test Loss: 0.0569450\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0558735\n",
      "\tspeed: 0.0594s/iter; left time: 719.0240s\n",
      "\titers: 200, epoch: 47 | loss: 0.0562957\n",
      "\tspeed: 0.0300s/iter; left time: 359.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0550245 Vali Loss: 0.0544049 Test Loss: 0.0569942\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0557008\n",
      "\tspeed: 0.0530s/iter; left time: 629.6357s\n",
      "\titers: 200, epoch: 48 | loss: 0.0573912\n",
      "\tspeed: 0.0292s/iter; left time: 344.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 226 | Train Loss: 0.0550281 Vali Loss: 0.0544020 Test Loss: 0.0570180\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0546718\n",
      "\tspeed: 0.0476s/iter; left time: 554.5971s\n",
      "\titers: 200, epoch: 49 | loss: 0.0545007\n",
      "\tspeed: 0.0293s/iter; left time: 337.9737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 226 | Train Loss: 0.0549733 Vali Loss: 0.0545117 Test Loss: 0.0570557\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0567902\n",
      "\tspeed: 0.0509s/iter; left time: 581.8192s\n",
      "\titers: 200, epoch: 50 | loss: 0.0535607\n",
      "\tspeed: 0.0241s/iter; left time: 272.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 226 | Train Loss: 0.0549857 Vali Loss: 0.0542776 Test Loss: 0.0569479\n",
      "Validation loss decreased (0.054350 --> 0.054278).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0541929\n",
      "\tspeed: 0.0524s/iter; left time: 586.9150s\n",
      "\titers: 200, epoch: 51 | loss: 0.0532043\n",
      "\tspeed: 0.0299s/iter; left time: 331.8213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 226 | Train Loss: 0.0550235 Vali Loss: 0.0544153 Test Loss: 0.0570159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0517970\n",
      "\tspeed: 0.0552s/iter; left time: 605.8079s\n",
      "\titers: 200, epoch: 52 | loss: 0.0561695\n",
      "\tspeed: 0.0317s/iter; left time: 345.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0550057 Vali Loss: 0.0544147 Test Loss: 0.0569938\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0564113\n",
      "\tspeed: 0.0472s/iter; left time: 507.2525s\n",
      "\titers: 200, epoch: 53 | loss: 0.0545869\n",
      "\tspeed: 0.0295s/iter; left time: 314.0962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 226 | Train Loss: 0.0549994 Vali Loss: 0.0542674 Test Loss: 0.0569478\n",
      "Validation loss decreased (0.054278 --> 0.054267).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0558922\n",
      "\tspeed: 0.0502s/iter; left time: 528.1924s\n",
      "\titers: 200, epoch: 54 | loss: 0.0500513\n",
      "\tspeed: 0.0287s/iter; left time: 299.1153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 226 | Train Loss: 0.0549873 Vali Loss: 0.0543921 Test Loss: 0.0569369\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0583103\n",
      "\tspeed: 0.0559s/iter; left time: 575.1348s\n",
      "\titers: 200, epoch: 55 | loss: 0.0526342\n",
      "\tspeed: 0.0314s/iter; left time: 319.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0549969 Vali Loss: 0.0544587 Test Loss: 0.0570053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0560073\n",
      "\tspeed: 0.0503s/iter; left time: 506.6557s\n",
      "\titers: 200, epoch: 56 | loss: 0.0549848\n",
      "\tspeed: 0.0284s/iter; left time: 283.0088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 226 | Train Loss: 0.0549915 Vali Loss: 0.0544629 Test Loss: 0.0569569\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0586904\n",
      "\tspeed: 0.0553s/iter; left time: 544.0501s\n",
      "\titers: 200, epoch: 57 | loss: 0.0569365\n",
      "\tspeed: 0.0310s/iter; left time: 301.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0550113 Vali Loss: 0.0543688 Test Loss: 0.0569486\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0548015\n",
      "\tspeed: 0.0467s/iter; left time: 449.1191s\n",
      "\titers: 200, epoch: 58 | loss: 0.0559248\n",
      "\tspeed: 0.0306s/iter; left time: 291.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:06.49s\n",
      "Steps: 226 | Train Loss: 0.0550106 Vali Loss: 0.0544411 Test Loss: 0.0570273\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0563634\n",
      "\tspeed: 0.0561s/iter; left time: 526.9429s\n",
      "\titers: 200, epoch: 59 | loss: 0.0529164\n",
      "\tspeed: 0.0298s/iter; left time: 276.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0550187 Vali Loss: 0.0543835 Test Loss: 0.0569421\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0513109\n",
      "\tspeed: 0.0463s/iter; left time: 424.5147s\n",
      "\titers: 200, epoch: 60 | loss: 0.0575434\n",
      "\tspeed: 0.0301s/iter; left time: 273.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 226 | Train Loss: 0.0550089 Vali Loss: 0.0544088 Test Loss: 0.0569655\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0525246\n",
      "\tspeed: 0.0568s/iter; left time: 507.9152s\n",
      "\titers: 200, epoch: 61 | loss: 0.0528906\n",
      "\tspeed: 0.0336s/iter; left time: 297.3657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 226 | Train Loss: 0.0549117 Vali Loss: 0.0544557 Test Loss: 0.0569940\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0564995\n",
      "\tspeed: 0.0593s/iter; left time: 516.9842s\n",
      "\titers: 200, epoch: 62 | loss: 0.0514744\n",
      "\tspeed: 0.0296s/iter; left time: 255.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 226 | Train Loss: 0.0550009 Vali Loss: 0.0542982 Test Loss: 0.0569604\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0603337\n",
      "\tspeed: 0.0545s/iter; left time: 462.6180s\n",
      "\titers: 200, epoch: 63 | loss: 0.0585992\n",
      "\tspeed: 0.0264s/iter; left time: 221.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 226 | Train Loss: 0.0549873 Vali Loss: 0.0543450 Test Loss: 0.0569679\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_24_IT_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010085921734571457, rmse:0.10042869299650192, mae:0.05694780498743057, rse:0.379470556974411\n",
      "Intermediate time for IT and pred_len 24: 00h:17m:12.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1805620\n",
      "\tspeed: 0.0519s/iter; left time: 1162.8633s\n",
      "\titers: 200, epoch: 1 | loss: 0.1604668\n",
      "\tspeed: 0.0293s/iter; left time: 654.3453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.61s\n",
      "Steps: 225 | Train Loss: 0.1799002 Vali Loss: 0.1531601 Test Loss: 0.1623265\n",
      "Validation loss decreased (inf --> 0.153160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1056841\n",
      "\tspeed: 0.0474s/iter; left time: 1051.1115s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949816\n",
      "\tspeed: 0.0230s/iter; left time: 507.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 225 | Train Loss: 0.1107018 Vali Loss: 0.0847156 Test Loss: 0.0898317\n",
      "Validation loss decreased (0.153160 --> 0.084716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903883\n",
      "\tspeed: 0.0451s/iter; left time: 990.5345s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877064\n",
      "\tspeed: 0.0242s/iter; left time: 529.3414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0886370 Vali Loss: 0.0799162 Test Loss: 0.0851156\n",
      "Validation loss decreased (0.084716 --> 0.079916).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849233\n",
      "\tspeed: 0.0496s/iter; left time: 1077.2709s\n",
      "\titers: 200, epoch: 4 | loss: 0.0863226\n",
      "\tspeed: 0.0337s/iter; left time: 728.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 225 | Train Loss: 0.0846948 Vali Loss: 0.0781025 Test Loss: 0.0833411\n",
      "Validation loss decreased (0.079916 --> 0.078102).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819032\n",
      "\tspeed: 0.0556s/iter; left time: 1194.4493s\n",
      "\titers: 200, epoch: 5 | loss: 0.0811997\n",
      "\tspeed: 0.0303s/iter; left time: 648.5425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 225 | Train Loss: 0.0823563 Vali Loss: 0.0769063 Test Loss: 0.0825890\n",
      "Validation loss decreased (0.078102 --> 0.076906).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839242\n",
      "\tspeed: 0.0478s/iter; left time: 1017.8120s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821715\n",
      "\tspeed: 0.0244s/iter; left time: 515.9615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0809487 Vali Loss: 0.0761848 Test Loss: 0.0819233\n",
      "Validation loss decreased (0.076906 --> 0.076185).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0793673\n",
      "\tspeed: 0.0451s/iter; left time: 948.5124s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810894\n",
      "\tspeed: 0.0228s/iter; left time: 477.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 225 | Train Loss: 0.0799971 Vali Loss: 0.0757786 Test Loss: 0.0812300\n",
      "Validation loss decreased (0.076185 --> 0.075779).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0806313\n",
      "\tspeed: 0.0484s/iter; left time: 1007.3201s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806243\n",
      "\tspeed: 0.0210s/iter; left time: 435.2683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 225 | Train Loss: 0.0793282 Vali Loss: 0.0756721 Test Loss: 0.0810366\n",
      "Validation loss decreased (0.075779 --> 0.075672).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0797274\n",
      "\tspeed: 0.0485s/iter; left time: 998.5841s\n",
      "\titers: 200, epoch: 9 | loss: 0.0800558\n",
      "\tspeed: 0.0332s/iter; left time: 681.5667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 225 | Train Loss: 0.0788017 Vali Loss: 0.0751570 Test Loss: 0.0806254\n",
      "Validation loss decreased (0.075672 --> 0.075157).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781363\n",
      "\tspeed: 0.0529s/iter; left time: 1078.2643s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821204\n",
      "\tspeed: 0.0295s/iter; left time: 598.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.76s\n",
      "Steps: 225 | Train Loss: 0.0784086 Vali Loss: 0.0748331 Test Loss: 0.0803863\n",
      "Validation loss decreased (0.075157 --> 0.074833).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0773081\n",
      "\tspeed: 0.0506s/iter; left time: 1019.2319s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769340\n",
      "\tspeed: 0.0306s/iter; left time: 613.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0780557 Vali Loss: 0.0748576 Test Loss: 0.0803838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0739010\n",
      "\tspeed: 0.0428s/iter; left time: 852.3341s\n",
      "\titers: 200, epoch: 12 | loss: 0.0764393\n",
      "\tspeed: 0.0192s/iter; left time: 380.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.88s\n",
      "Steps: 225 | Train Loss: 0.0778147 Vali Loss: 0.0747394 Test Loss: 0.0802362\n",
      "Validation loss decreased (0.074833 --> 0.074739).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0770929\n",
      "\tspeed: 0.0480s/iter; left time: 945.0190s\n",
      "\titers: 200, epoch: 13 | loss: 0.0768943\n",
      "\tspeed: 0.0232s/iter; left time: 454.6449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 225 | Train Loss: 0.0775008 Vali Loss: 0.0745214 Test Loss: 0.0799649\n",
      "Validation loss decreased (0.074739 --> 0.074521).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0770124\n",
      "\tspeed: 0.0580s/iter; left time: 1129.6667s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781280\n",
      "\tspeed: 0.0316s/iter; left time: 611.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 225 | Train Loss: 0.0772693 Vali Loss: 0.0744808 Test Loss: 0.0800061\n",
      "Validation loss decreased (0.074521 --> 0.074481).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0770420\n",
      "\tspeed: 0.0524s/iter; left time: 1008.7737s\n",
      "\titers: 200, epoch: 15 | loss: 0.0778218\n",
      "\tspeed: 0.0299s/iter; left time: 572.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0771457 Vali Loss: 0.0745342 Test Loss: 0.0800457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0788047\n",
      "\tspeed: 0.0590s/iter; left time: 1121.7168s\n",
      "\titers: 200, epoch: 16 | loss: 0.0733577\n",
      "\tspeed: 0.0333s/iter; left time: 630.8500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.79s\n",
      "Steps: 225 | Train Loss: 0.0768803 Vali Loss: 0.0745147 Test Loss: 0.0799389\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0849317\n",
      "\tspeed: 0.0441s/iter; left time: 828.3722s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769682\n",
      "\tspeed: 0.0203s/iter; left time: 379.8736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.0767694 Vali Loss: 0.0743689 Test Loss: 0.0799724\n",
      "Validation loss decreased (0.074481 --> 0.074369).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0740751\n",
      "\tspeed: 0.0533s/iter; left time: 989.6025s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740322\n",
      "\tspeed: 0.0317s/iter; left time: 586.0610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 225 | Train Loss: 0.0765871 Vali Loss: 0.0741889 Test Loss: 0.0799109\n",
      "Validation loss decreased (0.074369 --> 0.074189).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0762765\n",
      "\tspeed: 0.0469s/iter; left time: 860.5855s\n",
      "\titers: 200, epoch: 19 | loss: 0.0740567\n",
      "\tspeed: 0.0296s/iter; left time: 539.8495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0764642 Vali Loss: 0.0741447 Test Loss: 0.0797611\n",
      "Validation loss decreased (0.074189 --> 0.074145).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0760027\n",
      "\tspeed: 0.0578s/iter; left time: 1048.1331s\n",
      "\titers: 200, epoch: 20 | loss: 0.0772175\n",
      "\tspeed: 0.0346s/iter; left time: 623.4148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.70s\n",
      "Steps: 225 | Train Loss: 0.0763880 Vali Loss: 0.0741452 Test Loss: 0.0796693\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0732374\n",
      "\tspeed: 0.0528s/iter; left time: 944.8037s\n",
      "\titers: 200, epoch: 21 | loss: 0.0762790\n",
      "\tspeed: 0.0319s/iter; left time: 567.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 225 | Train Loss: 0.0762697 Vali Loss: 0.0740867 Test Loss: 0.0798120\n",
      "Validation loss decreased (0.074145 --> 0.074087).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0756372\n",
      "\tspeed: 0.0530s/iter; left time: 936.4639s\n",
      "\titers: 200, epoch: 22 | loss: 0.0716529\n",
      "\tspeed: 0.0277s/iter; left time: 486.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0761757 Vali Loss: 0.0741539 Test Loss: 0.0797682\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0771927\n",
      "\tspeed: 0.0468s/iter; left time: 816.5573s\n",
      "\titers: 200, epoch: 23 | loss: 0.0765624\n",
      "\tspeed: 0.0259s/iter; left time: 450.0137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0761410 Vali Loss: 0.0740627 Test Loss: 0.0797253\n",
      "Validation loss decreased (0.074087 --> 0.074063).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0768347\n",
      "\tspeed: 0.0519s/iter; left time: 894.4645s\n",
      "\titers: 200, epoch: 24 | loss: 0.0757049\n",
      "\tspeed: 0.0296s/iter; left time: 507.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0760581 Vali Loss: 0.0740495 Test Loss: 0.0796765\n",
      "Validation loss decreased (0.074063 --> 0.074050).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0780853\n",
      "\tspeed: 0.0502s/iter; left time: 852.8996s\n",
      "\titers: 200, epoch: 25 | loss: 0.0782617\n",
      "\tspeed: 0.0296s/iter; left time: 499.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0759656 Vali Loss: 0.0740208 Test Loss: 0.0797114\n",
      "Validation loss decreased (0.074050 --> 0.074021).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0729303\n",
      "\tspeed: 0.0489s/iter; left time: 820.1862s\n",
      "\titers: 200, epoch: 26 | loss: 0.0760167\n",
      "\tspeed: 0.0202s/iter; left time: 337.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 225 | Train Loss: 0.0759042 Vali Loss: 0.0740213 Test Loss: 0.0797527\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0779798\n",
      "\tspeed: 0.0469s/iter; left time: 775.9772s\n",
      "\titers: 200, epoch: 27 | loss: 0.0730974\n",
      "\tspeed: 0.0262s/iter; left time: 430.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0758558 Vali Loss: 0.0739786 Test Loss: 0.0797341\n",
      "Validation loss decreased (0.074021 --> 0.073979).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0789156\n",
      "\tspeed: 0.0505s/iter; left time: 825.2561s\n",
      "\titers: 200, epoch: 28 | loss: 0.0755482\n",
      "\tspeed: 0.0335s/iter; left time: 543.8115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.98s\n",
      "Steps: 225 | Train Loss: 0.0758470 Vali Loss: 0.0740256 Test Loss: 0.0797478\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0742041\n",
      "\tspeed: 0.0517s/iter; left time: 832.5813s\n",
      "\titers: 200, epoch: 29 | loss: 0.0770120\n",
      "\tspeed: 0.0298s/iter; left time: 476.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 225 | Train Loss: 0.0757809 Vali Loss: 0.0739312 Test Loss: 0.0796134\n",
      "Validation loss decreased (0.073979 --> 0.073931).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0743474\n",
      "\tspeed: 0.0497s/iter; left time: 788.5267s\n",
      "\titers: 200, epoch: 30 | loss: 0.0743649\n",
      "\tspeed: 0.0284s/iter; left time: 448.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 225 | Train Loss: 0.0757547 Vali Loss: 0.0738966 Test Loss: 0.0796489\n",
      "Validation loss decreased (0.073931 --> 0.073897).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0769657\n",
      "\tspeed: 0.0498s/iter; left time: 778.7611s\n",
      "\titers: 200, epoch: 31 | loss: 0.0767465\n",
      "\tspeed: 0.0337s/iter; left time: 523.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.00s\n",
      "Steps: 225 | Train Loss: 0.0757479 Vali Loss: 0.0739233 Test Loss: 0.0796932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0746304\n",
      "\tspeed: 0.0539s/iter; left time: 832.0435s\n",
      "\titers: 200, epoch: 32 | loss: 0.0737139\n",
      "\tspeed: 0.0296s/iter; left time: 452.9490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0756927 Vali Loss: 0.0739457 Test Loss: 0.0796888\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0774381\n",
      "\tspeed: 0.0541s/iter; left time: 822.5513s\n",
      "\titers: 200, epoch: 33 | loss: 0.0736052\n",
      "\tspeed: 0.0303s/iter; left time: 458.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0756846 Vali Loss: 0.0738672 Test Loss: 0.0796748\n",
      "Validation loss decreased (0.073897 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0778821\n",
      "\tspeed: 0.0536s/iter; left time: 802.0761s\n",
      "\titers: 200, epoch: 34 | loss: 0.0769082\n",
      "\tspeed: 0.0305s/iter; left time: 454.1337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 225 | Train Loss: 0.0755951 Vali Loss: 0.0739160 Test Loss: 0.0796510\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0706455\n",
      "\tspeed: 0.0527s/iter; left time: 777.1290s\n",
      "\titers: 200, epoch: 35 | loss: 0.0743120\n",
      "\tspeed: 0.0266s/iter; left time: 390.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 225 | Train Loss: 0.0756107 Vali Loss: 0.0738675 Test Loss: 0.0796316\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0757184\n",
      "\tspeed: 0.0533s/iter; left time: 774.1222s\n",
      "\titers: 200, epoch: 36 | loss: 0.0789647\n",
      "\tspeed: 0.0269s/iter; left time: 388.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 225 | Train Loss: 0.0755679 Vali Loss: 0.0738346 Test Loss: 0.0796362\n",
      "Validation loss decreased (0.073867 --> 0.073835).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0823950\n",
      "\tspeed: 0.0466s/iter; left time: 666.2990s\n",
      "\titers: 200, epoch: 37 | loss: 0.0751047\n",
      "\tspeed: 0.0229s/iter; left time: 324.5557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 225 | Train Loss: 0.0755710 Vali Loss: 0.0738364 Test Loss: 0.0796816\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0771139\n",
      "\tspeed: 0.0551s/iter; left time: 775.4749s\n",
      "\titers: 200, epoch: 38 | loss: 0.0795248\n",
      "\tspeed: 0.0294s/iter; left time: 411.1895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0755763 Vali Loss: 0.0738889 Test Loss: 0.0796442\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0755012\n",
      "\tspeed: 0.0522s/iter; left time: 722.6248s\n",
      "\titers: 200, epoch: 39 | loss: 0.0750739\n",
      "\tspeed: 0.0235s/iter; left time: 322.4778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 225 | Train Loss: 0.0755440 Vali Loss: 0.0738972 Test Loss: 0.0796942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0786288\n",
      "\tspeed: 0.0462s/iter; left time: 629.4702s\n",
      "\titers: 200, epoch: 40 | loss: 0.0695698\n",
      "\tspeed: 0.0306s/iter; left time: 413.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0755733 Vali Loss: 0.0738691 Test Loss: 0.0796484\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0762501\n",
      "\tspeed: 0.0490s/iter; left time: 656.8606s\n",
      "\titers: 200, epoch: 41 | loss: 0.0711865\n",
      "\tspeed: 0.0301s/iter; left time: 399.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0755028 Vali Loss: 0.0738545 Test Loss: 0.0796684\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0734441\n",
      "\tspeed: 0.0553s/iter; left time: 728.0576s\n",
      "\titers: 200, epoch: 42 | loss: 0.0758917\n",
      "\tspeed: 0.0311s/iter; left time: 406.3994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 225 | Train Loss: 0.0755312 Vali Loss: 0.0737964 Test Loss: 0.0796481\n",
      "Validation loss decreased (0.073835 --> 0.073796).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0733277\n",
      "\tspeed: 0.0457s/iter; left time: 591.2522s\n",
      "\titers: 200, epoch: 43 | loss: 0.0771407\n",
      "\tspeed: 0.0282s/iter; left time: 362.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 225 | Train Loss: 0.0755338 Vali Loss: 0.0738415 Test Loss: 0.0796714\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0747953\n",
      "\tspeed: 0.0468s/iter; left time: 595.0386s\n",
      "\titers: 200, epoch: 44 | loss: 0.0741519\n",
      "\tspeed: 0.0303s/iter; left time: 382.1021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 225 | Train Loss: 0.0754940 Vali Loss: 0.0738805 Test Loss: 0.0796630\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769906\n",
      "\tspeed: 0.0448s/iter; left time: 560.1053s\n",
      "\titers: 200, epoch: 45 | loss: 0.0761429\n",
      "\tspeed: 0.0195s/iter; left time: 242.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.83s\n",
      "Steps: 225 | Train Loss: 0.0754916 Vali Loss: 0.0738032 Test Loss: 0.0796840\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0759332\n",
      "\tspeed: 0.0460s/iter; left time: 565.0444s\n",
      "\titers: 200, epoch: 46 | loss: 0.0706540\n",
      "\tspeed: 0.0232s/iter; left time: 282.0983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0755041 Vali Loss: 0.0738029 Test Loss: 0.0796604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753413\n",
      "\tspeed: 0.0510s/iter; left time: 614.8172s\n",
      "\titers: 200, epoch: 47 | loss: 0.0759820\n",
      "\tspeed: 0.0306s/iter; left time: 365.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.69s\n",
      "Steps: 225 | Train Loss: 0.0754766 Vali Loss: 0.0738504 Test Loss: 0.0796809\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0736977\n",
      "\tspeed: 0.0478s/iter; left time: 565.0541s\n",
      "\titers: 200, epoch: 48 | loss: 0.0774811\n",
      "\tspeed: 0.0270s/iter; left time: 316.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0754439 Vali Loss: 0.0738729 Test Loss: 0.0796779\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0742064\n",
      "\tspeed: 0.0489s/iter; left time: 567.2492s\n",
      "\titers: 200, epoch: 49 | loss: 0.0763281\n",
      "\tspeed: 0.0277s/iter; left time: 318.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0754684 Vali Loss: 0.0738392 Test Loss: 0.0796467\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0738480\n",
      "\tspeed: 0.0457s/iter; left time: 519.6296s\n",
      "\titers: 200, epoch: 50 | loss: 0.0730180\n",
      "\tspeed: 0.0266s/iter; left time: 300.0786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0754635 Vali Loss: 0.0738703 Test Loss: 0.0796760\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0756818\n",
      "\tspeed: 0.0523s/iter; left time: 583.3631s\n",
      "\titers: 200, epoch: 51 | loss: 0.0794990\n",
      "\tspeed: 0.0300s/iter; left time: 331.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0754601 Vali Loss: 0.0738453 Test Loss: 0.0796572\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0704052\n",
      "\tspeed: 0.0517s/iter; left time: 564.8042s\n",
      "\titers: 200, epoch: 52 | loss: 0.0758301\n",
      "\tspeed: 0.0205s/iter; left time: 221.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 225 | Train Loss: 0.0754571 Vali Loss: 0.0738097 Test Loss: 0.0796377\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018305838108062744, rmse:0.13529907166957855, mae:0.07964807003736496, rse:0.5115803480148315\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1790881\n",
      "\tspeed: 0.0210s/iter; left time: 470.0092s\n",
      "\titers: 200, epoch: 1 | loss: 0.1657722\n",
      "\tspeed: 0.0274s/iter; left time: 611.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 225 | Train Loss: 0.1823005 Vali Loss: 0.1545539 Test Loss: 0.1640103\n",
      "Validation loss decreased (inf --> 0.154554).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1020215\n",
      "\tspeed: 0.0521s/iter; left time: 1154.9627s\n",
      "\titers: 200, epoch: 2 | loss: 0.0918243\n",
      "\tspeed: 0.0305s/iter; left time: 674.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 225 | Train Loss: 0.1109366 Vali Loss: 0.0847074 Test Loss: 0.0896899\n",
      "Validation loss decreased (0.154554 --> 0.084707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0926616\n",
      "\tspeed: 0.0520s/iter; left time: 1141.4641s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870116\n",
      "\tspeed: 0.0296s/iter; left time: 646.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0891119 Vali Loss: 0.0801562 Test Loss: 0.0851888\n",
      "Validation loss decreased (0.084707 --> 0.080156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0865172\n",
      "\tspeed: 0.0562s/iter; left time: 1221.6089s\n",
      "\titers: 200, epoch: 4 | loss: 0.0807629\n",
      "\tspeed: 0.0292s/iter; left time: 632.1566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 225 | Train Loss: 0.0852437 Vali Loss: 0.0786048 Test Loss: 0.0836677\n",
      "Validation loss decreased (0.080156 --> 0.078605).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815287\n",
      "\tspeed: 0.0492s/iter; left time: 1058.5932s\n",
      "\titers: 200, epoch: 5 | loss: 0.0852425\n",
      "\tspeed: 0.0248s/iter; left time: 531.5487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0826992 Vali Loss: 0.0771317 Test Loss: 0.0825239\n",
      "Validation loss decreased (0.078605 --> 0.077132).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0855075\n",
      "\tspeed: 0.0451s/iter; left time: 959.7671s\n",
      "\titers: 200, epoch: 6 | loss: 0.0810368\n",
      "\tspeed: 0.0259s/iter; left time: 548.6693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0810929 Vali Loss: 0.0765272 Test Loss: 0.0819078\n",
      "Validation loss decreased (0.077132 --> 0.076527).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0770050\n",
      "\tspeed: 0.0461s/iter; left time: 969.9724s\n",
      "\titers: 200, epoch: 7 | loss: 0.0781120\n",
      "\tspeed: 0.0276s/iter; left time: 579.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 225 | Train Loss: 0.0800917 Vali Loss: 0.0758637 Test Loss: 0.0813290\n",
      "Validation loss decreased (0.076527 --> 0.075864).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0814507\n",
      "\tspeed: 0.0521s/iter; left time: 1085.3334s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810540\n",
      "\tspeed: 0.0334s/iter; left time: 691.5035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 225 | Train Loss: 0.0794074 Vali Loss: 0.0757473 Test Loss: 0.0809703\n",
      "Validation loss decreased (0.075864 --> 0.075747).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0785709\n",
      "\tspeed: 0.0549s/iter; left time: 1130.6216s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773229\n",
      "\tspeed: 0.0297s/iter; left time: 607.9262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.89s\n",
      "Steps: 225 | Train Loss: 0.0788632 Vali Loss: 0.0751910 Test Loss: 0.0805931\n",
      "Validation loss decreased (0.075747 --> 0.075191).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0808593\n",
      "\tspeed: 0.0521s/iter; left time: 1060.7529s\n",
      "\titers: 200, epoch: 10 | loss: 0.0760220\n",
      "\tspeed: 0.0268s/iter; left time: 543.8240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 225 | Train Loss: 0.0784034 Vali Loss: 0.0749507 Test Loss: 0.0803177\n",
      "Validation loss decreased (0.075191 --> 0.074951).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816761\n",
      "\tspeed: 0.0510s/iter; left time: 1028.2459s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758451\n",
      "\tspeed: 0.0308s/iter; left time: 617.6004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0780377 Vali Loss: 0.0748240 Test Loss: 0.0803157\n",
      "Validation loss decreased (0.074951 --> 0.074824).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733595\n",
      "\tspeed: 0.0603s/iter; left time: 1202.2466s\n",
      "\titers: 200, epoch: 12 | loss: 0.0775170\n",
      "\tspeed: 0.0290s/iter; left time: 575.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 225 | Train Loss: 0.0777423 Vali Loss: 0.0747157 Test Loss: 0.0800200\n",
      "Validation loss decreased (0.074824 --> 0.074716).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0778685\n",
      "\tspeed: 0.0527s/iter; left time: 1038.8944s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779369\n",
      "\tspeed: 0.0263s/iter; left time: 515.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0774560 Vali Loss: 0.0745607 Test Loss: 0.0800957\n",
      "Validation loss decreased (0.074716 --> 0.074561).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752640\n",
      "\tspeed: 0.0504s/iter; left time: 980.9766s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772109\n",
      "\tspeed: 0.0243s/iter; left time: 470.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 225 | Train Loss: 0.0771855 Vali Loss: 0.0745269 Test Loss: 0.0799434\n",
      "Validation loss decreased (0.074561 --> 0.074527).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755306\n",
      "\tspeed: 0.0496s/iter; left time: 955.6114s\n",
      "\titers: 200, epoch: 15 | loss: 0.0763766\n",
      "\tspeed: 0.0236s/iter; left time: 452.3277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 225 | Train Loss: 0.0770187 Vali Loss: 0.0743560 Test Loss: 0.0797780\n",
      "Validation loss decreased (0.074527 --> 0.074356).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0805588\n",
      "\tspeed: 0.0482s/iter; left time: 917.4913s\n",
      "\titers: 200, epoch: 16 | loss: 0.0789654\n",
      "\tspeed: 0.0208s/iter; left time: 393.3317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0768375 Vali Loss: 0.0743071 Test Loss: 0.0798205\n",
      "Validation loss decreased (0.074356 --> 0.074307).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0784135\n",
      "\tspeed: 0.0448s/iter; left time: 841.6925s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752202\n",
      "\tspeed: 0.0219s/iter; left time: 409.7830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 225 | Train Loss: 0.0767227 Vali Loss: 0.0742462 Test Loss: 0.0797481\n",
      "Validation loss decreased (0.074307 --> 0.074246).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0782087\n",
      "\tspeed: 0.0528s/iter; left time: 981.6482s\n",
      "\titers: 200, epoch: 18 | loss: 0.0795883\n",
      "\tspeed: 0.0280s/iter; left time: 516.6581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 225 | Train Loss: 0.0765944 Vali Loss: 0.0742247 Test Loss: 0.0797466\n",
      "Validation loss decreased (0.074246 --> 0.074225).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0779423\n",
      "\tspeed: 0.0543s/iter; left time: 996.7476s\n",
      "\titers: 200, epoch: 19 | loss: 0.0741632\n",
      "\tspeed: 0.0262s/iter; left time: 478.3752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0764083 Vali Loss: 0.0741696 Test Loss: 0.0796356\n",
      "Validation loss decreased (0.074225 --> 0.074170).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0784153\n",
      "\tspeed: 0.0463s/iter; left time: 840.1191s\n",
      "\titers: 200, epoch: 20 | loss: 0.0784849\n",
      "\tspeed: 0.0253s/iter; left time: 455.2760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 225 | Train Loss: 0.0763808 Vali Loss: 0.0740472 Test Loss: 0.0795232\n",
      "Validation loss decreased (0.074170 --> 0.074047).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737283\n",
      "\tspeed: 0.0501s/iter; left time: 897.6407s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750930\n",
      "\tspeed: 0.0261s/iter; left time: 464.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0762870 Vali Loss: 0.0741221 Test Loss: 0.0796024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0750439\n",
      "\tspeed: 0.0537s/iter; left time: 948.5754s\n",
      "\titers: 200, epoch: 22 | loss: 0.0800672\n",
      "\tspeed: 0.0309s/iter; left time: 543.1002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.04s\n",
      "Steps: 225 | Train Loss: 0.0761221 Vali Loss: 0.0740300 Test Loss: 0.0795310\n",
      "Validation loss decreased (0.074047 --> 0.074030).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0740797\n",
      "\tspeed: 0.0544s/iter; left time: 948.6721s\n",
      "\titers: 200, epoch: 23 | loss: 0.0691196\n",
      "\tspeed: 0.0264s/iter; left time: 458.6481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0760698 Vali Loss: 0.0740356 Test Loss: 0.0795706\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0743738\n",
      "\tspeed: 0.0540s/iter; left time: 929.5278s\n",
      "\titers: 200, epoch: 24 | loss: 0.0797742\n",
      "\tspeed: 0.0297s/iter; left time: 508.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.09s\n",
      "Steps: 225 | Train Loss: 0.0760023 Vali Loss: 0.0739953 Test Loss: 0.0795833\n",
      "Validation loss decreased (0.074030 --> 0.073995).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0774466\n",
      "\tspeed: 0.0435s/iter; left time: 740.1664s\n",
      "\titers: 200, epoch: 25 | loss: 0.0778909\n",
      "\tspeed: 0.0188s/iter; left time: 317.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.45s\n",
      "Steps: 225 | Train Loss: 0.0759958 Vali Loss: 0.0740413 Test Loss: 0.0795815\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0780001\n",
      "\tspeed: 0.0422s/iter; left time: 707.2411s\n",
      "\titers: 200, epoch: 26 | loss: 0.0763809\n",
      "\tspeed: 0.0254s/iter; left time: 423.2670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 225 | Train Loss: 0.0758109 Vali Loss: 0.0740130 Test Loss: 0.0795372\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0759217\n",
      "\tspeed: 0.0567s/iter; left time: 937.9791s\n",
      "\titers: 200, epoch: 27 | loss: 0.0768139\n",
      "\tspeed: 0.0304s/iter; left time: 500.3218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 225 | Train Loss: 0.0758581 Vali Loss: 0.0739008 Test Loss: 0.0794840\n",
      "Validation loss decreased (0.073995 --> 0.073901).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809324\n",
      "\tspeed: 0.0438s/iter; left time: 715.3982s\n",
      "\titers: 200, epoch: 28 | loss: 0.0707953\n",
      "\tspeed: 0.0188s/iter; left time: 304.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.47s\n",
      "Steps: 225 | Train Loss: 0.0758429 Vali Loss: 0.0738786 Test Loss: 0.0794998\n",
      "Validation loss decreased (0.073901 --> 0.073879).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0721506\n",
      "\tspeed: 0.0462s/iter; left time: 744.3248s\n",
      "\titers: 200, epoch: 29 | loss: 0.0742410\n",
      "\tspeed: 0.0302s/iter; left time: 483.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.55s\n",
      "Steps: 225 | Train Loss: 0.0757575 Vali Loss: 0.0739099 Test Loss: 0.0795173\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0775100\n",
      "\tspeed: 0.0636s/iter; left time: 1009.4665s\n",
      "\titers: 200, epoch: 30 | loss: 0.0723973\n",
      "\tspeed: 0.0365s/iter; left time: 575.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 225 | Train Loss: 0.0757562 Vali Loss: 0.0739307 Test Loss: 0.0795078\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0801369\n",
      "\tspeed: 0.0570s/iter; left time: 892.0156s\n",
      "\titers: 200, epoch: 31 | loss: 0.0784943\n",
      "\tspeed: 0.0268s/iter; left time: 416.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 225 | Train Loss: 0.0757115 Vali Loss: 0.0738676 Test Loss: 0.0795069\n",
      "Validation loss decreased (0.073879 --> 0.073868).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0789659\n",
      "\tspeed: 0.0529s/iter; left time: 816.0835s\n",
      "\titers: 200, epoch: 32 | loss: 0.0737221\n",
      "\tspeed: 0.0345s/iter; left time: 528.9748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 225 | Train Loss: 0.0756342 Vali Loss: 0.0738669 Test Loss: 0.0795308\n",
      "Validation loss decreased (0.073868 --> 0.073867).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0721539\n",
      "\tspeed: 0.0521s/iter; left time: 791.6168s\n",
      "\titers: 200, epoch: 33 | loss: 0.0724874\n",
      "\tspeed: 0.0272s/iter; left time: 410.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 225 | Train Loss: 0.0755756 Vali Loss: 0.0738196 Test Loss: 0.0794518\n",
      "Validation loss decreased (0.073867 --> 0.073820).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0746614\n",
      "\tspeed: 0.0570s/iter; left time: 853.1540s\n",
      "\titers: 200, epoch: 34 | loss: 0.0746784\n",
      "\tspeed: 0.0306s/iter; left time: 454.9447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0756492 Vali Loss: 0.0738246 Test Loss: 0.0794897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0766999\n",
      "\tspeed: 0.0462s/iter; left time: 681.5345s\n",
      "\titers: 200, epoch: 35 | loss: 0.0754725\n",
      "\tspeed: 0.0255s/iter; left time: 373.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 225 | Train Loss: 0.0755886 Vali Loss: 0.0738690 Test Loss: 0.0794683\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0751653\n",
      "\tspeed: 0.0511s/iter; left time: 742.1519s\n",
      "\titers: 200, epoch: 36 | loss: 0.0764476\n",
      "\tspeed: 0.0305s/iter; left time: 440.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.99s\n",
      "Steps: 225 | Train Loss: 0.0755780 Vali Loss: 0.0738295 Test Loss: 0.0794947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0764202\n",
      "\tspeed: 0.0550s/iter; left time: 786.9232s\n",
      "\titers: 200, epoch: 37 | loss: 0.0727640\n",
      "\tspeed: 0.0314s/iter; left time: 446.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.06s\n",
      "Steps: 225 | Train Loss: 0.0755563 Vali Loss: 0.0738518 Test Loss: 0.0794914\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0752195\n",
      "\tspeed: 0.0476s/iter; left time: 670.1916s\n",
      "\titers: 200, epoch: 38 | loss: 0.0756702\n",
      "\tspeed: 0.0291s/iter; left time: 406.6700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 225 | Train Loss: 0.0755056 Vali Loss: 0.0738162 Test Loss: 0.0794783\n",
      "Validation loss decreased (0.073820 --> 0.073816).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0771633\n",
      "\tspeed: 0.0480s/iter; left time: 664.7757s\n",
      "\titers: 200, epoch: 39 | loss: 0.0776391\n",
      "\tspeed: 0.0294s/iter; left time: 404.0284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 225 | Train Loss: 0.0754969 Vali Loss: 0.0738267 Test Loss: 0.0794866\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0803662\n",
      "\tspeed: 0.0568s/iter; left time: 774.3166s\n",
      "\titers: 200, epoch: 40 | loss: 0.0739795\n",
      "\tspeed: 0.0248s/iter; left time: 335.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0754540 Vali Loss: 0.0738386 Test Loss: 0.0794849\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0799819\n",
      "\tspeed: 0.0521s/iter; left time: 698.3912s\n",
      "\titers: 200, epoch: 41 | loss: 0.0724458\n",
      "\tspeed: 0.0280s/iter; left time: 372.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0755010 Vali Loss: 0.0738616 Test Loss: 0.0794929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0770340\n",
      "\tspeed: 0.0449s/iter; left time: 592.0953s\n",
      "\titers: 200, epoch: 42 | loss: 0.0735448\n",
      "\tspeed: 0.0283s/iter; left time: 369.4020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 225 | Train Loss: 0.0755102 Vali Loss: 0.0738463 Test Loss: 0.0794932\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0760082\n",
      "\tspeed: 0.0485s/iter; left time: 628.2887s\n",
      "\titers: 200, epoch: 43 | loss: 0.0749146\n",
      "\tspeed: 0.0307s/iter; left time: 394.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 225 | Train Loss: 0.0754570 Vali Loss: 0.0737946 Test Loss: 0.0794973\n",
      "Validation loss decreased (0.073816 --> 0.073795).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0756610\n",
      "\tspeed: 0.0493s/iter; left time: 627.4488s\n",
      "\titers: 200, epoch: 44 | loss: 0.0774383\n",
      "\tspeed: 0.0303s/iter; left time: 383.1854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.51s\n",
      "Steps: 225 | Train Loss: 0.0754674 Vali Loss: 0.0738476 Test Loss: 0.0795091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0734283\n",
      "\tspeed: 0.0564s/iter; left time: 704.6256s\n",
      "\titers: 200, epoch: 45 | loss: 0.0710394\n",
      "\tspeed: 0.0351s/iter; left time: 434.7033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.87s\n",
      "Steps: 225 | Train Loss: 0.0754520 Vali Loss: 0.0738455 Test Loss: 0.0795059\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0708159\n",
      "\tspeed: 0.0521s/iter; left time: 639.9318s\n",
      "\titers: 200, epoch: 46 | loss: 0.0780994\n",
      "\tspeed: 0.0256s/iter; left time: 311.2912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0754575 Vali Loss: 0.0738445 Test Loss: 0.0794902\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0724014\n",
      "\tspeed: 0.0518s/iter; left time: 624.2553s\n",
      "\titers: 200, epoch: 47 | loss: 0.0738643\n",
      "\tspeed: 0.0299s/iter; left time: 356.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:06.64s\n",
      "Steps: 225 | Train Loss: 0.0754107 Vali Loss: 0.0738300 Test Loss: 0.0794834\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0786052\n",
      "\tspeed: 0.0486s/iter; left time: 574.9446s\n",
      "\titers: 200, epoch: 48 | loss: 0.0770917\n",
      "\tspeed: 0.0221s/iter; left time: 258.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0754408 Vali Loss: 0.0738190 Test Loss: 0.0794723\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0754975\n",
      "\tspeed: 0.0450s/iter; left time: 522.3499s\n",
      "\titers: 200, epoch: 49 | loss: 0.0771508\n",
      "\tspeed: 0.0259s/iter; left time: 298.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0754946 Vali Loss: 0.0738595 Test Loss: 0.0794853\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0757545\n",
      "\tspeed: 0.0557s/iter; left time: 633.3106s\n",
      "\titers: 200, epoch: 50 | loss: 0.0732413\n",
      "\tspeed: 0.0333s/iter; left time: 375.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.58s\n",
      "Steps: 225 | Train Loss: 0.0754509 Vali Loss: 0.0738343 Test Loss: 0.0794914\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0757393\n",
      "\tspeed: 0.0489s/iter; left time: 545.3981s\n",
      "\titers: 200, epoch: 51 | loss: 0.0788999\n",
      "\tspeed: 0.0268s/iter; left time: 296.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 225 | Train Loss: 0.0754437 Vali Loss: 0.0738431 Test Loss: 0.0794810\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0761891\n",
      "\tspeed: 0.0492s/iter; left time: 537.5366s\n",
      "\titers: 200, epoch: 52 | loss: 0.0724254\n",
      "\tspeed: 0.0295s/iter; left time: 319.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 225 | Train Loss: 0.0754188 Vali Loss: 0.0738193 Test Loss: 0.0794760\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0762165\n",
      "\tspeed: 0.0516s/iter; left time: 552.3373s\n",
      "\titers: 200, epoch: 53 | loss: 0.0760677\n",
      "\tspeed: 0.0290s/iter; left time: 306.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.83s\n",
      "Steps: 225 | Train Loss: 0.0754509 Vali Loss: 0.0737906 Test Loss: 0.0794727\n",
      "Validation loss decreased (0.073795 --> 0.073791).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0756035\n",
      "\tspeed: 0.0538s/iter; left time: 563.9505s\n",
      "\titers: 200, epoch: 54 | loss: 0.0773814\n",
      "\tspeed: 0.0269s/iter; left time: 279.1261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0754188 Vali Loss: 0.0738212 Test Loss: 0.0794904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0711235\n",
      "\tspeed: 0.0427s/iter; left time: 437.2315s\n",
      "\titers: 200, epoch: 55 | loss: 0.0735966\n",
      "\tspeed: 0.0189s/iter; left time: 192.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.49s\n",
      "Steps: 225 | Train Loss: 0.0754077 Vali Loss: 0.0738077 Test Loss: 0.0794723\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0755664\n",
      "\tspeed: 0.0489s/iter; left time: 489.9243s\n",
      "\titers: 200, epoch: 56 | loss: 0.0748949\n",
      "\tspeed: 0.0227s/iter; left time: 225.1873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0754186 Vali Loss: 0.0738800 Test Loss: 0.0795176\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0737460\n",
      "\tspeed: 0.0482s/iter; left time: 472.0786s\n",
      "\titers: 200, epoch: 57 | loss: 0.0724761\n",
      "\tspeed: 0.0295s/iter; left time: 285.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.54s\n",
      "Steps: 225 | Train Loss: 0.0754397 Vali Loss: 0.0738223 Test Loss: 0.0794878\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0727171\n",
      "\tspeed: 0.0525s/iter; left time: 502.8817s\n",
      "\titers: 200, epoch: 58 | loss: 0.0756273\n",
      "\tspeed: 0.0307s/iter; left time: 290.5225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 225 | Train Loss: 0.0754023 Vali Loss: 0.0737841 Test Loss: 0.0794823\n",
      "Validation loss decreased (0.073791 --> 0.073784).  Saving model ...\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0730906\n",
      "\tspeed: 0.0515s/iter; left time: 481.7092s\n",
      "\titers: 200, epoch: 59 | loss: 0.0772122\n",
      "\tspeed: 0.0287s/iter; left time: 265.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 225 | Train Loss: 0.0754130 Vali Loss: 0.0738190 Test Loss: 0.0794906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0736467\n",
      "\tspeed: 0.0475s/iter; left time: 433.2226s\n",
      "\titers: 200, epoch: 60 | loss: 0.0755759\n",
      "\tspeed: 0.0248s/iter; left time: 223.8422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0753993 Vali Loss: 0.0738504 Test Loss: 0.0795066\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0751130\n",
      "\tspeed: 0.0498s/iter; left time: 443.0488s\n",
      "\titers: 200, epoch: 61 | loss: 0.0753030\n",
      "\tspeed: 0.0285s/iter; left time: 251.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 225 | Train Loss: 0.0753909 Vali Loss: 0.0738311 Test Loss: 0.0794865\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0757755\n",
      "\tspeed: 0.0534s/iter; left time: 463.0460s\n",
      "\titers: 200, epoch: 62 | loss: 0.0695692\n",
      "\tspeed: 0.0285s/iter; left time: 244.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 225 | Train Loss: 0.0753604 Vali Loss: 0.0738126 Test Loss: 0.0794836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0758435\n",
      "\tspeed: 0.0484s/iter; left time: 409.0732s\n",
      "\titers: 200, epoch: 63 | loss: 0.0769937\n",
      "\tspeed: 0.0240s/iter; left time: 200.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 225 | Train Loss: 0.0753878 Vali Loss: 0.0738097 Test Loss: 0.0794762\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0750599\n",
      "\tspeed: 0.0480s/iter; left time: 394.6231s\n",
      "\titers: 200, epoch: 64 | loss: 0.0738896\n",
      "\tspeed: 0.0264s/iter; left time: 214.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 225 | Train Loss: 0.0754262 Vali Loss: 0.0738157 Test Loss: 0.0794868\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0800771\n",
      "\tspeed: 0.0418s/iter; left time: 334.2490s\n",
      "\titers: 200, epoch: 65 | loss: 0.0764180\n",
      "\tspeed: 0.0190s/iter; left time: 150.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:04.60s\n",
      "Steps: 225 | Train Loss: 0.0754034 Vali Loss: 0.0738054 Test Loss: 0.0794848\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0783498\n",
      "\tspeed: 0.0497s/iter; left time: 386.6184s\n",
      "\titers: 200, epoch: 66 | loss: 0.0783960\n",
      "\tspeed: 0.0250s/iter; left time: 191.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 225 | Train Loss: 0.0753819 Vali Loss: 0.0738158 Test Loss: 0.0794879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0708528\n",
      "\tspeed: 0.0497s/iter; left time: 375.2506s\n",
      "\titers: 200, epoch: 67 | loss: 0.0710542\n",
      "\tspeed: 0.0250s/iter; left time: 186.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 225 | Train Loss: 0.0753369 Vali Loss: 0.0738132 Test Loss: 0.0794802\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0730779\n",
      "\tspeed: 0.0515s/iter; left time: 376.9654s\n",
      "\titers: 200, epoch: 68 | loss: 0.0792189\n",
      "\tspeed: 0.0301s/iter; left time: 217.4547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:06.88s\n",
      "Steps: 225 | Train Loss: 0.0754393 Vali Loss: 0.0738283 Test Loss: 0.0794841\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_96_IT_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01832953467965126, rmse:0.1353866159915924, mae:0.0794823169708252, rse:0.5119113922119141\n",
      "Intermediate time for IT and pred_len 96: 00h:15m:47.76s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_168_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1870383\n",
      "\tspeed: 0.0530s/iter; left time: 1187.6223s\n",
      "\titers: 200, epoch: 1 | loss: 0.1715603\n",
      "\tspeed: 0.0222s/iter; left time: 494.7917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 225 | Train Loss: 0.1853553 Vali Loss: 0.1568048 Test Loss: 0.1660703\n",
      "Validation loss decreased (inf --> 0.156805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1076143\n",
      "\tspeed: 0.0451s/iter; left time: 1000.7689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932135\n",
      "\tspeed: 0.0239s/iter; left time: 528.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 225 | Train Loss: 0.1145113 Vali Loss: 0.0890583 Test Loss: 0.0936706\n",
      "Validation loss decreased (0.156805 --> 0.089058).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0969614\n",
      "\tspeed: 0.0477s/iter; left time: 1047.5406s\n",
      "\titers: 200, epoch: 3 | loss: 0.0886289\n",
      "\tspeed: 0.0240s/iter; left time: 524.0215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 225 | Train Loss: 0.0935062 Vali Loss: 0.0845694 Test Loss: 0.0895883\n",
      "Validation loss decreased (0.089058 --> 0.084569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0874625\n",
      "\tspeed: 0.0533s/iter; left time: 1157.1418s\n",
      "\titers: 200, epoch: 4 | loss: 0.0900980\n",
      "\tspeed: 0.0245s/iter; left time: 530.1249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 225 | Train Loss: 0.0895805 Vali Loss: 0.0827342 Test Loss: 0.0878479\n",
      "Validation loss decreased (0.084569 --> 0.082734).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0844901\n",
      "\tspeed: 0.0457s/iter; left time: 982.2682s\n",
      "\titers: 200, epoch: 5 | loss: 0.0865713\n",
      "\tspeed: 0.0191s/iter; left time: 409.6463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.80s\n",
      "Steps: 225 | Train Loss: 0.0872905 Vali Loss: 0.0817755 Test Loss: 0.0867167\n",
      "Validation loss decreased (0.082734 --> 0.081776).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0891566\n",
      "\tspeed: 0.0503s/iter; left time: 1069.9232s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812639\n",
      "\tspeed: 0.0268s/iter; left time: 568.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 225 | Train Loss: 0.0859008 Vali Loss: 0.0814405 Test Loss: 0.0862796\n",
      "Validation loss decreased (0.081776 --> 0.081441).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801779\n",
      "\tspeed: 0.0553s/iter; left time: 1164.4329s\n",
      "\titers: 200, epoch: 7 | loss: 0.0839427\n",
      "\tspeed: 0.0304s/iter; left time: 637.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.16s\n",
      "Steps: 225 | Train Loss: 0.0851128 Vali Loss: 0.0811499 Test Loss: 0.0859220\n",
      "Validation loss decreased (0.081441 --> 0.081150).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0855081\n",
      "\tspeed: 0.0531s/iter; left time: 1106.5250s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827369\n",
      "\tspeed: 0.0248s/iter; left time: 513.7592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 225 | Train Loss: 0.0844766 Vali Loss: 0.0809494 Test Loss: 0.0854709\n",
      "Validation loss decreased (0.081150 --> 0.080949).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0828159\n",
      "\tspeed: 0.0535s/iter; left time: 1103.0341s\n",
      "\titers: 200, epoch: 9 | loss: 0.0814609\n",
      "\tspeed: 0.0249s/iter; left time: 509.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0839091 Vali Loss: 0.0807725 Test Loss: 0.0852282\n",
      "Validation loss decreased (0.080949 --> 0.080772).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0850896\n",
      "\tspeed: 0.0492s/iter; left time: 1003.0017s\n",
      "\titers: 200, epoch: 10 | loss: 0.0819488\n",
      "\tspeed: 0.0256s/iter; left time: 518.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 225 | Train Loss: 0.0835141 Vali Loss: 0.0806206 Test Loss: 0.0851980\n",
      "Validation loss decreased (0.080772 --> 0.080621).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0808780\n",
      "\tspeed: 0.0521s/iter; left time: 1050.3959s\n",
      "\titers: 200, epoch: 11 | loss: 0.0832348\n",
      "\tspeed: 0.0334s/iter; left time: 668.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.95s\n",
      "Steps: 225 | Train Loss: 0.0831508 Vali Loss: 0.0803353 Test Loss: 0.0851180\n",
      "Validation loss decreased (0.080621 --> 0.080335).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0817546\n",
      "\tspeed: 0.0523s/iter; left time: 1041.8946s\n",
      "\titers: 200, epoch: 12 | loss: 0.0817587\n",
      "\tspeed: 0.0256s/iter; left time: 507.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0828775 Vali Loss: 0.0803466 Test Loss: 0.0849709\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0832407\n",
      "\tspeed: 0.0564s/iter; left time: 1111.2775s\n",
      "\titers: 200, epoch: 13 | loss: 0.0805905\n",
      "\tspeed: 0.0290s/iter; left time: 568.4872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0826251 Vali Loss: 0.0803146 Test Loss: 0.0849297\n",
      "Validation loss decreased (0.080335 --> 0.080315).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825088\n",
      "\tspeed: 0.0543s/iter; left time: 1057.6136s\n",
      "\titers: 200, epoch: 14 | loss: 0.0817128\n",
      "\tspeed: 0.0258s/iter; left time: 499.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0823843 Vali Loss: 0.0803333 Test Loss: 0.0849445\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803306\n",
      "\tspeed: 0.0517s/iter; left time: 995.6271s\n",
      "\titers: 200, epoch: 15 | loss: 0.0829988\n",
      "\tspeed: 0.0265s/iter; left time: 507.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0821832 Vali Loss: 0.0801801 Test Loss: 0.0849477\n",
      "Validation loss decreased (0.080315 --> 0.080180).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0843089\n",
      "\tspeed: 0.0529s/iter; left time: 1006.9692s\n",
      "\titers: 200, epoch: 16 | loss: 0.0825813\n",
      "\tspeed: 0.0241s/iter; left time: 455.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0819858 Vali Loss: 0.0800799 Test Loss: 0.0849492\n",
      "Validation loss decreased (0.080180 --> 0.080080).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0866396\n",
      "\tspeed: 0.0473s/iter; left time: 888.9542s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802184\n",
      "\tspeed: 0.0297s/iter; left time: 556.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0818580 Vali Loss: 0.0802803 Test Loss: 0.0850842\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0837353\n",
      "\tspeed: 0.0507s/iter; left time: 942.5106s\n",
      "\titers: 200, epoch: 18 | loss: 0.0844034\n",
      "\tspeed: 0.0250s/iter; left time: 462.1972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 225 | Train Loss: 0.0816901 Vali Loss: 0.0801386 Test Loss: 0.0850110\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0803253\n",
      "\tspeed: 0.0516s/iter; left time: 946.2819s\n",
      "\titers: 200, epoch: 19 | loss: 0.0813744\n",
      "\tspeed: 0.0276s/iter; left time: 503.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0815585 Vali Loss: 0.0800813 Test Loss: 0.0849962\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0786014\n",
      "\tspeed: 0.0510s/iter; left time: 925.1082s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859499\n",
      "\tspeed: 0.0268s/iter; left time: 483.9495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0814428 Vali Loss: 0.0799977 Test Loss: 0.0849762\n",
      "Validation loss decreased (0.080080 --> 0.079998).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0815522\n",
      "\tspeed: 0.0480s/iter; left time: 859.6618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823843\n",
      "\tspeed: 0.0241s/iter; left time: 428.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 225 | Train Loss: 0.0813704 Vali Loss: 0.0800583 Test Loss: 0.0850808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0800771\n",
      "\tspeed: 0.0472s/iter; left time: 834.5372s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811914\n",
      "\tspeed: 0.0278s/iter; left time: 489.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 225 | Train Loss: 0.0812269 Vali Loss: 0.0800063 Test Loss: 0.0851742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0807579\n",
      "\tspeed: 0.0457s/iter; left time: 797.1149s\n",
      "\titers: 200, epoch: 23 | loss: 0.0796830\n",
      "\tspeed: 0.0249s/iter; left time: 432.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 225 | Train Loss: 0.0811856 Vali Loss: 0.0799935 Test Loss: 0.0851762\n",
      "Validation loss decreased (0.079998 --> 0.079993).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0824995\n",
      "\tspeed: 0.0489s/iter; left time: 842.3694s\n",
      "\titers: 200, epoch: 24 | loss: 0.0829436\n",
      "\tspeed: 0.0237s/iter; left time: 405.9087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0810849 Vali Loss: 0.0800554 Test Loss: 0.0852059\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0845193\n",
      "\tspeed: 0.0484s/iter; left time: 822.2740s\n",
      "\titers: 200, epoch: 25 | loss: 0.0822650\n",
      "\tspeed: 0.0193s/iter; left time: 325.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 225 | Train Loss: 0.0810041 Vali Loss: 0.0799557 Test Loss: 0.0851858\n",
      "Validation loss decreased (0.079993 --> 0.079956).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0829754\n",
      "\tspeed: 0.0541s/iter; left time: 907.8570s\n",
      "\titers: 200, epoch: 26 | loss: 0.0842279\n",
      "\tspeed: 0.0318s/iter; left time: 529.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 225 | Train Loss: 0.0809648 Vali Loss: 0.0800002 Test Loss: 0.0852860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0819412\n",
      "\tspeed: 0.0524s/iter; left time: 867.4836s\n",
      "\titers: 200, epoch: 27 | loss: 0.0816244\n",
      "\tspeed: 0.0304s/iter; left time: 500.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.50s\n",
      "Steps: 225 | Train Loss: 0.0808716 Vali Loss: 0.0799935 Test Loss: 0.0852660\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802033\n",
      "\tspeed: 0.0460s/iter; left time: 750.7496s\n",
      "\titers: 200, epoch: 28 | loss: 0.0804373\n",
      "\tspeed: 0.0320s/iter; left time: 518.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.63s\n",
      "Steps: 225 | Train Loss: 0.0808384 Vali Loss: 0.0799336 Test Loss: 0.0852661\n",
      "Validation loss decreased (0.079956 --> 0.079934).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0805667\n",
      "\tspeed: 0.0523s/iter; left time: 841.6193s\n",
      "\titers: 200, epoch: 29 | loss: 0.0810601\n",
      "\tspeed: 0.0271s/iter; left time: 434.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 225 | Train Loss: 0.0808041 Vali Loss: 0.0799064 Test Loss: 0.0853089\n",
      "Validation loss decreased (0.079934 --> 0.079906).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0832688\n",
      "\tspeed: 0.0491s/iter; left time: 780.1163s\n",
      "\titers: 200, epoch: 30 | loss: 0.0829474\n",
      "\tspeed: 0.0264s/iter; left time: 416.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0808051 Vali Loss: 0.0798372 Test Loss: 0.0852992\n",
      "Validation loss decreased (0.079906 --> 0.079837).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0778924\n",
      "\tspeed: 0.0481s/iter; left time: 752.3475s\n",
      "\titers: 200, epoch: 31 | loss: 0.0805558\n",
      "\tspeed: 0.0266s/iter; left time: 413.0506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 225 | Train Loss: 0.0807081 Vali Loss: 0.0799277 Test Loss: 0.0853229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0875428\n",
      "\tspeed: 0.0496s/iter; left time: 764.7145s\n",
      "\titers: 200, epoch: 32 | loss: 0.0801462\n",
      "\tspeed: 0.0224s/iter; left time: 343.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 225 | Train Loss: 0.0806755 Vali Loss: 0.0800014 Test Loss: 0.0854342\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822497\n",
      "\tspeed: 0.0459s/iter; left time: 697.9711s\n",
      "\titers: 200, epoch: 33 | loss: 0.0821414\n",
      "\tspeed: 0.0190s/iter; left time: 287.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 225 | Train Loss: 0.0806552 Vali Loss: 0.0800011 Test Loss: 0.0853880\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0797373\n",
      "\tspeed: 0.0487s/iter; left time: 729.9735s\n",
      "\titers: 200, epoch: 34 | loss: 0.0793358\n",
      "\tspeed: 0.0218s/iter; left time: 324.4152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 225 | Train Loss: 0.0806553 Vali Loss: 0.0800313 Test Loss: 0.0854301\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0819117\n",
      "\tspeed: 0.0466s/iter; left time: 688.0043s\n",
      "\titers: 200, epoch: 35 | loss: 0.0796660\n",
      "\tspeed: 0.0258s/iter; left time: 378.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 225 | Train Loss: 0.0806135 Vali Loss: 0.0799569 Test Loss: 0.0854088\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0811039\n",
      "\tspeed: 0.0451s/iter; left time: 654.4638s\n",
      "\titers: 200, epoch: 36 | loss: 0.0808613\n",
      "\tspeed: 0.0247s/iter; left time: 355.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 225 | Train Loss: 0.0805913 Vali Loss: 0.0799412 Test Loss: 0.0854182\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0803814\n",
      "\tspeed: 0.0495s/iter; left time: 707.6192s\n",
      "\titers: 200, epoch: 37 | loss: 0.0787124\n",
      "\tspeed: 0.0282s/iter; left time: 400.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0805685 Vali Loss: 0.0798584 Test Loss: 0.0854245\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0817339\n",
      "\tspeed: 0.0548s/iter; left time: 771.6184s\n",
      "\titers: 200, epoch: 38 | loss: 0.0800650\n",
      "\tspeed: 0.0301s/iter; left time: 420.1460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 225 | Train Loss: 0.0805502 Vali Loss: 0.0798705 Test Loss: 0.0854187\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0804477\n",
      "\tspeed: 0.0451s/iter; left time: 624.7986s\n",
      "\titers: 200, epoch: 39 | loss: 0.0821592\n",
      "\tspeed: 0.0197s/iter; left time: 270.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.90s\n",
      "Steps: 225 | Train Loss: 0.0805305 Vali Loss: 0.0799363 Test Loss: 0.0854187\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0770451\n",
      "\tspeed: 0.0444s/iter; left time: 604.9656s\n",
      "\titers: 200, epoch: 40 | loss: 0.0820152\n",
      "\tspeed: 0.0255s/iter; left time: 345.0640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 225 | Train Loss: 0.0805570 Vali Loss: 0.0799209 Test Loss: 0.0854142\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019987324252724648, rmse:0.1413765400648117, mae:0.08529917895793915, rse:0.5350566506385803\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28801\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1840543\n",
      "\tspeed: 0.0283s/iter; left time: 635.0111s\n",
      "\titers: 200, epoch: 1 | loss: 0.1685224\n",
      "\tspeed: 0.0254s/iter; left time: 566.3328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.17s\n",
      "Steps: 225 | Train Loss: 0.1844982 Vali Loss: 0.1566570 Test Loss: 0.1659417\n",
      "Validation loss decreased (inf --> 0.156657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1132285\n",
      "\tspeed: 0.0527s/iter; left time: 1167.6067s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019533\n",
      "\tspeed: 0.0264s/iter; left time: 583.7759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.1153133 Vali Loss: 0.0894829 Test Loss: 0.0940419\n",
      "Validation loss decreased (0.156657 --> 0.089483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0906220\n",
      "\tspeed: 0.0489s/iter; left time: 1073.4433s\n",
      "\titers: 200, epoch: 3 | loss: 0.0922002\n",
      "\tspeed: 0.0222s/iter; left time: 484.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 225 | Train Loss: 0.0941500 Vali Loss: 0.0851695 Test Loss: 0.0901265\n",
      "Validation loss decreased (0.089483 --> 0.085170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0905102\n",
      "\tspeed: 0.0485s/iter; left time: 1053.2921s\n",
      "\titers: 200, epoch: 4 | loss: 0.0934588\n",
      "\tspeed: 0.0240s/iter; left time: 519.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 225 | Train Loss: 0.0901883 Vali Loss: 0.0833089 Test Loss: 0.0883095\n",
      "Validation loss decreased (0.085170 --> 0.083309).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0869687\n",
      "\tspeed: 0.0491s/iter; left time: 1054.7985s\n",
      "\titers: 200, epoch: 5 | loss: 0.0852287\n",
      "\tspeed: 0.0283s/iter; left time: 604.6821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.18s\n",
      "Steps: 225 | Train Loss: 0.0878854 Vali Loss: 0.0824049 Test Loss: 0.0873542\n",
      "Validation loss decreased (0.083309 --> 0.082405).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889387\n",
      "\tspeed: 0.0529s/iter; left time: 1126.1671s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888741\n",
      "\tspeed: 0.0252s/iter; left time: 533.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.33s\n",
      "Steps: 225 | Train Loss: 0.0863424 Vali Loss: 0.0816884 Test Loss: 0.0865861\n",
      "Validation loss decreased (0.082405 --> 0.081688).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891346\n",
      "\tspeed: 0.0596s/iter; left time: 1255.0231s\n",
      "\titers: 200, epoch: 7 | loss: 0.0892126\n",
      "\tspeed: 0.0286s/iter; left time: 599.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 225 | Train Loss: 0.0854523 Vali Loss: 0.0814068 Test Loss: 0.0861835\n",
      "Validation loss decreased (0.081688 --> 0.081407).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0836080\n",
      "\tspeed: 0.0488s/iter; left time: 1016.3865s\n",
      "\titers: 200, epoch: 8 | loss: 0.0833302\n",
      "\tspeed: 0.0244s/iter; left time: 504.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 225 | Train Loss: 0.0847868 Vali Loss: 0.0812494 Test Loss: 0.0859815\n",
      "Validation loss decreased (0.081407 --> 0.081249).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0844111\n",
      "\tspeed: 0.0481s/iter; left time: 991.9269s\n",
      "\titers: 200, epoch: 9 | loss: 0.0839203\n",
      "\tspeed: 0.0276s/iter; left time: 566.1741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 225 | Train Loss: 0.0842783 Vali Loss: 0.0809623 Test Loss: 0.0856916\n",
      "Validation loss decreased (0.081249 --> 0.080962).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0840827\n",
      "\tspeed: 0.0480s/iter; left time: 979.0573s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833659\n",
      "\tspeed: 0.0253s/iter; left time: 512.9400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 225 | Train Loss: 0.0837914 Vali Loss: 0.0807498 Test Loss: 0.0853891\n",
      "Validation loss decreased (0.080962 --> 0.080750).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844054\n",
      "\tspeed: 0.0503s/iter; left time: 1013.0260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0841210\n",
      "\tspeed: 0.0239s/iter; left time: 478.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 225 | Train Loss: 0.0834776 Vali Loss: 0.0806861 Test Loss: 0.0854105\n",
      "Validation loss decreased (0.080750 --> 0.080686).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0856243\n",
      "\tspeed: 0.0463s/iter; left time: 922.8811s\n",
      "\titers: 200, epoch: 12 | loss: 0.0814999\n",
      "\tspeed: 0.0190s/iter; left time: 376.9476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.69s\n",
      "Steps: 225 | Train Loss: 0.0831765 Vali Loss: 0.0805396 Test Loss: 0.0852748\n",
      "Validation loss decreased (0.080686 --> 0.080540).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0823201\n",
      "\tspeed: 0.0491s/iter; left time: 966.7401s\n",
      "\titers: 200, epoch: 13 | loss: 0.0824843\n",
      "\tspeed: 0.0291s/iter; left time: 570.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 225 | Train Loss: 0.0828718 Vali Loss: 0.0806253 Test Loss: 0.0853202\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0857025\n",
      "\tspeed: 0.0480s/iter; left time: 935.2010s\n",
      "\titers: 200, epoch: 14 | loss: 0.0842681\n",
      "\tspeed: 0.0264s/iter; left time: 512.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0826168 Vali Loss: 0.0805015 Test Loss: 0.0852329\n",
      "Validation loss decreased (0.080540 --> 0.080502).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803370\n",
      "\tspeed: 0.0550s/iter; left time: 1058.3849s\n",
      "\titers: 200, epoch: 15 | loss: 0.0810816\n",
      "\tspeed: 0.0286s/iter; left time: 547.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 225 | Train Loss: 0.0824204 Vali Loss: 0.0803796 Test Loss: 0.0851721\n",
      "Validation loss decreased (0.080502 --> 0.080380).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0836899\n",
      "\tspeed: 0.0481s/iter; left time: 914.3237s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845447\n",
      "\tspeed: 0.0247s/iter; left time: 467.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 225 | Train Loss: 0.0822336 Vali Loss: 0.0804758 Test Loss: 0.0853276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0848320\n",
      "\tspeed: 0.0542s/iter; left time: 1018.5180s\n",
      "\titers: 200, epoch: 17 | loss: 0.0789179\n",
      "\tspeed: 0.0303s/iter; left time: 566.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.92s\n",
      "Steps: 225 | Train Loss: 0.0820664 Vali Loss: 0.0803697 Test Loss: 0.0852048\n",
      "Validation loss decreased (0.080380 --> 0.080370).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0851984\n",
      "\tspeed: 0.0490s/iter; left time: 909.3852s\n",
      "\titers: 200, epoch: 18 | loss: 0.0820806\n",
      "\tspeed: 0.0269s/iter; left time: 497.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 225 | Train Loss: 0.0819157 Vali Loss: 0.0804346 Test Loss: 0.0851734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0839131\n",
      "\tspeed: 0.0475s/iter; left time: 872.3472s\n",
      "\titers: 200, epoch: 19 | loss: 0.0830659\n",
      "\tspeed: 0.0198s/iter; left time: 362.2307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 225 | Train Loss: 0.0817556 Vali Loss: 0.0803696 Test Loss: 0.0851382\n",
      "Validation loss decreased (0.080370 --> 0.080370).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0845550\n",
      "\tspeed: 0.0535s/iter; left time: 968.8931s\n",
      "\titers: 200, epoch: 20 | loss: 0.0835551\n",
      "\tspeed: 0.0266s/iter; left time: 479.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 225 | Train Loss: 0.0816904 Vali Loss: 0.0804153 Test Loss: 0.0852913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0853033\n",
      "\tspeed: 0.0560s/iter; left time: 1002.1862s\n",
      "\titers: 200, epoch: 21 | loss: 0.0811036\n",
      "\tspeed: 0.0253s/iter; left time: 450.2199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 225 | Train Loss: 0.0815676 Vali Loss: 0.0803861 Test Loss: 0.0852296\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0832729\n",
      "\tspeed: 0.0571s/iter; left time: 1009.6678s\n",
      "\titers: 200, epoch: 22 | loss: 0.0833033\n",
      "\tspeed: 0.0340s/iter; left time: 597.6241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.67s\n",
      "Steps: 225 | Train Loss: 0.0814544 Vali Loss: 0.0803558 Test Loss: 0.0851281\n",
      "Validation loss decreased (0.080370 --> 0.080356).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0812934\n",
      "\tspeed: 0.0559s/iter; left time: 975.0119s\n",
      "\titers: 200, epoch: 23 | loss: 0.0778939\n",
      "\tspeed: 0.0267s/iter; left time: 463.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.60s\n",
      "Steps: 225 | Train Loss: 0.0813538 Vali Loss: 0.0803401 Test Loss: 0.0851232\n",
      "Validation loss decreased (0.080356 --> 0.080340).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0798932\n",
      "\tspeed: 0.0542s/iter; left time: 934.5044s\n",
      "\titers: 200, epoch: 24 | loss: 0.0799176\n",
      "\tspeed: 0.0246s/iter; left time: 421.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 225 | Train Loss: 0.0813174 Vali Loss: 0.0803973 Test Loss: 0.0851114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0781831\n",
      "\tspeed: 0.0552s/iter; left time: 937.7107s\n",
      "\titers: 200, epoch: 25 | loss: 0.0801677\n",
      "\tspeed: 0.0303s/iter; left time: 512.7122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 225 | Train Loss: 0.0812149 Vali Loss: 0.0803270 Test Loss: 0.0851396\n",
      "Validation loss decreased (0.080340 --> 0.080327).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0842388\n",
      "\tspeed: 0.0513s/iter; left time: 860.3276s\n",
      "\titers: 200, epoch: 26 | loss: 0.0848632\n",
      "\tspeed: 0.0288s/iter; left time: 479.7731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 225 | Train Loss: 0.0811977 Vali Loss: 0.0804594 Test Loss: 0.0851851\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0855992\n",
      "\tspeed: 0.0502s/iter; left time: 831.0068s\n",
      "\titers: 200, epoch: 27 | loss: 0.0824470\n",
      "\tspeed: 0.0261s/iter; left time: 429.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 225 | Train Loss: 0.0810765 Vali Loss: 0.0802903 Test Loss: 0.0852222\n",
      "Validation loss decreased (0.080327 --> 0.080290).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0795919\n",
      "\tspeed: 0.0512s/iter; left time: 835.5050s\n",
      "\titers: 200, epoch: 28 | loss: 0.0814527\n",
      "\tspeed: 0.0267s/iter; left time: 432.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:06.19s\n",
      "Steps: 225 | Train Loss: 0.0810530 Vali Loss: 0.0803517 Test Loss: 0.0851737\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0819565\n",
      "\tspeed: 0.0525s/iter; left time: 845.1188s\n",
      "\titers: 200, epoch: 29 | loss: 0.0810080\n",
      "\tspeed: 0.0291s/iter; left time: 465.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 225 | Train Loss: 0.0810184 Vali Loss: 0.0804359 Test Loss: 0.0852643\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0857717\n",
      "\tspeed: 0.0540s/iter; left time: 857.7606s\n",
      "\titers: 200, epoch: 30 | loss: 0.0759639\n",
      "\tspeed: 0.0271s/iter; left time: 427.2497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.47s\n",
      "Steps: 225 | Train Loss: 0.0809112 Vali Loss: 0.0804278 Test Loss: 0.0852496\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0843048\n",
      "\tspeed: 0.0494s/iter; left time: 772.7096s\n",
      "\titers: 200, epoch: 31 | loss: 0.0825789\n",
      "\tspeed: 0.0282s/iter; left time: 437.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.34s\n",
      "Steps: 225 | Train Loss: 0.0809512 Vali Loss: 0.0802745 Test Loss: 0.0851780\n",
      "Validation loss decreased (0.080290 --> 0.080275).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0817797\n",
      "\tspeed: 0.0573s/iter; left time: 884.3511s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841645\n",
      "\tspeed: 0.0266s/iter; left time: 407.2445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.62s\n",
      "Steps: 225 | Train Loss: 0.0808820 Vali Loss: 0.0804246 Test Loss: 0.0852316\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0790420\n",
      "\tspeed: 0.0505s/iter; left time: 768.1035s\n",
      "\titers: 200, epoch: 33 | loss: 0.0808264\n",
      "\tspeed: 0.0211s/iter; left time: 318.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 225 | Train Loss: 0.0808836 Vali Loss: 0.0803094 Test Loss: 0.0852217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0813956\n",
      "\tspeed: 0.0495s/iter; left time: 741.3969s\n",
      "\titers: 200, epoch: 34 | loss: 0.0802785\n",
      "\tspeed: 0.0257s/iter; left time: 382.4833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.12s\n",
      "Steps: 225 | Train Loss: 0.0808873 Vali Loss: 0.0803756 Test Loss: 0.0852348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0820862\n",
      "\tspeed: 0.0477s/iter; left time: 704.0633s\n",
      "\titers: 200, epoch: 35 | loss: 0.0778505\n",
      "\tspeed: 0.0248s/iter; left time: 363.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 225 | Train Loss: 0.0807801 Vali Loss: 0.0803882 Test Loss: 0.0852780\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0843533\n",
      "\tspeed: 0.0449s/iter; left time: 651.6178s\n",
      "\titers: 200, epoch: 36 | loss: 0.0829121\n",
      "\tspeed: 0.0245s/iter; left time: 353.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 225 | Train Loss: 0.0807507 Vali Loss: 0.0804198 Test Loss: 0.0852077\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0747861\n",
      "\tspeed: 0.0542s/iter; left time: 775.0166s\n",
      "\titers: 200, epoch: 37 | loss: 0.0831783\n",
      "\tspeed: 0.0299s/iter; left time: 424.9247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 225 | Train Loss: 0.0807784 Vali Loss: 0.0803491 Test Loss: 0.0852391\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0808313\n",
      "\tspeed: 0.0464s/iter; left time: 653.1537s\n",
      "\titers: 200, epoch: 38 | loss: 0.0774353\n",
      "\tspeed: 0.0224s/iter; left time: 312.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 225 | Train Loss: 0.0807539 Vali Loss: 0.0803463 Test Loss: 0.0851984\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0803528\n",
      "\tspeed: 0.0485s/iter; left time: 672.2164s\n",
      "\titers: 200, epoch: 39 | loss: 0.0773313\n",
      "\tspeed: 0.0223s/iter; left time: 306.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 225 | Train Loss: 0.0807201 Vali Loss: 0.0804620 Test Loss: 0.0852809\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0826981\n",
      "\tspeed: 0.0494s/iter; left time: 672.8553s\n",
      "\titers: 200, epoch: 40 | loss: 0.0803929\n",
      "\tspeed: 0.0264s/iter; left time: 357.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 225 | Train Loss: 0.0807109 Vali Loss: 0.0804412 Test Loss: 0.0852437\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0817502\n",
      "\tspeed: 0.0475s/iter; left time: 636.1647s\n",
      "\titers: 200, epoch: 41 | loss: 0.0825093\n",
      "\tspeed: 0.0288s/iter; left time: 382.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 225 | Train Loss: 0.0806799 Vali Loss: 0.0804509 Test Loss: 0.0852655\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_168_168_IT_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019877824932336807, rmse:0.14098873734474182, mae:0.08517807722091675, rse:0.5335890054702759\n",
      "Intermediate time for IT and pred_len 168: 00h:10m:31.71s\n",
      "Intermediate time for IT: 00h:43m:32.29s\n",
      "Total time: 03h:46m:41.65s\n"
     ]
    }
   ],
   "source": [
    "# Here so long because someone started running his 2 processes on my GPU while I was running my code >:( without it, it runs 3-4 hours.\n",
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            if country == \"DE\" and pred_len == 24:\n",
    "                seq_len = 336\n",
    "            else:\n",
    "                seq_len = seq_lens[i]\n",
    "                \n",
    "            model_id = f\"ts_decomp_{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            #shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1439</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.0852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0213  0.1458  0.0891\n",
       "        96              0.0356  0.1887  0.1254\n",
       "        168             0.0380  0.1950  0.1324\n",
       "ES      24              0.0098  0.0991  0.0595\n",
       "        96              0.0186  0.1364  0.0868\n",
       "        168             0.0212  0.1455  0.0953\n",
       "FR      24              0.0099  0.0995  0.0542\n",
       "        96              0.0192  0.1385  0.0795\n",
       "        168             0.0207  0.1439  0.0857\n",
       "GB      24              0.0257  0.1603  0.1023\n",
       "        96              0.0442  0.2103  0.1428\n",
       "        168             0.0447  0.2114  0.1468\n",
       "IT      24              0.0101  0.1005  0.0569\n",
       "        96              0.0183  0.1353  0.0796\n",
       "        168             0.0199  0.1412  0.0852"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
