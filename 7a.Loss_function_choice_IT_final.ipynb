{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax Scaler Informer](#3-minmax-scaler-informer)\n",
    "- [4. MinMax Scaler PatchTST](#4-minmax-scaler-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on **Italy** dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison_IT\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2655926\n",
      "\tspeed: 0.0645s/iter; left time: 1163.1290s\n",
      "\titers: 200, epoch: 1 | loss: 1.1257330\n",
      "\tspeed: 0.0334s/iter; left time: 598.8550s\n",
      "\titers: 300, epoch: 1 | loss: 1.0365514\n",
      "\tspeed: 0.0336s/iter; left time: 598.8625s\n",
      "\titers: 400, epoch: 1 | loss: 1.0826616\n",
      "\tspeed: 0.0332s/iter; left time: 588.5207s\n",
      "\titers: 500, epoch: 1 | loss: 0.9831452\n",
      "\tspeed: 0.0333s/iter; left time: 587.5538s\n",
      "\titers: 600, epoch: 1 | loss: 0.9529172\n",
      "\tspeed: 0.0333s/iter; left time: 583.9105s\n",
      "\titers: 700, epoch: 1 | loss: 0.8132041\n",
      "\tspeed: 0.0352s/iter; left time: 613.9352s\n",
      "\titers: 800, epoch: 1 | loss: 0.8678878\n",
      "\tspeed: 0.0330s/iter; left time: 572.3718s\n",
      "\titers: 900, epoch: 1 | loss: 0.8668443\n",
      "\tspeed: 0.0330s/iter; left time: 568.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.64s\n",
      "Steps: 906 | Train Loss: 1.0168596 Vali Loss: 0.8487804 Test Loss: 0.9571623\n",
      "Validation loss decreased (inf --> 0.848780).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6205368\n",
      "\tspeed: 0.0983s/iter; left time: 1681.9596s\n",
      "\titers: 200, epoch: 2 | loss: 0.4253878\n",
      "\tspeed: 0.0330s/iter; left time: 561.3882s\n",
      "\titers: 300, epoch: 2 | loss: 0.3354857\n",
      "\tspeed: 0.0345s/iter; left time: 583.4433s\n",
      "\titers: 400, epoch: 2 | loss: 0.2754024\n",
      "\tspeed: 0.0334s/iter; left time: 561.4366s\n",
      "\titers: 500, epoch: 2 | loss: 0.3423934\n",
      "\tspeed: 0.0330s/iter; left time: 551.2826s\n",
      "\titers: 600, epoch: 2 | loss: 0.2980999\n",
      "\tspeed: 0.0329s/iter; left time: 546.1756s\n",
      "\titers: 700, epoch: 2 | loss: 0.2921608\n",
      "\tspeed: 0.0330s/iter; left time: 544.1735s\n",
      "\titers: 800, epoch: 2 | loss: 0.2983772\n",
      "\tspeed: 0.0329s/iter; left time: 540.6488s\n",
      "\titers: 900, epoch: 2 | loss: 0.2948388\n",
      "\tspeed: 0.0328s/iter; left time: 535.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.51s\n",
      "Steps: 906 | Train Loss: 0.3569713 Vali Loss: 0.2462852 Test Loss: 0.2797472\n",
      "Validation loss decreased (0.848780 --> 0.246285).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2653996\n",
      "\tspeed: 0.1000s/iter; left time: 1620.6737s\n",
      "\titers: 200, epoch: 3 | loss: 0.2120890\n",
      "\tspeed: 0.0328s/iter; left time: 527.8860s\n",
      "\titers: 300, epoch: 3 | loss: 0.2602098\n",
      "\tspeed: 0.0328s/iter; left time: 524.8766s\n",
      "\titers: 400, epoch: 3 | loss: 0.2079800\n",
      "\tspeed: 0.0330s/iter; left time: 524.9169s\n",
      "\titers: 500, epoch: 3 | loss: 0.3032918\n",
      "\tspeed: 0.0328s/iter; left time: 518.7615s\n",
      "\titers: 600, epoch: 3 | loss: 0.2656105\n",
      "\tspeed: 0.0328s/iter; left time: 515.2379s\n",
      "\titers: 700, epoch: 3 | loss: 0.1913124\n",
      "\tspeed: 0.0327s/iter; left time: 509.8536s\n",
      "\titers: 800, epoch: 3 | loss: 0.2174596\n",
      "\tspeed: 0.0324s/iter; left time: 503.2106s\n",
      "\titers: 900, epoch: 3 | loss: 0.2116019\n",
      "\tspeed: 0.0325s/iter; left time: 501.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 906 | Train Loss: 0.2390530 Vali Loss: 0.2166305 Test Loss: 0.2498899\n",
      "Validation loss decreased (0.246285 --> 0.216630).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1990468\n",
      "\tspeed: 0.0999s/iter; left time: 1529.4257s\n",
      "\titers: 200, epoch: 4 | loss: 0.1888942\n",
      "\tspeed: 0.0325s/iter; left time: 494.5352s\n",
      "\titers: 300, epoch: 4 | loss: 0.2250282\n",
      "\tspeed: 0.0325s/iter; left time: 491.4924s\n",
      "\titers: 400, epoch: 4 | loss: 0.2040859\n",
      "\tspeed: 0.0325s/iter; left time: 486.8950s\n",
      "\titers: 500, epoch: 4 | loss: 0.2031991\n",
      "\tspeed: 0.0325s/iter; left time: 484.5961s\n",
      "\titers: 600, epoch: 4 | loss: 0.2883396\n",
      "\tspeed: 0.0326s/iter; left time: 482.3796s\n",
      "\titers: 700, epoch: 4 | loss: 0.2602419\n",
      "\tspeed: 0.0324s/iter; left time: 476.3455s\n",
      "\titers: 800, epoch: 4 | loss: 0.2502171\n",
      "\tspeed: 0.0323s/iter; left time: 471.3138s\n",
      "\titers: 900, epoch: 4 | loss: 0.2754031\n",
      "\tspeed: 0.0327s/iter; left time: 474.0360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.88s\n",
      "Steps: 906 | Train Loss: 0.2162457 Vali Loss: 0.2035362 Test Loss: 0.2375945\n",
      "Validation loss decreased (0.216630 --> 0.203536).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1779218\n",
      "\tspeed: 0.0941s/iter; left time: 1355.3232s\n",
      "\titers: 200, epoch: 5 | loss: 0.1628965\n",
      "\tspeed: 0.0320s/iter; left time: 457.3853s\n",
      "\titers: 300, epoch: 5 | loss: 0.1668604\n",
      "\tspeed: 0.0319s/iter; left time: 453.3149s\n",
      "\titers: 400, epoch: 5 | loss: 0.1712749\n",
      "\tspeed: 0.0320s/iter; left time: 450.9551s\n",
      "\titers: 500, epoch: 5 | loss: 0.2286835\n",
      "\tspeed: 0.0320s/iter; left time: 448.2459s\n",
      "\titers: 600, epoch: 5 | loss: 0.1758938\n",
      "\tspeed: 0.0320s/iter; left time: 444.3929s\n",
      "\titers: 700, epoch: 5 | loss: 0.2287813\n",
      "\tspeed: 0.0319s/iter; left time: 439.8470s\n",
      "\titers: 800, epoch: 5 | loss: 0.1645952\n",
      "\tspeed: 0.0317s/iter; left time: 433.5500s\n",
      "\titers: 900, epoch: 5 | loss: 0.2300254\n",
      "\tspeed: 0.0317s/iter; left time: 431.3851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 906 | Train Loss: 0.2023375 Vali Loss: 0.1983158 Test Loss: 0.2302715\n",
      "Validation loss decreased (0.203536 --> 0.198316).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1984994\n",
      "\tspeed: 0.0910s/iter; left time: 1228.3472s\n",
      "\titers: 200, epoch: 6 | loss: 0.2014216\n",
      "\tspeed: 0.0316s/iter; left time: 423.4627s\n",
      "\titers: 300, epoch: 6 | loss: 0.2673222\n",
      "\tspeed: 0.0316s/iter; left time: 420.3885s\n",
      "\titers: 400, epoch: 6 | loss: 0.2324974\n",
      "\tspeed: 0.0318s/iter; left time: 418.8575s\n",
      "\titers: 500, epoch: 6 | loss: 0.1736211\n",
      "\tspeed: 0.0316s/iter; left time: 414.3100s\n",
      "\titers: 600, epoch: 6 | loss: 0.2277704\n",
      "\tspeed: 0.0316s/iter; left time: 410.7830s\n",
      "\titers: 700, epoch: 6 | loss: 0.2457504\n",
      "\tspeed: 0.0316s/iter; left time: 406.8684s\n",
      "\titers: 800, epoch: 6 | loss: 0.1754776\n",
      "\tspeed: 0.0317s/iter; left time: 404.9718s\n",
      "\titers: 900, epoch: 6 | loss: 0.2075734\n",
      "\tspeed: 0.0317s/iter; left time: 402.7895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.95s\n",
      "Steps: 906 | Train Loss: 0.1929701 Vali Loss: 0.1915811 Test Loss: 0.2247654\n",
      "Validation loss decreased (0.198316 --> 0.191581).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1909763\n",
      "\tspeed: 0.0899s/iter; left time: 1131.4732s\n",
      "\titers: 200, epoch: 7 | loss: 0.1391223\n",
      "\tspeed: 0.0316s/iter; left time: 394.0341s\n",
      "\titers: 300, epoch: 7 | loss: 0.1620394\n",
      "\tspeed: 0.0315s/iter; left time: 389.8233s\n",
      "\titers: 400, epoch: 7 | loss: 0.1572613\n",
      "\tspeed: 0.0314s/iter; left time: 385.9734s\n",
      "\titers: 500, epoch: 7 | loss: 0.1740226\n",
      "\tspeed: 0.0314s/iter; left time: 383.0674s\n",
      "\titers: 600, epoch: 7 | loss: 0.1448199\n",
      "\tspeed: 0.0315s/iter; left time: 380.2064s\n",
      "\titers: 700, epoch: 7 | loss: 0.1617811\n",
      "\tspeed: 0.0314s/iter; left time: 376.6538s\n",
      "\titers: 800, epoch: 7 | loss: 0.2418114\n",
      "\tspeed: 0.0315s/iter; left time: 373.9198s\n",
      "\titers: 900, epoch: 7 | loss: 0.1763118\n",
      "\tspeed: 0.0315s/iter; left time: 371.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.84s\n",
      "Steps: 906 | Train Loss: 0.1855679 Vali Loss: 0.1916122 Test Loss: 0.2240161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1528163\n",
      "\tspeed: 0.0898s/iter; left time: 1049.0655s\n",
      "\titers: 200, epoch: 8 | loss: 0.1402654\n",
      "\tspeed: 0.0323s/iter; left time: 373.8837s\n",
      "\titers: 300, epoch: 8 | loss: 0.1994791\n",
      "\tspeed: 0.0323s/iter; left time: 370.7118s\n",
      "\titers: 400, epoch: 8 | loss: 0.1748054\n",
      "\tspeed: 0.0327s/iter; left time: 372.0569s\n",
      "\titers: 500, epoch: 8 | loss: 0.2032394\n",
      "\tspeed: 0.0325s/iter; left time: 366.1325s\n",
      "\titers: 600, epoch: 8 | loss: 0.1853030\n",
      "\tspeed: 0.0323s/iter; left time: 360.9262s\n",
      "\titers: 700, epoch: 8 | loss: 0.1588358\n",
      "\tspeed: 0.0321s/iter; left time: 355.6575s\n",
      "\titers: 800, epoch: 8 | loss: 0.1668811\n",
      "\tspeed: 0.0319s/iter; left time: 350.5853s\n",
      "\titers: 900, epoch: 8 | loss: 0.2083564\n",
      "\tspeed: 0.0319s/iter; left time: 347.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.58s\n",
      "Steps: 906 | Train Loss: 0.1789123 Vali Loss: 0.1909796 Test Loss: 0.2257884\n",
      "Validation loss decreased (0.191581 --> 0.190980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1739116\n",
      "\tspeed: 0.0925s/iter; left time: 996.9422s\n",
      "\titers: 200, epoch: 9 | loss: 0.1993625\n",
      "\tspeed: 0.0319s/iter; left time: 340.8745s\n",
      "\titers: 300, epoch: 9 | loss: 0.1636563\n",
      "\tspeed: 0.0319s/iter; left time: 337.7103s\n",
      "\titers: 400, epoch: 9 | loss: 0.2166614\n",
      "\tspeed: 0.0319s/iter; left time: 334.1953s\n",
      "\titers: 500, epoch: 9 | loss: 0.1858605\n",
      "\tspeed: 0.0320s/iter; left time: 331.5020s\n",
      "\titers: 600, epoch: 9 | loss: 0.1781302\n",
      "\tspeed: 0.0319s/iter; left time: 327.8943s\n",
      "\titers: 700, epoch: 9 | loss: 0.1733542\n",
      "\tspeed: 0.0319s/iter; left time: 324.7958s\n",
      "\titers: 800, epoch: 9 | loss: 0.1696661\n",
      "\tspeed: 0.0319s/iter; left time: 320.9749s\n",
      "\titers: 900, epoch: 9 | loss: 0.1628733\n",
      "\tspeed: 0.0318s/iter; left time: 317.2615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.27s\n",
      "Steps: 906 | Train Loss: 0.1739853 Vali Loss: 0.1913661 Test Loss: 0.2280283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1886700\n",
      "\tspeed: 0.0869s/iter; left time: 857.7209s\n",
      "\titers: 200, epoch: 10 | loss: 0.1583662\n",
      "\tspeed: 0.0305s/iter; left time: 298.1652s\n",
      "\titers: 300, epoch: 10 | loss: 0.2071207\n",
      "\tspeed: 0.0305s/iter; left time: 295.0708s\n",
      "\titers: 400, epoch: 10 | loss: 0.1750381\n",
      "\tspeed: 0.0305s/iter; left time: 291.6122s\n",
      "\titers: 500, epoch: 10 | loss: 0.1599534\n",
      "\tspeed: 0.0305s/iter; left time: 288.4065s\n",
      "\titers: 600, epoch: 10 | loss: 0.1547934\n",
      "\tspeed: 0.0305s/iter; left time: 285.6697s\n",
      "\titers: 700, epoch: 10 | loss: 0.1641959\n",
      "\tspeed: 0.0305s/iter; left time: 282.5363s\n",
      "\titers: 800, epoch: 10 | loss: 0.1693465\n",
      "\tspeed: 0.0305s/iter; left time: 279.6251s\n",
      "\titers: 900, epoch: 10 | loss: 0.2088962\n",
      "\tspeed: 0.0305s/iter; left time: 276.9105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 906 | Train Loss: 0.1698084 Vali Loss: 0.1913244 Test Loss: 0.2238524\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1410738\n",
      "\tspeed: 0.0856s/iter; left time: 766.6166s\n",
      "\titers: 200, epoch: 11 | loss: 0.1254946\n",
      "\tspeed: 0.0305s/iter; left time: 270.6632s\n",
      "\titers: 300, epoch: 11 | loss: 0.1921563\n",
      "\tspeed: 0.0306s/iter; left time: 267.6494s\n",
      "\titers: 400, epoch: 11 | loss: 0.1626051\n",
      "\tspeed: 0.0305s/iter; left time: 264.3194s\n",
      "\titers: 500, epoch: 11 | loss: 0.1395112\n",
      "\tspeed: 0.0305s/iter; left time: 261.3798s\n",
      "\titers: 600, epoch: 11 | loss: 0.1702996\n",
      "\tspeed: 0.0304s/iter; left time: 257.4136s\n",
      "\titers: 700, epoch: 11 | loss: 0.1565440\n",
      "\tspeed: 0.0303s/iter; left time: 253.2346s\n",
      "\titers: 800, epoch: 11 | loss: 0.1646023\n",
      "\tspeed: 0.0303s/iter; left time: 250.4390s\n",
      "\titers: 900, epoch: 11 | loss: 0.1816361\n",
      "\tspeed: 0.0303s/iter; left time: 247.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.89s\n",
      "Steps: 906 | Train Loss: 0.1661819 Vali Loss: 0.1863565 Test Loss: 0.2223691\n",
      "Validation loss decreased (0.190980 --> 0.186356).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2047073\n",
      "\tspeed: 0.0920s/iter; left time: 741.0522s\n",
      "\titers: 200, epoch: 12 | loss: 0.1806621\n",
      "\tspeed: 0.0302s/iter; left time: 240.0103s\n",
      "\titers: 300, epoch: 12 | loss: 0.2038715\n",
      "\tspeed: 0.0302s/iter; left time: 237.3835s\n",
      "\titers: 400, epoch: 12 | loss: 0.1419129\n",
      "\tspeed: 0.0302s/iter; left time: 234.1270s\n",
      "\titers: 500, epoch: 12 | loss: 0.1215186\n",
      "\tspeed: 0.0302s/iter; left time: 231.0748s\n",
      "\titers: 600, epoch: 12 | loss: 0.1550405\n",
      "\tspeed: 0.0303s/iter; left time: 228.6485s\n",
      "\titers: 700, epoch: 12 | loss: 0.1790772\n",
      "\tspeed: 0.0303s/iter; left time: 225.6667s\n",
      "\titers: 800, epoch: 12 | loss: 0.1482660\n",
      "\tspeed: 0.0302s/iter; left time: 222.3609s\n",
      "\titers: 900, epoch: 12 | loss: 0.1308462\n",
      "\tspeed: 0.0303s/iter; left time: 219.6609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.68s\n",
      "Steps: 906 | Train Loss: 0.1631092 Vali Loss: 0.1833248 Test Loss: 0.2202100\n",
      "Validation loss decreased (0.186356 --> 0.183325).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2019415\n",
      "\tspeed: 0.0888s/iter; left time: 634.8460s\n",
      "\titers: 200, epoch: 13 | loss: 0.1578228\n",
      "\tspeed: 0.0303s/iter; left time: 213.3379s\n",
      "\titers: 300, epoch: 13 | loss: 0.1638445\n",
      "\tspeed: 0.0303s/iter; left time: 210.2209s\n",
      "\titers: 400, epoch: 13 | loss: 0.1835979\n",
      "\tspeed: 0.0302s/iter; left time: 206.8192s\n",
      "\titers: 500, epoch: 13 | loss: 0.1297828\n",
      "\tspeed: 0.0302s/iter; left time: 204.0778s\n",
      "\titers: 600, epoch: 13 | loss: 0.1768717\n",
      "\tspeed: 0.0303s/iter; left time: 201.3557s\n",
      "\titers: 700, epoch: 13 | loss: 0.1593725\n",
      "\tspeed: 0.0303s/iter; left time: 198.4293s\n",
      "\titers: 800, epoch: 13 | loss: 0.1237680\n",
      "\tspeed: 0.0303s/iter; left time: 195.2640s\n",
      "\titers: 900, epoch: 13 | loss: 0.1891339\n",
      "\tspeed: 0.0303s/iter; left time: 192.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.70s\n",
      "Steps: 906 | Train Loss: 0.1603260 Vali Loss: 0.1840722 Test Loss: 0.2198605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1957013\n",
      "\tspeed: 0.0835s/iter; left time: 521.0004s\n",
      "\titers: 200, epoch: 14 | loss: 0.1663086\n",
      "\tspeed: 0.0303s/iter; left time: 186.0366s\n",
      "\titers: 300, epoch: 14 | loss: 0.1738329\n",
      "\tspeed: 0.0303s/iter; left time: 182.9138s\n",
      "\titers: 400, epoch: 14 | loss: 0.1429007\n",
      "\tspeed: 0.0303s/iter; left time: 179.9698s\n",
      "\titers: 500, epoch: 14 | loss: 0.1599222\n",
      "\tspeed: 0.0303s/iter; left time: 176.8835s\n",
      "\titers: 600, epoch: 14 | loss: 0.1743926\n",
      "\tspeed: 0.0303s/iter; left time: 173.8981s\n",
      "\titers: 700, epoch: 14 | loss: 0.1334641\n",
      "\tspeed: 0.0303s/iter; left time: 170.9197s\n",
      "\titers: 800, epoch: 14 | loss: 0.1281492\n",
      "\tspeed: 0.0303s/iter; left time: 167.9768s\n",
      "\titers: 900, epoch: 14 | loss: 0.1342761\n",
      "\tspeed: 0.0303s/iter; left time: 164.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.71s\n",
      "Steps: 906 | Train Loss: 0.1581648 Vali Loss: 0.1850006 Test Loss: 0.2216871\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1295189\n",
      "\tspeed: 0.0832s/iter; left time: 444.1976s\n",
      "\titers: 200, epoch: 15 | loss: 0.1223399\n",
      "\tspeed: 0.0303s/iter; left time: 158.4610s\n",
      "\titers: 300, epoch: 15 | loss: 0.1357728\n",
      "\tspeed: 0.0302s/iter; left time: 155.3259s\n",
      "\titers: 400, epoch: 15 | loss: 0.1444422\n",
      "\tspeed: 0.0303s/iter; left time: 152.4297s\n",
      "\titers: 500, epoch: 15 | loss: 0.1802864\n",
      "\tspeed: 0.0303s/iter; left time: 149.6979s\n",
      "\titers: 600, epoch: 15 | loss: 0.1279870\n",
      "\tspeed: 0.0303s/iter; left time: 146.7310s\n",
      "\titers: 700, epoch: 15 | loss: 0.1535772\n",
      "\tspeed: 0.0303s/iter; left time: 143.4354s\n",
      "\titers: 800, epoch: 15 | loss: 0.1905851\n",
      "\tspeed: 0.0304s/iter; left time: 140.8355s\n",
      "\titers: 900, epoch: 15 | loss: 0.1444526\n",
      "\tspeed: 0.0303s/iter; left time: 137.3389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.71s\n",
      "Steps: 906 | Train Loss: 0.1560168 Vali Loss: 0.1850767 Test Loss: 0.2227659\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22030074894428253, rmse:0.4693620800971985, mae:0.2934994399547577, rse:0.4298593997955322\n",
      "Original data scale mse:1680994.875, rmse:1296.5318603515625, mae:861.99560546875, rse:0.09111034870147705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1973295\n",
      "\tspeed: 0.0331s/iter; left time: 597.1368s\n",
      "\titers: 200, epoch: 1 | loss: 1.1421980\n",
      "\tspeed: 0.0302s/iter; left time: 542.1042s\n",
      "\titers: 300, epoch: 1 | loss: 1.0683498\n",
      "\tspeed: 0.0302s/iter; left time: 538.2024s\n",
      "\titers: 400, epoch: 1 | loss: 1.0709852\n",
      "\tspeed: 0.0302s/iter; left time: 535.1117s\n",
      "\titers: 500, epoch: 1 | loss: 0.9242501\n",
      "\tspeed: 0.0302s/iter; left time: 532.3480s\n",
      "\titers: 600, epoch: 1 | loss: 0.9109845\n",
      "\tspeed: 0.0302s/iter; left time: 528.7240s\n",
      "\titers: 700, epoch: 1 | loss: 0.8609775\n",
      "\tspeed: 0.0301s/iter; left time: 524.0272s\n",
      "\titers: 800, epoch: 1 | loss: 0.9410301\n",
      "\tspeed: 0.0299s/iter; left time: 518.2336s\n",
      "\titers: 900, epoch: 1 | loss: 0.8934740\n",
      "\tspeed: 0.0299s/iter; left time: 515.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.64s\n",
      "Steps: 906 | Train Loss: 1.0131149 Vali Loss: 0.8399439 Test Loss: 0.9540177\n",
      "Validation loss decreased (inf --> 0.839944).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5374418\n",
      "\tspeed: 0.0861s/iter; left time: 1472.7873s\n",
      "\titers: 200, epoch: 2 | loss: 0.4233172\n",
      "\tspeed: 0.0301s/iter; left time: 512.2404s\n",
      "\titers: 300, epoch: 2 | loss: 0.3481802\n",
      "\tspeed: 0.0301s/iter; left time: 508.7664s\n",
      "\titers: 400, epoch: 2 | loss: 0.3249161\n",
      "\tspeed: 0.0301s/iter; left time: 506.2153s\n",
      "\titers: 500, epoch: 2 | loss: 0.3003129\n",
      "\tspeed: 0.0301s/iter; left time: 503.8228s\n",
      "\titers: 600, epoch: 2 | loss: 0.3237344\n",
      "\tspeed: 0.0301s/iter; left time: 500.5551s\n",
      "\titers: 700, epoch: 2 | loss: 0.2852631\n",
      "\tspeed: 0.0301s/iter; left time: 496.8078s\n",
      "\titers: 800, epoch: 2 | loss: 0.2535228\n",
      "\tspeed: 0.0301s/iter; left time: 493.6008s\n",
      "\titers: 900, epoch: 2 | loss: 0.2464543\n",
      "\tspeed: 0.0301s/iter; left time: 491.1864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.59s\n",
      "Steps: 906 | Train Loss: 0.3592484 Vali Loss: 0.2497449 Test Loss: 0.2751626\n",
      "Validation loss decreased (0.839944 --> 0.249745).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2510317\n",
      "\tspeed: 0.0878s/iter; left time: 1423.4172s\n",
      "\titers: 200, epoch: 3 | loss: 0.2203990\n",
      "\tspeed: 0.0300s/iter; left time: 483.4522s\n",
      "\titers: 300, epoch: 3 | loss: 0.1857467\n",
      "\tspeed: 0.0300s/iter; left time: 480.4008s\n",
      "\titers: 400, epoch: 3 | loss: 0.2201314\n",
      "\tspeed: 0.0300s/iter; left time: 476.8723s\n",
      "\titers: 500, epoch: 3 | loss: 0.2493524\n",
      "\tspeed: 0.0300s/iter; left time: 474.0173s\n",
      "\titers: 600, epoch: 3 | loss: 0.2327100\n",
      "\tspeed: 0.0300s/iter; left time: 471.1628s\n",
      "\titers: 700, epoch: 3 | loss: 0.1974741\n",
      "\tspeed: 0.0300s/iter; left time: 468.4419s\n",
      "\titers: 800, epoch: 3 | loss: 0.2512345\n",
      "\tspeed: 0.0300s/iter; left time: 465.1880s\n",
      "\titers: 900, epoch: 3 | loss: 0.1945242\n",
      "\tspeed: 0.0300s/iter; left time: 462.2478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.50s\n",
      "Steps: 906 | Train Loss: 0.2380821 Vali Loss: 0.2192356 Test Loss: 0.2467774\n",
      "Validation loss decreased (0.249745 --> 0.219236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2088396\n",
      "\tspeed: 0.0925s/iter; left time: 1415.8979s\n",
      "\titers: 200, epoch: 4 | loss: 0.2268296\n",
      "\tspeed: 0.0300s/iter; left time: 456.0171s\n",
      "\titers: 300, epoch: 4 | loss: 0.2682111\n",
      "\tspeed: 0.0300s/iter; left time: 453.8006s\n",
      "\titers: 400, epoch: 4 | loss: 0.2142512\n",
      "\tspeed: 0.0300s/iter; left time: 450.3977s\n",
      "\titers: 500, epoch: 4 | loss: 0.2133008\n",
      "\tspeed: 0.0300s/iter; left time: 447.0090s\n",
      "\titers: 600, epoch: 4 | loss: 0.2556488\n",
      "\tspeed: 0.0300s/iter; left time: 444.4221s\n",
      "\titers: 700, epoch: 4 | loss: 0.1777005\n",
      "\tspeed: 0.0300s/iter; left time: 440.5006s\n",
      "\titers: 800, epoch: 4 | loss: 0.2581894\n",
      "\tspeed: 0.0300s/iter; left time: 437.8109s\n",
      "\titers: 900, epoch: 4 | loss: 0.1423981\n",
      "\tspeed: 0.0300s/iter; left time: 435.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.48s\n",
      "Steps: 906 | Train Loss: 0.2149451 Vali Loss: 0.2036094 Test Loss: 0.2357368\n",
      "Validation loss decreased (0.219236 --> 0.203609).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2451628\n",
      "\tspeed: 0.0859s/iter; left time: 1236.6785s\n",
      "\titers: 200, epoch: 5 | loss: 0.1844019\n",
      "\tspeed: 0.0300s/iter; left time: 429.1551s\n",
      "\titers: 300, epoch: 5 | loss: 0.1272023\n",
      "\tspeed: 0.0300s/iter; left time: 425.9297s\n",
      "\titers: 400, epoch: 5 | loss: 0.2236189\n",
      "\tspeed: 0.0300s/iter; left time: 422.9288s\n",
      "\titers: 500, epoch: 5 | loss: 0.1628642\n",
      "\tspeed: 0.0300s/iter; left time: 420.4496s\n",
      "\titers: 600, epoch: 5 | loss: 0.1402728\n",
      "\tspeed: 0.0300s/iter; left time: 417.2173s\n",
      "\titers: 700, epoch: 5 | loss: 0.2224473\n",
      "\tspeed: 0.0300s/iter; left time: 413.9148s\n",
      "\titers: 800, epoch: 5 | loss: 0.2364742\n",
      "\tspeed: 0.0300s/iter; left time: 411.1036s\n",
      "\titers: 900, epoch: 5 | loss: 0.2050458\n",
      "\tspeed: 0.0300s/iter; left time: 407.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.48s\n",
      "Steps: 906 | Train Loss: 0.2004238 Vali Loss: 0.1958581 Test Loss: 0.2253950\n",
      "Validation loss decreased (0.203609 --> 0.195858).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1923144\n",
      "\tspeed: 0.0883s/iter; left time: 1191.6470s\n",
      "\titers: 200, epoch: 6 | loss: 0.1665370\n",
      "\tspeed: 0.0300s/iter; left time: 402.2874s\n",
      "\titers: 300, epoch: 6 | loss: 0.1647235\n",
      "\tspeed: 0.0300s/iter; left time: 398.5364s\n",
      "\titers: 400, epoch: 6 | loss: 0.1797579\n",
      "\tspeed: 0.0300s/iter; left time: 395.2480s\n",
      "\titers: 500, epoch: 6 | loss: 0.1545018\n",
      "\tspeed: 0.0300s/iter; left time: 392.1223s\n",
      "\titers: 600, epoch: 6 | loss: 0.2259643\n",
      "\tspeed: 0.0300s/iter; left time: 389.2560s\n",
      "\titers: 700, epoch: 6 | loss: 0.1816601\n",
      "\tspeed: 0.0300s/iter; left time: 386.0955s\n",
      "\titers: 800, epoch: 6 | loss: 0.1513158\n",
      "\tspeed: 0.0300s/iter; left time: 383.1009s\n",
      "\titers: 900, epoch: 6 | loss: 0.1692653\n",
      "\tspeed: 0.0299s/iter; left time: 379.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.45s\n",
      "Steps: 906 | Train Loss: 0.1902713 Vali Loss: 0.1955038 Test Loss: 0.2277900\n",
      "Validation loss decreased (0.195858 --> 0.195504).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2298900\n",
      "\tspeed: 0.0853s/iter; left time: 1073.7301s\n",
      "\titers: 200, epoch: 7 | loss: 0.1472812\n",
      "\tspeed: 0.0300s/iter; left time: 375.0070s\n",
      "\titers: 300, epoch: 7 | loss: 0.1788663\n",
      "\tspeed: 0.0301s/iter; left time: 372.5321s\n",
      "\titers: 400, epoch: 7 | loss: 0.1623691\n",
      "\tspeed: 0.0300s/iter; left time: 369.0336s\n",
      "\titers: 500, epoch: 7 | loss: 0.1475256\n",
      "\tspeed: 0.0300s/iter; left time: 365.6372s\n",
      "\titers: 600, epoch: 7 | loss: 0.1393432\n",
      "\tspeed: 0.0300s/iter; left time: 362.4063s\n",
      "\titers: 700, epoch: 7 | loss: 0.1944267\n",
      "\tspeed: 0.0300s/iter; left time: 359.2233s\n",
      "\titers: 800, epoch: 7 | loss: 0.1804781\n",
      "\tspeed: 0.0300s/iter; left time: 356.3488s\n",
      "\titers: 900, epoch: 7 | loss: 0.1573293\n",
      "\tspeed: 0.0300s/iter; left time: 353.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.48s\n",
      "Steps: 906 | Train Loss: 0.1823200 Vali Loss: 0.1930710 Test Loss: 0.2249620\n",
      "Validation loss decreased (0.195504 --> 0.193071).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1789100\n",
      "\tspeed: 0.0881s/iter; left time: 1028.5819s\n",
      "\titers: 200, epoch: 8 | loss: 0.1614548\n",
      "\tspeed: 0.0300s/iter; left time: 347.3805s\n",
      "\titers: 300, epoch: 8 | loss: 0.1923694\n",
      "\tspeed: 0.0300s/iter; left time: 344.4026s\n",
      "\titers: 400, epoch: 8 | loss: 0.2199651\n",
      "\tspeed: 0.0300s/iter; left time: 341.3317s\n",
      "\titers: 500, epoch: 8 | loss: 0.1808472\n",
      "\tspeed: 0.0301s/iter; left time: 339.4498s\n",
      "\titers: 600, epoch: 8 | loss: 0.2397220\n",
      "\tspeed: 0.0300s/iter; left time: 335.1406s\n",
      "\titers: 700, epoch: 8 | loss: 0.2278471\n",
      "\tspeed: 0.0300s/iter; left time: 332.3878s\n",
      "\titers: 800, epoch: 8 | loss: 0.2043150\n",
      "\tspeed: 0.0300s/iter; left time: 329.1771s\n",
      "\titers: 900, epoch: 8 | loss: 0.1779005\n",
      "\tspeed: 0.0300s/iter; left time: 326.3565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.46s\n",
      "Steps: 906 | Train Loss: 0.1759455 Vali Loss: 0.1875082 Test Loss: 0.2209941\n",
      "Validation loss decreased (0.193071 --> 0.187508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1644031\n",
      "\tspeed: 0.0869s/iter; left time: 935.7968s\n",
      "\titers: 200, epoch: 9 | loss: 0.2507294\n",
      "\tspeed: 0.0300s/iter; left time: 319.7723s\n",
      "\titers: 300, epoch: 9 | loss: 0.2283448\n",
      "\tspeed: 0.0299s/iter; left time: 316.4675s\n",
      "\titers: 400, epoch: 9 | loss: 0.1817382\n",
      "\tspeed: 0.0300s/iter; left time: 314.2980s\n",
      "\titers: 500, epoch: 9 | loss: 0.1469816\n",
      "\tspeed: 0.0300s/iter; left time: 311.0364s\n",
      "\titers: 600, epoch: 9 | loss: 0.1369695\n",
      "\tspeed: 0.0300s/iter; left time: 308.5459s\n",
      "\titers: 700, epoch: 9 | loss: 0.1735614\n",
      "\tspeed: 0.0300s/iter; left time: 304.7610s\n",
      "\titers: 800, epoch: 9 | loss: 0.1863412\n",
      "\tspeed: 0.0300s/iter; left time: 301.7859s\n",
      "\titers: 900, epoch: 9 | loss: 0.1586168\n",
      "\tspeed: 0.0300s/iter; left time: 299.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.43s\n",
      "Steps: 906 | Train Loss: 0.1704638 Vali Loss: 0.1869479 Test Loss: 0.2218861\n",
      "Validation loss decreased (0.187508 --> 0.186948).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1457572\n",
      "\tspeed: 0.0875s/iter; left time: 863.3844s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251245\n",
      "\tspeed: 0.0300s/iter; left time: 293.0288s\n",
      "\titers: 300, epoch: 10 | loss: 0.1279689\n",
      "\tspeed: 0.0301s/iter; left time: 290.5573s\n",
      "\titers: 400, epoch: 10 | loss: 0.2251878\n",
      "\tspeed: 0.0300s/iter; left time: 286.8774s\n",
      "\titers: 500, epoch: 10 | loss: 0.1428768\n",
      "\tspeed: 0.0300s/iter; left time: 284.0455s\n",
      "\titers: 600, epoch: 10 | loss: 0.1350298\n",
      "\tspeed: 0.0300s/iter; left time: 280.9236s\n",
      "\titers: 700, epoch: 10 | loss: 0.1976508\n",
      "\tspeed: 0.0300s/iter; left time: 277.9905s\n",
      "\titers: 800, epoch: 10 | loss: 0.1537141\n",
      "\tspeed: 0.0300s/iter; left time: 275.4100s\n",
      "\titers: 900, epoch: 10 | loss: 0.1983796\n",
      "\tspeed: 0.0301s/iter; left time: 272.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.51s\n",
      "Steps: 906 | Train Loss: 0.1660709 Vali Loss: 0.1898970 Test Loss: 0.2283974\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1414833\n",
      "\tspeed: 0.0838s/iter; left time: 750.9173s\n",
      "\titers: 200, epoch: 11 | loss: 0.1964810\n",
      "\tspeed: 0.0301s/iter; left time: 266.5659s\n",
      "\titers: 300, epoch: 11 | loss: 0.1748426\n",
      "\tspeed: 0.0300s/iter; left time: 262.9623s\n",
      "\titers: 400, epoch: 11 | loss: 0.1310564\n",
      "\tspeed: 0.0300s/iter; left time: 259.4383s\n",
      "\titers: 500, epoch: 11 | loss: 0.1376743\n",
      "\tspeed: 0.0300s/iter; left time: 256.4575s\n",
      "\titers: 600, epoch: 11 | loss: 0.1773211\n",
      "\tspeed: 0.0300s/iter; left time: 253.4089s\n",
      "\titers: 700, epoch: 11 | loss: 0.1335469\n",
      "\tspeed: 0.0300s/iter; left time: 250.6750s\n",
      "\titers: 800, epoch: 11 | loss: 0.1604896\n",
      "\tspeed: 0.0300s/iter; left time: 247.4972s\n",
      "\titers: 900, epoch: 11 | loss: 0.1420005\n",
      "\tspeed: 0.0300s/iter; left time: 244.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.45s\n",
      "Steps: 906 | Train Loss: 0.1620493 Vali Loss: 0.1876232 Test Loss: 0.2207744\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1794909\n",
      "\tspeed: 0.0828s/iter; left time: 666.7311s\n",
      "\titers: 200, epoch: 12 | loss: 0.1482996\n",
      "\tspeed: 0.0301s/iter; left time: 239.1626s\n",
      "\titers: 300, epoch: 12 | loss: 0.1748915\n",
      "\tspeed: 0.0301s/iter; left time: 236.1895s\n",
      "\titers: 400, epoch: 12 | loss: 0.1930236\n",
      "\tspeed: 0.0300s/iter; left time: 233.0031s\n",
      "\titers: 500, epoch: 12 | loss: 0.1466676\n",
      "\tspeed: 0.0301s/iter; left time: 230.2141s\n",
      "\titers: 600, epoch: 12 | loss: 0.1437257\n",
      "\tspeed: 0.0301s/iter; left time: 227.2452s\n",
      "\titers: 700, epoch: 12 | loss: 0.2111108\n",
      "\tspeed: 0.0301s/iter; left time: 224.1386s\n",
      "\titers: 800, epoch: 12 | loss: 0.1766935\n",
      "\tspeed: 0.0301s/iter; left time: 221.4640s\n",
      "\titers: 900, epoch: 12 | loss: 0.1558518\n",
      "\tspeed: 0.0301s/iter; left time: 218.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.54s\n",
      "Steps: 906 | Train Loss: 0.1592279 Vali Loss: 0.1830799 Test Loss: 0.2161524\n",
      "Validation loss decreased (0.186948 --> 0.183080).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1335872\n",
      "\tspeed: 0.0866s/iter; left time: 618.8869s\n",
      "\titers: 200, epoch: 13 | loss: 0.1904642\n",
      "\tspeed: 0.0300s/iter; left time: 211.5857s\n",
      "\titers: 300, epoch: 13 | loss: 0.1406990\n",
      "\tspeed: 0.0300s/iter; left time: 208.4297s\n",
      "\titers: 400, epoch: 13 | loss: 0.1491441\n",
      "\tspeed: 0.0300s/iter; left time: 205.5397s\n",
      "\titers: 500, epoch: 13 | loss: 0.1908478\n",
      "\tspeed: 0.0300s/iter; left time: 202.5455s\n",
      "\titers: 600, epoch: 13 | loss: 0.1886673\n",
      "\tspeed: 0.0301s/iter; left time: 200.1375s\n",
      "\titers: 700, epoch: 13 | loss: 0.1309064\n",
      "\tspeed: 0.0300s/iter; left time: 196.4595s\n",
      "\titers: 800, epoch: 13 | loss: 0.1589462\n",
      "\tspeed: 0.0300s/iter; left time: 193.4215s\n",
      "\titers: 900, epoch: 13 | loss: 0.1876475\n",
      "\tspeed: 0.0300s/iter; left time: 190.3491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.49s\n",
      "Steps: 906 | Train Loss: 0.1563049 Vali Loss: 0.1856795 Test Loss: 0.2219029\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1495333\n",
      "\tspeed: 0.0830s/iter; left time: 518.1374s\n",
      "\titers: 200, epoch: 14 | loss: 0.0944232\n",
      "\tspeed: 0.0301s/iter; left time: 184.7374s\n",
      "\titers: 300, epoch: 14 | loss: 0.1575354\n",
      "\tspeed: 0.0301s/iter; left time: 181.6256s\n",
      "\titers: 400, epoch: 14 | loss: 0.1296602\n",
      "\tspeed: 0.0301s/iter; left time: 178.7741s\n",
      "\titers: 500, epoch: 14 | loss: 0.1424343\n",
      "\tspeed: 0.0301s/iter; left time: 175.6434s\n",
      "\titers: 600, epoch: 14 | loss: 0.1530355\n",
      "\tspeed: 0.0300s/iter; left time: 172.5209s\n",
      "\titers: 700, epoch: 14 | loss: 0.1749859\n",
      "\tspeed: 0.0300s/iter; left time: 169.5089s\n",
      "\titers: 800, epoch: 14 | loss: 0.1459346\n",
      "\tspeed: 0.0301s/iter; left time: 167.0267s\n",
      "\titers: 900, epoch: 14 | loss: 0.2009379\n",
      "\tspeed: 0.0301s/iter; left time: 163.6234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.51s\n",
      "Steps: 906 | Train Loss: 0.1537245 Vali Loss: 0.1861046 Test Loss: 0.2244890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1449612\n",
      "\tspeed: 0.0829s/iter; left time: 442.2043s\n",
      "\titers: 200, epoch: 15 | loss: 0.1392896\n",
      "\tspeed: 0.0300s/iter; left time: 157.2547s\n",
      "\titers: 300, epoch: 15 | loss: 0.1350373\n",
      "\tspeed: 0.0300s/iter; left time: 154.1967s\n",
      "\titers: 400, epoch: 15 | loss: 0.1786360\n",
      "\tspeed: 0.0301s/iter; left time: 151.5792s\n",
      "\titers: 500, epoch: 15 | loss: 0.1219083\n",
      "\tspeed: 0.0301s/iter; left time: 148.6239s\n",
      "\titers: 600, epoch: 15 | loss: 0.1108440\n",
      "\tspeed: 0.0301s/iter; left time: 145.7405s\n",
      "\titers: 700, epoch: 15 | loss: 0.1847629\n",
      "\tspeed: 0.0300s/iter; left time: 142.2635s\n",
      "\titers: 800, epoch: 15 | loss: 0.1144152\n",
      "\tspeed: 0.0300s/iter; left time: 139.2765s\n",
      "\titers: 900, epoch: 15 | loss: 0.1235651\n",
      "\tspeed: 0.0301s/iter; left time: 136.4244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.52s\n",
      "Steps: 906 | Train Loss: 0.1517470 Vali Loss: 0.1870975 Test Loss: 0.2185816\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21708616614341736, rmse:0.46592506766319275, mae:0.28623270988464355, rse:0.42671167850494385\n",
      "Original data scale mse:1580196.75, rmse:1257.0587158203125, mae:835.594482421875, rse:0.08833649009466171\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0433810\n",
      "\tspeed: 0.0569s/iter; left time: 1024.0082s\n",
      "\titers: 200, epoch: 1 | loss: 0.9495971\n",
      "\tspeed: 0.0377s/iter; left time: 673.9913s\n",
      "\titers: 300, epoch: 1 | loss: 0.7839106\n",
      "\tspeed: 0.0377s/iter; left time: 669.4830s\n",
      "\titers: 400, epoch: 1 | loss: 0.7479047\n",
      "\tspeed: 0.0377s/iter; left time: 667.3794s\n",
      "\titers: 500, epoch: 1 | loss: 0.6955235\n",
      "\tspeed: 0.0377s/iter; left time: 663.0406s\n",
      "\titers: 600, epoch: 1 | loss: 0.6325172\n",
      "\tspeed: 0.0378s/iter; left time: 659.9135s\n",
      "\titers: 700, epoch: 1 | loss: 0.5802335\n",
      "\tspeed: 0.0377s/iter; left time: 655.1418s\n",
      "\titers: 800, epoch: 1 | loss: 0.5810441\n",
      "\tspeed: 0.0377s/iter; left time: 651.7636s\n",
      "\titers: 900, epoch: 1 | loss: 0.5980899\n",
      "\tspeed: 0.0377s/iter; left time: 648.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.79s\n",
      "Steps: 904 | Train Loss: 0.7531377 Vali Loss: 0.5355341 Test Loss: 0.6029890\n",
      "Validation loss decreased (inf --> 0.535534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4816381\n",
      "\tspeed: 0.1161s/iter; left time: 1982.9286s\n",
      "\titers: 200, epoch: 2 | loss: 0.4974765\n",
      "\tspeed: 0.0376s/iter; left time: 638.9604s\n",
      "\titers: 300, epoch: 2 | loss: 0.3962263\n",
      "\tspeed: 0.0376s/iter; left time: 635.1478s\n",
      "\titers: 400, epoch: 2 | loss: 0.3811402\n",
      "\tspeed: 0.0376s/iter; left time: 631.0355s\n",
      "\titers: 500, epoch: 2 | loss: 0.3722235\n",
      "\tspeed: 0.0377s/iter; left time: 627.9117s\n",
      "\titers: 600, epoch: 2 | loss: 0.3952564\n",
      "\tspeed: 0.0376s/iter; left time: 624.1202s\n",
      "\titers: 700, epoch: 2 | loss: 0.3544340\n",
      "\tspeed: 0.0377s/iter; left time: 620.6429s\n",
      "\titers: 800, epoch: 2 | loss: 0.3584991\n",
      "\tspeed: 0.0376s/iter; left time: 615.7825s\n",
      "\titers: 900, epoch: 2 | loss: 0.3201607\n",
      "\tspeed: 0.0376s/iter; left time: 611.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.29s\n",
      "Steps: 904 | Train Loss: 0.4017989 Vali Loss: 0.3387201 Test Loss: 0.3724573\n",
      "Validation loss decreased (0.535534 --> 0.338720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3438635\n",
      "\tspeed: 0.1079s/iter; left time: 1744.7986s\n",
      "\titers: 200, epoch: 3 | loss: 0.3321435\n",
      "\tspeed: 0.0377s/iter; left time: 605.2934s\n",
      "\titers: 300, epoch: 3 | loss: 0.3372475\n",
      "\tspeed: 0.0377s/iter; left time: 601.4924s\n",
      "\titers: 400, epoch: 3 | loss: 0.3517059\n",
      "\tspeed: 0.0376s/iter; left time: 597.1930s\n",
      "\titers: 500, epoch: 3 | loss: 0.2855895\n",
      "\tspeed: 0.0376s/iter; left time: 593.2270s\n",
      "\titers: 600, epoch: 3 | loss: 0.2975675\n",
      "\tspeed: 0.0376s/iter; left time: 590.0400s\n",
      "\titers: 700, epoch: 3 | loss: 0.2875018\n",
      "\tspeed: 0.0376s/iter; left time: 585.8464s\n",
      "\titers: 800, epoch: 3 | loss: 0.3534431\n",
      "\tspeed: 0.0376s/iter; left time: 581.7769s\n",
      "\titers: 900, epoch: 3 | loss: 0.3374185\n",
      "\tspeed: 0.0376s/iter; left time: 578.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.33s\n",
      "Steps: 904 | Train Loss: 0.3183414 Vali Loss: 0.3282952 Test Loss: 0.3708166\n",
      "Validation loss decreased (0.338720 --> 0.328295).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2574762\n",
      "\tspeed: 0.1077s/iter; left time: 1645.0413s\n",
      "\titers: 200, epoch: 4 | loss: 0.2858969\n",
      "\tspeed: 0.0377s/iter; left time: 571.8356s\n",
      "\titers: 300, epoch: 4 | loss: 0.2627040\n",
      "\tspeed: 0.0377s/iter; left time: 567.9005s\n",
      "\titers: 400, epoch: 4 | loss: 0.3160098\n",
      "\tspeed: 0.0377s/iter; left time: 564.6174s\n",
      "\titers: 500, epoch: 4 | loss: 0.3133468\n",
      "\tspeed: 0.0377s/iter; left time: 559.8755s\n",
      "\titers: 600, epoch: 4 | loss: 0.3077377\n",
      "\tspeed: 0.0377s/iter; left time: 556.5746s\n",
      "\titers: 700, epoch: 4 | loss: 0.2466153\n",
      "\tspeed: 0.0377s/iter; left time: 552.7487s\n",
      "\titers: 800, epoch: 4 | loss: 0.2869949\n",
      "\tspeed: 0.0377s/iter; left time: 549.2527s\n",
      "\titers: 900, epoch: 4 | loss: 0.2474540\n",
      "\tspeed: 0.0377s/iter; left time: 545.1041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.38s\n",
      "Steps: 904 | Train Loss: 0.2874134 Vali Loss: 0.3369873 Test Loss: 0.4013102\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2177296\n",
      "\tspeed: 0.1037s/iter; left time: 1489.9128s\n",
      "\titers: 200, epoch: 5 | loss: 0.2392200\n",
      "\tspeed: 0.0377s/iter; left time: 538.2414s\n",
      "\titers: 300, epoch: 5 | loss: 0.2466172\n",
      "\tspeed: 0.0377s/iter; left time: 534.4068s\n",
      "\titers: 400, epoch: 5 | loss: 0.3085367\n",
      "\tspeed: 0.0377s/iter; left time: 530.0428s\n",
      "\titers: 500, epoch: 5 | loss: 0.2516232\n",
      "\tspeed: 0.0377s/iter; left time: 526.8087s\n",
      "\titers: 600, epoch: 5 | loss: 0.2561632\n",
      "\tspeed: 0.0377s/iter; left time: 522.5252s\n",
      "\titers: 700, epoch: 5 | loss: 0.2971331\n",
      "\tspeed: 0.0377s/iter; left time: 518.8838s\n",
      "\titers: 800, epoch: 5 | loss: 0.2664599\n",
      "\tspeed: 0.0377s/iter; left time: 514.8066s\n",
      "\titers: 900, epoch: 5 | loss: 0.2453663\n",
      "\tspeed: 0.0377s/iter; left time: 510.9887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.40s\n",
      "Steps: 904 | Train Loss: 0.2574948 Vali Loss: 0.3611175 Test Loss: 0.3933213\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1780142\n",
      "\tspeed: 0.1035s/iter; left time: 1392.9055s\n",
      "\titers: 200, epoch: 6 | loss: 0.2488946\n",
      "\tspeed: 0.0377s/iter; left time: 503.9347s\n",
      "\titers: 300, epoch: 6 | loss: 0.2395774\n",
      "\tspeed: 0.0376s/iter; left time: 499.1077s\n",
      "\titers: 400, epoch: 6 | loss: 0.2469465\n",
      "\tspeed: 0.0376s/iter; left time: 495.4591s\n",
      "\titers: 500, epoch: 6 | loss: 0.2110956\n",
      "\tspeed: 0.0377s/iter; left time: 492.0184s\n",
      "\titers: 600, epoch: 6 | loss: 0.2194913\n",
      "\tspeed: 0.0377s/iter; left time: 488.0563s\n",
      "\titers: 700, epoch: 6 | loss: 0.1760184\n",
      "\tspeed: 0.0376s/iter; left time: 483.9136s\n",
      "\titers: 800, epoch: 6 | loss: 0.2334978\n",
      "\tspeed: 0.0376s/iter; left time: 480.3680s\n",
      "\titers: 900, epoch: 6 | loss: 0.2233697\n",
      "\tspeed: 0.0376s/iter; left time: 476.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.30s\n",
      "Steps: 904 | Train Loss: 0.2282654 Vali Loss: 0.3764598 Test Loss: 0.4058681\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.37084266543388367, rmse:0.6089684963226318, mae:0.40437051653862, rse:0.557574450969696\n",
      "Original data scale mse:3333727.75, rmse:1825.849853515625, mae:1242.7080078125, rse:0.12849251925945282\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9310343\n",
      "\tspeed: 0.0403s/iter; left time: 724.1424s\n",
      "\titers: 200, epoch: 1 | loss: 0.9147289\n",
      "\tspeed: 0.0379s/iter; left time: 677.7552s\n",
      "\titers: 300, epoch: 1 | loss: 0.8570474\n",
      "\tspeed: 0.0377s/iter; left time: 670.4289s\n",
      "\titers: 400, epoch: 1 | loss: 0.7464865\n",
      "\tspeed: 0.0377s/iter; left time: 667.3594s\n",
      "\titers: 500, epoch: 1 | loss: 0.7416446\n",
      "\tspeed: 0.0377s/iter; left time: 663.1987s\n",
      "\titers: 600, epoch: 1 | loss: 0.5792195\n",
      "\tspeed: 0.0379s/iter; left time: 661.7161s\n",
      "\titers: 700, epoch: 1 | loss: 0.6355222\n",
      "\tspeed: 0.0377s/iter; left time: 655.7716s\n",
      "\titers: 800, epoch: 1 | loss: 0.5904879\n",
      "\tspeed: 0.0377s/iter; left time: 651.3748s\n",
      "\titers: 900, epoch: 1 | loss: 0.5825278\n",
      "\tspeed: 0.0377s/iter; left time: 647.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.44s\n",
      "Steps: 904 | Train Loss: 0.7520023 Vali Loss: 0.5394430 Test Loss: 0.6188242\n",
      "Validation loss decreased (inf --> 0.539443).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5777426\n",
      "\tspeed: 0.1100s/iter; left time: 1877.6433s\n",
      "\titers: 200, epoch: 2 | loss: 0.5601380\n",
      "\tspeed: 0.0377s/iter; left time: 639.4571s\n",
      "\titers: 300, epoch: 2 | loss: 0.3959455\n",
      "\tspeed: 0.0377s/iter; left time: 635.4391s\n",
      "\titers: 400, epoch: 2 | loss: 0.3575569\n",
      "\tspeed: 0.0377s/iter; left time: 631.7300s\n",
      "\titers: 500, epoch: 2 | loss: 0.3508132\n",
      "\tspeed: 0.0377s/iter; left time: 628.5374s\n",
      "\titers: 600, epoch: 2 | loss: 0.4210768\n",
      "\tspeed: 0.0376s/iter; left time: 623.6913s\n",
      "\titers: 700, epoch: 2 | loss: 0.3401209\n",
      "\tspeed: 0.0376s/iter; left time: 620.0123s\n",
      "\titers: 800, epoch: 2 | loss: 0.3282757\n",
      "\tspeed: 0.0376s/iter; left time: 615.9705s\n",
      "\titers: 900, epoch: 2 | loss: 0.2986883\n",
      "\tspeed: 0.0376s/iter; left time: 612.5596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.34s\n",
      "Steps: 904 | Train Loss: 0.4000782 Vali Loss: 0.3314674 Test Loss: 0.3737507\n",
      "Validation loss decreased (0.539443 --> 0.331467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3327233\n",
      "\tspeed: 0.1071s/iter; left time: 1731.6260s\n",
      "\titers: 200, epoch: 3 | loss: 0.3367423\n",
      "\tspeed: 0.0377s/iter; left time: 606.6234s\n",
      "\titers: 300, epoch: 3 | loss: 0.3462038\n",
      "\tspeed: 0.0377s/iter; left time: 601.9935s\n",
      "\titers: 400, epoch: 3 | loss: 0.3281111\n",
      "\tspeed: 0.0378s/iter; left time: 599.3999s\n",
      "\titers: 500, epoch: 3 | loss: 0.3106598\n",
      "\tspeed: 0.0376s/iter; left time: 593.5081s\n",
      "\titers: 600, epoch: 3 | loss: 0.3515031\n",
      "\tspeed: 0.0377s/iter; left time: 590.9953s\n",
      "\titers: 700, epoch: 3 | loss: 0.3463474\n",
      "\tspeed: 0.0377s/iter; left time: 587.7160s\n",
      "\titers: 800, epoch: 3 | loss: 0.2964612\n",
      "\tspeed: 0.0377s/iter; left time: 583.3999s\n",
      "\titers: 900, epoch: 3 | loss: 0.2469234\n",
      "\tspeed: 0.0376s/iter; left time: 578.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.38s\n",
      "Steps: 904 | Train Loss: 0.3193620 Vali Loss: 0.3252755 Test Loss: 0.3624292\n",
      "Validation loss decreased (0.331467 --> 0.325275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2780003\n",
      "\tspeed: 0.1063s/iter; left time: 1622.9697s\n",
      "\titers: 200, epoch: 4 | loss: 0.2793081\n",
      "\tspeed: 0.0376s/iter; left time: 570.0459s\n",
      "\titers: 300, epoch: 4 | loss: 0.2678560\n",
      "\tspeed: 0.0376s/iter; left time: 565.9655s\n",
      "\titers: 400, epoch: 4 | loss: 0.2835883\n",
      "\tspeed: 0.0376s/iter; left time: 562.3242s\n",
      "\titers: 500, epoch: 4 | loss: 0.2706463\n",
      "\tspeed: 0.0376s/iter; left time: 559.4220s\n",
      "\titers: 600, epoch: 4 | loss: 0.2996997\n",
      "\tspeed: 0.0376s/iter; left time: 554.8207s\n",
      "\titers: 700, epoch: 4 | loss: 0.2831515\n",
      "\tspeed: 0.0376s/iter; left time: 551.4538s\n",
      "\titers: 800, epoch: 4 | loss: 0.2655961\n",
      "\tspeed: 0.0376s/iter; left time: 547.5039s\n",
      "\titers: 900, epoch: 4 | loss: 0.2640123\n",
      "\tspeed: 0.0376s/iter; left time: 543.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.26s\n",
      "Steps: 904 | Train Loss: 0.2878566 Vali Loss: 0.3581431 Test Loss: 0.3730399\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2474798\n",
      "\tspeed: 0.1043s/iter; left time: 1498.7728s\n",
      "\titers: 200, epoch: 5 | loss: 0.2787637\n",
      "\tspeed: 0.0377s/iter; left time: 537.1097s\n",
      "\titers: 300, epoch: 5 | loss: 0.2955056\n",
      "\tspeed: 0.0376s/iter; left time: 533.1558s\n",
      "\titers: 400, epoch: 5 | loss: 0.2447727\n",
      "\tspeed: 0.0376s/iter; left time: 529.3492s\n",
      "\titers: 500, epoch: 5 | loss: 0.2601503\n",
      "\tspeed: 0.0375s/iter; left time: 524.0882s\n",
      "\titers: 600, epoch: 5 | loss: 0.2364178\n",
      "\tspeed: 0.0374s/iter; left time: 518.5631s\n",
      "\titers: 700, epoch: 5 | loss: 0.2461311\n",
      "\tspeed: 0.0374s/iter; left time: 514.7506s\n",
      "\titers: 800, epoch: 5 | loss: 0.2391737\n",
      "\tspeed: 0.0374s/iter; left time: 511.5207s\n",
      "\titers: 900, epoch: 5 | loss: 0.2079362\n",
      "\tspeed: 0.0374s/iter; left time: 507.4393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.22s\n",
      "Steps: 904 | Train Loss: 0.2588882 Vali Loss: 0.3430499 Test Loss: 0.3840977\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2355718\n",
      "\tspeed: 0.1020s/iter; left time: 1372.6722s\n",
      "\titers: 200, epoch: 6 | loss: 0.2274001\n",
      "\tspeed: 0.0374s/iter; left time: 499.7743s\n",
      "\titers: 300, epoch: 6 | loss: 0.2482404\n",
      "\tspeed: 0.0374s/iter; left time: 495.9254s\n",
      "\titers: 400, epoch: 6 | loss: 0.2259423\n",
      "\tspeed: 0.0374s/iter; left time: 492.0059s\n",
      "\titers: 500, epoch: 6 | loss: 0.2531618\n",
      "\tspeed: 0.0374s/iter; left time: 488.3754s\n",
      "\titers: 600, epoch: 6 | loss: 0.2216336\n",
      "\tspeed: 0.0374s/iter; left time: 484.6852s\n",
      "\titers: 700, epoch: 6 | loss: 0.2537532\n",
      "\tspeed: 0.0374s/iter; left time: 480.6494s\n",
      "\titers: 800, epoch: 6 | loss: 0.2284748\n",
      "\tspeed: 0.0374s/iter; left time: 477.4921s\n",
      "\titers: 900, epoch: 6 | loss: 0.1975201\n",
      "\tspeed: 0.0374s/iter; left time: 473.6613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.04s\n",
      "Steps: 904 | Train Loss: 0.2283777 Vali Loss: 0.3500589 Test Loss: 0.3929238\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3623674511909485, rmse:0.6019696593284607, mae:0.40077000856399536, rse:0.5511662364006042\n",
      "Original data scale mse:3329982.0, rmse:1824.8238525390625, mae:1235.0142822265625, rse:0.12842030823230743\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0365422\n",
      "\tspeed: 0.0653s/iter; left time: 1170.6770s\n",
      "\titers: 200, epoch: 1 | loss: 0.8846171\n",
      "\tspeed: 0.0461s/iter; left time: 821.8567s\n",
      "\titers: 300, epoch: 1 | loss: 0.9547038\n",
      "\tspeed: 0.0460s/iter; left time: 816.6930s\n",
      "\titers: 400, epoch: 1 | loss: 0.8920675\n",
      "\tspeed: 0.0460s/iter; left time: 811.7746s\n",
      "\titers: 500, epoch: 1 | loss: 0.8275010\n",
      "\tspeed: 0.0460s/iter; left time: 806.9469s\n",
      "\titers: 600, epoch: 1 | loss: 0.8351727\n",
      "\tspeed: 0.0460s/iter; left time: 802.6539s\n",
      "\titers: 700, epoch: 1 | loss: 0.7744251\n",
      "\tspeed: 0.0460s/iter; left time: 798.0742s\n",
      "\titers: 800, epoch: 1 | loss: 0.8452673\n",
      "\tspeed: 0.0460s/iter; left time: 793.2100s\n",
      "\titers: 900, epoch: 1 | loss: 0.7219580\n",
      "\tspeed: 0.0460s/iter; left time: 788.9305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 902 | Train Loss: 0.8602328 Vali Loss: 0.7254865 Test Loss: 0.8113574\n",
      "Validation loss decreased (inf --> 0.725486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7216184\n",
      "\tspeed: 0.1308s/iter; left time: 2228.7236s\n",
      "\titers: 200, epoch: 2 | loss: 0.5977059\n",
      "\tspeed: 0.0460s/iter; left time: 778.8051s\n",
      "\titers: 300, epoch: 2 | loss: 0.4923407\n",
      "\tspeed: 0.0460s/iter; left time: 774.0135s\n",
      "\titers: 400, epoch: 2 | loss: 0.4656889\n",
      "\tspeed: 0.0460s/iter; left time: 769.8012s\n",
      "\titers: 500, epoch: 2 | loss: 0.3986078\n",
      "\tspeed: 0.0460s/iter; left time: 764.7337s\n",
      "\titers: 600, epoch: 2 | loss: 0.4369687\n",
      "\tspeed: 0.0459s/iter; left time: 759.8672s\n",
      "\titers: 700, epoch: 2 | loss: 0.3256683\n",
      "\tspeed: 0.0460s/iter; left time: 755.8531s\n",
      "\titers: 800, epoch: 2 | loss: 0.3587376\n",
      "\tspeed: 0.0460s/iter; left time: 752.1556s\n",
      "\titers: 900, epoch: 2 | loss: 0.3530706\n",
      "\tspeed: 0.0460s/iter; left time: 747.2583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 902 | Train Loss: 0.4776453 Vali Loss: 0.3714094 Test Loss: 0.4325749\n",
      "Validation loss decreased (0.725486 --> 0.371409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3177940\n",
      "\tspeed: 0.1278s/iter; left time: 2062.3018s\n",
      "\titers: 200, epoch: 3 | loss: 0.3877927\n",
      "\tspeed: 0.0460s/iter; left time: 737.2365s\n",
      "\titers: 300, epoch: 3 | loss: 0.3711354\n",
      "\tspeed: 0.0460s/iter; left time: 732.5720s\n",
      "\titers: 400, epoch: 3 | loss: 0.3970094\n",
      "\tspeed: 0.0460s/iter; left time: 727.9206s\n",
      "\titers: 500, epoch: 3 | loss: 0.3705113\n",
      "\tspeed: 0.0460s/iter; left time: 723.5329s\n",
      "\titers: 600, epoch: 3 | loss: 0.3258202\n",
      "\tspeed: 0.0460s/iter; left time: 719.0005s\n",
      "\titers: 700, epoch: 3 | loss: 0.3217875\n",
      "\tspeed: 0.0460s/iter; left time: 714.8503s\n",
      "\titers: 800, epoch: 3 | loss: 0.3373196\n",
      "\tspeed: 0.0460s/iter; left time: 709.8886s\n",
      "\titers: 900, epoch: 3 | loss: 0.3432759\n",
      "\tspeed: 0.0460s/iter; left time: 705.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 902 | Train Loss: 0.3510486 Vali Loss: 0.3671135 Test Loss: 0.4210625\n",
      "Validation loss decreased (0.371409 --> 0.367113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3528281\n",
      "\tspeed: 0.1391s/iter; left time: 2118.8700s\n",
      "\titers: 200, epoch: 4 | loss: 0.3186574\n",
      "\tspeed: 0.0460s/iter; left time: 695.6235s\n",
      "\titers: 300, epoch: 4 | loss: 0.3744135\n",
      "\tspeed: 0.0460s/iter; left time: 691.7972s\n",
      "\titers: 400, epoch: 4 | loss: 0.3007407\n",
      "\tspeed: 0.0460s/iter; left time: 686.6211s\n",
      "\titers: 500, epoch: 4 | loss: 0.2949081\n",
      "\tspeed: 0.0460s/iter; left time: 681.8642s\n",
      "\titers: 600, epoch: 4 | loss: 0.2888547\n",
      "\tspeed: 0.0460s/iter; left time: 677.5281s\n",
      "\titers: 700, epoch: 4 | loss: 0.3272570\n",
      "\tspeed: 0.0460s/iter; left time: 673.0745s\n",
      "\titers: 800, epoch: 4 | loss: 0.3382494\n",
      "\tspeed: 0.0460s/iter; left time: 668.6579s\n",
      "\titers: 900, epoch: 4 | loss: 0.2757096\n",
      "\tspeed: 0.0460s/iter; left time: 664.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 902 | Train Loss: 0.3145241 Vali Loss: 0.3660716 Test Loss: 0.4241156\n",
      "Validation loss decreased (0.367113 --> 0.366072).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2358644\n",
      "\tspeed: 0.1314s/iter; left time: 1882.8356s\n",
      "\titers: 200, epoch: 5 | loss: 0.2573364\n",
      "\tspeed: 0.0460s/iter; left time: 654.6122s\n",
      "\titers: 300, epoch: 5 | loss: 0.3155867\n",
      "\tspeed: 0.0459s/iter; left time: 649.3689s\n",
      "\titers: 400, epoch: 5 | loss: 0.2975460\n",
      "\tspeed: 0.0460s/iter; left time: 645.6292s\n",
      "\titers: 500, epoch: 5 | loss: 0.3126471\n",
      "\tspeed: 0.0460s/iter; left time: 640.3623s\n",
      "\titers: 600, epoch: 5 | loss: 0.2959611\n",
      "\tspeed: 0.0459s/iter; left time: 635.4049s\n",
      "\titers: 700, epoch: 5 | loss: 0.2912783\n",
      "\tspeed: 0.0459s/iter; left time: 630.8552s\n",
      "\titers: 800, epoch: 5 | loss: 0.2545171\n",
      "\tspeed: 0.0460s/iter; left time: 626.6237s\n",
      "\titers: 900, epoch: 5 | loss: 0.2511979\n",
      "\tspeed: 0.0459s/iter; left time: 621.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 902 | Train Loss: 0.2790021 Vali Loss: 0.3885911 Test Loss: 0.4254634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2349278\n",
      "\tspeed: 0.1242s/iter; left time: 1667.5303s\n",
      "\titers: 200, epoch: 6 | loss: 0.2527872\n",
      "\tspeed: 0.0460s/iter; left time: 612.6010s\n",
      "\titers: 300, epoch: 6 | loss: 0.2303856\n",
      "\tspeed: 0.0460s/iter; left time: 608.2484s\n",
      "\titers: 400, epoch: 6 | loss: 0.2505732\n",
      "\tspeed: 0.0459s/iter; left time: 603.3416s\n",
      "\titers: 500, epoch: 6 | loss: 0.2211367\n",
      "\tspeed: 0.0459s/iter; left time: 598.7680s\n",
      "\titers: 600, epoch: 6 | loss: 0.2237590\n",
      "\tspeed: 0.0459s/iter; left time: 594.0626s\n",
      "\titers: 700, epoch: 6 | loss: 0.2217987\n",
      "\tspeed: 0.0460s/iter; left time: 590.0449s\n",
      "\titers: 800, epoch: 6 | loss: 0.2063637\n",
      "\tspeed: 0.0460s/iter; left time: 585.9575s\n",
      "\titers: 900, epoch: 6 | loss: 0.2388363\n",
      "\tspeed: 0.0460s/iter; left time: 581.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 902 | Train Loss: 0.2412845 Vali Loss: 0.4343924 Test Loss: 0.4782678\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2122227\n",
      "\tspeed: 0.1245s/iter; left time: 1560.2874s\n",
      "\titers: 200, epoch: 7 | loss: 0.2170379\n",
      "\tspeed: 0.0460s/iter; left time: 572.2216s\n",
      "\titers: 300, epoch: 7 | loss: 0.1788052\n",
      "\tspeed: 0.0460s/iter; left time: 567.1034s\n",
      "\titers: 400, epoch: 7 | loss: 0.2009487\n",
      "\tspeed: 0.0460s/iter; left time: 562.6962s\n",
      "\titers: 500, epoch: 7 | loss: 0.2186683\n",
      "\tspeed: 0.0460s/iter; left time: 557.5170s\n",
      "\titers: 600, epoch: 7 | loss: 0.1997348\n",
      "\tspeed: 0.0460s/iter; left time: 552.9203s\n",
      "\titers: 700, epoch: 7 | loss: 0.2164418\n",
      "\tspeed: 0.0460s/iter; left time: 548.5680s\n",
      "\titers: 800, epoch: 7 | loss: 0.1825523\n",
      "\tspeed: 0.0460s/iter; left time: 543.8909s\n",
      "\titers: 900, epoch: 7 | loss: 0.1736540\n",
      "\tspeed: 0.0460s/iter; left time: 539.3218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 902 | Train Loss: 0.2064077 Vali Loss: 0.4329301 Test Loss: 0.4813861\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.42409995198249817, rmse:0.6512295603752136, mae:0.4370887279510498, rse:0.5964465141296387\n",
      "Original data scale mse:4642685.0, rmse:2154.68896484375, mae:1412.206298828125, rse:0.15177665650844574\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9483397\n",
      "\tspeed: 0.0486s/iter; left time: 871.2939s\n",
      "\titers: 200, epoch: 1 | loss: 0.9486579\n",
      "\tspeed: 0.0459s/iter; left time: 819.4881s\n",
      "\titers: 300, epoch: 1 | loss: 0.8301455\n",
      "\tspeed: 0.0459s/iter; left time: 815.1927s\n",
      "\titers: 400, epoch: 1 | loss: 0.8503751\n",
      "\tspeed: 0.0460s/iter; left time: 811.5638s\n",
      "\titers: 500, epoch: 1 | loss: 0.8364280\n",
      "\tspeed: 0.0460s/iter; left time: 806.5143s\n",
      "\titers: 600, epoch: 1 | loss: 0.7260083\n",
      "\tspeed: 0.0460s/iter; left time: 802.2086s\n",
      "\titers: 700, epoch: 1 | loss: 0.7473571\n",
      "\tspeed: 0.0460s/iter; left time: 797.1512s\n",
      "\titers: 800, epoch: 1 | loss: 0.7346708\n",
      "\tspeed: 0.0459s/iter; left time: 791.9212s\n",
      "\titers: 900, epoch: 1 | loss: 0.7429011\n",
      "\tspeed: 0.0459s/iter; left time: 787.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.78s\n",
      "Steps: 902 | Train Loss: 0.8504171 Vali Loss: 0.7121906 Test Loss: 0.8145077\n",
      "Validation loss decreased (inf --> 0.712191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6728511\n",
      "\tspeed: 0.1291s/iter; left time: 2200.3610s\n",
      "\titers: 200, epoch: 2 | loss: 0.5547946\n",
      "\tspeed: 0.0460s/iter; left time: 778.4769s\n",
      "\titers: 300, epoch: 2 | loss: 0.4963667\n",
      "\tspeed: 0.0460s/iter; left time: 774.3294s\n",
      "\titers: 400, epoch: 2 | loss: 0.4185760\n",
      "\tspeed: 0.0460s/iter; left time: 769.7803s\n",
      "\titers: 500, epoch: 2 | loss: 0.4750888\n",
      "\tspeed: 0.0460s/iter; left time: 765.2050s\n",
      "\titers: 600, epoch: 2 | loss: 0.3476305\n",
      "\tspeed: 0.0460s/iter; left time: 760.8368s\n",
      "\titers: 700, epoch: 2 | loss: 0.3973275\n",
      "\tspeed: 0.0460s/iter; left time: 756.4821s\n",
      "\titers: 800, epoch: 2 | loss: 0.3312517\n",
      "\tspeed: 0.0460s/iter; left time: 751.6923s\n",
      "\titers: 900, epoch: 2 | loss: 0.3894624\n",
      "\tspeed: 0.0460s/iter; left time: 746.8053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 902 | Train Loss: 0.4763714 Vali Loss: 0.3743415 Test Loss: 0.4174978\n",
      "Validation loss decreased (0.712191 --> 0.374341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4348660\n",
      "\tspeed: 0.1308s/iter; left time: 2110.4257s\n",
      "\titers: 200, epoch: 3 | loss: 0.3467556\n",
      "\tspeed: 0.0459s/iter; left time: 736.0747s\n",
      "\titers: 300, epoch: 3 | loss: 0.3449248\n",
      "\tspeed: 0.0459s/iter; left time: 731.6484s\n",
      "\titers: 400, epoch: 3 | loss: 0.3525844\n",
      "\tspeed: 0.0459s/iter; left time: 727.3909s\n",
      "\titers: 500, epoch: 3 | loss: 0.3267336\n",
      "\tspeed: 0.0459s/iter; left time: 722.7367s\n",
      "\titers: 600, epoch: 3 | loss: 0.3575354\n",
      "\tspeed: 0.0459s/iter; left time: 718.0812s\n",
      "\titers: 700, epoch: 3 | loss: 0.3118579\n",
      "\tspeed: 0.0459s/iter; left time: 713.4389s\n",
      "\titers: 800, epoch: 3 | loss: 0.3681702\n",
      "\tspeed: 0.0460s/iter; left time: 709.7085s\n",
      "\titers: 900, epoch: 3 | loss: 0.3573784\n",
      "\tspeed: 0.0460s/iter; left time: 704.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 902 | Train Loss: 0.3528322 Vali Loss: 0.3532912 Test Loss: 0.3813401\n",
      "Validation loss decreased (0.374341 --> 0.353291).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3417735\n",
      "\tspeed: 0.1317s/iter; left time: 2006.1464s\n",
      "\titers: 200, epoch: 4 | loss: 0.3159100\n",
      "\tspeed: 0.0460s/iter; left time: 696.0940s\n",
      "\titers: 300, epoch: 4 | loss: 0.3165792\n",
      "\tspeed: 0.0459s/iter; left time: 690.8286s\n",
      "\titers: 400, epoch: 4 | loss: 0.3459593\n",
      "\tspeed: 0.0460s/iter; left time: 686.7806s\n",
      "\titers: 500, epoch: 4 | loss: 0.3109958\n",
      "\tspeed: 0.0460s/iter; left time: 682.1137s\n",
      "\titers: 600, epoch: 4 | loss: 0.2787214\n",
      "\tspeed: 0.0460s/iter; left time: 677.2847s\n",
      "\titers: 700, epoch: 4 | loss: 0.2935751\n",
      "\tspeed: 0.0460s/iter; left time: 673.2650s\n",
      "\titers: 800, epoch: 4 | loss: 0.3336336\n",
      "\tspeed: 0.0460s/iter; left time: 668.3545s\n",
      "\titers: 900, epoch: 4 | loss: 0.2844190\n",
      "\tspeed: 0.0460s/iter; left time: 663.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 902 | Train Loss: 0.3145994 Vali Loss: 0.3677874 Test Loss: 0.4210186\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2839892\n",
      "\tspeed: 0.1254s/iter; left time: 1797.6038s\n",
      "\titers: 200, epoch: 5 | loss: 0.2727775\n",
      "\tspeed: 0.0460s/iter; left time: 654.5081s\n",
      "\titers: 300, epoch: 5 | loss: 0.2952268\n",
      "\tspeed: 0.0460s/iter; left time: 649.9031s\n",
      "\titers: 400, epoch: 5 | loss: 0.3162156\n",
      "\tspeed: 0.0460s/iter; left time: 645.5828s\n",
      "\titers: 500, epoch: 5 | loss: 0.2694507\n",
      "\tspeed: 0.0460s/iter; left time: 640.7541s\n",
      "\titers: 600, epoch: 5 | loss: 0.2709764\n",
      "\tspeed: 0.0460s/iter; left time: 636.1252s\n",
      "\titers: 700, epoch: 5 | loss: 0.2563318\n",
      "\tspeed: 0.0460s/iter; left time: 631.3768s\n",
      "\titers: 800, epoch: 5 | loss: 0.2637875\n",
      "\tspeed: 0.0459s/iter; left time: 625.6919s\n",
      "\titers: 900, epoch: 5 | loss: 0.2628876\n",
      "\tspeed: 0.0459s/iter; left time: 621.3065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 902 | Train Loss: 0.2780898 Vali Loss: 0.3827886 Test Loss: 0.4289864\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2936564\n",
      "\tspeed: 0.1256s/iter; left time: 1686.5657s\n",
      "\titers: 200, epoch: 6 | loss: 0.2175375\n",
      "\tspeed: 0.0460s/iter; left time: 612.7038s\n",
      "\titers: 300, epoch: 6 | loss: 0.2566068\n",
      "\tspeed: 0.0459s/iter; left time: 607.3514s\n",
      "\titers: 400, epoch: 6 | loss: 0.2495589\n",
      "\tspeed: 0.0460s/iter; left time: 603.6189s\n",
      "\titers: 500, epoch: 6 | loss: 0.2659388\n",
      "\tspeed: 0.0459s/iter; left time: 598.4815s\n",
      "\titers: 600, epoch: 6 | loss: 0.2379672\n",
      "\tspeed: 0.0459s/iter; left time: 593.6949s\n",
      "\titers: 700, epoch: 6 | loss: 0.2380564\n",
      "\tspeed: 0.0459s/iter; left time: 588.9495s\n",
      "\titers: 800, epoch: 6 | loss: 0.2162333\n",
      "\tspeed: 0.0459s/iter; left time: 584.5651s\n",
      "\titers: 900, epoch: 6 | loss: 0.1989905\n",
      "\tspeed: 0.0459s/iter; left time: 580.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.69s\n",
      "Steps: 902 | Train Loss: 0.2424242 Vali Loss: 0.4012789 Test Loss: 0.4505979\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3812984824180603, rmse:0.6174936890602112, mae:0.42579272389411926, rse:0.5655485987663269\n",
      "Original data scale mse:3976689.75, rmse:1994.1639404296875, mae:1357.449951171875, rse:0.1404692530632019\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8982518\n",
      "\tspeed: 0.0481s/iter; left time: 867.4449s\n",
      "\titers: 200, epoch: 1 | loss: 0.8458576\n",
      "\tspeed: 0.0297s/iter; left time: 532.9588s\n",
      "\titers: 300, epoch: 1 | loss: 0.8074365\n",
      "\tspeed: 0.0298s/iter; left time: 530.2900s\n",
      "\titers: 400, epoch: 1 | loss: 0.8315028\n",
      "\tspeed: 0.0297s/iter; left time: 526.4179s\n",
      "\titers: 500, epoch: 1 | loss: 0.7915738\n",
      "\tspeed: 0.0297s/iter; left time: 523.2911s\n",
      "\titers: 600, epoch: 1 | loss: 0.7709562\n",
      "\tspeed: 0.0297s/iter; left time: 520.5343s\n",
      "\titers: 700, epoch: 1 | loss: 0.7027000\n",
      "\tspeed: 0.0297s/iter; left time: 517.4899s\n",
      "\titers: 800, epoch: 1 | loss: 0.7458278\n",
      "\tspeed: 0.0297s/iter; left time: 514.2975s\n",
      "\titers: 900, epoch: 1 | loss: 0.7395509\n",
      "\tspeed: 0.0297s/iter; left time: 511.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.57s\n",
      "Steps: 906 | Train Loss: 0.8002553 Vali Loss: 0.7254151 Test Loss: 0.7859074\n",
      "Validation loss decreased (inf --> 0.725415).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6148894\n",
      "\tspeed: 0.0841s/iter; left time: 1438.8980s\n",
      "\titers: 200, epoch: 2 | loss: 0.4927519\n",
      "\tspeed: 0.0297s/iter; left time: 506.0349s\n",
      "\titers: 300, epoch: 2 | loss: 0.4147166\n",
      "\tspeed: 0.0297s/iter; left time: 502.4199s\n",
      "\titers: 400, epoch: 2 | loss: 0.3876883\n",
      "\tspeed: 0.0297s/iter; left time: 499.4253s\n",
      "\titers: 500, epoch: 2 | loss: 0.4275194\n",
      "\tspeed: 0.0297s/iter; left time: 496.5132s\n",
      "\titers: 600, epoch: 2 | loss: 0.3958344\n",
      "\tspeed: 0.0297s/iter; left time: 493.6855s\n",
      "\titers: 700, epoch: 2 | loss: 0.3779832\n",
      "\tspeed: 0.0297s/iter; left time: 490.2781s\n",
      "\titers: 800, epoch: 2 | loss: 0.3738647\n",
      "\tspeed: 0.0297s/iter; left time: 487.3906s\n",
      "\titers: 900, epoch: 2 | loss: 0.3732349\n",
      "\tspeed: 0.0297s/iter; left time: 484.4823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.4314672 Vali Loss: 0.3343946 Test Loss: 0.3576734\n",
      "Validation loss decreased (0.725415 --> 0.334395).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3488475\n",
      "\tspeed: 0.0848s/iter; left time: 1373.9056s\n",
      "\titers: 200, epoch: 3 | loss: 0.3256014\n",
      "\tspeed: 0.0297s/iter; left time: 479.2160s\n",
      "\titers: 300, epoch: 3 | loss: 0.3474699\n",
      "\tspeed: 0.0298s/iter; left time: 476.2749s\n",
      "\titers: 400, epoch: 3 | loss: 0.3086111\n",
      "\tspeed: 0.0298s/iter; left time: 473.4016s\n",
      "\titers: 500, epoch: 3 | loss: 0.3724214\n",
      "\tspeed: 0.0297s/iter; left time: 470.1714s\n",
      "\titers: 600, epoch: 3 | loss: 0.3401731\n",
      "\tspeed: 0.0297s/iter; left time: 467.2649s\n",
      "\titers: 700, epoch: 3 | loss: 0.2903460\n",
      "\tspeed: 0.0297s/iter; left time: 464.2514s\n",
      "\titers: 800, epoch: 3 | loss: 0.3162773\n",
      "\tspeed: 0.0297s/iter; left time: 461.1949s\n",
      "\titers: 900, epoch: 3 | loss: 0.2989454\n",
      "\tspeed: 0.0298s/iter; left time: 458.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 906 | Train Loss: 0.3265869 Vali Loss: 0.3017584 Test Loss: 0.3241872\n",
      "Validation loss decreased (0.334395 --> 0.301758).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2934006\n",
      "\tspeed: 0.0874s/iter; left time: 1336.7751s\n",
      "\titers: 200, epoch: 4 | loss: 0.2847592\n",
      "\tspeed: 0.0297s/iter; left time: 451.4091s\n",
      "\titers: 300, epoch: 4 | loss: 0.2830035\n",
      "\tspeed: 0.0297s/iter; left time: 448.6787s\n",
      "\titers: 400, epoch: 4 | loss: 0.3007552\n",
      "\tspeed: 0.0297s/iter; left time: 445.7759s\n",
      "\titers: 500, epoch: 4 | loss: 0.2848407\n",
      "\tspeed: 0.0298s/iter; left time: 443.6352s\n",
      "\titers: 600, epoch: 4 | loss: 0.3638254\n",
      "\tspeed: 0.0297s/iter; left time: 439.9402s\n",
      "\titers: 700, epoch: 4 | loss: 0.3218064\n",
      "\tspeed: 0.0297s/iter; left time: 436.7098s\n",
      "\titers: 800, epoch: 4 | loss: 0.3125134\n",
      "\tspeed: 0.0297s/iter; left time: 434.1397s\n",
      "\titers: 900, epoch: 4 | loss: 0.3308379\n",
      "\tspeed: 0.0297s/iter; left time: 431.0257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.3002852 Vali Loss: 0.2842374 Test Loss: 0.3071113\n",
      "Validation loss decreased (0.301758 --> 0.284237).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2778125\n",
      "\tspeed: 0.0836s/iter; left time: 1203.5683s\n",
      "\titers: 200, epoch: 5 | loss: 0.2598670\n",
      "\tspeed: 0.0297s/iter; left time: 424.9238s\n",
      "\titers: 300, epoch: 5 | loss: 0.2578112\n",
      "\tspeed: 0.0297s/iter; left time: 421.8773s\n",
      "\titers: 400, epoch: 5 | loss: 0.2655600\n",
      "\tspeed: 0.0297s/iter; left time: 418.2920s\n",
      "\titers: 500, epoch: 5 | loss: 0.2985246\n",
      "\tspeed: 0.0297s/iter; left time: 415.2158s\n",
      "\titers: 600, epoch: 5 | loss: 0.2696084\n",
      "\tspeed: 0.0297s/iter; left time: 412.0989s\n",
      "\titers: 700, epoch: 5 | loss: 0.3071485\n",
      "\tspeed: 0.0297s/iter; left time: 409.1783s\n",
      "\titers: 800, epoch: 5 | loss: 0.2650835\n",
      "\tspeed: 0.0297s/iter; left time: 406.2400s\n",
      "\titers: 900, epoch: 5 | loss: 0.3005427\n",
      "\tspeed: 0.0297s/iter; left time: 403.3584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2854086 Vali Loss: 0.2762106 Test Loss: 0.2984711\n",
      "Validation loss decreased (0.284237 --> 0.276211).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2698609\n",
      "\tspeed: 0.0835s/iter; left time: 1126.8387s\n",
      "\titers: 200, epoch: 6 | loss: 0.2821735\n",
      "\tspeed: 0.0297s/iter; left time: 397.6747s\n",
      "\titers: 300, epoch: 6 | loss: 0.3199257\n",
      "\tspeed: 0.0297s/iter; left time: 394.6988s\n",
      "\titers: 400, epoch: 6 | loss: 0.3014683\n",
      "\tspeed: 0.0298s/iter; left time: 393.2111s\n",
      "\titers: 500, epoch: 6 | loss: 0.2745761\n",
      "\tspeed: 0.0297s/iter; left time: 388.4676s\n",
      "\titers: 600, epoch: 6 | loss: 0.3011068\n",
      "\tspeed: 0.0297s/iter; left time: 385.7197s\n",
      "\titers: 700, epoch: 6 | loss: 0.3174651\n",
      "\tspeed: 0.0297s/iter; left time: 382.7527s\n",
      "\titers: 800, epoch: 6 | loss: 0.2696464\n",
      "\tspeed: 0.0297s/iter; left time: 379.3997s\n",
      "\titers: 900, epoch: 6 | loss: 0.2929690\n",
      "\tspeed: 0.0297s/iter; left time: 376.9704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2763475 Vali Loss: 0.2698329 Test Loss: 0.2898619\n",
      "Validation loss decreased (0.276211 --> 0.269833).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2727868\n",
      "\tspeed: 0.0896s/iter; left time: 1127.4983s\n",
      "\titers: 200, epoch: 7 | loss: 0.2350268\n",
      "\tspeed: 0.0297s/iter; left time: 371.0242s\n",
      "\titers: 300, epoch: 7 | loss: 0.2592110\n",
      "\tspeed: 0.0297s/iter; left time: 368.0230s\n",
      "\titers: 400, epoch: 7 | loss: 0.2567597\n",
      "\tspeed: 0.0297s/iter; left time: 365.0991s\n",
      "\titers: 500, epoch: 7 | loss: 0.2733704\n",
      "\tspeed: 0.0297s/iter; left time: 362.1358s\n",
      "\titers: 600, epoch: 7 | loss: 0.2359796\n",
      "\tspeed: 0.0298s/iter; left time: 359.5599s\n",
      "\titers: 700, epoch: 7 | loss: 0.2640343\n",
      "\tspeed: 0.0297s/iter; left time: 356.1277s\n",
      "\titers: 800, epoch: 7 | loss: 0.3033043\n",
      "\tspeed: 0.0297s/iter; left time: 353.3048s\n",
      "\titers: 900, epoch: 7 | loss: 0.2588506\n",
      "\tspeed: 0.0297s/iter; left time: 350.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 906 | Train Loss: 0.2694365 Vali Loss: 0.2679622 Test Loss: 0.2863183\n",
      "Validation loss decreased (0.269833 --> 0.267962).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2531316\n",
      "\tspeed: 0.0855s/iter; left time: 999.0332s\n",
      "\titers: 200, epoch: 8 | loss: 0.2331702\n",
      "\tspeed: 0.0298s/iter; left time: 345.5013s\n",
      "\titers: 300, epoch: 8 | loss: 0.2810597\n",
      "\tspeed: 0.0297s/iter; left time: 340.7911s\n",
      "\titers: 400, epoch: 8 | loss: 0.2593723\n",
      "\tspeed: 0.0297s/iter; left time: 337.8376s\n",
      "\titers: 500, epoch: 8 | loss: 0.2738975\n",
      "\tspeed: 0.0298s/iter; left time: 336.2042s\n",
      "\titers: 600, epoch: 8 | loss: 0.2735357\n",
      "\tspeed: 0.0297s/iter; left time: 331.8914s\n",
      "\titers: 700, epoch: 8 | loss: 0.2414902\n",
      "\tspeed: 0.0297s/iter; left time: 329.2963s\n",
      "\titers: 800, epoch: 8 | loss: 0.2622409\n",
      "\tspeed: 0.0298s/iter; left time: 326.6831s\n",
      "\titers: 900, epoch: 8 | loss: 0.2747293\n",
      "\tspeed: 0.0298s/iter; left time: 323.8279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.2640604 Vali Loss: 0.2653358 Test Loss: 0.2851748\n",
      "Validation loss decreased (0.267962 --> 0.265336).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2595016\n",
      "\tspeed: 0.0845s/iter; left time: 909.8972s\n",
      "\titers: 200, epoch: 9 | loss: 0.2779095\n",
      "\tspeed: 0.0297s/iter; left time: 317.4450s\n",
      "\titers: 300, epoch: 9 | loss: 0.2664872\n",
      "\tspeed: 0.0297s/iter; left time: 314.3498s\n",
      "\titers: 400, epoch: 9 | loss: 0.2874963\n",
      "\tspeed: 0.0297s/iter; left time: 311.4365s\n",
      "\titers: 500, epoch: 9 | loss: 0.2765655\n",
      "\tspeed: 0.0298s/iter; left time: 308.6198s\n",
      "\titers: 600, epoch: 9 | loss: 0.2846298\n",
      "\tspeed: 0.0297s/iter; left time: 305.2169s\n",
      "\titers: 700, epoch: 9 | loss: 0.2560660\n",
      "\tspeed: 0.0297s/iter; left time: 302.3223s\n",
      "\titers: 800, epoch: 9 | loss: 0.2671131\n",
      "\tspeed: 0.0297s/iter; left time: 299.2118s\n",
      "\titers: 900, epoch: 9 | loss: 0.2638635\n",
      "\tspeed: 0.0297s/iter; left time: 296.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 906 | Train Loss: 0.2599821 Vali Loss: 0.2610800 Test Loss: 0.2821350\n",
      "Validation loss decreased (0.265336 --> 0.261080).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2800991\n",
      "\tspeed: 0.0890s/iter; left time: 878.3295s\n",
      "\titers: 200, epoch: 10 | loss: 0.2533764\n",
      "\tspeed: 0.0297s/iter; left time: 290.1227s\n",
      "\titers: 300, epoch: 10 | loss: 0.2552003\n",
      "\tspeed: 0.0297s/iter; left time: 286.9439s\n",
      "\titers: 400, epoch: 10 | loss: 0.2396801\n",
      "\tspeed: 0.0297s/iter; left time: 283.9378s\n",
      "\titers: 500, epoch: 10 | loss: 0.2476129\n",
      "\tspeed: 0.0297s/iter; left time: 280.9742s\n",
      "\titers: 600, epoch: 10 | loss: 0.2463096\n",
      "\tspeed: 0.0297s/iter; left time: 278.2766s\n",
      "\titers: 700, epoch: 10 | loss: 0.2813039\n",
      "\tspeed: 0.0297s/iter; left time: 275.0762s\n",
      "\titers: 800, epoch: 10 | loss: 0.2465423\n",
      "\tspeed: 0.0297s/iter; left time: 272.0061s\n",
      "\titers: 900, epoch: 10 | loss: 0.2718271\n",
      "\tspeed: 0.0297s/iter; left time: 269.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 906 | Train Loss: 0.2567788 Vali Loss: 0.2563201 Test Loss: 0.2764029\n",
      "Validation loss decreased (0.261080 --> 0.256320).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2349428\n",
      "\tspeed: 0.0837s/iter; left time: 749.6510s\n",
      "\titers: 200, epoch: 11 | loss: 0.2101355\n",
      "\tspeed: 0.0297s/iter; left time: 263.0291s\n",
      "\titers: 300, epoch: 11 | loss: 0.2650644\n",
      "\tspeed: 0.0297s/iter; left time: 260.1611s\n",
      "\titers: 400, epoch: 11 | loss: 0.2470534\n",
      "\tspeed: 0.0297s/iter; left time: 257.2599s\n",
      "\titers: 500, epoch: 11 | loss: 0.2220689\n",
      "\tspeed: 0.0297s/iter; left time: 254.0692s\n",
      "\titers: 600, epoch: 11 | loss: 0.2561055\n",
      "\tspeed: 0.0298s/iter; left time: 252.0712s\n",
      "\titers: 700, epoch: 11 | loss: 0.2374993\n",
      "\tspeed: 0.0297s/iter; left time: 248.0921s\n",
      "\titers: 800, epoch: 11 | loss: 0.2698430\n",
      "\tspeed: 0.0297s/iter; left time: 245.0836s\n",
      "\titers: 900, epoch: 11 | loss: 0.2755079\n",
      "\tspeed: 0.0297s/iter; left time: 242.2851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2536946 Vali Loss: 0.2556883 Test Loss: 0.2753615\n",
      "Validation loss decreased (0.256320 --> 0.255688).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2882319\n",
      "\tspeed: 0.0855s/iter; left time: 689.0102s\n",
      "\titers: 200, epoch: 12 | loss: 0.2682012\n",
      "\tspeed: 0.0298s/iter; left time: 237.0759s\n",
      "\titers: 300, epoch: 12 | loss: 0.2818410\n",
      "\tspeed: 0.0297s/iter; left time: 233.5231s\n",
      "\titers: 400, epoch: 12 | loss: 0.2349325\n",
      "\tspeed: 0.0297s/iter; left time: 230.5776s\n",
      "\titers: 500, epoch: 12 | loss: 0.2266099\n",
      "\tspeed: 0.0297s/iter; left time: 227.4607s\n",
      "\titers: 600, epoch: 12 | loss: 0.2481263\n",
      "\tspeed: 0.0297s/iter; left time: 224.7088s\n",
      "\titers: 700, epoch: 12 | loss: 0.2797031\n",
      "\tspeed: 0.0297s/iter; left time: 221.5651s\n",
      "\titers: 800, epoch: 12 | loss: 0.2338008\n",
      "\tspeed: 0.0297s/iter; left time: 218.6188s\n",
      "\titers: 900, epoch: 12 | loss: 0.2118474\n",
      "\tspeed: 0.0297s/iter; left time: 215.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.2514646 Vali Loss: 0.2569689 Test Loss: 0.2758863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2733481\n",
      "\tspeed: 0.0810s/iter; left time: 579.1838s\n",
      "\titers: 200, epoch: 13 | loss: 0.2261509\n",
      "\tspeed: 0.0297s/iter; left time: 209.1092s\n",
      "\titers: 300, epoch: 13 | loss: 0.2664162\n",
      "\tspeed: 0.0296s/iter; left time: 206.0195s\n",
      "\titers: 400, epoch: 13 | loss: 0.2684229\n",
      "\tspeed: 0.0297s/iter; left time: 203.3725s\n",
      "\titers: 500, epoch: 13 | loss: 0.2347163\n",
      "\tspeed: 0.0297s/iter; left time: 200.1210s\n",
      "\titers: 600, epoch: 13 | loss: 0.2607549\n",
      "\tspeed: 0.0297s/iter; left time: 197.3067s\n",
      "\titers: 700, epoch: 13 | loss: 0.2645776\n",
      "\tspeed: 0.0297s/iter; left time: 194.2120s\n",
      "\titers: 800, epoch: 13 | loss: 0.2235833\n",
      "\tspeed: 0.0297s/iter; left time: 191.2300s\n",
      "\titers: 900, epoch: 13 | loss: 0.2673401\n",
      "\tspeed: 0.0297s/iter; left time: 188.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.13s\n",
      "Steps: 906 | Train Loss: 0.2495886 Vali Loss: 0.2539084 Test Loss: 0.2739456\n",
      "Validation loss decreased (0.255688 --> 0.253908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2711326\n",
      "\tspeed: 0.0850s/iter; left time: 530.5404s\n",
      "\titers: 200, epoch: 14 | loss: 0.2620098\n",
      "\tspeed: 0.0297s/iter; left time: 182.5565s\n",
      "\titers: 300, epoch: 14 | loss: 0.2505479\n",
      "\tspeed: 0.0298s/iter; left time: 180.0664s\n",
      "\titers: 400, epoch: 14 | loss: 0.2493832\n",
      "\tspeed: 0.0298s/iter; left time: 176.9898s\n",
      "\titers: 500, epoch: 14 | loss: 0.2596759\n",
      "\tspeed: 0.0298s/iter; left time: 173.9443s\n",
      "\titers: 600, epoch: 14 | loss: 0.2682787\n",
      "\tspeed: 0.0298s/iter; left time: 170.8650s\n",
      "\titers: 700, epoch: 14 | loss: 0.2262208\n",
      "\tspeed: 0.0297s/iter; left time: 167.7721s\n",
      "\titers: 800, epoch: 14 | loss: 0.2294442\n",
      "\tspeed: 0.0297s/iter; left time: 164.7715s\n",
      "\titers: 900, epoch: 14 | loss: 0.2381168\n",
      "\tspeed: 0.0297s/iter; left time: 161.8526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.29s\n",
      "Steps: 906 | Train Loss: 0.2475619 Vali Loss: 0.2536014 Test Loss: 0.2733522\n",
      "Validation loss decreased (0.253908 --> 0.253601).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2370972\n",
      "\tspeed: 0.0943s/iter; left time: 503.2433s\n",
      "\titers: 200, epoch: 15 | loss: 0.2218398\n",
      "\tspeed: 0.0297s/iter; left time: 155.5923s\n",
      "\titers: 300, epoch: 15 | loss: 0.2296391\n",
      "\tspeed: 0.0297s/iter; left time: 152.6052s\n",
      "\titers: 400, epoch: 15 | loss: 0.2450830\n",
      "\tspeed: 0.0297s/iter; left time: 149.7055s\n",
      "\titers: 500, epoch: 15 | loss: 0.2539105\n",
      "\tspeed: 0.0297s/iter; left time: 146.6762s\n",
      "\titers: 600, epoch: 15 | loss: 0.2359191\n",
      "\tspeed: 0.0297s/iter; left time: 143.7300s\n",
      "\titers: 700, epoch: 15 | loss: 0.2427872\n",
      "\tspeed: 0.0297s/iter; left time: 140.7293s\n",
      "\titers: 800, epoch: 15 | loss: 0.2720754\n",
      "\tspeed: 0.0297s/iter; left time: 137.7881s\n",
      "\titers: 900, epoch: 15 | loss: 0.2266614\n",
      "\tspeed: 0.0297s/iter; left time: 134.8216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 906 | Train Loss: 0.2461112 Vali Loss: 0.2515949 Test Loss: 0.2726883\n",
      "Validation loss decreased (0.253601 --> 0.251595).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2497180\n",
      "\tspeed: 0.0844s/iter; left time: 373.8421s\n",
      "\titers: 200, epoch: 16 | loss: 0.2179761\n",
      "\tspeed: 0.0297s/iter; left time: 128.4918s\n",
      "\titers: 300, epoch: 16 | loss: 0.2537304\n",
      "\tspeed: 0.0297s/iter; left time: 125.5295s\n",
      "\titers: 400, epoch: 16 | loss: 0.2146583\n",
      "\tspeed: 0.0297s/iter; left time: 122.5427s\n",
      "\titers: 500, epoch: 16 | loss: 0.2429717\n",
      "\tspeed: 0.0297s/iter; left time: 119.5926s\n",
      "\titers: 600, epoch: 16 | loss: 0.2603196\n",
      "\tspeed: 0.0297s/iter; left time: 116.6146s\n",
      "\titers: 700, epoch: 16 | loss: 0.2139096\n",
      "\tspeed: 0.0297s/iter; left time: 113.6635s\n",
      "\titers: 800, epoch: 16 | loss: 0.2822977\n",
      "\tspeed: 0.0297s/iter; left time: 110.6746s\n",
      "\titers: 900, epoch: 16 | loss: 0.2415431\n",
      "\tspeed: 0.0297s/iter; left time: 107.7848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 906 | Train Loss: 0.2447823 Vali Loss: 0.2506451 Test Loss: 0.2708200\n",
      "Validation loss decreased (0.251595 --> 0.250645).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2776798\n",
      "\tspeed: 0.0836s/iter; left time: 294.6541s\n",
      "\titers: 200, epoch: 17 | loss: 0.2585074\n",
      "\tspeed: 0.0297s/iter; left time: 101.7487s\n",
      "\titers: 300, epoch: 17 | loss: 0.2394258\n",
      "\tspeed: 0.0298s/iter; left time: 98.9250s\n",
      "\titers: 400, epoch: 17 | loss: 0.2552698\n",
      "\tspeed: 0.0298s/iter; left time: 96.0708s\n",
      "\titers: 500, epoch: 17 | loss: 0.2025661\n",
      "\tspeed: 0.0298s/iter; left time: 93.1585s\n",
      "\titers: 600, epoch: 17 | loss: 0.2419886\n",
      "\tspeed: 0.0298s/iter; left time: 90.0811s\n",
      "\titers: 700, epoch: 17 | loss: 0.2193597\n",
      "\tspeed: 0.0297s/iter; left time: 87.0132s\n",
      "\titers: 800, epoch: 17 | loss: 0.2553150\n",
      "\tspeed: 0.0298s/iter; left time: 84.2773s\n",
      "\titers: 900, epoch: 17 | loss: 0.2422516\n",
      "\tspeed: 0.0298s/iter; left time: 81.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.2437425 Vali Loss: 0.2494281 Test Loss: 0.2729142\n",
      "Validation loss decreased (0.250645 --> 0.249428).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2305934\n",
      "\tspeed: 0.0913s/iter; left time: 238.9989s\n",
      "\titers: 200, epoch: 18 | loss: 0.3099913\n",
      "\tspeed: 0.0297s/iter; left time: 74.8895s\n",
      "\titers: 300, epoch: 18 | loss: 0.2491073\n",
      "\tspeed: 0.0297s/iter; left time: 71.7583s\n",
      "\titers: 400, epoch: 18 | loss: 0.2230721\n",
      "\tspeed: 0.0296s/iter; left time: 68.7421s\n",
      "\titers: 500, epoch: 18 | loss: 0.2287904\n",
      "\tspeed: 0.0296s/iter; left time: 65.7752s\n",
      "\titers: 600, epoch: 18 | loss: 0.2555149\n",
      "\tspeed: 0.0296s/iter; left time: 62.7942s\n",
      "\titers: 700, epoch: 18 | loss: 0.2349044\n",
      "\tspeed: 0.0296s/iter; left time: 59.8325s\n",
      "\titers: 800, epoch: 18 | loss: 0.2563432\n",
      "\tspeed: 0.0297s/iter; left time: 56.9289s\n",
      "\titers: 900, epoch: 18 | loss: 0.2518946\n",
      "\tspeed: 0.0297s/iter; left time: 54.0497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.15s\n",
      "Steps: 906 | Train Loss: 0.2425837 Vali Loss: 0.2502056 Test Loss: 0.2719750\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2546939\n",
      "\tspeed: 0.0816s/iter; left time: 139.8302s\n",
      "\titers: 200, epoch: 19 | loss: 0.2464008\n",
      "\tspeed: 0.0297s/iter; left time: 47.8488s\n",
      "\titers: 300, epoch: 19 | loss: 0.2259780\n",
      "\tspeed: 0.0297s/iter; left time: 44.9106s\n",
      "\titers: 400, epoch: 19 | loss: 0.2565815\n",
      "\tspeed: 0.0297s/iter; left time: 41.9182s\n",
      "\titers: 500, epoch: 19 | loss: 0.2522539\n",
      "\tspeed: 0.0297s/iter; left time: 38.9499s\n",
      "\titers: 600, epoch: 19 | loss: 0.2340999\n",
      "\tspeed: 0.0297s/iter; left time: 35.9794s\n",
      "\titers: 700, epoch: 19 | loss: 0.2489940\n",
      "\tspeed: 0.0297s/iter; left time: 33.0274s\n",
      "\titers: 800, epoch: 19 | loss: 0.2335016\n",
      "\tspeed: 0.0297s/iter; left time: 30.0633s\n",
      "\titers: 900, epoch: 19 | loss: 0.2551128\n",
      "\tspeed: 0.0297s/iter; left time: 27.1611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 906 | Train Loss: 0.2415383 Vali Loss: 0.2505901 Test Loss: 0.2700067\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2540413\n",
      "\tspeed: 0.0815s/iter; left time: 65.7976s\n",
      "\titers: 200, epoch: 20 | loss: 0.2746835\n",
      "\tspeed: 0.0298s/iter; left time: 21.0381s\n",
      "\titers: 300, epoch: 20 | loss: 0.2585455\n",
      "\tspeed: 0.0297s/iter; left time: 18.0570s\n",
      "\titers: 400, epoch: 20 | loss: 0.2225086\n",
      "\tspeed: 0.0297s/iter; left time: 15.0756s\n",
      "\titers: 500, epoch: 20 | loss: 0.2870366\n",
      "\tspeed: 0.0297s/iter; left time: 12.1002s\n",
      "\titers: 600, epoch: 20 | loss: 0.2433546\n",
      "\tspeed: 0.0297s/iter; left time: 9.1215s\n",
      "\titers: 700, epoch: 20 | loss: 0.2240592\n",
      "\tspeed: 0.0297s/iter; left time: 6.1506s\n",
      "\titers: 800, epoch: 20 | loss: 0.2773416\n",
      "\tspeed: 0.0297s/iter; left time: 3.1804s\n",
      "\titers: 900, epoch: 20 | loss: 0.2103368\n",
      "\tspeed: 0.0297s/iter; left time: 0.2080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 906 | Train Loss: 0.2407939 Vali Loss: 0.2490563 Test Loss: 0.2700902\n",
      "Validation loss decreased (0.249428 --> 0.249056).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2122817486524582, rmse:0.46074044704437256, mae:0.2702677845954895, rse:0.4219633936882019\n",
      "Original data scale mse:1440519.5, rmse:1200.2164306640625, mae:759.9635620117188, rse:0.08434204012155533\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9303597\n",
      "\tspeed: 0.0326s/iter; left time: 586.9792s\n",
      "\titers: 200, epoch: 1 | loss: 0.8192927\n",
      "\tspeed: 0.0297s/iter; left time: 532.6112s\n",
      "\titers: 300, epoch: 1 | loss: 0.8756372\n",
      "\tspeed: 0.0297s/iter; left time: 529.2985s\n",
      "\titers: 400, epoch: 1 | loss: 0.7628884\n",
      "\tspeed: 0.0297s/iter; left time: 526.6783s\n",
      "\titers: 500, epoch: 1 | loss: 0.7693668\n",
      "\tspeed: 0.0298s/iter; left time: 524.7210s\n",
      "\titers: 600, epoch: 1 | loss: 0.7992023\n",
      "\tspeed: 0.0298s/iter; left time: 521.4579s\n",
      "\titers: 700, epoch: 1 | loss: 0.7673064\n",
      "\tspeed: 0.0297s/iter; left time: 517.8952s\n",
      "\titers: 800, epoch: 1 | loss: 0.7632505\n",
      "\tspeed: 0.0297s/iter; left time: 515.0162s\n",
      "\titers: 900, epoch: 1 | loss: 0.7252381\n",
      "\tspeed: 0.0297s/iter; left time: 512.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.8191658 Vali Loss: 0.7367652 Test Loss: 0.8015324\n",
      "Validation loss decreased (inf --> 0.736765).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5939575\n",
      "\tspeed: 0.0930s/iter; left time: 1591.0904s\n",
      "\titers: 200, epoch: 2 | loss: 0.4519100\n",
      "\tspeed: 0.0296s/iter; left time: 504.4735s\n",
      "\titers: 300, epoch: 2 | loss: 0.4430814\n",
      "\tspeed: 0.0297s/iter; left time: 501.5422s\n",
      "\titers: 400, epoch: 2 | loss: 0.4072329\n",
      "\tspeed: 0.0297s/iter; left time: 498.7854s\n",
      "\titers: 500, epoch: 2 | loss: 0.3674377\n",
      "\tspeed: 0.0296s/iter; left time: 495.5015s\n",
      "\titers: 600, epoch: 2 | loss: 0.3417858\n",
      "\tspeed: 0.0296s/iter; left time: 492.4725s\n",
      "\titers: 700, epoch: 2 | loss: 0.3673163\n",
      "\tspeed: 0.0296s/iter; left time: 489.1801s\n",
      "\titers: 800, epoch: 2 | loss: 0.3352906\n",
      "\tspeed: 0.0296s/iter; left time: 486.2918s\n",
      "\titers: 900, epoch: 2 | loss: 0.3289691\n",
      "\tspeed: 0.0296s/iter; left time: 483.6157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 906 | Train Loss: 0.4283856 Vali Loss: 0.3295324 Test Loss: 0.3497426\n",
      "Validation loss decreased (0.736765 --> 0.329532).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3273184\n",
      "\tspeed: 0.0872s/iter; left time: 1413.4415s\n",
      "\titers: 200, epoch: 3 | loss: 0.3205146\n",
      "\tspeed: 0.0297s/iter; left time: 478.4437s\n",
      "\titers: 300, epoch: 3 | loss: 0.3572803\n",
      "\tspeed: 0.0297s/iter; left time: 475.2252s\n",
      "\titers: 400, epoch: 3 | loss: 0.3491791\n",
      "\tspeed: 0.0297s/iter; left time: 472.2608s\n",
      "\titers: 500, epoch: 3 | loss: 0.3285128\n",
      "\tspeed: 0.0297s/iter; left time: 469.4995s\n",
      "\titers: 600, epoch: 3 | loss: 0.3490100\n",
      "\tspeed: 0.0297s/iter; left time: 466.1848s\n",
      "\titers: 700, epoch: 3 | loss: 0.3510199\n",
      "\tspeed: 0.0297s/iter; left time: 463.2814s\n",
      "\titers: 800, epoch: 3 | loss: 0.3305733\n",
      "\tspeed: 0.0297s/iter; left time: 460.2696s\n",
      "\titers: 900, epoch: 3 | loss: 0.3242746\n",
      "\tspeed: 0.0297s/iter; left time: 457.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 906 | Train Loss: 0.3215313 Vali Loss: 0.3007587 Test Loss: 0.3236365\n",
      "Validation loss decreased (0.329532 --> 0.300759).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2934029\n",
      "\tspeed: 0.0855s/iter; left time: 1308.2738s\n",
      "\titers: 200, epoch: 4 | loss: 0.3443906\n",
      "\tspeed: 0.0298s/iter; left time: 452.6202s\n",
      "\titers: 300, epoch: 4 | loss: 0.3247115\n",
      "\tspeed: 0.0297s/iter; left time: 448.7962s\n",
      "\titers: 400, epoch: 4 | loss: 0.3113715\n",
      "\tspeed: 0.0297s/iter; left time: 446.2804s\n",
      "\titers: 500, epoch: 4 | loss: 0.2876775\n",
      "\tspeed: 0.0297s/iter; left time: 443.0331s\n",
      "\titers: 600, epoch: 4 | loss: 0.2765463\n",
      "\tspeed: 0.0297s/iter; left time: 439.9927s\n",
      "\titers: 700, epoch: 4 | loss: 0.2743662\n",
      "\tspeed: 0.0297s/iter; left time: 436.7594s\n",
      "\titers: 800, epoch: 4 | loss: 0.2984843\n",
      "\tspeed: 0.0299s/iter; left time: 436.2664s\n",
      "\titers: 900, epoch: 4 | loss: 0.2925319\n",
      "\tspeed: 0.0297s/iter; left time: 430.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.28s\n",
      "Steps: 906 | Train Loss: 0.2977832 Vali Loss: 0.2814059 Test Loss: 0.3024971\n",
      "Validation loss decreased (0.300759 --> 0.281406).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2975923\n",
      "\tspeed: 0.0870s/iter; left time: 1252.4389s\n",
      "\titers: 200, epoch: 5 | loss: 0.2624957\n",
      "\tspeed: 0.0297s/iter; left time: 424.6663s\n",
      "\titers: 300, epoch: 5 | loss: 0.2594224\n",
      "\tspeed: 0.0297s/iter; left time: 422.0511s\n",
      "\titers: 400, epoch: 5 | loss: 0.3374806\n",
      "\tspeed: 0.0297s/iter; left time: 418.7985s\n",
      "\titers: 500, epoch: 5 | loss: 0.2633976\n",
      "\tspeed: 0.0297s/iter; left time: 415.9577s\n",
      "\titers: 600, epoch: 5 | loss: 0.2445966\n",
      "\tspeed: 0.0297s/iter; left time: 413.0095s\n",
      "\titers: 700, epoch: 5 | loss: 0.2778179\n",
      "\tspeed: 0.0297s/iter; left time: 410.1356s\n",
      "\titers: 800, epoch: 5 | loss: 0.2677927\n",
      "\tspeed: 0.0297s/iter; left time: 406.6834s\n",
      "\titers: 900, epoch: 5 | loss: 0.3016306\n",
      "\tspeed: 0.0297s/iter; left time: 403.7709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.2837949 Vali Loss: 0.2746767 Test Loss: 0.2949765\n",
      "Validation loss decreased (0.281406 --> 0.274677).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2517997\n",
      "\tspeed: 0.0851s/iter; left time: 1148.3904s\n",
      "\titers: 200, epoch: 6 | loss: 0.3100924\n",
      "\tspeed: 0.0297s/iter; left time: 397.5403s\n",
      "\titers: 300, epoch: 6 | loss: 0.2727546\n",
      "\tspeed: 0.0297s/iter; left time: 394.7224s\n",
      "\titers: 400, epoch: 6 | loss: 0.2320868\n",
      "\tspeed: 0.0298s/iter; left time: 392.5534s\n",
      "\titers: 500, epoch: 6 | loss: 0.2645080\n",
      "\tspeed: 0.0297s/iter; left time: 389.3964s\n",
      "\titers: 600, epoch: 6 | loss: 0.2786039\n",
      "\tspeed: 0.0298s/iter; left time: 386.6330s\n",
      "\titers: 700, epoch: 6 | loss: 0.2487097\n",
      "\tspeed: 0.0297s/iter; left time: 383.2807s\n",
      "\titers: 800, epoch: 6 | loss: 0.2429876\n",
      "\tspeed: 0.0298s/iter; left time: 381.1682s\n",
      "\titers: 900, epoch: 6 | loss: 0.2557825\n",
      "\tspeed: 0.0298s/iter; left time: 378.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.2744221 Vali Loss: 0.2668014 Test Loss: 0.2890441\n",
      "Validation loss decreased (0.274677 --> 0.266801).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2778957\n",
      "\tspeed: 0.0853s/iter; left time: 1072.9598s\n",
      "\titers: 200, epoch: 7 | loss: 0.2636458\n",
      "\tspeed: 0.0297s/iter; left time: 371.3007s\n",
      "\titers: 300, epoch: 7 | loss: 0.2854033\n",
      "\tspeed: 0.0297s/iter; left time: 368.2265s\n",
      "\titers: 400, epoch: 7 | loss: 0.2845186\n",
      "\tspeed: 0.0297s/iter; left time: 365.3568s\n",
      "\titers: 500, epoch: 7 | loss: 0.2655800\n",
      "\tspeed: 0.0297s/iter; left time: 362.4132s\n",
      "\titers: 600, epoch: 7 | loss: 0.2446871\n",
      "\tspeed: 0.0297s/iter; left time: 359.2617s\n",
      "\titers: 700, epoch: 7 | loss: 0.3329983\n",
      "\tspeed: 0.0297s/iter; left time: 356.2926s\n",
      "\titers: 800, epoch: 7 | loss: 0.2764859\n",
      "\tspeed: 0.0297s/iter; left time: 353.3629s\n",
      "\titers: 900, epoch: 7 | loss: 0.2517844\n",
      "\tspeed: 0.0297s/iter; left time: 350.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.25s\n",
      "Steps: 906 | Train Loss: 0.2676544 Vali Loss: 0.2648553 Test Loss: 0.2808464\n",
      "Validation loss decreased (0.266801 --> 0.264855).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2560193\n",
      "\tspeed: 0.0847s/iter; left time: 989.3790s\n",
      "\titers: 200, epoch: 8 | loss: 0.2670867\n",
      "\tspeed: 0.0297s/iter; left time: 344.2435s\n",
      "\titers: 300, epoch: 8 | loss: 0.2400081\n",
      "\tspeed: 0.0297s/iter; left time: 341.3633s\n",
      "\titers: 400, epoch: 8 | loss: 0.2598019\n",
      "\tspeed: 0.0298s/iter; left time: 338.7085s\n",
      "\titers: 500, epoch: 8 | loss: 0.2636440\n",
      "\tspeed: 0.0298s/iter; left time: 335.7785s\n",
      "\titers: 600, epoch: 8 | loss: 0.2835736\n",
      "\tspeed: 0.0298s/iter; left time: 333.1830s\n",
      "\titers: 700, epoch: 8 | loss: 0.2559046\n",
      "\tspeed: 0.0297s/iter; left time: 329.4972s\n",
      "\titers: 800, epoch: 8 | loss: 0.2724702\n",
      "\tspeed: 0.0297s/iter; left time: 326.0561s\n",
      "\titers: 900, epoch: 8 | loss: 0.2947002\n",
      "\tspeed: 0.0297s/iter; left time: 323.1083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.2621302 Vali Loss: 0.2571634 Test Loss: 0.2844976\n",
      "Validation loss decreased (0.264855 --> 0.257163).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2716273\n",
      "\tspeed: 0.0869s/iter; left time: 935.8086s\n",
      "\titers: 200, epoch: 9 | loss: 0.2145229\n",
      "\tspeed: 0.0297s/iter; left time: 317.4157s\n",
      "\titers: 300, epoch: 9 | loss: 0.2432051\n",
      "\tspeed: 0.0297s/iter; left time: 314.1877s\n",
      "\titers: 400, epoch: 9 | loss: 0.2403807\n",
      "\tspeed: 0.0297s/iter; left time: 311.1321s\n",
      "\titers: 500, epoch: 9 | loss: 0.2410014\n",
      "\tspeed: 0.0297s/iter; left time: 308.1593s\n",
      "\titers: 600, epoch: 9 | loss: 0.2758222\n",
      "\tspeed: 0.0297s/iter; left time: 305.3799s\n",
      "\titers: 700, epoch: 9 | loss: 0.2780923\n",
      "\tspeed: 0.0297s/iter; left time: 302.5114s\n",
      "\titers: 800, epoch: 9 | loss: 0.2528399\n",
      "\tspeed: 0.0297s/iter; left time: 299.4109s\n",
      "\titers: 900, epoch: 9 | loss: 0.2815757\n",
      "\tspeed: 0.0297s/iter; left time: 296.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.2582970 Vali Loss: 0.2553545 Test Loss: 0.2808213\n",
      "Validation loss decreased (0.257163 --> 0.255355).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2581372\n",
      "\tspeed: 0.0841s/iter; left time: 829.9376s\n",
      "\titers: 200, epoch: 10 | loss: 0.2428953\n",
      "\tspeed: 0.0298s/iter; left time: 290.8452s\n",
      "\titers: 300, epoch: 10 | loss: 0.2504463\n",
      "\tspeed: 0.0298s/iter; left time: 287.8333s\n",
      "\titers: 400, epoch: 10 | loss: 0.2884009\n",
      "\tspeed: 0.0298s/iter; left time: 284.6374s\n",
      "\titers: 500, epoch: 10 | loss: 0.2555453\n",
      "\tspeed: 0.0297s/iter; left time: 281.3531s\n",
      "\titers: 600, epoch: 10 | loss: 0.2282630\n",
      "\tspeed: 0.0297s/iter; left time: 278.3321s\n",
      "\titers: 700, epoch: 10 | loss: 0.2553661\n",
      "\tspeed: 0.0297s/iter; left time: 275.3069s\n",
      "\titers: 800, epoch: 10 | loss: 0.2430495\n",
      "\tspeed: 0.0297s/iter; left time: 272.3415s\n",
      "\titers: 900, epoch: 10 | loss: 0.2311419\n",
      "\tspeed: 0.0297s/iter; left time: 269.5938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.2546838 Vali Loss: 0.2557582 Test Loss: 0.2759125\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2596675\n",
      "\tspeed: 0.0817s/iter; left time: 732.0639s\n",
      "\titers: 200, epoch: 11 | loss: 0.2587310\n",
      "\tspeed: 0.0296s/iter; left time: 262.7214s\n",
      "\titers: 300, epoch: 11 | loss: 0.2235795\n",
      "\tspeed: 0.0296s/iter; left time: 259.7499s\n",
      "\titers: 400, epoch: 11 | loss: 0.2279402\n",
      "\tspeed: 0.0296s/iter; left time: 256.6977s\n",
      "\titers: 500, epoch: 11 | loss: 0.2848815\n",
      "\tspeed: 0.0296s/iter; left time: 253.8299s\n",
      "\titers: 600, epoch: 11 | loss: 0.2675300\n",
      "\tspeed: 0.0296s/iter; left time: 250.7357s\n",
      "\titers: 700, epoch: 11 | loss: 0.2346966\n",
      "\tspeed: 0.0296s/iter; left time: 247.8062s\n",
      "\titers: 800, epoch: 11 | loss: 0.2234470\n",
      "\tspeed: 0.0296s/iter; left time: 244.8440s\n",
      "\titers: 900, epoch: 11 | loss: 0.2768649\n",
      "\tspeed: 0.0296s/iter; left time: 241.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.14s\n",
      "Steps: 906 | Train Loss: 0.2518432 Vali Loss: 0.2534573 Test Loss: 0.2760886\n",
      "Validation loss decreased (0.255355 --> 0.253457).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2355793\n",
      "\tspeed: 0.0845s/iter; left time: 680.9141s\n",
      "\titers: 200, epoch: 12 | loss: 0.2460623\n",
      "\tspeed: 0.0297s/iter; left time: 236.5404s\n",
      "\titers: 300, epoch: 12 | loss: 0.2458866\n",
      "\tspeed: 0.0297s/iter; left time: 233.4098s\n",
      "\titers: 400, epoch: 12 | loss: 0.2901711\n",
      "\tspeed: 0.0297s/iter; left time: 230.4566s\n",
      "\titers: 500, epoch: 12 | loss: 0.2442312\n",
      "\tspeed: 0.0297s/iter; left time: 227.0561s\n",
      "\titers: 600, epoch: 12 | loss: 0.2325747\n",
      "\tspeed: 0.0297s/iter; left time: 224.1511s\n",
      "\titers: 700, epoch: 12 | loss: 0.2606840\n",
      "\tspeed: 0.0297s/iter; left time: 221.5413s\n",
      "\titers: 800, epoch: 12 | loss: 0.2331602\n",
      "\tspeed: 0.0297s/iter; left time: 218.5537s\n",
      "\titers: 900, epoch: 12 | loss: 0.2301960\n",
      "\tspeed: 0.0297s/iter; left time: 215.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.21s\n",
      "Steps: 906 | Train Loss: 0.2494160 Vali Loss: 0.2504608 Test Loss: 0.2713868\n",
      "Validation loss decreased (0.253457 --> 0.250461).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2390223\n",
      "\tspeed: 0.0840s/iter; left time: 600.5392s\n",
      "\titers: 200, epoch: 13 | loss: 0.2358641\n",
      "\tspeed: 0.0297s/iter; left time: 209.2916s\n",
      "\titers: 300, epoch: 13 | loss: 0.2319415\n",
      "\tspeed: 0.0297s/iter; left time: 206.1479s\n",
      "\titers: 400, epoch: 13 | loss: 0.2719097\n",
      "\tspeed: 0.0296s/iter; left time: 203.0059s\n",
      "\titers: 500, epoch: 13 | loss: 0.2816010\n",
      "\tspeed: 0.0296s/iter; left time: 199.9928s\n",
      "\titers: 600, epoch: 13 | loss: 0.2265584\n",
      "\tspeed: 0.0296s/iter; left time: 197.0046s\n",
      "\titers: 700, epoch: 13 | loss: 0.2560033\n",
      "\tspeed: 0.0296s/iter; left time: 194.0592s\n",
      "\titers: 800, epoch: 13 | loss: 0.2094005\n",
      "\tspeed: 0.0296s/iter; left time: 191.0651s\n",
      "\titers: 900, epoch: 13 | loss: 0.1995389\n",
      "\tspeed: 0.0296s/iter; left time: 188.1114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.15s\n",
      "Steps: 906 | Train Loss: 0.2474359 Vali Loss: 0.2490291 Test Loss: 0.2725363\n",
      "Validation loss decreased (0.250461 --> 0.249029).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2317441\n",
      "\tspeed: 0.0846s/iter; left time: 528.0283s\n",
      "\titers: 200, epoch: 14 | loss: 0.2502038\n",
      "\tspeed: 0.0297s/iter; left time: 182.5454s\n",
      "\titers: 300, epoch: 14 | loss: 0.2363130\n",
      "\tspeed: 0.0297s/iter; left time: 179.5008s\n",
      "\titers: 400, epoch: 14 | loss: 0.2655280\n",
      "\tspeed: 0.0296s/iter; left time: 176.1714s\n",
      "\titers: 500, epoch: 14 | loss: 0.2653955\n",
      "\tspeed: 0.0296s/iter; left time: 173.1674s\n",
      "\titers: 600, epoch: 14 | loss: 0.2435174\n",
      "\tspeed: 0.0298s/iter; left time: 170.9052s\n",
      "\titers: 700, epoch: 14 | loss: 0.2368079\n",
      "\tspeed: 0.0297s/iter; left time: 167.4013s\n",
      "\titers: 800, epoch: 14 | loss: 0.2336951\n",
      "\tspeed: 0.0297s/iter; left time: 164.4195s\n",
      "\titers: 900, epoch: 14 | loss: 0.2768160\n",
      "\tspeed: 0.0297s/iter; left time: 161.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 906 | Train Loss: 0.2456541 Vali Loss: 0.2486161 Test Loss: 0.2733704\n",
      "Validation loss decreased (0.249029 --> 0.248616).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2262324\n",
      "\tspeed: 0.0840s/iter; left time: 448.3596s\n",
      "\titers: 200, epoch: 15 | loss: 0.2571841\n",
      "\tspeed: 0.0297s/iter; left time: 155.6499s\n",
      "\titers: 300, epoch: 15 | loss: 0.2922182\n",
      "\tspeed: 0.0297s/iter; left time: 152.7801s\n",
      "\titers: 400, epoch: 15 | loss: 0.2663425\n",
      "\tspeed: 0.0297s/iter; left time: 149.7176s\n",
      "\titers: 500, epoch: 15 | loss: 0.2416984\n",
      "\tspeed: 0.0297s/iter; left time: 146.7448s\n",
      "\titers: 600, epoch: 15 | loss: 0.2661588\n",
      "\tspeed: 0.0297s/iter; left time: 143.7651s\n",
      "\titers: 700, epoch: 15 | loss: 0.2324841\n",
      "\tspeed: 0.0297s/iter; left time: 140.8390s\n",
      "\titers: 800, epoch: 15 | loss: 0.2875350\n",
      "\tspeed: 0.0297s/iter; left time: 137.8252s\n",
      "\titers: 900, epoch: 15 | loss: 0.2483862\n",
      "\tspeed: 0.0297s/iter; left time: 134.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.2442277 Vali Loss: 0.2486614 Test Loss: 0.2727549\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2580866\n",
      "\tspeed: 0.0819s/iter; left time: 362.8449s\n",
      "\titers: 200, epoch: 16 | loss: 0.2610742\n",
      "\tspeed: 0.0297s/iter; left time: 128.5407s\n",
      "\titers: 300, epoch: 16 | loss: 0.2428169\n",
      "\tspeed: 0.0297s/iter; left time: 125.4956s\n",
      "\titers: 400, epoch: 16 | loss: 0.2550306\n",
      "\tspeed: 0.0297s/iter; left time: 122.4997s\n",
      "\titers: 500, epoch: 16 | loss: 0.2314095\n",
      "\tspeed: 0.0297s/iter; left time: 119.6146s\n",
      "\titers: 600, epoch: 16 | loss: 0.2286934\n",
      "\tspeed: 0.0297s/iter; left time: 116.6313s\n",
      "\titers: 700, epoch: 16 | loss: 0.2168345\n",
      "\tspeed: 0.0296s/iter; left time: 113.5630s\n",
      "\titers: 800, epoch: 16 | loss: 0.2415393\n",
      "\tspeed: 0.0297s/iter; left time: 110.6996s\n",
      "\titers: 900, epoch: 16 | loss: 0.2262828\n",
      "\tspeed: 0.0297s/iter; left time: 107.6609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.15s\n",
      "Steps: 906 | Train Loss: 0.2424408 Vali Loss: 0.2466327 Test Loss: 0.2727647\n",
      "Validation loss decreased (0.248616 --> 0.246633).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2161431\n",
      "\tspeed: 0.0852s/iter; left time: 300.4944s\n",
      "\titers: 200, epoch: 17 | loss: 0.2529179\n",
      "\tspeed: 0.0297s/iter; left time: 101.7114s\n",
      "\titers: 300, epoch: 17 | loss: 0.2262137\n",
      "\tspeed: 0.0297s/iter; left time: 98.7399s\n",
      "\titers: 400, epoch: 17 | loss: 0.1929938\n",
      "\tspeed: 0.0297s/iter; left time: 95.7707s\n",
      "\titers: 500, epoch: 17 | loss: 0.2696162\n",
      "\tspeed: 0.0297s/iter; left time: 92.8047s\n",
      "\titers: 600, epoch: 17 | loss: 0.2311496\n",
      "\tspeed: 0.0296s/iter; left time: 89.6794s\n",
      "\titers: 700, epoch: 17 | loss: 0.2199807\n",
      "\tspeed: 0.0297s/iter; left time: 86.7306s\n",
      "\titers: 800, epoch: 17 | loss: 0.2416278\n",
      "\tspeed: 0.0297s/iter; left time: 83.7614s\n",
      "\titers: 900, epoch: 17 | loss: 0.2810754\n",
      "\tspeed: 0.0297s/iter; left time: 80.8611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2413637 Vali Loss: 0.2464718 Test Loss: 0.2705329\n",
      "Validation loss decreased (0.246633 --> 0.246472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2167058\n",
      "\tspeed: 0.0847s/iter; left time: 221.9057s\n",
      "\titers: 200, epoch: 18 | loss: 0.2368382\n",
      "\tspeed: 0.0297s/iter; left time: 74.7456s\n",
      "\titers: 300, epoch: 18 | loss: 0.2192357\n",
      "\tspeed: 0.0297s/iter; left time: 71.7985s\n",
      "\titers: 400, epoch: 18 | loss: 0.2327405\n",
      "\tspeed: 0.0297s/iter; left time: 68.9066s\n",
      "\titers: 500, epoch: 18 | loss: 0.2245473\n",
      "\tspeed: 0.0296s/iter; left time: 65.7693s\n",
      "\titers: 600, epoch: 18 | loss: 0.2043872\n",
      "\tspeed: 0.0296s/iter; left time: 62.8237s\n",
      "\titers: 700, epoch: 18 | loss: 0.2337856\n",
      "\tspeed: 0.0296s/iter; left time: 59.8587s\n",
      "\titers: 800, epoch: 18 | loss: 0.2345974\n",
      "\tspeed: 0.0296s/iter; left time: 56.8741s\n",
      "\titers: 900, epoch: 18 | loss: 0.2442849\n",
      "\tspeed: 0.0297s/iter; left time: 54.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2403704 Vali Loss: 0.2465864 Test Loss: 0.2721342\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2852758\n",
      "\tspeed: 0.0813s/iter; left time: 139.2840s\n",
      "\titers: 200, epoch: 19 | loss: 0.2500556\n",
      "\tspeed: 0.0297s/iter; left time: 47.9651s\n",
      "\titers: 300, epoch: 19 | loss: 0.2271177\n",
      "\tspeed: 0.0297s/iter; left time: 44.9767s\n",
      "\titers: 400, epoch: 19 | loss: 0.1958688\n",
      "\tspeed: 0.0297s/iter; left time: 42.0149s\n",
      "\titers: 500, epoch: 19 | loss: 0.2321912\n",
      "\tspeed: 0.0297s/iter; left time: 39.0288s\n",
      "\titers: 600, epoch: 19 | loss: 0.2199782\n",
      "\tspeed: 0.0297s/iter; left time: 36.0422s\n",
      "\titers: 700, epoch: 19 | loss: 0.2116968\n",
      "\tspeed: 0.0298s/iter; left time: 33.1877s\n",
      "\titers: 800, epoch: 19 | loss: 0.2390930\n",
      "\tspeed: 0.0297s/iter; left time: 30.0972s\n",
      "\titers: 900, epoch: 19 | loss: 0.2520115\n",
      "\tspeed: 0.0297s/iter; left time: 27.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 906 | Train Loss: 0.2395252 Vali Loss: 0.2471846 Test Loss: 0.2706857\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2002559\n",
      "\tspeed: 0.0811s/iter; left time: 65.4880s\n",
      "\titers: 200, epoch: 20 | loss: 0.2317692\n",
      "\tspeed: 0.0297s/iter; left time: 21.0164s\n",
      "\titers: 300, epoch: 20 | loss: 0.2474830\n",
      "\tspeed: 0.0297s/iter; left time: 18.0412s\n",
      "\titers: 400, epoch: 20 | loss: 0.2230704\n",
      "\tspeed: 0.0297s/iter; left time: 15.0637s\n",
      "\titers: 500, epoch: 20 | loss: 0.2750233\n",
      "\tspeed: 0.0297s/iter; left time: 12.0914s\n",
      "\titers: 600, epoch: 20 | loss: 0.2412827\n",
      "\tspeed: 0.0297s/iter; left time: 9.1208s\n",
      "\titers: 700, epoch: 20 | loss: 0.2620236\n",
      "\tspeed: 0.0297s/iter; left time: 6.1519s\n",
      "\titers: 800, epoch: 20 | loss: 0.2424151\n",
      "\tspeed: 0.0297s/iter; left time: 3.1793s\n",
      "\titers: 900, epoch: 20 | loss: 0.2197125\n",
      "\tspeed: 0.0297s/iter; left time: 0.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.2387766 Vali Loss: 0.2458301 Test Loss: 0.2699371\n",
      "Validation loss decreased (0.246472 --> 0.245830).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21430844068527222, rmse:0.46293458342552185, mae:0.26991504430770874, rse:0.42397287487983704\n",
      "Original data scale mse:1422171.75, rmse:1192.5484619140625, mae:752.7681274414062, rse:0.083803191781044\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8150337\n",
      "\tspeed: 0.0571s/iter; left time: 1027.0300s\n",
      "\titers: 200, epoch: 1 | loss: 0.7865309\n",
      "\tspeed: 0.0375s/iter; left time: 670.5916s\n",
      "\titers: 300, epoch: 1 | loss: 0.7082292\n",
      "\tspeed: 0.0375s/iter; left time: 666.1179s\n",
      "\titers: 400, epoch: 1 | loss: 0.6916044\n",
      "\tspeed: 0.0375s/iter; left time: 663.3239s\n",
      "\titers: 500, epoch: 1 | loss: 0.6595669\n",
      "\tspeed: 0.0375s/iter; left time: 658.7198s\n",
      "\titers: 600, epoch: 1 | loss: 0.6274444\n",
      "\tspeed: 0.0375s/iter; left time: 654.9922s\n",
      "\titers: 700, epoch: 1 | loss: 0.5982677\n",
      "\tspeed: 0.0375s/iter; left time: 651.2928s\n",
      "\titers: 800, epoch: 1 | loss: 0.5808680\n",
      "\tspeed: 0.0375s/iter; left time: 648.7011s\n",
      "\titers: 900, epoch: 1 | loss: 0.5951590\n",
      "\tspeed: 0.0375s/iter; left time: 644.2150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.59s\n",
      "Steps: 904 | Train Loss: 0.6850672 Vali Loss: 0.5645998 Test Loss: 0.6092119\n",
      "Validation loss decreased (inf --> 0.564600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5116340\n",
      "\tspeed: 0.1068s/iter; left time: 1823.7026s\n",
      "\titers: 200, epoch: 2 | loss: 0.5119313\n",
      "\tspeed: 0.0380s/iter; left time: 645.7579s\n",
      "\titers: 300, epoch: 2 | loss: 0.4384262\n",
      "\tspeed: 0.0381s/iter; left time: 642.6145s\n",
      "\titers: 400, epoch: 2 | loss: 0.4303905\n",
      "\tspeed: 0.0381s/iter; left time: 638.5407s\n",
      "\titers: 500, epoch: 2 | loss: 0.4120647\n",
      "\tspeed: 0.0381s/iter; left time: 634.6446s\n",
      "\titers: 600, epoch: 2 | loss: 0.4223784\n",
      "\tspeed: 0.0380s/iter; left time: 630.6994s\n",
      "\titers: 700, epoch: 2 | loss: 0.4023072\n",
      "\tspeed: 0.0381s/iter; left time: 627.5626s\n",
      "\titers: 800, epoch: 2 | loss: 0.3992223\n",
      "\tspeed: 0.0377s/iter; left time: 617.0627s\n",
      "\titers: 900, epoch: 2 | loss: 0.3646308\n",
      "\tspeed: 0.0375s/iter; left time: 611.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.60s\n",
      "Steps: 904 | Train Loss: 0.4395237 Vali Loss: 0.3742394 Test Loss: 0.4021838\n",
      "Validation loss decreased (0.564600 --> 0.374239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3748493\n",
      "\tspeed: 0.1196s/iter; left time: 1934.5646s\n",
      "\titers: 200, epoch: 3 | loss: 0.3729239\n",
      "\tspeed: 0.0376s/iter; left time: 603.8395s\n",
      "\titers: 300, epoch: 3 | loss: 0.3902239\n",
      "\tspeed: 0.0376s/iter; left time: 600.0100s\n",
      "\titers: 400, epoch: 3 | loss: 0.3805928\n",
      "\tspeed: 0.0375s/iter; left time: 595.1036s\n",
      "\titers: 500, epoch: 3 | loss: 0.3480365\n",
      "\tspeed: 0.0375s/iter; left time: 591.9830s\n",
      "\titers: 600, epoch: 3 | loss: 0.3729757\n",
      "\tspeed: 0.0376s/iter; left time: 589.1283s\n",
      "\titers: 700, epoch: 3 | loss: 0.3477038\n",
      "\tspeed: 0.0376s/iter; left time: 585.2741s\n",
      "\titers: 800, epoch: 3 | loss: 0.3995710\n",
      "\tspeed: 0.0375s/iter; left time: 580.9570s\n",
      "\titers: 900, epoch: 3 | loss: 0.3725554\n",
      "\tspeed: 0.0381s/iter; left time: 585.2538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.32s\n",
      "Steps: 904 | Train Loss: 0.3649984 Vali Loss: 0.3627852 Test Loss: 0.3926698\n",
      "Validation loss decreased (0.374239 --> 0.362785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3369209\n",
      "\tspeed: 0.1066s/iter; left time: 1628.0758s\n",
      "\titers: 200, epoch: 4 | loss: 0.3438199\n",
      "\tspeed: 0.0375s/iter; left time: 568.2858s\n",
      "\titers: 300, epoch: 4 | loss: 0.3186904\n",
      "\tspeed: 0.0375s/iter; left time: 564.9885s\n",
      "\titers: 400, epoch: 4 | loss: 0.3523760\n",
      "\tspeed: 0.0375s/iter; left time: 560.9002s\n",
      "\titers: 500, epoch: 4 | loss: 0.3491880\n",
      "\tspeed: 0.0375s/iter; left time: 557.4642s\n",
      "\titers: 600, epoch: 4 | loss: 0.3450741\n",
      "\tspeed: 0.0376s/iter; left time: 554.7143s\n",
      "\titers: 700, epoch: 4 | loss: 0.3198591\n",
      "\tspeed: 0.0375s/iter; left time: 549.3687s\n",
      "\titers: 800, epoch: 4 | loss: 0.3282226\n",
      "\tspeed: 0.0377s/iter; left time: 548.8080s\n",
      "\titers: 900, epoch: 4 | loss: 0.3083993\n",
      "\tspeed: 0.0380s/iter; left time: 550.4655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.23s\n",
      "Steps: 904 | Train Loss: 0.3405427 Vali Loss: 0.3546020 Test Loss: 0.3999583\n",
      "Validation loss decreased (0.362785 --> 0.354602).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3082108\n",
      "\tspeed: 0.1059s/iter; left time: 1521.3681s\n",
      "\titers: 200, epoch: 5 | loss: 0.3236231\n",
      "\tspeed: 0.0375s/iter; left time: 535.1098s\n",
      "\titers: 300, epoch: 5 | loss: 0.3039698\n",
      "\tspeed: 0.0375s/iter; left time: 531.2313s\n",
      "\titers: 400, epoch: 5 | loss: 0.3608793\n",
      "\tspeed: 0.0375s/iter; left time: 527.9320s\n",
      "\titers: 500, epoch: 5 | loss: 0.3142963\n",
      "\tspeed: 0.0375s/iter; left time: 524.0369s\n",
      "\titers: 600, epoch: 5 | loss: 0.3134119\n",
      "\tspeed: 0.0375s/iter; left time: 520.0403s\n",
      "\titers: 700, epoch: 5 | loss: 0.3490780\n",
      "\tspeed: 0.0375s/iter; left time: 515.7575s\n",
      "\titers: 800, epoch: 5 | loss: 0.3387781\n",
      "\tspeed: 0.0375s/iter; left time: 511.7868s\n",
      "\titers: 900, epoch: 5 | loss: 0.3102326\n",
      "\tspeed: 0.0375s/iter; left time: 508.0107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.18s\n",
      "Steps: 904 | Train Loss: 0.3213092 Vali Loss: 0.3511533 Test Loss: 0.3767008\n",
      "Validation loss decreased (0.354602 --> 0.351153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2619042\n",
      "\tspeed: 0.1067s/iter; left time: 1435.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.3239393\n",
      "\tspeed: 0.0381s/iter; left time: 509.0829s\n",
      "\titers: 300, epoch: 6 | loss: 0.3155590\n",
      "\tspeed: 0.0376s/iter; left time: 498.4058s\n",
      "\titers: 400, epoch: 6 | loss: 0.3265509\n",
      "\tspeed: 0.0376s/iter; left time: 494.5927s\n",
      "\titers: 500, epoch: 6 | loss: 0.2980553\n",
      "\tspeed: 0.0375s/iter; left time: 490.3284s\n",
      "\titers: 600, epoch: 6 | loss: 0.3054219\n",
      "\tspeed: 0.0375s/iter; left time: 486.4441s\n",
      "\titers: 700, epoch: 6 | loss: 0.2757724\n",
      "\tspeed: 0.0376s/iter; left time: 482.9909s\n",
      "\titers: 800, epoch: 6 | loss: 0.3181484\n",
      "\tspeed: 0.0375s/iter; left time: 478.9380s\n",
      "\titers: 900, epoch: 6 | loss: 0.2964580\n",
      "\tspeed: 0.0375s/iter; left time: 475.2743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.38s\n",
      "Steps: 904 | Train Loss: 0.3061327 Vali Loss: 0.3628338 Test Loss: 0.3884365\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2978437\n",
      "\tspeed: 0.1048s/iter; left time: 1315.9603s\n",
      "\titers: 200, epoch: 7 | loss: 0.2830954\n",
      "\tspeed: 0.0375s/iter; left time: 467.4470s\n",
      "\titers: 300, epoch: 7 | loss: 0.2900503\n",
      "\tspeed: 0.0375s/iter; left time: 463.8769s\n",
      "\titers: 400, epoch: 7 | loss: 0.2858080\n",
      "\tspeed: 0.0376s/iter; left time: 460.6450s\n",
      "\titers: 500, epoch: 7 | loss: 0.2673484\n",
      "\tspeed: 0.0376s/iter; left time: 456.6471s\n",
      "\titers: 600, epoch: 7 | loss: 0.3229191\n",
      "\tspeed: 0.0376s/iter; left time: 453.3841s\n",
      "\titers: 700, epoch: 7 | loss: 0.2741376\n",
      "\tspeed: 0.0376s/iter; left time: 449.1000s\n",
      "\titers: 800, epoch: 7 | loss: 0.2455494\n",
      "\tspeed: 0.0375s/iter; left time: 445.0959s\n",
      "\titers: 900, epoch: 7 | loss: 0.2912613\n",
      "\tspeed: 0.0376s/iter; left time: 441.9013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.24s\n",
      "Steps: 904 | Train Loss: 0.2898870 Vali Loss: 0.3604039 Test Loss: 0.3900767\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2654546\n",
      "\tspeed: 0.1048s/iter; left time: 1221.3755s\n",
      "\titers: 200, epoch: 8 | loss: 0.2805337\n",
      "\tspeed: 0.0381s/iter; left time: 440.3548s\n",
      "\titers: 300, epoch: 8 | loss: 0.2866867\n",
      "\tspeed: 0.0381s/iter; left time: 436.3423s\n",
      "\titers: 400, epoch: 8 | loss: 0.2736313\n",
      "\tspeed: 0.0381s/iter; left time: 432.1537s\n",
      "\titers: 500, epoch: 8 | loss: 0.2847659\n",
      "\tspeed: 0.0381s/iter; left time: 428.6094s\n",
      "\titers: 600, epoch: 8 | loss: 0.2609076\n",
      "\tspeed: 0.0381s/iter; left time: 425.2393s\n",
      "\titers: 700, epoch: 8 | loss: 0.2739472\n",
      "\tspeed: 0.0381s/iter; left time: 420.8724s\n",
      "\titers: 800, epoch: 8 | loss: 0.2664894\n",
      "\tspeed: 0.0381s/iter; left time: 417.0207s\n",
      "\titers: 900, epoch: 8 | loss: 0.2703234\n",
      "\tspeed: 0.0381s/iter; left time: 413.1208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:34.73s\n",
      "Steps: 904 | Train Loss: 0.2745776 Vali Loss: 0.3704009 Test Loss: 0.3950642\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3860393762588501, rmse:0.6213206648826599, mae:0.37681102752685547, rse:0.5688841342926025\n",
      "Original data scale mse:2678728.5, rmse:1636.68212890625, mae:1075.39013671875, rse:0.11518000811338425\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7977383\n",
      "\tspeed: 0.0405s/iter; left time: 728.9609s\n",
      "\titers: 200, epoch: 1 | loss: 0.7573959\n",
      "\tspeed: 0.0375s/iter; left time: 671.3267s\n",
      "\titers: 300, epoch: 1 | loss: 0.7317508\n",
      "\tspeed: 0.0375s/iter; left time: 667.1749s\n",
      "\titers: 400, epoch: 1 | loss: 0.6853316\n",
      "\tspeed: 0.0375s/iter; left time: 663.0008s\n",
      "\titers: 500, epoch: 1 | loss: 0.6389797\n",
      "\tspeed: 0.0375s/iter; left time: 659.1503s\n",
      "\titers: 600, epoch: 1 | loss: 0.6572399\n",
      "\tspeed: 0.0375s/iter; left time: 655.6831s\n",
      "\titers: 700, epoch: 1 | loss: 0.6264318\n",
      "\tspeed: 0.0375s/iter; left time: 651.7014s\n",
      "\titers: 800, epoch: 1 | loss: 0.6064339\n",
      "\tspeed: 0.0375s/iter; left time: 648.8700s\n",
      "\titers: 900, epoch: 1 | loss: 0.5623375\n",
      "\tspeed: 0.0376s/iter; left time: 645.5621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.28s\n",
      "Steps: 904 | Train Loss: 0.6866124 Vali Loss: 0.5657853 Test Loss: 0.6095882\n",
      "Validation loss decreased (inf --> 0.565785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5049976\n",
      "\tspeed: 0.1070s/iter; left time: 1827.1604s\n",
      "\titers: 200, epoch: 2 | loss: 0.4583150\n",
      "\tspeed: 0.0375s/iter; left time: 636.8089s\n",
      "\titers: 300, epoch: 2 | loss: 0.4456894\n",
      "\tspeed: 0.0375s/iter; left time: 633.3854s\n",
      "\titers: 400, epoch: 2 | loss: 0.4533090\n",
      "\tspeed: 0.0376s/iter; left time: 630.5014s\n",
      "\titers: 500, epoch: 2 | loss: 0.4204739\n",
      "\tspeed: 0.0375s/iter; left time: 626.1323s\n",
      "\titers: 600, epoch: 2 | loss: 0.4253356\n",
      "\tspeed: 0.0375s/iter; left time: 622.2301s\n",
      "\titers: 700, epoch: 2 | loss: 0.4037566\n",
      "\tspeed: 0.0375s/iter; left time: 618.3432s\n",
      "\titers: 800, epoch: 2 | loss: 0.3865068\n",
      "\tspeed: 0.0376s/iter; left time: 615.0318s\n",
      "\titers: 900, epoch: 2 | loss: 0.3612042\n",
      "\tspeed: 0.0375s/iter; left time: 610.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.26s\n",
      "Steps: 904 | Train Loss: 0.4439592 Vali Loss: 0.3900311 Test Loss: 0.4203017\n",
      "Validation loss decreased (0.565785 --> 0.390031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3815211\n",
      "\tspeed: 0.1060s/iter; left time: 1714.4680s\n",
      "\titers: 200, epoch: 3 | loss: 0.3716187\n",
      "\tspeed: 0.0375s/iter; left time: 603.1464s\n",
      "\titers: 300, epoch: 3 | loss: 0.3916775\n",
      "\tspeed: 0.0375s/iter; left time: 599.1812s\n",
      "\titers: 400, epoch: 3 | loss: 0.3593472\n",
      "\tspeed: 0.0375s/iter; left time: 594.8796s\n",
      "\titers: 500, epoch: 3 | loss: 0.3692485\n",
      "\tspeed: 0.0375s/iter; left time: 591.4259s\n",
      "\titers: 600, epoch: 3 | loss: 0.3481042\n",
      "\tspeed: 0.0375s/iter; left time: 587.8379s\n",
      "\titers: 700, epoch: 3 | loss: 0.3654119\n",
      "\tspeed: 0.0375s/iter; left time: 584.0099s\n",
      "\titers: 800, epoch: 3 | loss: 0.3498480\n",
      "\tspeed: 0.0375s/iter; left time: 580.1506s\n",
      "\titers: 900, epoch: 3 | loss: 0.3100273\n",
      "\tspeed: 0.0375s/iter; left time: 576.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.19s\n",
      "Steps: 904 | Train Loss: 0.3654165 Vali Loss: 0.3589092 Test Loss: 0.3908001\n",
      "Validation loss decreased (0.390031 --> 0.358909).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3473025\n",
      "\tspeed: 0.1087s/iter; left time: 1660.0657s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399260\n",
      "\tspeed: 0.0375s/iter; left time: 568.7360s\n",
      "\titers: 300, epoch: 4 | loss: 0.3408269\n",
      "\tspeed: 0.0375s/iter; left time: 565.6346s\n",
      "\titers: 400, epoch: 4 | loss: 0.3393246\n",
      "\tspeed: 0.0375s/iter; left time: 561.6981s\n",
      "\titers: 500, epoch: 4 | loss: 0.3567283\n",
      "\tspeed: 0.0375s/iter; left time: 558.2047s\n",
      "\titers: 600, epoch: 4 | loss: 0.3573701\n",
      "\tspeed: 0.0376s/iter; left time: 555.0123s\n",
      "\titers: 700, epoch: 4 | loss: 0.3585140\n",
      "\tspeed: 0.0376s/iter; left time: 550.9456s\n",
      "\titers: 800, epoch: 4 | loss: 0.3528823\n",
      "\tspeed: 0.0376s/iter; left time: 547.2860s\n",
      "\titers: 900, epoch: 4 | loss: 0.3077019\n",
      "\tspeed: 0.0376s/iter; left time: 544.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.35s\n",
      "Steps: 904 | Train Loss: 0.3424055 Vali Loss: 0.3478123 Test Loss: 0.3919922\n",
      "Validation loss decreased (0.358909 --> 0.347812).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3381594\n",
      "\tspeed: 0.1106s/iter; left time: 1588.9792s\n",
      "\titers: 200, epoch: 5 | loss: 0.3218094\n",
      "\tspeed: 0.0375s/iter; left time: 534.8815s\n",
      "\titers: 300, epoch: 5 | loss: 0.3541737\n",
      "\tspeed: 0.0376s/iter; left time: 531.9164s\n",
      "\titers: 400, epoch: 5 | loss: 0.3116988\n",
      "\tspeed: 0.0375s/iter; left time: 527.3819s\n",
      "\titers: 500, epoch: 5 | loss: 0.3338269\n",
      "\tspeed: 0.0375s/iter; left time: 523.9197s\n",
      "\titers: 600, epoch: 5 | loss: 0.2980376\n",
      "\tspeed: 0.0375s/iter; left time: 520.2871s\n",
      "\titers: 700, epoch: 5 | loss: 0.3347347\n",
      "\tspeed: 0.0375s/iter; left time: 516.2773s\n",
      "\titers: 800, epoch: 5 | loss: 0.3145725\n",
      "\tspeed: 0.0375s/iter; left time: 512.5478s\n",
      "\titers: 900, epoch: 5 | loss: 0.2930928\n",
      "\tspeed: 0.0375s/iter; left time: 508.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.23s\n",
      "Steps: 904 | Train Loss: 0.3253946 Vali Loss: 0.3588083 Test Loss: 0.4050261\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3154757\n",
      "\tspeed: 0.1038s/iter; left time: 1397.5447s\n",
      "\titers: 200, epoch: 6 | loss: 0.2960304\n",
      "\tspeed: 0.0381s/iter; left time: 509.3535s\n",
      "\titers: 300, epoch: 6 | loss: 0.3257332\n",
      "\tspeed: 0.0381s/iter; left time: 504.6835s\n",
      "\titers: 400, epoch: 6 | loss: 0.3083124\n",
      "\tspeed: 0.0381s/iter; left time: 501.0911s\n",
      "\titers: 500, epoch: 6 | loss: 0.3041582\n",
      "\tspeed: 0.0381s/iter; left time: 497.2419s\n",
      "\titers: 600, epoch: 6 | loss: 0.2994896\n",
      "\tspeed: 0.0380s/iter; left time: 492.9504s\n",
      "\titers: 700, epoch: 6 | loss: 0.2627114\n",
      "\tspeed: 0.0381s/iter; left time: 489.6458s\n",
      "\titers: 800, epoch: 6 | loss: 0.2952165\n",
      "\tspeed: 0.0377s/iter; left time: 480.5313s\n",
      "\titers: 900, epoch: 6 | loss: 0.3007255\n",
      "\tspeed: 0.0375s/iter; left time: 474.5668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.58s\n",
      "Steps: 904 | Train Loss: 0.3104735 Vali Loss: 0.3581659 Test Loss: 0.3918914\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3124721\n",
      "\tspeed: 0.1036s/iter; left time: 1300.2887s\n",
      "\titers: 200, epoch: 7 | loss: 0.2769096\n",
      "\tspeed: 0.0376s/iter; left time: 468.3732s\n",
      "\titers: 300, epoch: 7 | loss: 0.2846074\n",
      "\tspeed: 0.0376s/iter; left time: 465.2190s\n",
      "\titers: 400, epoch: 7 | loss: 0.2937971\n",
      "\tspeed: 0.0376s/iter; left time: 460.4218s\n",
      "\titers: 500, epoch: 7 | loss: 0.2685632\n",
      "\tspeed: 0.0375s/iter; left time: 456.4859s\n",
      "\titers: 600, epoch: 7 | loss: 0.2725448\n",
      "\tspeed: 0.0376s/iter; left time: 453.6257s\n",
      "\titers: 700, epoch: 7 | loss: 0.2755593\n",
      "\tspeed: 0.0376s/iter; left time: 449.7034s\n",
      "\titers: 800, epoch: 7 | loss: 0.2673206\n",
      "\tspeed: 0.0376s/iter; left time: 445.3372s\n",
      "\titers: 900, epoch: 7 | loss: 0.2814191\n",
      "\tspeed: 0.0376s/iter; left time: 441.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.28s\n",
      "Steps: 904 | Train Loss: 0.2954007 Vali Loss: 0.3726324 Test Loss: 0.4216487\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.39962294697761536, rmse:0.6321573853492737, mae:0.39198100566864014, rse:0.5788062214851379\n",
      "Original data scale mse:3289923.75, rmse:1813.814697265625, mae:1161.396728515625, rse:0.1276455521583557\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8280501\n",
      "\tspeed: 0.0648s/iter; left time: 1162.0792s\n",
      "\titers: 200, epoch: 1 | loss: 0.7671803\n",
      "\tspeed: 0.0460s/iter; left time: 819.8382s\n",
      "\titers: 300, epoch: 1 | loss: 0.7849457\n",
      "\tspeed: 0.0459s/iter; left time: 815.0010s\n",
      "\titers: 400, epoch: 1 | loss: 0.7654822\n",
      "\tspeed: 0.0459s/iter; left time: 809.9302s\n",
      "\titers: 500, epoch: 1 | loss: 0.7249994\n",
      "\tspeed: 0.0460s/iter; left time: 806.0810s\n",
      "\titers: 600, epoch: 1 | loss: 0.7271847\n",
      "\tspeed: 0.0459s/iter; left time: 801.0097s\n",
      "\titers: 700, epoch: 1 | loss: 0.6938729\n",
      "\tspeed: 0.0460s/iter; left time: 796.8871s\n",
      "\titers: 800, epoch: 1 | loss: 0.7244999\n",
      "\tspeed: 0.0460s/iter; left time: 792.2574s\n",
      "\titers: 900, epoch: 1 | loss: 0.6612191\n",
      "\tspeed: 0.0460s/iter; left time: 787.8262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 902 | Train Loss: 0.7398342 Vali Loss: 0.6647944 Test Loss: 0.7146385\n",
      "Validation loss decreased (inf --> 0.664794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6549571\n",
      "\tspeed: 0.1340s/iter; left time: 2283.4777s\n",
      "\titers: 200, epoch: 2 | loss: 0.5886534\n",
      "\tspeed: 0.0460s/iter; left time: 778.4671s\n",
      "\titers: 300, epoch: 2 | loss: 0.5208691\n",
      "\tspeed: 0.0460s/iter; left time: 774.1602s\n",
      "\titers: 400, epoch: 2 | loss: 0.4893373\n",
      "\tspeed: 0.0460s/iter; left time: 769.5013s\n",
      "\titers: 500, epoch: 2 | loss: 0.4368061\n",
      "\tspeed: 0.0460s/iter; left time: 764.6985s\n",
      "\titers: 600, epoch: 2 | loss: 0.4560348\n",
      "\tspeed: 0.0460s/iter; left time: 760.7329s\n",
      "\titers: 700, epoch: 2 | loss: 0.3951013\n",
      "\tspeed: 0.0460s/iter; left time: 756.1441s\n",
      "\titers: 800, epoch: 2 | loss: 0.4011065\n",
      "\tspeed: 0.0460s/iter; left time: 751.5147s\n",
      "\titers: 900, epoch: 2 | loss: 0.4047628\n",
      "\tspeed: 0.0460s/iter; left time: 746.8052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 902 | Train Loss: 0.4958260 Vali Loss: 0.4030131 Test Loss: 0.4575190\n",
      "Validation loss decreased (0.664794 --> 0.403013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3732580\n",
      "\tspeed: 0.1270s/iter; left time: 2049.9142s\n",
      "\titers: 200, epoch: 3 | loss: 0.4142113\n",
      "\tspeed: 0.0460s/iter; left time: 737.6633s\n",
      "\titers: 300, epoch: 3 | loss: 0.4074443\n",
      "\tspeed: 0.0460s/iter; left time: 733.2607s\n",
      "\titers: 400, epoch: 3 | loss: 0.4110204\n",
      "\tspeed: 0.0460s/iter; left time: 728.4617s\n",
      "\titers: 500, epoch: 3 | loss: 0.4058383\n",
      "\tspeed: 0.0460s/iter; left time: 724.0710s\n",
      "\titers: 600, epoch: 3 | loss: 0.3690900\n",
      "\tspeed: 0.0460s/iter; left time: 719.6120s\n",
      "\titers: 700, epoch: 3 | loss: 0.3863875\n",
      "\tspeed: 0.0460s/iter; left time: 714.9164s\n",
      "\titers: 800, epoch: 3 | loss: 0.3612333\n",
      "\tspeed: 0.0460s/iter; left time: 710.1167s\n",
      "\titers: 900, epoch: 3 | loss: 0.3778325\n",
      "\tspeed: 0.0460s/iter; left time: 705.3669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 902 | Train Loss: 0.3893514 Vali Loss: 0.3763303 Test Loss: 0.4238930\n",
      "Validation loss decreased (0.403013 --> 0.376330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3786625\n",
      "\tspeed: 0.1276s/iter; left time: 1943.4564s\n",
      "\titers: 200, epoch: 4 | loss: 0.3670406\n",
      "\tspeed: 0.0459s/iter; left time: 694.8889s\n",
      "\titers: 300, epoch: 4 | loss: 0.3980571\n",
      "\tspeed: 0.0461s/iter; left time: 692.4354s\n",
      "\titers: 400, epoch: 4 | loss: 0.3459499\n",
      "\tspeed: 0.0459s/iter; left time: 686.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3482888\n",
      "\tspeed: 0.0459s/iter; left time: 681.5713s\n",
      "\titers: 600, epoch: 4 | loss: 0.3452627\n",
      "\tspeed: 0.0459s/iter; left time: 676.6531s\n",
      "\titers: 700, epoch: 4 | loss: 0.3783236\n",
      "\tspeed: 0.0459s/iter; left time: 672.1073s\n",
      "\titers: 800, epoch: 4 | loss: 0.3829342\n",
      "\tspeed: 0.0459s/iter; left time: 667.2400s\n",
      "\titers: 900, epoch: 4 | loss: 0.3624015\n",
      "\tspeed: 0.0459s/iter; left time: 662.7438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 902 | Train Loss: 0.3627147 Vali Loss: 0.3870502 Test Loss: 0.4186793\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3258232\n",
      "\tspeed: 0.1243s/iter; left time: 1782.1133s\n",
      "\titers: 200, epoch: 5 | loss: 0.3195130\n",
      "\tspeed: 0.0460s/iter; left time: 655.1124s\n",
      "\titers: 300, epoch: 5 | loss: 0.3546770\n",
      "\tspeed: 0.0460s/iter; left time: 649.8544s\n",
      "\titers: 400, epoch: 5 | loss: 0.3555680\n",
      "\tspeed: 0.0460s/iter; left time: 645.0062s\n",
      "\titers: 500, epoch: 5 | loss: 0.3524508\n",
      "\tspeed: 0.0460s/iter; left time: 640.3811s\n",
      "\titers: 600, epoch: 5 | loss: 0.3631451\n",
      "\tspeed: 0.0460s/iter; left time: 636.3669s\n",
      "\titers: 700, epoch: 5 | loss: 0.3687120\n",
      "\tspeed: 0.0459s/iter; left time: 630.9881s\n",
      "\titers: 800, epoch: 5 | loss: 0.3300255\n",
      "\tspeed: 0.0460s/iter; left time: 626.7650s\n",
      "\titers: 900, epoch: 5 | loss: 0.3168762\n",
      "\tspeed: 0.0460s/iter; left time: 622.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 902 | Train Loss: 0.3414206 Vali Loss: 0.3805757 Test Loss: 0.4232909\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3305565\n",
      "\tspeed: 0.1240s/iter; left time: 1665.3506s\n",
      "\titers: 200, epoch: 6 | loss: 0.3264413\n",
      "\tspeed: 0.0459s/iter; left time: 611.8131s\n",
      "\titers: 300, epoch: 6 | loss: 0.3067354\n",
      "\tspeed: 0.0459s/iter; left time: 607.3502s\n",
      "\titers: 400, epoch: 6 | loss: 0.3274036\n",
      "\tspeed: 0.0459s/iter; left time: 602.6175s\n",
      "\titers: 500, epoch: 6 | loss: 0.3122303\n",
      "\tspeed: 0.0459s/iter; left time: 598.2635s\n",
      "\titers: 600, epoch: 6 | loss: 0.3093185\n",
      "\tspeed: 0.0459s/iter; left time: 593.8813s\n",
      "\titers: 700, epoch: 6 | loss: 0.3042404\n",
      "\tspeed: 0.0459s/iter; left time: 589.1627s\n",
      "\titers: 800, epoch: 6 | loss: 0.3062407\n",
      "\tspeed: 0.0459s/iter; left time: 584.5509s\n",
      "\titers: 900, epoch: 6 | loss: 0.3096261\n",
      "\tspeed: 0.0459s/iter; left time: 579.8216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 902 | Train Loss: 0.3224779 Vali Loss: 0.3952253 Test Loss: 0.4266629\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4348284602165222, rmse:0.6594152450561523, mae:0.42385366559028625, rse:0.6039435863494873\n",
      "Original data scale mse:4242708.0, rmse:2059.783447265625, mae:1329.1781005859375, rse:0.1450914889574051\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7974735\n",
      "\tspeed: 0.0489s/iter; left time: 876.6159s\n",
      "\titers: 200, epoch: 1 | loss: 0.7544412\n",
      "\tspeed: 0.0459s/iter; left time: 819.5194s\n",
      "\titers: 300, epoch: 1 | loss: 0.7925992\n",
      "\tspeed: 0.0460s/iter; left time: 815.3856s\n",
      "\titers: 400, epoch: 1 | loss: 0.7377703\n",
      "\tspeed: 0.0459s/iter; left time: 810.2478s\n",
      "\titers: 500, epoch: 1 | loss: 0.7340454\n",
      "\tspeed: 0.0459s/iter; left time: 805.9650s\n",
      "\titers: 600, epoch: 1 | loss: 0.7256621\n",
      "\tspeed: 0.0459s/iter; left time: 801.3613s\n",
      "\titers: 700, epoch: 1 | loss: 0.7105807\n",
      "\tspeed: 0.0460s/iter; left time: 796.9050s\n",
      "\titers: 800, epoch: 1 | loss: 0.6977004\n",
      "\tspeed: 0.0460s/iter; left time: 792.4218s\n",
      "\titers: 900, epoch: 1 | loss: 0.6401993\n",
      "\tspeed: 0.0459s/iter; left time: 787.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.79s\n",
      "Steps: 902 | Train Loss: 0.7437132 Vali Loss: 0.6597509 Test Loss: 0.7151433\n",
      "Validation loss decreased (inf --> 0.659751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6102369\n",
      "\tspeed: 0.1301s/iter; left time: 2216.0522s\n",
      "\titers: 200, epoch: 2 | loss: 0.5705064\n",
      "\tspeed: 0.0460s/iter; left time: 778.5306s\n",
      "\titers: 300, epoch: 2 | loss: 0.4899058\n",
      "\tspeed: 0.0460s/iter; left time: 774.2105s\n",
      "\titers: 400, epoch: 2 | loss: 0.4781640\n",
      "\tspeed: 0.0460s/iter; left time: 769.5036s\n",
      "\titers: 500, epoch: 2 | loss: 0.4673846\n",
      "\tspeed: 0.0460s/iter; left time: 764.9942s\n",
      "\titers: 600, epoch: 2 | loss: 0.4334404\n",
      "\tspeed: 0.0460s/iter; left time: 760.8389s\n",
      "\titers: 700, epoch: 2 | loss: 0.4007219\n",
      "\tspeed: 0.0460s/iter; left time: 756.1422s\n",
      "\titers: 800, epoch: 2 | loss: 0.4263807\n",
      "\tspeed: 0.0460s/iter; left time: 751.8025s\n",
      "\titers: 900, epoch: 2 | loss: 0.4291814\n",
      "\tspeed: 0.0460s/iter; left time: 746.9764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.78s\n",
      "Steps: 902 | Train Loss: 0.4971245 Vali Loss: 0.4060253 Test Loss: 0.4578899\n",
      "Validation loss decreased (0.659751 --> 0.406025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4284823\n",
      "\tspeed: 0.1310s/iter; left time: 2114.4274s\n",
      "\titers: 200, epoch: 3 | loss: 0.3880342\n",
      "\tspeed: 0.0459s/iter; left time: 736.4957s\n",
      "\titers: 300, epoch: 3 | loss: 0.4185027\n",
      "\tspeed: 0.0459s/iter; left time: 732.0549s\n",
      "\titers: 400, epoch: 3 | loss: 0.3936366\n",
      "\tspeed: 0.0459s/iter; left time: 727.5856s\n",
      "\titers: 500, epoch: 3 | loss: 0.4209563\n",
      "\tspeed: 0.0459s/iter; left time: 722.5659s\n",
      "\titers: 600, epoch: 3 | loss: 0.3490029\n",
      "\tspeed: 0.0460s/iter; left time: 718.9048s\n",
      "\titers: 700, epoch: 3 | loss: 0.3856685\n",
      "\tspeed: 0.0460s/iter; left time: 714.4894s\n",
      "\titers: 800, epoch: 3 | loss: 0.3550621\n",
      "\tspeed: 0.0460s/iter; left time: 709.5749s\n",
      "\titers: 900, epoch: 3 | loss: 0.3765105\n",
      "\tspeed: 0.0460s/iter; left time: 705.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.77s\n",
      "Steps: 902 | Train Loss: 0.3937890 Vali Loss: 0.3807809 Test Loss: 0.4213197\n",
      "Validation loss decreased (0.406025 --> 0.380781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4087430\n",
      "\tspeed: 0.1290s/iter; left time: 1966.0731s\n",
      "\titers: 200, epoch: 4 | loss: 0.3617661\n",
      "\tspeed: 0.0459s/iter; left time: 695.3753s\n",
      "\titers: 300, epoch: 4 | loss: 0.3720865\n",
      "\tspeed: 0.0459s/iter; left time: 690.5803s\n",
      "\titers: 400, epoch: 4 | loss: 0.3709372\n",
      "\tspeed: 0.0459s/iter; left time: 686.0791s\n",
      "\titers: 500, epoch: 4 | loss: 0.3520428\n",
      "\tspeed: 0.0460s/iter; left time: 681.9133s\n",
      "\titers: 600, epoch: 4 | loss: 0.3697520\n",
      "\tspeed: 0.0460s/iter; left time: 677.5122s\n",
      "\titers: 700, epoch: 4 | loss: 0.3444159\n",
      "\tspeed: 0.0460s/iter; left time: 673.0597s\n",
      "\titers: 800, epoch: 4 | loss: 0.3860698\n",
      "\tspeed: 0.0460s/iter; left time: 668.2669s\n",
      "\titers: 900, epoch: 4 | loss: 0.3856181\n",
      "\tspeed: 0.0460s/iter; left time: 663.5784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 902 | Train Loss: 0.3666811 Vali Loss: 0.3818067 Test Loss: 0.4054340\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3714052\n",
      "\tspeed: 0.1254s/iter; left time: 1797.7750s\n",
      "\titers: 200, epoch: 5 | loss: 0.3473887\n",
      "\tspeed: 0.0460s/iter; left time: 654.3548s\n",
      "\titers: 300, epoch: 5 | loss: 0.3265126\n",
      "\tspeed: 0.0459s/iter; left time: 649.3528s\n",
      "\titers: 400, epoch: 5 | loss: 0.3595056\n",
      "\tspeed: 0.0459s/iter; left time: 644.4749s\n",
      "\titers: 500, epoch: 5 | loss: 0.3287465\n",
      "\tspeed: 0.0459s/iter; left time: 640.0399s\n",
      "\titers: 600, epoch: 5 | loss: 0.3324325\n",
      "\tspeed: 0.0459s/iter; left time: 635.5376s\n",
      "\titers: 700, epoch: 5 | loss: 0.3384423\n",
      "\tspeed: 0.0459s/iter; left time: 630.6958s\n",
      "\titers: 800, epoch: 5 | loss: 0.3693855\n",
      "\tspeed: 0.0459s/iter; left time: 626.3665s\n",
      "\titers: 900, epoch: 5 | loss: 0.3303832\n",
      "\tspeed: 0.0460s/iter; left time: 622.3776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 902 | Train Loss: 0.3449307 Vali Loss: 0.3710508 Test Loss: 0.4327653\n",
      "Validation loss decreased (0.380781 --> 0.371051).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3339225\n",
      "\tspeed: 0.1305s/iter; left time: 1753.3196s\n",
      "\titers: 200, epoch: 6 | loss: 0.3325287\n",
      "\tspeed: 0.0459s/iter; left time: 611.8145s\n",
      "\titers: 300, epoch: 6 | loss: 0.3434712\n",
      "\tspeed: 0.0459s/iter; left time: 607.1119s\n",
      "\titers: 400, epoch: 6 | loss: 0.3417833\n",
      "\tspeed: 0.0459s/iter; left time: 602.6456s\n",
      "\titers: 500, epoch: 6 | loss: 0.3304627\n",
      "\tspeed: 0.0459s/iter; left time: 598.0939s\n",
      "\titers: 600, epoch: 6 | loss: 0.3096986\n",
      "\tspeed: 0.0459s/iter; left time: 593.4194s\n",
      "\titers: 700, epoch: 6 | loss: 0.3188351\n",
      "\tspeed: 0.0459s/iter; left time: 589.0232s\n",
      "\titers: 800, epoch: 6 | loss: 0.3207916\n",
      "\tspeed: 0.0459s/iter; left time: 584.6534s\n",
      "\titers: 900, epoch: 6 | loss: 0.3165942\n",
      "\tspeed: 0.0459s/iter; left time: 580.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 902 | Train Loss: 0.3264330 Vali Loss: 0.3824500 Test Loss: 0.4231836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3252023\n",
      "\tspeed: 0.1254s/iter; left time: 1570.6715s\n",
      "\titers: 200, epoch: 7 | loss: 0.2956451\n",
      "\tspeed: 0.0460s/iter; left time: 571.8627s\n",
      "\titers: 300, epoch: 7 | loss: 0.3121677\n",
      "\tspeed: 0.0460s/iter; left time: 567.0415s\n",
      "\titers: 400, epoch: 7 | loss: 0.3224980\n",
      "\tspeed: 0.0460s/iter; left time: 562.1929s\n",
      "\titers: 500, epoch: 7 | loss: 0.3192953\n",
      "\tspeed: 0.0460s/iter; left time: 557.6396s\n",
      "\titers: 600, epoch: 7 | loss: 0.3228470\n",
      "\tspeed: 0.0460s/iter; left time: 553.4963s\n",
      "\titers: 700, epoch: 7 | loss: 0.3234811\n",
      "\tspeed: 0.0460s/iter; left time: 548.4020s\n",
      "\titers: 800, epoch: 7 | loss: 0.2908741\n",
      "\tspeed: 0.0460s/iter; left time: 544.1635s\n",
      "\titers: 900, epoch: 7 | loss: 0.2781619\n",
      "\tspeed: 0.0460s/iter; left time: 539.1398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 902 | Train Loss: 0.3102664 Vali Loss: 0.3849172 Test Loss: 0.4344090\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3061499\n",
      "\tspeed: 0.1246s/iter; left time: 1448.6184s\n",
      "\titers: 200, epoch: 8 | loss: 0.2870059\n",
      "\tspeed: 0.0460s/iter; left time: 530.1086s\n",
      "\titers: 300, epoch: 8 | loss: 0.3007690\n",
      "\tspeed: 0.0460s/iter; left time: 525.6528s\n",
      "\titers: 400, epoch: 8 | loss: 0.3293248\n",
      "\tspeed: 0.0460s/iter; left time: 520.9789s\n",
      "\titers: 500, epoch: 8 | loss: 0.2685870\n",
      "\tspeed: 0.0460s/iter; left time: 516.2828s\n",
      "\titers: 600, epoch: 8 | loss: 0.2870359\n",
      "\tspeed: 0.0460s/iter; left time: 511.6359s\n",
      "\titers: 700, epoch: 8 | loss: 0.2987286\n",
      "\tspeed: 0.0460s/iter; left time: 507.0246s\n",
      "\titers: 800, epoch: 8 | loss: 0.2776779\n",
      "\tspeed: 0.0460s/iter; left time: 502.2331s\n",
      "\titers: 900, epoch: 8 | loss: 0.2833379\n",
      "\tspeed: 0.0460s/iter; left time: 497.8054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 902 | Train Loss: 0.2932087 Vali Loss: 0.3821450 Test Loss: 0.4211602\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.45692309737205505, rmse:0.675960898399353, mae:0.4327623248100281, rse:0.6190972924232483\n",
      "Original data scale mse:4784611.0, rmse:2187.37548828125, mae:1385.891357421875, rse:0.15407909452915192\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>0.4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.4267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.6020</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>0.5512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4241</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>0.5964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3813</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.5655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3860</td>\n",
       "      <td>0.6213</td>\n",
       "      <td>0.3768</td>\n",
       "      <td>0.5689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3996</td>\n",
       "      <td>0.6322</td>\n",
       "      <td>0.3920</td>\n",
       "      <td>0.5788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.6594</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.6039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4569</td>\n",
       "      <td>0.6760</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>0.6191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2203  0.4694  0.2935  0.4299\n",
       "              2         24        0.2171  0.4659  0.2862  0.4267\n",
       "              1         96        0.3708  0.6090  0.4044  0.5576\n",
       "              2         96        0.3624  0.6020  0.4008  0.5512\n",
       "              1         168       0.4241  0.6512  0.4371  0.5964\n",
       "              2         168       0.3813  0.6175  0.4258  0.5655\n",
       "MAE           1         24        0.2123  0.4607  0.2703  0.4220\n",
       "              2         24        0.2143  0.4629  0.2699  0.4240\n",
       "              1         96        0.3860  0.6213  0.3768  0.5689\n",
       "              2         96        0.3996  0.6322  0.3920  0.5788\n",
       "              1         168       0.4348  0.6594  0.4239  0.6039\n",
       "              2         168       0.4569  0.6760  0.4328  0.6191"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1680994.875</td>\n",
       "      <td>1296.5319</td>\n",
       "      <td>861.9956</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1580196.750</td>\n",
       "      <td>1257.0587</td>\n",
       "      <td>835.5945</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3333727.750</td>\n",
       "      <td>1825.8499</td>\n",
       "      <td>1242.7080</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3329982.000</td>\n",
       "      <td>1824.8239</td>\n",
       "      <td>1235.0143</td>\n",
       "      <td>0.1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4642685.000</td>\n",
       "      <td>2154.6890</td>\n",
       "      <td>1412.2063</td>\n",
       "      <td>0.1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3976689.750</td>\n",
       "      <td>1994.1639</td>\n",
       "      <td>1357.4500</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1440519.500</td>\n",
       "      <td>1200.2164</td>\n",
       "      <td>759.9636</td>\n",
       "      <td>0.0843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1422171.750</td>\n",
       "      <td>1192.5485</td>\n",
       "      <td>752.7681</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2678728.500</td>\n",
       "      <td>1636.6821</td>\n",
       "      <td>1075.3901</td>\n",
       "      <td>0.1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3289923.750</td>\n",
       "      <td>1813.8147</td>\n",
       "      <td>1161.3967</td>\n",
       "      <td>0.1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4242708.000</td>\n",
       "      <td>2059.7834</td>\n",
       "      <td>1329.1781</td>\n",
       "      <td>0.1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4784611.000</td>\n",
       "      <td>2187.3755</td>\n",
       "      <td>1385.8914</td>\n",
       "      <td>0.1541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1680994.875  1296.5319   861.9956  0.0911\n",
       "              2         24        1580196.750  1257.0587   835.5945  0.0883\n",
       "              1         96        3333727.750  1825.8499  1242.7080  0.1285\n",
       "              2         96        3329982.000  1824.8239  1235.0143  0.1284\n",
       "              1         168       4642685.000  2154.6890  1412.2063  0.1518\n",
       "              2         168       3976689.750  1994.1639  1357.4500  0.1405\n",
       "MAE           1         24        1440519.500  1200.2164   759.9636  0.0843\n",
       "              2         24        1422171.750  1192.5485   752.7681  0.0838\n",
       "              1         96        2678728.500  1636.6821  1075.3901  0.1152\n",
       "              2         96        3289923.750  1813.8147  1161.3967  0.1276\n",
       "              1         168       4242708.000  2059.7834  1329.1781  0.1451\n",
       "              2         168       4784611.000  2187.3755  1385.8914  0.1541"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>0.5738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.6055</td>\n",
       "      <td>0.4026</td>\n",
       "      <td>0.5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4459</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.4283</td>\n",
       "      <td>0.6115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4027</td>\n",
       "      <td>0.6344</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.5810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2133  0.4618  0.2701  0.4230\n",
       "         MSE            0.2187  0.4676  0.2899  0.4283\n",
       "96       MAE            0.3928  0.6267  0.3844  0.5738\n",
       "         MSE            0.3666  0.6055  0.4026  0.5544\n",
       "168      MAE            0.4459  0.6677  0.4283  0.6115\n",
       "         MSE            0.4027  0.6344  0.4314  0.5810"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.431346e+06</td>\n",
       "      <td>1196.3824</td>\n",
       "      <td>756.3658</td>\n",
       "      <td>0.0841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.630596e+06</td>\n",
       "      <td>1276.7953</td>\n",
       "      <td>848.7950</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.984326e+06</td>\n",
       "      <td>1725.2484</td>\n",
       "      <td>1118.3934</td>\n",
       "      <td>0.1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.331855e+06</td>\n",
       "      <td>1825.3369</td>\n",
       "      <td>1238.8611</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.513660e+06</td>\n",
       "      <td>2123.5795</td>\n",
       "      <td>1357.5347</td>\n",
       "      <td>0.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.309687e+06</td>\n",
       "      <td>2074.4265</td>\n",
       "      <td>1384.8281</td>\n",
       "      <td>0.1461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.431346e+06  1196.3824   756.3658  0.0841\n",
       "         MSE            1.630596e+06  1276.7953   848.7950  0.0897\n",
       "96       MAE            2.984326e+06  1725.2484  1118.3934  0.1214\n",
       "         MSE            3.331855e+06  1825.3369  1238.8611  0.1285\n",
       "168      MAE            4.513660e+06  2123.5795  1357.5347  0.1496\n",
       "         MSE            4.309687e+06  2074.4265  1384.8281  0.1461"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7115721\n",
      "\tspeed: 0.0475s/iter; left time: 844.4129s\n",
      "\titers: 200, epoch: 1 | loss: 0.5507042\n",
      "\tspeed: 0.0313s/iter; left time: 553.6085s\n",
      "\titers: 300, epoch: 1 | loss: 0.4904538\n",
      "\tspeed: 0.0314s/iter; left time: 551.1303s\n",
      "\titers: 400, epoch: 1 | loss: 0.4336677\n",
      "\tspeed: 0.0315s/iter; left time: 549.6351s\n",
      "\titers: 500, epoch: 1 | loss: 0.5502787\n",
      "\tspeed: 0.0315s/iter; left time: 547.0270s\n",
      "\titers: 600, epoch: 1 | loss: 0.4105817\n",
      "\tspeed: 0.0315s/iter; left time: 544.4683s\n",
      "\titers: 700, epoch: 1 | loss: 0.3281822\n",
      "\tspeed: 0.0315s/iter; left time: 541.1206s\n",
      "\titers: 800, epoch: 1 | loss: 0.3063668\n",
      "\tspeed: 0.0316s/iter; left time: 538.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 893 | Train Loss: 0.5158445 Vali Loss: 0.3272034 Test Loss: 0.3433180\n",
      "Validation loss decreased (inf --> 0.327203).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2450888\n",
      "\tspeed: 0.1233s/iter; left time: 2079.3136s\n",
      "\titers: 200, epoch: 2 | loss: 0.2045712\n",
      "\tspeed: 0.0315s/iter; left time: 528.7154s\n",
      "\titers: 300, epoch: 2 | loss: 0.3276693\n",
      "\tspeed: 0.0315s/iter; left time: 525.7684s\n",
      "\titers: 400, epoch: 2 | loss: 0.2449387\n",
      "\tspeed: 0.0316s/iter; left time: 523.2184s\n",
      "\titers: 500, epoch: 2 | loss: 0.1909926\n",
      "\tspeed: 0.0316s/iter; left time: 520.0801s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 600, epoch: 2 | loss: 0.1344917\n",
      "\tspeed: 0.0316s/iter; left time: 516.8431s\n",
      "\titers: 700, epoch: 2 | loss: 0.2044084\n",
      "\tspeed: 0.0316s/iter; left time: 513.6871s\n",
      "\titers: 800, epoch: 2 | loss: 0.1776914\n",
      "\tspeed: 0.0316s/iter; left time: 510.5148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2219412 Vali Loss: 0.1973972 Test Loss: 0.2222147\n",
      "Validation loss decreased (0.327203 --> 0.197397).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1550447\n",
      "\tspeed: 0.1150s/iter; left time: 1837.0177s\n",
      "\titers: 200, epoch: 3 | loss: 0.2049012\n",
      "\tspeed: 0.0316s/iter; left time: 501.1151s\n",
      "\titers: 300, epoch: 3 | loss: 0.1628761\n",
      "\tspeed: 0.0316s/iter; left time: 497.9564s\n",
      "\titers: 400, epoch: 3 | loss: 0.1779979\n",
      "\tspeed: 0.0316s/iter; left time: 495.1875s\n",
      "\titers: 500, epoch: 3 | loss: 0.1302713\n",
      "\tspeed: 0.0316s/iter; left time: 491.8090s\n",
      "\titers: 600, epoch: 3 | loss: 0.2445797\n",
      "\tspeed: 0.0316s/iter; left time: 488.6225s\n",
      "\titers: 700, epoch: 3 | loss: 0.1402915\n",
      "\tspeed: 0.0316s/iter; left time: 485.5566s\n",
      "\titers: 800, epoch: 3 | loss: 0.2342398\n",
      "\tspeed: 0.0316s/iter; left time: 482.2000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.1909966 Vali Loss: 0.1881811 Test Loss: 0.2058878\n",
      "Validation loss decreased (0.197397 --> 0.188181).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1791987\n",
      "\tspeed: 0.1149s/iter; left time: 1732.5687s\n",
      "\titers: 200, epoch: 4 | loss: 0.1499173\n",
      "\tspeed: 0.0316s/iter; left time: 472.9968s\n",
      "\titers: 300, epoch: 4 | loss: 0.1817994\n",
      "\tspeed: 0.0316s/iter; left time: 470.2858s\n",
      "\titers: 400, epoch: 4 | loss: 0.1488673\n",
      "\tspeed: 0.0316s/iter; left time: 466.8429s\n",
      "\titers: 500, epoch: 4 | loss: 0.1863056\n",
      "\tspeed: 0.0316s/iter; left time: 463.7425s\n",
      "\titers: 600, epoch: 4 | loss: 0.1504370\n",
      "\tspeed: 0.0316s/iter; left time: 460.4314s\n",
      "\titers: 700, epoch: 4 | loss: 0.2184440\n",
      "\tspeed: 0.0316s/iter; left time: 457.3999s\n",
      "\titers: 800, epoch: 4 | loss: 0.1995789\n",
      "\tspeed: 0.0316s/iter; left time: 454.1506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.1824290 Vali Loss: 0.1877502 Test Loss: 0.2050086\n",
      "Validation loss decreased (0.188181 --> 0.187750).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2297120\n",
      "\tspeed: 0.1494s/iter; left time: 2120.0398s\n",
      "\titers: 200, epoch: 5 | loss: 0.1467914\n",
      "\tspeed: 0.0846s/iter; left time: 1191.5150s\n",
      "\titers: 300, epoch: 5 | loss: 0.2450626\n",
      "\tspeed: 0.0883s/iter; left time: 1235.6001s\n",
      "\titers: 400, epoch: 5 | loss: 0.2573461\n",
      "\tspeed: 0.1012s/iter; left time: 1406.1992s\n",
      "\titers: 500, epoch: 5 | loss: 0.1579923\n",
      "\tspeed: 0.0980s/iter; left time: 1351.6148s\n",
      "\titers: 600, epoch: 5 | loss: 0.1456550\n",
      "\tspeed: 0.0822s/iter; left time: 1125.5896s\n",
      "\titers: 700, epoch: 5 | loss: 0.1548489\n",
      "\tspeed: 0.0900s/iter; left time: 1223.5400s\n",
      "\titers: 800, epoch: 5 | loss: 0.1215519\n",
      "\tspeed: 0.0865s/iter; left time: 1166.3027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:18.12s\n",
      "Steps: 893 | Train Loss: 0.1770157 Vali Loss: 0.1825214 Test Loss: 0.2023349\n",
      "Validation loss decreased (0.187750 --> 0.182521).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1890004\n",
      "\tspeed: 0.5345s/iter; left time: 7106.7054s\n",
      "\titers: 200, epoch: 6 | loss: 0.1832414\n",
      "\tspeed: 0.0519s/iter; left time: 685.2622s\n",
      "\titers: 300, epoch: 6 | loss: 0.1470521\n",
      "\tspeed: 0.0475s/iter; left time: 622.3178s\n",
      "\titers: 400, epoch: 6 | loss: 0.1725373\n",
      "\tspeed: 0.0890s/iter; left time: 1156.4028s\n",
      "\titers: 500, epoch: 6 | loss: 0.1658833\n",
      "\tspeed: 0.0380s/iter; left time: 489.8458s\n",
      "\titers: 600, epoch: 6 | loss: 0.2045155\n",
      "\tspeed: 0.0317s/iter; left time: 405.5746s\n",
      "\titers: 700, epoch: 6 | loss: 0.0993592\n",
      "\tspeed: 0.0315s/iter; left time: 399.6039s\n",
      "\titers: 800, epoch: 6 | loss: 0.1488251\n",
      "\tspeed: 0.0313s/iter; left time: 394.0926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.19s\n",
      "Steps: 893 | Train Loss: 0.1727726 Vali Loss: 0.1814266 Test Loss: 0.2005763\n",
      "Validation loss decreased (0.182521 --> 0.181427).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1828355\n",
      "\tspeed: 0.1186s/iter; left time: 1471.4110s\n",
      "\titers: 200, epoch: 7 | loss: 0.1245444\n",
      "\tspeed: 0.0312s/iter; left time: 383.7955s\n",
      "\titers: 300, epoch: 7 | loss: 0.1342298\n",
      "\tspeed: 0.0312s/iter; left time: 381.0717s\n",
      "\titers: 400, epoch: 7 | loss: 0.1847023\n",
      "\tspeed: 0.0313s/iter; left time: 378.3020s\n",
      "\titers: 500, epoch: 7 | loss: 0.1565119\n",
      "\tspeed: 0.0312s/iter; left time: 375.0532s\n",
      "\titers: 600, epoch: 7 | loss: 0.1247160\n",
      "\tspeed: 0.0313s/iter; left time: 372.6198s\n",
      "\titers: 700, epoch: 7 | loss: 0.1267635\n",
      "\tspeed: 0.0313s/iter; left time: 369.4946s\n",
      "\titers: 800, epoch: 7 | loss: 0.1291117\n",
      "\tspeed: 0.0313s/iter; left time: 366.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 893 | Train Loss: 0.1693574 Vali Loss: 0.1807181 Test Loss: 0.2035200\n",
      "Validation loss decreased (0.181427 --> 0.180718).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1983522\n",
      "\tspeed: 0.1174s/iter; left time: 1350.9526s\n",
      "\titers: 200, epoch: 8 | loss: 0.1680878\n",
      "\tspeed: 0.0315s/iter; left time: 359.0747s\n",
      "\titers: 300, epoch: 8 | loss: 0.1934931\n",
      "\tspeed: 0.0315s/iter; left time: 356.3276s\n",
      "\titers: 400, epoch: 8 | loss: 0.1547793\n",
      "\tspeed: 0.0315s/iter; left time: 353.2546s\n",
      "\titers: 500, epoch: 8 | loss: 0.1743437\n",
      "\tspeed: 0.0321s/iter; left time: 356.9376s\n",
      "\titers: 600, epoch: 8 | loss: 0.1659480\n",
      "\tspeed: 0.0635s/iter; left time: 699.3374s\n",
      "\titers: 700, epoch: 8 | loss: 0.1698437\n",
      "\tspeed: 0.0921s/iter; left time: 1005.0241s\n",
      "\titers: 800, epoch: 8 | loss: 0.1259636\n",
      "\tspeed: 0.0902s/iter; left time: 974.8383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.59s\n",
      "Steps: 893 | Train Loss: 0.1664935 Vali Loss: 0.1776384 Test Loss: 0.2019370\n",
      "Validation loss decreased (0.180718 --> 0.177638).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1974452\n",
      "\tspeed: 0.5655s/iter; left time: 6003.7484s\n",
      "\titers: 200, epoch: 9 | loss: 0.1930901\n",
      "\tspeed: 0.0981s/iter; left time: 1032.0475s\n",
      "\titers: 300, epoch: 9 | loss: 0.1371461\n",
      "\tspeed: 0.0965s/iter; left time: 1005.0199s\n",
      "\titers: 400, epoch: 9 | loss: 0.1667616\n",
      "\tspeed: 0.0954s/iter; left time: 984.2196s\n",
      "\titers: 500, epoch: 9 | loss: 0.1464733\n",
      "\tspeed: 0.0983s/iter; left time: 1004.7658s\n",
      "\titers: 600, epoch: 9 | loss: 0.1184142\n",
      "\tspeed: 0.0946s/iter; left time: 957.1690s\n",
      "\titers: 700, epoch: 9 | loss: 0.1472315\n",
      "\tspeed: 0.1081s/iter; left time: 1082.7464s\n",
      "\titers: 800, epoch: 9 | loss: 0.1284741\n",
      "\tspeed: 0.0998s/iter; left time: 989.6699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:28.66s\n",
      "Steps: 893 | Train Loss: 0.1642179 Vali Loss: 0.1814527 Test Loss: 0.2042053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1529788\n",
      "\tspeed: 0.5717s/iter; left time: 5559.4800s\n",
      "\titers: 200, epoch: 10 | loss: 0.1823331\n",
      "\tspeed: 0.0990s/iter; left time: 952.6955s\n",
      "\titers: 300, epoch: 10 | loss: 0.1132455\n",
      "\tspeed: 0.0965s/iter; left time: 918.9324s\n",
      "\titers: 400, epoch: 10 | loss: 0.1696854\n",
      "\tspeed: 0.0970s/iter; left time: 913.7434s\n",
      "\titers: 500, epoch: 10 | loss: 0.1151098\n",
      "\tspeed: 0.0990s/iter; left time: 923.3999s\n",
      "\titers: 600, epoch: 10 | loss: 0.1350601\n",
      "\tspeed: 0.0932s/iter; left time: 860.1214s\n",
      "\titers: 700, epoch: 10 | loss: 0.1453555\n",
      "\tspeed: 0.1002s/iter; left time: 914.6591s\n",
      "\titers: 800, epoch: 10 | loss: 0.1759953\n",
      "\tspeed: 0.0909s/iter; left time: 820.7312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:27.95s\n",
      "Steps: 893 | Train Loss: 0.1621108 Vali Loss: 0.1814588 Test Loss: 0.2033812\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1450501\n",
      "\tspeed: 0.5737s/iter; left time: 5066.1597s\n",
      "\titers: 200, epoch: 11 | loss: 0.1679197\n",
      "\tspeed: 0.1021s/iter; left time: 891.0037s\n",
      "\titers: 300, epoch: 11 | loss: 0.1391447\n",
      "\tspeed: 0.0985s/iter; left time: 850.5277s\n",
      "\titers: 400, epoch: 11 | loss: 0.1507022\n",
      "\tspeed: 0.0933s/iter; left time: 795.7153s\n",
      "\titers: 500, epoch: 11 | loss: 0.1312802\n",
      "\tspeed: 0.1019s/iter; left time: 859.0363s\n",
      "\titers: 600, epoch: 11 | loss: 0.1089376\n",
      "\tspeed: 0.0882s/iter; left time: 734.8388s\n",
      "\titers: 700, epoch: 11 | loss: 0.1551562\n",
      "\tspeed: 0.0927s/iter; left time: 762.8227s\n",
      "\titers: 800, epoch: 11 | loss: 0.1736612\n",
      "\tspeed: 0.0930s/iter; left time: 756.4228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:27.42s\n",
      "Steps: 893 | Train Loss: 0.1595131 Vali Loss: 0.1816549 Test Loss: 0.2038076\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2019370049238205, rmse:0.4493740200996399, mae:0.27185386419296265, rse:0.4115535616874695\n",
      "Original data scale mse:1312173.25, rmse:1145.5013427734375, mae:756.471923828125, rse:0.08049707859754562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7219309\n",
      "\tspeed: 0.0989s/iter; left time: 1756.8997s\n",
      "\titers: 200, epoch: 1 | loss: 0.6133953\n",
      "\tspeed: 0.0786s/iter; left time: 1387.5284s\n",
      "\titers: 300, epoch: 1 | loss: 0.5185424\n",
      "\tspeed: 0.0706s/iter; left time: 1240.3594s\n",
      "\titers: 400, epoch: 1 | loss: 0.4917779\n",
      "\tspeed: 0.0686s/iter; left time: 1197.3925s\n",
      "\titers: 500, epoch: 1 | loss: 0.4100563\n",
      "\tspeed: 0.0620s/iter; left time: 1077.1597s\n",
      "\titers: 600, epoch: 1 | loss: 0.3435362\n",
      "\tspeed: 0.0541s/iter; left time: 934.5308s\n",
      "\titers: 700, epoch: 1 | loss: 0.3281915\n",
      "\tspeed: 0.0528s/iter; left time: 906.4380s\n",
      "\titers: 800, epoch: 1 | loss: 0.4416419\n",
      "\tspeed: 0.0510s/iter; left time: 870.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:58.07s\n",
      "Steps: 893 | Train Loss: 0.5115161 Vali Loss: 0.3302354 Test Loss: 0.3427135\n",
      "Validation loss decreased (inf --> 0.330235).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2239200\n",
      "\tspeed: 0.2151s/iter; left time: 3627.6844s\n",
      "\titers: 200, epoch: 2 | loss: 0.2190194\n",
      "\tspeed: 0.0376s/iter; left time: 630.7319s\n",
      "\titers: 300, epoch: 2 | loss: 0.1713692\n",
      "\tspeed: 0.0377s/iter; left time: 627.7185s\n",
      "\titers: 400, epoch: 2 | loss: 0.2273610\n",
      "\tspeed: 0.0376s/iter; left time: 623.7115s\n",
      "\titers: 500, epoch: 2 | loss: 0.2745308\n",
      "\tspeed: 0.0375s/iter; left time: 617.5794s\n",
      "\titers: 600, epoch: 2 | loss: 0.1923447\n",
      "\tspeed: 0.0376s/iter; left time: 616.1416s\n",
      "\titers: 700, epoch: 2 | loss: 0.1729581\n",
      "\tspeed: 0.0372s/iter; left time: 605.3813s\n",
      "\titers: 800, epoch: 2 | loss: 0.2283264\n",
      "\tspeed: 0.0376s/iter; left time: 607.9523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.94s\n",
      "Steps: 893 | Train Loss: 0.2211204 Vali Loss: 0.1950946 Test Loss: 0.2135102\n",
      "Validation loss decreased (0.330235 --> 0.195095).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2614579\n",
      "\tspeed: 0.1925s/iter; left time: 3075.8578s\n",
      "\titers: 200, epoch: 3 | loss: 0.2411612\n",
      "\tspeed: 0.0356s/iter; left time: 564.4217s\n",
      "\titers: 300, epoch: 3 | loss: 0.2170652\n",
      "\tspeed: 0.0338s/iter; left time: 533.7760s\n",
      "\titers: 400, epoch: 3 | loss: 0.2033328\n",
      "\tspeed: 0.0326s/iter; left time: 510.5345s\n",
      "\titers: 500, epoch: 3 | loss: 0.1873829\n",
      "\tspeed: 0.0329s/iter; left time: 512.5249s\n",
      "\titers: 600, epoch: 3 | loss: 0.2088000\n",
      "\tspeed: 0.0323s/iter; left time: 500.3798s\n",
      "\titers: 700, epoch: 3 | loss: 0.2535047\n",
      "\tspeed: 0.0325s/iter; left time: 499.6134s\n",
      "\titers: 800, epoch: 3 | loss: 0.1580636\n",
      "\tspeed: 0.0323s/iter; left time: 492.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.35s\n",
      "Steps: 893 | Train Loss: 0.1901281 Vali Loss: 0.1918507 Test Loss: 0.2148287\n",
      "Validation loss decreased (0.195095 --> 0.191851).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1910846\n",
      "\tspeed: 0.1276s/iter; left time: 1924.8638s\n",
      "\titers: 200, epoch: 4 | loss: 0.1841216\n",
      "\tspeed: 0.0328s/iter; left time: 491.4157s\n",
      "\titers: 300, epoch: 4 | loss: 0.1567620\n",
      "\tspeed: 0.0323s/iter; left time: 481.0693s\n",
      "\titers: 400, epoch: 4 | loss: 0.1277536\n",
      "\tspeed: 0.0323s/iter; left time: 477.2915s\n",
      "\titers: 500, epoch: 4 | loss: 0.2447009\n",
      "\tspeed: 0.0322s/iter; left time: 472.4887s\n",
      "\titers: 600, epoch: 4 | loss: 0.1902483\n",
      "\tspeed: 0.0323s/iter; left time: 470.4696s\n",
      "\titers: 700, epoch: 4 | loss: 0.1348345\n",
      "\tspeed: 0.0323s/iter; left time: 467.8135s\n",
      "\titers: 800, epoch: 4 | loss: 0.1853374\n",
      "\tspeed: 0.0322s/iter; left time: 462.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.19s\n",
      "Steps: 893 | Train Loss: 0.1818103 Vali Loss: 0.1882270 Test Loss: 0.2059754\n",
      "Validation loss decreased (0.191851 --> 0.188227).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1398451\n",
      "\tspeed: 0.1250s/iter; left time: 1774.0069s\n",
      "\titers: 200, epoch: 5 | loss: 0.1592869\n",
      "\tspeed: 0.0320s/iter; left time: 450.6478s\n",
      "\titers: 300, epoch: 5 | loss: 0.1833869\n",
      "\tspeed: 0.0320s/iter; left time: 447.6788s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195400\n",
      "\tspeed: 0.0320s/iter; left time: 444.6660s\n",
      "\titers: 500, epoch: 5 | loss: 0.1530256\n",
      "\tspeed: 0.0321s/iter; left time: 442.1061s\n",
      "\titers: 600, epoch: 5 | loss: 0.1513401\n",
      "\tspeed: 0.0320s/iter; left time: 438.6921s\n",
      "\titers: 700, epoch: 5 | loss: 0.1396977\n",
      "\tspeed: 0.0320s/iter; left time: 435.2537s\n",
      "\titers: 800, epoch: 5 | loss: 0.1531565\n",
      "\tspeed: 0.0320s/iter; left time: 432.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.00s\n",
      "Steps: 893 | Train Loss: 0.1766973 Vali Loss: 0.1827646 Test Loss: 0.2044723\n",
      "Validation loss decreased (0.188227 --> 0.182765).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1789286\n",
      "\tspeed: 0.1217s/iter; left time: 1618.6293s\n",
      "\titers: 200, epoch: 6 | loss: 0.1609799\n",
      "\tspeed: 0.0319s/iter; left time: 420.8945s\n",
      "\titers: 300, epoch: 6 | loss: 0.2101550\n",
      "\tspeed: 0.0319s/iter; left time: 418.0693s\n",
      "\titers: 400, epoch: 6 | loss: 0.2002501\n",
      "\tspeed: 0.0320s/iter; left time: 416.2065s\n",
      "\titers: 500, epoch: 6 | loss: 0.1507419\n",
      "\tspeed: 0.0320s/iter; left time: 413.2837s\n",
      "\titers: 600, epoch: 6 | loss: 0.1424685\n",
      "\tspeed: 0.0321s/iter; left time: 410.3361s\n",
      "\titers: 700, epoch: 6 | loss: 0.1468622\n",
      "\tspeed: 0.0321s/iter; left time: 407.1254s\n",
      "\titers: 800, epoch: 6 | loss: 0.1674400\n",
      "\tspeed: 0.0320s/iter; left time: 403.6993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.87s\n",
      "Steps: 893 | Train Loss: 0.1723761 Vali Loss: 0.1818055 Test Loss: 0.2037120\n",
      "Validation loss decreased (0.182765 --> 0.181806).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2041469\n",
      "\tspeed: 0.1222s/iter; left time: 1515.9560s\n",
      "\titers: 200, epoch: 7 | loss: 0.1680109\n",
      "\tspeed: 0.0322s/iter; left time: 395.6750s\n",
      "\titers: 300, epoch: 7 | loss: 0.1412251\n",
      "\tspeed: 0.0322s/iter; left time: 392.8885s\n",
      "\titers: 400, epoch: 7 | loss: 0.2074238\n",
      "\tspeed: 0.0322s/iter; left time: 389.7782s\n",
      "\titers: 500, epoch: 7 | loss: 0.2165565\n",
      "\tspeed: 0.0322s/iter; left time: 386.5134s\n",
      "\titers: 600, epoch: 7 | loss: 0.1447392\n",
      "\tspeed: 0.0323s/iter; left time: 383.9428s\n",
      "\titers: 700, epoch: 7 | loss: 0.1693653\n",
      "\tspeed: 0.0323s/iter; left time: 381.0987s\n",
      "\titers: 800, epoch: 7 | loss: 0.1250626\n",
      "\tspeed: 0.0323s/iter; left time: 377.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 893 | Train Loss: 0.1686634 Vali Loss: 0.1813426 Test Loss: 0.2043023\n",
      "Validation loss decreased (0.181806 --> 0.181343).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1835176\n",
      "\tspeed: 0.1249s/iter; left time: 1438.1671s\n",
      "\titers: 200, epoch: 8 | loss: 0.1446326\n",
      "\tspeed: 0.0322s/iter; left time: 367.5026s\n",
      "\titers: 300, epoch: 8 | loss: 0.1494437\n",
      "\tspeed: 0.0323s/iter; left time: 365.2730s\n",
      "\titers: 400, epoch: 8 | loss: 0.1911340\n",
      "\tspeed: 0.0323s/iter; left time: 361.9714s\n",
      "\titers: 500, epoch: 8 | loss: 0.1761708\n",
      "\tspeed: 0.0323s/iter; left time: 358.5645s\n",
      "\titers: 600, epoch: 8 | loss: 0.1726518\n",
      "\tspeed: 0.0322s/iter; left time: 354.5059s\n",
      "\titers: 700, epoch: 8 | loss: 0.1172048\n",
      "\tspeed: 0.0322s/iter; left time: 351.2654s\n",
      "\titers: 800, epoch: 8 | loss: 0.1619110\n",
      "\tspeed: 0.0322s/iter; left time: 348.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.09s\n",
      "Steps: 893 | Train Loss: 0.1658784 Vali Loss: 0.1814213 Test Loss: 0.2043181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1688373\n",
      "\tspeed: 0.1189s/iter; left time: 1262.1997s\n",
      "\titers: 200, epoch: 9 | loss: 0.1561201\n",
      "\tspeed: 0.0322s/iter; left time: 338.4993s\n",
      "\titers: 300, epoch: 9 | loss: 0.1608616\n",
      "\tspeed: 0.0322s/iter; left time: 335.7580s\n",
      "\titers: 400, epoch: 9 | loss: 0.1582914\n",
      "\tspeed: 0.0323s/iter; left time: 333.0154s\n",
      "\titers: 500, epoch: 9 | loss: 0.1720232\n",
      "\tspeed: 0.0322s/iter; left time: 328.9447s\n",
      "\titers: 600, epoch: 9 | loss: 0.1456776\n",
      "\tspeed: 0.0321s/iter; left time: 325.0023s\n",
      "\titers: 700, epoch: 9 | loss: 0.2187583\n",
      "\tspeed: 0.0321s/iter; left time: 321.8674s\n",
      "\titers: 800, epoch: 9 | loss: 0.1321400\n",
      "\tspeed: 0.0321s/iter; left time: 318.6369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 893 | Train Loss: 0.1632227 Vali Loss: 0.1805984 Test Loss: 0.2044907\n",
      "Validation loss decreased (0.181343 --> 0.180598).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1470544\n",
      "\tspeed: 0.1194s/iter; left time: 1161.1746s\n",
      "\titers: 200, epoch: 10 | loss: 0.1544752\n",
      "\tspeed: 0.0321s/iter; left time: 309.2052s\n",
      "\titers: 300, epoch: 10 | loss: 0.1257343\n",
      "\tspeed: 0.0320s/iter; left time: 305.2045s\n",
      "\titers: 400, epoch: 10 | loss: 0.1215282\n",
      "\tspeed: 0.0320s/iter; left time: 301.7974s\n",
      "\titers: 500, epoch: 10 | loss: 0.2250792\n",
      "\tspeed: 0.0320s/iter; left time: 298.7351s\n",
      "\titers: 600, epoch: 10 | loss: 0.1515349\n",
      "\tspeed: 0.0320s/iter; left time: 295.4895s\n",
      "\titers: 700, epoch: 10 | loss: 0.1528929\n",
      "\tspeed: 0.0322s/iter; left time: 294.0858s\n",
      "\titers: 800, epoch: 10 | loss: 0.1416255\n",
      "\tspeed: 0.0320s/iter; left time: 289.2080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.92s\n",
      "Steps: 893 | Train Loss: 0.1608201 Vali Loss: 0.1832188 Test Loss: 0.2045684\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1754676\n",
      "\tspeed: 0.1172s/iter; left time: 1035.3034s\n",
      "\titers: 200, epoch: 11 | loss: 0.1908560\n",
      "\tspeed: 0.0319s/iter; left time: 278.6161s\n",
      "\titers: 300, epoch: 11 | loss: 0.1844759\n",
      "\tspeed: 0.0320s/iter; left time: 275.9357s\n",
      "\titers: 400, epoch: 11 | loss: 0.1556458\n",
      "\tspeed: 0.0319s/iter; left time: 272.2228s\n",
      "\titers: 500, epoch: 11 | loss: 0.1511192\n",
      "\tspeed: 0.0319s/iter; left time: 268.5847s\n",
      "\titers: 600, epoch: 11 | loss: 0.1412127\n",
      "\tspeed: 0.0319s/iter; left time: 265.9134s\n",
      "\titers: 700, epoch: 11 | loss: 0.2110361\n",
      "\tspeed: 0.0320s/iter; left time: 263.0607s\n",
      "\titers: 800, epoch: 11 | loss: 0.1739367\n",
      "\tspeed: 0.0319s/iter; left time: 259.4818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.79s\n",
      "Steps: 893 | Train Loss: 0.1587278 Vali Loss: 0.1799454 Test Loss: 0.2052253\n",
      "Validation loss decreased (0.180598 --> 0.179945).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1697270\n",
      "\tspeed: 0.1182s/iter; left time: 938.3822s\n",
      "\titers: 200, epoch: 12 | loss: 0.1378167\n",
      "\tspeed: 0.0319s/iter; left time: 249.7465s\n",
      "\titers: 300, epoch: 12 | loss: 0.1450365\n",
      "\tspeed: 0.0319s/iter; left time: 246.7476s\n",
      "\titers: 400, epoch: 12 | loss: 0.1571363\n",
      "\tspeed: 0.0319s/iter; left time: 243.4433s\n",
      "\titers: 500, epoch: 12 | loss: 0.1391631\n",
      "\tspeed: 0.0319s/iter; left time: 240.4302s\n",
      "\titers: 600, epoch: 12 | loss: 0.1349751\n",
      "\tspeed: 0.0319s/iter; left time: 237.1121s\n",
      "\titers: 700, epoch: 12 | loss: 0.1458865\n",
      "\tspeed: 0.0318s/iter; left time: 233.6932s\n",
      "\titers: 800, epoch: 12 | loss: 0.1599350\n",
      "\tspeed: 0.0319s/iter; left time: 230.6590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.74s\n",
      "Steps: 893 | Train Loss: 0.1572258 Vali Loss: 0.1820960 Test Loss: 0.2085653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2127008\n",
      "\tspeed: 0.1168s/iter; left time: 822.8477s\n",
      "\titers: 200, epoch: 13 | loss: 0.1334345\n",
      "\tspeed: 0.0319s/iter; left time: 221.3170s\n",
      "\titers: 300, epoch: 13 | loss: 0.1691724\n",
      "\tspeed: 0.0319s/iter; left time: 218.1282s\n",
      "\titers: 400, epoch: 13 | loss: 0.1516244\n",
      "\tspeed: 0.0319s/iter; left time: 214.8833s\n",
      "\titers: 500, epoch: 13 | loss: 0.1543733\n",
      "\tspeed: 0.0319s/iter; left time: 211.7607s\n",
      "\titers: 600, epoch: 13 | loss: 0.1174439\n",
      "\tspeed: 0.0319s/iter; left time: 208.5521s\n",
      "\titers: 700, epoch: 13 | loss: 0.1098477\n",
      "\tspeed: 0.0319s/iter; left time: 205.3780s\n",
      "\titers: 800, epoch: 13 | loss: 0.1474336\n",
      "\tspeed: 0.0319s/iter; left time: 202.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.75s\n",
      "Steps: 893 | Train Loss: 0.1556374 Vali Loss: 0.1811722 Test Loss: 0.2080009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1454503\n",
      "\tspeed: 0.1156s/iter; left time: 711.1237s\n",
      "\titers: 200, epoch: 14 | loss: 0.1211724\n",
      "\tspeed: 0.0318s/iter; left time: 192.6334s\n",
      "\titers: 300, epoch: 14 | loss: 0.1491771\n",
      "\tspeed: 0.0318s/iter; left time: 189.5013s\n",
      "\titers: 400, epoch: 14 | loss: 0.1382432\n",
      "\tspeed: 0.0318s/iter; left time: 186.3344s\n",
      "\titers: 500, epoch: 14 | loss: 0.1228036\n",
      "\tspeed: 0.0318s/iter; left time: 183.1700s\n",
      "\titers: 600, epoch: 14 | loss: 0.1343849\n",
      "\tspeed: 0.0318s/iter; left time: 179.7827s\n",
      "\titers: 700, epoch: 14 | loss: 0.1528351\n",
      "\tspeed: 0.0318s/iter; left time: 176.4074s\n",
      "\titers: 800, epoch: 14 | loss: 0.1507266\n",
      "\tspeed: 0.0318s/iter; left time: 173.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.64s\n",
      "Steps: 893 | Train Loss: 0.1541659 Vali Loss: 0.1827271 Test Loss: 0.2086433\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20522522926330566, rmse:0.453017920255661, mae:0.27248555421829224, rse:0.4148908257484436\n",
      "Original data scale mse:1321465.125, rmse:1149.5499267578125, mae:759.6286010742188, rse:0.08078158646821976\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8687953\n",
      "\tspeed: 0.0514s/iter; left time: 910.3080s\n",
      "\titers: 200, epoch: 1 | loss: 0.6752395\n",
      "\tspeed: 0.0323s/iter; left time: 568.4519s\n",
      "\titers: 300, epoch: 1 | loss: 0.6096700\n",
      "\tspeed: 0.0323s/iter; left time: 565.1278s\n",
      "\titers: 400, epoch: 1 | loss: 0.4843620\n",
      "\tspeed: 0.0323s/iter; left time: 563.4427s\n",
      "\titers: 500, epoch: 1 | loss: 0.4535579\n",
      "\tspeed: 0.0343s/iter; left time: 593.9407s\n",
      "\titers: 600, epoch: 1 | loss: 0.4970736\n",
      "\tspeed: 0.0324s/iter; left time: 557.1785s\n",
      "\titers: 700, epoch: 1 | loss: 0.4186538\n",
      "\tspeed: 0.0321s/iter; left time: 549.2189s\n",
      "\titers: 800, epoch: 1 | loss: 0.4138215\n",
      "\tspeed: 0.0321s/iter; left time: 545.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 891 | Train Loss: 0.5873678 Vali Loss: 0.4241488 Test Loss: 0.4349606\n",
      "Validation loss decreased (inf --> 0.424149).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4331522\n",
      "\tspeed: 0.1173s/iter; left time: 1974.0055s\n",
      "\titers: 200, epoch: 2 | loss: 0.2740224\n",
      "\tspeed: 0.0324s/iter; left time: 541.3627s\n",
      "\titers: 300, epoch: 2 | loss: 0.3394139\n",
      "\tspeed: 0.0324s/iter; left time: 538.2997s\n",
      "\titers: 400, epoch: 2 | loss: 0.3355964\n",
      "\tspeed: 0.0324s/iter; left time: 535.7519s\n",
      "\titers: 500, epoch: 2 | loss: 0.3067711\n",
      "\tspeed: 0.0324s/iter; left time: 531.9843s\n",
      "\titers: 600, epoch: 2 | loss: 0.3417076\n",
      "\tspeed: 0.0324s/iter; left time: 529.1743s\n",
      "\titers: 700, epoch: 2 | loss: 0.3917704\n",
      "\tspeed: 0.0324s/iter; left time: 526.0489s\n",
      "\titers: 800, epoch: 2 | loss: 0.3547277\n",
      "\tspeed: 0.0324s/iter; left time: 522.4086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 891 | Train Loss: 0.3611521 Vali Loss: 0.3410858 Test Loss: 0.3542138\n",
      "Validation loss decreased (0.424149 --> 0.341086).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3436865\n",
      "\tspeed: 0.1194s/iter; left time: 1902.8471s\n",
      "\titers: 200, epoch: 3 | loss: 0.3284120\n",
      "\tspeed: 0.0325s/iter; left time: 515.4166s\n",
      "\titers: 300, epoch: 3 | loss: 0.2872005\n",
      "\tspeed: 0.0324s/iter; left time: 510.5065s\n",
      "\titers: 400, epoch: 3 | loss: 0.3130924\n",
      "\tspeed: 0.0324s/iter; left time: 506.2322s\n",
      "\titers: 500, epoch: 3 | loss: 0.3699544\n",
      "\tspeed: 0.0324s/iter; left time: 503.5933s\n",
      "\titers: 600, epoch: 3 | loss: 0.3171983\n",
      "\tspeed: 0.0325s/iter; left time: 501.1264s\n",
      "\titers: 700, epoch: 3 | loss: 0.3574215\n",
      "\tspeed: 0.0325s/iter; left time: 497.8315s\n",
      "\titers: 800, epoch: 3 | loss: 0.2528096\n",
      "\tspeed: 0.0325s/iter; left time: 495.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.18s\n",
      "Steps: 891 | Train Loss: 0.3261789 Vali Loss: 0.3329804 Test Loss: 0.3541793\n",
      "Validation loss decreased (0.341086 --> 0.332980).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4034785\n",
      "\tspeed: 0.1231s/iter; left time: 1853.1074s\n",
      "\titers: 200, epoch: 4 | loss: 0.3417699\n",
      "\tspeed: 0.0323s/iter; left time: 483.5285s\n",
      "\titers: 300, epoch: 4 | loss: 0.3784653\n",
      "\tspeed: 0.0324s/iter; left time: 480.7259s\n",
      "\titers: 400, epoch: 4 | loss: 0.3640740\n",
      "\tspeed: 0.0324s/iter; left time: 478.0339s\n",
      "\titers: 500, epoch: 4 | loss: 0.3861934\n",
      "\tspeed: 0.0324s/iter; left time: 474.6079s\n",
      "\titers: 600, epoch: 4 | loss: 0.3308927\n",
      "\tspeed: 0.0324s/iter; left time: 471.2840s\n",
      "\titers: 700, epoch: 4 | loss: 0.3022046\n",
      "\tspeed: 0.0324s/iter; left time: 467.9333s\n",
      "\titers: 800, epoch: 4 | loss: 0.3465479\n",
      "\tspeed: 0.0324s/iter; left time: 465.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.09s\n",
      "Steps: 891 | Train Loss: 0.3142648 Vali Loss: 0.3350371 Test Loss: 0.3627731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3167041\n",
      "\tspeed: 0.1159s/iter; left time: 1640.9776s\n",
      "\titers: 200, epoch: 5 | loss: 0.3534675\n",
      "\tspeed: 0.0324s/iter; left time: 454.9940s\n",
      "\titers: 300, epoch: 5 | loss: 0.3455953\n",
      "\tspeed: 0.0324s/iter; left time: 451.8206s\n",
      "\titers: 400, epoch: 5 | loss: 0.2774753\n",
      "\tspeed: 0.0324s/iter; left time: 448.9112s\n",
      "\titers: 500, epoch: 5 | loss: 0.2820708\n",
      "\tspeed: 0.0324s/iter; left time: 445.2273s\n",
      "\titers: 600, epoch: 5 | loss: 0.3190175\n",
      "\tspeed: 0.0323s/iter; left time: 441.4991s\n",
      "\titers: 700, epoch: 5 | loss: 0.2429793\n",
      "\tspeed: 0.0324s/iter; left time: 438.8337s\n",
      "\titers: 800, epoch: 5 | loss: 0.2792119\n",
      "\tspeed: 0.0324s/iter; left time: 435.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 891 | Train Loss: 0.3012146 Vali Loss: 0.3476683 Test Loss: 0.3655497\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3442821\n",
      "\tspeed: 0.1163s/iter; left time: 1542.1877s\n",
      "\titers: 200, epoch: 6 | loss: 0.2784532\n",
      "\tspeed: 0.0324s/iter; left time: 427.1305s\n",
      "\titers: 300, epoch: 6 | loss: 0.2469601\n",
      "\tspeed: 0.0325s/iter; left time: 424.0205s\n",
      "\titers: 400, epoch: 6 | loss: 0.3586939\n",
      "\tspeed: 0.0324s/iter; left time: 420.4834s\n",
      "\titers: 500, epoch: 6 | loss: 0.2707564\n",
      "\tspeed: 0.0324s/iter; left time: 417.0436s\n",
      "\titers: 600, epoch: 6 | loss: 0.2368994\n",
      "\tspeed: 0.0324s/iter; left time: 414.1730s\n",
      "\titers: 700, epoch: 6 | loss: 0.2981693\n",
      "\tspeed: 0.0324s/iter; left time: 410.4682s\n",
      "\titers: 800, epoch: 6 | loss: 0.3097724\n",
      "\tspeed: 0.0324s/iter; left time: 407.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 891 | Train Loss: 0.2898923 Vali Loss: 0.3634784 Test Loss: 0.3777666\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.35417935252189636, rmse:0.595129668712616, mae:0.3813801109790802, rse:0.5449035167694092\n",
      "Original data scale mse:2694919.0, rmse:1641.620849609375, mae:1102.18798828125, rse:0.11552756279706955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7851738\n",
      "\tspeed: 0.0343s/iter; left time: 607.6080s\n",
      "\titers: 200, epoch: 1 | loss: 0.6105053\n",
      "\tspeed: 0.0321s/iter; left time: 564.9756s\n",
      "\titers: 300, epoch: 1 | loss: 0.5314367\n",
      "\tspeed: 0.0320s/iter; left time: 561.5031s\n",
      "\titers: 400, epoch: 1 | loss: 0.4953493\n",
      "\tspeed: 0.0324s/iter; left time: 564.3446s\n",
      "\titers: 500, epoch: 1 | loss: 0.4712453\n",
      "\tspeed: 0.0325s/iter; left time: 562.4811s\n",
      "\titers: 600, epoch: 1 | loss: 0.5267744\n",
      "\tspeed: 0.0325s/iter; left time: 560.1363s\n",
      "\titers: 700, epoch: 1 | loss: 0.4998352\n",
      "\tspeed: 0.0325s/iter; left time: 556.7239s\n",
      "\titers: 800, epoch: 1 | loss: 0.4044023\n",
      "\tspeed: 0.0324s/iter; left time: 552.0687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.05s\n",
      "Steps: 891 | Train Loss: 0.5843011 Vali Loss: 0.4263145 Test Loss: 0.4385482\n",
      "Validation loss decreased (inf --> 0.426315).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4811377\n",
      "\tspeed: 0.1190s/iter; left time: 2003.1018s\n",
      "\titers: 200, epoch: 2 | loss: 0.3932590\n",
      "\tspeed: 0.0324s/iter; left time: 541.7130s\n",
      "\titers: 300, epoch: 2 | loss: 0.3535902\n",
      "\tspeed: 0.0324s/iter; left time: 538.7078s\n",
      "\titers: 400, epoch: 2 | loss: 0.2928059\n",
      "\tspeed: 0.0324s/iter; left time: 535.8260s\n",
      "\titers: 500, epoch: 2 | loss: 0.3092028\n",
      "\tspeed: 0.0324s/iter; left time: 532.1338s\n",
      "\titers: 600, epoch: 2 | loss: 0.3792779\n",
      "\tspeed: 0.0324s/iter; left time: 528.8210s\n",
      "\titers: 700, epoch: 2 | loss: 0.3401310\n",
      "\tspeed: 0.0324s/iter; left time: 525.4656s\n",
      "\titers: 800, epoch: 2 | loss: 0.3505719\n",
      "\tspeed: 0.0324s/iter; left time: 522.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.12s\n",
      "Steps: 891 | Train Loss: 0.3610939 Vali Loss: 0.3339284 Test Loss: 0.3566892\n",
      "Validation loss decreased (0.426315 --> 0.333928).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3481597\n",
      "\tspeed: 0.1203s/iter; left time: 1918.2507s\n",
      "\titers: 200, epoch: 3 | loss: 0.2898208\n",
      "\tspeed: 0.0323s/iter; left time: 512.2357s\n",
      "\titers: 300, epoch: 3 | loss: 0.3266286\n",
      "\tspeed: 0.0324s/iter; left time: 509.8899s\n",
      "\titers: 400, epoch: 3 | loss: 0.3000391\n",
      "\tspeed: 0.0324s/iter; left time: 506.4385s\n",
      "\titers: 500, epoch: 3 | loss: 0.2742831\n",
      "\tspeed: 0.0324s/iter; left time: 503.1537s\n",
      "\titers: 600, epoch: 3 | loss: 0.3130276\n",
      "\tspeed: 0.0324s/iter; left time: 500.0794s\n",
      "\titers: 700, epoch: 3 | loss: 0.3235125\n",
      "\tspeed: 0.0324s/iter; left time: 496.6949s\n",
      "\titers: 800, epoch: 3 | loss: 0.2952645\n",
      "\tspeed: 0.0324s/iter; left time: 493.2505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.12s\n",
      "Steps: 891 | Train Loss: 0.3276658 Vali Loss: 0.3379722 Test Loss: 0.3532803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3226508\n",
      "\tspeed: 0.1159s/iter; left time: 1743.3469s\n",
      "\titers: 200, epoch: 4 | loss: 0.3677955\n",
      "\tspeed: 0.0325s/iter; left time: 485.0999s\n",
      "\titers: 300, epoch: 4 | loss: 0.3277742\n",
      "\tspeed: 0.0325s/iter; left time: 481.9419s\n",
      "\titers: 400, epoch: 4 | loss: 0.2929807\n",
      "\tspeed: 0.0325s/iter; left time: 479.1210s\n",
      "\titers: 500, epoch: 4 | loss: 0.3178971\n",
      "\tspeed: 0.0325s/iter; left time: 476.1053s\n",
      "\titers: 600, epoch: 4 | loss: 0.3013581\n",
      "\tspeed: 0.0324s/iter; left time: 471.9245s\n",
      "\titers: 700, epoch: 4 | loss: 0.3198916\n",
      "\tspeed: 0.0324s/iter; left time: 468.7119s\n",
      "\titers: 800, epoch: 4 | loss: 0.3611475\n",
      "\tspeed: 0.0325s/iter; left time: 465.8216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 891 | Train Loss: 0.3161601 Vali Loss: 0.3317240 Test Loss: 0.3525242\n",
      "Validation loss decreased (0.333928 --> 0.331724).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3422648\n",
      "\tspeed: 0.1191s/iter; left time: 1685.4538s\n",
      "\titers: 200, epoch: 5 | loss: 0.2471191\n",
      "\tspeed: 0.0323s/iter; left time: 454.3642s\n",
      "\titers: 300, epoch: 5 | loss: 0.2370705\n",
      "\tspeed: 0.0324s/iter; left time: 451.7186s\n",
      "\titers: 400, epoch: 5 | loss: 0.3224496\n",
      "\tspeed: 0.0324s/iter; left time: 448.7245s\n",
      "\titers: 500, epoch: 5 | loss: 0.2995226\n",
      "\tspeed: 0.0324s/iter; left time: 446.1078s\n",
      "\titers: 600, epoch: 5 | loss: 0.2766058\n",
      "\tspeed: 0.0324s/iter; left time: 442.5935s\n",
      "\titers: 700, epoch: 5 | loss: 0.3354356\n",
      "\tspeed: 0.0324s/iter; left time: 439.5230s\n",
      "\titers: 800, epoch: 5 | loss: 0.3222758\n",
      "\tspeed: 0.0324s/iter; left time: 436.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.13s\n",
      "Steps: 891 | Train Loss: 0.3039154 Vali Loss: 0.3418694 Test Loss: 0.3641959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2671846\n",
      "\tspeed: 0.1169s/iter; left time: 1550.5771s\n",
      "\titers: 200, epoch: 6 | loss: 0.2691176\n",
      "\tspeed: 0.0324s/iter; left time: 426.0047s\n",
      "\titers: 300, epoch: 6 | loss: 0.2525728\n",
      "\tspeed: 0.0324s/iter; left time: 423.0239s\n",
      "\titers: 400, epoch: 6 | loss: 0.2659838\n",
      "\tspeed: 0.0324s/iter; left time: 419.5907s\n",
      "\titers: 500, epoch: 6 | loss: 0.2840540\n",
      "\tspeed: 0.0324s/iter; left time: 416.5240s\n",
      "\titers: 600, epoch: 6 | loss: 0.3546274\n",
      "\tspeed: 0.0324s/iter; left time: 413.6400s\n",
      "\titers: 700, epoch: 6 | loss: 0.2477082\n",
      "\tspeed: 0.0324s/iter; left time: 410.0324s\n",
      "\titers: 800, epoch: 6 | loss: 0.2783850\n",
      "\tspeed: 0.0324s/iter; left time: 406.6509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.08s\n",
      "Steps: 891 | Train Loss: 0.2932275 Vali Loss: 0.3636852 Test Loss: 0.3717092\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2467491\n",
      "\tspeed: 0.1159s/iter; left time: 1434.6028s\n",
      "\titers: 200, epoch: 7 | loss: 0.3023964\n",
      "\tspeed: 0.0325s/iter; left time: 398.3884s\n",
      "\titers: 300, epoch: 7 | loss: 0.3874838\n",
      "\tspeed: 0.0324s/iter; left time: 394.3356s\n",
      "\titers: 400, epoch: 7 | loss: 0.3654455\n",
      "\tspeed: 0.0323s/iter; left time: 390.5406s\n",
      "\titers: 500, epoch: 7 | loss: 0.3107609\n",
      "\tspeed: 0.0323s/iter; left time: 386.7629s\n",
      "\titers: 600, epoch: 7 | loss: 0.3386610\n",
      "\tspeed: 0.0324s/iter; left time: 385.1401s\n",
      "\titers: 700, epoch: 7 | loss: 0.2955678\n",
      "\tspeed: 0.0325s/iter; left time: 382.6739s\n",
      "\titers: 800, epoch: 7 | loss: 0.2618113\n",
      "\tspeed: 0.0323s/iter; left time: 377.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.13s\n",
      "Steps: 891 | Train Loss: 0.2838475 Vali Loss: 0.3612177 Test Loss: 0.3787090\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.352524071931839, rmse:0.5937373638153076, mae:0.37898802757263184, rse:0.5436287522315979\n",
      "Original data scale mse:2625019.0, rmse:1620.1910400390625, mae:1093.866455078125, rse:0.11401946097612381\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8537032\n",
      "\tspeed: 0.0534s/iter; left time: 943.8821s\n",
      "\titers: 200, epoch: 1 | loss: 0.5695519\n",
      "\tspeed: 0.0325s/iter; left time: 571.1529s\n",
      "\titers: 300, epoch: 1 | loss: 0.5451734\n",
      "\tspeed: 0.0325s/iter; left time: 568.7070s\n",
      "\titers: 400, epoch: 1 | loss: 0.6487391\n",
      "\tspeed: 0.0326s/iter; left time: 567.2565s\n",
      "\titers: 500, epoch: 1 | loss: 0.5722955\n",
      "\tspeed: 0.0327s/iter; left time: 564.6763s\n",
      "\titers: 600, epoch: 1 | loss: 0.5328101\n",
      "\tspeed: 0.0327s/iter; left time: 561.3198s\n",
      "\titers: 700, epoch: 1 | loss: 0.5296453\n",
      "\tspeed: 0.0327s/iter; left time: 558.7034s\n",
      "\titers: 800, epoch: 1 | loss: 0.4887833\n",
      "\tspeed: 0.0327s/iter; left time: 555.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.47s\n",
      "Steps: 889 | Train Loss: 0.6048403 Vali Loss: 0.4450696 Test Loss: 0.4478828\n",
      "Validation loss decreased (inf --> 0.445070).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4536391\n",
      "\tspeed: 0.1167s/iter; left time: 1959.7346s\n",
      "\titers: 200, epoch: 2 | loss: 0.4180069\n",
      "\tspeed: 0.0326s/iter; left time: 544.4016s\n",
      "\titers: 300, epoch: 2 | loss: 0.4597606\n",
      "\tspeed: 0.0326s/iter; left time: 541.0180s\n",
      "\titers: 400, epoch: 2 | loss: 0.3618578\n",
      "\tspeed: 0.0326s/iter; left time: 538.3290s\n",
      "\titers: 500, epoch: 2 | loss: 0.3676082\n",
      "\tspeed: 0.0326s/iter; left time: 534.2298s\n",
      "\titers: 600, epoch: 2 | loss: 0.4104816\n",
      "\tspeed: 0.0326s/iter; left time: 530.8460s\n",
      "\titers: 700, epoch: 2 | loss: 0.3547207\n",
      "\tspeed: 0.0326s/iter; left time: 527.3446s\n",
      "\titers: 800, epoch: 2 | loss: 0.4136699\n",
      "\tspeed: 0.0326s/iter; left time: 524.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 889 | Train Loss: 0.3887345 Vali Loss: 0.3712647 Test Loss: 0.3798449\n",
      "Validation loss decreased (0.445070 --> 0.371265).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3531785\n",
      "\tspeed: 0.1196s/iter; left time: 1901.2770s\n",
      "\titers: 200, epoch: 3 | loss: 0.3907917\n",
      "\tspeed: 0.0327s/iter; left time: 516.8364s\n",
      "\titers: 300, epoch: 3 | loss: 0.4181572\n",
      "\tspeed: 0.0327s/iter; left time: 513.5811s\n",
      "\titers: 400, epoch: 3 | loss: 0.3879940\n",
      "\tspeed: 0.0327s/iter; left time: 510.4947s\n",
      "\titers: 500, epoch: 3 | loss: 0.3243119\n",
      "\tspeed: 0.0327s/iter; left time: 507.0784s\n",
      "\titers: 600, epoch: 3 | loss: 0.3153468\n",
      "\tspeed: 0.0327s/iter; left time: 504.2163s\n",
      "\titers: 700, epoch: 3 | loss: 0.3420871\n",
      "\tspeed: 0.0327s/iter; left time: 500.4315s\n",
      "\titers: 800, epoch: 3 | loss: 0.3690082\n",
      "\tspeed: 0.0327s/iter; left time: 497.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.30s\n",
      "Steps: 889 | Train Loss: 0.3530936 Vali Loss: 0.3692195 Test Loss: 0.3829071\n",
      "Validation loss decreased (0.371265 --> 0.369219).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3389340\n",
      "\tspeed: 0.1171s/iter; left time: 1758.7537s\n",
      "\titers: 200, epoch: 4 | loss: 0.3184113\n",
      "\tspeed: 0.0326s/iter; left time: 486.5408s\n",
      "\titers: 300, epoch: 4 | loss: 0.3661776\n",
      "\tspeed: 0.0326s/iter; left time: 482.7483s\n",
      "\titers: 400, epoch: 4 | loss: 0.3185847\n",
      "\tspeed: 0.0326s/iter; left time: 479.8903s\n",
      "\titers: 500, epoch: 4 | loss: 0.2722640\n",
      "\tspeed: 0.0326s/iter; left time: 476.8088s\n",
      "\titers: 600, epoch: 4 | loss: 0.2940600\n",
      "\tspeed: 0.0326s/iter; left time: 473.0571s\n",
      "\titers: 700, epoch: 4 | loss: 0.3337396\n",
      "\tspeed: 0.0326s/iter; left time: 470.0650s\n",
      "\titers: 800, epoch: 4 | loss: 0.3283527\n",
      "\tspeed: 0.0326s/iter; left time: 466.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 889 | Train Loss: 0.3385745 Vali Loss: 0.3827470 Test Loss: 0.3955583\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3435049\n",
      "\tspeed: 0.1152s/iter; left time: 1627.5221s\n",
      "\titers: 200, epoch: 5 | loss: 0.2807623\n",
      "\tspeed: 0.0326s/iter; left time: 457.3379s\n",
      "\titers: 300, epoch: 5 | loss: 0.3043932\n",
      "\tspeed: 0.0326s/iter; left time: 453.9326s\n",
      "\titers: 400, epoch: 5 | loss: 0.3380823\n",
      "\tspeed: 0.0326s/iter; left time: 450.8955s\n",
      "\titers: 500, epoch: 5 | loss: 0.3248403\n",
      "\tspeed: 0.0326s/iter; left time: 448.0759s\n",
      "\titers: 600, epoch: 5 | loss: 0.2928286\n",
      "\tspeed: 0.0326s/iter; left time: 444.8373s\n",
      "\titers: 700, epoch: 5 | loss: 0.3670836\n",
      "\tspeed: 0.0326s/iter; left time: 441.2913s\n",
      "\titers: 800, epoch: 5 | loss: 0.3272755\n",
      "\tspeed: 0.0326s/iter; left time: 438.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.24s\n",
      "Steps: 889 | Train Loss: 0.3244906 Vali Loss: 0.3741144 Test Loss: 0.4142777\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2680669\n",
      "\tspeed: 0.1159s/iter; left time: 1533.8618s\n",
      "\titers: 200, epoch: 6 | loss: 0.3396250\n",
      "\tspeed: 0.0328s/iter; left time: 431.5149s\n",
      "\titers: 300, epoch: 6 | loss: 0.3213683\n",
      "\tspeed: 0.0328s/iter; left time: 428.1732s\n",
      "\titers: 400, epoch: 6 | loss: 0.2747234\n",
      "\tspeed: 0.0328s/iter; left time: 424.4658s\n",
      "\titers: 500, epoch: 6 | loss: 0.2895899\n",
      "\tspeed: 0.0328s/iter; left time: 420.8533s\n",
      "\titers: 600, epoch: 6 | loss: 0.3004614\n",
      "\tspeed: 0.0328s/iter; left time: 417.3851s\n",
      "\titers: 700, epoch: 6 | loss: 0.3177295\n",
      "\tspeed: 0.0328s/iter; left time: 414.2572s\n",
      "\titers: 800, epoch: 6 | loss: 0.2946863\n",
      "\tspeed: 0.0328s/iter; left time: 410.8379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 889 | Train Loss: 0.3110130 Vali Loss: 0.3948340 Test Loss: 0.4245331\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3829072415828705, rmse:0.6187949776649475, mae:0.40458106994628906, rse:0.5667403936386108\n",
      "Original data scale mse:3139875.25, rmse:1771.9693603515625, mae:1196.216552734375, rse:0.12481781840324402\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7753379\n",
      "\tspeed: 0.0353s/iter; left time: 624.0495s\n",
      "\titers: 200, epoch: 1 | loss: 0.6809441\n",
      "\tspeed: 0.0328s/iter; left time: 576.6113s\n",
      "\titers: 300, epoch: 1 | loss: 0.6004956\n",
      "\tspeed: 0.0328s/iter; left time: 572.7973s\n",
      "\titers: 400, epoch: 1 | loss: 0.5337401\n",
      "\tspeed: 0.0328s/iter; left time: 569.3198s\n",
      "\titers: 500, epoch: 1 | loss: 0.5757738\n",
      "\tspeed: 0.0327s/iter; left time: 565.8182s\n",
      "\titers: 600, epoch: 1 | loss: 0.5145159\n",
      "\tspeed: 0.0328s/iter; left time: 563.6574s\n",
      "\titers: 700, epoch: 1 | loss: 0.4887009\n",
      "\tspeed: 0.0328s/iter; left time: 559.5224s\n",
      "\titers: 800, epoch: 1 | loss: 0.4870414\n",
      "\tspeed: 0.0328s/iter; left time: 556.6510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.42s\n",
      "Steps: 889 | Train Loss: 0.6012810 Vali Loss: 0.4462638 Test Loss: 0.4495331\n",
      "Validation loss decreased (inf --> 0.446264).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4142169\n",
      "\tspeed: 0.1187s/iter; left time: 1992.5153s\n",
      "\titers: 200, epoch: 2 | loss: 0.4274948\n",
      "\tspeed: 0.0328s/iter; left time: 546.8838s\n",
      "\titers: 300, epoch: 2 | loss: 0.4309711\n",
      "\tspeed: 0.0328s/iter; left time: 543.9843s\n",
      "\titers: 400, epoch: 2 | loss: 0.3883498\n",
      "\tspeed: 0.0328s/iter; left time: 540.4838s\n",
      "\titers: 500, epoch: 2 | loss: 0.4314784\n",
      "\tspeed: 0.0328s/iter; left time: 537.1751s\n",
      "\titers: 600, epoch: 2 | loss: 0.3775866\n",
      "\tspeed: 0.0328s/iter; left time: 534.1817s\n",
      "\titers: 700, epoch: 2 | loss: 0.3924968\n",
      "\tspeed: 0.0328s/iter; left time: 531.1924s\n",
      "\titers: 800, epoch: 2 | loss: 0.3988679\n",
      "\tspeed: 0.0327s/iter; left time: 526.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 889 | Train Loss: 0.3877668 Vali Loss: 0.3688564 Test Loss: 0.3796367\n",
      "Validation loss decreased (0.446264 --> 0.368856).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3502907\n",
      "\tspeed: 0.1196s/iter; left time: 1902.1342s\n",
      "\titers: 200, epoch: 3 | loss: 0.3600634\n",
      "\tspeed: 0.0328s/iter; left time: 517.8057s\n",
      "\titers: 300, epoch: 3 | loss: 0.3186027\n",
      "\tspeed: 0.0328s/iter; left time: 514.7201s\n",
      "\titers: 400, epoch: 3 | loss: 0.3588612\n",
      "\tspeed: 0.0328s/iter; left time: 512.2551s\n",
      "\titers: 500, epoch: 3 | loss: 0.3601991\n",
      "\tspeed: 0.0329s/iter; left time: 510.4346s\n",
      "\titers: 600, epoch: 3 | loss: 0.3274461\n",
      "\tspeed: 0.0329s/iter; left time: 507.4223s\n",
      "\titers: 700, epoch: 3 | loss: 0.3670895\n",
      "\tspeed: 0.0329s/iter; left time: 503.2669s\n",
      "\titers: 800, epoch: 3 | loss: 0.3449373\n",
      "\tspeed: 0.0330s/iter; left time: 501.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 889 | Train Loss: 0.3521828 Vali Loss: 0.3717173 Test Loss: 0.3826810\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3695828\n",
      "\tspeed: 0.1168s/iter; left time: 1753.6706s\n",
      "\titers: 200, epoch: 4 | loss: 0.3586979\n",
      "\tspeed: 0.0329s/iter; left time: 491.1676s\n",
      "\titers: 300, epoch: 4 | loss: 0.3045539\n",
      "\tspeed: 0.0329s/iter; left time: 487.4922s\n",
      "\titers: 400, epoch: 4 | loss: 0.3626105\n",
      "\tspeed: 0.0329s/iter; left time: 484.6449s\n",
      "\titers: 500, epoch: 4 | loss: 0.3160306\n",
      "\tspeed: 0.0329s/iter; left time: 481.0237s\n",
      "\titers: 600, epoch: 4 | loss: 0.3227006\n",
      "\tspeed: 0.0329s/iter; left time: 478.0260s\n",
      "\titers: 700, epoch: 4 | loss: 0.3472717\n",
      "\tspeed: 0.0329s/iter; left time: 474.5572s\n",
      "\titers: 800, epoch: 4 | loss: 0.3122483\n",
      "\tspeed: 0.0330s/iter; left time: 471.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.56s\n",
      "Steps: 889 | Train Loss: 0.3372330 Vali Loss: 0.3813899 Test Loss: 0.3986235\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3665446\n",
      "\tspeed: 0.1168s/iter; left time: 1649.0938s\n",
      "\titers: 200, epoch: 5 | loss: 0.3180199\n",
      "\tspeed: 0.0329s/iter; left time: 461.5570s\n",
      "\titers: 300, epoch: 5 | loss: 0.3623837\n",
      "\tspeed: 0.0329s/iter; left time: 458.3781s\n",
      "\titers: 400, epoch: 5 | loss: 0.3258888\n",
      "\tspeed: 0.0330s/iter; left time: 455.9849s\n",
      "\titers: 500, epoch: 5 | loss: 0.3628269\n",
      "\tspeed: 0.0329s/iter; left time: 452.0049s\n",
      "\titers: 600, epoch: 5 | loss: 0.3343900\n",
      "\tspeed: 0.0329s/iter; left time: 448.2097s\n",
      "\titers: 700, epoch: 5 | loss: 0.3423249\n",
      "\tspeed: 0.0329s/iter; left time: 444.9867s\n",
      "\titers: 800, epoch: 5 | loss: 0.3108262\n",
      "\tspeed: 0.0329s/iter; left time: 442.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.57s\n",
      "Steps: 889 | Train Loss: 0.3220020 Vali Loss: 0.3818478 Test Loss: 0.4030247\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.37963664531707764, rmse:0.6161466240882874, mae:0.4080275297164917, rse:0.5643148422241211\n",
      "Original data scale mse:3260984.75, rmse:1805.8197021484375, mae:1226.39453125, rse:0.12720224261283875\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6555070\n",
      "\tspeed: 0.0534s/iter; left time: 947.7891s\n",
      "\titers: 200, epoch: 1 | loss: 0.5591167\n",
      "\tspeed: 0.0315s/iter; left time: 556.5296s\n",
      "\titers: 300, epoch: 1 | loss: 0.4975783\n",
      "\tspeed: 0.0315s/iter; left time: 553.9401s\n",
      "\titers: 400, epoch: 1 | loss: 0.4610074\n",
      "\tspeed: 0.0315s/iter; left time: 550.8656s\n",
      "\titers: 500, epoch: 1 | loss: 0.5216176\n",
      "\tspeed: 0.0316s/iter; left time: 549.2264s\n",
      "\titers: 600, epoch: 1 | loss: 0.4650809\n",
      "\tspeed: 0.0316s/iter; left time: 545.0570s\n",
      "\titers: 700, epoch: 1 | loss: 0.4156896\n",
      "\tspeed: 0.0315s/iter; left time: 541.1575s\n",
      "\titers: 800, epoch: 1 | loss: 0.4012448\n",
      "\tspeed: 0.0316s/iter; left time: 538.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.61s\n",
      "Steps: 893 | Train Loss: 0.5172169 Vali Loss: 0.3909419 Test Loss: 0.4012013\n",
      "Validation loss decreased (inf --> 0.390942).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.3329136\n",
      "\tspeed: 0.1162s/iter; left time: 1960.4218s\n",
      "\titers: 200, epoch: 2 | loss: 0.3051157\n",
      "\tspeed: 0.0315s/iter; left time: 528.9884s\n",
      "\titers: 300, epoch: 2 | loss: 0.3783871\n",
      "\tspeed: 0.0315s/iter; left time: 525.7976s\n",
      "\titers: 400, epoch: 2 | loss: 0.3210444\n",
      "\tspeed: 0.0316s/iter; left time: 522.9053s\n",
      "\titers: 500, epoch: 2 | loss: 0.2767418\n",
      "\tspeed: 0.0316s/iter; left time: 519.7589s\n",
      "\titers: 600, epoch: 2 | loss: 0.2397419\n",
      "\tspeed: 0.0316s/iter; left time: 516.8711s\n",
      "\titers: 700, epoch: 2 | loss: 0.2917682\n",
      "\tspeed: 0.0316s/iter; left time: 513.3308s\n",
      "\titers: 800, epoch: 2 | loss: 0.2611503\n",
      "\tspeed: 0.0316s/iter; left time: 510.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.3086804 Vali Loss: 0.2775987 Test Loss: 0.2896311\n",
      "Validation loss decreased (0.390942 --> 0.277599).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2639548\n",
      "\tspeed: 0.1149s/iter; left time: 1835.4346s\n",
      "\titers: 200, epoch: 3 | loss: 0.2729660\n",
      "\tspeed: 0.0316s/iter; left time: 501.9510s\n",
      "\titers: 300, epoch: 3 | loss: 0.2605044\n",
      "\tspeed: 0.0317s/iter; left time: 499.4537s\n",
      "\titers: 400, epoch: 3 | loss: 0.2788781\n",
      "\tspeed: 0.0316s/iter; left time: 495.4040s\n",
      "\titers: 500, epoch: 3 | loss: 0.2373098\n",
      "\tspeed: 0.0316s/iter; left time: 491.9671s\n",
      "\titers: 600, epoch: 3 | loss: 0.2859555\n",
      "\tspeed: 0.0316s/iter; left time: 488.6503s\n",
      "\titers: 700, epoch: 3 | loss: 0.2379736\n",
      "\tspeed: 0.0316s/iter; left time: 485.6571s\n",
      "\titers: 800, epoch: 3 | loss: 0.3003955\n",
      "\tspeed: 0.0317s/iter; left time: 483.4554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.2741227 Vali Loss: 0.2677004 Test Loss: 0.2767538\n",
      "Validation loss decreased (0.277599 --> 0.267700).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2731439\n",
      "\tspeed: 0.1144s/iter; left time: 1725.4186s\n",
      "\titers: 200, epoch: 4 | loss: 0.2443695\n",
      "\tspeed: 0.0316s/iter; left time: 472.8189s\n",
      "\titers: 300, epoch: 4 | loss: 0.2708040\n",
      "\tspeed: 0.0316s/iter; left time: 469.7766s\n",
      "\titers: 400, epoch: 4 | loss: 0.2337376\n",
      "\tspeed: 0.0316s/iter; left time: 466.7383s\n",
      "\titers: 500, epoch: 4 | loss: 0.2652700\n",
      "\tspeed: 0.0316s/iter; left time: 463.3417s\n",
      "\titers: 600, epoch: 4 | loss: 0.2374048\n",
      "\tspeed: 0.0316s/iter; left time: 460.8036s\n",
      "\titers: 700, epoch: 4 | loss: 0.2728975\n",
      "\tspeed: 0.0316s/iter; left time: 457.7704s\n",
      "\titers: 800, epoch: 4 | loss: 0.2796249\n",
      "\tspeed: 0.0316s/iter; left time: 454.9934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 893 | Train Loss: 0.2644213 Vali Loss: 0.2624713 Test Loss: 0.2716621\n",
      "Validation loss decreased (0.267700 --> 0.262471).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2930860\n",
      "\tspeed: 0.1147s/iter; left time: 1627.7809s\n",
      "\titers: 200, epoch: 5 | loss: 0.2316188\n",
      "\tspeed: 0.0317s/iter; left time: 446.3552s\n",
      "\titers: 300, epoch: 5 | loss: 0.2892490\n",
      "\tspeed: 0.0317s/iter; left time: 442.8993s\n",
      "\titers: 400, epoch: 5 | loss: 0.2983845\n",
      "\tspeed: 0.0316s/iter; left time: 439.3049s\n",
      "\titers: 500, epoch: 5 | loss: 0.2540570\n",
      "\tspeed: 0.0316s/iter; left time: 435.0771s\n",
      "\titers: 600, epoch: 5 | loss: 0.2259790\n",
      "\tspeed: 0.0316s/iter; left time: 432.1955s\n",
      "\titers: 700, epoch: 5 | loss: 0.2447995\n",
      "\tspeed: 0.0316s/iter; left time: 428.9704s\n",
      "\titers: 800, epoch: 5 | loss: 0.2169718\n",
      "\tspeed: 0.0316s/iter; left time: 425.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.46s\n",
      "Steps: 893 | Train Loss: 0.2586045 Vali Loss: 0.2581793 Test Loss: 0.2673375\n",
      "Validation loss decreased (0.262471 --> 0.258179).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2630603\n",
      "\tspeed: 0.1146s/iter; left time: 1523.6201s\n",
      "\titers: 200, epoch: 6 | loss: 0.2661979\n",
      "\tspeed: 0.0316s/iter; left time: 416.7106s\n",
      "\titers: 300, epoch: 6 | loss: 0.2495898\n",
      "\tspeed: 0.0316s/iter; left time: 413.7765s\n",
      "\titers: 400, epoch: 6 | loss: 0.2557808\n",
      "\tspeed: 0.0316s/iter; left time: 410.2206s\n",
      "\titers: 500, epoch: 6 | loss: 0.2527471\n",
      "\tspeed: 0.0316s/iter; left time: 407.3696s\n",
      "\titers: 600, epoch: 6 | loss: 0.2774071\n",
      "\tspeed: 0.0316s/iter; left time: 404.0226s\n",
      "\titers: 700, epoch: 6 | loss: 0.1960831\n",
      "\tspeed: 0.0316s/iter; left time: 400.7708s\n",
      "\titers: 800, epoch: 6 | loss: 0.2443065\n",
      "\tspeed: 0.0316s/iter; left time: 397.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.2542046 Vali Loss: 0.2567239 Test Loss: 0.2653377\n",
      "Validation loss decreased (0.258179 --> 0.256724).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2689722\n",
      "\tspeed: 0.1143s/iter; left time: 1417.0464s\n",
      "\titers: 200, epoch: 7 | loss: 0.2188629\n",
      "\tspeed: 0.0316s/iter; left time: 388.5070s\n",
      "\titers: 300, epoch: 7 | loss: 0.2244141\n",
      "\tspeed: 0.0316s/iter; left time: 385.4822s\n",
      "\titers: 400, epoch: 7 | loss: 0.2601210\n",
      "\tspeed: 0.0316s/iter; left time: 382.4194s\n",
      "\titers: 500, epoch: 7 | loss: 0.2543232\n",
      "\tspeed: 0.0316s/iter; left time: 379.2789s\n",
      "\titers: 600, epoch: 7 | loss: 0.2206755\n",
      "\tspeed: 0.0316s/iter; left time: 376.1645s\n",
      "\titers: 700, epoch: 7 | loss: 0.2188539\n",
      "\tspeed: 0.0316s/iter; left time: 372.7840s\n",
      "\titers: 800, epoch: 7 | loss: 0.2206604\n",
      "\tspeed: 0.0316s/iter; left time: 369.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2510932 Vali Loss: 0.2566962 Test Loss: 0.2657960\n",
      "Validation loss decreased (0.256724 --> 0.256696).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2573139\n",
      "\tspeed: 0.1141s/iter; left time: 1312.8794s\n",
      "\titers: 200, epoch: 8 | loss: 0.2472233\n",
      "\tspeed: 0.0316s/iter; left time: 360.2966s\n",
      "\titers: 300, epoch: 8 | loss: 0.2776766\n",
      "\tspeed: 0.0316s/iter; left time: 357.2690s\n",
      "\titers: 400, epoch: 8 | loss: 0.2366810\n",
      "\tspeed: 0.0316s/iter; left time: 354.3811s\n",
      "\titers: 500, epoch: 8 | loss: 0.2523938\n",
      "\tspeed: 0.0316s/iter; left time: 351.0449s\n",
      "\titers: 600, epoch: 8 | loss: 0.2504436\n",
      "\tspeed: 0.0316s/iter; left time: 347.7291s\n",
      "\titers: 700, epoch: 8 | loss: 0.2564319\n",
      "\tspeed: 0.0316s/iter; left time: 344.6658s\n",
      "\titers: 800, epoch: 8 | loss: 0.2213441\n",
      "\tspeed: 0.0316s/iter; left time: 341.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.41s\n",
      "Steps: 893 | Train Loss: 0.2482514 Vali Loss: 0.2533533 Test Loss: 0.2626646\n",
      "Validation loss decreased (0.256696 --> 0.253353).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2737295\n",
      "\tspeed: 0.1160s/iter; left time: 1231.8061s\n",
      "\titers: 200, epoch: 9 | loss: 0.2716286\n",
      "\tspeed: 0.0317s/iter; left time: 332.9259s\n",
      "\titers: 300, epoch: 9 | loss: 0.2171892\n",
      "\tspeed: 0.0317s/iter; left time: 329.8786s\n",
      "\titers: 400, epoch: 9 | loss: 0.2534241\n",
      "\tspeed: 0.0317s/iter; left time: 326.5339s\n",
      "\titers: 500, epoch: 9 | loss: 0.2308261\n",
      "\tspeed: 0.0317s/iter; left time: 323.6245s\n",
      "\titers: 600, epoch: 9 | loss: 0.2262620\n",
      "\tspeed: 0.0317s/iter; left time: 320.3515s\n",
      "\titers: 700, epoch: 9 | loss: 0.2345880\n",
      "\tspeed: 0.0317s/iter; left time: 317.4018s\n",
      "\titers: 800, epoch: 9 | loss: 0.2201943\n",
      "\tspeed: 0.0316s/iter; left time: 312.9172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.2462554 Vali Loss: 0.2526498 Test Loss: 0.2612193\n",
      "Validation loss decreased (0.253353 --> 0.252650).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2491078\n",
      "\tspeed: 0.1161s/iter; left time: 1129.4081s\n",
      "\titers: 200, epoch: 10 | loss: 0.2663479\n",
      "\tspeed: 0.0318s/iter; left time: 306.3333s\n",
      "\titers: 300, epoch: 10 | loss: 0.2113236\n",
      "\tspeed: 0.0319s/iter; left time: 303.5983s\n",
      "\titers: 400, epoch: 10 | loss: 0.2494238\n",
      "\tspeed: 0.0318s/iter; left time: 300.1470s\n",
      "\titers: 500, epoch: 10 | loss: 0.2072393\n",
      "\tspeed: 0.0318s/iter; left time: 296.8405s\n",
      "\titers: 600, epoch: 10 | loss: 0.2076439\n",
      "\tspeed: 0.0317s/iter; left time: 292.0625s\n",
      "\titers: 700, epoch: 10 | loss: 0.2281912\n",
      "\tspeed: 0.0317s/iter; left time: 289.0167s\n",
      "\titers: 800, epoch: 10 | loss: 0.2610453\n",
      "\tspeed: 0.0317s/iter; left time: 285.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.63s\n",
      "Steps: 893 | Train Loss: 0.2445075 Vali Loss: 0.2518273 Test Loss: 0.2592405\n",
      "Validation loss decreased (0.252650 --> 0.251827).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2341568\n",
      "\tspeed: 0.1150s/iter; left time: 1015.4537s\n",
      "\titers: 200, epoch: 11 | loss: 0.2537177\n",
      "\tspeed: 0.0315s/iter; left time: 275.4391s\n",
      "\titers: 300, epoch: 11 | loss: 0.2266982\n",
      "\tspeed: 0.0315s/iter; left time: 272.0948s\n",
      "\titers: 400, epoch: 11 | loss: 0.2202058\n",
      "\tspeed: 0.0316s/iter; left time: 269.3032s\n",
      "\titers: 500, epoch: 11 | loss: 0.2146208\n",
      "\tspeed: 0.0316s/iter; left time: 266.1619s\n",
      "\titers: 600, epoch: 11 | loss: 0.2055262\n",
      "\tspeed: 0.0316s/iter; left time: 263.1581s\n",
      "\titers: 700, epoch: 11 | loss: 0.2524802\n",
      "\tspeed: 0.0315s/iter; left time: 259.6374s\n",
      "\titers: 800, epoch: 11 | loss: 0.2827221\n",
      "\tspeed: 0.0315s/iter; left time: 256.4330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2427989 Vali Loss: 0.2506115 Test Loss: 0.2603586\n",
      "Validation loss decreased (0.251827 --> 0.250611).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2507849\n",
      "\tspeed: 0.1153s/iter; left time: 915.5082s\n",
      "\titers: 200, epoch: 12 | loss: 0.2165677\n",
      "\tspeed: 0.0316s/iter; left time: 247.4699s\n",
      "\titers: 300, epoch: 12 | loss: 0.1843169\n",
      "\tspeed: 0.0316s/iter; left time: 244.4667s\n",
      "\titers: 400, epoch: 12 | loss: 0.2487691\n",
      "\tspeed: 0.0316s/iter; left time: 241.1557s\n",
      "\titers: 500, epoch: 12 | loss: 0.2463638\n",
      "\tspeed: 0.0316s/iter; left time: 237.9890s\n",
      "\titers: 600, epoch: 12 | loss: 0.2453960\n",
      "\tspeed: 0.0316s/iter; left time: 234.8730s\n",
      "\titers: 700, epoch: 12 | loss: 0.2497053\n",
      "\tspeed: 0.0316s/iter; left time: 231.7484s\n",
      "\titers: 800, epoch: 12 | loss: 0.2090461\n",
      "\tspeed: 0.0316s/iter; left time: 228.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2416013 Vali Loss: 0.2509341 Test Loss: 0.2594627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2027169\n",
      "\tspeed: 0.1127s/iter; left time: 794.3065s\n",
      "\titers: 200, epoch: 13 | loss: 0.2765835\n",
      "\tspeed: 0.0316s/iter; left time: 219.2854s\n",
      "\titers: 300, epoch: 13 | loss: 0.2244914\n",
      "\tspeed: 0.0316s/iter; left time: 216.1746s\n",
      "\titers: 400, epoch: 13 | loss: 0.2457835\n",
      "\tspeed: 0.0316s/iter; left time: 212.9725s\n",
      "\titers: 500, epoch: 13 | loss: 0.2276308\n",
      "\tspeed: 0.0316s/iter; left time: 209.7992s\n",
      "\titers: 600, epoch: 13 | loss: 0.2525270\n",
      "\tspeed: 0.0316s/iter; left time: 206.7174s\n",
      "\titers: 700, epoch: 13 | loss: 0.2423701\n",
      "\tspeed: 0.0316s/iter; left time: 203.4110s\n",
      "\titers: 800, epoch: 13 | loss: 0.2181254\n",
      "\tspeed: 0.0316s/iter; left time: 200.5078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 893 | Train Loss: 0.2403181 Vali Loss: 0.2493706 Test Loss: 0.2591109\n",
      "Validation loss decreased (0.250611 --> 0.249371).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2631365\n",
      "\tspeed: 0.1157s/iter; left time: 711.5589s\n",
      "\titers: 200, epoch: 14 | loss: 0.2830195\n",
      "\tspeed: 0.0316s/iter; left time: 190.9978s\n",
      "\titers: 300, epoch: 14 | loss: 0.2096737\n",
      "\tspeed: 0.0316s/iter; left time: 187.8280s\n",
      "\titers: 400, epoch: 14 | loss: 0.2091210\n",
      "\tspeed: 0.0316s/iter; left time: 184.7730s\n",
      "\titers: 500, epoch: 14 | loss: 0.2171544\n",
      "\tspeed: 0.0315s/iter; left time: 181.4042s\n",
      "\titers: 600, epoch: 14 | loss: 0.2638274\n",
      "\tspeed: 0.0316s/iter; left time: 178.4495s\n",
      "\titers: 700, epoch: 14 | loss: 0.2423234\n",
      "\tspeed: 0.0316s/iter; left time: 175.2264s\n",
      "\titers: 800, epoch: 14 | loss: 0.2032232\n",
      "\tspeed: 0.0316s/iter; left time: 172.1277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2392803 Vali Loss: 0.2489750 Test Loss: 0.2577620\n",
      "Validation loss decreased (0.249371 --> 0.248975).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2257874\n",
      "\tspeed: 0.1145s/iter; left time: 602.2048s\n",
      "\titers: 200, epoch: 15 | loss: 0.2430697\n",
      "\tspeed: 0.0316s/iter; left time: 162.8115s\n",
      "\titers: 300, epoch: 15 | loss: 0.2429270\n",
      "\tspeed: 0.0316s/iter; left time: 159.7116s\n",
      "\titers: 400, epoch: 15 | loss: 0.2489905\n",
      "\tspeed: 0.0316s/iter; left time: 156.5603s\n",
      "\titers: 500, epoch: 15 | loss: 0.2303152\n",
      "\tspeed: 0.0315s/iter; left time: 153.2968s\n",
      "\titers: 600, epoch: 15 | loss: 0.1963075\n",
      "\tspeed: 0.0316s/iter; left time: 150.2797s\n",
      "\titers: 700, epoch: 15 | loss: 0.2521002\n",
      "\tspeed: 0.0316s/iter; left time: 147.0280s\n",
      "\titers: 800, epoch: 15 | loss: 0.2139912\n",
      "\tspeed: 0.0316s/iter; left time: 143.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2383131 Vali Loss: 0.2489050 Test Loss: 0.2574034\n",
      "Validation loss decreased (0.248975 --> 0.248905).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2613737\n",
      "\tspeed: 0.1159s/iter; left time: 505.9276s\n",
      "\titers: 200, epoch: 16 | loss: 0.2222573\n",
      "\tspeed: 0.0318s/iter; left time: 135.6897s\n",
      "\titers: 300, epoch: 16 | loss: 0.2453973\n",
      "\tspeed: 0.0319s/iter; left time: 132.7469s\n",
      "\titers: 400, epoch: 16 | loss: 0.2603023\n",
      "\tspeed: 0.0318s/iter; left time: 129.1444s\n",
      "\titers: 500, epoch: 16 | loss: 0.2249487\n",
      "\tspeed: 0.0316s/iter; left time: 125.2322s\n",
      "\titers: 600, epoch: 16 | loss: 0.1986960\n",
      "\tspeed: 0.0316s/iter; left time: 122.0086s\n",
      "\titers: 700, epoch: 16 | loss: 0.2862662\n",
      "\tspeed: 0.0316s/iter; left time: 118.8746s\n",
      "\titers: 800, epoch: 16 | loss: 0.2182466\n",
      "\tspeed: 0.0316s/iter; left time: 115.7590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 893 | Train Loss: 0.2375227 Vali Loss: 0.2494802 Test Loss: 0.2582058\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2733065\n",
      "\tspeed: 0.1126s/iter; left time: 390.9224s\n",
      "\titers: 200, epoch: 17 | loss: 0.2285104\n",
      "\tspeed: 0.0315s/iter; left time: 106.3901s\n",
      "\titers: 300, epoch: 17 | loss: 0.2580472\n",
      "\tspeed: 0.0316s/iter; left time: 103.2705s\n",
      "\titers: 400, epoch: 17 | loss: 0.2548212\n",
      "\tspeed: 0.0316s/iter; left time: 100.1133s\n",
      "\titers: 500, epoch: 17 | loss: 0.1966954\n",
      "\tspeed: 0.0315s/iter; left time: 96.9527s\n",
      "\titers: 600, epoch: 17 | loss: 0.2102374\n",
      "\tspeed: 0.0316s/iter; left time: 93.8184s\n",
      "\titers: 700, epoch: 17 | loss: 0.2384559\n",
      "\tspeed: 0.0316s/iter; left time: 90.6496s\n",
      "\titers: 800, epoch: 17 | loss: 0.2604111\n",
      "\tspeed: 0.0316s/iter; left time: 87.5468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.35s\n",
      "Steps: 893 | Train Loss: 0.2367027 Vali Loss: 0.2492532 Test Loss: 0.2577972\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2377448\n",
      "\tspeed: 0.1124s/iter; left time: 289.9127s\n",
      "\titers: 200, epoch: 18 | loss: 0.2817394\n",
      "\tspeed: 0.0316s/iter; left time: 78.2713s\n",
      "\titers: 300, epoch: 18 | loss: 0.2535853\n",
      "\tspeed: 0.0316s/iter; left time: 75.1582s\n",
      "\titers: 400, epoch: 18 | loss: 0.2443666\n",
      "\tspeed: 0.0316s/iter; left time: 71.9633s\n",
      "\titers: 500, epoch: 18 | loss: 0.2458494\n",
      "\tspeed: 0.0316s/iter; left time: 68.8219s\n",
      "\titers: 600, epoch: 18 | loss: 0.2630318\n",
      "\tspeed: 0.0316s/iter; left time: 65.6658s\n",
      "\titers: 700, epoch: 18 | loss: 0.2428611\n",
      "\tspeed: 0.0316s/iter; left time: 62.5460s\n",
      "\titers: 800, epoch: 18 | loss: 0.2627814\n",
      "\tspeed: 0.0316s/iter; left time: 59.3547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.38s\n",
      "Steps: 893 | Train Loss: 0.2362437 Vali Loss: 0.2484618 Test Loss: 0.2568868\n",
      "Validation loss decreased (0.248905 --> 0.248462).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2267180\n",
      "\tspeed: 0.1145s/iter; left time: 193.1390s\n",
      "\titers: 200, epoch: 19 | loss: 0.2241946\n",
      "\tspeed: 0.0316s/iter; left time: 50.0993s\n",
      "\titers: 300, epoch: 19 | loss: 0.2238404\n",
      "\tspeed: 0.0316s/iter; left time: 46.9346s\n",
      "\titers: 400, epoch: 19 | loss: 0.2602724\n",
      "\tspeed: 0.0316s/iter; left time: 43.8058s\n",
      "\titers: 500, epoch: 19 | loss: 0.2270650\n",
      "\tspeed: 0.0316s/iter; left time: 40.6455s\n",
      "\titers: 600, epoch: 19 | loss: 0.2538011\n",
      "\tspeed: 0.0316s/iter; left time: 37.4929s\n",
      "\titers: 700, epoch: 19 | loss: 0.2788670\n",
      "\tspeed: 0.0316s/iter; left time: 34.3174s\n",
      "\titers: 800, epoch: 19 | loss: 0.2221485\n",
      "\tspeed: 0.0316s/iter; left time: 31.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 893 | Train Loss: 0.2356816 Vali Loss: 0.2478627 Test Loss: 0.2563355\n",
      "Validation loss decreased (0.248462 --> 0.247863).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2752744\n",
      "\tspeed: 0.1141s/iter; left time: 90.5873s\n",
      "\titers: 200, epoch: 20 | loss: 0.2117154\n",
      "\tspeed: 0.0315s/iter; left time: 21.8942s\n",
      "\titers: 300, epoch: 20 | loss: 0.2141363\n",
      "\tspeed: 0.0316s/iter; left time: 18.7456s\n",
      "\titers: 400, epoch: 20 | loss: 0.2154867\n",
      "\tspeed: 0.0315s/iter; left time: 15.5779s\n",
      "\titers: 500, epoch: 20 | loss: 0.2716494\n",
      "\tspeed: 0.0315s/iter; left time: 12.4243s\n",
      "\titers: 600, epoch: 20 | loss: 0.2585154\n",
      "\tspeed: 0.0318s/iter; left time: 9.3528s\n",
      "\titers: 700, epoch: 20 | loss: 0.2406651\n",
      "\tspeed: 0.0320s/iter; left time: 6.2067s\n",
      "\titers: 800, epoch: 20 | loss: 0.2348152\n",
      "\tspeed: 0.0316s/iter; left time: 2.9679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.47s\n",
      "Steps: 893 | Train Loss: 0.2350039 Vali Loss: 0.2471875 Test Loss: 0.2564662\n",
      "Validation loss decreased (0.247863 --> 0.247188).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20235617458820343, rmse:0.44984015822410583, mae:0.25646618008613586, rse:0.411980539560318\n",
      "Original data scale mse:1205955.25, rmse:1098.159912109375, mae:689.5393676757812, rse:0.07717029005289078\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6853384\n",
      "\tspeed: 0.0384s/iter; left time: 681.9683s\n",
      "\titers: 200, epoch: 1 | loss: 0.5709584\n",
      "\tspeed: 0.0315s/iter; left time: 556.1571s\n",
      "\titers: 300, epoch: 1 | loss: 0.5183161\n",
      "\tspeed: 0.0313s/iter; left time: 550.2217s\n",
      "\titers: 400, epoch: 1 | loss: 0.4511522\n",
      "\tspeed: 0.0313s/iter; left time: 546.2927s\n",
      "\titers: 500, epoch: 1 | loss: 0.5028278\n",
      "\tspeed: 0.0319s/iter; left time: 553.1696s\n",
      "\titers: 600, epoch: 1 | loss: 0.4705900\n",
      "\tspeed: 0.0674s/iter; left time: 1162.8734s\n",
      "\titers: 700, epoch: 1 | loss: 0.4274298\n",
      "\tspeed: 0.0964s/iter; left time: 1655.1074s\n",
      "\titers: 800, epoch: 1 | loss: 0.4067618\n",
      "\tspeed: 0.0906s/iter; left time: 1545.8250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.74s\n",
      "Steps: 893 | Train Loss: 0.5231530 Vali Loss: 0.4027090 Test Loss: 0.4103051\n",
      "Validation loss decreased (inf --> 0.402709).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.3675163\n",
      "\tspeed: 0.5581s/iter; left time: 9414.6187s\n",
      "\titers: 200, epoch: 2 | loss: 0.3380258\n",
      "\tspeed: 0.0938s/iter; left time: 1573.1862s\n",
      "\titers: 300, epoch: 2 | loss: 0.3200255\n",
      "\tspeed: 0.0928s/iter; left time: 1547.2673s\n",
      "\titers: 400, epoch: 2 | loss: 0.2769679\n",
      "\tspeed: 0.0932s/iter; left time: 1543.5882s\n",
      "\titers: 500, epoch: 2 | loss: 0.2863346\n",
      "\tspeed: 0.0975s/iter; left time: 1605.9434s\n",
      "\titers: 600, epoch: 2 | loss: 0.2665667\n",
      "\tspeed: 0.1010s/iter; left time: 1652.8730s\n",
      "\titers: 700, epoch: 2 | loss: 0.3271181\n",
      "\tspeed: 0.0994s/iter; left time: 1617.2316s\n",
      "\titers: 800, epoch: 2 | loss: 0.2938661\n",
      "\tspeed: 0.0955s/iter; left time: 1544.6490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:27.41s\n",
      "Steps: 893 | Train Loss: 0.3096806 Vali Loss: 0.2776573 Test Loss: 0.2873787\n",
      "Validation loss decreased (0.402709 --> 0.277657).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2518935\n",
      "\tspeed: 0.5912s/iter; left time: 9444.8417s\n",
      "\titers: 200, epoch: 3 | loss: 0.2585225\n",
      "\tspeed: 0.1028s/iter; left time: 1631.8310s\n",
      "\titers: 300, epoch: 3 | loss: 0.2657301\n",
      "\tspeed: 0.1031s/iter; left time: 1625.7838s\n",
      "\titers: 400, epoch: 3 | loss: 0.2495827\n",
      "\tspeed: 0.0963s/iter; left time: 1508.7317s\n",
      "\titers: 500, epoch: 3 | loss: 0.2826906\n",
      "\tspeed: 0.0954s/iter; left time: 1485.3610s\n",
      "\titers: 600, epoch: 3 | loss: 0.2636112\n",
      "\tspeed: 0.0980s/iter; left time: 1516.4071s\n",
      "\titers: 700, epoch: 3 | loss: 0.2527453\n",
      "\tspeed: 0.1051s/iter; left time: 1615.2185s\n",
      "\titers: 800, epoch: 3 | loss: 0.2719934\n",
      "\tspeed: 0.0942s/iter; left time: 1438.3138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.62s\n",
      "Steps: 893 | Train Loss: 0.2737493 Vali Loss: 0.2668281 Test Loss: 0.2760764\n",
      "Validation loss decreased (0.277657 --> 0.266828).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2785350\n",
      "\tspeed: 0.5589s/iter; left time: 8429.5741s\n",
      "\titers: 200, epoch: 4 | loss: 0.2597584\n",
      "\tspeed: 0.0983s/iter; left time: 1472.8466s\n",
      "\titers: 300, epoch: 4 | loss: 0.2843045\n",
      "\tspeed: 0.1000s/iter; left time: 1487.8901s\n",
      "\titers: 400, epoch: 4 | loss: 0.2838999\n",
      "\tspeed: 0.1013s/iter; left time: 1497.0433s\n",
      "\titers: 500, epoch: 4 | loss: 0.2558833\n",
      "\tspeed: 0.0941s/iter; left time: 1381.1284s\n",
      "\titers: 600, epoch: 4 | loss: 0.2393299\n",
      "\tspeed: 0.1143s/iter; left time: 1667.0164s\n",
      "\titers: 700, epoch: 4 | loss: 0.2376697\n",
      "\tspeed: 0.1215s/iter; left time: 1759.4723s\n",
      "\titers: 800, epoch: 4 | loss: 0.2732026\n",
      "\tspeed: 0.1275s/iter; left time: 1833.9152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:35.81s\n",
      "Steps: 893 | Train Loss: 0.2638572 Vali Loss: 0.2609591 Test Loss: 0.2712106\n",
      "Validation loss decreased (0.266828 --> 0.260959).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2605382\n",
      "\tspeed: 0.6679s/iter; left time: 9476.4992s\n",
      "\titers: 200, epoch: 5 | loss: 0.2239241\n",
      "\tspeed: 0.1088s/iter; left time: 1532.3074s\n",
      "\titers: 300, epoch: 5 | loss: 0.2642403\n",
      "\tspeed: 0.1010s/iter; left time: 1412.9267s\n",
      "\titers: 400, epoch: 5 | loss: 0.2558028\n",
      "\tspeed: 0.0938s/iter; left time: 1302.9660s\n",
      "\titers: 500, epoch: 5 | loss: 0.2453992\n",
      "\tspeed: 0.0971s/iter; left time: 1339.0468s\n",
      "\titers: 600, epoch: 5 | loss: 0.2239451\n",
      "\tspeed: 0.0954s/iter; left time: 1305.9025s\n",
      "\titers: 700, epoch: 5 | loss: 0.2475607\n",
      "\tspeed: 0.0955s/iter; left time: 1297.3448s\n",
      "\titers: 800, epoch: 5 | loss: 0.2434539\n",
      "\tspeed: 0.0937s/iter; left time: 1263.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:30.39s\n",
      "Steps: 893 | Train Loss: 0.2577606 Vali Loss: 0.2591886 Test Loss: 0.2686861\n",
      "Validation loss decreased (0.260959 --> 0.259189).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2900487\n",
      "\tspeed: 0.5381s/iter; left time: 7154.7723s\n",
      "\titers: 200, epoch: 6 | loss: 0.2427238\n",
      "\tspeed: 0.0994s/iter; left time: 1312.1761s\n",
      "\titers: 300, epoch: 6 | loss: 0.2885865\n",
      "\tspeed: 0.0942s/iter; left time: 1234.1537s\n",
      "\titers: 400, epoch: 6 | loss: 0.2408950\n",
      "\tspeed: 0.0960s/iter; left time: 1248.1643s\n",
      "\titers: 500, epoch: 6 | loss: 0.2397611\n",
      "\tspeed: 0.0999s/iter; left time: 1288.2308s\n",
      "\titers: 600, epoch: 6 | loss: 0.2604333\n",
      "\tspeed: 0.0910s/iter; left time: 1163.8343s\n",
      "\titers: 700, epoch: 6 | loss: 0.2534460\n",
      "\tspeed: 0.0881s/iter; left time: 1118.6420s\n",
      "\titers: 800, epoch: 6 | loss: 0.2344520\n",
      "\tspeed: 0.0963s/iter; left time: 1212.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2535814 Vali Loss: 0.2579949 Test Loss: 0.2699594\n",
      "Validation loss decreased (0.259189 --> 0.257995).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2204038\n",
      "\tspeed: 0.5527s/iter; left time: 6855.7362s\n",
      "\titers: 200, epoch: 7 | loss: 0.2281839\n",
      "\tspeed: 0.0944s/iter; left time: 1160.9171s\n",
      "\titers: 300, epoch: 7 | loss: 0.2339796\n",
      "\tspeed: 0.0695s/iter; left time: 848.2558s\n",
      "\titers: 400, epoch: 7 | loss: 0.2386514\n",
      "\tspeed: 0.0873s/iter; left time: 1056.4257s\n",
      "\titers: 500, epoch: 7 | loss: 0.3049762\n",
      "\tspeed: 0.1034s/iter; left time: 1240.8350s\n",
      "\titers: 600, epoch: 7 | loss: 0.2797050\n",
      "\tspeed: 0.0992s/iter; left time: 1180.2761s\n",
      "\titers: 700, epoch: 7 | loss: 0.2660284\n",
      "\tspeed: 0.0964s/iter; left time: 1138.0425s\n",
      "\titers: 800, epoch: 7 | loss: 0.2665933\n",
      "\tspeed: 0.0954s/iter; left time: 1116.1343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:24.88s\n",
      "Steps: 893 | Train Loss: 0.2505297 Vali Loss: 0.2557031 Test Loss: 0.2646774\n",
      "Validation loss decreased (0.257995 --> 0.255703).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2222491\n",
      "\tspeed: 0.5707s/iter; left time: 6568.4836s\n",
      "\titers: 200, epoch: 8 | loss: 0.2889420\n",
      "\tspeed: 0.0939s/iter; left time: 1071.4990s\n",
      "\titers: 300, epoch: 8 | loss: 0.2171935\n",
      "\tspeed: 0.0902s/iter; left time: 1019.8607s\n",
      "\titers: 400, epoch: 8 | loss: 0.2311474\n",
      "\tspeed: 0.0859s/iter; left time: 963.3553s\n",
      "\titers: 500, epoch: 8 | loss: 0.2535686\n",
      "\tspeed: 0.0971s/iter; left time: 1078.8259s\n",
      "\titers: 600, epoch: 8 | loss: 0.2297953\n",
      "\tspeed: 0.0904s/iter; left time: 995.0417s\n",
      "\titers: 700, epoch: 8 | loss: 0.2540425\n",
      "\tspeed: 0.0647s/iter; left time: 705.4642s\n",
      "\titers: 800, epoch: 8 | loss: 0.2726748\n",
      "\tspeed: 0.0944s/iter; left time: 1020.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:21.65s\n",
      "Steps: 893 | Train Loss: 0.2477252 Vali Loss: 0.2544312 Test Loss: 0.2657301\n",
      "Validation loss decreased (0.255703 --> 0.254431).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2765501\n",
      "\tspeed: 0.5565s/iter; left time: 5907.9394s\n",
      "\titers: 200, epoch: 9 | loss: 0.2301902\n",
      "\tspeed: 0.1020s/iter; left time: 1072.2937s\n",
      "\titers: 300, epoch: 9 | loss: 0.2303302\n",
      "\tspeed: 0.0927s/iter; left time: 965.4466s\n",
      "\titers: 400, epoch: 9 | loss: 0.2632057\n",
      "\tspeed: 0.0845s/iter; left time: 871.3082s\n",
      "\titers: 500, epoch: 9 | loss: 0.2254531\n",
      "\tspeed: 0.0904s/iter; left time: 924.0849s\n",
      "\titers: 600, epoch: 9 | loss: 0.2560235\n",
      "\tspeed: 0.1022s/iter; left time: 1033.4929s\n",
      "\titers: 700, epoch: 9 | loss: 0.2139202\n",
      "\tspeed: 0.0920s/iter; left time: 921.2156s\n",
      "\titers: 800, epoch: 9 | loss: 0.2696873\n",
      "\tspeed: 0.0900s/iter; left time: 892.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:24.96s\n",
      "Steps: 893 | Train Loss: 0.2455645 Vali Loss: 0.2507346 Test Loss: 0.2610210\n",
      "Validation loss decreased (0.254431 --> 0.250735).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2430879\n",
      "\tspeed: 0.5681s/iter; left time: 5524.4053s\n",
      "\titers: 200, epoch: 10 | loss: 0.2345661\n",
      "\tspeed: 0.0935s/iter; left time: 900.2189s\n",
      "\titers: 300, epoch: 10 | loss: 0.2399669\n",
      "\tspeed: 0.0921s/iter; left time: 877.2916s\n",
      "\titers: 400, epoch: 10 | loss: 0.2060126\n",
      "\tspeed: 0.0936s/iter; left time: 882.3958s\n",
      "\titers: 500, epoch: 10 | loss: 0.2820653\n",
      "\tspeed: 0.0972s/iter; left time: 906.4788s\n",
      "\titers: 600, epoch: 10 | loss: 0.2774793\n",
      "\tspeed: 0.0974s/iter; left time: 898.2492s\n",
      "\titers: 700, epoch: 10 | loss: 0.2251614\n",
      "\tspeed: 0.1009s/iter; left time: 920.8684s\n",
      "\titers: 800, epoch: 10 | loss: 0.1992216\n",
      "\tspeed: 0.1035s/iter; left time: 933.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:27.63s\n",
      "Steps: 893 | Train Loss: 0.2439292 Vali Loss: 0.2540835 Test Loss: 0.2625539\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2144765\n",
      "\tspeed: 0.5082s/iter; left time: 4488.0548s\n",
      "\titers: 200, epoch: 11 | loss: 0.2543577\n",
      "\tspeed: 0.0937s/iter; left time: 818.0383s\n",
      "\titers: 300, epoch: 11 | loss: 0.2544709\n",
      "\tspeed: 0.0982s/iter; left time: 847.9641s\n",
      "\titers: 400, epoch: 11 | loss: 0.2091634\n",
      "\tspeed: 0.0965s/iter; left time: 822.9558s\n",
      "\titers: 500, epoch: 11 | loss: 0.2463766\n",
      "\tspeed: 0.0995s/iter; left time: 839.1279s\n",
      "\titers: 600, epoch: 11 | loss: 0.2683782\n",
      "\tspeed: 0.0911s/iter; left time: 758.7669s\n",
      "\titers: 700, epoch: 11 | loss: 0.2743813\n",
      "\tspeed: 0.0931s/iter; left time: 766.1742s\n",
      "\titers: 800, epoch: 11 | loss: 0.2700862\n",
      "\tspeed: 0.0944s/iter; left time: 767.8659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:26.40s\n",
      "Steps: 893 | Train Loss: 0.2421961 Vali Loss: 0.2505007 Test Loss: 0.2604265\n",
      "Validation loss decreased (0.250735 --> 0.250501).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2619439\n",
      "\tspeed: 0.5554s/iter; left time: 4408.4939s\n",
      "\titers: 200, epoch: 12 | loss: 0.2328947\n",
      "\tspeed: 0.0982s/iter; left time: 770.0183s\n",
      "\titers: 300, epoch: 12 | loss: 0.2148771\n",
      "\tspeed: 0.0975s/iter; left time: 754.7674s\n",
      "\titers: 400, epoch: 12 | loss: 0.2073749\n",
      "\tspeed: 0.1072s/iter; left time: 818.5854s\n",
      "\titers: 500, epoch: 12 | loss: 0.2474194\n",
      "\tspeed: 0.0994s/iter; left time: 749.0426s\n",
      "\titers: 600, epoch: 12 | loss: 0.2603330\n",
      "\tspeed: 0.0928s/iter; left time: 690.4119s\n",
      "\titers: 700, epoch: 12 | loss: 0.2556296\n",
      "\tspeed: 0.0569s/iter; left time: 417.6494s\n",
      "\titers: 800, epoch: 12 | loss: 0.2539606\n",
      "\tspeed: 0.0371s/iter; left time: 268.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:11.93s\n",
      "Steps: 893 | Train Loss: 0.2410153 Vali Loss: 0.2499755 Test Loss: 0.2601428\n",
      "Validation loss decreased (0.250501 --> 0.249976).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2480574\n",
      "\tspeed: 0.1436s/iter; left time: 1011.4016s\n",
      "\titers: 200, epoch: 13 | loss: 0.2552005\n",
      "\tspeed: 0.0314s/iter; left time: 218.0378s\n",
      "\titers: 300, epoch: 13 | loss: 0.2424062\n",
      "\tspeed: 0.0314s/iter; left time: 214.8349s\n",
      "\titers: 400, epoch: 13 | loss: 0.2173914\n",
      "\tspeed: 0.0314s/iter; left time: 211.5254s\n",
      "\titers: 500, epoch: 13 | loss: 0.2269723\n",
      "\tspeed: 0.0314s/iter; left time: 208.8640s\n",
      "\titers: 600, epoch: 13 | loss: 0.2352703\n",
      "\tspeed: 0.0314s/iter; left time: 205.2184s\n",
      "\titers: 700, epoch: 13 | loss: 0.2169636\n",
      "\tspeed: 0.0313s/iter; left time: 201.9546s\n",
      "\titers: 800, epoch: 13 | loss: 0.2716199\n",
      "\tspeed: 0.0313s/iter; left time: 198.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.2399963 Vali Loss: 0.2503783 Test Loss: 0.2599301\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2432371\n",
      "\tspeed: 0.1145s/iter; left time: 704.4205s\n",
      "\titers: 200, epoch: 14 | loss: 0.2454006\n",
      "\tspeed: 0.0314s/iter; left time: 189.8224s\n",
      "\titers: 300, epoch: 14 | loss: 0.2583016\n",
      "\tspeed: 0.0313s/iter; left time: 186.5249s\n",
      "\titers: 400, epoch: 14 | loss: 0.2406298\n",
      "\tspeed: 0.0314s/iter; left time: 183.4742s\n",
      "\titers: 500, epoch: 14 | loss: 0.2261155\n",
      "\tspeed: 0.0314s/iter; left time: 180.3836s\n",
      "\titers: 600, epoch: 14 | loss: 0.2417040\n",
      "\tspeed: 0.0314s/iter; left time: 177.5566s\n",
      "\titers: 700, epoch: 14 | loss: 0.2395690\n",
      "\tspeed: 0.0314s/iter; left time: 174.3665s\n",
      "\titers: 800, epoch: 14 | loss: 0.2250243\n",
      "\tspeed: 0.0314s/iter; left time: 170.9638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.32s\n",
      "Steps: 893 | Train Loss: 0.2388796 Vali Loss: 0.2500123 Test Loss: 0.2582500\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2029620\n",
      "\tspeed: 0.1156s/iter; left time: 607.6789s\n",
      "\titers: 200, epoch: 15 | loss: 0.2404068\n",
      "\tspeed: 0.0315s/iter; left time: 162.5449s\n",
      "\titers: 300, epoch: 15 | loss: 0.2499936\n",
      "\tspeed: 0.0315s/iter; left time: 159.5341s\n",
      "\titers: 400, epoch: 15 | loss: 0.2365125\n",
      "\tspeed: 0.0315s/iter; left time: 156.3411s\n",
      "\titers: 500, epoch: 15 | loss: 0.2407171\n",
      "\tspeed: 0.0316s/iter; left time: 153.3352s\n",
      "\titers: 600, epoch: 15 | loss: 0.2781359\n",
      "\tspeed: 0.0316s/iter; left time: 150.3323s\n",
      "\titers: 700, epoch: 15 | loss: 0.2616869\n",
      "\tspeed: 0.0316s/iter; left time: 147.0996s\n",
      "\titers: 800, epoch: 15 | loss: 0.2161899\n",
      "\tspeed: 0.0316s/iter; left time: 143.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.2380583 Vali Loss: 0.2490439 Test Loss: 0.2587821\n",
      "Validation loss decreased (0.249976 --> 0.249044).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2385732\n",
      "\tspeed: 0.1196s/iter; left time: 522.2056s\n",
      "\titers: 200, epoch: 16 | loss: 0.2365368\n",
      "\tspeed: 0.0316s/iter; left time: 134.7599s\n",
      "\titers: 300, epoch: 16 | loss: 0.2203151\n",
      "\tspeed: 0.0316s/iter; left time: 131.7154s\n",
      "\titers: 400, epoch: 16 | loss: 0.2306923\n",
      "\tspeed: 0.0316s/iter; left time: 128.4794s\n",
      "\titers: 500, epoch: 16 | loss: 0.2194030\n",
      "\tspeed: 0.0316s/iter; left time: 125.3559s\n",
      "\titers: 600, epoch: 16 | loss: 0.2069327\n",
      "\tspeed: 0.0316s/iter; left time: 122.3255s\n",
      "\titers: 700, epoch: 16 | loss: 0.2347485\n",
      "\tspeed: 0.0316s/iter; left time: 119.0928s\n",
      "\titers: 800, epoch: 16 | loss: 0.2418443\n",
      "\tspeed: 0.0316s/iter; left time: 115.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.56s\n",
      "Steps: 893 | Train Loss: 0.2373561 Vali Loss: 0.2495108 Test Loss: 0.2588449\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2141582\n",
      "\tspeed: 0.1156s/iter; left time: 401.4212s\n",
      "\titers: 200, epoch: 17 | loss: 0.2529851\n",
      "\tspeed: 0.0320s/iter; left time: 107.8240s\n",
      "\titers: 300, epoch: 17 | loss: 0.2000230\n",
      "\tspeed: 0.0319s/iter; left time: 104.5160s\n",
      "\titers: 400, epoch: 17 | loss: 0.2542096\n",
      "\tspeed: 0.0319s/iter; left time: 101.3425s\n",
      "\titers: 500, epoch: 17 | loss: 0.2311839\n",
      "\tspeed: 0.0320s/iter; left time: 98.3895s\n",
      "\titers: 600, epoch: 17 | loss: 0.2298502\n",
      "\tspeed: 0.0670s/iter; left time: 199.0582s\n",
      "\titers: 700, epoch: 17 | loss: 0.2119494\n",
      "\tspeed: 0.0413s/iter; left time: 118.5829s\n",
      "\titers: 800, epoch: 17 | loss: 0.2441208\n",
      "\tspeed: 0.0318s/iter; left time: 88.2912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:33.28s\n",
      "Steps: 893 | Train Loss: 0.2364494 Vali Loss: 0.2483759 Test Loss: 0.2571553\n",
      "Validation loss decreased (0.249044 --> 0.248376).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2224274\n",
      "\tspeed: 0.1197s/iter; left time: 308.9187s\n",
      "\titers: 200, epoch: 18 | loss: 0.2134745\n",
      "\tspeed: 0.0327s/iter; left time: 81.1268s\n",
      "\titers: 300, epoch: 18 | loss: 0.2690977\n",
      "\tspeed: 0.0336s/iter; left time: 80.0088s\n",
      "\titers: 400, epoch: 18 | loss: 0.2340597\n",
      "\tspeed: 0.0415s/iter; left time: 94.6560s\n",
      "\titers: 500, epoch: 18 | loss: 0.2242667\n",
      "\tspeed: 0.0335s/iter; left time: 73.1027s\n",
      "\titers: 600, epoch: 18 | loss: 0.2374065\n",
      "\tspeed: 0.0319s/iter; left time: 66.2963s\n",
      "\titers: 700, epoch: 18 | loss: 0.2071742\n",
      "\tspeed: 0.0319s/iter; left time: 63.0657s\n",
      "\titers: 800, epoch: 18 | loss: 0.2272671\n",
      "\tspeed: 0.0317s/iter; left time: 59.5134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.34s\n",
      "Steps: 893 | Train Loss: 0.2359448 Vali Loss: 0.2483763 Test Loss: 0.2573794\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2465288\n",
      "\tspeed: 0.1151s/iter; left time: 194.1978s\n",
      "\titers: 200, epoch: 19 | loss: 0.2507596\n",
      "\tspeed: 0.0318s/iter; left time: 50.4161s\n",
      "\titers: 300, epoch: 19 | loss: 0.2479840\n",
      "\tspeed: 0.0318s/iter; left time: 47.2256s\n",
      "\titers: 400, epoch: 19 | loss: 0.2345795\n",
      "\tspeed: 0.0365s/iter; left time: 50.6187s\n",
      "\titers: 500, epoch: 19 | loss: 0.2297338\n",
      "\tspeed: 0.0319s/iter; left time: 41.0128s\n",
      "\titers: 600, epoch: 19 | loss: 0.2541734\n",
      "\tspeed: 0.0317s/iter; left time: 37.6206s\n",
      "\titers: 700, epoch: 19 | loss: 0.2712956\n",
      "\tspeed: 0.0317s/iter; left time: 34.4755s\n",
      "\titers: 800, epoch: 19 | loss: 0.2616410\n",
      "\tspeed: 0.0316s/iter; left time: 31.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 893 | Train Loss: 0.2353932 Vali Loss: 0.2462539 Test Loss: 0.2566255\n",
      "Validation loss decreased (0.248376 --> 0.246254).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2373825\n",
      "\tspeed: 0.1175s/iter; left time: 93.3264s\n",
      "\titers: 200, epoch: 20 | loss: 0.2208904\n",
      "\tspeed: 0.0588s/iter; left time: 40.8052s\n",
      "\titers: 300, epoch: 20 | loss: 0.2113225\n",
      "\tspeed: 0.0462s/iter; left time: 27.4533s\n",
      "\titers: 400, epoch: 20 | loss: 0.2229316\n",
      "\tspeed: 0.0317s/iter; left time: 15.6610s\n",
      "\titers: 500, epoch: 20 | loss: 0.2357544\n",
      "\tspeed: 0.0316s/iter; left time: 12.4621s\n",
      "\titers: 600, epoch: 20 | loss: 0.2459009\n",
      "\tspeed: 0.0317s/iter; left time: 9.3086s\n",
      "\titers: 700, epoch: 20 | loss: 0.2566755\n",
      "\tspeed: 0.0317s/iter; left time: 6.1516s\n",
      "\titers: 800, epoch: 20 | loss: 0.2718703\n",
      "\tspeed: 0.0318s/iter; left time: 2.9850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 893 | Train Loss: 0.2348328 Vali Loss: 0.2473557 Test Loss: 0.2567831\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20474950969219208, rmse:0.4524925649166107, mae:0.2566255033016205, rse:0.41440966725349426\n",
      "Original data scale mse:1217987.25, rmse:1103.6246337890625, mae:689.6762084960938, rse:0.07755430042743683\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7258288\n",
      "\tspeed: 0.0505s/iter; left time: 895.3512s\n",
      "\titers: 200, epoch: 1 | loss: 0.6010347\n",
      "\tspeed: 0.0322s/iter; left time: 566.6995s\n",
      "\titers: 300, epoch: 1 | loss: 0.5690444\n",
      "\tspeed: 0.0323s/iter; left time: 566.4931s\n",
      "\titers: 400, epoch: 1 | loss: 0.4945218\n",
      "\tspeed: 0.0502s/iter; left time: 874.1208s\n",
      "\titers: 500, epoch: 1 | loss: 0.4822377\n",
      "\tspeed: 0.0337s/iter; left time: 583.4240s\n",
      "\titers: 600, epoch: 1 | loss: 0.5062515\n",
      "\tspeed: 0.0427s/iter; left time: 734.5073s\n",
      "\titers: 700, epoch: 1 | loss: 0.4565914\n",
      "\tspeed: 0.0332s/iter; left time: 569.1856s\n",
      "\titers: 800, epoch: 1 | loss: 0.4643840\n",
      "\tspeed: 0.0322s/iter; left time: 548.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.37s\n",
      "Steps: 891 | Train Loss: 0.5544775 Vali Loss: 0.4453341 Test Loss: 0.4535313\n",
      "Validation loss decreased (inf --> 0.445334).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4315578\n",
      "\tspeed: 0.1216s/iter; left time: 2045.8980s\n",
      "\titers: 200, epoch: 2 | loss: 0.3597669\n",
      "\tspeed: 0.0325s/iter; left time: 543.3804s\n",
      "\titers: 300, epoch: 2 | loss: 0.3903033\n",
      "\tspeed: 0.0326s/iter; left time: 541.3827s\n",
      "\titers: 400, epoch: 2 | loss: 0.3685282\n",
      "\tspeed: 0.0333s/iter; left time: 549.7584s\n",
      "\titers: 500, epoch: 2 | loss: 0.3615198\n",
      "\tspeed: 0.0341s/iter; left time: 560.0842s\n",
      "\titers: 600, epoch: 2 | loss: 0.3746618\n",
      "\tspeed: 0.0327s/iter; left time: 534.3261s\n",
      "\titers: 700, epoch: 2 | loss: 0.4085601\n",
      "\tspeed: 0.0328s/iter; left time: 532.1371s\n",
      "\titers: 800, epoch: 2 | loss: 0.3759416\n",
      "\tspeed: 0.0326s/iter; left time: 525.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.60s\n",
      "Steps: 891 | Train Loss: 0.3948935 Vali Loss: 0.3684960 Test Loss: 0.3810019\n",
      "Validation loss decreased (0.445334 --> 0.368496).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3827534\n",
      "\tspeed: 0.1227s/iter; left time: 1955.6754s\n",
      "\titers: 200, epoch: 3 | loss: 0.3584317\n",
      "\tspeed: 0.0325s/iter; left time: 515.2275s\n",
      "\titers: 300, epoch: 3 | loss: 0.3461233\n",
      "\tspeed: 0.0327s/iter; left time: 514.2185s\n",
      "\titers: 400, epoch: 3 | loss: 0.3555109\n",
      "\tspeed: 0.0325s/iter; left time: 507.8466s\n",
      "\titers: 500, epoch: 3 | loss: 0.3778221\n",
      "\tspeed: 0.0324s/iter; left time: 503.3589s\n",
      "\titers: 600, epoch: 3 | loss: 0.3481736\n",
      "\tspeed: 0.0323s/iter; left time: 498.2520s\n",
      "\titers: 700, epoch: 3 | loss: 0.3752605\n",
      "\tspeed: 0.0323s/iter; left time: 494.6863s\n",
      "\titers: 800, epoch: 3 | loss: 0.3142370\n",
      "\tspeed: 0.0323s/iter; left time: 492.4204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.11s\n",
      "Steps: 891 | Train Loss: 0.3614492 Vali Loss: 0.3583712 Test Loss: 0.3752911\n",
      "Validation loss decreased (0.368496 --> 0.358371).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3927111\n",
      "\tspeed: 0.1189s/iter; left time: 1788.7198s\n",
      "\titers: 200, epoch: 4 | loss: 0.3576466\n",
      "\tspeed: 0.0324s/iter; left time: 483.5984s\n",
      "\titers: 300, epoch: 4 | loss: 0.3800444\n",
      "\tspeed: 0.0442s/iter; left time: 656.6614s\n",
      "\titers: 400, epoch: 4 | loss: 0.3841175\n",
      "\tspeed: 0.0329s/iter; left time: 484.8248s\n",
      "\titers: 500, epoch: 4 | loss: 0.3818028\n",
      "\tspeed: 0.0323s/iter; left time: 473.2530s\n",
      "\titers: 600, epoch: 4 | loss: 0.3705722\n",
      "\tspeed: 0.0323s/iter; left time: 470.0153s\n",
      "\titers: 700, epoch: 4 | loss: 0.3480760\n",
      "\tspeed: 0.0323s/iter; left time: 466.7885s\n",
      "\titers: 800, epoch: 4 | loss: 0.3472134\n",
      "\tspeed: 0.0323s/iter; left time: 463.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.27s\n",
      "Steps: 891 | Train Loss: 0.3517037 Vali Loss: 0.3572736 Test Loss: 0.3716470\n",
      "Validation loss decreased (0.358371 --> 0.357274).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3537914\n",
      "\tspeed: 0.1179s/iter; left time: 1669.4079s\n",
      "\titers: 200, epoch: 5 | loss: 0.3848159\n",
      "\tspeed: 0.0323s/iter; left time: 454.2859s\n",
      "\titers: 300, epoch: 5 | loss: 0.3658484\n",
      "\tspeed: 0.0323s/iter; left time: 451.3627s\n",
      "\titers: 400, epoch: 5 | loss: 0.3438016\n",
      "\tspeed: 0.0323s/iter; left time: 447.1793s\n",
      "\titers: 500, epoch: 5 | loss: 0.3298039\n",
      "\tspeed: 0.0323s/iter; left time: 444.2413s\n",
      "\titers: 600, epoch: 5 | loss: 0.3690844\n",
      "\tspeed: 0.0323s/iter; left time: 440.8715s\n",
      "\titers: 700, epoch: 5 | loss: 0.3231797\n",
      "\tspeed: 0.0323s/iter; left time: 438.0791s\n",
      "\titers: 800, epoch: 5 | loss: 0.3333758\n",
      "\tspeed: 0.0323s/iter; left time: 434.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.07s\n",
      "Steps: 891 | Train Loss: 0.3448746 Vali Loss: 0.3547672 Test Loss: 0.3691972\n",
      "Validation loss decreased (0.357274 --> 0.354767).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3581964\n",
      "\tspeed: 0.1515s/iter; left time: 2009.6230s\n",
      "\titers: 200, epoch: 6 | loss: 0.3451887\n",
      "\tspeed: 0.0322s/iter; left time: 423.3328s\n",
      "\titers: 300, epoch: 6 | loss: 0.3088588\n",
      "\tspeed: 0.0323s/iter; left time: 422.5820s\n",
      "\titers: 400, epoch: 6 | loss: 0.3691954\n",
      "\tspeed: 0.0362s/iter; left time: 469.2846s\n",
      "\titers: 500, epoch: 6 | loss: 0.3242213\n",
      "\tspeed: 0.0321s/iter; left time: 413.5170s\n",
      "\titers: 600, epoch: 6 | loss: 0.3051241\n",
      "\tspeed: 0.0321s/iter; left time: 410.2830s\n",
      "\titers: 700, epoch: 6 | loss: 0.3347548\n",
      "\tspeed: 0.0323s/iter; left time: 408.9827s\n",
      "\titers: 800, epoch: 6 | loss: 0.3607292\n",
      "\tspeed: 0.0336s/iter; left time: 422.0552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.54s\n",
      "Steps: 891 | Train Loss: 0.3394644 Vali Loss: 0.3555425 Test Loss: 0.3689241\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3276907\n",
      "\tspeed: 0.1219s/iter; left time: 1508.9950s\n",
      "\titers: 200, epoch: 7 | loss: 0.3012269\n",
      "\tspeed: 0.0324s/iter; left time: 397.2658s\n",
      "\titers: 300, epoch: 7 | loss: 0.3517112\n",
      "\tspeed: 0.0321s/iter; left time: 391.1380s\n",
      "\titers: 400, epoch: 7 | loss: 0.3117738\n",
      "\tspeed: 0.0332s/iter; left time: 400.4445s\n",
      "\titers: 500, epoch: 7 | loss: 0.3169316\n",
      "\tspeed: 0.0326s/iter; left time: 390.2798s\n",
      "\titers: 600, epoch: 7 | loss: 0.3092468\n",
      "\tspeed: 0.0323s/iter; left time: 383.5690s\n",
      "\titers: 700, epoch: 7 | loss: 0.3496321\n",
      "\tspeed: 0.0323s/iter; left time: 379.9381s\n",
      "\titers: 800, epoch: 7 | loss: 0.3639553\n",
      "\tspeed: 0.0323s/iter; left time: 377.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 891 | Train Loss: 0.3353596 Vali Loss: 0.3577233 Test Loss: 0.3706525\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2858768\n",
      "\tspeed: 0.1152s/iter; left time: 1323.5155s\n",
      "\titers: 200, epoch: 8 | loss: 0.3485679\n",
      "\tspeed: 0.0323s/iter; left time: 367.4487s\n",
      "\titers: 300, epoch: 8 | loss: 0.2745721\n",
      "\tspeed: 0.0323s/iter; left time: 364.5397s\n",
      "\titers: 400, epoch: 8 | loss: 0.3504907\n",
      "\tspeed: 0.0323s/iter; left time: 361.1524s\n",
      "\titers: 500, epoch: 8 | loss: 0.3292584\n",
      "\tspeed: 0.0323s/iter; left time: 358.3622s\n",
      "\titers: 600, epoch: 8 | loss: 0.3269175\n",
      "\tspeed: 0.0323s/iter; left time: 354.6268s\n",
      "\titers: 700, epoch: 8 | loss: 0.3094549\n",
      "\tspeed: 0.0323s/iter; left time: 351.5217s\n",
      "\titers: 800, epoch: 8 | loss: 0.2945649\n",
      "\tspeed: 0.0323s/iter; left time: 348.3188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.29s\n",
      "Steps: 891 | Train Loss: 0.3312931 Vali Loss: 0.3581069 Test Loss: 0.3709327\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36822813749313354, rmse:0.6068180203437805, mae:0.3691971004009247, rse:0.5556054711341858\n",
      "Original data scale mse:2643049.5, rmse:1625.745849609375, mae:1045.0140380859375, rse:0.11441037058830261\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6874251\n",
      "\tspeed: 0.0346s/iter; left time: 613.1393s\n",
      "\titers: 200, epoch: 1 | loss: 0.5854033\n",
      "\tspeed: 0.0323s/iter; left time: 569.1025s\n",
      "\titers: 300, epoch: 1 | loss: 0.5570576\n",
      "\tspeed: 0.0323s/iter; left time: 565.8339s\n",
      "\titers: 400, epoch: 1 | loss: 0.5144084\n",
      "\tspeed: 0.0322s/iter; left time: 561.3003s\n",
      "\titers: 500, epoch: 1 | loss: 0.4904325\n",
      "\tspeed: 0.0322s/iter; left time: 557.4493s\n",
      "\titers: 600, epoch: 1 | loss: 0.5035841\n",
      "\tspeed: 0.0323s/iter; left time: 555.4173s\n",
      "\titers: 700, epoch: 1 | loss: 0.4871917\n",
      "\tspeed: 0.0323s/iter; left time: 552.3854s\n",
      "\titers: 800, epoch: 1 | loss: 0.4610247\n",
      "\tspeed: 0.0322s/iter; left time: 548.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.00s\n",
      "Steps: 891 | Train Loss: 0.5570646 Vali Loss: 0.4491257 Test Loss: 0.4569663\n",
      "Validation loss decreased (inf --> 0.449126).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4078445\n",
      "\tspeed: 0.1168s/iter; left time: 1965.0370s\n",
      "\titers: 200, epoch: 2 | loss: 0.4404646\n",
      "\tspeed: 0.0324s/iter; left time: 541.3415s\n",
      "\titers: 300, epoch: 2 | loss: 0.3947672\n",
      "\tspeed: 0.0410s/iter; left time: 682.5215s\n",
      "\titers: 400, epoch: 2 | loss: 0.3887472\n",
      "\tspeed: 0.0331s/iter; left time: 547.1917s\n",
      "\titers: 500, epoch: 2 | loss: 0.3899078\n",
      "\tspeed: 0.0323s/iter; left time: 530.5505s\n",
      "\titers: 600, epoch: 2 | loss: 0.3777060\n",
      "\tspeed: 0.0323s/iter; left time: 527.0635s\n",
      "\titers: 700, epoch: 2 | loss: 0.3749471\n",
      "\tspeed: 0.0323s/iter; left time: 524.8636s\n",
      "\titers: 800, epoch: 2 | loss: 0.4034452\n",
      "\tspeed: 0.0323s/iter; left time: 521.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:30.29s\n",
      "Steps: 891 | Train Loss: 0.3947710 Vali Loss: 0.3646075 Test Loss: 0.3790632\n",
      "Validation loss decreased (0.449126 --> 0.364608).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3701350\n",
      "\tspeed: 0.1219s/iter; left time: 1942.7896s\n",
      "\titers: 200, epoch: 3 | loss: 0.3418259\n",
      "\tspeed: 0.0338s/iter; left time: 535.0591s\n",
      "\titers: 300, epoch: 3 | loss: 0.3310635\n",
      "\tspeed: 0.0329s/iter; left time: 517.7160s\n",
      "\titers: 400, epoch: 3 | loss: 0.3689071\n",
      "\tspeed: 0.0326s/iter; left time: 509.8424s\n",
      "\titers: 500, epoch: 3 | loss: 0.3612926\n",
      "\tspeed: 0.0333s/iter; left time: 517.3601s\n",
      "\titers: 600, epoch: 3 | loss: 0.3443550\n",
      "\tspeed: 0.0324s/iter; left time: 500.8244s\n",
      "\titers: 700, epoch: 3 | loss: 0.3882134\n",
      "\tspeed: 0.0322s/iter; left time: 493.4073s\n",
      "\titers: 800, epoch: 3 | loss: 0.3592698\n",
      "\tspeed: 0.0322s/iter; left time: 490.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.53s\n",
      "Steps: 891 | Train Loss: 0.3611405 Vali Loss: 0.3606587 Test Loss: 0.3761629\n",
      "Validation loss decreased (0.364608 --> 0.360659).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3375158\n",
      "\tspeed: 0.1200s/iter; left time: 1805.8784s\n",
      "\titers: 200, epoch: 4 | loss: 0.3405784\n",
      "\tspeed: 0.0322s/iter; left time: 481.3963s\n",
      "\titers: 300, epoch: 4 | loss: 0.3177379\n",
      "\tspeed: 0.0322s/iter; left time: 478.6232s\n",
      "\titers: 400, epoch: 4 | loss: 0.3207020\n",
      "\tspeed: 0.0322s/iter; left time: 475.1805s\n",
      "\titers: 500, epoch: 4 | loss: 0.3423826\n",
      "\tspeed: 0.0322s/iter; left time: 471.7505s\n",
      "\titers: 600, epoch: 4 | loss: 0.3957885\n",
      "\tspeed: 0.0322s/iter; left time: 468.6822s\n",
      "\titers: 700, epoch: 4 | loss: 0.3238301\n",
      "\tspeed: 0.0322s/iter; left time: 465.4086s\n",
      "\titers: 800, epoch: 4 | loss: 0.3371016\n",
      "\tspeed: 0.0322s/iter; left time: 462.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.15s\n",
      "Steps: 891 | Train Loss: 0.3511792 Vali Loss: 0.3553438 Test Loss: 0.3699446\n",
      "Validation loss decreased (0.360659 --> 0.355344).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3185120\n",
      "\tspeed: 0.1184s/iter; left time: 1676.5350s\n",
      "\titers: 200, epoch: 5 | loss: 0.3492564\n",
      "\tspeed: 0.0321s/iter; left time: 451.8073s\n",
      "\titers: 300, epoch: 5 | loss: 0.4106488\n",
      "\tspeed: 0.0321s/iter; left time: 448.6834s\n",
      "\titers: 400, epoch: 5 | loss: 0.3996746\n",
      "\tspeed: 0.0322s/iter; left time: 445.6145s\n",
      "\titers: 500, epoch: 5 | loss: 0.3664767\n",
      "\tspeed: 0.0321s/iter; left time: 442.2071s\n",
      "\titers: 600, epoch: 5 | loss: 0.3637887\n",
      "\tspeed: 0.0322s/iter; left time: 439.4876s\n",
      "\titers: 700, epoch: 5 | loss: 0.3268692\n",
      "\tspeed: 0.0322s/iter; left time: 436.2363s\n",
      "\titers: 800, epoch: 5 | loss: 0.3361259\n",
      "\tspeed: 0.0322s/iter; left time: 432.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.94s\n",
      "Steps: 891 | Train Loss: 0.3449557 Vali Loss: 0.3526857 Test Loss: 0.3708680\n",
      "Validation loss decreased (0.355344 --> 0.352686).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3059343\n",
      "\tspeed: 0.1208s/iter; left time: 1603.0053s\n",
      "\titers: 200, epoch: 6 | loss: 0.3638947\n",
      "\tspeed: 0.0322s/iter; left time: 423.4781s\n",
      "\titers: 300, epoch: 6 | loss: 0.3797022\n",
      "\tspeed: 0.0328s/iter; left time: 429.1293s\n",
      "\titers: 400, epoch: 6 | loss: 0.3288668\n",
      "\tspeed: 0.0322s/iter; left time: 417.1840s\n",
      "\titers: 500, epoch: 6 | loss: 0.3410768\n",
      "\tspeed: 0.0322s/iter; left time: 414.0365s\n",
      "\titers: 600, epoch: 6 | loss: 0.3046964\n",
      "\tspeed: 0.0332s/iter; left time: 423.2625s\n",
      "\titers: 700, epoch: 6 | loss: 0.3404973\n",
      "\tspeed: 0.0328s/iter; left time: 414.9645s\n",
      "\titers: 800, epoch: 6 | loss: 0.3726162\n",
      "\tspeed: 0.0322s/iter; left time: 405.0186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 891 | Train Loss: 0.3402606 Vali Loss: 0.3548367 Test Loss: 0.3698507\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3532450\n",
      "\tspeed: 0.1202s/iter; left time: 1487.0180s\n",
      "\titers: 200, epoch: 7 | loss: 0.3472324\n",
      "\tspeed: 0.0322s/iter; left time: 394.8929s\n",
      "\titers: 300, epoch: 7 | loss: 0.4106057\n",
      "\tspeed: 0.0322s/iter; left time: 391.8255s\n",
      "\titers: 400, epoch: 7 | loss: 0.3288011\n",
      "\tspeed: 0.0322s/iter; left time: 388.8847s\n",
      "\titers: 500, epoch: 7 | loss: 0.3194849\n",
      "\tspeed: 0.0322s/iter; left time: 385.9546s\n",
      "\titers: 600, epoch: 7 | loss: 0.3120731\n",
      "\tspeed: 0.0322s/iter; left time: 382.4033s\n",
      "\titers: 700, epoch: 7 | loss: 0.3138196\n",
      "\tspeed: 0.0322s/iter; left time: 379.6864s\n",
      "\titers: 800, epoch: 7 | loss: 0.3679406\n",
      "\tspeed: 0.0322s/iter; left time: 376.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.05s\n",
      "Steps: 891 | Train Loss: 0.3360085 Vali Loss: 0.3513015 Test Loss: 0.3692293\n",
      "Validation loss decreased (0.352686 --> 0.351301).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3187053\n",
      "\tspeed: 0.1195s/iter; left time: 1372.1665s\n",
      "\titers: 200, epoch: 8 | loss: 0.2966263\n",
      "\tspeed: 0.0322s/iter; left time: 366.1884s\n",
      "\titers: 300, epoch: 8 | loss: 0.3254100\n",
      "\tspeed: 0.0322s/iter; left time: 363.1997s\n",
      "\titers: 400, epoch: 8 | loss: 0.3364365\n",
      "\tspeed: 0.0322s/iter; left time: 359.9977s\n",
      "\titers: 500, epoch: 8 | loss: 0.3597936\n",
      "\tspeed: 0.0322s/iter; left time: 356.7773s\n",
      "\titers: 600, epoch: 8 | loss: 0.3181033\n",
      "\tspeed: 0.0322s/iter; left time: 353.3925s\n",
      "\titers: 700, epoch: 8 | loss: 0.3530628\n",
      "\tspeed: 0.0322s/iter; left time: 350.5810s\n",
      "\titers: 800, epoch: 8 | loss: 0.3444417\n",
      "\tspeed: 0.0322s/iter; left time: 347.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.98s\n",
      "Steps: 891 | Train Loss: 0.3324220 Vali Loss: 0.3536215 Test Loss: 0.3692212\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3790807\n",
      "\tspeed: 0.1158s/iter; left time: 1226.8976s\n",
      "\titers: 200, epoch: 9 | loss: 0.3614714\n",
      "\tspeed: 0.0330s/iter; left time: 346.7443s\n",
      "\titers: 300, epoch: 9 | loss: 0.3256419\n",
      "\tspeed: 0.0327s/iter; left time: 340.2868s\n",
      "\titers: 400, epoch: 9 | loss: 0.3395175\n",
      "\tspeed: 0.0321s/iter; left time: 330.8968s\n",
      "\titers: 500, epoch: 9 | loss: 0.3370060\n",
      "\tspeed: 0.0322s/iter; left time: 327.8666s\n",
      "\titers: 600, epoch: 9 | loss: 0.3032283\n",
      "\tspeed: 0.0322s/iter; left time: 325.0535s\n",
      "\titers: 700, epoch: 9 | loss: 0.3176999\n",
      "\tspeed: 0.0322s/iter; left time: 322.1479s\n",
      "\titers: 800, epoch: 9 | loss: 0.3679609\n",
      "\tspeed: 0.0337s/iter; left time: 333.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.31s\n",
      "Steps: 891 | Train Loss: 0.3293696 Vali Loss: 0.3546576 Test Loss: 0.3693305\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3161399\n",
      "\tspeed: 0.1148s/iter; left time: 1113.8904s\n",
      "\titers: 200, epoch: 10 | loss: 0.3011234\n",
      "\tspeed: 0.0322s/iter; left time: 308.9699s\n",
      "\titers: 300, epoch: 10 | loss: 0.2857997\n",
      "\tspeed: 0.0322s/iter; left time: 305.7782s\n",
      "\titers: 400, epoch: 10 | loss: 0.3672584\n",
      "\tspeed: 0.0322s/iter; left time: 302.5592s\n",
      "\titers: 500, epoch: 10 | loss: 0.3294429\n",
      "\tspeed: 0.0322s/iter; left time: 299.2666s\n",
      "\titers: 600, epoch: 10 | loss: 0.2849515\n",
      "\tspeed: 0.0322s/iter; left time: 296.1699s\n",
      "\titers: 700, epoch: 10 | loss: 0.3099799\n",
      "\tspeed: 0.0322s/iter; left time: 293.2885s\n",
      "\titers: 800, epoch: 10 | loss: 0.3419327\n",
      "\tspeed: 0.0322s/iter; left time: 289.7393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.93s\n",
      "Steps: 891 | Train Loss: 0.3264639 Vali Loss: 0.3606435 Test Loss: 0.3691833\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.37962606549263, rmse:0.6161380410194397, mae:0.36922937631607056, rse:0.5641388893127441\n",
      "Original data scale mse:2620916.5, rmse:1618.9244384765625, mae:1033.93017578125, rse:0.11393032968044281\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7270476\n",
      "\tspeed: 0.0528s/iter; left time: 932.9705s\n",
      "\titers: 200, epoch: 1 | loss: 0.5669037\n",
      "\tspeed: 0.0324s/iter; left time: 570.3238s\n",
      "\titers: 300, epoch: 1 | loss: 0.5388072\n",
      "\tspeed: 0.0324s/iter; left time: 567.0931s\n",
      "\titers: 400, epoch: 1 | loss: 0.5685266\n",
      "\tspeed: 0.0325s/iter; left time: 565.2309s\n",
      "\titers: 500, epoch: 1 | loss: 0.5379171\n",
      "\tspeed: 0.0338s/iter; left time: 584.8754s\n",
      "\titers: 600, epoch: 1 | loss: 0.5119932\n",
      "\tspeed: 0.0325s/iter; left time: 558.4984s\n",
      "\titers: 700, epoch: 1 | loss: 0.5141836\n",
      "\tspeed: 0.0335s/iter; left time: 572.8371s\n",
      "\titers: 800, epoch: 1 | loss: 0.4832072\n",
      "\tspeed: 0.0328s/iter; left time: 557.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.58s\n",
      "Steps: 889 | Train Loss: 0.5636466 Vali Loss: 0.4588413 Test Loss: 0.4648027\n",
      "Validation loss decreased (inf --> 0.458841).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4552069\n",
      "\tspeed: 0.1214s/iter; left time: 2039.2439s\n",
      "\titers: 200, epoch: 2 | loss: 0.4404276\n",
      "\tspeed: 0.0326s/iter; left time: 543.3335s\n",
      "\titers: 300, epoch: 2 | loss: 0.4466491\n",
      "\tspeed: 0.0325s/iter; left time: 539.6610s\n",
      "\titers: 400, epoch: 2 | loss: 0.4002703\n",
      "\tspeed: 0.0325s/iter; left time: 536.5050s\n",
      "\titers: 500, epoch: 2 | loss: 0.4099946\n",
      "\tspeed: 0.0325s/iter; left time: 533.5179s\n",
      "\titers: 600, epoch: 2 | loss: 0.4178249\n",
      "\tspeed: 0.0326s/iter; left time: 530.4655s\n",
      "\titers: 700, epoch: 2 | loss: 0.3810467\n",
      "\tspeed: 0.0326s/iter; left time: 527.5438s\n",
      "\titers: 800, epoch: 2 | loss: 0.4157515\n",
      "\tspeed: 0.0326s/iter; left time: 524.7588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 889 | Train Loss: 0.4123568 Vali Loss: 0.3900301 Test Loss: 0.3993490\n",
      "Validation loss decreased (0.458841 --> 0.390030).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3762018\n",
      "\tspeed: 0.1158s/iter; left time: 1841.3884s\n",
      "\titers: 200, epoch: 3 | loss: 0.3956524\n",
      "\tspeed: 0.0326s/iter; left time: 514.5123s\n",
      "\titers: 300, epoch: 3 | loss: 0.4080909\n",
      "\tspeed: 0.0326s/iter; left time: 511.1649s\n",
      "\titers: 400, epoch: 3 | loss: 0.3901886\n",
      "\tspeed: 0.0326s/iter; left time: 507.9032s\n",
      "\titers: 500, epoch: 3 | loss: 0.3585455\n",
      "\tspeed: 0.0326s/iter; left time: 505.2689s\n",
      "\titers: 600, epoch: 3 | loss: 0.3528174\n",
      "\tspeed: 0.0326s/iter; left time: 502.2818s\n",
      "\titers: 700, epoch: 3 | loss: 0.3765912\n",
      "\tspeed: 0.0326s/iter; left time: 498.9766s\n",
      "\titers: 800, epoch: 3 | loss: 0.3816853\n",
      "\tspeed: 0.0326s/iter; left time: 495.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 889 | Train Loss: 0.3791943 Vali Loss: 0.3819398 Test Loss: 0.3954139\n",
      "Validation loss decreased (0.390030 --> 0.381940).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3717485\n",
      "\tspeed: 0.1151s/iter; left time: 1728.2704s\n",
      "\titers: 200, epoch: 4 | loss: 0.3574297\n",
      "\tspeed: 0.0338s/iter; left time: 504.1261s\n",
      "\titers: 300, epoch: 4 | loss: 0.3840978\n",
      "\tspeed: 0.0325s/iter; left time: 482.1336s\n",
      "\titers: 400, epoch: 4 | loss: 0.3573242\n",
      "\tspeed: 0.0334s/iter; left time: 491.2952s\n",
      "\titers: 500, epoch: 4 | loss: 0.3399325\n",
      "\tspeed: 0.0330s/iter; left time: 482.8793s\n",
      "\titers: 600, epoch: 4 | loss: 0.3531784\n",
      "\tspeed: 0.0326s/iter; left time: 473.3086s\n",
      "\titers: 700, epoch: 4 | loss: 0.3729576\n",
      "\tspeed: 0.0326s/iter; left time: 470.1939s\n",
      "\titers: 800, epoch: 4 | loss: 0.3626520\n",
      "\tspeed: 0.0326s/iter; left time: 466.9614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.58s\n",
      "Steps: 889 | Train Loss: 0.3691652 Vali Loss: 0.3807053 Test Loss: 0.3919594\n",
      "Validation loss decreased (0.381940 --> 0.380705).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3657677\n",
      "\tspeed: 0.1180s/iter; left time: 1667.2237s\n",
      "\titers: 200, epoch: 5 | loss: 0.3187989\n",
      "\tspeed: 0.0326s/iter; left time: 457.0977s\n",
      "\titers: 300, epoch: 5 | loss: 0.3665122\n",
      "\tspeed: 0.0326s/iter; left time: 453.7981s\n",
      "\titers: 400, epoch: 5 | loss: 0.3917305\n",
      "\tspeed: 0.0325s/iter; left time: 449.9243s\n",
      "\titers: 500, epoch: 5 | loss: 0.3778329\n",
      "\tspeed: 0.0326s/iter; left time: 447.0405s\n",
      "\titers: 600, epoch: 5 | loss: 0.3521453\n",
      "\tspeed: 0.0326s/iter; left time: 443.8069s\n",
      "\titers: 700, epoch: 5 | loss: 0.3765719\n",
      "\tspeed: 0.0326s/iter; left time: 440.6996s\n",
      "\titers: 800, epoch: 5 | loss: 0.3518147\n",
      "\tspeed: 0.0326s/iter; left time: 437.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.19s\n",
      "Steps: 889 | Train Loss: 0.3620906 Vali Loss: 0.3783111 Test Loss: 0.3928422\n",
      "Validation loss decreased (0.380705 --> 0.378311).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3284959\n",
      "\tspeed: 0.1152s/iter; left time: 1524.9903s\n",
      "\titers: 200, epoch: 6 | loss: 0.3727474\n",
      "\tspeed: 0.0326s/iter; left time: 428.3884s\n",
      "\titers: 300, epoch: 6 | loss: 0.3570708\n",
      "\tspeed: 0.0325s/iter; left time: 424.1394s\n",
      "\titers: 400, epoch: 6 | loss: 0.3307027\n",
      "\tspeed: 0.0326s/iter; left time: 421.2445s\n",
      "\titers: 500, epoch: 6 | loss: 0.3360224\n",
      "\tspeed: 0.0326s/iter; left time: 418.1162s\n",
      "\titers: 600, epoch: 6 | loss: 0.3443426\n",
      "\tspeed: 0.0326s/iter; left time: 414.7747s\n",
      "\titers: 700, epoch: 6 | loss: 0.3540103\n",
      "\tspeed: 0.0326s/iter; left time: 412.0781s\n",
      "\titers: 800, epoch: 6 | loss: 0.3428229\n",
      "\tspeed: 0.0326s/iter; left time: 408.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.17s\n",
      "Steps: 889 | Train Loss: 0.3565812 Vali Loss: 0.3808932 Test Loss: 0.3928587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3745449\n",
      "\tspeed: 0.1165s/iter; left time: 1438.8708s\n",
      "\titers: 200, epoch: 7 | loss: 0.3416779\n",
      "\tspeed: 0.0330s/iter; left time: 404.7626s\n",
      "\titers: 300, epoch: 7 | loss: 0.3809003\n",
      "\tspeed: 0.0327s/iter; left time: 396.6752s\n",
      "\titers: 400, epoch: 7 | loss: 0.3749903\n",
      "\tspeed: 0.0329s/iter; left time: 396.2764s\n",
      "\titers: 500, epoch: 7 | loss: 0.3478078\n",
      "\tspeed: 0.0326s/iter; left time: 389.5271s\n",
      "\titers: 600, epoch: 7 | loss: 0.3544452\n",
      "\tspeed: 0.0340s/iter; left time: 402.4789s\n",
      "\titers: 700, epoch: 7 | loss: 0.3269373\n",
      "\tspeed: 0.0326s/iter; left time: 382.6120s\n",
      "\titers: 800, epoch: 7 | loss: 0.3994677\n",
      "\tspeed: 0.0326s/iter; left time: 379.7620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 889 | Train Loss: 0.3516269 Vali Loss: 0.3840469 Test Loss: 0.3960072\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3293174\n",
      "\tspeed: 0.1129s/iter; left time: 1293.0747s\n",
      "\titers: 200, epoch: 8 | loss: 0.3649451\n",
      "\tspeed: 0.0326s/iter; left time: 369.9228s\n",
      "\titers: 300, epoch: 8 | loss: 0.3491306\n",
      "\tspeed: 0.0326s/iter; left time: 366.7068s\n",
      "\titers: 400, epoch: 8 | loss: 0.3366256\n",
      "\tspeed: 0.0326s/iter; left time: 363.5353s\n",
      "\titers: 500, epoch: 8 | loss: 0.3451333\n",
      "\tspeed: 0.0326s/iter; left time: 360.0611s\n",
      "\titers: 600, epoch: 8 | loss: 0.3598365\n",
      "\tspeed: 0.0326s/iter; left time: 356.7324s\n",
      "\titers: 700, epoch: 8 | loss: 0.3534002\n",
      "\tspeed: 0.0326s/iter; left time: 353.8720s\n",
      "\titers: 800, epoch: 8 | loss: 0.3167257\n",
      "\tspeed: 0.0326s/iter; left time: 350.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 889 | Train Loss: 0.3474199 Vali Loss: 0.3864173 Test Loss: 0.3941187\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.41122308373451233, rmse:0.6412667632102966, mae:0.3928421437740326, rse:0.5873218178749084\n",
      "Original data scale mse:3088662.0, rmse:1757.458984375, mae:1125.1514892578125, rse:0.12379570305347443\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6982303\n",
      "\tspeed: 0.0347s/iter; left time: 612.8792s\n",
      "\titers: 200, epoch: 1 | loss: 0.5875710\n",
      "\tspeed: 0.0326s/iter; left time: 572.5886s\n",
      "\titers: 300, epoch: 1 | loss: 0.5245558\n",
      "\tspeed: 0.0326s/iter; left time: 569.7858s\n",
      "\titers: 400, epoch: 1 | loss: 0.5157704\n",
      "\tspeed: 0.0326s/iter; left time: 566.2575s\n",
      "\titers: 500, epoch: 1 | loss: 0.5235018\n",
      "\tspeed: 0.0339s/iter; left time: 586.0699s\n",
      "\titers: 600, epoch: 1 | loss: 0.4996416\n",
      "\tspeed: 0.0326s/iter; left time: 560.1876s\n",
      "\titers: 700, epoch: 1 | loss: 0.4935263\n",
      "\tspeed: 0.0334s/iter; left time: 571.2810s\n",
      "\titers: 800, epoch: 1 | loss: 0.4955661\n",
      "\tspeed: 0.0332s/iter; left time: 563.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.99s\n",
      "Steps: 889 | Train Loss: 0.5604781 Vali Loss: 0.4583968 Test Loss: 0.4649744\n",
      "Validation loss decreased (inf --> 0.458397).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4560531\n",
      "\tspeed: 0.1544s/iter; left time: 2593.4113s\n",
      "\titers: 200, epoch: 2 | loss: 0.4333660\n",
      "\tspeed: 0.0334s/iter; left time: 557.5716s\n",
      "\titers: 300, epoch: 2 | loss: 0.4146414\n",
      "\tspeed: 0.0324s/iter; left time: 538.2796s\n",
      "\titers: 400, epoch: 2 | loss: 0.4280121\n",
      "\tspeed: 0.0325s/iter; left time: 535.9136s\n",
      "\titers: 500, epoch: 2 | loss: 0.3733323\n",
      "\tspeed: 0.0325s/iter; left time: 532.9836s\n",
      "\titers: 600, epoch: 2 | loss: 0.3960021\n",
      "\tspeed: 0.0324s/iter; left time: 528.6336s\n",
      "\titers: 700, epoch: 2 | loss: 0.4008497\n",
      "\tspeed: 0.0325s/iter; left time: 525.8897s\n",
      "\titers: 800, epoch: 2 | loss: 0.3891093\n",
      "\tspeed: 0.0325s/iter; left time: 522.6825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.20s\n",
      "Steps: 889 | Train Loss: 0.4120157 Vali Loss: 0.3898458 Test Loss: 0.3989874\n",
      "Validation loss decreased (0.458397 --> 0.389846).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3948753\n",
      "\tspeed: 0.1185s/iter; left time: 1884.3168s\n",
      "\titers: 200, epoch: 3 | loss: 0.3788526\n",
      "\tspeed: 0.0325s/iter; left time: 513.1821s\n",
      "\titers: 300, epoch: 3 | loss: 0.4068096\n",
      "\tspeed: 0.0339s/iter; left time: 532.1218s\n",
      "\titers: 400, epoch: 3 | loss: 0.3753833\n",
      "\tspeed: 0.0336s/iter; left time: 523.5055s\n",
      "\titers: 500, epoch: 3 | loss: 0.3771241\n",
      "\tspeed: 0.0325s/iter; left time: 504.2931s\n",
      "\titers: 600, epoch: 3 | loss: 0.3847867\n",
      "\tspeed: 0.0325s/iter; left time: 500.6205s\n",
      "\titers: 700, epoch: 3 | loss: 0.3799548\n",
      "\tspeed: 0.0325s/iter; left time: 497.6209s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645066\n",
      "\tspeed: 0.0325s/iter; left time: 494.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.39s\n",
      "Steps: 889 | Train Loss: 0.3784827 Vali Loss: 0.3825206 Test Loss: 0.3937073\n",
      "Validation loss decreased (0.389846 --> 0.382521).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3667192\n",
      "\tspeed: 0.1216s/iter; left time: 1825.1707s\n",
      "\titers: 200, epoch: 4 | loss: 0.3428490\n",
      "\tspeed: 0.0328s/iter; left time: 489.2075s\n",
      "\titers: 300, epoch: 4 | loss: 0.3957298\n",
      "\tspeed: 0.0326s/iter; left time: 482.9697s\n",
      "\titers: 400, epoch: 4 | loss: 0.4024765\n",
      "\tspeed: 0.0326s/iter; left time: 480.2436s\n",
      "\titers: 500, epoch: 4 | loss: 0.3775966\n",
      "\tspeed: 0.0326s/iter; left time: 475.7686s\n",
      "\titers: 600, epoch: 4 | loss: 0.3281412\n",
      "\tspeed: 0.0326s/iter; left time: 472.6081s\n",
      "\titers: 700, epoch: 4 | loss: 0.3707654\n",
      "\tspeed: 0.0326s/iter; left time: 469.3643s\n",
      "\titers: 800, epoch: 4 | loss: 0.3532638\n",
      "\tspeed: 0.0326s/iter; left time: 466.5220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.30s\n",
      "Steps: 889 | Train Loss: 0.3691993 Vali Loss: 0.3772049 Test Loss: 0.3906495\n",
      "Validation loss decreased (0.382521 --> 0.377205).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3325445\n",
      "\tspeed: 0.1168s/iter; left time: 1649.4127s\n",
      "\titers: 200, epoch: 5 | loss: 0.3620659\n",
      "\tspeed: 0.0328s/iter; left time: 460.6380s\n",
      "\titers: 300, epoch: 5 | loss: 0.3949550\n",
      "\tspeed: 0.0328s/iter; left time: 457.1060s\n",
      "\titers: 400, epoch: 5 | loss: 0.3453274\n",
      "\tspeed: 0.0328s/iter; left time: 453.7335s\n",
      "\titers: 500, epoch: 5 | loss: 0.3764210\n",
      "\tspeed: 0.0328s/iter; left time: 450.3809s\n",
      "\titers: 600, epoch: 5 | loss: 0.3788173\n",
      "\tspeed: 0.0329s/iter; left time: 447.7053s\n",
      "\titers: 700, epoch: 5 | loss: 0.3733041\n",
      "\tspeed: 0.0329s/iter; left time: 444.3458s\n",
      "\titers: 800, epoch: 5 | loss: 0.3857840\n",
      "\tspeed: 0.0328s/iter; left time: 440.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 889 | Train Loss: 0.3627478 Vali Loss: 0.3799118 Test Loss: 0.3965525\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3650259\n",
      "\tspeed: 0.1156s/iter; left time: 1530.2754s\n",
      "\titers: 200, epoch: 6 | loss: 0.3788296\n",
      "\tspeed: 0.0329s/iter; left time: 431.7925s\n",
      "\titers: 300, epoch: 6 | loss: 0.3488452\n",
      "\tspeed: 0.0328s/iter; left time: 427.8715s\n",
      "\titers: 400, epoch: 6 | loss: 0.3558772\n",
      "\tspeed: 0.0329s/iter; left time: 425.0940s\n",
      "\titers: 500, epoch: 6 | loss: 0.3700227\n",
      "\tspeed: 0.0329s/iter; left time: 421.8080s\n",
      "\titers: 600, epoch: 6 | loss: 0.3508479\n",
      "\tspeed: 0.0329s/iter; left time: 418.7552s\n",
      "\titers: 700, epoch: 6 | loss: 0.3783502\n",
      "\tspeed: 0.0329s/iter; left time: 415.7819s\n",
      "\titers: 800, epoch: 6 | loss: 0.3460811\n",
      "\tspeed: 0.0329s/iter; left time: 412.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.47s\n",
      "Steps: 889 | Train Loss: 0.3573227 Vali Loss: 0.3764589 Test Loss: 0.3943146\n",
      "Validation loss decreased (0.377205 --> 0.376459).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3478370\n",
      "\tspeed: 0.1191s/iter; left time: 1470.9815s\n",
      "\titers: 200, epoch: 7 | loss: 0.3941488\n",
      "\tspeed: 0.0329s/iter; left time: 402.6307s\n",
      "\titers: 300, epoch: 7 | loss: 0.3391254\n",
      "\tspeed: 0.0329s/iter; left time: 399.3937s\n",
      "\titers: 400, epoch: 7 | loss: 0.3689819\n",
      "\tspeed: 0.0329s/iter; left time: 396.4404s\n",
      "\titers: 500, epoch: 7 | loss: 0.3634501\n",
      "\tspeed: 0.0329s/iter; left time: 392.8510s\n",
      "\titers: 600, epoch: 7 | loss: 0.3459078\n",
      "\tspeed: 0.0329s/iter; left time: 390.0132s\n",
      "\titers: 700, epoch: 7 | loss: 0.3223836\n",
      "\tspeed: 0.0328s/iter; left time: 385.8790s\n",
      "\titers: 800, epoch: 7 | loss: 0.3470972\n",
      "\tspeed: 0.0328s/iter; left time: 381.9242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 889 | Train Loss: 0.3527341 Vali Loss: 0.3798488 Test Loss: 0.3983599\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3351883\n",
      "\tspeed: 0.1163s/iter; left time: 1332.3327s\n",
      "\titers: 200, epoch: 8 | loss: 0.3315546\n",
      "\tspeed: 0.0328s/iter; left time: 372.5728s\n",
      "\titers: 300, epoch: 8 | loss: 0.3271826\n",
      "\tspeed: 0.0328s/iter; left time: 369.1737s\n",
      "\titers: 400, epoch: 8 | loss: 0.3363646\n",
      "\tspeed: 0.0328s/iter; left time: 365.9305s\n",
      "\titers: 500, epoch: 8 | loss: 0.3173248\n",
      "\tspeed: 0.0328s/iter; left time: 362.6265s\n",
      "\titers: 600, epoch: 8 | loss: 0.3620347\n",
      "\tspeed: 0.0328s/iter; left time: 359.3869s\n",
      "\titers: 700, epoch: 8 | loss: 0.3874176\n",
      "\tspeed: 0.0328s/iter; left time: 356.4424s\n",
      "\titers: 800, epoch: 8 | loss: 0.3320169\n",
      "\tspeed: 0.0328s/iter; left time: 352.8855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.44s\n",
      "Steps: 889 | Train Loss: 0.3486719 Vali Loss: 0.3821284 Test Loss: 0.3986234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3709632\n",
      "\tspeed: 0.1155s/iter; left time: 1220.9882s\n",
      "\titers: 200, epoch: 9 | loss: 0.3439408\n",
      "\tspeed: 0.0329s/iter; left time: 344.7523s\n",
      "\titers: 300, epoch: 9 | loss: 0.3630788\n",
      "\tspeed: 0.0329s/iter; left time: 341.3921s\n",
      "\titers: 400, epoch: 9 | loss: 0.3211525\n",
      "\tspeed: 0.0329s/iter; left time: 338.3111s\n",
      "\titers: 500, epoch: 9 | loss: 0.3290427\n",
      "\tspeed: 0.0329s/iter; left time: 334.7145s\n",
      "\titers: 600, epoch: 9 | loss: 0.3406472\n",
      "\tspeed: 0.0329s/iter; left time: 331.6363s\n",
      "\titers: 700, epoch: 9 | loss: 0.3692785\n",
      "\tspeed: 0.0329s/iter; left time: 327.6490s\n",
      "\titers: 800, epoch: 9 | loss: 0.3376790\n",
      "\tspeed: 0.0328s/iter; left time: 323.5760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:29.44s\n",
      "Steps: 889 | Train Loss: 0.3457095 Vali Loss: 0.3829813 Test Loss: 0.3970268\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.41676291823387146, rmse:0.645571768283844, mae:0.39431434869766235, rse:0.5912646651268005\n",
      "Original data scale mse:3025792.0, rmse:1739.4803466796875, mae:1117.3406982421875, rse:0.1225292906165123\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2019</td>\n",
       "      <td>0.4494</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.4116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.4149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.5951</td>\n",
       "      <td>0.3814</td>\n",
       "      <td>0.5449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.3790</td>\n",
       "      <td>0.5436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3829</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.5667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.5643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.4120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.2566</td>\n",
       "      <td>0.4144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.6068</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.5556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3796</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.5641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4112</td>\n",
       "      <td>0.6413</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0.5873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4168</td>\n",
       "      <td>0.6456</td>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.5913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2019  0.4494  0.2719  0.4116\n",
       "              2         24        0.2052  0.4530  0.2725  0.4149\n",
       "              1         96        0.3542  0.5951  0.3814  0.5449\n",
       "              2         96        0.3525  0.5937  0.3790  0.5436\n",
       "              1         168       0.3829  0.6188  0.4046  0.5667\n",
       "              2         168       0.3796  0.6161  0.4080  0.5643\n",
       "MAE           1         24        0.2024  0.4498  0.2565  0.4120\n",
       "              2         24        0.2047  0.4525  0.2566  0.4144\n",
       "              1         96        0.3682  0.6068  0.3692  0.5556\n",
       "              2         96        0.3796  0.6161  0.3692  0.5641\n",
       "              1         168       0.4112  0.6413  0.3928  0.5873\n",
       "              2         168       0.4168  0.6456  0.3943  0.5913"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1312173.250</td>\n",
       "      <td>1145.5013</td>\n",
       "      <td>756.4719</td>\n",
       "      <td>0.0805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1321465.125</td>\n",
       "      <td>1149.5499</td>\n",
       "      <td>759.6286</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2694919.000</td>\n",
       "      <td>1641.6208</td>\n",
       "      <td>1102.1880</td>\n",
       "      <td>0.1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2625019.000</td>\n",
       "      <td>1620.1910</td>\n",
       "      <td>1093.8665</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3139875.250</td>\n",
       "      <td>1771.9694</td>\n",
       "      <td>1196.2166</td>\n",
       "      <td>0.1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3260984.750</td>\n",
       "      <td>1805.8197</td>\n",
       "      <td>1226.3945</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1205955.250</td>\n",
       "      <td>1098.1599</td>\n",
       "      <td>689.5394</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1217987.250</td>\n",
       "      <td>1103.6246</td>\n",
       "      <td>689.6762</td>\n",
       "      <td>0.0776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2643049.500</td>\n",
       "      <td>1625.7458</td>\n",
       "      <td>1045.0140</td>\n",
       "      <td>0.1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2620916.500</td>\n",
       "      <td>1618.9244</td>\n",
       "      <td>1033.9302</td>\n",
       "      <td>0.1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3088662.000</td>\n",
       "      <td>1757.4590</td>\n",
       "      <td>1125.1515</td>\n",
       "      <td>0.1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3025792.000</td>\n",
       "      <td>1739.4803</td>\n",
       "      <td>1117.3407</td>\n",
       "      <td>0.1225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1312173.250  1145.5013   756.4719  0.0805\n",
       "              2         24        1321465.125  1149.5499   759.6286  0.0808\n",
       "              1         96        2694919.000  1641.6208  1102.1880  0.1155\n",
       "              2         96        2625019.000  1620.1910  1093.8665  0.1140\n",
       "              1         168       3139875.250  1771.9694  1196.2166  0.1248\n",
       "              2         168       3260984.750  1805.8197  1226.3945  0.1272\n",
       "MAE           1         24        1205955.250  1098.1599   689.5394  0.0772\n",
       "              2         24        1217987.250  1103.6246   689.6762  0.0776\n",
       "              1         96        2643049.500  1625.7458  1045.0140  0.1144\n",
       "              2         96        2620916.500  1618.9244  1033.9302  0.1139\n",
       "              1         168       3088662.000  1757.4590  1125.1515  0.1238\n",
       "              2         168       3025792.000  1739.4803  1117.3407  0.1225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.4132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.4512</td>\n",
       "      <td>0.2722</td>\n",
       "      <td>0.4132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.6115</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.5599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>0.5443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4140</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3813</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.4063</td>\n",
       "      <td>0.5655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2036  0.4512  0.2565  0.4132\n",
       "         MSE            0.2036  0.4512  0.2722  0.4132\n",
       "96       MAE            0.3739  0.6115  0.3692  0.5599\n",
       "         MSE            0.3534  0.5944  0.3802  0.5443\n",
       "168      MAE            0.4140  0.6434  0.3936  0.5893\n",
       "         MSE            0.3813  0.6175  0.4063  0.5655"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.211971e+06</td>\n",
       "      <td>1100.8923</td>\n",
       "      <td>689.6078</td>\n",
       "      <td>0.0774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.316819e+06</td>\n",
       "      <td>1147.5256</td>\n",
       "      <td>758.0503</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.631983e+06</td>\n",
       "      <td>1622.3351</td>\n",
       "      <td>1039.4721</td>\n",
       "      <td>0.1142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.659969e+06</td>\n",
       "      <td>1630.9059</td>\n",
       "      <td>1098.0272</td>\n",
       "      <td>0.1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.057227e+06</td>\n",
       "      <td>1748.4697</td>\n",
       "      <td>1121.2461</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.200430e+06</td>\n",
       "      <td>1788.8945</td>\n",
       "      <td>1211.3055</td>\n",
       "      <td>0.1260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.211971e+06  1100.8923   689.6078  0.0774\n",
       "         MSE            1.316819e+06  1147.5256   758.0503  0.0806\n",
       "96       MAE            2.631983e+06  1622.3351  1039.4721  0.1142\n",
       "         MSE            2.659969e+06  1630.9059  1098.0272  0.1148\n",
       "168      MAE            3.057227e+06  1748.4697  1121.2461  0.1232\n",
       "         MSE            3.200430e+06  1788.8945  1211.3055  0.1260"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled_IT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1442611\n",
      "\tspeed: 0.0548s/iter; left time: 987.4905s\n",
      "\titers: 200, epoch: 1 | loss: 0.1330288\n",
      "\tspeed: 0.0298s/iter; left time: 533.3092s\n",
      "\titers: 300, epoch: 1 | loss: 0.1246196\n",
      "\tspeed: 0.0298s/iter; left time: 531.4279s\n",
      "\titers: 400, epoch: 1 | loss: 0.1301423\n",
      "\tspeed: 0.0298s/iter; left time: 527.9704s\n",
      "\titers: 500, epoch: 1 | loss: 0.1105557\n",
      "\tspeed: 0.0298s/iter; left time: 525.0593s\n",
      "\titers: 600, epoch: 1 | loss: 0.1012148\n",
      "\tspeed: 0.0298s/iter; left time: 521.2817s\n",
      "\titers: 700, epoch: 1 | loss: 0.0925243\n",
      "\tspeed: 0.0297s/iter; left time: 518.1868s\n",
      "\titers: 800, epoch: 1 | loss: 0.0934068\n",
      "\tspeed: 0.0297s/iter; left time: 515.0631s\n",
      "\titers: 900, epoch: 1 | loss: 0.0932732\n",
      "\tspeed: 0.0297s/iter; left time: 512.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.68s\n",
      "Steps: 906 | Train Loss: 0.1163214 Vali Loss: 0.0844860 Test Loss: 0.0991064\n",
      "Validation loss decreased (inf --> 0.084486).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0607003\n",
      "\tspeed: 0.0985s/iter; left time: 1686.3065s\n",
      "\titers: 200, epoch: 2 | loss: 0.0343048\n",
      "\tspeed: 0.0298s/iter; left time: 507.8108s\n",
      "\titers: 300, epoch: 2 | loss: 0.0262060\n",
      "\tspeed: 0.0305s/iter; left time: 515.3921s\n",
      "\titers: 400, epoch: 2 | loss: 0.0250035\n",
      "\tspeed: 0.0301s/iter; left time: 505.4224s\n",
      "\titers: 500, epoch: 2 | loss: 0.0261994\n",
      "\tspeed: 0.0298s/iter; left time: 497.8599s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 600, epoch: 2 | loss: 0.0234527\n",
      "\tspeed: 0.0299s/iter; left time: 496.8980s\n",
      "\titers: 700, epoch: 2 | loss: 0.0208072\n",
      "\tspeed: 0.0297s/iter; left time: 491.2887s\n",
      "\titers: 800, epoch: 2 | loss: 0.0212584\n",
      "\tspeed: 0.0300s/iter; left time: 493.1181s\n",
      "\titers: 900, epoch: 2 | loss: 0.0207911\n",
      "\tspeed: 0.0305s/iter; left time: 498.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.57s\n",
      "Steps: 906 | Train Loss: 0.0312752 Vali Loss: 0.0131057 Test Loss: 0.0143359\n",
      "Validation loss decreased (0.084486 --> 0.013106).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0202638\n",
      "\tspeed: 0.0864s/iter; left time: 1400.4847s\n",
      "\titers: 200, epoch: 3 | loss: 0.0160392\n",
      "\tspeed: 0.0298s/iter; left time: 480.2914s\n",
      "\titers: 300, epoch: 3 | loss: 0.0193679\n",
      "\tspeed: 0.0298s/iter; left time: 477.2098s\n",
      "\titers: 400, epoch: 3 | loss: 0.0150699\n",
      "\tspeed: 0.0298s/iter; left time: 474.2034s\n",
      "\titers: 500, epoch: 3 | loss: 0.0208335\n",
      "\tspeed: 0.0298s/iter; left time: 471.2193s\n",
      "\titers: 600, epoch: 3 | loss: 0.0170691\n",
      "\tspeed: 0.0298s/iter; left time: 468.1836s\n",
      "\titers: 700, epoch: 3 | loss: 0.0133923\n",
      "\tspeed: 0.0298s/iter; left time: 465.2911s\n",
      "\titers: 800, epoch: 3 | loss: 0.0149182\n",
      "\tspeed: 0.0298s/iter; left time: 462.2814s\n",
      "\titers: 900, epoch: 3 | loss: 0.0139291\n",
      "\tspeed: 0.0298s/iter; left time: 459.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.0169382 Vali Loss: 0.0122507 Test Loss: 0.0130448\n",
      "Validation loss decreased (0.013106 --> 0.012251).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0136599\n",
      "\tspeed: 0.0855s/iter; left time: 1307.8115s\n",
      "\titers: 200, epoch: 4 | loss: 0.0125735\n",
      "\tspeed: 0.0297s/iter; left time: 451.7231s\n",
      "\titers: 300, epoch: 4 | loss: 0.0141964\n",
      "\tspeed: 0.0297s/iter; left time: 449.0312s\n",
      "\titers: 400, epoch: 4 | loss: 0.0141679\n",
      "\tspeed: 0.0297s/iter; left time: 445.7824s\n",
      "\titers: 500, epoch: 4 | loss: 0.0127503\n",
      "\tspeed: 0.0297s/iter; left time: 442.8327s\n",
      "\titers: 600, epoch: 4 | loss: 0.0167954\n",
      "\tspeed: 0.0297s/iter; left time: 439.8572s\n",
      "\titers: 700, epoch: 4 | loss: 0.0168050\n",
      "\tspeed: 0.0297s/iter; left time: 437.2491s\n",
      "\titers: 800, epoch: 4 | loss: 0.0152211\n",
      "\tspeed: 0.0297s/iter; left time: 433.8700s\n",
      "\titers: 900, epoch: 4 | loss: 0.0161852\n",
      "\tspeed: 0.0297s/iter; left time: 430.9543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.0139525 Vali Loss: 0.0115478 Test Loss: 0.0129588\n",
      "Validation loss decreased (0.012251 --> 0.011548).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0116978\n",
      "\tspeed: 0.0847s/iter; left time: 1219.2069s\n",
      "\titers: 200, epoch: 5 | loss: 0.0107528\n",
      "\tspeed: 0.0298s/iter; left time: 425.9266s\n",
      "\titers: 300, epoch: 5 | loss: 0.0105410\n",
      "\tspeed: 0.0298s/iter; left time: 422.5944s\n",
      "\titers: 400, epoch: 5 | loss: 0.0106397\n",
      "\tspeed: 0.0298s/iter; left time: 419.5688s\n",
      "\titers: 500, epoch: 5 | loss: 0.0161156\n",
      "\tspeed: 0.0298s/iter; left time: 416.5833s\n",
      "\titers: 600, epoch: 5 | loss: 0.0103516\n",
      "\tspeed: 0.0298s/iter; left time: 413.6893s\n",
      "\titers: 700, epoch: 5 | loss: 0.0139339\n",
      "\tspeed: 0.0297s/iter; left time: 410.0877s\n",
      "\titers: 800, epoch: 5 | loss: 0.0105400\n",
      "\tspeed: 0.0297s/iter; left time: 407.4756s\n",
      "\titers: 900, epoch: 5 | loss: 0.0136083\n",
      "\tspeed: 0.0298s/iter; left time: 404.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.0123763 Vali Loss: 0.0105932 Test Loss: 0.0116680\n",
      "Validation loss decreased (0.011548 --> 0.010593).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0117407\n",
      "\tspeed: 0.0844s/iter; left time: 1138.3481s\n",
      "\titers: 200, epoch: 6 | loss: 0.0114923\n",
      "\tspeed: 0.0297s/iter; left time: 398.2014s\n",
      "\titers: 300, epoch: 6 | loss: 0.0143046\n",
      "\tspeed: 0.0297s/iter; left time: 395.1209s\n",
      "\titers: 400, epoch: 6 | loss: 0.0128260\n",
      "\tspeed: 0.0297s/iter; left time: 391.7118s\n",
      "\titers: 500, epoch: 6 | loss: 0.0102818\n",
      "\tspeed: 0.0297s/iter; left time: 388.9381s\n",
      "\titers: 600, epoch: 6 | loss: 0.0126296\n",
      "\tspeed: 0.0297s/iter; left time: 385.9025s\n",
      "\titers: 700, epoch: 6 | loss: 0.0140987\n",
      "\tspeed: 0.0297s/iter; left time: 383.1803s\n",
      "\titers: 800, epoch: 6 | loss: 0.0098945\n",
      "\tspeed: 0.0298s/iter; left time: 380.6316s\n",
      "\titers: 900, epoch: 6 | loss: 0.0127391\n",
      "\tspeed: 0.0297s/iter; left time: 377.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.0115221 Vali Loss: 0.0105335 Test Loss: 0.0115794\n",
      "Validation loss decreased (0.010593 --> 0.010533).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0119838\n",
      "\tspeed: 0.0847s/iter; left time: 1065.8724s\n",
      "\titers: 200, epoch: 7 | loss: 0.0088632\n",
      "\tspeed: 0.0297s/iter; left time: 371.1758s\n",
      "\titers: 300, epoch: 7 | loss: 0.0088754\n",
      "\tspeed: 0.0298s/iter; left time: 368.5343s\n",
      "\titers: 400, epoch: 7 | loss: 0.0094725\n",
      "\tspeed: 0.0298s/iter; left time: 365.5484s\n",
      "\titers: 500, epoch: 7 | loss: 0.0098783\n",
      "\tspeed: 0.0297s/iter; left time: 362.2855s\n",
      "\titers: 600, epoch: 7 | loss: 0.0082472\n",
      "\tspeed: 0.0297s/iter; left time: 359.3926s\n",
      "\titers: 700, epoch: 7 | loss: 0.0098130\n",
      "\tspeed: 0.0297s/iter; left time: 356.2615s\n",
      "\titers: 800, epoch: 7 | loss: 0.0129564\n",
      "\tspeed: 0.0297s/iter; left time: 353.4137s\n",
      "\titers: 900, epoch: 7 | loss: 0.0102865\n",
      "\tspeed: 0.0297s/iter; left time: 350.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.0108247 Vali Loss: 0.0097810 Test Loss: 0.0110267\n",
      "Validation loss decreased (0.010533 --> 0.009781).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0096078\n",
      "\tspeed: 0.0849s/iter; left time: 991.4774s\n",
      "\titers: 200, epoch: 8 | loss: 0.0082815\n",
      "\tspeed: 0.0305s/iter; left time: 353.6903s\n",
      "\titers: 300, epoch: 8 | loss: 0.0101124\n",
      "\tspeed: 0.0305s/iter; left time: 350.5934s\n",
      "\titers: 400, epoch: 8 | loss: 0.0094736\n",
      "\tspeed: 0.0305s/iter; left time: 347.5328s\n",
      "\titers: 500, epoch: 8 | loss: 0.0116006\n",
      "\tspeed: 0.0305s/iter; left time: 344.4491s\n",
      "\titers: 600, epoch: 8 | loss: 0.0117530\n",
      "\tspeed: 0.0305s/iter; left time: 341.4882s\n",
      "\titers: 700, epoch: 8 | loss: 0.0099294\n",
      "\tspeed: 0.0305s/iter; left time: 338.3392s\n",
      "\titers: 800, epoch: 8 | loss: 0.0098161\n",
      "\tspeed: 0.0298s/iter; left time: 326.8640s\n",
      "\titers: 900, epoch: 8 | loss: 0.0117540\n",
      "\tspeed: 0.0297s/iter; left time: 323.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.76s\n",
      "Steps: 906 | Train Loss: 0.0103724 Vali Loss: 0.0097335 Test Loss: 0.0109858\n",
      "Validation loss decreased (0.009781 --> 0.009733).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0088905\n",
      "\tspeed: 0.0853s/iter; left time: 919.1229s\n",
      "\titers: 200, epoch: 9 | loss: 0.0108472\n",
      "\tspeed: 0.0298s/iter; left time: 317.9102s\n",
      "\titers: 300, epoch: 9 | loss: 0.0090449\n",
      "\tspeed: 0.0298s/iter; left time: 314.7926s\n",
      "\titers: 400, epoch: 9 | loss: 0.0121371\n",
      "\tspeed: 0.0298s/iter; left time: 311.8608s\n",
      "\titers: 500, epoch: 9 | loss: 0.0101456\n",
      "\tspeed: 0.0298s/iter; left time: 308.8714s\n",
      "\titers: 600, epoch: 9 | loss: 0.0102536\n",
      "\tspeed: 0.0298s/iter; left time: 305.7008s\n",
      "\titers: 700, epoch: 9 | loss: 0.0104068\n",
      "\tspeed: 0.0297s/iter; left time: 302.2889s\n",
      "\titers: 800, epoch: 9 | loss: 0.0095396\n",
      "\tspeed: 0.0297s/iter; left time: 299.4481s\n",
      "\titers: 900, epoch: 9 | loss: 0.0102056\n",
      "\tspeed: 0.0297s/iter; left time: 296.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.0099921 Vali Loss: 0.0093397 Test Loss: 0.0106632\n",
      "Validation loss decreased (0.009733 --> 0.009340).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0101062\n",
      "\tspeed: 0.0850s/iter; left time: 839.1311s\n",
      "\titers: 200, epoch: 10 | loss: 0.0084982\n",
      "\tspeed: 0.0298s/iter; left time: 291.0603s\n",
      "\titers: 300, epoch: 10 | loss: 0.0107522\n",
      "\tspeed: 0.0300s/iter; left time: 289.8426s\n",
      "\titers: 400, epoch: 10 | loss: 0.0105198\n",
      "\tspeed: 0.0298s/iter; left time: 285.1869s\n",
      "\titers: 500, epoch: 10 | loss: 0.0094096\n",
      "\tspeed: 0.0298s/iter; left time: 282.0824s\n",
      "\titers: 600, epoch: 10 | loss: 0.0088788\n",
      "\tspeed: 0.0298s/iter; left time: 279.1807s\n",
      "\titers: 700, epoch: 10 | loss: 0.0089523\n",
      "\tspeed: 0.0298s/iter; left time: 276.1689s\n",
      "\titers: 800, epoch: 10 | loss: 0.0089778\n",
      "\tspeed: 0.0298s/iter; left time: 273.1723s\n",
      "\titers: 900, epoch: 10 | loss: 0.0119817\n",
      "\tspeed: 0.0298s/iter; left time: 270.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.29s\n",
      "Steps: 906 | Train Loss: 0.0097695 Vali Loss: 0.0093038 Test Loss: 0.0105212\n",
      "Validation loss decreased (0.009340 --> 0.009304).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0081937\n",
      "\tspeed: 0.0858s/iter; left time: 768.5422s\n",
      "\titers: 200, epoch: 11 | loss: 0.0067531\n",
      "\tspeed: 0.0298s/iter; left time: 263.8706s\n",
      "\titers: 300, epoch: 11 | loss: 0.0103547\n",
      "\tspeed: 0.0298s/iter; left time: 261.3363s\n",
      "\titers: 400, epoch: 11 | loss: 0.0106216\n",
      "\tspeed: 0.0298s/iter; left time: 257.9928s\n",
      "\titers: 500, epoch: 11 | loss: 0.0078783\n",
      "\tspeed: 0.0298s/iter; left time: 254.7846s\n",
      "\titers: 600, epoch: 11 | loss: 0.0108294\n",
      "\tspeed: 0.0298s/iter; left time: 251.8285s\n",
      "\titers: 700, epoch: 11 | loss: 0.0097380\n",
      "\tspeed: 0.0298s/iter; left time: 248.8756s\n",
      "\titers: 800, epoch: 11 | loss: 0.0097086\n",
      "\tspeed: 0.0298s/iter; left time: 246.0968s\n",
      "\titers: 900, epoch: 11 | loss: 0.0098636\n",
      "\tspeed: 0.0298s/iter; left time: 243.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.0095456 Vali Loss: 0.0093377 Test Loss: 0.0105352\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0105640\n",
      "\tspeed: 0.0816s/iter; left time: 657.4103s\n",
      "\titers: 200, epoch: 12 | loss: 0.0111127\n",
      "\tspeed: 0.0306s/iter; left time: 243.2870s\n",
      "\titers: 300, epoch: 12 | loss: 0.0111082\n",
      "\tspeed: 0.0306s/iter; left time: 240.1392s\n",
      "\titers: 400, epoch: 12 | loss: 0.0081644\n",
      "\tspeed: 0.0306s/iter; left time: 237.0687s\n",
      "\titers: 500, epoch: 12 | loss: 0.0069198\n",
      "\tspeed: 0.0306s/iter; left time: 233.8657s\n",
      "\titers: 600, epoch: 12 | loss: 0.0100578\n",
      "\tspeed: 0.0305s/iter; left time: 230.7981s\n",
      "\titers: 700, epoch: 12 | loss: 0.0112533\n",
      "\tspeed: 0.0306s/iter; left time: 227.8269s\n",
      "\titers: 800, epoch: 12 | loss: 0.0079106\n",
      "\tspeed: 0.0305s/iter; left time: 224.1106s\n",
      "\titers: 900, epoch: 12 | loss: 0.0076293\n",
      "\tspeed: 0.0298s/iter; left time: 216.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.80s\n",
      "Steps: 906 | Train Loss: 0.0093455 Vali Loss: 0.0093899 Test Loss: 0.0104810\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0114163\n",
      "\tspeed: 0.0836s/iter; left time: 597.3185s\n",
      "\titers: 200, epoch: 13 | loss: 0.0087990\n",
      "\tspeed: 0.0298s/iter; left time: 209.7876s\n",
      "\titers: 300, epoch: 13 | loss: 0.0095320\n",
      "\tspeed: 0.0298s/iter; left time: 206.7818s\n",
      "\titers: 400, epoch: 13 | loss: 0.0107319\n",
      "\tspeed: 0.0298s/iter; left time: 203.8070s\n",
      "\titers: 500, epoch: 13 | loss: 0.0082600\n",
      "\tspeed: 0.0298s/iter; left time: 200.9348s\n",
      "\titers: 600, epoch: 13 | loss: 0.0096551\n",
      "\tspeed: 0.0298s/iter; left time: 197.9453s\n",
      "\titers: 700, epoch: 13 | loss: 0.0105555\n",
      "\tspeed: 0.0298s/iter; left time: 194.8804s\n",
      "\titers: 800, epoch: 13 | loss: 0.0076535\n",
      "\tspeed: 0.0298s/iter; left time: 191.9590s\n",
      "\titers: 900, epoch: 13 | loss: 0.0113287\n",
      "\tspeed: 0.0298s/iter; left time: 188.8979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.28s\n",
      "Steps: 906 | Train Loss: 0.0091993 Vali Loss: 0.0092516 Test Loss: 0.0105101\n",
      "Validation loss decreased (0.009304 --> 0.009252).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0107250\n",
      "\tspeed: 0.0874s/iter; left time: 545.5340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0099450\n",
      "\tspeed: 0.0300s/iter; left time: 184.4024s\n",
      "\titers: 300, epoch: 14 | loss: 0.0100260\n",
      "\tspeed: 0.0305s/iter; left time: 184.6028s\n",
      "\titers: 400, epoch: 14 | loss: 0.0076054\n",
      "\tspeed: 0.0305s/iter; left time: 181.4845s\n",
      "\titers: 500, epoch: 14 | loss: 0.0090449\n",
      "\tspeed: 0.0306s/iter; left time: 178.6208s\n",
      "\titers: 600, epoch: 14 | loss: 0.0114058\n",
      "\tspeed: 0.0305s/iter; left time: 175.3328s\n",
      "\titers: 700, epoch: 14 | loss: 0.0088055\n",
      "\tspeed: 0.0305s/iter; left time: 172.3074s\n",
      "\titers: 800, epoch: 14 | loss: 0.0080943\n",
      "\tspeed: 0.0305s/iter; left time: 169.1666s\n",
      "\titers: 900, epoch: 14 | loss: 0.0080023\n",
      "\tspeed: 0.0306s/iter; left time: 166.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 906 | Train Loss: 0.0090944 Vali Loss: 0.0091131 Test Loss: 0.0104677\n",
      "Validation loss decreased (0.009252 --> 0.009113).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0086416\n",
      "\tspeed: 0.0849s/iter; left time: 453.3546s\n",
      "\titers: 200, epoch: 15 | loss: 0.0064624\n",
      "\tspeed: 0.0297s/iter; left time: 155.5175s\n",
      "\titers: 300, epoch: 15 | loss: 0.0088270\n",
      "\tspeed: 0.0297s/iter; left time: 152.5267s\n",
      "\titers: 400, epoch: 15 | loss: 0.0095518\n",
      "\tspeed: 0.0297s/iter; left time: 149.5595s\n",
      "\titers: 500, epoch: 15 | loss: 0.0091090\n",
      "\tspeed: 0.0297s/iter; left time: 146.6204s\n",
      "\titers: 600, epoch: 15 | loss: 0.0071228\n",
      "\tspeed: 0.0297s/iter; left time: 143.6525s\n",
      "\titers: 700, epoch: 15 | loss: 0.0087029\n",
      "\tspeed: 0.0297s/iter; left time: 140.6696s\n",
      "\titers: 800, epoch: 15 | loss: 0.0107585\n",
      "\tspeed: 0.0298s/iter; left time: 138.0427s\n",
      "\titers: 900, epoch: 15 | loss: 0.0074554\n",
      "\tspeed: 0.0298s/iter; left time: 135.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.21s\n",
      "Steps: 906 | Train Loss: 0.0090041 Vali Loss: 0.0090939 Test Loss: 0.0103499\n",
      "Validation loss decreased (0.009113 --> 0.009094).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0097343\n",
      "\tspeed: 0.0868s/iter; left time: 384.4326s\n",
      "\titers: 200, epoch: 16 | loss: 0.0073113\n",
      "\tspeed: 0.0306s/iter; left time: 132.4826s\n",
      "\titers: 300, epoch: 16 | loss: 0.0099642\n",
      "\tspeed: 0.0306s/iter; left time: 129.3708s\n",
      "\titers: 400, epoch: 16 | loss: 0.0065743\n",
      "\tspeed: 0.0306s/iter; left time: 126.3101s\n",
      "\titers: 500, epoch: 16 | loss: 0.0088386\n",
      "\tspeed: 0.0306s/iter; left time: 123.1933s\n",
      "\titers: 600, epoch: 16 | loss: 0.0096962\n",
      "\tspeed: 0.0306s/iter; left time: 120.1372s\n",
      "\titers: 700, epoch: 16 | loss: 0.0072239\n",
      "\tspeed: 0.0306s/iter; left time: 117.0948s\n",
      "\titers: 800, epoch: 16 | loss: 0.0121213\n",
      "\tspeed: 0.0306s/iter; left time: 114.0619s\n",
      "\titers: 900, epoch: 16 | loss: 0.0088560\n",
      "\tspeed: 0.0306s/iter; left time: 110.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.03s\n",
      "Steps: 906 | Train Loss: 0.0088757 Vali Loss: 0.0092832 Test Loss: 0.0105035\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0102557\n",
      "\tspeed: 0.0820s/iter; left time: 289.1214s\n",
      "\titers: 200, epoch: 17 | loss: 0.0092325\n",
      "\tspeed: 0.0298s/iter; left time: 101.9707s\n",
      "\titers: 300, epoch: 17 | loss: 0.0078814\n",
      "\tspeed: 0.0298s/iter; left time: 99.0034s\n",
      "\titers: 400, epoch: 17 | loss: 0.0104807\n",
      "\tspeed: 0.0298s/iter; left time: 96.1390s\n",
      "\titers: 500, epoch: 17 | loss: 0.0062310\n",
      "\tspeed: 0.0298s/iter; left time: 93.0287s\n",
      "\titers: 600, epoch: 17 | loss: 0.0080565\n",
      "\tspeed: 0.0298s/iter; left time: 90.0188s\n",
      "\titers: 700, epoch: 17 | loss: 0.0068373\n",
      "\tspeed: 0.0298s/iter; left time: 87.1660s\n",
      "\titers: 800, epoch: 17 | loss: 0.0086257\n",
      "\tspeed: 0.0298s/iter; left time: 84.0924s\n",
      "\titers: 900, epoch: 17 | loss: 0.0084499\n",
      "\tspeed: 0.0298s/iter; left time: 81.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.0087921 Vali Loss: 0.0093143 Test Loss: 0.0106182\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0075825\n",
      "\tspeed: 0.0820s/iter; left time: 214.7898s\n",
      "\titers: 200, epoch: 18 | loss: 0.0122544\n",
      "\tspeed: 0.0298s/iter; left time: 75.0798s\n",
      "\titers: 300, epoch: 18 | loss: 0.0093085\n",
      "\tspeed: 0.0297s/iter; left time: 71.9579s\n",
      "\titers: 400, epoch: 18 | loss: 0.0075157\n",
      "\tspeed: 0.0298s/iter; left time: 69.0106s\n",
      "\titers: 500, epoch: 18 | loss: 0.0069848\n",
      "\tspeed: 0.0298s/iter; left time: 66.0322s\n",
      "\titers: 600, epoch: 18 | loss: 0.0086436\n",
      "\tspeed: 0.0298s/iter; left time: 63.0547s\n",
      "\titers: 700, epoch: 18 | loss: 0.0076667\n",
      "\tspeed: 0.0298s/iter; left time: 60.1042s\n",
      "\titers: 800, epoch: 18 | loss: 0.0101423\n",
      "\tspeed: 0.0298s/iter; left time: 57.1091s\n",
      "\titers: 900, epoch: 18 | loss: 0.0082834\n",
      "\tspeed: 0.0298s/iter; left time: 54.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 906 | Train Loss: 0.0087149 Vali Loss: 0.0091280 Test Loss: 0.0103517\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010338997468352318, rmse:0.10168085992336273, mae:0.06268459558486938, rse:0.38425907492637634\n",
      "Original data scale mse:1547444.0, rmse:1243.9630126953125, mae:822.1914672851562, rse:0.08741621673107147\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1301301\n",
      "\tspeed: 0.0336s/iter; left time: 604.8406s\n",
      "\titers: 200, epoch: 1 | loss: 0.1278115\n",
      "\tspeed: 0.0306s/iter; left time: 547.6338s\n",
      "\titers: 300, epoch: 1 | loss: 0.1239432\n",
      "\tspeed: 0.0299s/iter; left time: 532.7666s\n",
      "\titers: 400, epoch: 1 | loss: 0.1089272\n",
      "\tspeed: 0.0297s/iter; left time: 526.4928s\n",
      "\titers: 500, epoch: 1 | loss: 0.1130522\n",
      "\tspeed: 0.0297s/iter; left time: 523.9031s\n",
      "\titers: 600, epoch: 1 | loss: 0.1130771\n",
      "\tspeed: 0.0302s/iter; left time: 529.5493s\n",
      "\titers: 700, epoch: 1 | loss: 0.0998832\n",
      "\tspeed: 0.0306s/iter; left time: 532.2285s\n",
      "\titers: 800, epoch: 1 | loss: 0.1008026\n",
      "\tspeed: 0.0305s/iter; left time: 528.9270s\n",
      "\titers: 900, epoch: 1 | loss: 0.0748656\n",
      "\tspeed: 0.0306s/iter; left time: 526.1190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.78s\n",
      "Steps: 906 | Train Loss: 0.1123151 Vali Loss: 0.0838156 Test Loss: 0.0977263\n",
      "Validation loss decreased (inf --> 0.083816).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0538716\n",
      "\tspeed: 0.0857s/iter; left time: 1467.1251s\n",
      "\titers: 200, epoch: 2 | loss: 0.0341119\n",
      "\tspeed: 0.0297s/iter; left time: 505.6749s\n",
      "\titers: 300, epoch: 2 | loss: 0.0225425\n",
      "\tspeed: 0.0297s/iter; left time: 502.7957s\n",
      "\titers: 400, epoch: 2 | loss: 0.0290803\n",
      "\tspeed: 0.0297s/iter; left time: 499.6374s\n",
      "\titers: 500, epoch: 2 | loss: 0.0193506\n",
      "\tspeed: 0.0297s/iter; left time: 496.7778s\n",
      "\titers: 600, epoch: 2 | loss: 0.0195138\n",
      "\tspeed: 0.0297s/iter; left time: 493.6129s\n",
      "\titers: 700, epoch: 2 | loss: 0.0209719\n",
      "\tspeed: 0.0297s/iter; left time: 490.7021s\n",
      "\titers: 800, epoch: 2 | loss: 0.0227312\n",
      "\tspeed: 0.0297s/iter; left time: 487.6536s\n",
      "\titers: 900, epoch: 2 | loss: 0.0190174\n",
      "\tspeed: 0.0297s/iter; left time: 485.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.28s\n",
      "Steps: 906 | Train Loss: 0.0293774 Vali Loss: 0.0136277 Test Loss: 0.0141543\n",
      "Validation loss decreased (0.083816 --> 0.013628).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0187159\n",
      "\tspeed: 0.0854s/iter; left time: 1384.7422s\n",
      "\titers: 200, epoch: 3 | loss: 0.0171712\n",
      "\tspeed: 0.0297s/iter; left time: 478.8803s\n",
      "\titers: 300, epoch: 3 | loss: 0.0149653\n",
      "\tspeed: 0.0297s/iter; left time: 475.9715s\n",
      "\titers: 400, epoch: 3 | loss: 0.0163777\n",
      "\tspeed: 0.0297s/iter; left time: 472.6965s\n",
      "\titers: 500, epoch: 3 | loss: 0.0140667\n",
      "\tspeed: 0.0297s/iter; left time: 469.7445s\n",
      "\titers: 600, epoch: 3 | loss: 0.0175495\n",
      "\tspeed: 0.0297s/iter; left time: 467.0153s\n",
      "\titers: 700, epoch: 3 | loss: 0.0153528\n",
      "\tspeed: 0.0297s/iter; left time: 463.8096s\n",
      "\titers: 800, epoch: 3 | loss: 0.0125979\n",
      "\tspeed: 0.0297s/iter; left time: 460.8224s\n",
      "\titers: 900, epoch: 3 | loss: 0.0141828\n",
      "\tspeed: 0.0297s/iter; left time: 457.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.0166602 Vali Loss: 0.0119998 Test Loss: 0.0129877\n",
      "Validation loss decreased (0.013628 --> 0.012000).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0188662\n",
      "\tspeed: 0.0849s/iter; left time: 1299.5863s\n",
      "\titers: 200, epoch: 4 | loss: 0.0125512\n",
      "\tspeed: 0.0297s/iter; left time: 452.1819s\n",
      "\titers: 300, epoch: 4 | loss: 0.0133795\n",
      "\tspeed: 0.0298s/iter; left time: 449.3731s\n",
      "\titers: 400, epoch: 4 | loss: 0.0134547\n",
      "\tspeed: 0.0298s/iter; left time: 446.3493s\n",
      "\titers: 500, epoch: 4 | loss: 0.0124662\n",
      "\tspeed: 0.0298s/iter; left time: 443.4211s\n",
      "\titers: 600, epoch: 4 | loss: 0.0114287\n",
      "\tspeed: 0.0298s/iter; left time: 440.4739s\n",
      "\titers: 700, epoch: 4 | loss: 0.0133417\n",
      "\tspeed: 0.0297s/iter; left time: 437.3223s\n",
      "\titers: 800, epoch: 4 | loss: 0.0125391\n",
      "\tspeed: 0.0298s/iter; left time: 434.4404s\n",
      "\titers: 900, epoch: 4 | loss: 0.0121796\n",
      "\tspeed: 0.0298s/iter; left time: 431.5033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.25s\n",
      "Steps: 906 | Train Loss: 0.0139549 Vali Loss: 0.0113355 Test Loss: 0.0124665\n",
      "Validation loss decreased (0.012000 --> 0.011335).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0120643\n",
      "\tspeed: 0.0863s/iter; left time: 1242.5725s\n",
      "\titers: 200, epoch: 5 | loss: 0.0123600\n",
      "\tspeed: 0.0305s/iter; left time: 436.4163s\n",
      "\titers: 300, epoch: 5 | loss: 0.0140470\n",
      "\tspeed: 0.0301s/iter; left time: 426.7297s\n",
      "\titers: 400, epoch: 5 | loss: 0.0146234\n",
      "\tspeed: 0.0297s/iter; left time: 418.8710s\n",
      "\titers: 500, epoch: 5 | loss: 0.0121092\n",
      "\tspeed: 0.0297s/iter; left time: 415.8212s\n",
      "\titers: 600, epoch: 5 | loss: 0.0153681\n",
      "\tspeed: 0.0297s/iter; left time: 412.8871s\n",
      "\titers: 700, epoch: 5 | loss: 0.0136895\n",
      "\tspeed: 0.0297s/iter; left time: 410.0593s\n",
      "\titers: 800, epoch: 5 | loss: 0.0143563\n",
      "\tspeed: 0.0297s/iter; left time: 406.9442s\n",
      "\titers: 900, epoch: 5 | loss: 0.0131545\n",
      "\tspeed: 0.0297s/iter; left time: 403.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.46s\n",
      "Steps: 906 | Train Loss: 0.0124500 Vali Loss: 0.0104100 Test Loss: 0.0115697\n",
      "Validation loss decreased (0.011335 --> 0.010410).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0110167\n",
      "\tspeed: 0.0866s/iter; left time: 1168.1914s\n",
      "\titers: 200, epoch: 6 | loss: 0.0158623\n",
      "\tspeed: 0.0298s/iter; left time: 398.4797s\n",
      "\titers: 300, epoch: 6 | loss: 0.0138902\n",
      "\tspeed: 0.0298s/iter; left time: 395.4603s\n",
      "\titers: 400, epoch: 6 | loss: 0.0111550\n",
      "\tspeed: 0.0298s/iter; left time: 392.4737s\n",
      "\titers: 500, epoch: 6 | loss: 0.0106144\n",
      "\tspeed: 0.0298s/iter; left time: 389.5395s\n",
      "\titers: 600, epoch: 6 | loss: 0.0094002\n",
      "\tspeed: 0.0298s/iter; left time: 386.5552s\n",
      "\titers: 700, epoch: 6 | loss: 0.0110870\n",
      "\tspeed: 0.0298s/iter; left time: 383.5859s\n",
      "\titers: 800, epoch: 6 | loss: 0.0127206\n",
      "\tspeed: 0.0298s/iter; left time: 381.2565s\n",
      "\titers: 900, epoch: 6 | loss: 0.0105031\n",
      "\tspeed: 0.0298s/iter; left time: 377.5905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.33s\n",
      "Steps: 906 | Train Loss: 0.0114987 Vali Loss: 0.0098951 Test Loss: 0.0113371\n",
      "Validation loss decreased (0.010410 --> 0.009895).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0106290\n",
      "\tspeed: 0.0858s/iter; left time: 1079.2426s\n",
      "\titers: 200, epoch: 7 | loss: 0.0090832\n",
      "\tspeed: 0.0297s/iter; left time: 371.3729s\n",
      "\titers: 300, epoch: 7 | loss: 0.0086089\n",
      "\tspeed: 0.0297s/iter; left time: 368.0497s\n",
      "\titers: 400, epoch: 7 | loss: 0.0136617\n",
      "\tspeed: 0.0297s/iter; left time: 364.9330s\n",
      "\titers: 500, epoch: 7 | loss: 0.0103768\n",
      "\tspeed: 0.0297s/iter; left time: 361.9881s\n",
      "\titers: 600, epoch: 7 | loss: 0.0108484\n",
      "\tspeed: 0.0297s/iter; left time: 359.0235s\n",
      "\titers: 700, epoch: 7 | loss: 0.0126621\n",
      "\tspeed: 0.0300s/iter; left time: 359.1463s\n",
      "\titers: 800, epoch: 7 | loss: 0.0097621\n",
      "\tspeed: 0.0302s/iter; left time: 359.3797s\n",
      "\titers: 900, epoch: 7 | loss: 0.0121403\n",
      "\tspeed: 0.0297s/iter; left time: 349.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.29s\n",
      "Steps: 906 | Train Loss: 0.0108895 Vali Loss: 0.0103424 Test Loss: 0.0114672\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0087634\n",
      "\tspeed: 0.0835s/iter; left time: 975.5336s\n",
      "\titers: 200, epoch: 8 | loss: 0.0126886\n",
      "\tspeed: 0.0298s/iter; left time: 345.1102s\n",
      "\titers: 300, epoch: 8 | loss: 0.0100458\n",
      "\tspeed: 0.0298s/iter; left time: 342.1710s\n",
      "\titers: 400, epoch: 8 | loss: 0.0077429\n",
      "\tspeed: 0.0298s/iter; left time: 339.0681s\n",
      "\titers: 500, epoch: 8 | loss: 0.0100603\n",
      "\tspeed: 0.0298s/iter; left time: 336.2160s\n",
      "\titers: 600, epoch: 8 | loss: 0.0105344\n",
      "\tspeed: 0.0298s/iter; left time: 333.1352s\n",
      "\titers: 700, epoch: 8 | loss: 0.0094969\n",
      "\tspeed: 0.0298s/iter; left time: 330.1222s\n",
      "\titers: 800, epoch: 8 | loss: 0.0102020\n",
      "\tspeed: 0.0298s/iter; left time: 327.2017s\n",
      "\titers: 900, epoch: 8 | loss: 0.0084325\n",
      "\tspeed: 0.0298s/iter; left time: 324.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.29s\n",
      "Steps: 906 | Train Loss: 0.0103977 Vali Loss: 0.0098874 Test Loss: 0.0109617\n",
      "Validation loss decreased (0.009895 --> 0.009887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0110146\n",
      "\tspeed: 0.0851s/iter; left time: 917.0840s\n",
      "\titers: 200, epoch: 9 | loss: 0.0082909\n",
      "\tspeed: 0.0298s/iter; left time: 317.7274s\n",
      "\titers: 300, epoch: 9 | loss: 0.0109563\n",
      "\tspeed: 0.0298s/iter; left time: 314.7521s\n",
      "\titers: 400, epoch: 9 | loss: 0.0110995\n",
      "\tspeed: 0.0298s/iter; left time: 311.8017s\n",
      "\titers: 500, epoch: 9 | loss: 0.0092475\n",
      "\tspeed: 0.0298s/iter; left time: 308.7578s\n",
      "\titers: 600, epoch: 9 | loss: 0.0087300\n",
      "\tspeed: 0.0298s/iter; left time: 305.8053s\n",
      "\titers: 700, epoch: 9 | loss: 0.0120953\n",
      "\tspeed: 0.0298s/iter; left time: 302.7913s\n",
      "\titers: 800, epoch: 9 | loss: 0.0110878\n",
      "\tspeed: 0.0298s/iter; left time: 299.9602s\n",
      "\titers: 900, epoch: 9 | loss: 0.0096264\n",
      "\tspeed: 0.0298s/iter; left time: 297.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.28s\n",
      "Steps: 906 | Train Loss: 0.0100215 Vali Loss: 0.0095972 Test Loss: 0.0108418\n",
      "Validation loss decreased (0.009887 --> 0.009597).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0093429\n",
      "\tspeed: 0.0905s/iter; left time: 893.1384s\n",
      "\titers: 200, epoch: 10 | loss: 0.0110323\n",
      "\tspeed: 0.0298s/iter; left time: 290.8094s\n",
      "\titers: 300, epoch: 10 | loss: 0.0085518\n",
      "\tspeed: 0.0297s/iter; left time: 287.4017s\n",
      "\titers: 400, epoch: 10 | loss: 0.0090212\n",
      "\tspeed: 0.0297s/iter; left time: 284.3796s\n",
      "\titers: 500, epoch: 10 | loss: 0.0104883\n",
      "\tspeed: 0.0297s/iter; left time: 281.3911s\n",
      "\titers: 600, epoch: 10 | loss: 0.0114427\n",
      "\tspeed: 0.0297s/iter; left time: 278.4467s\n",
      "\titers: 700, epoch: 10 | loss: 0.0090303\n",
      "\tspeed: 0.0297s/iter; left time: 275.3963s\n",
      "\titers: 800, epoch: 10 | loss: 0.0100005\n",
      "\tspeed: 0.0297s/iter; left time: 272.4399s\n",
      "\titers: 900, epoch: 10 | loss: 0.0112108\n",
      "\tspeed: 0.0297s/iter; left time: 269.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 906 | Train Loss: 0.0096945 Vali Loss: 0.0094075 Test Loss: 0.0107539\n",
      "Validation loss decreased (0.009597 --> 0.009408).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0097324\n",
      "\tspeed: 0.0888s/iter; left time: 795.5718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0072158\n",
      "\tspeed: 0.0298s/iter; left time: 263.6352s\n",
      "\titers: 300, epoch: 11 | loss: 0.0089382\n",
      "\tspeed: 0.0297s/iter; left time: 260.5432s\n",
      "\titers: 400, epoch: 11 | loss: 0.0084794\n",
      "\tspeed: 0.0297s/iter; left time: 257.6361s\n",
      "\titers: 500, epoch: 11 | loss: 0.0091129\n",
      "\tspeed: 0.0297s/iter; left time: 254.4814s\n",
      "\titers: 600, epoch: 11 | loss: 0.0111446\n",
      "\tspeed: 0.0297s/iter; left time: 251.5656s\n",
      "\titers: 700, epoch: 11 | loss: 0.0103540\n",
      "\tspeed: 0.0297s/iter; left time: 248.4818s\n",
      "\titers: 800, epoch: 11 | loss: 0.0089186\n",
      "\tspeed: 0.0297s/iter; left time: 245.5930s\n",
      "\titers: 900, epoch: 11 | loss: 0.0123147\n",
      "\tspeed: 0.0297s/iter; left time: 242.6421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.30s\n",
      "Steps: 906 | Train Loss: 0.0094954 Vali Loss: 0.0095923 Test Loss: 0.0109472\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0085312\n",
      "\tspeed: 0.0817s/iter; left time: 658.0454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0085927\n",
      "\tspeed: 0.0298s/iter; left time: 236.6613s\n",
      "\titers: 300, epoch: 12 | loss: 0.0087270\n",
      "\tspeed: 0.0298s/iter; left time: 233.7153s\n",
      "\titers: 400, epoch: 12 | loss: 0.0115851\n",
      "\tspeed: 0.0298s/iter; left time: 230.7649s\n",
      "\titers: 500, epoch: 12 | loss: 0.0080124\n",
      "\tspeed: 0.0298s/iter; left time: 227.7460s\n",
      "\titers: 600, epoch: 12 | loss: 0.0081245\n",
      "\tspeed: 0.0298s/iter; left time: 224.7866s\n",
      "\titers: 700, epoch: 12 | loss: 0.0114448\n",
      "\tspeed: 0.0297s/iter; left time: 221.7528s\n",
      "\titers: 800, epoch: 12 | loss: 0.0073995\n",
      "\tspeed: 0.0298s/iter; left time: 218.9149s\n",
      "\titers: 900, epoch: 12 | loss: 0.0078858\n",
      "\tspeed: 0.0298s/iter; left time: 216.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.24s\n",
      "Steps: 906 | Train Loss: 0.0093262 Vali Loss: 0.0096058 Test Loss: 0.0109195\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0083790\n",
      "\tspeed: 0.0821s/iter; left time: 586.7636s\n",
      "\titers: 200, epoch: 13 | loss: 0.0089831\n",
      "\tspeed: 0.0298s/iter; left time: 210.1502s\n",
      "\titers: 300, epoch: 13 | loss: 0.0080100\n",
      "\tspeed: 0.0298s/iter; left time: 207.1496s\n",
      "\titers: 400, epoch: 13 | loss: 0.0084853\n",
      "\tspeed: 0.0298s/iter; left time: 204.2125s\n",
      "\titers: 500, epoch: 13 | loss: 0.0115003\n",
      "\tspeed: 0.0298s/iter; left time: 201.1518s\n",
      "\titers: 600, epoch: 13 | loss: 0.0104059\n",
      "\tspeed: 0.0298s/iter; left time: 198.1808s\n",
      "\titers: 700, epoch: 13 | loss: 0.0079880\n",
      "\tspeed: 0.0298s/iter; left time: 195.1958s\n",
      "\titers: 800, epoch: 13 | loss: 0.0075785\n",
      "\tspeed: 0.0298s/iter; left time: 192.0273s\n",
      "\titers: 900, epoch: 13 | loss: 0.0129434\n",
      "\tspeed: 0.0297s/iter; left time: 188.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 906 | Train Loss: 0.0091663 Vali Loss: 0.0094657 Test Loss: 0.0106895\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010734870098531246, rmse:0.10360921919345856, mae:0.06474432349205017, rse:0.39154648780822754\n",
      "Original data scale mse:1827726.75, rmse:1351.9344482421875, mae:885.418701171875, rse:0.09500361979007721\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0954931\n",
      "\tspeed: 0.0608s/iter; left time: 1093.7915s\n",
      "\titers: 200, epoch: 1 | loss: 0.0765949\n",
      "\tspeed: 0.0372s/iter; left time: 665.9843s\n",
      "\titers: 300, epoch: 1 | loss: 0.0613500\n",
      "\tspeed: 0.0374s/iter; left time: 664.2126s\n",
      "\titers: 400, epoch: 1 | loss: 0.0574919\n",
      "\tspeed: 0.0373s/iter; left time: 659.5391s\n",
      "\titers: 500, epoch: 1 | loss: 0.0528576\n",
      "\tspeed: 0.0374s/iter; left time: 656.7798s\n",
      "\titers: 600, epoch: 1 | loss: 0.0486320\n",
      "\tspeed: 0.0373s/iter; left time: 652.1861s\n",
      "\titers: 700, epoch: 1 | loss: 0.0440399\n",
      "\tspeed: 0.0373s/iter; left time: 649.1507s\n",
      "\titers: 800, epoch: 1 | loss: 0.0429644\n",
      "\tspeed: 0.0374s/iter; left time: 645.4687s\n",
      "\titers: 900, epoch: 1 | loss: 0.0436177\n",
      "\tspeed: 0.0374s/iter; left time: 641.7388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.41s\n",
      "Steps: 904 | Train Loss: 0.0626929 Vali Loss: 0.0341101 Test Loss: 0.0393872\n",
      "Validation loss decreased (inf --> 0.034110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0333187\n",
      "\tspeed: 0.1057s/iter; left time: 1805.6840s\n",
      "\titers: 200, epoch: 2 | loss: 0.0293130\n",
      "\tspeed: 0.0373s/iter; left time: 633.7878s\n",
      "\titers: 300, epoch: 2 | loss: 0.0247914\n",
      "\tspeed: 0.0374s/iter; left time: 630.8123s\n",
      "\titers: 400, epoch: 2 | loss: 0.0222569\n",
      "\tspeed: 0.0373s/iter; left time: 626.4970s\n",
      "\titers: 500, epoch: 2 | loss: 0.0217948\n",
      "\tspeed: 0.0373s/iter; left time: 622.6003s\n",
      "\titers: 600, epoch: 2 | loss: 0.0231056\n",
      "\tspeed: 0.0373s/iter; left time: 619.0994s\n",
      "\titers: 700, epoch: 2 | loss: 0.0202825\n",
      "\tspeed: 0.0375s/iter; left time: 617.4217s\n",
      "\titers: 800, epoch: 2 | loss: 0.0200948\n",
      "\tspeed: 0.0376s/iter; left time: 615.1362s\n",
      "\titers: 900, epoch: 2 | loss: 0.0170172\n",
      "\tspeed: 0.0375s/iter; left time: 611.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.10s\n",
      "Steps: 904 | Train Loss: 0.0247541 Vali Loss: 0.0180899 Test Loss: 0.0190497\n",
      "Validation loss decreased (0.034110 --> 0.018090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0183560\n",
      "\tspeed: 0.1456s/iter; left time: 2355.2402s\n",
      "\titers: 200, epoch: 3 | loss: 0.0179470\n",
      "\tspeed: 0.0504s/iter; left time: 809.7527s\n",
      "\titers: 300, epoch: 3 | loss: 0.0190734\n",
      "\tspeed: 0.0510s/iter; left time: 815.0010s\n",
      "\titers: 400, epoch: 3 | loss: 0.0180438\n",
      "\tspeed: 0.0521s/iter; left time: 826.9385s\n",
      "\titers: 500, epoch: 3 | loss: 0.0169119\n",
      "\tspeed: 0.0501s/iter; left time: 789.8549s\n",
      "\titers: 600, epoch: 3 | loss: 0.0156383\n",
      "\tspeed: 0.0503s/iter; left time: 787.8768s\n",
      "\titers: 700, epoch: 3 | loss: 0.0144604\n",
      "\tspeed: 0.0505s/iter; left time: 785.8199s\n",
      "\titers: 800, epoch: 3 | loss: 0.0194007\n",
      "\tspeed: 0.0502s/iter; left time: 777.0637s\n",
      "\titers: 900, epoch: 3 | loss: 0.0191011\n",
      "\tspeed: 0.0491s/iter; left time: 755.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.0173060 Vali Loss: 0.0167963 Test Loss: 0.0189022\n",
      "Validation loss decreased (0.018090 --> 0.016796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0146229\n",
      "\tspeed: 0.1083s/iter; left time: 1653.0121s\n",
      "\titers: 200, epoch: 4 | loss: 0.0154170\n",
      "\tspeed: 0.0374s/iter; left time: 566.6126s\n",
      "\titers: 300, epoch: 4 | loss: 0.0153268\n",
      "\tspeed: 0.0373s/iter; left time: 562.4206s\n",
      "\titers: 400, epoch: 4 | loss: 0.0164736\n",
      "\tspeed: 0.0374s/iter; left time: 559.6254s\n",
      "\titers: 500, epoch: 4 | loss: 0.0170802\n",
      "\tspeed: 0.0387s/iter; left time: 575.1440s\n",
      "\titers: 600, epoch: 4 | loss: 0.0166589\n",
      "\tspeed: 0.0452s/iter; left time: 667.4583s\n",
      "\titers: 700, epoch: 4 | loss: 0.0142376\n",
      "\tspeed: 0.0446s/iter; left time: 654.3164s\n",
      "\titers: 800, epoch: 4 | loss: 0.0159530\n",
      "\tspeed: 0.0445s/iter; left time: 648.0513s\n",
      "\titers: 900, epoch: 4 | loss: 0.0133104\n",
      "\tspeed: 0.0449s/iter; left time: 650.0997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 904 | Train Loss: 0.0155955 Vali Loss: 0.0159026 Test Loss: 0.0189128\n",
      "Validation loss decreased (0.016796 --> 0.015903).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0124335\n",
      "\tspeed: 0.1440s/iter; left time: 2069.0018s\n",
      "\titers: 200, epoch: 5 | loss: 0.0139212\n",
      "\tspeed: 0.0462s/iter; left time: 658.8564s\n",
      "\titers: 300, epoch: 5 | loss: 0.0145604\n",
      "\tspeed: 0.0459s/iter; left time: 649.5364s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173979\n",
      "\tspeed: 0.0441s/iter; left time: 620.1201s\n",
      "\titers: 500, epoch: 5 | loss: 0.0136953\n",
      "\tspeed: 0.0444s/iter; left time: 620.3099s\n",
      "\titers: 600, epoch: 5 | loss: 0.0135619\n",
      "\tspeed: 0.0461s/iter; left time: 639.3656s\n",
      "\titers: 700, epoch: 5 | loss: 0.0150012\n",
      "\tspeed: 0.0449s/iter; left time: 618.4316s\n",
      "\titers: 800, epoch: 5 | loss: 0.0151126\n",
      "\tspeed: 0.0450s/iter; left time: 615.1537s\n",
      "\titers: 900, epoch: 5 | loss: 0.0131189\n",
      "\tspeed: 0.0448s/iter; left time: 607.1864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.62s\n",
      "Steps: 904 | Train Loss: 0.0141870 Vali Loss: 0.0171744 Test Loss: 0.0198022\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0093213\n",
      "\tspeed: 0.1399s/iter; left time: 1883.7059s\n",
      "\titers: 200, epoch: 6 | loss: 0.0142594\n",
      "\tspeed: 0.0454s/iter; left time: 606.3483s\n",
      "\titers: 300, epoch: 6 | loss: 0.0135621\n",
      "\tspeed: 0.0448s/iter; left time: 593.7291s\n",
      "\titers: 400, epoch: 6 | loss: 0.0147418\n",
      "\tspeed: 0.0450s/iter; left time: 592.6016s\n",
      "\titers: 500, epoch: 6 | loss: 0.0132335\n",
      "\tspeed: 0.0447s/iter; left time: 583.5265s\n",
      "\titers: 600, epoch: 6 | loss: 0.0121273\n",
      "\tspeed: 0.0470s/iter; left time: 609.1442s\n",
      "\titers: 700, epoch: 6 | loss: 0.0104701\n",
      "\tspeed: 0.0476s/iter; left time: 612.3448s\n",
      "\titers: 800, epoch: 6 | loss: 0.0134757\n",
      "\tspeed: 0.0449s/iter; left time: 573.4995s\n",
      "\titers: 900, epoch: 6 | loss: 0.0137269\n",
      "\tspeed: 0.0444s/iter; left time: 561.6934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 904 | Train Loss: 0.0129665 Vali Loss: 0.0181893 Test Loss: 0.0199882\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0109601\n",
      "\tspeed: 0.1409s/iter; left time: 1768.7464s\n",
      "\titers: 200, epoch: 7 | loss: 0.0107731\n",
      "\tspeed: 0.0444s/iter; left time: 552.9314s\n",
      "\titers: 300, epoch: 7 | loss: 0.0125319\n",
      "\tspeed: 0.0473s/iter; left time: 584.1784s\n",
      "\titers: 400, epoch: 7 | loss: 0.0112393\n",
      "\tspeed: 0.0469s/iter; left time: 575.0674s\n",
      "\titers: 500, epoch: 7 | loss: 0.0105261\n",
      "\tspeed: 0.0449s/iter; left time: 545.7468s\n",
      "\titers: 600, epoch: 7 | loss: 0.0140882\n",
      "\tspeed: 0.0449s/iter; left time: 541.8854s\n",
      "\titers: 700, epoch: 7 | loss: 0.0112381\n",
      "\tspeed: 0.0458s/iter; left time: 547.8492s\n",
      "\titers: 800, epoch: 7 | loss: 0.0078659\n",
      "\tspeed: 0.0450s/iter; left time: 533.0952s\n",
      "\titers: 900, epoch: 7 | loss: 0.0118471\n",
      "\tspeed: 0.0451s/iter; left time: 529.9323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.0116280 Vali Loss: 0.0170923 Test Loss: 0.0208177\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018906524404883385, rmse:0.13750100135803223, mae:0.089120052754879, rse:0.5199061036109924\n",
      "Original data scale mse:3707538.75, rmse:1925.4970703125, mae:1254.8304443359375, rse:0.1355050802230835\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0976467\n",
      "\tspeed: 0.0546s/iter; left time: 980.9233s\n",
      "\titers: 200, epoch: 1 | loss: 0.0866916\n",
      "\tspeed: 0.0463s/iter; left time: 827.6992s\n",
      "\titers: 300, epoch: 1 | loss: 0.0704725\n",
      "\tspeed: 0.0462s/iter; left time: 821.4656s\n",
      "\titers: 400, epoch: 1 | loss: 0.0657056\n",
      "\tspeed: 0.0447s/iter; left time: 790.4740s\n",
      "\titers: 500, epoch: 1 | loss: 0.0589035\n",
      "\tspeed: 0.0446s/iter; left time: 784.6083s\n",
      "\titers: 600, epoch: 1 | loss: 0.0538787\n",
      "\tspeed: 0.0442s/iter; left time: 772.7554s\n",
      "\titers: 700, epoch: 1 | loss: 0.0479613\n",
      "\tspeed: 0.0449s/iter; left time: 780.5923s\n",
      "\titers: 800, epoch: 1 | loss: 0.0415635\n",
      "\tspeed: 0.0441s/iter; left time: 761.8691s\n",
      "\titers: 900, epoch: 1 | loss: 0.0363863\n",
      "\tspeed: 0.0445s/iter; left time: 764.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 904 | Train Loss: 0.0662176 Vali Loss: 0.0304875 Test Loss: 0.0350228\n",
      "Validation loss decreased (inf --> 0.030487).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0343265\n",
      "\tspeed: 0.1444s/iter; left time: 2466.4297s\n",
      "\titers: 200, epoch: 2 | loss: 0.0269141\n",
      "\tspeed: 0.0452s/iter; left time: 766.8390s\n",
      "\titers: 300, epoch: 2 | loss: 0.0283692\n",
      "\tspeed: 0.0457s/iter; left time: 771.1817s\n",
      "\titers: 400, epoch: 2 | loss: 0.0232896\n",
      "\tspeed: 0.0450s/iter; left time: 755.2937s\n",
      "\titers: 500, epoch: 2 | loss: 0.0216333\n",
      "\tspeed: 0.0461s/iter; left time: 768.5609s\n",
      "\titers: 600, epoch: 2 | loss: 0.0245413\n",
      "\tspeed: 0.0447s/iter; left time: 741.4413s\n",
      "\titers: 700, epoch: 2 | loss: 0.0209456\n",
      "\tspeed: 0.0453s/iter; left time: 745.9005s\n",
      "\titers: 800, epoch: 2 | loss: 0.0198930\n",
      "\tspeed: 0.0449s/iter; left time: 734.8853s\n",
      "\titers: 900, epoch: 2 | loss: 0.0159086\n",
      "\tspeed: 0.0447s/iter; left time: 727.2745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 904 | Train Loss: 0.0247903 Vali Loss: 0.0177388 Test Loss: 0.0196736\n",
      "Validation loss decreased (0.030487 --> 0.017739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0170038\n",
      "\tspeed: 0.1474s/iter; left time: 2384.6443s\n",
      "\titers: 200, epoch: 3 | loss: 0.0171574\n",
      "\tspeed: 0.0450s/iter; left time: 722.8577s\n",
      "\titers: 300, epoch: 3 | loss: 0.0167927\n",
      "\tspeed: 0.0448s/iter; left time: 716.1565s\n",
      "\titers: 400, epoch: 3 | loss: 0.0191418\n",
      "\tspeed: 0.0445s/iter; left time: 705.6372s\n",
      "\titers: 500, epoch: 3 | loss: 0.0171614\n",
      "\tspeed: 0.0451s/iter; left time: 711.9809s\n",
      "\titers: 600, epoch: 3 | loss: 0.0192646\n",
      "\tspeed: 0.0451s/iter; left time: 706.7636s\n",
      "\titers: 700, epoch: 3 | loss: 0.0175305\n",
      "\tspeed: 0.0455s/iter; left time: 707.9259s\n",
      "\titers: 800, epoch: 3 | loss: 0.0158333\n",
      "\tspeed: 0.0453s/iter; left time: 700.9348s\n",
      "\titers: 900, epoch: 3 | loss: 0.0151498\n",
      "\tspeed: 0.0446s/iter; left time: 685.7656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.59s\n",
      "Steps: 904 | Train Loss: 0.0175124 Vali Loss: 0.0176772 Test Loss: 0.0187609\n",
      "Validation loss decreased (0.017739 --> 0.017677).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0166615\n",
      "\tspeed: 0.1423s/iter; left time: 2172.5308s\n",
      "\titers: 200, epoch: 4 | loss: 0.0168326\n",
      "\tspeed: 0.0451s/iter; left time: 683.8682s\n",
      "\titers: 300, epoch: 4 | loss: 0.0188695\n",
      "\tspeed: 0.0460s/iter; left time: 692.7477s\n",
      "\titers: 400, epoch: 4 | loss: 0.0158456\n",
      "\tspeed: 0.0459s/iter; left time: 687.6620s\n",
      "\titers: 500, epoch: 4 | loss: 0.0154171\n",
      "\tspeed: 0.0449s/iter; left time: 668.3200s\n",
      "\titers: 600, epoch: 4 | loss: 0.0153358\n",
      "\tspeed: 0.0457s/iter; left time: 675.3945s\n",
      "\titers: 700, epoch: 4 | loss: 0.0164644\n",
      "\tspeed: 0.0469s/iter; left time: 688.1397s\n",
      "\titers: 800, epoch: 4 | loss: 0.0151930\n",
      "\tspeed: 0.0446s/iter; left time: 649.7195s\n",
      "\titers: 900, epoch: 4 | loss: 0.0125507\n",
      "\tspeed: 0.0443s/iter; left time: 641.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 904 | Train Loss: 0.0158873 Vali Loss: 0.0165593 Test Loss: 0.0184611\n",
      "Validation loss decreased (0.017677 --> 0.016559).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0147515\n",
      "\tspeed: 0.1429s/iter; left time: 2053.3011s\n",
      "\titers: 200, epoch: 5 | loss: 0.0142787\n",
      "\tspeed: 0.0452s/iter; left time: 645.3531s\n",
      "\titers: 300, epoch: 5 | loss: 0.0150970\n",
      "\tspeed: 0.0442s/iter; left time: 626.7207s\n",
      "\titers: 400, epoch: 5 | loss: 0.0151469\n",
      "\tspeed: 0.0445s/iter; left time: 625.6686s\n",
      "\titers: 500, epoch: 5 | loss: 0.0138411\n",
      "\tspeed: 0.0445s/iter; left time: 621.1221s\n",
      "\titers: 600, epoch: 5 | loss: 0.0159346\n",
      "\tspeed: 0.0444s/iter; left time: 615.2419s\n",
      "\titers: 700, epoch: 5 | loss: 0.0169811\n",
      "\tspeed: 0.0444s/iter; left time: 610.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0151293\n",
      "\tspeed: 0.0444s/iter; left time: 606.2532s\n",
      "\titers: 900, epoch: 5 | loss: 0.0130795\n",
      "\tspeed: 0.0444s/iter; left time: 602.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.27s\n",
      "Steps: 904 | Train Loss: 0.0145810 Vali Loss: 0.0166824 Test Loss: 0.0181468\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0146569\n",
      "\tspeed: 0.1432s/iter; left time: 1927.8996s\n",
      "\titers: 200, epoch: 6 | loss: 0.0125786\n",
      "\tspeed: 0.0448s/iter; left time: 599.2389s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151721\n",
      "\tspeed: 0.0448s/iter; left time: 594.3836s\n",
      "\titers: 400, epoch: 6 | loss: 0.0122208\n",
      "\tspeed: 0.0445s/iter; left time: 585.0172s\n",
      "\titers: 500, epoch: 6 | loss: 0.0152650\n",
      "\tspeed: 0.0443s/iter; left time: 578.6253s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131107\n",
      "\tspeed: 0.0445s/iter; left time: 576.7044s\n",
      "\titers: 700, epoch: 6 | loss: 0.0133329\n",
      "\tspeed: 0.0443s/iter; left time: 569.9872s\n",
      "\titers: 800, epoch: 6 | loss: 0.0136852\n",
      "\tspeed: 0.0443s/iter; left time: 564.8504s\n",
      "\titers: 900, epoch: 6 | loss: 0.0118865\n",
      "\tspeed: 0.0442s/iter; left time: 559.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.42s\n",
      "Steps: 904 | Train Loss: 0.0135008 Vali Loss: 0.0175327 Test Loss: 0.0192267\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0144951\n",
      "\tspeed: 0.1377s/iter; left time: 1728.8238s\n",
      "\titers: 200, epoch: 7 | loss: 0.0114681\n",
      "\tspeed: 0.0450s/iter; left time: 560.0282s\n",
      "\titers: 300, epoch: 7 | loss: 0.0132434\n",
      "\tspeed: 0.0445s/iter; left time: 549.5822s\n",
      "\titers: 400, epoch: 7 | loss: 0.0122486\n",
      "\tspeed: 0.0445s/iter; left time: 545.0499s\n",
      "\titers: 500, epoch: 7 | loss: 0.0112732\n",
      "\tspeed: 0.0445s/iter; left time: 540.8644s\n",
      "\titers: 600, epoch: 7 | loss: 0.0110572\n",
      "\tspeed: 0.0449s/iter; left time: 541.6138s\n",
      "\titers: 700, epoch: 7 | loss: 0.0109618\n",
      "\tspeed: 0.0447s/iter; left time: 534.9353s\n",
      "\titers: 800, epoch: 7 | loss: 0.0123636\n",
      "\tspeed: 0.0456s/iter; left time: 540.6161s\n",
      "\titers: 900, epoch: 7 | loss: 0.0119041\n",
      "\tspeed: 0.0466s/iter; left time: 547.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.59s\n",
      "Steps: 904 | Train Loss: 0.0122945 Vali Loss: 0.0170613 Test Loss: 0.0190646\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01846655271947384, rmse:0.13589169085025787, mae:0.08840931951999664, rse:0.5138211846351624\n",
      "Original data scale mse:3334153.0, rmse:1825.96630859375, mae:1212.46337890625, rse:0.12850069999694824\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0972596\n",
      "\tspeed: 0.1216s/iter; left time: 2181.1051s\n",
      "\titers: 200, epoch: 1 | loss: 0.0732371\n",
      "\tspeed: 0.0522s/iter; left time: 931.1480s\n",
      "\titers: 300, epoch: 1 | loss: 0.0739854\n",
      "\tspeed: 0.0520s/iter; left time: 922.4486s\n",
      "\titers: 400, epoch: 1 | loss: 0.0646574\n",
      "\tspeed: 0.0519s/iter; left time: 915.9097s\n",
      "\titers: 500, epoch: 1 | loss: 0.0619157\n",
      "\tspeed: 0.0521s/iter; left time: 913.5345s\n",
      "\titers: 600, epoch: 1 | loss: 0.0591417\n",
      "\tspeed: 0.0527s/iter; left time: 919.4393s\n",
      "\titers: 700, epoch: 1 | loss: 0.0565022\n",
      "\tspeed: 0.0533s/iter; left time: 924.3969s\n",
      "\titers: 800, epoch: 1 | loss: 0.0576037\n",
      "\tspeed: 0.0522s/iter; left time: 899.9580s\n",
      "\titers: 900, epoch: 1 | loss: 0.0548286\n",
      "\tspeed: 0.0524s/iter; left time: 897.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0695326 Vali Loss: 0.0453684 Test Loss: 0.0527750\n",
      "Validation loss decreased (inf --> 0.045368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0440192\n",
      "\tspeed: 0.1629s/iter; left time: 2775.7929s\n",
      "\titers: 200, epoch: 2 | loss: 0.0381187\n",
      "\tspeed: 0.0527s/iter; left time: 892.7406s\n",
      "\titers: 300, epoch: 2 | loss: 0.0346322\n",
      "\tspeed: 0.0528s/iter; left time: 889.4728s\n",
      "\titers: 400, epoch: 2 | loss: 0.0273747\n",
      "\tspeed: 0.0526s/iter; left time: 880.1577s\n",
      "\titers: 500, epoch: 2 | loss: 0.0227474\n",
      "\tspeed: 0.0526s/iter; left time: 875.9270s\n",
      "\titers: 600, epoch: 2 | loss: 0.0230347\n",
      "\tspeed: 0.0529s/iter; left time: 874.9828s\n",
      "\titers: 700, epoch: 2 | loss: 0.0187265\n",
      "\tspeed: 0.0527s/iter; left time: 867.1508s\n",
      "\titers: 800, epoch: 2 | loss: 0.0187494\n",
      "\tspeed: 0.0530s/iter; left time: 866.3073s\n",
      "\titers: 900, epoch: 2 | loss: 0.0190889\n",
      "\tspeed: 0.0531s/iter; left time: 861.7941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 0.0296123 Vali Loss: 0.0193431 Test Loss: 0.0211725\n",
      "Validation loss decreased (0.045368 --> 0.019343).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0186137\n",
      "\tspeed: 0.1640s/iter; left time: 2646.6101s\n",
      "\titers: 200, epoch: 3 | loss: 0.0206502\n",
      "\tspeed: 0.0531s/iter; left time: 852.0938s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205086\n",
      "\tspeed: 0.0519s/iter; left time: 827.8199s\n",
      "\titers: 400, epoch: 3 | loss: 0.0210698\n",
      "\tspeed: 0.0528s/iter; left time: 836.5241s\n",
      "\titers: 500, epoch: 3 | loss: 0.0209393\n",
      "\tspeed: 0.0529s/iter; left time: 833.0335s\n",
      "\titers: 600, epoch: 3 | loss: 0.0181215\n",
      "\tspeed: 0.0526s/iter; left time: 823.2219s\n",
      "\titers: 700, epoch: 3 | loss: 0.0175095\n",
      "\tspeed: 0.0529s/iter; left time: 822.2139s\n",
      "\titers: 800, epoch: 3 | loss: 0.0192538\n",
      "\tspeed: 0.0526s/iter; left time: 812.6608s\n",
      "\titers: 900, epoch: 3 | loss: 0.0184505\n",
      "\tspeed: 0.0522s/iter; left time: 800.4940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.0192396 Vali Loss: 0.0187485 Test Loss: 0.0200714\n",
      "Validation loss decreased (0.019343 --> 0.018749).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0184216\n",
      "\tspeed: 0.1599s/iter; left time: 2435.8601s\n",
      "\titers: 200, epoch: 4 | loss: 0.0172501\n",
      "\tspeed: 0.0523s/iter; left time: 790.9398s\n",
      "\titers: 300, epoch: 4 | loss: 0.0213223\n",
      "\tspeed: 0.0525s/iter; left time: 789.5946s\n",
      "\titers: 400, epoch: 4 | loss: 0.0159237\n",
      "\tspeed: 0.0534s/iter; left time: 796.8841s\n",
      "\titers: 500, epoch: 4 | loss: 0.0160662\n",
      "\tspeed: 0.0518s/iter; left time: 768.8340s\n",
      "\titers: 600, epoch: 4 | loss: 0.0153777\n",
      "\tspeed: 0.0525s/iter; left time: 773.5522s\n",
      "\titers: 700, epoch: 4 | loss: 0.0182667\n",
      "\tspeed: 0.0526s/iter; left time: 769.6952s\n",
      "\titers: 800, epoch: 4 | loss: 0.0189181\n",
      "\tspeed: 0.0534s/iter; left time: 775.4903s\n",
      "\titers: 900, epoch: 4 | loss: 0.0165188\n",
      "\tspeed: 0.0522s/iter; left time: 753.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.99s\n",
      "Steps: 902 | Train Loss: 0.0172685 Vali Loss: 0.0179997 Test Loss: 0.0204721\n",
      "Validation loss decreased (0.018749 --> 0.018000).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0135628\n",
      "\tspeed: 0.1634s/iter; left time: 2341.7716s\n",
      "\titers: 200, epoch: 5 | loss: 0.0144853\n",
      "\tspeed: 0.0522s/iter; left time: 743.6323s\n",
      "\titers: 300, epoch: 5 | loss: 0.0171341\n",
      "\tspeed: 0.0526s/iter; left time: 742.8778s\n",
      "\titers: 400, epoch: 5 | loss: 0.0170608\n",
      "\tspeed: 0.0527s/iter; left time: 739.1785s\n",
      "\titers: 500, epoch: 5 | loss: 0.0167194\n",
      "\tspeed: 0.0525s/iter; left time: 731.2804s\n",
      "\titers: 600, epoch: 5 | loss: 0.0171583\n",
      "\tspeed: 0.0523s/iter; left time: 723.7206s\n",
      "\titers: 700, epoch: 5 | loss: 0.0158545\n",
      "\tspeed: 0.0524s/iter; left time: 720.1025s\n",
      "\titers: 800, epoch: 5 | loss: 0.0146269\n",
      "\tspeed: 0.0525s/iter; left time: 715.6442s\n",
      "\titers: 900, epoch: 5 | loss: 0.0159846\n",
      "\tspeed: 0.0519s/iter; left time: 702.7111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.0156949 Vali Loss: 0.0184787 Test Loss: 0.0218099\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0137303\n",
      "\tspeed: 0.1628s/iter; left time: 2187.1122s\n",
      "\titers: 200, epoch: 6 | loss: 0.0144591\n",
      "\tspeed: 0.0518s/iter; left time: 691.1777s\n",
      "\titers: 300, epoch: 6 | loss: 0.0135411\n",
      "\tspeed: 0.0518s/iter; left time: 685.3395s\n",
      "\titers: 400, epoch: 6 | loss: 0.0144007\n",
      "\tspeed: 0.0518s/iter; left time: 680.3266s\n",
      "\titers: 500, epoch: 6 | loss: 0.0134445\n",
      "\tspeed: 0.0523s/iter; left time: 681.4779s\n",
      "\titers: 600, epoch: 6 | loss: 0.0130570\n",
      "\tspeed: 0.0523s/iter; left time: 676.0726s\n",
      "\titers: 700, epoch: 6 | loss: 0.0131871\n",
      "\tspeed: 0.0528s/iter; left time: 677.0953s\n",
      "\titers: 800, epoch: 6 | loss: 0.0131947\n",
      "\tspeed: 0.0528s/iter; left time: 672.6488s\n",
      "\titers: 900, epoch: 6 | loss: 0.0127539\n",
      "\tspeed: 0.0524s/iter; left time: 661.3516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.10s\n",
      "Steps: 902 | Train Loss: 0.0142045 Vali Loss: 0.0205999 Test Loss: 0.0227170\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0142956\n",
      "\tspeed: 0.1648s/iter; left time: 2064.5047s\n",
      "\titers: 200, epoch: 7 | loss: 0.0137401\n",
      "\tspeed: 0.0532s/iter; left time: 660.6431s\n",
      "\titers: 300, epoch: 7 | loss: 0.0110561\n",
      "\tspeed: 0.0527s/iter; left time: 650.1054s\n",
      "\titers: 400, epoch: 7 | loss: 0.0129260\n",
      "\tspeed: 0.0528s/iter; left time: 645.1784s\n",
      "\titers: 500, epoch: 7 | loss: 0.0132612\n",
      "\tspeed: 0.0527s/iter; left time: 639.4908s\n",
      "\titers: 600, epoch: 7 | loss: 0.0134526\n",
      "\tspeed: 0.0525s/iter; left time: 631.9936s\n",
      "\titers: 700, epoch: 7 | loss: 0.0122740\n",
      "\tspeed: 0.0525s/iter; left time: 626.3451s\n",
      "\titers: 800, epoch: 7 | loss: 0.0114208\n",
      "\tspeed: 0.0526s/iter; left time: 621.9530s\n",
      "\titers: 900, epoch: 7 | loss: 0.0114280\n",
      "\tspeed: 0.0532s/iter; left time: 623.6985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.0127443 Vali Loss: 0.0197489 Test Loss: 0.0227088\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02046244777739048, rmse:0.1430470198392868, mae:0.09501297026872635, rse:0.5412498712539673\n",
      "Original data scale mse:4258305.5, rmse:2063.566162109375, mae:1351.6522216796875, rse:0.14535795152187347\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0884546\n",
      "\tspeed: 0.0610s/iter; left time: 1095.2368s\n",
      "\titers: 200, epoch: 1 | loss: 0.0764151\n",
      "\tspeed: 0.0529s/iter; left time: 943.9145s\n",
      "\titers: 300, epoch: 1 | loss: 0.0622167\n",
      "\tspeed: 0.0526s/iter; left time: 933.1872s\n",
      "\titers: 400, epoch: 1 | loss: 0.0637582\n",
      "\tspeed: 0.0528s/iter; left time: 931.8775s\n",
      "\titers: 500, epoch: 1 | loss: 0.0587414\n",
      "\tspeed: 0.0525s/iter; left time: 920.6006s\n",
      "\titers: 600, epoch: 1 | loss: 0.0524721\n",
      "\tspeed: 0.0525s/iter; left time: 915.8415s\n",
      "\titers: 700, epoch: 1 | loss: 0.0529274\n",
      "\tspeed: 0.0524s/iter; left time: 908.4760s\n",
      "\titers: 800, epoch: 1 | loss: 0.0510824\n",
      "\tspeed: 0.0523s/iter; left time: 901.3163s\n",
      "\titers: 900, epoch: 1 | loss: 0.0502224\n",
      "\tspeed: 0.0524s/iter; left time: 897.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.0661613 Vali Loss: 0.0414571 Test Loss: 0.0480749\n",
      "Validation loss decreased (inf --> 0.041457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0430366\n",
      "\tspeed: 0.1696s/iter; left time: 2890.4063s\n",
      "\titers: 200, epoch: 2 | loss: 0.0369083\n",
      "\tspeed: 0.0555s/iter; left time: 940.5407s\n",
      "\titers: 300, epoch: 2 | loss: 0.0316949\n",
      "\tspeed: 0.0561s/iter; left time: 944.9702s\n",
      "\titers: 400, epoch: 2 | loss: 0.0255610\n",
      "\tspeed: 0.0565s/iter; left time: 945.7173s\n",
      "\titers: 500, epoch: 2 | loss: 0.0281548\n",
      "\tspeed: 0.0529s/iter; left time: 879.3819s\n",
      "\titers: 600, epoch: 2 | loss: 0.0204028\n",
      "\tspeed: 0.0527s/iter; left time: 871.5504s\n",
      "\titers: 700, epoch: 2 | loss: 0.0219794\n",
      "\tspeed: 0.0525s/iter; left time: 863.0407s\n",
      "\titers: 800, epoch: 2 | loss: 0.0187024\n",
      "\tspeed: 0.0526s/iter; left time: 859.6869s\n",
      "\titers: 900, epoch: 2 | loss: 0.0214683\n",
      "\tspeed: 0.0526s/iter; left time: 853.4857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.60s\n",
      "Steps: 902 | Train Loss: 0.0290857 Vali Loss: 0.0191228 Test Loss: 0.0215900\n",
      "Validation loss decreased (0.041457 --> 0.019123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0226256\n",
      "\tspeed: 0.1718s/iter; left time: 2771.8417s\n",
      "\titers: 200, epoch: 3 | loss: 0.0186814\n",
      "\tspeed: 0.0526s/iter; left time: 842.9255s\n",
      "\titers: 300, epoch: 3 | loss: 0.0188780\n",
      "\tspeed: 0.0526s/iter; left time: 837.8372s\n",
      "\titers: 400, epoch: 3 | loss: 0.0197421\n",
      "\tspeed: 0.0534s/iter; left time: 845.8037s\n",
      "\titers: 500, epoch: 3 | loss: 0.0182198\n",
      "\tspeed: 0.0541s/iter; left time: 851.0922s\n",
      "\titers: 600, epoch: 3 | loss: 0.0191936\n",
      "\tspeed: 0.0528s/iter; left time: 826.3637s\n",
      "\titers: 700, epoch: 3 | loss: 0.0175551\n",
      "\tspeed: 0.0523s/iter; left time: 812.6926s\n",
      "\titers: 800, epoch: 3 | loss: 0.0200538\n",
      "\tspeed: 0.0523s/iter; left time: 807.3282s\n",
      "\titers: 900, epoch: 3 | loss: 0.0203353\n",
      "\tspeed: 0.0557s/iter; left time: 854.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.93s\n",
      "Steps: 902 | Train Loss: 0.0192360 Vali Loss: 0.0188432 Test Loss: 0.0201867\n",
      "Validation loss decreased (0.019123 --> 0.018843).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0188412\n",
      "\tspeed: 0.1623s/iter; left time: 2473.2513s\n",
      "\titers: 200, epoch: 4 | loss: 0.0168883\n",
      "\tspeed: 0.0528s/iter; left time: 798.7598s\n",
      "\titers: 300, epoch: 4 | loss: 0.0162838\n",
      "\tspeed: 0.0561s/iter; left time: 843.1395s\n",
      "\titers: 400, epoch: 4 | loss: 0.0181183\n",
      "\tspeed: 0.0541s/iter; left time: 808.3479s\n",
      "\titers: 500, epoch: 4 | loss: 0.0175099\n",
      "\tspeed: 0.0529s/iter; left time: 785.1987s\n",
      "\titers: 600, epoch: 4 | loss: 0.0153600\n",
      "\tspeed: 0.0525s/iter; left time: 773.8965s\n",
      "\titers: 700, epoch: 4 | loss: 0.0161713\n",
      "\tspeed: 0.0525s/iter; left time: 768.4861s\n",
      "\titers: 800, epoch: 4 | loss: 0.0191006\n",
      "\tspeed: 0.0524s/iter; left time: 761.2832s\n",
      "\titers: 900, epoch: 4 | loss: 0.0154285\n",
      "\tspeed: 0.0524s/iter; left time: 756.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.0172411 Vali Loss: 0.0177478 Test Loss: 0.0204499\n",
      "Validation loss decreased (0.018843 --> 0.017748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0168039\n",
      "\tspeed: 0.1645s/iter; left time: 2358.1919s\n",
      "\titers: 200, epoch: 5 | loss: 0.0158544\n",
      "\tspeed: 0.0522s/iter; left time: 743.3795s\n",
      "\titers: 300, epoch: 5 | loss: 0.0166832\n",
      "\tspeed: 0.0521s/iter; left time: 735.7868s\n",
      "\titers: 400, epoch: 5 | loss: 0.0167056\n",
      "\tspeed: 0.0521s/iter; left time: 730.8543s\n",
      "\titers: 500, epoch: 5 | loss: 0.0152042\n",
      "\tspeed: 0.0524s/iter; left time: 729.9291s\n",
      "\titers: 600, epoch: 5 | loss: 0.0158394\n",
      "\tspeed: 0.0520s/iter; left time: 719.9417s\n",
      "\titers: 700, epoch: 5 | loss: 0.0141160\n",
      "\tspeed: 0.0520s/iter; left time: 714.1399s\n",
      "\titers: 800, epoch: 5 | loss: 0.0145714\n",
      "\tspeed: 0.0522s/iter; left time: 711.5073s\n",
      "\titers: 900, epoch: 5 | loss: 0.0145051\n",
      "\tspeed: 0.0522s/iter; left time: 706.3220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.91s\n",
      "Steps: 902 | Train Loss: 0.0155517 Vali Loss: 0.0193685 Test Loss: 0.0203139\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0169447\n",
      "\tspeed: 0.1611s/iter; left time: 2163.4634s\n",
      "\titers: 200, epoch: 6 | loss: 0.0132523\n",
      "\tspeed: 0.0525s/iter; left time: 699.3582s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151682\n",
      "\tspeed: 0.0526s/iter; left time: 696.0845s\n",
      "\titers: 400, epoch: 6 | loss: 0.0146404\n",
      "\tspeed: 0.0526s/iter; left time: 690.9407s\n",
      "\titers: 500, epoch: 6 | loss: 0.0163109\n",
      "\tspeed: 0.0526s/iter; left time: 684.9296s\n",
      "\titers: 600, epoch: 6 | loss: 0.0149259\n",
      "\tspeed: 0.0544s/iter; left time: 703.2028s\n",
      "\titers: 700, epoch: 6 | loss: 0.0146730\n",
      "\tspeed: 0.0520s/iter; left time: 667.0903s\n",
      "\titers: 800, epoch: 6 | loss: 0.0128408\n",
      "\tspeed: 0.0523s/iter; left time: 666.0879s\n",
      "\titers: 900, epoch: 6 | loss: 0.0130797\n",
      "\tspeed: 0.0549s/iter; left time: 693.6726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0141558 Vali Loss: 0.0186256 Test Loss: 0.0207581\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0137599\n",
      "\tspeed: 0.1651s/iter; left time: 2068.5142s\n",
      "\titers: 200, epoch: 7 | loss: 0.0116340\n",
      "\tspeed: 0.0560s/iter; left time: 695.7413s\n",
      "\titers: 300, epoch: 7 | loss: 0.0138862\n",
      "\tspeed: 0.0559s/iter; left time: 689.3811s\n",
      "\titers: 400, epoch: 7 | loss: 0.0160140\n",
      "\tspeed: 0.0562s/iter; left time: 687.3834s\n",
      "\titers: 500, epoch: 7 | loss: 0.0114175\n",
      "\tspeed: 0.0547s/iter; left time: 663.6270s\n",
      "\titers: 600, epoch: 7 | loss: 0.0114408\n",
      "\tspeed: 0.0523s/iter; left time: 628.5782s\n",
      "\titers: 700, epoch: 7 | loss: 0.0118382\n",
      "\tspeed: 0.0531s/iter; left time: 633.2705s\n",
      "\titers: 800, epoch: 7 | loss: 0.0107872\n",
      "\tspeed: 0.0523s/iter; left time: 618.1863s\n",
      "\titers: 900, epoch: 7 | loss: 0.0111840\n",
      "\tspeed: 0.0514s/iter; left time: 602.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.57s\n",
      "Steps: 902 | Train Loss: 0.0126304 Vali Loss: 0.0205957 Test Loss: 0.0224589\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020444514229893684, rmse:0.1429843157529831, mae:0.09515336155891418, rse:0.5410126447677612\n",
      "Original data scale mse:4184471.5, rmse:2045.5980224609375, mae:1344.2694091796875, rse:0.14409227669239044\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2902493\n",
      "\tspeed: 0.0523s/iter; left time: 942.3397s\n",
      "\titers: 200, epoch: 1 | loss: 0.2741888\n",
      "\tspeed: 0.0315s/iter; left time: 564.6744s\n",
      "\titers: 300, epoch: 1 | loss: 0.2610337\n",
      "\tspeed: 0.0313s/iter; left time: 557.3865s\n",
      "\titers: 400, epoch: 1 | loss: 0.2704972\n",
      "\tspeed: 0.0312s/iter; left time: 553.1411s\n",
      "\titers: 500, epoch: 1 | loss: 0.2456489\n",
      "\tspeed: 0.0312s/iter; left time: 550.1929s\n",
      "\titers: 600, epoch: 1 | loss: 0.2311719\n",
      "\tspeed: 0.0307s/iter; left time: 538.2733s\n",
      "\titers: 700, epoch: 1 | loss: 0.2196548\n",
      "\tspeed: 0.0302s/iter; left time: 526.9753s\n",
      "\titers: 800, epoch: 1 | loss: 0.2212136\n",
      "\tspeed: 0.0301s/iter; left time: 522.1186s\n",
      "\titers: 900, epoch: 1 | loss: 0.2233823\n",
      "\tspeed: 0.0304s/iter; left time: 523.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.81s\n",
      "Steps: 906 | Train Loss: 0.2514932 Vali Loss: 0.2060444 Test Loss: 0.2244131\n",
      "Validation loss decreased (inf --> 0.206044).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1803533\n",
      "\tspeed: 0.0888s/iter; left time: 1519.6118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1647318\n",
      "\tspeed: 0.0300s/iter; left time: 510.5270s\n",
      "\titers: 300, epoch: 2 | loss: 0.1535174\n",
      "\tspeed: 0.0300s/iter; left time: 507.2181s\n",
      "\titers: 400, epoch: 2 | loss: 0.1525052\n",
      "\tspeed: 0.0300s/iter; left time: 503.8365s\n",
      "\titers: 500, epoch: 2 | loss: 0.1601175\n",
      "\tspeed: 0.0300s/iter; left time: 501.1393s\n",
      "\titers: 600, epoch: 2 | loss: 0.1443701\n",
      "\tspeed: 0.0300s/iter; left time: 498.0194s\n",
      "\titers: 700, epoch: 2 | loss: 0.1315372\n",
      "\tspeed: 0.0300s/iter; left time: 494.6257s\n",
      "\titers: 800, epoch: 2 | loss: 0.1292601\n",
      "\tspeed: 0.0299s/iter; left time: 490.9801s\n",
      "\titers: 900, epoch: 2 | loss: 0.1108416\n",
      "\tspeed: 0.0299s/iter; left time: 487.2517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.53s\n",
      "Steps: 906 | Train Loss: 0.1511596 Vali Loss: 0.0927487 Test Loss: 0.0993738\n",
      "Validation loss decreased (0.206044 --> 0.092749).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1093953\n",
      "\tspeed: 0.0881s/iter; left time: 1427.4752s\n",
      "\titers: 200, epoch: 3 | loss: 0.0894001\n",
      "\tspeed: 0.0299s/iter; left time: 481.2666s\n",
      "\titers: 300, epoch: 3 | loss: 0.0985301\n",
      "\tspeed: 0.0298s/iter; left time: 477.3494s\n",
      "\titers: 400, epoch: 3 | loss: 0.0876931\n",
      "\tspeed: 0.0298s/iter; left time: 474.2677s\n",
      "\titers: 500, epoch: 3 | loss: 0.0958897\n",
      "\tspeed: 0.0298s/iter; left time: 471.6624s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893619\n",
      "\tspeed: 0.0298s/iter; left time: 468.7628s\n",
      "\titers: 700, epoch: 3 | loss: 0.0801954\n",
      "\tspeed: 0.0299s/iter; left time: 466.5334s\n",
      "\titers: 800, epoch: 3 | loss: 0.0824574\n",
      "\tspeed: 0.0297s/iter; left time: 460.9884s\n",
      "\titers: 900, epoch: 3 | loss: 0.0790002\n",
      "\tspeed: 0.0297s/iter; left time: 457.5523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.37s\n",
      "Steps: 906 | Train Loss: 0.0906504 Vali Loss: 0.0732097 Test Loss: 0.0756763\n",
      "Validation loss decreased (0.092749 --> 0.073210).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0778671\n",
      "\tspeed: 0.1073s/iter; left time: 1642.3741s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749894\n",
      "\tspeed: 0.0434s/iter; left time: 659.7585s\n",
      "\titers: 300, epoch: 4 | loss: 0.0766752\n",
      "\tspeed: 0.0379s/iter; left time: 572.9419s\n",
      "\titers: 400, epoch: 4 | loss: 0.0800773\n",
      "\tspeed: 0.0308s/iter; left time: 461.9044s\n",
      "\titers: 500, epoch: 4 | loss: 0.0742403\n",
      "\tspeed: 0.0303s/iter; left time: 451.0793s\n",
      "\titers: 600, epoch: 4 | loss: 0.0876850\n",
      "\tspeed: 0.0301s/iter; left time: 445.4711s\n",
      "\titers: 700, epoch: 4 | loss: 0.0861338\n",
      "\tspeed: 0.0301s/iter; left time: 441.8453s\n",
      "\titers: 800, epoch: 4 | loss: 0.0785777\n",
      "\tspeed: 0.0302s/iter; left time: 440.5965s\n",
      "\titers: 900, epoch: 4 | loss: 0.0819057\n",
      "\tspeed: 0.0310s/iter; left time: 449.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.49s\n",
      "Steps: 906 | Train Loss: 0.0783287 Vali Loss: 0.0688663 Test Loss: 0.0728115\n",
      "Validation loss decreased (0.073210 --> 0.068866).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0720612\n",
      "\tspeed: 0.1194s/iter; left time: 1719.5171s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664565\n",
      "\tspeed: 0.0451s/iter; left time: 645.2956s\n",
      "\titers: 300, epoch: 5 | loss: 0.0669777\n",
      "\tspeed: 0.0465s/iter; left time: 659.6143s\n",
      "\titers: 400, epoch: 5 | loss: 0.0694795\n",
      "\tspeed: 0.0487s/iter; left time: 687.1156s\n",
      "\titers: 500, epoch: 5 | loss: 0.0782501\n",
      "\tspeed: 0.0479s/iter; left time: 670.9046s\n",
      "\titers: 600, epoch: 5 | loss: 0.0670698\n",
      "\tspeed: 0.0479s/iter; left time: 665.7855s\n",
      "\titers: 700, epoch: 5 | loss: 0.0760397\n",
      "\tspeed: 0.0485s/iter; left time: 668.9087s\n",
      "\titers: 800, epoch: 5 | loss: 0.0669637\n",
      "\tspeed: 0.0460s/iter; left time: 629.7116s\n",
      "\titers: 900, epoch: 5 | loss: 0.0768906\n",
      "\tspeed: 0.0464s/iter; left time: 630.6487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 906 | Train Loss: 0.0722862 Vali Loss: 0.0662428 Test Loss: 0.0685869\n",
      "Validation loss decreased (0.068866 --> 0.066243).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0669852\n",
      "\tspeed: 0.1485s/iter; left time: 2003.0217s\n",
      "\titers: 200, epoch: 6 | loss: 0.0687520\n",
      "\tspeed: 0.0475s/iter; left time: 635.7273s\n",
      "\titers: 300, epoch: 6 | loss: 0.0801936\n",
      "\tspeed: 0.0464s/iter; left time: 616.8340s\n",
      "\titers: 400, epoch: 6 | loss: 0.0728249\n",
      "\tspeed: 0.0455s/iter; left time: 600.1183s\n",
      "\titers: 500, epoch: 6 | loss: 0.0664718\n",
      "\tspeed: 0.0498s/iter; left time: 652.5264s\n",
      "\titers: 600, epoch: 6 | loss: 0.0725403\n",
      "\tspeed: 0.0459s/iter; left time: 596.1829s\n",
      "\titers: 700, epoch: 6 | loss: 0.0784970\n",
      "\tspeed: 0.0461s/iter; left time: 594.2755s\n",
      "\titers: 800, epoch: 6 | loss: 0.0662701\n",
      "\tspeed: 0.0454s/iter; left time: 580.8947s\n",
      "\titers: 900, epoch: 6 | loss: 0.0762237\n",
      "\tspeed: 0.0363s/iter; left time: 460.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.14s\n",
      "Steps: 906 | Train Loss: 0.0687720 Vali Loss: 0.0684630 Test Loss: 0.0693044\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0688635\n",
      "\tspeed: 0.0893s/iter; left time: 1124.4458s\n",
      "\titers: 200, epoch: 7 | loss: 0.0581973\n",
      "\tspeed: 0.0308s/iter; left time: 384.8467s\n",
      "\titers: 300, epoch: 7 | loss: 0.0630935\n",
      "\tspeed: 0.0308s/iter; left time: 381.9805s\n",
      "\titers: 400, epoch: 7 | loss: 0.0630240\n",
      "\tspeed: 0.0302s/iter; left time: 370.5312s\n",
      "\titers: 500, epoch: 7 | loss: 0.0670441\n",
      "\tspeed: 0.0298s/iter; left time: 363.2434s\n",
      "\titers: 600, epoch: 7 | loss: 0.0585939\n",
      "\tspeed: 0.0297s/iter; left time: 358.8691s\n",
      "\titers: 700, epoch: 7 | loss: 0.0632973\n",
      "\tspeed: 0.0297s/iter; left time: 355.6238s\n",
      "\titers: 800, epoch: 7 | loss: 0.0723130\n",
      "\tspeed: 0.0301s/iter; left time: 357.8045s\n",
      "\titers: 900, epoch: 7 | loss: 0.0634317\n",
      "\tspeed: 0.0321s/iter; left time: 378.7379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.17s\n",
      "Steps: 906 | Train Loss: 0.0660216 Vali Loss: 0.0614992 Test Loss: 0.0646311\n",
      "Validation loss decreased (0.066243 --> 0.061499).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0622691\n",
      "\tspeed: 0.1252s/iter; left time: 1462.7574s\n",
      "\titers: 200, epoch: 8 | loss: 0.0572450\n",
      "\tspeed: 0.0384s/iter; left time: 444.2597s\n",
      "\titers: 300, epoch: 8 | loss: 0.0651051\n",
      "\tspeed: 0.0392s/iter; left time: 449.5174s\n",
      "\titers: 400, epoch: 8 | loss: 0.0611684\n",
      "\tspeed: 0.0385s/iter; left time: 438.3859s\n",
      "\titers: 500, epoch: 8 | loss: 0.0670146\n",
      "\tspeed: 0.0383s/iter; left time: 432.2799s\n",
      "\titers: 600, epoch: 8 | loss: 0.0683972\n",
      "\tspeed: 0.0388s/iter; left time: 433.3386s\n",
      "\titers: 700, epoch: 8 | loss: 0.0622452\n",
      "\tspeed: 0.0374s/iter; left time: 414.1537s\n",
      "\titers: 800, epoch: 8 | loss: 0.0620193\n",
      "\tspeed: 0.0381s/iter; left time: 417.8558s\n",
      "\titers: 900, epoch: 8 | loss: 0.0676173\n",
      "\tspeed: 0.0385s/iter; left time: 418.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:35.63s\n",
      "Steps: 906 | Train Loss: 0.0642538 Vali Loss: 0.0628026 Test Loss: 0.0651178\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0613522\n",
      "\tspeed: 0.1201s/iter; left time: 1293.4960s\n",
      "\titers: 200, epoch: 9 | loss: 0.0652013\n",
      "\tspeed: 0.0383s/iter; left time: 408.8301s\n",
      "\titers: 300, epoch: 9 | loss: 0.0618752\n",
      "\tspeed: 0.0382s/iter; left time: 403.6510s\n",
      "\titers: 400, epoch: 9 | loss: 0.0683897\n",
      "\tspeed: 0.0383s/iter; left time: 401.1909s\n",
      "\titers: 500, epoch: 9 | loss: 0.0660354\n",
      "\tspeed: 0.0369s/iter; left time: 382.5238s\n",
      "\titers: 600, epoch: 9 | loss: 0.0661985\n",
      "\tspeed: 0.0391s/iter; left time: 401.8683s\n",
      "\titers: 700, epoch: 9 | loss: 0.0626055\n",
      "\tspeed: 0.0382s/iter; left time: 388.5290s\n",
      "\titers: 800, epoch: 9 | loss: 0.0641785\n",
      "\tspeed: 0.0385s/iter; left time: 387.7583s\n",
      "\titers: 900, epoch: 9 | loss: 0.0626485\n",
      "\tspeed: 0.0382s/iter; left time: 380.7770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:35.46s\n",
      "Steps: 906 | Train Loss: 0.0627686 Vali Loss: 0.0584813 Test Loss: 0.0631119\n",
      "Validation loss decreased (0.061499 --> 0.058481).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0642382\n",
      "\tspeed: 0.1266s/iter; left time: 1249.3531s\n",
      "\titers: 200, epoch: 10 | loss: 0.0590335\n",
      "\tspeed: 0.0381s/iter; left time: 371.7456s\n",
      "\titers: 300, epoch: 10 | loss: 0.0595673\n",
      "\tspeed: 0.0384s/iter; left time: 371.1383s\n",
      "\titers: 400, epoch: 10 | loss: 0.0623627\n",
      "\tspeed: 0.0390s/iter; left time: 373.1393s\n",
      "\titers: 500, epoch: 10 | loss: 0.0606330\n",
      "\tspeed: 0.0381s/iter; left time: 360.3094s\n",
      "\titers: 600, epoch: 10 | loss: 0.0587805\n",
      "\tspeed: 0.0381s/iter; left time: 356.9795s\n",
      "\titers: 700, epoch: 10 | loss: 0.0626884\n",
      "\tspeed: 0.0380s/iter; left time: 352.4103s\n",
      "\titers: 800, epoch: 10 | loss: 0.0583919\n",
      "\tspeed: 0.0378s/iter; left time: 346.3293s\n",
      "\titers: 900, epoch: 10 | loss: 0.0666970\n",
      "\tspeed: 0.0379s/iter; left time: 343.7519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:35.40s\n",
      "Steps: 906 | Train Loss: 0.0618593 Vali Loss: 0.0584933 Test Loss: 0.0621403\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0542567\n",
      "\tspeed: 0.1200s/iter; left time: 1075.4743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0518613\n",
      "\tspeed: 0.0381s/iter; left time: 337.9527s\n",
      "\titers: 300, epoch: 11 | loss: 0.0621452\n",
      "\tspeed: 0.0380s/iter; left time: 333.1760s\n",
      "\titers: 400, epoch: 11 | loss: 0.0610250\n",
      "\tspeed: 0.0376s/iter; left time: 326.0664s\n",
      "\titers: 500, epoch: 11 | loss: 0.0539611\n",
      "\tspeed: 0.0378s/iter; left time: 323.3008s\n",
      "\titers: 600, epoch: 11 | loss: 0.0644234\n",
      "\tspeed: 0.0377s/iter; left time: 319.3941s\n",
      "\titers: 700, epoch: 11 | loss: 0.0612320\n",
      "\tspeed: 0.0377s/iter; left time: 315.5658s\n",
      "\titers: 800, epoch: 11 | loss: 0.0617345\n",
      "\tspeed: 0.0387s/iter; left time: 319.5130s\n",
      "\titers: 900, epoch: 11 | loss: 0.0623700\n",
      "\tspeed: 0.0381s/iter; left time: 311.2738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:35.09s\n",
      "Steps: 906 | Train Loss: 0.0608514 Vali Loss: 0.0587256 Test Loss: 0.0618673\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0651484\n",
      "\tspeed: 0.1200s/iter; left time: 966.5344s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657314\n",
      "\tspeed: 0.0380s/iter; left time: 302.6803s\n",
      "\titers: 300, epoch: 12 | loss: 0.0693399\n",
      "\tspeed: 0.0381s/iter; left time: 299.5242s\n",
      "\titers: 400, epoch: 12 | loss: 0.0562475\n",
      "\tspeed: 0.0380s/iter; left time: 294.9323s\n",
      "\titers: 500, epoch: 12 | loss: 0.0550637\n",
      "\tspeed: 0.0382s/iter; left time: 292.3169s\n",
      "\titers: 600, epoch: 12 | loss: 0.0609136\n",
      "\tspeed: 0.0379s/iter; left time: 286.0949s\n",
      "\titers: 700, epoch: 12 | loss: 0.0653252\n",
      "\tspeed: 0.0381s/iter; left time: 284.0432s\n",
      "\titers: 800, epoch: 12 | loss: 0.0556690\n",
      "\tspeed: 0.0391s/iter; left time: 287.5481s\n",
      "\titers: 900, epoch: 12 | loss: 0.0541054\n",
      "\tspeed: 0.0392s/iter; left time: 284.1724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:35.39s\n",
      "Steps: 906 | Train Loss: 0.0600968 Vali Loss: 0.0585420 Test Loss: 0.0619712\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010945471934974194, rmse:0.10462061315774918, mae:0.06313996762037277, rse:0.3953685760498047\n",
      "Original data scale mse:1645302.5, rmse:1282.6934814453125, mae:826.3154296875, rse:0.09013789147138596\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3215514\n",
      "\tspeed: 0.0524s/iter; left time: 943.8541s\n",
      "\titers: 200, epoch: 1 | loss: 0.2962449\n",
      "\tspeed: 0.0403s/iter; left time: 722.9031s\n",
      "\titers: 300, epoch: 1 | loss: 0.2778833\n",
      "\tspeed: 0.0427s/iter; left time: 760.4733s\n",
      "\titers: 400, epoch: 1 | loss: 0.2541887\n",
      "\tspeed: 0.0429s/iter; left time: 759.9133s\n",
      "\titers: 500, epoch: 1 | loss: 0.2432526\n",
      "\tspeed: 0.0392s/iter; left time: 689.9898s\n",
      "\titers: 600, epoch: 1 | loss: 0.2443031\n",
      "\tspeed: 0.0393s/iter; left time: 688.0821s\n",
      "\titers: 700, epoch: 1 | loss: 0.2264178\n",
      "\tspeed: 0.0423s/iter; left time: 737.2794s\n",
      "\titers: 800, epoch: 1 | loss: 0.2336654\n",
      "\tspeed: 0.0398s/iter; left time: 689.5075s\n",
      "\titers: 900, epoch: 1 | loss: 0.2164385\n",
      "\tspeed: 0.0395s/iter; left time: 680.1122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.2649641 Vali Loss: 0.2097614 Test Loss: 0.2285840\n",
      "Validation loss decreased (inf --> 0.209761).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1800373\n",
      "\tspeed: 0.1307s/iter; left time: 2237.0971s\n",
      "\titers: 200, epoch: 2 | loss: 0.1536442\n",
      "\tspeed: 0.0389s/iter; left time: 661.2225s\n",
      "\titers: 300, epoch: 2 | loss: 0.1354571\n",
      "\tspeed: 0.0387s/iter; left time: 654.5614s\n",
      "\titers: 400, epoch: 2 | loss: 0.1200715\n",
      "\tspeed: 0.0393s/iter; left time: 660.6859s\n",
      "\titers: 500, epoch: 2 | loss: 0.1101638\n",
      "\tspeed: 0.0389s/iter; left time: 650.6516s\n",
      "\titers: 600, epoch: 2 | loss: 0.1052522\n",
      "\tspeed: 0.0388s/iter; left time: 645.1457s\n",
      "\titers: 700, epoch: 2 | loss: 0.1080620\n",
      "\tspeed: 0.0390s/iter; left time: 644.8994s\n",
      "\titers: 800, epoch: 2 | loss: 0.0969323\n",
      "\tspeed: 0.0385s/iter; left time: 631.4561s\n",
      "\titers: 900, epoch: 2 | loss: 0.0951101\n",
      "\tspeed: 0.0382s/iter; left time: 623.8505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.01s\n",
      "Steps: 906 | Train Loss: 0.1303824 Vali Loss: 0.0785427 Test Loss: 0.0836729\n",
      "Validation loss decreased (0.209761 --> 0.078543).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0989101\n",
      "\tspeed: 0.1312s/iter; left time: 2126.1483s\n",
      "\titers: 200, epoch: 3 | loss: 0.0877792\n",
      "\tspeed: 0.0381s/iter; left time: 614.0891s\n",
      "\titers: 300, epoch: 3 | loss: 0.0894169\n",
      "\tspeed: 0.0383s/iter; left time: 613.8357s\n",
      "\titers: 400, epoch: 3 | loss: 0.0849288\n",
      "\tspeed: 0.0400s/iter; left time: 636.6274s\n",
      "\titers: 500, epoch: 3 | loss: 0.0934045\n",
      "\tspeed: 0.0387s/iter; left time: 611.4711s\n",
      "\titers: 600, epoch: 3 | loss: 0.0808327\n",
      "\tspeed: 0.0386s/iter; left time: 606.7067s\n",
      "\titers: 700, epoch: 3 | loss: 0.0920352\n",
      "\tspeed: 0.0392s/iter; left time: 612.2196s\n",
      "\titers: 800, epoch: 3 | loss: 0.0774384\n",
      "\tspeed: 0.0398s/iter; left time: 617.4325s\n",
      "\titers: 900, epoch: 3 | loss: 0.0871820\n",
      "\tspeed: 0.0392s/iter; left time: 604.6630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.31s\n",
      "Steps: 906 | Train Loss: 0.0880011 Vali Loss: 0.0708143 Test Loss: 0.0744535\n",
      "Validation loss decreased (0.078543 --> 0.070814).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0873075\n",
      "\tspeed: 0.1281s/iter; left time: 1960.3761s\n",
      "\titers: 200, epoch: 4 | loss: 0.0833491\n",
      "\tspeed: 0.0396s/iter; left time: 602.3061s\n",
      "\titers: 300, epoch: 4 | loss: 0.0741808\n",
      "\tspeed: 0.0387s/iter; left time: 584.6630s\n",
      "\titers: 400, epoch: 4 | loss: 0.0798994\n",
      "\tspeed: 0.0391s/iter; left time: 586.6889s\n",
      "\titers: 500, epoch: 4 | loss: 0.0721976\n",
      "\tspeed: 0.0389s/iter; left time: 579.2924s\n",
      "\titers: 600, epoch: 4 | loss: 0.0733277\n",
      "\tspeed: 0.0389s/iter; left time: 575.3130s\n",
      "\titers: 700, epoch: 4 | loss: 0.0661782\n",
      "\tspeed: 0.0389s/iter; left time: 571.3649s\n",
      "\titers: 800, epoch: 4 | loss: 0.0691553\n",
      "\tspeed: 0.0393s/iter; left time: 573.3771s\n",
      "\titers: 900, epoch: 4 | loss: 0.0768283\n",
      "\tspeed: 0.0395s/iter; left time: 572.7037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.44s\n",
      "Steps: 906 | Train Loss: 0.0787245 Vali Loss: 0.0681166 Test Loss: 0.0705592\n",
      "Validation loss decreased (0.070814 --> 0.068117).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0775105\n",
      "\tspeed: 0.1269s/iter; left time: 1826.8052s\n",
      "\titers: 200, epoch: 5 | loss: 0.0789741\n",
      "\tspeed: 0.0390s/iter; left time: 557.1464s\n",
      "\titers: 300, epoch: 5 | loss: 0.0719022\n",
      "\tspeed: 0.0386s/iter; left time: 548.4498s\n",
      "\titers: 400, epoch: 5 | loss: 0.0759309\n",
      "\tspeed: 0.0388s/iter; left time: 547.2527s\n",
      "\titers: 500, epoch: 5 | loss: 0.0736981\n",
      "\tspeed: 0.0390s/iter; left time: 546.5256s\n",
      "\titers: 600, epoch: 5 | loss: 0.0803437\n",
      "\tspeed: 0.0386s/iter; left time: 536.4857s\n",
      "\titers: 700, epoch: 5 | loss: 0.0745182\n",
      "\tspeed: 0.0387s/iter; left time: 533.8264s\n",
      "\titers: 800, epoch: 5 | loss: 0.0693683\n",
      "\tspeed: 0.0386s/iter; left time: 528.2389s\n",
      "\titers: 900, epoch: 5 | loss: 0.0704218\n",
      "\tspeed: 0.0382s/iter; left time: 520.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:35.85s\n",
      "Steps: 906 | Train Loss: 0.0733596 Vali Loss: 0.0648952 Test Loss: 0.0695075\n",
      "Validation loss decreased (0.068117 --> 0.064895).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0706680\n",
      "\tspeed: 0.1352s/iter; left time: 1823.3860s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692734\n",
      "\tspeed: 0.0383s/iter; left time: 513.2198s\n",
      "\titers: 300, epoch: 6 | loss: 0.0608656\n",
      "\tspeed: 0.0381s/iter; left time: 505.7258s\n",
      "\titers: 400, epoch: 6 | loss: 0.0653162\n",
      "\tspeed: 0.0379s/iter; left time: 499.3281s\n",
      "\titers: 500, epoch: 6 | loss: 0.0702204\n",
      "\tspeed: 0.0378s/iter; left time: 494.7853s\n",
      "\titers: 600, epoch: 6 | loss: 0.0716197\n",
      "\tspeed: 0.0378s/iter; left time: 490.8010s\n",
      "\titers: 700, epoch: 6 | loss: 0.0632500\n",
      "\tspeed: 0.0377s/iter; left time: 485.5693s\n",
      "\titers: 800, epoch: 6 | loss: 0.0708879\n",
      "\tspeed: 0.0381s/iter; left time: 487.3002s\n",
      "\titers: 900, epoch: 6 | loss: 0.0629827\n",
      "\tspeed: 0.0383s/iter; left time: 486.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:35.49s\n",
      "Steps: 906 | Train Loss: 0.0698444 Vali Loss: 0.0646243 Test Loss: 0.0666179\n",
      "Validation loss decreased (0.064895 --> 0.064624).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0666910\n",
      "\tspeed: 0.1273s/iter; left time: 1601.9318s\n",
      "\titers: 200, epoch: 7 | loss: 0.0681744\n",
      "\tspeed: 0.0391s/iter; left time: 488.0346s\n",
      "\titers: 300, epoch: 7 | loss: 0.0748056\n",
      "\tspeed: 0.0383s/iter; left time: 474.1872s\n",
      "\titers: 400, epoch: 7 | loss: 0.0652026\n",
      "\tspeed: 0.0376s/iter; left time: 461.7148s\n",
      "\titers: 500, epoch: 7 | loss: 0.0648826\n",
      "\tspeed: 0.0375s/iter; left time: 456.5482s\n",
      "\titers: 600, epoch: 7 | loss: 0.0746607\n",
      "\tspeed: 0.0376s/iter; left time: 454.0022s\n",
      "\titers: 700, epoch: 7 | loss: 0.0606430\n",
      "\tspeed: 0.0376s/iter; left time: 450.4495s\n",
      "\titers: 800, epoch: 7 | loss: 0.0751413\n",
      "\tspeed: 0.0377s/iter; left time: 448.6445s\n",
      "\titers: 900, epoch: 7 | loss: 0.0526699\n",
      "\tspeed: 0.0379s/iter; left time: 447.1678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.20s\n",
      "Steps: 906 | Train Loss: 0.0672462 Vali Loss: 0.0610497 Test Loss: 0.0644447\n",
      "Validation loss decreased (0.064624 --> 0.061050).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0710869\n",
      "\tspeed: 0.1248s/iter; left time: 1457.2839s\n",
      "\titers: 200, epoch: 8 | loss: 0.0639833\n",
      "\tspeed: 0.0380s/iter; left time: 440.0018s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549742\n",
      "\tspeed: 0.0379s/iter; left time: 435.5521s\n",
      "\titers: 400, epoch: 8 | loss: 0.0721900\n",
      "\tspeed: 0.0381s/iter; left time: 433.1097s\n",
      "\titers: 500, epoch: 8 | loss: 0.0590878\n",
      "\tspeed: 0.0380s/iter; left time: 428.1028s\n",
      "\titers: 600, epoch: 8 | loss: 0.0553939\n",
      "\tspeed: 0.0372s/iter; left time: 416.1241s\n",
      "\titers: 700, epoch: 8 | loss: 0.0673762\n",
      "\tspeed: 0.0379s/iter; left time: 420.2651s\n",
      "\titers: 800, epoch: 8 | loss: 0.0694936\n",
      "\tspeed: 0.0381s/iter; left time: 417.8401s\n",
      "\titers: 900, epoch: 8 | loss: 0.0661889\n",
      "\tspeed: 0.0385s/iter; left time: 419.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:35.15s\n",
      "Steps: 906 | Train Loss: 0.0654583 Vali Loss: 0.0606418 Test Loss: 0.0636206\n",
      "Validation loss decreased (0.061050 --> 0.060642).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0632583\n",
      "\tspeed: 0.1224s/iter; left time: 1319.1102s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609181\n",
      "\tspeed: 0.0382s/iter; left time: 407.4575s\n",
      "\titers: 300, epoch: 9 | loss: 0.0637035\n",
      "\tspeed: 0.0378s/iter; left time: 399.7858s\n",
      "\titers: 400, epoch: 9 | loss: 0.0644229\n",
      "\tspeed: 0.0379s/iter; left time: 396.7293s\n",
      "\titers: 500, epoch: 9 | loss: 0.0582468\n",
      "\tspeed: 0.0384s/iter; left time: 398.7090s\n",
      "\titers: 600, epoch: 9 | loss: 0.0681481\n",
      "\tspeed: 0.0378s/iter; left time: 388.2072s\n",
      "\titers: 700, epoch: 9 | loss: 0.0631135\n",
      "\tspeed: 0.0378s/iter; left time: 384.8733s\n",
      "\titers: 800, epoch: 9 | loss: 0.0582296\n",
      "\tspeed: 0.0381s/iter; left time: 384.2393s\n",
      "\titers: 900, epoch: 9 | loss: 0.0565161\n",
      "\tspeed: 0.0384s/iter; left time: 382.7399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:35.26s\n",
      "Steps: 906 | Train Loss: 0.0637091 Vali Loss: 0.0592555 Test Loss: 0.0628836\n",
      "Validation loss decreased (0.060642 --> 0.059256).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0681334\n",
      "\tspeed: 0.1259s/iter; left time: 1241.7748s\n",
      "\titers: 200, epoch: 10 | loss: 0.0582601\n",
      "\tspeed: 0.0383s/iter; left time: 373.7376s\n",
      "\titers: 300, epoch: 10 | loss: 0.0621131\n",
      "\tspeed: 0.0389s/iter; left time: 376.1083s\n",
      "\titers: 400, epoch: 10 | loss: 0.0559246\n",
      "\tspeed: 0.0401s/iter; left time: 383.4446s\n",
      "\titers: 500, epoch: 10 | loss: 0.0596847\n",
      "\tspeed: 0.0404s/iter; left time: 382.3121s\n",
      "\titers: 600, epoch: 10 | loss: 0.0544512\n",
      "\tspeed: 0.0405s/iter; left time: 379.2405s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663585\n",
      "\tspeed: 0.0407s/iter; left time: 376.9906s\n",
      "\titers: 800, epoch: 10 | loss: 0.0594966\n",
      "\tspeed: 0.0398s/iter; left time: 364.4605s\n",
      "\titers: 900, epoch: 10 | loss: 0.0592491\n",
      "\tspeed: 0.0393s/iter; left time: 356.7146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.0625934 Vali Loss: 0.0598258 Test Loss: 0.0626642\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0591894\n",
      "\tspeed: 0.1271s/iter; left time: 1139.1892s\n",
      "\titers: 200, epoch: 11 | loss: 0.0628843\n",
      "\tspeed: 0.0404s/iter; left time: 357.6396s\n",
      "\titers: 300, epoch: 11 | loss: 0.0636712\n",
      "\tspeed: 0.0395s/iter; left time: 346.3615s\n",
      "\titers: 400, epoch: 11 | loss: 0.0665771\n",
      "\tspeed: 0.0421s/iter; left time: 364.6510s\n",
      "\titers: 500, epoch: 11 | loss: 0.0635719\n",
      "\tspeed: 0.0395s/iter; left time: 338.0164s\n",
      "\titers: 600, epoch: 11 | loss: 0.0701939\n",
      "\tspeed: 0.0406s/iter; left time: 343.3365s\n",
      "\titers: 700, epoch: 11 | loss: 0.0707603\n",
      "\tspeed: 0.0441s/iter; left time: 368.7331s\n",
      "\titers: 800, epoch: 11 | loss: 0.0652541\n",
      "\tspeed: 0.0395s/iter; left time: 326.5491s\n",
      "\titers: 900, epoch: 11 | loss: 0.0669865\n",
      "\tspeed: 0.0393s/iter; left time: 321.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.0615790 Vali Loss: 0.0591117 Test Loss: 0.0624501\n",
      "Validation loss decreased (0.059256 --> 0.059112).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0542223\n",
      "\tspeed: 0.1335s/iter; left time: 1074.9434s\n",
      "\titers: 200, epoch: 12 | loss: 0.0674231\n",
      "\tspeed: 0.0438s/iter; left time: 348.5611s\n",
      "\titers: 300, epoch: 12 | loss: 0.0684998\n",
      "\tspeed: 0.0389s/iter; left time: 305.1825s\n",
      "\titers: 400, epoch: 12 | loss: 0.0642560\n",
      "\tspeed: 0.0388s/iter; left time: 300.9079s\n",
      "\titers: 500, epoch: 12 | loss: 0.0574316\n",
      "\tspeed: 0.0390s/iter; left time: 298.8899s\n",
      "\titers: 600, epoch: 12 | loss: 0.0550110\n",
      "\tspeed: 0.0437s/iter; left time: 329.9065s\n",
      "\titers: 700, epoch: 12 | loss: 0.0572623\n",
      "\tspeed: 0.0424s/iter; left time: 315.8305s\n",
      "\titers: 800, epoch: 12 | loss: 0.0665260\n",
      "\tspeed: 0.0394s/iter; left time: 290.0647s\n",
      "\titers: 900, epoch: 12 | loss: 0.0579232\n",
      "\tspeed: 0.0415s/iter; left time: 300.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 906 | Train Loss: 0.0607714 Vali Loss: 0.0579167 Test Loss: 0.0616267\n",
      "Validation loss decreased (0.059112 --> 0.057917).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0585217\n",
      "\tspeed: 0.1313s/iter; left time: 938.3623s\n",
      "\titers: 200, epoch: 13 | loss: 0.0542667\n",
      "\tspeed: 0.0384s/iter; left time: 270.5957s\n",
      "\titers: 300, epoch: 13 | loss: 0.0524522\n",
      "\tspeed: 0.0384s/iter; left time: 266.8829s\n",
      "\titers: 400, epoch: 13 | loss: 0.0695628\n",
      "\tspeed: 0.0387s/iter; left time: 265.0013s\n",
      "\titers: 500, epoch: 13 | loss: 0.0586820\n",
      "\tspeed: 0.0384s/iter; left time: 259.4498s\n",
      "\titers: 600, epoch: 13 | loss: 0.0534613\n",
      "\tspeed: 0.0387s/iter; left time: 257.1477s\n",
      "\titers: 700, epoch: 13 | loss: 0.0634239\n",
      "\tspeed: 0.0400s/iter; left time: 261.9662s\n",
      "\titers: 800, epoch: 13 | loss: 0.0588961\n",
      "\tspeed: 0.0385s/iter; left time: 248.5423s\n",
      "\titers: 900, epoch: 13 | loss: 0.0625711\n",
      "\tspeed: 0.0391s/iter; left time: 248.3660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:36.00s\n",
      "Steps: 906 | Train Loss: 0.0601627 Vali Loss: 0.0573253 Test Loss: 0.0614484\n",
      "Validation loss decreased (0.057917 --> 0.057325).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0554540\n",
      "\tspeed: 0.1319s/iter; left time: 823.4533s\n",
      "\titers: 200, epoch: 14 | loss: 0.0673822\n",
      "\tspeed: 0.0392s/iter; left time: 240.5952s\n",
      "\titers: 300, epoch: 14 | loss: 0.0580425\n",
      "\tspeed: 0.0392s/iter; left time: 237.1602s\n",
      "\titers: 400, epoch: 14 | loss: 0.0507325\n",
      "\tspeed: 0.0393s/iter; left time: 233.3452s\n",
      "\titers: 500, epoch: 14 | loss: 0.0558091\n",
      "\tspeed: 0.0398s/iter; left time: 232.4309s\n",
      "\titers: 600, epoch: 14 | loss: 0.0614470\n",
      "\tspeed: 0.0433s/iter; left time: 248.4980s\n",
      "\titers: 700, epoch: 14 | loss: 0.0576007\n",
      "\tspeed: 0.0388s/iter; left time: 218.9674s\n",
      "\titers: 800, epoch: 14 | loss: 0.0567083\n",
      "\tspeed: 0.0390s/iter; left time: 216.4407s\n",
      "\titers: 900, epoch: 14 | loss: 0.0564441\n",
      "\tspeed: 0.0388s/iter; left time: 210.9294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.0595447 Vali Loss: 0.0574422 Test Loss: 0.0615878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0627353\n",
      "\tspeed: 0.1301s/iter; left time: 694.4051s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539344\n",
      "\tspeed: 0.0388s/iter; left time: 203.0942s\n",
      "\titers: 300, epoch: 15 | loss: 0.0617916\n",
      "\tspeed: 0.0390s/iter; left time: 200.3877s\n",
      "\titers: 400, epoch: 15 | loss: 0.0640817\n",
      "\tspeed: 0.0389s/iter; left time: 195.9356s\n",
      "\titers: 500, epoch: 15 | loss: 0.0610437\n",
      "\tspeed: 0.0391s/iter; left time: 193.0550s\n",
      "\titers: 600, epoch: 15 | loss: 0.0552038\n",
      "\tspeed: 0.0388s/iter; left time: 187.8975s\n",
      "\titers: 700, epoch: 15 | loss: 0.0684426\n",
      "\tspeed: 0.0383s/iter; left time: 181.3404s\n",
      "\titers: 800, epoch: 15 | loss: 0.0610780\n",
      "\tspeed: 0.0387s/iter; left time: 179.3351s\n",
      "\titers: 900, epoch: 15 | loss: 0.0571563\n",
      "\tspeed: 0.0391s/iter; left time: 177.2540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:36.30s\n",
      "Steps: 906 | Train Loss: 0.0589908 Vali Loss: 0.0575816 Test Loss: 0.0614171\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0560294\n",
      "\tspeed: 0.1284s/iter; left time: 568.9306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0610810\n",
      "\tspeed: 0.0389s/iter; left time: 168.3222s\n",
      "\titers: 300, epoch: 16 | loss: 0.0538194\n",
      "\tspeed: 0.0393s/iter; left time: 166.4624s\n",
      "\titers: 400, epoch: 16 | loss: 0.0583194\n",
      "\tspeed: 0.0393s/iter; left time: 162.1802s\n",
      "\titers: 500, epoch: 16 | loss: 0.0588251\n",
      "\tspeed: 0.0385s/iter; left time: 155.0568s\n",
      "\titers: 600, epoch: 16 | loss: 0.0635661\n",
      "\tspeed: 0.0431s/iter; left time: 169.4495s\n",
      "\titers: 700, epoch: 16 | loss: 0.0559292\n",
      "\tspeed: 0.0388s/iter; left time: 148.8214s\n",
      "\titers: 800, epoch: 16 | loss: 0.0596918\n",
      "\tspeed: 0.0392s/iter; left time: 146.3602s\n",
      "\titers: 900, epoch: 16 | loss: 0.0625972\n",
      "\tspeed: 0.0395s/iter; left time: 143.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.0585736 Vali Loss: 0.0566247 Test Loss: 0.0609283\n",
      "Validation loss decreased (0.057325 --> 0.056625).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0624986\n",
      "\tspeed: 0.1285s/iter; left time: 452.9117s\n",
      "\titers: 200, epoch: 17 | loss: 0.0498874\n",
      "\tspeed: 0.0389s/iter; left time: 133.3820s\n",
      "\titers: 300, epoch: 17 | loss: 0.0562520\n",
      "\tspeed: 0.0389s/iter; left time: 129.3531s\n",
      "\titers: 400, epoch: 17 | loss: 0.0549764\n",
      "\tspeed: 0.0386s/iter; left time: 124.3402s\n",
      "\titers: 500, epoch: 17 | loss: 0.0552374\n",
      "\tspeed: 0.0391s/iter; left time: 122.0806s\n",
      "\titers: 600, epoch: 17 | loss: 0.0648577\n",
      "\tspeed: 0.0398s/iter; left time: 120.4086s\n",
      "\titers: 700, epoch: 17 | loss: 0.0615047\n",
      "\tspeed: 0.0390s/iter; left time: 113.9850s\n",
      "\titers: 800, epoch: 17 | loss: 0.0574227\n",
      "\tspeed: 0.0418s/iter; left time: 117.9753s\n",
      "\titers: 900, epoch: 17 | loss: 0.0639487\n",
      "\tspeed: 0.0405s/iter; left time: 110.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:36.50s\n",
      "Steps: 906 | Train Loss: 0.0582433 Vali Loss: 0.0569728 Test Loss: 0.0614945\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0549237\n",
      "\tspeed: 0.1257s/iter; left time: 329.1169s\n",
      "\titers: 200, epoch: 18 | loss: 0.0559401\n",
      "\tspeed: 0.0406s/iter; left time: 102.2005s\n",
      "\titers: 300, epoch: 18 | loss: 0.0572384\n",
      "\tspeed: 0.0393s/iter; left time: 95.0376s\n",
      "\titers: 400, epoch: 18 | loss: 0.0636389\n",
      "\tspeed: 0.0390s/iter; left time: 90.3382s\n",
      "\titers: 500, epoch: 18 | loss: 0.0550979\n",
      "\tspeed: 0.0388s/iter; left time: 86.1259s\n",
      "\titers: 600, epoch: 18 | loss: 0.0528391\n",
      "\tspeed: 0.0389s/iter; left time: 82.5143s\n",
      "\titers: 700, epoch: 18 | loss: 0.0611030\n",
      "\tspeed: 0.0388s/iter; left time: 78.3176s\n",
      "\titers: 800, epoch: 18 | loss: 0.0530011\n",
      "\tspeed: 0.0389s/iter; left time: 74.5889s\n",
      "\titers: 900, epoch: 18 | loss: 0.0530139\n",
      "\tspeed: 0.0391s/iter; left time: 71.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:36.41s\n",
      "Steps: 906 | Train Loss: 0.0579204 Vali Loss: 0.0581870 Test Loss: 0.0614312\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0588550\n",
      "\tspeed: 0.1326s/iter; left time: 227.1561s\n",
      "\titers: 200, epoch: 19 | loss: 0.0587910\n",
      "\tspeed: 0.0441s/iter; left time: 71.1790s\n",
      "\titers: 300, epoch: 19 | loss: 0.0540270\n",
      "\tspeed: 0.0386s/iter; left time: 58.4299s\n",
      "\titers: 400, epoch: 19 | loss: 0.0509292\n",
      "\tspeed: 0.0387s/iter; left time: 54.7146s\n",
      "\titers: 500, epoch: 19 | loss: 0.0614764\n",
      "\tspeed: 0.0387s/iter; left time: 50.7654s\n",
      "\titers: 600, epoch: 19 | loss: 0.0619588\n",
      "\tspeed: 0.0388s/iter; left time: 47.0871s\n",
      "\titers: 700, epoch: 19 | loss: 0.0536997\n",
      "\tspeed: 0.0390s/iter; left time: 43.4133s\n",
      "\titers: 800, epoch: 19 | loss: 0.0512803\n",
      "\tspeed: 0.0391s/iter; left time: 39.5975s\n",
      "\titers: 900, epoch: 19 | loss: 0.0625779\n",
      "\tspeed: 0.0391s/iter; left time: 35.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:37.10s\n",
      "Steps: 906 | Train Loss: 0.0575639 Vali Loss: 0.0568886 Test Loss: 0.0606141\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010685218498110771, rmse:0.1033693328499794, mae:0.06094470992684364, rse:0.39063990116119385\n",
      "Original data scale mse:1408336.25, rmse:1186.7333984375, mae:765.263916015625, rse:0.08339455723762512\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2234164\n",
      "\tspeed: 0.1016s/iter; left time: 1825.9718s\n",
      "\titers: 200, epoch: 1 | loss: 0.2022699\n",
      "\tspeed: 0.0446s/iter; left time: 797.2405s\n",
      "\titers: 300, epoch: 1 | loss: 0.1857644\n",
      "\tspeed: 0.0443s/iter; left time: 788.3933s\n",
      "\titers: 400, epoch: 1 | loss: 0.1870912\n",
      "\tspeed: 0.0442s/iter; left time: 781.3740s\n",
      "\titers: 500, epoch: 1 | loss: 0.1875467\n",
      "\tspeed: 0.0441s/iter; left time: 775.5641s\n",
      "\titers: 600, epoch: 1 | loss: 0.1781097\n",
      "\tspeed: 0.0443s/iter; left time: 774.7564s\n",
      "\titers: 700, epoch: 1 | loss: 0.1764755\n",
      "\tspeed: 0.0442s/iter; left time: 768.4205s\n",
      "\titers: 800, epoch: 1 | loss: 0.1692605\n",
      "\tspeed: 0.0447s/iter; left time: 772.7564s\n",
      "\titers: 900, epoch: 1 | loss: 0.1721164\n",
      "\tspeed: 0.0443s/iter; left time: 761.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 904 | Train Loss: 0.1919547 Vali Loss: 0.1598371 Test Loss: 0.1781590\n",
      "Validation loss decreased (inf --> 0.159837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1587700\n",
      "\tspeed: 0.1420s/iter; left time: 2424.9913s\n",
      "\titers: 200, epoch: 2 | loss: 0.1293420\n",
      "\tspeed: 0.0440s/iter; left time: 747.7325s\n",
      "\titers: 300, epoch: 2 | loss: 0.1114798\n",
      "\tspeed: 0.0440s/iter; left time: 741.7773s\n",
      "\titers: 400, epoch: 2 | loss: 0.1062213\n",
      "\tspeed: 0.0440s/iter; left time: 738.1010s\n",
      "\titers: 500, epoch: 2 | loss: 0.1030116\n",
      "\tspeed: 0.0439s/iter; left time: 731.8357s\n",
      "\titers: 600, epoch: 2 | loss: 0.1068096\n",
      "\tspeed: 0.0442s/iter; left time: 732.2912s\n",
      "\titers: 700, epoch: 2 | loss: 0.0962882\n",
      "\tspeed: 0.0443s/iter; left time: 729.4837s\n",
      "\titers: 800, epoch: 2 | loss: 0.0939900\n",
      "\tspeed: 0.0442s/iter; left time: 724.6592s\n",
      "\titers: 900, epoch: 2 | loss: 0.0871617\n",
      "\tspeed: 0.0443s/iter; left time: 720.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.73s\n",
      "Steps: 904 | Train Loss: 0.1147608 Vali Loss: 0.0918198 Test Loss: 0.0954834\n",
      "Validation loss decreased (0.159837 --> 0.091820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0868053\n",
      "\tspeed: 0.1436s/iter; left time: 2321.6734s\n",
      "\titers: 200, epoch: 3 | loss: 0.0887945\n",
      "\tspeed: 0.0441s/iter; left time: 708.1120s\n",
      "\titers: 300, epoch: 3 | loss: 0.0912941\n",
      "\tspeed: 0.0441s/iter; left time: 704.8440s\n",
      "\titers: 400, epoch: 3 | loss: 0.0862730\n",
      "\tspeed: 0.0443s/iter; left time: 703.2308s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870565\n",
      "\tspeed: 0.0443s/iter; left time: 698.9549s\n",
      "\titers: 600, epoch: 3 | loss: 0.0834457\n",
      "\tspeed: 0.0445s/iter; left time: 698.1570s\n",
      "\titers: 700, epoch: 3 | loss: 0.0802337\n",
      "\tspeed: 0.0441s/iter; left time: 686.7985s\n",
      "\titers: 800, epoch: 3 | loss: 0.0909804\n",
      "\tspeed: 0.0442s/iter; left time: 683.5386s\n",
      "\titers: 900, epoch: 3 | loss: 0.0885427\n",
      "\tspeed: 0.0452s/iter; left time: 695.3917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 904 | Train Loss: 0.0857940 Vali Loss: 0.0823994 Test Loss: 0.0882448\n",
      "Validation loss decreased (0.091820 --> 0.082399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0783065\n",
      "\tspeed: 0.1450s/iter; left time: 2213.6431s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815353\n",
      "\tspeed: 0.0442s/iter; left time: 670.2676s\n",
      "\titers: 300, epoch: 4 | loss: 0.0767075\n",
      "\tspeed: 0.0446s/iter; left time: 671.3522s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832951\n",
      "\tspeed: 0.0447s/iter; left time: 669.3207s\n",
      "\titers: 500, epoch: 4 | loss: 0.0822221\n",
      "\tspeed: 0.0444s/iter; left time: 659.6702s\n",
      "\titers: 600, epoch: 4 | loss: 0.0801566\n",
      "\tspeed: 0.0445s/iter; left time: 656.6644s\n",
      "\titers: 700, epoch: 4 | loss: 0.0762827\n",
      "\tspeed: 0.0447s/iter; left time: 655.8621s\n",
      "\titers: 800, epoch: 4 | loss: 0.0798090\n",
      "\tspeed: 0.0447s/iter; left time: 651.6263s\n",
      "\titers: 900, epoch: 4 | loss: 0.0717353\n",
      "\tspeed: 0.0446s/iter; left time: 645.6067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.05s\n",
      "Steps: 904 | Train Loss: 0.0791869 Vali Loss: 0.0785477 Test Loss: 0.0890177\n",
      "Validation loss decreased (0.082399 --> 0.078548).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0720657\n",
      "\tspeed: 0.1383s/iter; left time: 1986.2046s\n",
      "\titers: 200, epoch: 5 | loss: 0.0794943\n",
      "\tspeed: 0.0453s/iter; left time: 645.9787s\n",
      "\titers: 300, epoch: 5 | loss: 0.0737573\n",
      "\tspeed: 0.0446s/iter; left time: 632.0912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0851306\n",
      "\tspeed: 0.0447s/iter; left time: 629.2434s\n",
      "\titers: 500, epoch: 5 | loss: 0.0751646\n",
      "\tspeed: 0.0472s/iter; left time: 658.8025s\n",
      "\titers: 600, epoch: 5 | loss: 0.0756328\n",
      "\tspeed: 0.0452s/iter; left time: 627.0209s\n",
      "\titers: 700, epoch: 5 | loss: 0.0784408\n",
      "\tspeed: 0.0440s/iter; left time: 605.3680s\n",
      "\titers: 800, epoch: 5 | loss: 0.0787868\n",
      "\tspeed: 0.0442s/iter; left time: 603.9708s\n",
      "\titers: 900, epoch: 5 | loss: 0.0707135\n",
      "\tspeed: 0.0445s/iter; left time: 603.1951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 904 | Train Loss: 0.0750352 Vali Loss: 0.0784350 Test Loss: 0.0873040\n",
      "Validation loss decreased (0.078548 --> 0.078435).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608570\n",
      "\tspeed: 0.1417s/iter; left time: 1907.3129s\n",
      "\titers: 200, epoch: 6 | loss: 0.0731282\n",
      "\tspeed: 0.0441s/iter; left time: 589.4856s\n",
      "\titers: 300, epoch: 6 | loss: 0.0743746\n",
      "\tspeed: 0.0454s/iter; left time: 602.1505s\n",
      "\titers: 400, epoch: 6 | loss: 0.0786287\n",
      "\tspeed: 0.0447s/iter; left time: 587.8104s\n",
      "\titers: 500, epoch: 6 | loss: 0.0711456\n",
      "\tspeed: 0.0440s/iter; left time: 574.9380s\n",
      "\titers: 600, epoch: 6 | loss: 0.0688125\n",
      "\tspeed: 0.0442s/iter; left time: 572.3739s\n",
      "\titers: 700, epoch: 6 | loss: 0.0645760\n",
      "\tspeed: 0.0437s/iter; left time: 562.3363s\n",
      "\titers: 800, epoch: 6 | loss: 0.0739696\n",
      "\tspeed: 0.0440s/iter; left time: 561.1960s\n",
      "\titers: 900, epoch: 6 | loss: 0.0709464\n",
      "\tspeed: 0.0442s/iter; left time: 559.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 904 | Train Loss: 0.0716413 Vali Loss: 0.0790789 Test Loss: 0.0905156\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0688940\n",
      "\tspeed: 0.1422s/iter; left time: 1785.7602s\n",
      "\titers: 200, epoch: 7 | loss: 0.0648436\n",
      "\tspeed: 0.0442s/iter; left time: 550.1801s\n",
      "\titers: 300, epoch: 7 | loss: 0.0682380\n",
      "\tspeed: 0.0447s/iter; left time: 552.8681s\n",
      "\titers: 400, epoch: 7 | loss: 0.0683820\n",
      "\tspeed: 0.0446s/iter; left time: 546.2456s\n",
      "\titers: 500, epoch: 7 | loss: 0.0626851\n",
      "\tspeed: 0.0444s/iter; left time: 539.8869s\n",
      "\titers: 600, epoch: 7 | loss: 0.0773246\n",
      "\tspeed: 0.0438s/iter; left time: 528.3298s\n",
      "\titers: 700, epoch: 7 | loss: 0.0646923\n",
      "\tspeed: 0.0437s/iter; left time: 522.3069s\n",
      "\titers: 800, epoch: 7 | loss: 0.0578526\n",
      "\tspeed: 0.0438s/iter; left time: 519.4211s\n",
      "\titers: 900, epoch: 7 | loss: 0.0684945\n",
      "\tspeed: 0.0430s/iter; left time: 505.6296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 904 | Train Loss: 0.0682806 Vali Loss: 0.0791010 Test Loss: 0.0920947\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0657914\n",
      "\tspeed: 0.1226s/iter; left time: 1428.9787s\n",
      "\titers: 200, epoch: 8 | loss: 0.0637566\n",
      "\tspeed: 0.0398s/iter; left time: 459.9746s\n",
      "\titers: 300, epoch: 8 | loss: 0.0698682\n",
      "\tspeed: 0.0388s/iter; left time: 444.0796s\n",
      "\titers: 400, epoch: 8 | loss: 0.0663481\n",
      "\tspeed: 0.0389s/iter; left time: 441.4572s\n",
      "\titers: 500, epoch: 8 | loss: 0.0669429\n",
      "\tspeed: 0.0388s/iter; left time: 437.0250s\n",
      "\titers: 600, epoch: 8 | loss: 0.0659548\n",
      "\tspeed: 0.0383s/iter; left time: 427.2075s\n",
      "\titers: 700, epoch: 8 | loss: 0.0648414\n",
      "\tspeed: 0.0381s/iter; left time: 421.3828s\n",
      "\titers: 800, epoch: 8 | loss: 0.0628099\n",
      "\tspeed: 0.0380s/iter; left time: 415.9866s\n",
      "\titers: 900, epoch: 8 | loss: 0.0677657\n",
      "\tspeed: 0.0378s/iter; left time: 409.7366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:35.67s\n",
      "Steps: 904 | Train Loss: 0.0654967 Vali Loss: 0.0814211 Test Loss: 0.0911637\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019647417590022087, rmse:0.14016924798488617, mae:0.08734754472970963, rse:0.5299950242042542\n",
      "Original data scale mse:3098940.5, rmse:1760.3807373046875, mae:1143.3651123046875, rse:0.12388518452644348\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2305787\n",
      "\tspeed: 0.0401s/iter; left time: 720.9849s\n",
      "\titers: 200, epoch: 1 | loss: 0.2002015\n",
      "\tspeed: 0.0374s/iter; left time: 668.8133s\n",
      "\titers: 300, epoch: 1 | loss: 0.1939660\n",
      "\tspeed: 0.0374s/iter; left time: 665.3799s\n",
      "\titers: 400, epoch: 1 | loss: 0.1827320\n",
      "\tspeed: 0.0375s/iter; left time: 662.3003s\n",
      "\titers: 500, epoch: 1 | loss: 0.1774096\n",
      "\tspeed: 0.0373s/iter; left time: 656.1732s\n",
      "\titers: 600, epoch: 1 | loss: 0.1837763\n",
      "\tspeed: 0.0373s/iter; left time: 652.7270s\n",
      "\titers: 700, epoch: 1 | loss: 0.1907933\n",
      "\tspeed: 0.0374s/iter; left time: 649.6333s\n",
      "\titers: 800, epoch: 1 | loss: 0.1770751\n",
      "\tspeed: 0.0373s/iter; left time: 645.1479s\n",
      "\titers: 900, epoch: 1 | loss: 0.1641386\n",
      "\tspeed: 0.0373s/iter; left time: 641.5572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.11s\n",
      "Steps: 904 | Train Loss: 0.1954213 Vali Loss: 0.1617718 Test Loss: 0.1785840\n",
      "Validation loss decreased (inf --> 0.161772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1517021\n",
      "\tspeed: 0.1092s/iter; left time: 1864.9773s\n",
      "\titers: 200, epoch: 2 | loss: 0.1233328\n",
      "\tspeed: 0.0374s/iter; left time: 634.6268s\n",
      "\titers: 300, epoch: 2 | loss: 0.1135465\n",
      "\tspeed: 0.0374s/iter; left time: 631.0876s\n",
      "\titers: 400, epoch: 2 | loss: 0.1109417\n",
      "\tspeed: 0.0478s/iter; left time: 801.4289s\n",
      "\titers: 500, epoch: 2 | loss: 0.1035156\n",
      "\tspeed: 0.0504s/iter; left time: 840.2632s\n",
      "\titers: 600, epoch: 2 | loss: 0.1034410\n",
      "\tspeed: 0.0441s/iter; left time: 730.9847s\n",
      "\titers: 700, epoch: 2 | loss: 0.0992679\n",
      "\tspeed: 0.0381s/iter; left time: 627.4461s\n",
      "\titers: 800, epoch: 2 | loss: 0.0934723\n",
      "\tspeed: 0.0379s/iter; left time: 619.9008s\n",
      "\titers: 900, epoch: 2 | loss: 0.1011899\n",
      "\tspeed: 0.0378s/iter; left time: 615.5777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 904 | Train Loss: 0.1149165 Vali Loss: 0.1081793 Test Loss: 0.1072797\n",
      "Validation loss decreased (0.161772 --> 0.108179).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0891823\n",
      "\tspeed: 0.1069s/iter; left time: 1728.8106s\n",
      "\titers: 200, epoch: 3 | loss: 0.0894226\n",
      "\tspeed: 0.0377s/iter; left time: 606.4034s\n",
      "\titers: 300, epoch: 3 | loss: 0.0894731\n",
      "\tspeed: 0.0380s/iter; left time: 607.6382s\n",
      "\titers: 400, epoch: 3 | loss: 0.0861133\n",
      "\tspeed: 0.0427s/iter; left time: 678.1096s\n",
      "\titers: 500, epoch: 3 | loss: 0.0865389\n",
      "\tspeed: 0.0503s/iter; left time: 793.0081s\n",
      "\titers: 600, epoch: 3 | loss: 0.0843280\n",
      "\tspeed: 0.0504s/iter; left time: 789.2974s\n",
      "\titers: 700, epoch: 3 | loss: 0.0834062\n",
      "\tspeed: 0.0515s/iter; left time: 802.6463s\n",
      "\titers: 800, epoch: 3 | loss: 0.0831972\n",
      "\tspeed: 0.0501s/iter; left time: 775.0747s\n",
      "\titers: 900, epoch: 3 | loss: 0.0730061\n",
      "\tspeed: 0.0505s/iter; left time: 776.3154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.42s\n",
      "Steps: 904 | Train Loss: 0.0871572 Vali Loss: 0.0813707 Test Loss: 0.0889578\n",
      "Validation loss decreased (0.108179 --> 0.081371).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0837898\n",
      "\tspeed: 0.1542s/iter; left time: 2354.9414s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797709\n",
      "\tspeed: 0.0388s/iter; left time: 588.2479s\n",
      "\titers: 300, epoch: 4 | loss: 0.0798079\n",
      "\tspeed: 0.0378s/iter; left time: 570.2000s\n",
      "\titers: 400, epoch: 4 | loss: 0.0792254\n",
      "\tspeed: 0.0376s/iter; left time: 562.6809s\n",
      "\titers: 500, epoch: 4 | loss: 0.0791823\n",
      "\tspeed: 0.0375s/iter; left time: 558.1747s\n",
      "\titers: 600, epoch: 4 | loss: 0.0838691\n",
      "\tspeed: 0.0376s/iter; left time: 554.7592s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838049\n",
      "\tspeed: 0.0375s/iter; left time: 550.7364s\n",
      "\titers: 800, epoch: 4 | loss: 0.0837702\n",
      "\tspeed: 0.0375s/iter; left time: 546.3736s\n",
      "\titers: 900, epoch: 4 | loss: 0.0713299\n",
      "\tspeed: 0.0375s/iter; left time: 543.0354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.22s\n",
      "Steps: 904 | Train Loss: 0.0805535 Vali Loss: 0.0803829 Test Loss: 0.0889783\n",
      "Validation loss decreased (0.081371 --> 0.080383).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769182\n",
      "\tspeed: 0.1067s/iter; left time: 1532.7655s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754545\n",
      "\tspeed: 0.0374s/iter; left time: 533.9493s\n",
      "\titers: 300, epoch: 5 | loss: 0.0822388\n",
      "\tspeed: 0.0374s/iter; left time: 530.4486s\n",
      "\titers: 400, epoch: 5 | loss: 0.0811492\n",
      "\tspeed: 0.0374s/iter; left time: 526.2331s\n",
      "\titers: 500, epoch: 5 | loss: 0.0794493\n",
      "\tspeed: 0.0374s/iter; left time: 522.3452s\n",
      "\titers: 600, epoch: 5 | loss: 0.0721271\n",
      "\tspeed: 0.0374s/iter; left time: 518.6967s\n",
      "\titers: 700, epoch: 5 | loss: 0.0799061\n",
      "\tspeed: 0.0374s/iter; left time: 515.0506s\n",
      "\titers: 800, epoch: 5 | loss: 0.0746707\n",
      "\tspeed: 0.0374s/iter; left time: 511.2503s\n",
      "\titers: 900, epoch: 5 | loss: 0.0681253\n",
      "\tspeed: 0.0374s/iter; left time: 507.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.11s\n",
      "Steps: 904 | Train Loss: 0.0766227 Vali Loss: 0.0808420 Test Loss: 0.0898678\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770324\n",
      "\tspeed: 0.1041s/iter; left time: 1401.4511s\n",
      "\titers: 200, epoch: 6 | loss: 0.0681594\n",
      "\tspeed: 0.0374s/iter; left time: 500.0897s\n",
      "\titers: 300, epoch: 6 | loss: 0.0745058\n",
      "\tspeed: 0.0374s/iter; left time: 495.9364s\n",
      "\titers: 400, epoch: 6 | loss: 0.0723388\n",
      "\tspeed: 0.0374s/iter; left time: 492.6837s\n",
      "\titers: 500, epoch: 6 | loss: 0.0695333\n",
      "\tspeed: 0.0374s/iter; left time: 488.2676s\n",
      "\titers: 600, epoch: 6 | loss: 0.0667735\n",
      "\tspeed: 0.0374s/iter; left time: 484.3656s\n",
      "\titers: 700, epoch: 6 | loss: 0.0661017\n",
      "\tspeed: 0.0373s/iter; left time: 480.2829s\n",
      "\titers: 800, epoch: 6 | loss: 0.0712306\n",
      "\tspeed: 0.0374s/iter; left time: 476.6399s\n",
      "\titers: 900, epoch: 6 | loss: 0.0739364\n",
      "\tspeed: 0.0373s/iter; left time: 472.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.11s\n",
      "Steps: 904 | Train Loss: 0.0727300 Vali Loss: 0.0817705 Test Loss: 0.0884986\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0709423\n",
      "\tspeed: 0.1030s/iter; left time: 1293.0075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0686571\n",
      "\tspeed: 0.0374s/iter; left time: 465.8884s\n",
      "\titers: 300, epoch: 7 | loss: 0.0669706\n",
      "\tspeed: 0.0375s/iter; left time: 463.1657s\n",
      "\titers: 400, epoch: 7 | loss: 0.0712829\n",
      "\tspeed: 0.0374s/iter; left time: 458.7725s\n",
      "\titers: 500, epoch: 7 | loss: 0.0615315\n",
      "\tspeed: 0.0374s/iter; left time: 454.5593s\n",
      "\titers: 600, epoch: 7 | loss: 0.0676655\n",
      "\tspeed: 0.0374s/iter; left time: 450.7825s\n",
      "\titers: 700, epoch: 7 | loss: 0.0688025\n",
      "\tspeed: 0.0374s/iter; left time: 446.9564s\n",
      "\titers: 800, epoch: 7 | loss: 0.0667062\n",
      "\tspeed: 0.0374s/iter; left time: 443.3970s\n",
      "\titers: 900, epoch: 7 | loss: 0.0672821\n",
      "\tspeed: 0.0374s/iter; left time: 439.5023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.12s\n",
      "Steps: 904 | Train Loss: 0.0696203 Vali Loss: 0.0803508 Test Loss: 0.0953534\n",
      "Validation loss decreased (0.080383 --> 0.080351).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0706888\n",
      "\tspeed: 0.1074s/iter; left time: 1251.9938s\n",
      "\titers: 200, epoch: 8 | loss: 0.0692664\n",
      "\tspeed: 0.0374s/iter; left time: 431.8152s\n",
      "\titers: 300, epoch: 8 | loss: 0.0645831\n",
      "\tspeed: 0.0374s/iter; left time: 428.3716s\n",
      "\titers: 400, epoch: 8 | loss: 0.0676747\n",
      "\tspeed: 0.0374s/iter; left time: 424.4206s\n",
      "\titers: 500, epoch: 8 | loss: 0.0715972\n",
      "\tspeed: 0.0374s/iter; left time: 420.8507s\n",
      "\titers: 600, epoch: 8 | loss: 0.0672992\n",
      "\tspeed: 0.0374s/iter; left time: 417.0586s\n",
      "\titers: 700, epoch: 8 | loss: 0.0617259\n",
      "\tspeed: 0.0374s/iter; left time: 413.0595s\n",
      "\titers: 800, epoch: 8 | loss: 0.0640620\n",
      "\tspeed: 0.0374s/iter; left time: 409.5799s\n",
      "\titers: 900, epoch: 8 | loss: 0.0672205\n",
      "\tspeed: 0.0374s/iter; left time: 405.5281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:34.12s\n",
      "Steps: 904 | Train Loss: 0.0667161 Vali Loss: 0.0797715 Test Loss: 0.0905222\n",
      "Validation loss decreased (0.080351 --> 0.079772).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604606\n",
      "\tspeed: 0.1218s/iter; left time: 1309.2856s\n",
      "\titers: 200, epoch: 9 | loss: 0.0624663\n",
      "\tspeed: 0.0448s/iter; left time: 476.7199s\n",
      "\titers: 300, epoch: 9 | loss: 0.0632557\n",
      "\tspeed: 0.0446s/iter; left time: 470.8099s\n",
      "\titers: 400, epoch: 9 | loss: 0.0579714\n",
      "\tspeed: 0.0442s/iter; left time: 461.5211s\n",
      "\titers: 500, epoch: 9 | loss: 0.0610232\n",
      "\tspeed: 0.0444s/iter; left time: 459.7205s\n",
      "\titers: 600, epoch: 9 | loss: 0.0625576\n",
      "\tspeed: 0.0444s/iter; left time: 454.6188s\n",
      "\titers: 700, epoch: 9 | loss: 0.0630962\n",
      "\tspeed: 0.0444s/iter; left time: 451.1109s\n",
      "\titers: 800, epoch: 9 | loss: 0.0612415\n",
      "\tspeed: 0.0445s/iter; left time: 447.2198s\n",
      "\titers: 900, epoch: 9 | loss: 0.0598984\n",
      "\tspeed: 0.0441s/iter; left time: 438.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.19s\n",
      "Steps: 904 | Train Loss: 0.0638043 Vali Loss: 0.0816255 Test Loss: 0.0927716\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596202\n",
      "\tspeed: 0.1424s/iter; left time: 1401.9287s\n",
      "\titers: 200, epoch: 10 | loss: 0.0694361\n",
      "\tspeed: 0.0454s/iter; left time: 442.3293s\n",
      "\titers: 300, epoch: 10 | loss: 0.0623093\n",
      "\tspeed: 0.0451s/iter; left time: 434.6918s\n",
      "\titers: 400, epoch: 10 | loss: 0.0647436\n",
      "\tspeed: 0.0459s/iter; left time: 438.0388s\n",
      "\titers: 500, epoch: 10 | loss: 0.0613003\n",
      "\tspeed: 0.0456s/iter; left time: 430.9954s\n",
      "\titers: 600, epoch: 10 | loss: 0.0594590\n",
      "\tspeed: 0.0446s/iter; left time: 416.9695s\n",
      "\titers: 700, epoch: 10 | loss: 0.0621540\n",
      "\tspeed: 0.0443s/iter; left time: 409.3554s\n",
      "\titers: 800, epoch: 10 | loss: 0.0635562\n",
      "\tspeed: 0.0424s/iter; left time: 387.7939s\n",
      "\titers: 900, epoch: 10 | loss: 0.0610592\n",
      "\tspeed: 0.0375s/iter; left time: 338.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.80s\n",
      "Steps: 904 | Train Loss: 0.0614268 Vali Loss: 0.0812600 Test Loss: 0.0951762\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0595022\n",
      "\tspeed: 0.1077s/iter; left time: 963.1240s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564372\n",
      "\tspeed: 0.0442s/iter; left time: 390.7456s\n",
      "\titers: 300, epoch: 11 | loss: 0.0606980\n",
      "\tspeed: 0.0444s/iter; left time: 387.8534s\n",
      "\titers: 400, epoch: 11 | loss: 0.0622247\n",
      "\tspeed: 0.0447s/iter; left time: 385.8388s\n",
      "\titers: 500, epoch: 11 | loss: 0.0554260\n",
      "\tspeed: 0.0446s/iter; left time: 380.9240s\n",
      "\titers: 600, epoch: 11 | loss: 0.0607741\n",
      "\tspeed: 0.0448s/iter; left time: 378.5128s\n",
      "\titers: 700, epoch: 11 | loss: 0.0551810\n",
      "\tspeed: 0.0441s/iter; left time: 367.7089s\n",
      "\titers: 800, epoch: 11 | loss: 0.0571173\n",
      "\tspeed: 0.0448s/iter; left time: 369.0444s\n",
      "\titers: 900, epoch: 11 | loss: 0.0562403\n",
      "\tspeed: 0.0441s/iter; left time: 359.3434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.15s\n",
      "Steps: 904 | Train Loss: 0.0588277 Vali Loss: 0.0813751 Test Loss: 0.0915845\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021865442395210266, rmse:0.14786967635154724, mae:0.09057914465665817, rse:0.5591111779212952\n",
      "Original data scale mse:3245477.75, rmse:1801.52099609375, mae:1160.1573486328125, rse:0.12678039073944092\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2281904\n",
      "\tspeed: 0.0671s/iter; left time: 1204.5901s\n",
      "\titers: 200, epoch: 1 | loss: 0.1992225\n",
      "\tspeed: 0.0459s/iter; left time: 819.1042s\n",
      "\titers: 300, epoch: 1 | loss: 0.2000681\n",
      "\tspeed: 0.0459s/iter; left time: 815.0027s\n",
      "\titers: 400, epoch: 1 | loss: 0.1915065\n",
      "\tspeed: 0.0459s/iter; left time: 810.4065s\n",
      "\titers: 500, epoch: 1 | loss: 0.1893290\n",
      "\tspeed: 0.0460s/iter; left time: 807.5045s\n",
      "\titers: 600, epoch: 1 | loss: 0.1882520\n",
      "\tspeed: 0.0460s/iter; left time: 801.9319s\n",
      "\titers: 700, epoch: 1 | loss: 0.1824189\n",
      "\tspeed: 0.0459s/iter; left time: 795.5914s\n",
      "\titers: 800, epoch: 1 | loss: 0.1842490\n",
      "\tspeed: 0.0458s/iter; left time: 790.3748s\n",
      "\titers: 900, epoch: 1 | loss: 0.1839423\n",
      "\tspeed: 0.0458s/iter; left time: 784.6715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 902 | Train Loss: 0.1966484 Vali Loss: 0.1675418 Test Loss: 0.1840666\n",
      "Validation loss decreased (inf --> 0.167542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1728914\n",
      "\tspeed: 0.1354s/iter; left time: 2306.9248s\n",
      "\titers: 200, epoch: 2 | loss: 0.1513560\n",
      "\tspeed: 0.0577s/iter; left time: 978.1068s\n",
      "\titers: 300, epoch: 2 | loss: 0.1514383\n",
      "\tspeed: 0.0584s/iter; left time: 984.2259s\n",
      "\titers: 400, epoch: 2 | loss: 0.1356430\n",
      "\tspeed: 0.0575s/iter; left time: 962.3348s\n",
      "\titers: 500, epoch: 2 | loss: 0.1222898\n",
      "\tspeed: 0.0573s/iter; left time: 952.9921s\n",
      "\titers: 600, epoch: 2 | loss: 0.1236183\n",
      "\tspeed: 0.0574s/iter; left time: 948.6044s\n",
      "\titers: 700, epoch: 2 | loss: 0.1000682\n",
      "\tspeed: 0.0574s/iter; left time: 943.3424s\n",
      "\titers: 800, epoch: 2 | loss: 0.0983723\n",
      "\tspeed: 0.0548s/iter; left time: 895.1865s\n",
      "\titers: 900, epoch: 2 | loss: 0.0956329\n",
      "\tspeed: 0.0479s/iter; left time: 777.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.97s\n",
      "Steps: 902 | Train Loss: 0.1338052 Vali Loss: 0.0936410 Test Loss: 0.1001951\n",
      "Validation loss decreased (0.167542 --> 0.093641).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0894568\n",
      "\tspeed: 0.1632s/iter; left time: 2633.5827s\n",
      "\titers: 200, epoch: 3 | loss: 0.0964436\n",
      "\tspeed: 0.0461s/iter; left time: 739.8317s\n",
      "\titers: 300, epoch: 3 | loss: 0.0968699\n",
      "\tspeed: 0.0460s/iter; left time: 733.3089s\n",
      "\titers: 400, epoch: 3 | loss: 0.0968377\n",
      "\tspeed: 0.0460s/iter; left time: 728.8099s\n",
      "\titers: 500, epoch: 3 | loss: 0.0986621\n",
      "\tspeed: 0.0460s/iter; left time: 724.2245s\n",
      "\titers: 600, epoch: 3 | loss: 0.0880901\n",
      "\tspeed: 0.0460s/iter; left time: 719.7893s\n",
      "\titers: 700, epoch: 3 | loss: 0.0921286\n",
      "\tspeed: 0.0461s/iter; left time: 715.5380s\n",
      "\titers: 800, epoch: 3 | loss: 0.0909137\n",
      "\tspeed: 0.0460s/iter; left time: 710.6331s\n",
      "\titers: 900, epoch: 3 | loss: 0.0881613\n",
      "\tspeed: 0.0461s/iter; left time: 706.9057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 902 | Train Loss: 0.0928133 Vali Loss: 0.0874168 Test Loss: 0.0971177\n",
      "Validation loss decreased (0.093641 --> 0.087417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0884515\n",
      "\tspeed: 0.1348s/iter; left time: 2054.3546s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873180\n",
      "\tspeed: 0.0461s/iter; left time: 698.3451s\n",
      "\titers: 300, epoch: 4 | loss: 0.0958848\n",
      "\tspeed: 0.0461s/iter; left time: 692.8727s\n",
      "\titers: 400, epoch: 4 | loss: 0.0815475\n",
      "\tspeed: 0.0461s/iter; left time: 688.4973s\n",
      "\titers: 500, epoch: 4 | loss: 0.0817972\n",
      "\tspeed: 0.0460s/iter; left time: 683.0769s\n",
      "\titers: 600, epoch: 4 | loss: 0.0822416\n",
      "\tspeed: 0.0460s/iter; left time: 678.3124s\n",
      "\titers: 700, epoch: 4 | loss: 0.0883716\n",
      "\tspeed: 0.0460s/iter; left time: 673.8478s\n",
      "\titers: 800, epoch: 4 | loss: 0.0885934\n",
      "\tspeed: 0.0461s/iter; left time: 669.5307s\n",
      "\titers: 900, epoch: 4 | loss: 0.0852883\n",
      "\tspeed: 0.0460s/iter; left time: 664.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 902 | Train Loss: 0.0856908 Vali Loss: 0.0851533 Test Loss: 0.0944837\n",
      "Validation loss decreased (0.087417 --> 0.085153).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770141\n",
      "\tspeed: 0.1341s/iter; left time: 1921.8578s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774422\n",
      "\tspeed: 0.0461s/iter; left time: 655.6926s\n",
      "\titers: 300, epoch: 5 | loss: 0.0831590\n",
      "\tspeed: 0.0461s/iter; left time: 651.6508s\n",
      "\titers: 400, epoch: 5 | loss: 0.0864383\n",
      "\tspeed: 0.0461s/iter; left time: 646.9501s\n",
      "\titers: 500, epoch: 5 | loss: 0.0862559\n",
      "\tspeed: 0.0460s/iter; left time: 641.5914s\n",
      "\titers: 600, epoch: 5 | loss: 0.0907257\n",
      "\tspeed: 0.0461s/iter; left time: 637.7954s\n",
      "\titers: 700, epoch: 5 | loss: 0.0860886\n",
      "\tspeed: 0.0461s/iter; left time: 632.6923s\n",
      "\titers: 800, epoch: 5 | loss: 0.0776600\n",
      "\tspeed: 0.0460s/iter; left time: 627.5954s\n",
      "\titers: 900, epoch: 5 | loss: 0.0779930\n",
      "\tspeed: 0.0460s/iter; left time: 623.0666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.88s\n",
      "Steps: 902 | Train Loss: 0.0813616 Vali Loss: 0.0835541 Test Loss: 0.0952780\n",
      "Validation loss decreased (0.085153 --> 0.083554).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0774252\n",
      "\tspeed: 0.1291s/iter; left time: 1734.1689s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760330\n",
      "\tspeed: 0.0460s/iter; left time: 613.6116s\n",
      "\titers: 300, epoch: 6 | loss: 0.0743826\n",
      "\tspeed: 0.0460s/iter; left time: 608.9909s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781829\n",
      "\tspeed: 0.0461s/iter; left time: 605.2299s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743838\n",
      "\tspeed: 0.0461s/iter; left time: 600.2175s\n",
      "\titers: 600, epoch: 6 | loss: 0.0755006\n",
      "\tspeed: 0.0461s/iter; left time: 595.7051s\n",
      "\titers: 700, epoch: 6 | loss: 0.0720696\n",
      "\tspeed: 0.0461s/iter; left time: 591.5615s\n",
      "\titers: 800, epoch: 6 | loss: 0.0752780\n",
      "\tspeed: 0.0460s/iter; left time: 585.9100s\n",
      "\titers: 900, epoch: 6 | loss: 0.0758558\n",
      "\tspeed: 0.0508s/iter; left time: 641.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 902 | Train Loss: 0.0775570 Vali Loss: 0.0862413 Test Loss: 0.0934805\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0791068\n",
      "\tspeed: 0.1478s/iter; left time: 1852.0148s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799156\n",
      "\tspeed: 0.0519s/iter; left time: 645.6346s\n",
      "\titers: 300, epoch: 7 | loss: 0.0701255\n",
      "\tspeed: 0.0526s/iter; left time: 648.8580s\n",
      "\titers: 400, epoch: 7 | loss: 0.0744747\n",
      "\tspeed: 0.0519s/iter; left time: 635.2858s\n",
      "\titers: 500, epoch: 7 | loss: 0.0746246\n",
      "\tspeed: 0.0512s/iter; left time: 621.4745s\n",
      "\titers: 600, epoch: 7 | loss: 0.0709402\n",
      "\tspeed: 0.0524s/iter; left time: 630.7683s\n",
      "\titers: 700, epoch: 7 | loss: 0.0715102\n",
      "\tspeed: 0.0523s/iter; left time: 623.3915s\n",
      "\titers: 800, epoch: 7 | loss: 0.0701919\n",
      "\tspeed: 0.0522s/iter; left time: 617.8237s\n",
      "\titers: 900, epoch: 7 | loss: 0.0687687\n",
      "\tspeed: 0.0524s/iter; left time: 615.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.67s\n",
      "Steps: 902 | Train Loss: 0.0740001 Vali Loss: 0.0844603 Test Loss: 0.0974999\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0698090\n",
      "\tspeed: 0.1580s/iter; left time: 1837.6468s\n",
      "\titers: 200, epoch: 8 | loss: 0.0711349\n",
      "\tspeed: 0.0560s/iter; left time: 645.6299s\n",
      "\titers: 300, epoch: 8 | loss: 0.0770909\n",
      "\tspeed: 0.0541s/iter; left time: 617.6991s\n",
      "\titers: 400, epoch: 8 | loss: 0.0690220\n",
      "\tspeed: 0.0542s/iter; left time: 613.4135s\n",
      "\titers: 500, epoch: 8 | loss: 0.0721073\n",
      "\tspeed: 0.0507s/iter; left time: 568.8757s\n",
      "\titers: 600, epoch: 8 | loss: 0.0638651\n",
      "\tspeed: 0.0518s/iter; left time: 575.9000s\n",
      "\titers: 700, epoch: 8 | loss: 0.0699864\n",
      "\tspeed: 0.0517s/iter; left time: 569.6713s\n",
      "\titers: 800, epoch: 8 | loss: 0.0691056\n",
      "\tspeed: 0.0478s/iter; left time: 522.2471s\n",
      "\titers: 900, epoch: 8 | loss: 0.0662333\n",
      "\tspeed: 0.0477s/iter; left time: 516.6968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.38s\n",
      "Steps: 902 | Train Loss: 0.0706970 Vali Loss: 0.0872057 Test Loss: 0.0972870\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02326315827667713, rmse:0.15252265334129333, mae:0.09529393911361694, rse:0.5771030187606812\n",
      "Original data scale mse:4006630.25, rmse:2001.6568603515625, mae:1286.006103515625, rse:0.140997052192688\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2343519\n",
      "\tspeed: 0.0495s/iter; left time: 887.7423s\n",
      "\titers: 200, epoch: 1 | loss: 0.2075508\n",
      "\tspeed: 0.0461s/iter; left time: 821.9994s\n",
      "\titers: 300, epoch: 1 | loss: 0.2022594\n",
      "\tspeed: 0.0461s/iter; left time: 817.4303s\n",
      "\titers: 400, epoch: 1 | loss: 0.1895085\n",
      "\tspeed: 0.0461s/iter; left time: 812.6757s\n",
      "\titers: 500, epoch: 1 | loss: 0.1930860\n",
      "\tspeed: 0.0462s/iter; left time: 809.6802s\n",
      "\titers: 600, epoch: 1 | loss: 0.1765502\n",
      "\tspeed: 0.0463s/iter; left time: 806.9295s\n",
      "\titers: 700, epoch: 1 | loss: 0.1821844\n",
      "\tspeed: 0.0541s/iter; left time: 937.3161s\n",
      "\titers: 800, epoch: 1 | loss: 0.1759556\n",
      "\tspeed: 0.0596s/iter; left time: 1028.1656s\n",
      "\titers: 900, epoch: 1 | loss: 0.1789742\n",
      "\tspeed: 0.0616s/iter; left time: 1056.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1992858 Vali Loss: 0.1685198 Test Loss: 0.1855442\n",
      "Validation loss decreased (inf --> 0.168520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1759926\n",
      "\tspeed: 0.1877s/iter; left time: 3198.4109s\n",
      "\titers: 200, epoch: 2 | loss: 0.1571959\n",
      "\tspeed: 0.0625s/iter; left time: 1058.4876s\n",
      "\titers: 300, epoch: 2 | loss: 0.1490268\n",
      "\tspeed: 0.0605s/iter; left time: 1018.1482s\n",
      "\titers: 400, epoch: 2 | loss: 0.1395864\n",
      "\tspeed: 0.0583s/iter; left time: 975.8328s\n",
      "\titers: 500, epoch: 2 | loss: 0.1293912\n",
      "\tspeed: 0.0584s/iter; left time: 972.3060s\n",
      "\titers: 600, epoch: 2 | loss: 0.1238206\n",
      "\tspeed: 0.0579s/iter; left time: 957.1417s\n",
      "\titers: 700, epoch: 2 | loss: 0.1050046\n",
      "\tspeed: 0.0576s/iter; left time: 947.2869s\n",
      "\titers: 800, epoch: 2 | loss: 0.1109328\n",
      "\tspeed: 0.0584s/iter; left time: 953.6569s\n",
      "\titers: 900, epoch: 2 | loss: 0.1060509\n",
      "\tspeed: 0.0581s/iter; left time: 943.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.44s\n",
      "Steps: 902 | Train Loss: 0.1358761 Vali Loss: 0.0972542 Test Loss: 0.1010444\n",
      "Validation loss decreased (0.168520 --> 0.097254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1004555\n",
      "\tspeed: 0.1796s/iter; left time: 2898.2118s\n",
      "\titers: 200, epoch: 3 | loss: 0.0941001\n",
      "\tspeed: 0.0578s/iter; left time: 927.4441s\n",
      "\titers: 300, epoch: 3 | loss: 0.0945768\n",
      "\tspeed: 0.0578s/iter; left time: 921.2178s\n",
      "\titers: 400, epoch: 3 | loss: 0.0956849\n",
      "\tspeed: 0.0570s/iter; left time: 902.8831s\n",
      "\titers: 500, epoch: 3 | loss: 0.0924007\n",
      "\tspeed: 0.0580s/iter; left time: 913.5053s\n",
      "\titers: 600, epoch: 3 | loss: 0.0887764\n",
      "\tspeed: 0.0584s/iter; left time: 912.7202s\n",
      "\titers: 700, epoch: 3 | loss: 0.0893886\n",
      "\tspeed: 0.0593s/iter; left time: 922.0174s\n",
      "\titers: 800, epoch: 3 | loss: 0.0951537\n",
      "\tspeed: 0.0577s/iter; left time: 890.8259s\n",
      "\titers: 900, epoch: 3 | loss: 0.0871527\n",
      "\tspeed: 0.0561s/iter; left time: 861.0121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.15s\n",
      "Steps: 902 | Train Loss: 0.0930714 Vali Loss: 0.0866642 Test Loss: 0.0986792\n",
      "Validation loss decreased (0.097254 --> 0.086664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0907243\n",
      "\tspeed: 0.1796s/iter; left time: 2736.9320s\n",
      "\titers: 200, epoch: 4 | loss: 0.0852676\n",
      "\tspeed: 0.0583s/iter; left time: 882.2251s\n",
      "\titers: 300, epoch: 4 | loss: 0.0898049\n",
      "\tspeed: 0.0599s/iter; left time: 900.8759s\n",
      "\titers: 400, epoch: 4 | loss: 0.0914506\n",
      "\tspeed: 0.0576s/iter; left time: 859.6085s\n",
      "\titers: 500, epoch: 4 | loss: 0.0853406\n",
      "\tspeed: 0.0577s/iter; left time: 856.4895s\n",
      "\titers: 600, epoch: 4 | loss: 0.0843446\n",
      "\tspeed: 0.0577s/iter; left time: 849.7614s\n",
      "\titers: 700, epoch: 4 | loss: 0.0851249\n",
      "\tspeed: 0.0575s/iter; left time: 841.8692s\n",
      "\titers: 800, epoch: 4 | loss: 0.0838873\n",
      "\tspeed: 0.0580s/iter; left time: 843.2831s\n",
      "\titers: 900, epoch: 4 | loss: 0.0858384\n",
      "\tspeed: 0.0576s/iter; left time: 832.1616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.04s\n",
      "Steps: 902 | Train Loss: 0.0860240 Vali Loss: 0.0868184 Test Loss: 0.0933650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0861090\n",
      "\tspeed: 0.1756s/iter; left time: 2516.4077s\n",
      "\titers: 200, epoch: 5 | loss: 0.0805828\n",
      "\tspeed: 0.0587s/iter; left time: 836.0125s\n",
      "\titers: 300, epoch: 5 | loss: 0.0825851\n",
      "\tspeed: 0.0579s/iter; left time: 818.8412s\n",
      "\titers: 400, epoch: 5 | loss: 0.0854736\n",
      "\tspeed: 0.0582s/iter; left time: 816.7793s\n",
      "\titers: 500, epoch: 5 | loss: 0.0854514\n",
      "\tspeed: 0.0600s/iter; left time: 835.3576s\n",
      "\titers: 600, epoch: 5 | loss: 0.0860135\n",
      "\tspeed: 0.0602s/iter; left time: 832.8784s\n",
      "\titers: 700, epoch: 5 | loss: 0.0865304\n",
      "\tspeed: 0.0554s/iter; left time: 760.8074s\n",
      "\titers: 800, epoch: 5 | loss: 0.0771477\n",
      "\tspeed: 0.0575s/iter; left time: 783.7274s\n",
      "\titers: 900, epoch: 5 | loss: 0.0729048\n",
      "\tspeed: 0.0552s/iter; left time: 746.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:52.92s\n",
      "Steps: 902 | Train Loss: 0.0813972 Vali Loss: 0.0841324 Test Loss: 0.0955062\n",
      "Validation loss decreased (0.086664 --> 0.084132).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0817804\n",
      "\tspeed: 0.1416s/iter; left time: 1901.7178s\n",
      "\titers: 200, epoch: 6 | loss: 0.0730293\n",
      "\tspeed: 0.0493s/iter; left time: 657.3016s\n",
      "\titers: 300, epoch: 6 | loss: 0.0804153\n",
      "\tspeed: 0.0492s/iter; left time: 651.1916s\n",
      "\titers: 400, epoch: 6 | loss: 0.0882466\n",
      "\tspeed: 0.0494s/iter; left time: 648.0166s\n",
      "\titers: 500, epoch: 6 | loss: 0.0711463\n",
      "\tspeed: 0.0489s/iter; left time: 636.8227s\n",
      "\titers: 600, epoch: 6 | loss: 0.0788568\n",
      "\tspeed: 0.0488s/iter; left time: 630.9166s\n",
      "\titers: 700, epoch: 6 | loss: 0.0774529\n",
      "\tspeed: 0.0487s/iter; left time: 625.1688s\n",
      "\titers: 800, epoch: 6 | loss: 0.0723999\n",
      "\tspeed: 0.0486s/iter; left time: 618.2457s\n",
      "\titers: 900, epoch: 6 | loss: 0.0733578\n",
      "\tspeed: 0.0486s/iter; left time: 613.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.60s\n",
      "Steps: 902 | Train Loss: 0.0775020 Vali Loss: 0.0840176 Test Loss: 0.0961253\n",
      "Validation loss decreased (0.084132 --> 0.084018).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797464\n",
      "\tspeed: 0.1396s/iter; left time: 1748.5147s\n",
      "\titers: 200, epoch: 7 | loss: 0.0724353\n",
      "\tspeed: 0.0481s/iter; left time: 597.6872s\n",
      "\titers: 300, epoch: 7 | loss: 0.0776749\n",
      "\tspeed: 0.0479s/iter; left time: 590.0580s\n",
      "\titers: 400, epoch: 7 | loss: 0.0766219\n",
      "\tspeed: 0.0478s/iter; left time: 585.1542s\n",
      "\titers: 500, epoch: 7 | loss: 0.0755988\n",
      "\tspeed: 0.0477s/iter; left time: 578.3571s\n",
      "\titers: 600, epoch: 7 | loss: 0.0718343\n",
      "\tspeed: 0.0478s/iter; left time: 574.5151s\n",
      "\titers: 700, epoch: 7 | loss: 0.0719676\n",
      "\tspeed: 0.0480s/iter; left time: 572.5700s\n",
      "\titers: 800, epoch: 7 | loss: 0.0703958\n",
      "\tspeed: 0.0480s/iter; left time: 567.6979s\n",
      "\titers: 900, epoch: 7 | loss: 0.0659114\n",
      "\tspeed: 0.0480s/iter; left time: 562.9279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.67s\n",
      "Steps: 902 | Train Loss: 0.0737302 Vali Loss: 0.0854848 Test Loss: 0.0983084\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0692709\n",
      "\tspeed: 0.1333s/iter; left time: 1549.3988s\n",
      "\titers: 200, epoch: 8 | loss: 0.0652691\n",
      "\tspeed: 0.0477s/iter; left time: 549.4977s\n",
      "\titers: 300, epoch: 8 | loss: 0.0695933\n",
      "\tspeed: 0.0481s/iter; left time: 549.2643s\n",
      "\titers: 400, epoch: 8 | loss: 0.0706969\n",
      "\tspeed: 0.0483s/iter; left time: 547.2846s\n",
      "\titers: 500, epoch: 8 | loss: 0.0769796\n",
      "\tspeed: 0.0484s/iter; left time: 542.9691s\n",
      "\titers: 600, epoch: 8 | loss: 0.0672631\n",
      "\tspeed: 0.0483s/iter; left time: 536.8952s\n",
      "\titers: 700, epoch: 8 | loss: 0.0725319\n",
      "\tspeed: 0.0473s/iter; left time: 522.0616s\n",
      "\titers: 800, epoch: 8 | loss: 0.0693540\n",
      "\tspeed: 0.0473s/iter; left time: 516.9950s\n",
      "\titers: 900, epoch: 8 | loss: 0.0708787\n",
      "\tspeed: 0.0470s/iter; left time: 508.4450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.49s\n",
      "Steps: 902 | Train Loss: 0.0704037 Vali Loss: 0.0863992 Test Loss: 0.0950462\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0741181\n",
      "\tspeed: 0.1284s/iter; left time: 1377.5868s\n",
      "\titers: 200, epoch: 9 | loss: 0.0659965\n",
      "\tspeed: 0.0468s/iter; left time: 497.3995s\n",
      "\titers: 300, epoch: 9 | loss: 0.0706813\n",
      "\tspeed: 0.0469s/iter; left time: 493.5698s\n",
      "\titers: 400, epoch: 9 | loss: 0.0757021\n",
      "\tspeed: 0.0469s/iter; left time: 489.0555s\n",
      "\titers: 500, epoch: 9 | loss: 0.0674424\n",
      "\tspeed: 0.0469s/iter; left time: 484.4505s\n",
      "\titers: 600, epoch: 9 | loss: 0.0643915\n",
      "\tspeed: 0.0470s/iter; left time: 480.2579s\n",
      "\titers: 700, epoch: 9 | loss: 0.0640328\n",
      "\tspeed: 0.0470s/iter; left time: 475.6178s\n",
      "\titers: 800, epoch: 9 | loss: 0.0669108\n",
      "\tspeed: 0.0469s/iter; left time: 470.0647s\n",
      "\titers: 900, epoch: 9 | loss: 0.0650688\n",
      "\tspeed: 0.0469s/iter; left time: 465.8646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.66s\n",
      "Steps: 902 | Train Loss: 0.0670223 Vali Loss: 0.0882982 Test Loss: 0.0950962\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02324366569519043, rmse:0.15245872735977173, mae:0.09611774235963821, rse:0.5768612027168274\n",
      "Original data scale mse:4571669.0, rmse:2138.146240234375, mae:1343.22216796875, rse:0.15061138570308685\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.3843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.3915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.5199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.5138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.5410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.3954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.3906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.5591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.5771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.5769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0103  0.1017  0.0627  0.3843\n",
       "              2         24        0.0107  0.1036  0.0647  0.3915\n",
       "              1         96        0.0189  0.1375  0.0891  0.5199\n",
       "              2         96        0.0185  0.1359  0.0884  0.5138\n",
       "              1         168       0.0205  0.1430  0.0950  0.5412\n",
       "              2         168       0.0204  0.1430  0.0952  0.5410\n",
       "MAE           1         24        0.0109  0.1046  0.0631  0.3954\n",
       "              2         24        0.0107  0.1034  0.0609  0.3906\n",
       "              1         96        0.0196  0.1402  0.0873  0.5300\n",
       "              2         96        0.0219  0.1479  0.0906  0.5591\n",
       "              1         168       0.0233  0.1525  0.0953  0.5771\n",
       "              2         168       0.0232  0.1525  0.0961  0.5769"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1547444.00</td>\n",
       "      <td>1243.9630</td>\n",
       "      <td>822.1915</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1827726.75</td>\n",
       "      <td>1351.9344</td>\n",
       "      <td>885.4187</td>\n",
       "      <td>0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3707538.75</td>\n",
       "      <td>1925.4971</td>\n",
       "      <td>1254.8304</td>\n",
       "      <td>0.1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3334153.00</td>\n",
       "      <td>1825.9663</td>\n",
       "      <td>1212.4634</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4258305.50</td>\n",
       "      <td>2063.5662</td>\n",
       "      <td>1351.6522</td>\n",
       "      <td>0.1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4184471.50</td>\n",
       "      <td>2045.5980</td>\n",
       "      <td>1344.2694</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1645302.50</td>\n",
       "      <td>1282.6935</td>\n",
       "      <td>826.3154</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1408336.25</td>\n",
       "      <td>1186.7334</td>\n",
       "      <td>765.2639</td>\n",
       "      <td>0.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3098940.50</td>\n",
       "      <td>1760.3807</td>\n",
       "      <td>1143.3651</td>\n",
       "      <td>0.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3245477.75</td>\n",
       "      <td>1801.5210</td>\n",
       "      <td>1160.1573</td>\n",
       "      <td>0.1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4006630.25</td>\n",
       "      <td>2001.6569</td>\n",
       "      <td>1286.0061</td>\n",
       "      <td>0.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4571669.00</td>\n",
       "      <td>2138.1462</td>\n",
       "      <td>1343.2222</td>\n",
       "      <td>0.1506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        1547444.00  1243.9630   822.1915  0.0874\n",
       "              2         24        1827726.75  1351.9344   885.4187  0.0950\n",
       "              1         96        3707538.75  1925.4971  1254.8304  0.1355\n",
       "              2         96        3334153.00  1825.9663  1212.4634  0.1285\n",
       "              1         168       4258305.50  2063.5662  1351.6522  0.1454\n",
       "              2         168       4184471.50  2045.5980  1344.2694  0.1441\n",
       "MAE           1         24        1645302.50  1282.6935   826.3154  0.0901\n",
       "              2         24        1408336.25  1186.7334   765.2639  0.0834\n",
       "              1         96        3098940.50  1760.3807  1143.3651  0.1239\n",
       "              2         96        3245477.75  1801.5210  1160.1573  0.1268\n",
       "              1         168       4006630.25  2001.6569  1286.0061  0.1410\n",
       "              2         168       4571669.00  2138.1462  1343.2222  0.1506"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.3930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.3879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.5446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.5770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.5411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0108  0.1040  0.0620  0.3930\n",
       "         MSE            0.0105  0.1026  0.0637  0.3879\n",
       "96       MAE            0.0208  0.1440  0.0890  0.5446\n",
       "         MSE            0.0187  0.1367  0.0888  0.5169\n",
       "168      MAE            0.0233  0.1525  0.0957  0.5770\n",
       "         MSE            0.0205  0.1430  0.0951  0.5411"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_IT.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_IT.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1526819.375</td>\n",
       "      <td>1234.7134</td>\n",
       "      <td>795.7897</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1687585.375</td>\n",
       "      <td>1297.9487</td>\n",
       "      <td>853.8051</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3172209.125</td>\n",
       "      <td>1780.9509</td>\n",
       "      <td>1151.7612</td>\n",
       "      <td>0.1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3520845.875</td>\n",
       "      <td>1875.7317</td>\n",
       "      <td>1233.6469</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4289149.625</td>\n",
       "      <td>2069.9016</td>\n",
       "      <td>1314.6141</td>\n",
       "      <td>0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4221388.500</td>\n",
       "      <td>2054.5821</td>\n",
       "      <td>1347.9608</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                           \n",
       "24       MAE            1526819.375  1234.7134   795.7897  0.0868\n",
       "         MSE            1687585.375  1297.9487   853.8051  0.0912\n",
       "96       MAE            3172209.125  1780.9509  1151.7612  0.1253\n",
       "         MSE            3520845.875  1875.7317  1233.6469  0.1320\n",
       "168      MAE            4289149.625  2069.9016  1314.6141  0.1458\n",
       "         MSE            4221388.500  2054.5821  1347.9608  0.1447"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0372323\n",
      "\tspeed: 0.0493s/iter; left time: 876.0315s\n",
      "\titers: 200, epoch: 1 | loss: 0.0276121\n",
      "\tspeed: 0.0317s/iter; left time: 559.5960s\n",
      "\titers: 300, epoch: 1 | loss: 0.0245925\n",
      "\tspeed: 0.0317s/iter; left time: 556.3058s\n",
      "\titers: 400, epoch: 1 | loss: 0.0215595\n",
      "\tspeed: 0.0317s/iter; left time: 553.7301s\n",
      "\titers: 500, epoch: 1 | loss: 0.0272849\n",
      "\tspeed: 0.0318s/iter; left time: 551.9020s\n",
      "\titers: 600, epoch: 1 | loss: 0.0205960\n",
      "\tspeed: 0.0318s/iter; left time: 548.7844s\n",
      "\titers: 700, epoch: 1 | loss: 0.0163748\n",
      "\tspeed: 0.0319s/iter; left time: 546.9621s\n",
      "\titers: 800, epoch: 1 | loss: 0.0154704\n",
      "\tspeed: 0.0318s/iter; left time: 543.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 893 | Train Loss: 0.0263476 Vali Loss: 0.0163548 Test Loss: 0.0173455\n",
      "Validation loss decreased (inf --> 0.016355).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0123138\n",
      "\tspeed: 0.1168s/iter; left time: 1969.3740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0103427\n",
      "\tspeed: 0.0317s/iter; left time: 531.9735s\n",
      "\titers: 300, epoch: 2 | loss: 0.0163344\n",
      "\tspeed: 0.0317s/iter; left time: 529.0671s\n",
      "\titers: 400, epoch: 2 | loss: 0.0124028\n",
      "\tspeed: 0.0317s/iter; left time: 525.5516s\n",
      "\titers: 500, epoch: 2 | loss: 0.0095551\n",
      "\tspeed: 0.0318s/iter; left time: 523.4546s\n",
      "\titers: 600, epoch: 2 | loss: 0.0066554\n",
      "\tspeed: 0.0319s/iter; left time: 522.9389s\n",
      "\titers: 700, epoch: 2 | loss: 0.0103693\n",
      "\tspeed: 0.0320s/iter; left time: 520.0860s\n",
      "\titers: 800, epoch: 2 | loss: 0.0089413\n",
      "\tspeed: 0.0319s/iter; left time: 516.5414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.66s\n",
      "Steps: 893 | Train Loss: 0.0110632 Vali Loss: 0.0098345 Test Loss: 0.0111422\n",
      "Validation loss decreased (0.016355 --> 0.009835).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0076160\n",
      "\tspeed: 0.1164s/iter; left time: 1859.9829s\n",
      "\titers: 200, epoch: 3 | loss: 0.0100746\n",
      "\tspeed: 0.0318s/iter; left time: 504.5579s\n",
      "\titers: 300, epoch: 3 | loss: 0.0081010\n",
      "\tspeed: 0.0318s/iter; left time: 501.6795s\n",
      "\titers: 400, epoch: 3 | loss: 0.0090030\n",
      "\tspeed: 0.0318s/iter; left time: 498.1336s\n",
      "\titers: 500, epoch: 3 | loss: 0.0065643\n",
      "\tspeed: 0.0318s/iter; left time: 495.7112s\n",
      "\titers: 600, epoch: 3 | loss: 0.0121474\n",
      "\tspeed: 0.0319s/iter; left time: 493.0633s\n",
      "\titers: 700, epoch: 3 | loss: 0.0070742\n",
      "\tspeed: 0.0319s/iter; left time: 489.9249s\n",
      "\titers: 800, epoch: 3 | loss: 0.0116977\n",
      "\tspeed: 0.0318s/iter; left time: 486.4784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.67s\n",
      "Steps: 893 | Train Loss: 0.0095075 Vali Loss: 0.0093776 Test Loss: 0.0103695\n",
      "Validation loss decreased (0.009835 --> 0.009378).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0091207\n",
      "\tspeed: 0.1168s/iter; left time: 1761.0669s\n",
      "\titers: 200, epoch: 4 | loss: 0.0075570\n",
      "\tspeed: 0.0318s/iter; left time: 476.9515s\n",
      "\titers: 300, epoch: 4 | loss: 0.0093856\n",
      "\tspeed: 0.0318s/iter; left time: 473.2710s\n",
      "\titers: 400, epoch: 4 | loss: 0.0074925\n",
      "\tspeed: 0.0318s/iter; left time: 470.6126s\n",
      "\titers: 500, epoch: 4 | loss: 0.0092174\n",
      "\tspeed: 0.0318s/iter; left time: 467.0648s\n",
      "\titers: 600, epoch: 4 | loss: 0.0075096\n",
      "\tspeed: 0.0318s/iter; left time: 463.6253s\n",
      "\titers: 700, epoch: 4 | loss: 0.0108075\n",
      "\tspeed: 0.0318s/iter; left time: 460.7047s\n",
      "\titers: 800, epoch: 4 | loss: 0.0103080\n",
      "\tspeed: 0.0318s/iter; left time: 458.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.66s\n",
      "Steps: 893 | Train Loss: 0.0091094 Vali Loss: 0.0093636 Test Loss: 0.0103023\n",
      "Validation loss decreased (0.009378 --> 0.009364).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0109814\n",
      "\tspeed: 0.1171s/iter; left time: 1661.1599s\n",
      "\titers: 200, epoch: 5 | loss: 0.0076589\n",
      "\tspeed: 0.0318s/iter; left time: 448.5311s\n",
      "\titers: 300, epoch: 5 | loss: 0.0120579\n",
      "\tspeed: 0.0318s/iter; left time: 444.9931s\n",
      "\titers: 400, epoch: 5 | loss: 0.0125474\n",
      "\tspeed: 0.0318s/iter; left time: 441.6687s\n",
      "\titers: 500, epoch: 5 | loss: 0.0078259\n",
      "\tspeed: 0.0318s/iter; left time: 438.9090s\n",
      "\titers: 600, epoch: 5 | loss: 0.0070448\n",
      "\tspeed: 0.0318s/iter; left time: 435.8705s\n",
      "\titers: 700, epoch: 5 | loss: 0.0076558\n",
      "\tspeed: 0.0318s/iter; left time: 432.7922s\n",
      "\titers: 800, epoch: 5 | loss: 0.0061779\n",
      "\tspeed: 0.0318s/iter; left time: 429.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.69s\n",
      "Steps: 893 | Train Loss: 0.0088568 Vali Loss: 0.0091504 Test Loss: 0.0101779\n",
      "Validation loss decreased (0.009364 --> 0.009150).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0094413\n",
      "\tspeed: 0.1173s/iter; left time: 1559.2426s\n",
      "\titers: 200, epoch: 6 | loss: 0.0089938\n",
      "\tspeed: 0.0318s/iter; left time: 419.7941s\n",
      "\titers: 300, epoch: 6 | loss: 0.0076177\n",
      "\tspeed: 0.0318s/iter; left time: 416.6661s\n",
      "\titers: 400, epoch: 6 | loss: 0.0085283\n",
      "\tspeed: 0.0318s/iter; left time: 413.5489s\n",
      "\titers: 500, epoch: 6 | loss: 0.0083953\n",
      "\tspeed: 0.0318s/iter; left time: 410.6899s\n",
      "\titers: 600, epoch: 6 | loss: 0.0101926\n",
      "\tspeed: 0.0318s/iter; left time: 407.2297s\n",
      "\titers: 700, epoch: 6 | loss: 0.0050567\n",
      "\tspeed: 0.0318s/iter; left time: 403.8456s\n",
      "\titers: 800, epoch: 6 | loss: 0.0075690\n",
      "\tspeed: 0.0318s/iter; left time: 400.9071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.66s\n",
      "Steps: 893 | Train Loss: 0.0086494 Vali Loss: 0.0090570 Test Loss: 0.0100679\n",
      "Validation loss decreased (0.009150 --> 0.009057).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0092986\n",
      "\tspeed: 0.1163s/iter; left time: 1442.3863s\n",
      "\titers: 200, epoch: 7 | loss: 0.0062557\n",
      "\tspeed: 0.0316s/iter; left time: 388.6965s\n",
      "\titers: 300, epoch: 7 | loss: 0.0069371\n",
      "\tspeed: 0.0316s/iter; left time: 385.8894s\n",
      "\titers: 400, epoch: 7 | loss: 0.0093821\n",
      "\tspeed: 0.0317s/iter; left time: 383.0924s\n",
      "\titers: 500, epoch: 7 | loss: 0.0077968\n",
      "\tspeed: 0.0316s/iter; left time: 379.7429s\n",
      "\titers: 600, epoch: 7 | loss: 0.0063814\n",
      "\tspeed: 0.0318s/iter; left time: 377.9846s\n",
      "\titers: 700, epoch: 7 | loss: 0.0063376\n",
      "\tspeed: 0.0318s/iter; left time: 375.0773s\n",
      "\titers: 800, epoch: 7 | loss: 0.0067031\n",
      "\tspeed: 0.0317s/iter; left time: 371.2927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 893 | Train Loss: 0.0084884 Vali Loss: 0.0090593 Test Loss: 0.0102432\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0098352\n",
      "\tspeed: 0.1144s/iter; left time: 1317.2388s\n",
      "\titers: 200, epoch: 8 | loss: 0.0086398\n",
      "\tspeed: 0.0317s/iter; left time: 361.1927s\n",
      "\titers: 300, epoch: 8 | loss: 0.0096381\n",
      "\tspeed: 0.0316s/iter; left time: 357.6723s\n",
      "\titers: 400, epoch: 8 | loss: 0.0075190\n",
      "\tspeed: 0.0317s/iter; left time: 354.8427s\n",
      "\titers: 500, epoch: 8 | loss: 0.0087557\n",
      "\tspeed: 0.0316s/iter; left time: 351.3598s\n",
      "\titers: 600, epoch: 8 | loss: 0.0084739\n",
      "\tspeed: 0.0316s/iter; left time: 348.4344s\n",
      "\titers: 700, epoch: 8 | loss: 0.0084637\n",
      "\tspeed: 0.0317s/iter; left time: 345.3610s\n",
      "\titers: 800, epoch: 8 | loss: 0.0064656\n",
      "\tspeed: 0.0316s/iter; left time: 341.9555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.50s\n",
      "Steps: 893 | Train Loss: 0.0083493 Vali Loss: 0.0089087 Test Loss: 0.0101798\n",
      "Validation loss decreased (0.009057 --> 0.008909).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0099023\n",
      "\tspeed: 0.1168s/iter; left time: 1239.6007s\n",
      "\titers: 200, epoch: 9 | loss: 0.0097409\n",
      "\tspeed: 0.0316s/iter; left time: 332.4867s\n",
      "\titers: 300, epoch: 9 | loss: 0.0070628\n",
      "\tspeed: 0.0316s/iter; left time: 329.4899s\n",
      "\titers: 400, epoch: 9 | loss: 0.0085115\n",
      "\tspeed: 0.0317s/iter; left time: 326.5596s\n",
      "\titers: 500, epoch: 9 | loss: 0.0072785\n",
      "\tspeed: 0.0316s/iter; left time: 323.3321s\n",
      "\titers: 600, epoch: 9 | loss: 0.0059115\n",
      "\tspeed: 0.0316s/iter; left time: 320.0696s\n",
      "\titers: 700, epoch: 9 | loss: 0.0076878\n",
      "\tspeed: 0.0316s/iter; left time: 316.8973s\n",
      "\titers: 800, epoch: 9 | loss: 0.0066980\n",
      "\tspeed: 0.0316s/iter; left time: 313.6226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.50s\n",
      "Steps: 893 | Train Loss: 0.0082452 Vali Loss: 0.0090974 Test Loss: 0.0103217\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0077928\n",
      "\tspeed: 0.1126s/iter; left time: 1095.1404s\n",
      "\titers: 200, epoch: 10 | loss: 0.0092154\n",
      "\tspeed: 0.0315s/iter; left time: 303.5645s\n",
      "\titers: 300, epoch: 10 | loss: 0.0057014\n",
      "\tspeed: 0.0316s/iter; left time: 300.7646s\n",
      "\titers: 400, epoch: 10 | loss: 0.0084446\n",
      "\tspeed: 0.0316s/iter; left time: 298.0710s\n",
      "\titers: 500, epoch: 10 | loss: 0.0058234\n",
      "\tspeed: 0.0316s/iter; left time: 294.9795s\n",
      "\titers: 600, epoch: 10 | loss: 0.0066992\n",
      "\tspeed: 0.0316s/iter; left time: 291.8054s\n",
      "\titers: 700, epoch: 10 | loss: 0.0074285\n",
      "\tspeed: 0.0317s/iter; left time: 288.7850s\n",
      "\titers: 800, epoch: 10 | loss: 0.0093585\n",
      "\tspeed: 0.0316s/iter; left time: 285.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.0081554 Vali Loss: 0.0090338 Test Loss: 0.0101985\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0077022\n",
      "\tspeed: 0.1122s/iter; left time: 991.1063s\n",
      "\titers: 200, epoch: 11 | loss: 0.0086446\n",
      "\tspeed: 0.0316s/iter; left time: 275.8384s\n",
      "\titers: 300, epoch: 11 | loss: 0.0070871\n",
      "\tspeed: 0.0316s/iter; left time: 272.5693s\n",
      "\titers: 400, epoch: 11 | loss: 0.0075254\n",
      "\tspeed: 0.0316s/iter; left time: 269.4887s\n",
      "\titers: 500, epoch: 11 | loss: 0.0068657\n",
      "\tspeed: 0.0316s/iter; left time: 266.2991s\n",
      "\titers: 600, epoch: 11 | loss: 0.0058351\n",
      "\tspeed: 0.0316s/iter; left time: 263.2107s\n",
      "\titers: 700, epoch: 11 | loss: 0.0081296\n",
      "\tspeed: 0.0316s/iter; left time: 259.8827s\n",
      "\titers: 800, epoch: 11 | loss: 0.0089255\n",
      "\tspeed: 0.0316s/iter; left time: 256.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 893 | Train Loss: 0.0080347 Vali Loss: 0.0090193 Test Loss: 0.0102379\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010179785080254078, rmse:0.10089492052793503, mae:0.0600285604596138, rse:0.38128894567489624\n",
      "Original data scale mse:1345279.75, rmse:1159.8619384765625, mae:744.5025634765625, rse:0.08150623738765717\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0386883\n",
      "\tspeed: 0.0339s/iter; left time: 601.9847s\n",
      "\titers: 200, epoch: 1 | loss: 0.0309294\n",
      "\tspeed: 0.0316s/iter; left time: 558.5656s\n",
      "\titers: 300, epoch: 1 | loss: 0.0262026\n",
      "\tspeed: 0.0317s/iter; left time: 555.9047s\n",
      "\titers: 400, epoch: 1 | loss: 0.0247535\n",
      "\tspeed: 0.0316s/iter; left time: 552.4323s\n",
      "\titers: 500, epoch: 1 | loss: 0.0205809\n",
      "\tspeed: 0.0317s/iter; left time: 549.7284s\n",
      "\titers: 600, epoch: 1 | loss: 0.0173654\n",
      "\tspeed: 0.0316s/iter; left time: 545.9487s\n",
      "\titers: 700, epoch: 1 | loss: 0.0164740\n",
      "\tspeed: 0.0317s/iter; left time: 543.2975s\n",
      "\titers: 800, epoch: 1 | loss: 0.0220026\n",
      "\tspeed: 0.0316s/iter; left time: 539.5958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0261487 Vali Loss: 0.0165403 Test Loss: 0.0173491\n",
      "Validation loss decreased (inf --> 0.016540).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0116301\n",
      "\tspeed: 0.1152s/iter; left time: 1944.0028s\n",
      "\titers: 200, epoch: 2 | loss: 0.0110677\n",
      "\tspeed: 0.0315s/iter; left time: 528.8841s\n",
      "\titers: 300, epoch: 2 | loss: 0.0086181\n",
      "\tspeed: 0.0316s/iter; left time: 525.9928s\n",
      "\titers: 400, epoch: 2 | loss: 0.0112028\n",
      "\tspeed: 0.0315s/iter; left time: 522.6478s\n",
      "\titers: 500, epoch: 2 | loss: 0.0135736\n",
      "\tspeed: 0.0315s/iter; left time: 519.5456s\n",
      "\titers: 600, epoch: 2 | loss: 0.0094897\n",
      "\tspeed: 0.0316s/iter; left time: 516.7310s\n",
      "\titers: 700, epoch: 2 | loss: 0.0086866\n",
      "\tspeed: 0.0316s/iter; left time: 513.7380s\n",
      "\titers: 800, epoch: 2 | loss: 0.0117472\n",
      "\tspeed: 0.0316s/iter; left time: 510.7497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.40s\n",
      "Steps: 893 | Train Loss: 0.0110358 Vali Loss: 0.0097095 Test Loss: 0.0107685\n",
      "Validation loss decreased (0.016540 --> 0.009710).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0126462\n",
      "\tspeed: 0.1156s/iter; left time: 1845.9566s\n",
      "\titers: 200, epoch: 3 | loss: 0.0118494\n",
      "\tspeed: 0.0316s/iter; left time: 501.1232s\n",
      "\titers: 300, epoch: 3 | loss: 0.0108408\n",
      "\tspeed: 0.0315s/iter; left time: 497.5542s\n",
      "\titers: 400, epoch: 3 | loss: 0.0098454\n",
      "\tspeed: 0.0315s/iter; left time: 494.3349s\n",
      "\titers: 500, epoch: 3 | loss: 0.0094537\n",
      "\tspeed: 0.0315s/iter; left time: 491.0020s\n",
      "\titers: 600, epoch: 3 | loss: 0.0104082\n",
      "\tspeed: 0.0316s/iter; left time: 488.2405s\n",
      "\titers: 700, epoch: 3 | loss: 0.0128298\n",
      "\tspeed: 0.0315s/iter; left time: 485.0318s\n",
      "\titers: 800, epoch: 3 | loss: 0.0079443\n",
      "\tspeed: 0.0316s/iter; left time: 482.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.44s\n",
      "Steps: 893 | Train Loss: 0.0094804 Vali Loss: 0.0095213 Test Loss: 0.0107789\n",
      "Validation loss decreased (0.009710 --> 0.009521).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0095548\n",
      "\tspeed: 0.1155s/iter; left time: 1742.4413s\n",
      "\titers: 200, epoch: 4 | loss: 0.0091143\n",
      "\tspeed: 0.0316s/iter; left time: 472.8965s\n",
      "\titers: 300, epoch: 4 | loss: 0.0080482\n",
      "\tspeed: 0.0316s/iter; left time: 469.7946s\n",
      "\titers: 400, epoch: 4 | loss: 0.0063617\n",
      "\tspeed: 0.0316s/iter; left time: 466.5531s\n",
      "\titers: 500, epoch: 4 | loss: 0.0120802\n",
      "\tspeed: 0.0316s/iter; left time: 463.6351s\n",
      "\titers: 600, epoch: 4 | loss: 0.0093445\n",
      "\tspeed: 0.0316s/iter; left time: 460.6598s\n",
      "\titers: 700, epoch: 4 | loss: 0.0067824\n",
      "\tspeed: 0.0316s/iter; left time: 457.2076s\n",
      "\titers: 800, epoch: 4 | loss: 0.0095844\n",
      "\tspeed: 0.0316s/iter; left time: 454.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.46s\n",
      "Steps: 893 | Train Loss: 0.0090803 Vali Loss: 0.0093065 Test Loss: 0.0103146\n",
      "Validation loss decreased (0.009521 --> 0.009307).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0069961\n",
      "\tspeed: 0.1147s/iter; left time: 1627.3934s\n",
      "\titers: 200, epoch: 5 | loss: 0.0079711\n",
      "\tspeed: 0.0315s/iter; left time: 444.3339s\n",
      "\titers: 300, epoch: 5 | loss: 0.0090334\n",
      "\tspeed: 0.0315s/iter; left time: 440.9056s\n",
      "\titers: 400, epoch: 5 | loss: 0.0107465\n",
      "\tspeed: 0.0315s/iter; left time: 437.9371s\n",
      "\titers: 500, epoch: 5 | loss: 0.0078138\n",
      "\tspeed: 0.0316s/iter; left time: 435.1598s\n",
      "\titers: 600, epoch: 5 | loss: 0.0079348\n",
      "\tspeed: 0.0316s/iter; left time: 432.1101s\n",
      "\titers: 700, epoch: 5 | loss: 0.0068863\n",
      "\tspeed: 0.0316s/iter; left time: 429.1608s\n",
      "\titers: 800, epoch: 5 | loss: 0.0076076\n",
      "\tspeed: 0.0315s/iter; left time: 425.5748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.0088471 Vali Loss: 0.0090760 Test Loss: 0.0102474\n",
      "Validation loss decreased (0.009307 --> 0.009076).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0087278\n",
      "\tspeed: 0.1167s/iter; left time: 1551.9255s\n",
      "\titers: 200, epoch: 6 | loss: 0.0081443\n",
      "\tspeed: 0.0316s/iter; left time: 416.8549s\n",
      "\titers: 300, epoch: 6 | loss: 0.0104516\n",
      "\tspeed: 0.0316s/iter; left time: 414.1725s\n",
      "\titers: 400, epoch: 6 | loss: 0.0100715\n",
      "\tspeed: 0.0317s/iter; left time: 411.3896s\n",
      "\titers: 500, epoch: 6 | loss: 0.0075160\n",
      "\tspeed: 0.0317s/iter; left time: 408.3870s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075563\n",
      "\tspeed: 0.0317s/iter; left time: 405.1708s\n",
      "\titers: 700, epoch: 6 | loss: 0.0073126\n",
      "\tspeed: 0.0317s/iter; left time: 402.1150s\n",
      "\titers: 800, epoch: 6 | loss: 0.0084259\n",
      "\tspeed: 0.0317s/iter; left time: 399.0750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.54s\n",
      "Steps: 893 | Train Loss: 0.0086545 Vali Loss: 0.0090082 Test Loss: 0.0101873\n",
      "Validation loss decreased (0.009076 --> 0.009008).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0101657\n",
      "\tspeed: 0.1154s/iter; left time: 1431.0314s\n",
      "\titers: 200, epoch: 7 | loss: 0.0085518\n",
      "\tspeed: 0.0316s/iter; left time: 388.2676s\n",
      "\titers: 300, epoch: 7 | loss: 0.0075153\n",
      "\tspeed: 0.0316s/iter; left time: 385.2293s\n",
      "\titers: 400, epoch: 7 | loss: 0.0103273\n",
      "\tspeed: 0.0316s/iter; left time: 382.2345s\n",
      "\titers: 500, epoch: 7 | loss: 0.0111148\n",
      "\tspeed: 0.0316s/iter; left time: 378.9996s\n",
      "\titers: 600, epoch: 7 | loss: 0.0072949\n",
      "\tspeed: 0.0316s/iter; left time: 375.7227s\n",
      "\titers: 700, epoch: 7 | loss: 0.0082835\n",
      "\tspeed: 0.0316s/iter; left time: 372.8064s\n",
      "\titers: 800, epoch: 7 | loss: 0.0063075\n",
      "\tspeed: 0.0316s/iter; left time: 369.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.0084860 Vali Loss: 0.0090358 Test Loss: 0.0102551\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0092223\n",
      "\tspeed: 0.1125s/iter; left time: 1294.4705s\n",
      "\titers: 200, epoch: 8 | loss: 0.0074120\n",
      "\tspeed: 0.0316s/iter; left time: 360.1578s\n",
      "\titers: 300, epoch: 8 | loss: 0.0072786\n",
      "\tspeed: 0.0316s/iter; left time: 357.0774s\n",
      "\titers: 400, epoch: 8 | loss: 0.0093758\n",
      "\tspeed: 0.0316s/iter; left time: 354.0212s\n",
      "\titers: 500, epoch: 8 | loss: 0.0086778\n",
      "\tspeed: 0.0316s/iter; left time: 350.6599s\n",
      "\titers: 600, epoch: 8 | loss: 0.0087682\n",
      "\tspeed: 0.0316s/iter; left time: 347.4496s\n",
      "\titers: 700, epoch: 8 | loss: 0.0058987\n",
      "\tspeed: 0.0316s/iter; left time: 344.6005s\n",
      "\titers: 800, epoch: 8 | loss: 0.0082650\n",
      "\tspeed: 0.0316s/iter; left time: 341.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 893 | Train Loss: 0.0083547 Vali Loss: 0.0090518 Test Loss: 0.0102742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0083114\n",
      "\tspeed: 0.1125s/iter; left time: 1194.6115s\n",
      "\titers: 200, epoch: 9 | loss: 0.0079012\n",
      "\tspeed: 0.0316s/iter; left time: 331.9998s\n",
      "\titers: 300, epoch: 9 | loss: 0.0082384\n",
      "\tspeed: 0.0316s/iter; left time: 328.9278s\n",
      "\titers: 400, epoch: 9 | loss: 0.0078376\n",
      "\tspeed: 0.0316s/iter; left time: 325.7540s\n",
      "\titers: 500, epoch: 9 | loss: 0.0086042\n",
      "\tspeed: 0.0316s/iter; left time: 322.9110s\n",
      "\titers: 600, epoch: 9 | loss: 0.0074068\n",
      "\tspeed: 0.0316s/iter; left time: 319.5355s\n",
      "\titers: 700, epoch: 9 | loss: 0.0107909\n",
      "\tspeed: 0.0316s/iter; left time: 316.4417s\n",
      "\titers: 800, epoch: 9 | loss: 0.0066278\n",
      "\tspeed: 0.0316s/iter; left time: 313.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.41s\n",
      "Steps: 893 | Train Loss: 0.0082338 Vali Loss: 0.0090181 Test Loss: 0.0102888\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010187342762947083, rmse:0.10093236714601517, mae:0.06018470227718353, rse:0.381430447101593\n",
      "Original data scale mse:1345018.875, rmse:1159.74951171875, mae:748.0704345703125, rse:0.08149833232164383\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0446759\n",
      "\tspeed: 0.0542s/iter; left time: 960.4710s\n",
      "\titers: 200, epoch: 1 | loss: 0.0339056\n",
      "\tspeed: 0.0320s/iter; left time: 563.2500s\n",
      "\titers: 300, epoch: 1 | loss: 0.0302009\n",
      "\tspeed: 0.0320s/iter; left time: 561.3655s\n",
      "\titers: 400, epoch: 1 | loss: 0.0241939\n",
      "\tspeed: 0.0321s/iter; left time: 558.5017s\n",
      "\titers: 500, epoch: 1 | loss: 0.0225760\n",
      "\tspeed: 0.0321s/iter; left time: 555.8099s\n",
      "\titers: 600, epoch: 1 | loss: 0.0246281\n",
      "\tspeed: 0.0321s/iter; left time: 552.5841s\n",
      "\titers: 700, epoch: 1 | loss: 0.0206922\n",
      "\tspeed: 0.0321s/iter; left time: 550.3538s\n",
      "\titers: 800, epoch: 1 | loss: 0.0205063\n",
      "\tspeed: 0.0321s/iter; left time: 546.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 891 | Train Loss: 0.0297742 Vali Loss: 0.0209953 Test Loss: 0.0217968\n",
      "Validation loss decreased (inf --> 0.020995).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0212563\n",
      "\tspeed: 0.1162s/iter; left time: 1955.6966s\n",
      "\titers: 200, epoch: 2 | loss: 0.0141209\n",
      "\tspeed: 0.0321s/iter; left time: 537.2559s\n",
      "\titers: 300, epoch: 2 | loss: 0.0171342\n",
      "\tspeed: 0.0321s/iter; left time: 534.2078s\n",
      "\titers: 400, epoch: 2 | loss: 0.0167763\n",
      "\tspeed: 0.0321s/iter; left time: 531.0880s\n",
      "\titers: 500, epoch: 2 | loss: 0.0153061\n",
      "\tspeed: 0.0321s/iter; left time: 527.9309s\n",
      "\titers: 600, epoch: 2 | loss: 0.0164437\n",
      "\tspeed: 0.0322s/iter; left time: 525.4897s\n",
      "\titers: 700, epoch: 2 | loss: 0.0192035\n",
      "\tspeed: 0.0321s/iter; left time: 521.7322s\n",
      "\titers: 800, epoch: 2 | loss: 0.0175744\n",
      "\tspeed: 0.0322s/iter; left time: 518.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.84s\n",
      "Steps: 891 | Train Loss: 0.0179372 Vali Loss: 0.0168389 Test Loss: 0.0177091\n",
      "Validation loss decreased (0.020995 --> 0.016839).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0167907\n",
      "\tspeed: 0.1160s/iter; left time: 1848.4650s\n",
      "\titers: 200, epoch: 3 | loss: 0.0161756\n",
      "\tspeed: 0.0322s/iter; left time: 509.4641s\n",
      "\titers: 300, epoch: 3 | loss: 0.0142141\n",
      "\tspeed: 0.0322s/iter; left time: 506.9082s\n",
      "\titers: 400, epoch: 3 | loss: 0.0156928\n",
      "\tspeed: 0.0322s/iter; left time: 503.5142s\n",
      "\titers: 500, epoch: 3 | loss: 0.0182573\n",
      "\tspeed: 0.0322s/iter; left time: 500.7408s\n",
      "\titers: 600, epoch: 3 | loss: 0.0158229\n",
      "\tspeed: 0.0322s/iter; left time: 497.2442s\n",
      "\titers: 700, epoch: 3 | loss: 0.0177532\n",
      "\tspeed: 0.0322s/iter; left time: 494.3362s\n",
      "\titers: 800, epoch: 3 | loss: 0.0125923\n",
      "\tspeed: 0.0322s/iter; left time: 491.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 891 | Train Loss: 0.0161688 Vali Loss: 0.0164319 Test Loss: 0.0177020\n",
      "Validation loss decreased (0.016839 --> 0.016432).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0200638\n",
      "\tspeed: 0.1154s/iter; left time: 1737.0532s\n",
      "\titers: 200, epoch: 4 | loss: 0.0172271\n",
      "\tspeed: 0.0322s/iter; left time: 481.0738s\n",
      "\titers: 300, epoch: 4 | loss: 0.0186417\n",
      "\tspeed: 0.0322s/iter; left time: 478.0338s\n",
      "\titers: 400, epoch: 4 | loss: 0.0178436\n",
      "\tspeed: 0.0322s/iter; left time: 475.1860s\n",
      "\titers: 500, epoch: 4 | loss: 0.0191946\n",
      "\tspeed: 0.0322s/iter; left time: 471.6752s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161984\n",
      "\tspeed: 0.0322s/iter; left time: 468.5213s\n",
      "\titers: 700, epoch: 4 | loss: 0.0150332\n",
      "\tspeed: 0.0322s/iter; left time: 465.0384s\n",
      "\titers: 800, epoch: 4 | loss: 0.0172511\n",
      "\tspeed: 0.0322s/iter; left time: 461.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 891 | Train Loss: 0.0156041 Vali Loss: 0.0165908 Test Loss: 0.0180330\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0156613\n",
      "\tspeed: 0.1148s/iter; left time: 1625.2587s\n",
      "\titers: 200, epoch: 5 | loss: 0.0176938\n",
      "\tspeed: 0.0322s/iter; left time: 452.4547s\n",
      "\titers: 300, epoch: 5 | loss: 0.0171251\n",
      "\tspeed: 0.0322s/iter; left time: 449.4233s\n",
      "\titers: 400, epoch: 5 | loss: 0.0138496\n",
      "\tspeed: 0.0322s/iter; left time: 446.2903s\n",
      "\titers: 500, epoch: 5 | loss: 0.0143258\n",
      "\tspeed: 0.0322s/iter; left time: 442.9458s\n",
      "\titers: 600, epoch: 5 | loss: 0.0157314\n",
      "\tspeed: 0.0322s/iter; left time: 439.3643s\n",
      "\titers: 700, epoch: 5 | loss: 0.0121322\n",
      "\tspeed: 0.0322s/iter; left time: 436.2396s\n",
      "\titers: 800, epoch: 5 | loss: 0.0139402\n",
      "\tspeed: 0.0322s/iter; left time: 433.4131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 891 | Train Loss: 0.0149875 Vali Loss: 0.0173657 Test Loss: 0.0180992\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0172490\n",
      "\tspeed: 0.1133s/iter; left time: 1503.2310s\n",
      "\titers: 200, epoch: 6 | loss: 0.0133060\n",
      "\tspeed: 0.0323s/iter; left time: 424.8135s\n",
      "\titers: 300, epoch: 6 | loss: 0.0129038\n",
      "\tspeed: 0.0322s/iter; left time: 420.4356s\n",
      "\titers: 400, epoch: 6 | loss: 0.0179277\n",
      "\tspeed: 0.0322s/iter; left time: 417.3505s\n",
      "\titers: 500, epoch: 6 | loss: 0.0136542\n",
      "\tspeed: 0.0322s/iter; left time: 414.2451s\n",
      "\titers: 600, epoch: 6 | loss: 0.0118115\n",
      "\tspeed: 0.0322s/iter; left time: 411.0131s\n",
      "\titers: 700, epoch: 6 | loss: 0.0147058\n",
      "\tspeed: 0.0322s/iter; left time: 407.6206s\n",
      "\titers: 800, epoch: 6 | loss: 0.0157054\n",
      "\tspeed: 0.0322s/iter; left time: 404.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 891 | Train Loss: 0.0144351 Vali Loss: 0.0180413 Test Loss: 0.0188302\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017702016979455948, rmse:0.1330489218235016, mae:0.08385562896728516, rse:0.5030723214149475\n",
      "Original data scale mse:2733544.0, rmse:1653.34326171875, mae:1080.4556884765625, rse:0.11635251343250275\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0406234\n",
      "\tspeed: 0.0343s/iter; left time: 607.5057s\n",
      "\titers: 200, epoch: 1 | loss: 0.0304506\n",
      "\tspeed: 0.0321s/iter; left time: 566.4704s\n",
      "\titers: 300, epoch: 1 | loss: 0.0264428\n",
      "\tspeed: 0.0322s/iter; left time: 563.9994s\n",
      "\titers: 400, epoch: 1 | loss: 0.0245147\n",
      "\tspeed: 0.0322s/iter; left time: 560.3512s\n",
      "\titers: 500, epoch: 1 | loss: 0.0236890\n",
      "\tspeed: 0.0322s/iter; left time: 557.0480s\n",
      "\titers: 600, epoch: 1 | loss: 0.0260627\n",
      "\tspeed: 0.0322s/iter; left time: 554.0373s\n",
      "\titers: 700, epoch: 1 | loss: 0.0246874\n",
      "\tspeed: 0.0322s/iter; left time: 550.4898s\n",
      "\titers: 800, epoch: 1 | loss: 0.0201032\n",
      "\tspeed: 0.0322s/iter; left time: 547.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 891 | Train Loss: 0.0295239 Vali Loss: 0.0211083 Test Loss: 0.0219867\n",
      "Validation loss decreased (inf --> 0.021108).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0236533\n",
      "\tspeed: 0.1154s/iter; left time: 1941.8032s\n",
      "\titers: 200, epoch: 2 | loss: 0.0194901\n",
      "\tspeed: 0.0321s/iter; left time: 537.7607s\n",
      "\titers: 300, epoch: 2 | loss: 0.0172046\n",
      "\tspeed: 0.0321s/iter; left time: 534.4956s\n",
      "\titers: 400, epoch: 2 | loss: 0.0145445\n",
      "\tspeed: 0.0322s/iter; left time: 531.5115s\n",
      "\titers: 500, epoch: 2 | loss: 0.0157168\n",
      "\tspeed: 0.0321s/iter; left time: 528.0841s\n",
      "\titers: 600, epoch: 2 | loss: 0.0188486\n",
      "\tspeed: 0.0321s/iter; left time: 524.8781s\n",
      "\titers: 700, epoch: 2 | loss: 0.0169419\n",
      "\tspeed: 0.0322s/iter; left time: 522.0402s\n",
      "\titers: 800, epoch: 2 | loss: 0.0173726\n",
      "\tspeed: 0.0322s/iter; left time: 518.6158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.85s\n",
      "Steps: 891 | Train Loss: 0.0179381 Vali Loss: 0.0165276 Test Loss: 0.0178640\n",
      "Validation loss decreased (0.021108 --> 0.016528).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0170408\n",
      "\tspeed: 0.1152s/iter; left time: 1836.4946s\n",
      "\titers: 200, epoch: 3 | loss: 0.0143623\n",
      "\tspeed: 0.0323s/iter; left time: 511.3758s\n",
      "\titers: 300, epoch: 3 | loss: 0.0160886\n",
      "\tspeed: 0.0323s/iter; left time: 507.6569s\n",
      "\titers: 400, epoch: 3 | loss: 0.0149194\n",
      "\tspeed: 0.0323s/iter; left time: 504.7953s\n",
      "\titers: 500, epoch: 3 | loss: 0.0135327\n",
      "\tspeed: 0.0323s/iter; left time: 501.3831s\n",
      "\titers: 600, epoch: 3 | loss: 0.0155402\n",
      "\tspeed: 0.0323s/iter; left time: 498.6634s\n",
      "\titers: 700, epoch: 3 | loss: 0.0161488\n",
      "\tspeed: 0.0323s/iter; left time: 495.0250s\n",
      "\titers: 800, epoch: 3 | loss: 0.0146325\n",
      "\tspeed: 0.0323s/iter; left time: 491.9356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.97s\n",
      "Steps: 891 | Train Loss: 0.0162347 Vali Loss: 0.0166346 Test Loss: 0.0176918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0158126\n",
      "\tspeed: 0.1133s/iter; left time: 1705.3503s\n",
      "\titers: 200, epoch: 4 | loss: 0.0183031\n",
      "\tspeed: 0.0321s/iter; left time: 480.5716s\n",
      "\titers: 300, epoch: 4 | loss: 0.0160641\n",
      "\tspeed: 0.0321s/iter; left time: 477.1366s\n",
      "\titers: 400, epoch: 4 | loss: 0.0146728\n",
      "\tspeed: 0.0321s/iter; left time: 474.0711s\n",
      "\titers: 500, epoch: 4 | loss: 0.0157657\n",
      "\tspeed: 0.0321s/iter; left time: 470.6826s\n",
      "\titers: 600, epoch: 4 | loss: 0.0150141\n",
      "\tspeed: 0.0321s/iter; left time: 467.5085s\n",
      "\titers: 700, epoch: 4 | loss: 0.0158790\n",
      "\tspeed: 0.0322s/iter; left time: 464.5294s\n",
      "\titers: 800, epoch: 4 | loss: 0.0178049\n",
      "\tspeed: 0.0322s/iter; left time: 461.3086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.80s\n",
      "Steps: 891 | Train Loss: 0.0157035 Vali Loss: 0.0162562 Test Loss: 0.0176970\n",
      "Validation loss decreased (0.016528 --> 0.016256).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0169804\n",
      "\tspeed: 0.1268s/iter; left time: 1795.7619s\n",
      "\titers: 200, epoch: 5 | loss: 0.0124564\n",
      "\tspeed: 0.0584s/iter; left time: 821.0924s\n",
      "\titers: 300, epoch: 5 | loss: 0.0120268\n",
      "\tspeed: 0.0731s/iter; left time: 1019.9496s\n",
      "\titers: 400, epoch: 5 | loss: 0.0160350\n",
      "\tspeed: 0.0607s/iter; left time: 840.5456s\n",
      "\titers: 500, epoch: 5 | loss: 0.0149844\n",
      "\tspeed: 0.0732s/iter; left time: 1007.1270s\n",
      "\titers: 600, epoch: 5 | loss: 0.0136117\n",
      "\tspeed: 0.0707s/iter; left time: 966.1319s\n",
      "\titers: 700, epoch: 5 | loss: 0.0170037\n",
      "\tspeed: 0.0691s/iter; left time: 937.1485s\n",
      "\titers: 800, epoch: 5 | loss: 0.0161937\n",
      "\tspeed: 0.0783s/iter; left time: 1053.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.76s\n",
      "Steps: 891 | Train Loss: 0.0151732 Vali Loss: 0.0166186 Test Loss: 0.0179996\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0134581\n",
      "\tspeed: 0.3164s/iter; left time: 4197.0403s\n",
      "\titers: 200, epoch: 6 | loss: 0.0137155\n",
      "\tspeed: 0.0325s/iter; left time: 427.5570s\n",
      "\titers: 300, epoch: 6 | loss: 0.0129766\n",
      "\tspeed: 0.0323s/iter; left time: 422.1667s\n",
      "\titers: 400, epoch: 6 | loss: 0.0133035\n",
      "\tspeed: 0.0324s/iter; left time: 419.7068s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140448\n",
      "\tspeed: 0.0324s/iter; left time: 416.6230s\n",
      "\titers: 600, epoch: 6 | loss: 0.0172476\n",
      "\tspeed: 0.0324s/iter; left time: 413.0870s\n",
      "\titers: 700, epoch: 6 | loss: 0.0123581\n",
      "\tspeed: 0.0324s/iter; left time: 410.0848s\n",
      "\titers: 800, epoch: 6 | loss: 0.0138627\n",
      "\tspeed: 0.0324s/iter; left time: 407.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.21s\n",
      "Steps: 891 | Train Loss: 0.0146976 Vali Loss: 0.0173353 Test Loss: 0.0184360\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0122698\n",
      "\tspeed: 0.1169s/iter; left time: 1446.0627s\n",
      "\titers: 200, epoch: 7 | loss: 0.0152275\n",
      "\tspeed: 0.0323s/iter; left time: 396.2277s\n",
      "\titers: 300, epoch: 7 | loss: 0.0193167\n",
      "\tspeed: 0.0323s/iter; left time: 393.2127s\n",
      "\titers: 400, epoch: 7 | loss: 0.0185996\n",
      "\tspeed: 0.0324s/iter; left time: 390.7275s\n",
      "\titers: 500, epoch: 7 | loss: 0.0155483\n",
      "\tspeed: 0.0323s/iter; left time: 386.9070s\n",
      "\titers: 600, epoch: 7 | loss: 0.0167669\n",
      "\tspeed: 0.0323s/iter; left time: 383.1237s\n",
      "\titers: 700, epoch: 7 | loss: 0.0144416\n",
      "\tspeed: 0.0323s/iter; left time: 380.1248s\n",
      "\titers: 800, epoch: 7 | loss: 0.0132680\n",
      "\tspeed: 0.0323s/iter; left time: 377.0752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 891 | Train Loss: 0.0142368 Vali Loss: 0.0173187 Test Loss: 0.0188920\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017696980386972427, rmse:0.1330299973487854, mae:0.08341965079307556, rse:0.503000795841217\n",
      "Original data scale mse:2685297.5, rmse:1638.687744140625, mae:1075.378662109375, rse:0.11532114446163177\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0450713\n",
      "\tspeed: 0.0513s/iter; left time: 906.2306s\n",
      "\titers: 200, epoch: 1 | loss: 0.0285126\n",
      "\tspeed: 0.0325s/iter; left time: 572.0685s\n",
      "\titers: 300, epoch: 1 | loss: 0.0269689\n",
      "\tspeed: 0.0325s/iter; left time: 568.9319s\n",
      "\titers: 400, epoch: 1 | loss: 0.0321130\n",
      "\tspeed: 0.0326s/iter; left time: 566.9328s\n",
      "\titers: 500, epoch: 1 | loss: 0.0280550\n",
      "\tspeed: 0.0326s/iter; left time: 563.8615s\n",
      "\titers: 600, epoch: 1 | loss: 0.0262634\n",
      "\tspeed: 0.0327s/iter; left time: 561.1413s\n",
      "\titers: 700, epoch: 1 | loss: 0.0261874\n",
      "\tspeed: 0.0327s/iter; left time: 558.6894s\n",
      "\titers: 800, epoch: 1 | loss: 0.0241447\n",
      "\tspeed: 0.0328s/iter; left time: 556.5136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.52s\n",
      "Steps: 889 | Train Loss: 0.0305881 Vali Loss: 0.0220056 Test Loss: 0.0224129\n",
      "Validation loss decreased (inf --> 0.022006).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0221449\n",
      "\tspeed: 0.1190s/iter; left time: 1998.4403s\n",
      "\titers: 200, epoch: 2 | loss: 0.0209684\n",
      "\tspeed: 0.0328s/iter; left time: 547.3865s\n",
      "\titers: 300, epoch: 2 | loss: 0.0231090\n",
      "\tspeed: 0.0328s/iter; left time: 543.6743s\n",
      "\titers: 400, epoch: 2 | loss: 0.0178215\n",
      "\tspeed: 0.0328s/iter; left time: 540.4382s\n",
      "\titers: 500, epoch: 2 | loss: 0.0183674\n",
      "\tspeed: 0.0327s/iter; left time: 536.3173s\n",
      "\titers: 600, epoch: 2 | loss: 0.0200455\n",
      "\tspeed: 0.0335s/iter; left time: 546.1414s\n",
      "\titers: 700, epoch: 2 | loss: 0.0174290\n",
      "\tspeed: 0.0666s/iter; left time: 1078.3201s\n",
      "\titers: 800, epoch: 2 | loss: 0.0203020\n",
      "\tspeed: 0.0933s/iter; left time: 1501.9771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.03s\n",
      "Steps: 889 | Train Loss: 0.0192915 Vali Loss: 0.0183680 Test Loss: 0.0190078\n",
      "Validation loss decreased (0.022006 --> 0.018368).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0174881\n",
      "\tspeed: 0.3606s/iter; left time: 5733.8556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0189570\n",
      "\tspeed: 0.0326s/iter; left time: 515.1570s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205802\n",
      "\tspeed: 0.0326s/iter; left time: 512.3394s\n",
      "\titers: 400, epoch: 3 | loss: 0.0193875\n",
      "\tspeed: 0.0326s/iter; left time: 508.6872s\n",
      "\titers: 500, epoch: 3 | loss: 0.0161234\n",
      "\tspeed: 0.0326s/iter; left time: 506.1420s\n",
      "\titers: 600, epoch: 3 | loss: 0.0156295\n",
      "\tspeed: 0.0327s/iter; left time: 503.1142s\n",
      "\titers: 700, epoch: 3 | loss: 0.0169990\n",
      "\tspeed: 0.0327s/iter; left time: 500.9467s\n",
      "\titers: 800, epoch: 3 | loss: 0.0183149\n",
      "\tspeed: 0.0327s/iter; left time: 497.0433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.36s\n",
      "Steps: 889 | Train Loss: 0.0175088 Vali Loss: 0.0182403 Test Loss: 0.0192384\n",
      "Validation loss decreased (0.018368 --> 0.018240).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0167525\n",
      "\tspeed: 0.1188s/iter; left time: 1783.5601s\n",
      "\titers: 200, epoch: 4 | loss: 0.0157168\n",
      "\tspeed: 0.0325s/iter; left time: 485.0513s\n",
      "\titers: 300, epoch: 4 | loss: 0.0181289\n",
      "\tspeed: 0.0326s/iter; left time: 482.8042s\n",
      "\titers: 400, epoch: 4 | loss: 0.0158558\n",
      "\tspeed: 0.0326s/iter; left time: 479.8927s\n",
      "\titers: 500, epoch: 4 | loss: 0.0139187\n",
      "\tspeed: 0.0327s/iter; left time: 477.8953s\n",
      "\titers: 600, epoch: 4 | loss: 0.0144530\n",
      "\tspeed: 0.0327s/iter; left time: 474.7187s\n",
      "\titers: 700, epoch: 4 | loss: 0.0167545\n",
      "\tspeed: 0.0327s/iter; left time: 471.1304s\n",
      "\titers: 800, epoch: 4 | loss: 0.0163018\n",
      "\tspeed: 0.0327s/iter; left time: 468.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.26s\n",
      "Steps: 889 | Train Loss: 0.0168175 Vali Loss: 0.0186223 Test Loss: 0.0199029\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0168585\n",
      "\tspeed: 0.1166s/iter; left time: 1646.6785s\n",
      "\titers: 200, epoch: 5 | loss: 0.0139494\n",
      "\tspeed: 0.0328s/iter; left time: 460.1442s\n",
      "\titers: 300, epoch: 5 | loss: 0.0151746\n",
      "\tspeed: 0.0328s/iter; left time: 456.8190s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173131\n",
      "\tspeed: 0.0328s/iter; left time: 453.5019s\n",
      "\titers: 500, epoch: 5 | loss: 0.0161495\n",
      "\tspeed: 0.0328s/iter; left time: 450.2812s\n",
      "\titers: 600, epoch: 5 | loss: 0.0147723\n",
      "\tspeed: 0.0328s/iter; left time: 446.6871s\n",
      "\titers: 700, epoch: 5 | loss: 0.0174813\n",
      "\tspeed: 0.0328s/iter; left time: 443.4558s\n",
      "\titers: 800, epoch: 5 | loss: 0.0162959\n",
      "\tspeed: 0.0327s/iter; left time: 439.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.43s\n",
      "Steps: 889 | Train Loss: 0.0161081 Vali Loss: 0.0185431 Test Loss: 0.0208752\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0133869\n",
      "\tspeed: 0.1165s/iter; left time: 1542.5044s\n",
      "\titers: 200, epoch: 6 | loss: 0.0168410\n",
      "\tspeed: 0.0327s/iter; left time: 430.1365s\n",
      "\titers: 300, epoch: 6 | loss: 0.0159169\n",
      "\tspeed: 0.0328s/iter; left time: 427.1004s\n",
      "\titers: 400, epoch: 6 | loss: 0.0135813\n",
      "\tspeed: 0.0327s/iter; left time: 423.0673s\n",
      "\titers: 500, epoch: 6 | loss: 0.0144146\n",
      "\tspeed: 0.0327s/iter; left time: 419.5147s\n",
      "\titers: 600, epoch: 6 | loss: 0.0147121\n",
      "\tspeed: 0.0327s/iter; left time: 416.3953s\n",
      "\titers: 700, epoch: 6 | loss: 0.0161939\n",
      "\tspeed: 0.0327s/iter; left time: 412.6536s\n",
      "\titers: 800, epoch: 6 | loss: 0.0141570\n",
      "\tspeed: 0.0327s/iter; left time: 410.1580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 889 | Train Loss: 0.0154301 Vali Loss: 0.0199369 Test Loss: 0.0216764\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019238349050283432, rmse:0.1387023776769638, mae:0.08914682269096375, rse:0.5248109698295593\n",
      "Original data scale mse:3203129.75, rmse:1789.72900390625, mae:1175.19287109375, rse:0.1260688155889511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0400533\n",
      "\tspeed: 0.0351s/iter; left time: 620.2111s\n",
      "\titers: 200, epoch: 1 | loss: 0.0341598\n",
      "\tspeed: 0.0327s/iter; left time: 574.1173s\n",
      "\titers: 300, epoch: 1 | loss: 0.0299333\n",
      "\tspeed: 0.0327s/iter; left time: 571.0640s\n",
      "\titers: 400, epoch: 1 | loss: 0.0262852\n",
      "\tspeed: 0.0327s/iter; left time: 567.7900s\n",
      "\titers: 500, epoch: 1 | loss: 0.0284389\n",
      "\tspeed: 0.0327s/iter; left time: 564.4607s\n",
      "\titers: 600, epoch: 1 | loss: 0.0254627\n",
      "\tspeed: 0.0326s/iter; left time: 560.3143s\n",
      "\titers: 700, epoch: 1 | loss: 0.0244071\n",
      "\tspeed: 0.0326s/iter; left time: 556.6990s\n",
      "\titers: 800, epoch: 1 | loss: 0.0240860\n",
      "\tspeed: 0.0326s/iter; left time: 554.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.30s\n",
      "Steps: 889 | Train Loss: 0.0304226 Vali Loss: 0.0220870 Test Loss: 0.0225252\n",
      "Validation loss decreased (inf --> 0.022087).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0203671\n",
      "\tspeed: 0.1197s/iter; left time: 2010.4858s\n",
      "\titers: 200, epoch: 2 | loss: 0.0212195\n",
      "\tspeed: 0.0325s/iter; left time: 543.2122s\n",
      "\titers: 300, epoch: 2 | loss: 0.0217393\n",
      "\tspeed: 0.0326s/iter; left time: 540.1015s\n",
      "\titers: 400, epoch: 2 | loss: 0.0191063\n",
      "\tspeed: 0.0325s/iter; left time: 536.3532s\n",
      "\titers: 500, epoch: 2 | loss: 0.0214449\n",
      "\tspeed: 0.0326s/iter; left time: 533.5985s\n",
      "\titers: 600, epoch: 2 | loss: 0.0184704\n",
      "\tspeed: 0.0326s/iter; left time: 530.5995s\n",
      "\titers: 700, epoch: 2 | loss: 0.0192936\n",
      "\tspeed: 0.0326s/iter; left time: 527.3356s\n",
      "\titers: 800, epoch: 2 | loss: 0.0197576\n",
      "\tspeed: 0.0326s/iter; left time: 524.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.25s\n",
      "Steps: 889 | Train Loss: 0.0192593 Vali Loss: 0.0183215 Test Loss: 0.0190579\n",
      "Validation loss decreased (0.022087 --> 0.018321).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0174452\n",
      "\tspeed: 0.1180s/iter; left time: 1876.5605s\n",
      "\titers: 200, epoch: 3 | loss: 0.0177213\n",
      "\tspeed: 0.0335s/iter; left time: 529.7515s\n",
      "\titers: 300, epoch: 3 | loss: 0.0159030\n",
      "\tspeed: 0.0471s/iter; left time: 739.7144s\n",
      "\titers: 400, epoch: 3 | loss: 0.0177999\n",
      "\tspeed: 0.0373s/iter; left time: 582.2400s\n",
      "\titers: 500, epoch: 3 | loss: 0.0179492\n",
      "\tspeed: 0.0336s/iter; left time: 520.2808s\n",
      "\titers: 600, epoch: 3 | loss: 0.0163139\n",
      "\tspeed: 0.0326s/iter; left time: 502.8692s\n",
      "\titers: 700, epoch: 3 | loss: 0.0180116\n",
      "\tspeed: 0.0326s/iter; left time: 499.2828s\n",
      "\titers: 800, epoch: 3 | loss: 0.0170829\n",
      "\tspeed: 0.0326s/iter; left time: 495.2944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 889 | Train Loss: 0.0174579 Vali Loss: 0.0182794 Test Loss: 0.0191404\n",
      "Validation loss decreased (0.018321 --> 0.018279).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0182305\n",
      "\tspeed: 0.1396s/iter; left time: 2096.3358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0177344\n",
      "\tspeed: 0.0888s/iter; left time: 1324.0456s\n",
      "\titers: 300, epoch: 4 | loss: 0.0155075\n",
      "\tspeed: 0.0963s/iter; left time: 1426.6287s\n",
      "\titers: 400, epoch: 4 | loss: 0.0180235\n",
      "\tspeed: 0.0984s/iter; left time: 1448.0163s\n",
      "\titers: 500, epoch: 4 | loss: 0.0158681\n",
      "\tspeed: 0.0938s/iter; left time: 1370.9688s\n",
      "\titers: 600, epoch: 4 | loss: 0.0162353\n",
      "\tspeed: 0.1006s/iter; left time: 1460.3487s\n",
      "\titers: 700, epoch: 4 | loss: 0.0172570\n",
      "\tspeed: 0.1061s/iter; left time: 1528.9770s\n",
      "\titers: 800, epoch: 4 | loss: 0.0155949\n",
      "\tspeed: 0.0962s/iter; left time: 1376.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:21.63s\n",
      "Steps: 889 | Train Loss: 0.0167536 Vali Loss: 0.0187042 Test Loss: 0.0200302\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0183104\n",
      "\tspeed: 0.5490s/iter; left time: 7754.7248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0157400\n",
      "\tspeed: 0.0900s/iter; left time: 1262.0364s\n",
      "\titers: 300, epoch: 5 | loss: 0.0179007\n",
      "\tspeed: 0.0921s/iter; left time: 1282.1334s\n",
      "\titers: 400, epoch: 5 | loss: 0.0159870\n",
      "\tspeed: 0.0957s/iter; left time: 1322.5121s\n",
      "\titers: 500, epoch: 5 | loss: 0.0180564\n",
      "\tspeed: 0.0889s/iter; left time: 1220.7600s\n",
      "\titers: 600, epoch: 5 | loss: 0.0168376\n",
      "\tspeed: 0.1021s/iter; left time: 1391.4963s\n",
      "\titers: 700, epoch: 5 | loss: 0.0166795\n",
      "\tspeed: 0.1023s/iter; left time: 1383.7963s\n",
      "\titers: 800, epoch: 5 | loss: 0.0153045\n",
      "\tspeed: 0.0928s/iter; left time: 1245.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.97s\n",
      "Steps: 889 | Train Loss: 0.0160490 Vali Loss: 0.0186591 Test Loss: 0.0203607\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0144191\n",
      "\tspeed: 0.5823s/iter; left time: 7706.8738s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130485\n",
      "\tspeed: 0.0926s/iter; left time: 1216.5495s\n",
      "\titers: 300, epoch: 6 | loss: 0.0163270\n",
      "\tspeed: 0.0979s/iter; left time: 1275.6525s\n",
      "\titers: 400, epoch: 6 | loss: 0.0164499\n",
      "\tspeed: 0.0936s/iter; left time: 1210.2187s\n",
      "\titers: 500, epoch: 6 | loss: 0.0166092\n",
      "\tspeed: 0.0895s/iter; left time: 1148.3738s\n",
      "\titers: 600, epoch: 6 | loss: 0.0120219\n",
      "\tspeed: 0.1008s/iter; left time: 1283.9662s\n",
      "\titers: 700, epoch: 6 | loss: 0.0158307\n",
      "\tspeed: 0.0760s/iter; left time: 960.0448s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142627\n",
      "\tspeed: 0.0600s/iter; left time: 752.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:17.90s\n",
      "Steps: 889 | Train Loss: 0.0154217 Vali Loss: 0.0190010 Test Loss: 0.0211448\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019140439108014107, rmse:0.13834898173809052, mae:0.08886647969484329, rse:0.5234737992286682\n",
      "Original data scale mse:3249148.25, rmse:1802.5394287109375, mae:1180.3934326171875, rse:0.12697118520736694\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1482891\n",
      "\tspeed: 0.0565s/iter; left time: 1002.7939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1231941\n",
      "\tspeed: 0.0318s/iter; left time: 560.9346s\n",
      "\titers: 300, epoch: 1 | loss: 0.1077814\n",
      "\tspeed: 0.0317s/iter; left time: 556.1745s\n",
      "\titers: 400, epoch: 1 | loss: 0.0994468\n",
      "\tspeed: 0.0317s/iter; left time: 552.6549s\n",
      "\titers: 500, epoch: 1 | loss: 0.1136864\n",
      "\tspeed: 0.0317s/iter; left time: 550.9476s\n",
      "\titers: 600, epoch: 1 | loss: 0.1013758\n",
      "\tspeed: 0.0316s/iter; left time: 544.9390s\n",
      "\titers: 700, epoch: 1 | loss: 0.0894089\n",
      "\tspeed: 0.0316s/iter; left time: 542.5694s\n",
      "\titers: 800, epoch: 1 | loss: 0.0868730\n",
      "\tspeed: 0.0317s/iter; left time: 540.4891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.93s\n",
      "Steps: 893 | Train Loss: 0.1137902 Vali Loss: 0.0852217 Test Loss: 0.0874162\n",
      "Validation loss decreased (inf --> 0.085222).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0721081\n",
      "\tspeed: 0.1204s/iter; left time: 2031.6096s\n",
      "\titers: 200, epoch: 2 | loss: 0.0649322\n",
      "\tspeed: 0.0318s/iter; left time: 532.9067s\n",
      "\titers: 300, epoch: 2 | loss: 0.0817468\n",
      "\tspeed: 0.0318s/iter; left time: 529.8672s\n",
      "\titers: 400, epoch: 2 | loss: 0.0693057\n",
      "\tspeed: 0.0319s/iter; left time: 527.8086s\n",
      "\titers: 500, epoch: 2 | loss: 0.0596833\n",
      "\tspeed: 0.0319s/iter; left time: 524.5060s\n",
      "\titers: 600, epoch: 2 | loss: 0.0498715\n",
      "\tspeed: 0.0319s/iter; left time: 521.3434s\n",
      "\titers: 700, epoch: 2 | loss: 0.0624934\n",
      "\tspeed: 0.0318s/iter; left time: 517.9333s\n",
      "\titers: 800, epoch: 2 | loss: 0.0570843\n",
      "\tspeed: 0.0318s/iter; left time: 514.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.69s\n",
      "Steps: 893 | Train Loss: 0.0658713 Vali Loss: 0.0598388 Test Loss: 0.0629169\n",
      "Validation loss decreased (0.085222 --> 0.059839).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0564329\n",
      "\tspeed: 0.1208s/iter; left time: 1929.6720s\n",
      "\titers: 200, epoch: 3 | loss: 0.0585793\n",
      "\tspeed: 0.0320s/iter; left time: 508.2870s\n",
      "\titers: 300, epoch: 3 | loss: 0.0550998\n",
      "\tspeed: 0.0321s/iter; left time: 505.6443s\n",
      "\titers: 400, epoch: 3 | loss: 0.0595986\n",
      "\tspeed: 0.0321s/iter; left time: 502.7541s\n",
      "\titers: 500, epoch: 3 | loss: 0.0524128\n",
      "\tspeed: 0.0322s/iter; left time: 501.8087s\n",
      "\titers: 600, epoch: 3 | loss: 0.0621090\n",
      "\tspeed: 0.0323s/iter; left time: 500.3178s\n",
      "\titers: 700, epoch: 3 | loss: 0.0523516\n",
      "\tspeed: 0.0323s/iter; left time: 497.2563s\n",
      "\titers: 800, epoch: 3 | loss: 0.0654900\n",
      "\tspeed: 0.0323s/iter; left time: 492.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.08s\n",
      "Steps: 893 | Train Loss: 0.0592280 Vali Loss: 0.0580211 Test Loss: 0.0606209\n",
      "Validation loss decreased (0.059839 --> 0.058021).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0600286\n",
      "\tspeed: 0.1205s/iter; left time: 1817.9106s\n",
      "\titers: 200, epoch: 4 | loss: 0.0529357\n",
      "\tspeed: 0.0324s/iter; left time: 486.0296s\n",
      "\titers: 300, epoch: 4 | loss: 0.0586079\n",
      "\tspeed: 0.0324s/iter; left time: 482.4030s\n",
      "\titers: 400, epoch: 4 | loss: 0.0509413\n",
      "\tspeed: 0.0323s/iter; left time: 476.8420s\n",
      "\titers: 500, epoch: 4 | loss: 0.0575120\n",
      "\tspeed: 0.0324s/iter; left time: 475.7259s\n",
      "\titers: 600, epoch: 4 | loss: 0.0516787\n",
      "\tspeed: 0.0323s/iter; left time: 470.3012s\n",
      "\titers: 700, epoch: 4 | loss: 0.0595648\n",
      "\tspeed: 0.0322s/iter; left time: 465.7822s\n",
      "\titers: 800, epoch: 4 | loss: 0.0619648\n",
      "\tspeed: 0.0322s/iter; left time: 462.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.10s\n",
      "Steps: 893 | Train Loss: 0.0574827 Vali Loss: 0.0576635 Test Loss: 0.0599883\n",
      "Validation loss decreased (0.058021 --> 0.057664).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0629421\n",
      "\tspeed: 0.1212s/iter; left time: 1719.2526s\n",
      "\titers: 200, epoch: 5 | loss: 0.0505218\n",
      "\tspeed: 0.0322s/iter; left time: 453.1800s\n",
      "\titers: 300, epoch: 5 | loss: 0.0642771\n",
      "\tspeed: 0.0321s/iter; left time: 448.5918s\n",
      "\titers: 400, epoch: 5 | loss: 0.0651405\n",
      "\tspeed: 0.0322s/iter; left time: 446.9734s\n",
      "\titers: 500, epoch: 5 | loss: 0.0561118\n",
      "\tspeed: 0.0322s/iter; left time: 443.4806s\n",
      "\titers: 600, epoch: 5 | loss: 0.0483814\n",
      "\tspeed: 0.0322s/iter; left time: 440.3053s\n",
      "\titers: 700, epoch: 5 | loss: 0.0533252\n",
      "\tspeed: 0.0322s/iter; left time: 437.2898s\n",
      "\titers: 800, epoch: 5 | loss: 0.0478290\n",
      "\tspeed: 0.0321s/iter; left time: 433.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.02s\n",
      "Steps: 893 | Train Loss: 0.0563732 Vali Loss: 0.0566316 Test Loss: 0.0590252\n",
      "Validation loss decreased (0.057664 --> 0.056632).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0568781\n",
      "\tspeed: 0.1191s/iter; left time: 1583.2390s\n",
      "\titers: 200, epoch: 6 | loss: 0.0571399\n",
      "\tspeed: 0.0322s/iter; left time: 425.0482s\n",
      "\titers: 300, epoch: 6 | loss: 0.0554693\n",
      "\tspeed: 0.0322s/iter; left time: 421.8343s\n",
      "\titers: 400, epoch: 6 | loss: 0.0560380\n",
      "\tspeed: 0.0322s/iter; left time: 418.8005s\n",
      "\titers: 500, epoch: 6 | loss: 0.0544334\n",
      "\tspeed: 0.0321s/iter; left time: 414.2404s\n",
      "\titers: 600, epoch: 6 | loss: 0.0607730\n",
      "\tspeed: 0.0321s/iter; left time: 410.8771s\n",
      "\titers: 700, epoch: 6 | loss: 0.0434663\n",
      "\tspeed: 0.0321s/iter; left time: 407.3304s\n",
      "\titers: 800, epoch: 6 | loss: 0.0538562\n",
      "\tspeed: 0.0321s/iter; left time: 403.8096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.97s\n",
      "Steps: 893 | Train Loss: 0.0555345 Vali Loss: 0.0563390 Test Loss: 0.0584518\n",
      "Validation loss decreased (0.056632 --> 0.056339).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0592000\n",
      "\tspeed: 0.1181s/iter; left time: 1465.2607s\n",
      "\titers: 200, epoch: 7 | loss: 0.0468877\n",
      "\tspeed: 0.0320s/iter; left time: 393.4702s\n",
      "\titers: 300, epoch: 7 | loss: 0.0500296\n",
      "\tspeed: 0.0320s/iter; left time: 390.3793s\n",
      "\titers: 400, epoch: 7 | loss: 0.0562175\n",
      "\tspeed: 0.0320s/iter; left time: 387.7429s\n",
      "\titers: 500, epoch: 7 | loss: 0.0557143\n",
      "\tspeed: 0.0320s/iter; left time: 384.0983s\n",
      "\titers: 600, epoch: 7 | loss: 0.0483438\n",
      "\tspeed: 0.0320s/iter; left time: 380.8444s\n",
      "\titers: 700, epoch: 7 | loss: 0.0480349\n",
      "\tspeed: 0.0320s/iter; left time: 377.4404s\n",
      "\titers: 800, epoch: 7 | loss: 0.0485173\n",
      "\tspeed: 0.0320s/iter; left time: 374.3436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.81s\n",
      "Steps: 893 | Train Loss: 0.0549359 Vali Loss: 0.0564159 Test Loss: 0.0587591\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0569213\n",
      "\tspeed: 0.1163s/iter; left time: 1338.6984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0541217\n",
      "\tspeed: 0.0320s/iter; left time: 364.9177s\n",
      "\titers: 300, epoch: 8 | loss: 0.0591012\n",
      "\tspeed: 0.0320s/iter; left time: 361.9551s\n",
      "\titers: 400, epoch: 8 | loss: 0.0516266\n",
      "\tspeed: 0.0320s/iter; left time: 358.7691s\n",
      "\titers: 500, epoch: 8 | loss: 0.0558147\n",
      "\tspeed: 0.0320s/iter; left time: 355.5843s\n",
      "\titers: 600, epoch: 8 | loss: 0.0545175\n",
      "\tspeed: 0.0320s/iter; left time: 352.5367s\n",
      "\titers: 700, epoch: 8 | loss: 0.0562759\n",
      "\tspeed: 0.0320s/iter; left time: 349.2711s\n",
      "\titers: 800, epoch: 8 | loss: 0.0484854\n",
      "\tspeed: 0.0320s/iter; left time: 346.1814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 893 | Train Loss: 0.0543694 Vali Loss: 0.0556004 Test Loss: 0.0581308\n",
      "Validation loss decreased (0.056339 --> 0.055600).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0607204\n",
      "\tspeed: 0.1181s/iter; left time: 1254.3330s\n",
      "\titers: 200, epoch: 9 | loss: 0.0595492\n",
      "\tspeed: 0.0320s/iter; left time: 336.5359s\n",
      "\titers: 300, epoch: 9 | loss: 0.0489887\n",
      "\tspeed: 0.0320s/iter; left time: 333.3980s\n",
      "\titers: 400, epoch: 9 | loss: 0.0549300\n",
      "\tspeed: 0.0320s/iter; left time: 330.2512s\n",
      "\titers: 500, epoch: 9 | loss: 0.0506289\n",
      "\tspeed: 0.0320s/iter; left time: 326.9400s\n",
      "\titers: 600, epoch: 9 | loss: 0.0487092\n",
      "\tspeed: 0.0320s/iter; left time: 323.7222s\n",
      "\titers: 700, epoch: 9 | loss: 0.0530170\n",
      "\tspeed: 0.0320s/iter; left time: 320.6540s\n",
      "\titers: 800, epoch: 9 | loss: 0.0479849\n",
      "\tspeed: 0.0320s/iter; left time: 317.2131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.83s\n",
      "Steps: 893 | Train Loss: 0.0540188 Vali Loss: 0.0556905 Test Loss: 0.0580706\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0546215\n",
      "\tspeed: 0.1162s/iter; left time: 1129.6248s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593094\n",
      "\tspeed: 0.0320s/iter; left time: 308.3953s\n",
      "\titers: 300, epoch: 10 | loss: 0.0461410\n",
      "\tspeed: 0.0321s/iter; left time: 305.2944s\n",
      "\titers: 400, epoch: 10 | loss: 0.0552814\n",
      "\tspeed: 0.0321s/iter; left time: 302.2627s\n",
      "\titers: 500, epoch: 10 | loss: 0.0443449\n",
      "\tspeed: 0.0321s/iter; left time: 298.8424s\n",
      "\titers: 600, epoch: 10 | loss: 0.0461320\n",
      "\tspeed: 0.0321s/iter; left time: 295.6434s\n",
      "\titers: 700, epoch: 10 | loss: 0.0505719\n",
      "\tspeed: 0.0320s/iter; left time: 291.8777s\n",
      "\titers: 800, epoch: 10 | loss: 0.0583797\n",
      "\tspeed: 0.0320s/iter; left time: 288.7626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.87s\n",
      "Steps: 893 | Train Loss: 0.0536786 Vali Loss: 0.0553423 Test Loss: 0.0576806\n",
      "Validation loss decreased (0.055600 --> 0.055342).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0529536\n",
      "\tspeed: 0.1172s/iter; left time: 1035.1350s\n",
      "\titers: 200, epoch: 11 | loss: 0.0563764\n",
      "\tspeed: 0.0319s/iter; left time: 278.0871s\n",
      "\titers: 300, epoch: 11 | loss: 0.0495870\n",
      "\tspeed: 0.0319s/iter; left time: 275.0456s\n",
      "\titers: 400, epoch: 11 | loss: 0.0480512\n",
      "\tspeed: 0.0319s/iter; left time: 272.1281s\n",
      "\titers: 500, epoch: 11 | loss: 0.0474665\n",
      "\tspeed: 0.0319s/iter; left time: 268.8204s\n",
      "\titers: 600, epoch: 11 | loss: 0.0454101\n",
      "\tspeed: 0.0319s/iter; left time: 265.5805s\n",
      "\titers: 700, epoch: 11 | loss: 0.0563859\n",
      "\tspeed: 0.0319s/iter; left time: 262.5637s\n",
      "\titers: 800, epoch: 11 | loss: 0.0621537\n",
      "\tspeed: 0.0319s/iter; left time: 258.9813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.70s\n",
      "Steps: 893 | Train Loss: 0.0533083 Vali Loss: 0.0553717 Test Loss: 0.0579627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0555992\n",
      "\tspeed: 0.1150s/iter; left time: 913.1614s\n",
      "\titers: 200, epoch: 12 | loss: 0.0485982\n",
      "\tspeed: 0.0320s/iter; left time: 250.5155s\n",
      "\titers: 300, epoch: 12 | loss: 0.0398637\n",
      "\tspeed: 0.0319s/iter; left time: 246.7140s\n",
      "\titers: 400, epoch: 12 | loss: 0.0551695\n",
      "\tspeed: 0.0319s/iter; left time: 243.6898s\n",
      "\titers: 500, epoch: 12 | loss: 0.0539231\n",
      "\tspeed: 0.0319s/iter; left time: 240.2319s\n",
      "\titers: 600, epoch: 12 | loss: 0.0537585\n",
      "\tspeed: 0.0319s/iter; left time: 237.2466s\n",
      "\titers: 700, epoch: 12 | loss: 0.0543746\n",
      "\tspeed: 0.0319s/iter; left time: 233.9267s\n",
      "\titers: 800, epoch: 12 | loss: 0.0464140\n",
      "\tspeed: 0.0319s/iter; left time: 230.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.70s\n",
      "Steps: 893 | Train Loss: 0.0530599 Vali Loss: 0.0551438 Test Loss: 0.0577086\n",
      "Validation loss decreased (0.055342 --> 0.055144).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0439355\n",
      "\tspeed: 0.1169s/iter; left time: 823.4198s\n",
      "\titers: 200, epoch: 13 | loss: 0.0607473\n",
      "\tspeed: 0.0319s/iter; left time: 221.4836s\n",
      "\titers: 300, epoch: 13 | loss: 0.0480291\n",
      "\tspeed: 0.0319s/iter; left time: 218.1363s\n",
      "\titers: 400, epoch: 13 | loss: 0.0546576\n",
      "\tspeed: 0.0319s/iter; left time: 214.9372s\n",
      "\titers: 500, epoch: 13 | loss: 0.0495851\n",
      "\tspeed: 0.0319s/iter; left time: 211.7106s\n",
      "\titers: 600, epoch: 13 | loss: 0.0553699\n",
      "\tspeed: 0.0318s/iter; left time: 208.4228s\n",
      "\titers: 700, epoch: 13 | loss: 0.0532423\n",
      "\tspeed: 0.0318s/iter; left time: 205.0088s\n",
      "\titers: 800, epoch: 13 | loss: 0.0485364\n",
      "\tspeed: 0.0318s/iter; left time: 201.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.68s\n",
      "Steps: 893 | Train Loss: 0.0527837 Vali Loss: 0.0548424 Test Loss: 0.0574790\n",
      "Validation loss decreased (0.055144 --> 0.054842).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0578485\n",
      "\tspeed: 0.1168s/iter; left time: 718.5613s\n",
      "\titers: 200, epoch: 14 | loss: 0.0608466\n",
      "\tspeed: 0.0319s/iter; left time: 192.8213s\n",
      "\titers: 300, epoch: 14 | loss: 0.0465479\n",
      "\tspeed: 0.0318s/iter; left time: 189.5177s\n",
      "\titers: 400, epoch: 14 | loss: 0.0446369\n",
      "\tspeed: 0.0319s/iter; left time: 186.5497s\n",
      "\titers: 500, epoch: 14 | loss: 0.0486763\n",
      "\tspeed: 0.0319s/iter; left time: 183.3823s\n",
      "\titers: 600, epoch: 14 | loss: 0.0590704\n",
      "\tspeed: 0.0319s/iter; left time: 180.1344s\n",
      "\titers: 700, epoch: 14 | loss: 0.0536866\n",
      "\tspeed: 0.0319s/iter; left time: 176.8548s\n",
      "\titers: 800, epoch: 14 | loss: 0.0446021\n",
      "\tspeed: 0.0319s/iter; left time: 173.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.69s\n",
      "Steps: 893 | Train Loss: 0.0525825 Vali Loss: 0.0549016 Test Loss: 0.0574036\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0499563\n",
      "\tspeed: 0.1152s/iter; left time: 605.5892s\n",
      "\titers: 200, epoch: 15 | loss: 0.0525489\n",
      "\tspeed: 0.0319s/iter; left time: 164.5960s\n",
      "\titers: 300, epoch: 15 | loss: 0.0535203\n",
      "\tspeed: 0.0319s/iter; left time: 161.3864s\n",
      "\titers: 400, epoch: 15 | loss: 0.0556244\n",
      "\tspeed: 0.0319s/iter; left time: 158.2098s\n",
      "\titers: 500, epoch: 15 | loss: 0.0507999\n",
      "\tspeed: 0.0319s/iter; left time: 154.9498s\n",
      "\titers: 600, epoch: 15 | loss: 0.0435700\n",
      "\tspeed: 0.0319s/iter; left time: 151.8810s\n",
      "\titers: 700, epoch: 15 | loss: 0.0557971\n",
      "\tspeed: 0.0319s/iter; left time: 148.6023s\n",
      "\titers: 800, epoch: 15 | loss: 0.0473245\n",
      "\tspeed: 0.0318s/iter; left time: 145.1524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.71s\n",
      "Steps: 893 | Train Loss: 0.0523772 Vali Loss: 0.0548185 Test Loss: 0.0573887\n",
      "Validation loss decreased (0.054842 --> 0.054818).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0577625\n",
      "\tspeed: 0.1165s/iter; left time: 508.7064s\n",
      "\titers: 200, epoch: 16 | loss: 0.0485273\n",
      "\tspeed: 0.0319s/iter; left time: 135.9364s\n",
      "\titers: 300, epoch: 16 | loss: 0.0551425\n",
      "\tspeed: 0.0319s/iter; left time: 132.7404s\n",
      "\titers: 400, epoch: 16 | loss: 0.0554549\n",
      "\tspeed: 0.0319s/iter; left time: 129.5595s\n",
      "\titers: 500, epoch: 16 | loss: 0.0489134\n",
      "\tspeed: 0.0319s/iter; left time: 126.4419s\n",
      "\titers: 600, epoch: 16 | loss: 0.0429672\n",
      "\tspeed: 0.0319s/iter; left time: 123.2449s\n",
      "\titers: 700, epoch: 16 | loss: 0.0637050\n",
      "\tspeed: 0.0319s/iter; left time: 120.1174s\n",
      "\titers: 800, epoch: 16 | loss: 0.0476931\n",
      "\tspeed: 0.0319s/iter; left time: 116.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:28.70s\n",
      "Steps: 893 | Train Loss: 0.0522080 Vali Loss: 0.0547268 Test Loss: 0.0574924\n",
      "Validation loss decreased (0.054818 --> 0.054727).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0609777\n",
      "\tspeed: 0.1163s/iter; left time: 404.0718s\n",
      "\titers: 200, epoch: 17 | loss: 0.0496217\n",
      "\tspeed: 0.0318s/iter; left time: 107.3047s\n",
      "\titers: 300, epoch: 17 | loss: 0.0563878\n",
      "\tspeed: 0.0318s/iter; left time: 103.9884s\n",
      "\titers: 400, epoch: 17 | loss: 0.0563402\n",
      "\tspeed: 0.0318s/iter; left time: 100.9478s\n",
      "\titers: 500, epoch: 17 | loss: 0.0428876\n",
      "\tspeed: 0.0318s/iter; left time: 97.8660s\n",
      "\titers: 600, epoch: 17 | loss: 0.0472717\n",
      "\tspeed: 0.0319s/iter; left time: 94.6920s\n",
      "\titers: 700, epoch: 17 | loss: 0.0525433\n",
      "\tspeed: 0.0319s/iter; left time: 91.5988s\n",
      "\titers: 800, epoch: 17 | loss: 0.0566503\n",
      "\tspeed: 0.0319s/iter; left time: 88.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:28.63s\n",
      "Steps: 893 | Train Loss: 0.0520372 Vali Loss: 0.0546993 Test Loss: 0.0573374\n",
      "Validation loss decreased (0.054727 --> 0.054699).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0516566\n",
      "\tspeed: 0.1165s/iter; left time: 300.4520s\n",
      "\titers: 200, epoch: 18 | loss: 0.0613151\n",
      "\tspeed: 0.0318s/iter; left time: 78.7930s\n",
      "\titers: 300, epoch: 18 | loss: 0.0564447\n",
      "\tspeed: 0.0318s/iter; left time: 75.6536s\n",
      "\titers: 400, epoch: 18 | loss: 0.0540311\n",
      "\tspeed: 0.0318s/iter; left time: 72.4977s\n",
      "\titers: 500, epoch: 18 | loss: 0.0546621\n",
      "\tspeed: 0.0318s/iter; left time: 69.3493s\n",
      "\titers: 600, epoch: 18 | loss: 0.0570106\n",
      "\tspeed: 0.0318s/iter; left time: 66.1645s\n",
      "\titers: 700, epoch: 18 | loss: 0.0541114\n",
      "\tspeed: 0.0318s/iter; left time: 62.9340s\n",
      "\titers: 800, epoch: 18 | loss: 0.0568436\n",
      "\tspeed: 0.0316s/iter; left time: 59.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 893 | Train Loss: 0.0519351 Vali Loss: 0.0545944 Test Loss: 0.0573003\n",
      "Validation loss decreased (0.054699 --> 0.054594).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0487275\n",
      "\tspeed: 0.1167s/iter; left time: 196.8644s\n",
      "\titers: 200, epoch: 19 | loss: 0.0498117\n",
      "\tspeed: 0.0316s/iter; left time: 50.1956s\n",
      "\titers: 300, epoch: 19 | loss: 0.0487178\n",
      "\tspeed: 0.0316s/iter; left time: 46.9857s\n",
      "\titers: 400, epoch: 19 | loss: 0.0574480\n",
      "\tspeed: 0.0316s/iter; left time: 43.8224s\n",
      "\titers: 500, epoch: 19 | loss: 0.0495684\n",
      "\tspeed: 0.0316s/iter; left time: 40.7167s\n",
      "\titers: 600, epoch: 19 | loss: 0.0561406\n",
      "\tspeed: 0.0316s/iter; left time: 37.5495s\n",
      "\titers: 700, epoch: 19 | loss: 0.0589492\n",
      "\tspeed: 0.0317s/iter; left time: 34.4329s\n",
      "\titers: 800, epoch: 19 | loss: 0.0488607\n",
      "\tspeed: 0.0317s/iter; left time: 31.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0518100 Vali Loss: 0.0545022 Test Loss: 0.0572358\n",
      "Validation loss decreased (0.054594 --> 0.054502).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.0604468\n",
      "\tspeed: 0.1150s/iter; left time: 91.2903s\n",
      "\titers: 200, epoch: 20 | loss: 0.0469944\n",
      "\tspeed: 0.0316s/iter; left time: 21.9386s\n",
      "\titers: 300, epoch: 20 | loss: 0.0478415\n",
      "\tspeed: 0.0316s/iter; left time: 18.7971s\n",
      "\titers: 400, epoch: 20 | loss: 0.0468567\n",
      "\tspeed: 0.0316s/iter; left time: 15.6289s\n",
      "\titers: 500, epoch: 20 | loss: 0.0591532\n",
      "\tspeed: 0.0317s/iter; left time: 12.4793s\n",
      "\titers: 600, epoch: 20 | loss: 0.0565805\n",
      "\tspeed: 0.0317s/iter; left time: 9.3182s\n",
      "\titers: 700, epoch: 20 | loss: 0.0523300\n",
      "\tspeed: 0.0317s/iter; left time: 6.1421s\n",
      "\titers: 800, epoch: 20 | loss: 0.0513932\n",
      "\tspeed: 0.0317s/iter; left time: 2.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 893 | Train Loss: 0.0516801 Vali Loss: 0.0542840 Test Loss: 0.0571518\n",
      "Validation loss decreased (0.054502 --> 0.054284).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010166891850531101, rmse:0.10083100944757462, mae:0.05715181678533554, rse:0.38104739785194397\n",
      "Original data scale mse:1196659.25, rmse:1093.919189453125, mae:676.91748046875, rse:0.07687228173017502\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1530644\n",
      "\tspeed: 0.0337s/iter; left time: 598.4109s\n",
      "\titers: 200, epoch: 1 | loss: 0.1248067\n",
      "\tspeed: 0.0317s/iter; left time: 559.0304s\n",
      "\titers: 300, epoch: 1 | loss: 0.1121699\n",
      "\tspeed: 0.0317s/iter; left time: 555.9142s\n",
      "\titers: 400, epoch: 1 | loss: 0.0974499\n",
      "\tspeed: 0.0317s/iter; left time: 553.3026s\n",
      "\titers: 500, epoch: 1 | loss: 0.1095749\n",
      "\tspeed: 0.0317s/iter; left time: 550.3145s\n",
      "\titers: 600, epoch: 1 | loss: 0.1001980\n",
      "\tspeed: 0.0317s/iter; left time: 547.0753s\n",
      "\titers: 700, epoch: 1 | loss: 0.0927407\n",
      "\tspeed: 0.0317s/iter; left time: 544.4625s\n",
      "\titers: 800, epoch: 1 | loss: 0.0883151\n",
      "\tspeed: 0.0317s/iter; left time: 541.1222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.53s\n",
      "Steps: 893 | Train Loss: 0.1147380 Vali Loss: 0.0878876 Test Loss: 0.0894936\n",
      "Validation loss decreased (inf --> 0.087888).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0783412\n",
      "\tspeed: 0.1161s/iter; left time: 1958.5566s\n",
      "\titers: 200, epoch: 2 | loss: 0.0728582\n",
      "\tspeed: 0.0317s/iter; left time: 530.9035s\n",
      "\titers: 300, epoch: 2 | loss: 0.0685469\n",
      "\tspeed: 0.0317s/iter; left time: 527.7803s\n",
      "\titers: 400, epoch: 2 | loss: 0.0588514\n",
      "\tspeed: 0.0317s/iter; left time: 524.4508s\n",
      "\titers: 500, epoch: 2 | loss: 0.0626258\n",
      "\tspeed: 0.0317s/iter; left time: 521.3805s\n",
      "\titers: 600, epoch: 2 | loss: 0.0557770\n",
      "\tspeed: 0.0317s/iter; left time: 518.1010s\n",
      "\titers: 700, epoch: 2 | loss: 0.0700099\n",
      "\tspeed: 0.0317s/iter; left time: 515.6005s\n",
      "\titers: 800, epoch: 2 | loss: 0.0640069\n",
      "\tspeed: 0.0316s/iter; left time: 511.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.53s\n",
      "Steps: 893 | Train Loss: 0.0661613 Vali Loss: 0.0599890 Test Loss: 0.0625691\n",
      "Validation loss decreased (0.087888 --> 0.059989).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0540088\n",
      "\tspeed: 0.1156s/iter; left time: 1846.2257s\n",
      "\titers: 200, epoch: 3 | loss: 0.0572548\n",
      "\tspeed: 0.0317s/iter; left time: 502.6856s\n",
      "\titers: 300, epoch: 3 | loss: 0.0579125\n",
      "\tspeed: 0.0316s/iter; left time: 498.9037s\n",
      "\titers: 400, epoch: 3 | loss: 0.0539823\n",
      "\tspeed: 0.0317s/iter; left time: 497.1631s\n",
      "\titers: 500, epoch: 3 | loss: 0.0617964\n",
      "\tspeed: 0.0317s/iter; left time: 493.7085s\n",
      "\titers: 600, epoch: 3 | loss: 0.0566095\n",
      "\tspeed: 0.0317s/iter; left time: 490.3633s\n",
      "\titers: 700, epoch: 3 | loss: 0.0552075\n",
      "\tspeed: 0.0317s/iter; left time: 487.0128s\n",
      "\titers: 800, epoch: 3 | loss: 0.0596447\n",
      "\tspeed: 0.0317s/iter; left time: 484.2171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.53s\n",
      "Steps: 893 | Train Loss: 0.0591828 Vali Loss: 0.0582748 Test Loss: 0.0607831\n",
      "Validation loss decreased (0.059989 --> 0.058275).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0601238\n",
      "\tspeed: 0.1164s/iter; left time: 1755.7000s\n",
      "\titers: 200, epoch: 4 | loss: 0.0558188\n",
      "\tspeed: 0.0317s/iter; left time: 474.9532s\n",
      "\titers: 300, epoch: 4 | loss: 0.0606261\n",
      "\tspeed: 0.0317s/iter; left time: 471.2362s\n",
      "\titers: 400, epoch: 4 | loss: 0.0613147\n",
      "\tspeed: 0.0317s/iter; left time: 468.1209s\n",
      "\titers: 500, epoch: 4 | loss: 0.0555380\n",
      "\tspeed: 0.0317s/iter; left time: 465.2172s\n",
      "\titers: 600, epoch: 4 | loss: 0.0514033\n",
      "\tspeed: 0.0317s/iter; left time: 461.9630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0520613\n",
      "\tspeed: 0.0316s/iter; left time: 458.2358s\n",
      "\titers: 800, epoch: 4 | loss: 0.0595150\n",
      "\tspeed: 0.0316s/iter; left time: 455.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0573982 Vali Loss: 0.0573497 Test Loss: 0.0601471\n",
      "Validation loss decreased (0.058275 --> 0.057350).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0569732\n",
      "\tspeed: 0.1157s/iter; left time: 1641.8307s\n",
      "\titers: 200, epoch: 5 | loss: 0.0490837\n",
      "\tspeed: 0.0317s/iter; left time: 446.1737s\n",
      "\titers: 300, epoch: 5 | loss: 0.0571303\n",
      "\tspeed: 0.0317s/iter; left time: 443.0459s\n",
      "\titers: 400, epoch: 5 | loss: 0.0553484\n",
      "\tspeed: 0.0317s/iter; left time: 440.2804s\n",
      "\titers: 500, epoch: 5 | loss: 0.0531825\n",
      "\tspeed: 0.0316s/iter; left time: 436.3544s\n",
      "\titers: 600, epoch: 5 | loss: 0.0492879\n",
      "\tspeed: 0.0316s/iter; left time: 433.1128s\n",
      "\titers: 700, epoch: 5 | loss: 0.0537311\n",
      "\tspeed: 0.0317s/iter; left time: 430.9490s\n",
      "\titers: 800, epoch: 5 | loss: 0.0534670\n",
      "\tspeed: 0.0316s/iter; left time: 426.8666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0562569 Vali Loss: 0.0565555 Test Loss: 0.0589671\n",
      "Validation loss decreased (0.057350 --> 0.056555).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0642670\n",
      "\tspeed: 0.1154s/iter; left time: 1534.6178s\n",
      "\titers: 200, epoch: 6 | loss: 0.0525373\n",
      "\tspeed: 0.0317s/iter; left time: 418.6429s\n",
      "\titers: 300, epoch: 6 | loss: 0.0627915\n",
      "\tspeed: 0.0317s/iter; left time: 415.1202s\n",
      "\titers: 400, epoch: 6 | loss: 0.0519940\n",
      "\tspeed: 0.0317s/iter; left time: 411.8092s\n",
      "\titers: 500, epoch: 6 | loss: 0.0520216\n",
      "\tspeed: 0.0317s/iter; left time: 409.1932s\n",
      "\titers: 600, epoch: 6 | loss: 0.0559841\n",
      "\tspeed: 0.0317s/iter; left time: 405.4705s\n",
      "\titers: 700, epoch: 6 | loss: 0.0566013\n",
      "\tspeed: 0.0317s/iter; left time: 402.3716s\n",
      "\titers: 800, epoch: 6 | loss: 0.0502800\n",
      "\tspeed: 0.0317s/iter; left time: 399.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.54s\n",
      "Steps: 893 | Train Loss: 0.0555206 Vali Loss: 0.0568789 Test Loss: 0.0598070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0488507\n",
      "\tspeed: 0.1143s/iter; left time: 1418.0501s\n",
      "\titers: 200, epoch: 7 | loss: 0.0509715\n",
      "\tspeed: 0.0316s/iter; left time: 389.3726s\n",
      "\titers: 300, epoch: 7 | loss: 0.0502074\n",
      "\tspeed: 0.0316s/iter; left time: 385.9693s\n",
      "\titers: 400, epoch: 7 | loss: 0.0518641\n",
      "\tspeed: 0.0317s/iter; left time: 383.2472s\n",
      "\titers: 500, epoch: 7 | loss: 0.0660093\n",
      "\tspeed: 0.0317s/iter; left time: 380.7917s\n",
      "\titers: 600, epoch: 7 | loss: 0.0625052\n",
      "\tspeed: 0.0317s/iter; left time: 377.0104s\n",
      "\titers: 700, epoch: 7 | loss: 0.0566493\n",
      "\tspeed: 0.0317s/iter; left time: 373.7307s\n",
      "\titers: 800, epoch: 7 | loss: 0.0581811\n",
      "\tspeed: 0.0317s/iter; left time: 370.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.51s\n",
      "Steps: 893 | Train Loss: 0.0549136 Vali Loss: 0.0562174 Test Loss: 0.0587518\n",
      "Validation loss decreased (0.056555 --> 0.056217).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0481787\n",
      "\tspeed: 0.1160s/iter; left time: 1335.6295s\n",
      "\titers: 200, epoch: 8 | loss: 0.0631344\n",
      "\tspeed: 0.0317s/iter; left time: 361.2909s\n",
      "\titers: 300, epoch: 8 | loss: 0.0476044\n",
      "\tspeed: 0.0316s/iter; left time: 357.9267s\n",
      "\titers: 400, epoch: 8 | loss: 0.0505641\n",
      "\tspeed: 0.0316s/iter; left time: 354.5883s\n",
      "\titers: 500, epoch: 8 | loss: 0.0549959\n",
      "\tspeed: 0.0316s/iter; left time: 351.6130s\n",
      "\titers: 600, epoch: 8 | loss: 0.0504642\n",
      "\tspeed: 0.0317s/iter; left time: 348.7046s\n",
      "\titers: 700, epoch: 8 | loss: 0.0559987\n",
      "\tspeed: 0.0317s/iter; left time: 345.7448s\n",
      "\titers: 800, epoch: 8 | loss: 0.0595698\n",
      "\tspeed: 0.0317s/iter; left time: 342.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.0543635 Vali Loss: 0.0557824 Test Loss: 0.0587428\n",
      "Validation loss decreased (0.056217 --> 0.055782).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0601407\n",
      "\tspeed: 0.1160s/iter; left time: 1231.9150s\n",
      "\titers: 200, epoch: 9 | loss: 0.0517798\n",
      "\tspeed: 0.0317s/iter; left time: 333.0356s\n",
      "\titers: 300, epoch: 9 | loss: 0.0494942\n",
      "\tspeed: 0.0317s/iter; left time: 330.1432s\n",
      "\titers: 400, epoch: 9 | loss: 0.0585102\n",
      "\tspeed: 0.0317s/iter; left time: 326.9064s\n",
      "\titers: 500, epoch: 9 | loss: 0.0491031\n",
      "\tspeed: 0.0317s/iter; left time: 324.0056s\n",
      "\titers: 600, epoch: 9 | loss: 0.0555107\n",
      "\tspeed: 0.0317s/iter; left time: 320.7779s\n",
      "\titers: 700, epoch: 9 | loss: 0.0475208\n",
      "\tspeed: 0.0317s/iter; left time: 317.6854s\n",
      "\titers: 800, epoch: 9 | loss: 0.0584571\n",
      "\tspeed: 0.0318s/iter; left time: 315.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.59s\n",
      "Steps: 893 | Train Loss: 0.0539862 Vali Loss: 0.0552973 Test Loss: 0.0579934\n",
      "Validation loss decreased (0.055782 --> 0.055297).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0537014\n",
      "\tspeed: 0.1156s/iter; left time: 1124.0223s\n",
      "\titers: 200, epoch: 10 | loss: 0.0512148\n",
      "\tspeed: 0.0317s/iter; left time: 304.6530s\n",
      "\titers: 300, epoch: 10 | loss: 0.0518603\n",
      "\tspeed: 0.0317s/iter; left time: 301.8601s\n",
      "\titers: 400, epoch: 10 | loss: 0.0459506\n",
      "\tspeed: 0.0317s/iter; left time: 298.3058s\n",
      "\titers: 500, epoch: 10 | loss: 0.0620870\n",
      "\tspeed: 0.0316s/iter; left time: 295.1021s\n",
      "\titers: 600, epoch: 10 | loss: 0.0621841\n",
      "\tspeed: 0.0317s/iter; left time: 292.2825s\n",
      "\titers: 700, epoch: 10 | loss: 0.0480739\n",
      "\tspeed: 0.0317s/iter; left time: 289.2234s\n",
      "\titers: 800, epoch: 10 | loss: 0.0441202\n",
      "\tspeed: 0.0317s/iter; left time: 286.1647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.51s\n",
      "Steps: 893 | Train Loss: 0.0536182 Vali Loss: 0.0558874 Test Loss: 0.0585141\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0458997\n",
      "\tspeed: 0.1142s/iter; left time: 1008.5496s\n",
      "\titers: 200, epoch: 11 | loss: 0.0564200\n",
      "\tspeed: 0.0317s/iter; left time: 276.6087s\n",
      "\titers: 300, epoch: 11 | loss: 0.0556660\n",
      "\tspeed: 0.0317s/iter; left time: 273.7020s\n",
      "\titers: 400, epoch: 11 | loss: 0.0449018\n",
      "\tspeed: 0.0317s/iter; left time: 270.3734s\n",
      "\titers: 500, epoch: 11 | loss: 0.0544155\n",
      "\tspeed: 0.0317s/iter; left time: 267.0751s\n",
      "\titers: 600, epoch: 11 | loss: 0.0600459\n",
      "\tspeed: 0.0317s/iter; left time: 264.4513s\n",
      "\titers: 700, epoch: 11 | loss: 0.0600340\n",
      "\tspeed: 0.0317s/iter; left time: 260.8335s\n",
      "\titers: 800, epoch: 11 | loss: 0.0588873\n",
      "\tspeed: 0.0317s/iter; left time: 257.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.55s\n",
      "Steps: 893 | Train Loss: 0.0533005 Vali Loss: 0.0552336 Test Loss: 0.0581039\n",
      "Validation loss decreased (0.055297 --> 0.055234).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0560315\n",
      "\tspeed: 0.1157s/iter; left time: 918.4788s\n",
      "\titers: 200, epoch: 12 | loss: 0.0500063\n",
      "\tspeed: 0.0316s/iter; left time: 248.0529s\n",
      "\titers: 300, epoch: 12 | loss: 0.0476595\n",
      "\tspeed: 0.0317s/iter; left time: 245.0719s\n",
      "\titers: 400, epoch: 12 | loss: 0.0457840\n",
      "\tspeed: 0.0317s/iter; left time: 242.1645s\n",
      "\titers: 500, epoch: 12 | loss: 0.0549216\n",
      "\tspeed: 0.0317s/iter; left time: 239.0137s\n",
      "\titers: 600, epoch: 12 | loss: 0.0564722\n",
      "\tspeed: 0.0317s/iter; left time: 235.7189s\n",
      "\titers: 700, epoch: 12 | loss: 0.0553479\n",
      "\tspeed: 0.0317s/iter; left time: 232.4909s\n",
      "\titers: 800, epoch: 12 | loss: 0.0572935\n",
      "\tspeed: 0.0317s/iter; left time: 229.2414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 893 | Train Loss: 0.0530132 Vali Loss: 0.0549970 Test Loss: 0.0580000\n",
      "Validation loss decreased (0.055234 --> 0.054997).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0552538\n",
      "\tspeed: 0.1190s/iter; left time: 838.2545s\n",
      "\titers: 200, epoch: 13 | loss: 0.0563544\n",
      "\tspeed: 0.0316s/iter; left time: 219.7428s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545805\n",
      "\tspeed: 0.0317s/iter; left time: 216.6729s\n",
      "\titers: 400, epoch: 13 | loss: 0.0483967\n",
      "\tspeed: 0.0317s/iter; left time: 213.5421s\n",
      "\titers: 500, epoch: 13 | loss: 0.0497442\n",
      "\tspeed: 0.0316s/iter; left time: 210.1617s\n",
      "\titers: 600, epoch: 13 | loss: 0.0513910\n",
      "\tspeed: 0.0316s/iter; left time: 207.1262s\n",
      "\titers: 700, epoch: 13 | loss: 0.0480220\n",
      "\tspeed: 0.0316s/iter; left time: 203.8694s\n",
      "\titers: 800, epoch: 13 | loss: 0.0591657\n",
      "\tspeed: 0.0316s/iter; left time: 200.6654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.47s\n",
      "Steps: 893 | Train Loss: 0.0528175 Vali Loss: 0.0552367 Test Loss: 0.0579756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0538010\n",
      "\tspeed: 0.1143s/iter; left time: 703.3176s\n",
      "\titers: 200, epoch: 14 | loss: 0.0547781\n",
      "\tspeed: 0.0316s/iter; left time: 191.4220s\n",
      "\titers: 300, epoch: 14 | loss: 0.0588153\n",
      "\tspeed: 0.0316s/iter; left time: 188.1838s\n",
      "\titers: 400, epoch: 14 | loss: 0.0529765\n",
      "\tspeed: 0.0316s/iter; left time: 185.0889s\n",
      "\titers: 500, epoch: 14 | loss: 0.0489814\n",
      "\tspeed: 0.0316s/iter; left time: 181.9407s\n",
      "\titers: 600, epoch: 14 | loss: 0.0527463\n",
      "\tspeed: 0.0317s/iter; left time: 178.9206s\n",
      "\titers: 700, epoch: 14 | loss: 0.0536936\n",
      "\tspeed: 0.0316s/iter; left time: 175.6404s\n",
      "\titers: 800, epoch: 14 | loss: 0.0498539\n",
      "\tspeed: 0.0316s/iter; left time: 172.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 893 | Train Loss: 0.0526164 Vali Loss: 0.0553223 Test Loss: 0.0577008\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0443645\n",
      "\tspeed: 0.1137s/iter; left time: 598.0098s\n",
      "\titers: 200, epoch: 15 | loss: 0.0527491\n",
      "\tspeed: 0.0316s/iter; left time: 163.2277s\n",
      "\titers: 300, epoch: 15 | loss: 0.0563961\n",
      "\tspeed: 0.0317s/iter; left time: 160.1359s\n",
      "\titers: 400, epoch: 15 | loss: 0.0509817\n",
      "\tspeed: 0.0316s/iter; left time: 156.9023s\n",
      "\titers: 500, epoch: 15 | loss: 0.0523592\n",
      "\tspeed: 0.0316s/iter; left time: 153.5871s\n",
      "\titers: 600, epoch: 15 | loss: 0.0610511\n",
      "\tspeed: 0.0316s/iter; left time: 150.4961s\n",
      "\titers: 700, epoch: 15 | loss: 0.0573445\n",
      "\tspeed: 0.0316s/iter; left time: 147.2766s\n",
      "\titers: 800, epoch: 15 | loss: 0.0476752\n",
      "\tspeed: 0.0316s/iter; left time: 144.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.47s\n",
      "Steps: 893 | Train Loss: 0.0524114 Vali Loss: 0.0550195 Test Loss: 0.0577323\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010372006334364414, rmse:0.10184304416179657, mae:0.05799999460577965, rse:0.3848719894886017\n",
      "Original data scale mse:1235584.125, rmse:1111.568359375, mae:693.6527709960938, rse:0.07811252772808075\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1635460\n",
      "\tspeed: 0.0493s/iter; left time: 872.8886s\n",
      "\titers: 200, epoch: 1 | loss: 0.1319113\n",
      "\tspeed: 0.0321s/iter; left time: 566.3102s\n",
      "\titers: 300, epoch: 1 | loss: 0.1235225\n",
      "\tspeed: 0.0321s/iter; left time: 562.6104s\n",
      "\titers: 400, epoch: 1 | loss: 0.1074541\n",
      "\tspeed: 0.0322s/iter; left time: 560.3082s\n",
      "\titers: 500, epoch: 1 | loss: 0.1047846\n",
      "\tspeed: 0.0322s/iter; left time: 556.9614s\n",
      "\titers: 600, epoch: 1 | loss: 0.1106790\n",
      "\tspeed: 0.0322s/iter; left time: 553.9962s\n",
      "\titers: 700, epoch: 1 | loss: 0.0991670\n",
      "\tspeed: 0.0322s/iter; left time: 551.3513s\n",
      "\titers: 800, epoch: 1 | loss: 0.1010794\n",
      "\tspeed: 0.0322s/iter; left time: 547.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.12s\n",
      "Steps: 891 | Train Loss: 0.1220934 Vali Loss: 0.0974296 Test Loss: 0.0991974\n",
      "Validation loss decreased (inf --> 0.097430).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0930815\n",
      "\tspeed: 0.1154s/iter; left time: 1942.5798s\n",
      "\titers: 200, epoch: 2 | loss: 0.0785111\n",
      "\tspeed: 0.0322s/iter; left time: 538.5078s\n",
      "\titers: 300, epoch: 2 | loss: 0.0848486\n",
      "\tspeed: 0.0322s/iter; left time: 534.7705s\n",
      "\titers: 400, epoch: 2 | loss: 0.0794810\n",
      "\tspeed: 0.0321s/iter; left time: 531.2224s\n",
      "\titers: 500, epoch: 2 | loss: 0.0793102\n",
      "\tspeed: 0.0321s/iter; left time: 527.7847s\n",
      "\titers: 600, epoch: 2 | loss: 0.0806319\n",
      "\tspeed: 0.0321s/iter; left time: 524.6580s\n",
      "\titers: 700, epoch: 2 | loss: 0.0892102\n",
      "\tspeed: 0.0321s/iter; left time: 521.3390s\n",
      "\titers: 800, epoch: 2 | loss: 0.0817222\n",
      "\tspeed: 0.0322s/iter; left time: 519.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 891 | Train Loss: 0.0857673 Vali Loss: 0.0805228 Test Loss: 0.0837944\n",
      "Validation loss decreased (0.097430 --> 0.080523).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0827389\n",
      "\tspeed: 0.1162s/iter; left time: 1851.8689s\n",
      "\titers: 200, epoch: 3 | loss: 0.0780932\n",
      "\tspeed: 0.0322s/iter; left time: 509.5304s\n",
      "\titers: 300, epoch: 3 | loss: 0.0749602\n",
      "\tspeed: 0.0322s/iter; left time: 506.4683s\n",
      "\titers: 400, epoch: 3 | loss: 0.0770017\n",
      "\tspeed: 0.0322s/iter; left time: 503.2300s\n",
      "\titers: 500, epoch: 3 | loss: 0.0828261\n",
      "\tspeed: 0.0322s/iter; left time: 500.0412s\n",
      "\titers: 600, epoch: 3 | loss: 0.0764043\n",
      "\tspeed: 0.0322s/iter; left time: 497.4495s\n",
      "\titers: 700, epoch: 3 | loss: 0.0824134\n",
      "\tspeed: 0.0322s/iter; left time: 493.5832s\n",
      "\titers: 800, epoch: 3 | loss: 0.0690836\n",
      "\tspeed: 0.0322s/iter; left time: 490.6714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 891 | Train Loss: 0.0790134 Vali Loss: 0.0786700 Test Loss: 0.0829957\n",
      "Validation loss decreased (0.080523 --> 0.078670).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0869404\n",
      "\tspeed: 0.1170s/iter; left time: 1760.4509s\n",
      "\titers: 200, epoch: 4 | loss: 0.0800638\n",
      "\tspeed: 0.0322s/iter; left time: 480.6797s\n",
      "\titers: 300, epoch: 4 | loss: 0.0835132\n",
      "\tspeed: 0.0322s/iter; left time: 478.1886s\n",
      "\titers: 400, epoch: 4 | loss: 0.0838140\n",
      "\tspeed: 0.0322s/iter; left time: 475.4807s\n",
      "\titers: 500, epoch: 4 | loss: 0.0843648\n",
      "\tspeed: 0.0322s/iter; left time: 471.8583s\n",
      "\titers: 600, epoch: 4 | loss: 0.0804754\n",
      "\tspeed: 0.0322s/iter; left time: 467.7970s\n",
      "\titers: 700, epoch: 4 | loss: 0.0765524\n",
      "\tspeed: 0.0323s/iter; left time: 466.3906s\n",
      "\titers: 800, epoch: 4 | loss: 0.0763200\n",
      "\tspeed: 0.0322s/iter; left time: 461.8430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.94s\n",
      "Steps: 891 | Train Loss: 0.0771770 Vali Loss: 0.0786550 Test Loss: 0.0828287\n",
      "Validation loss decreased (0.078670 --> 0.078655).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0766361\n",
      "\tspeed: 0.1161s/iter; left time: 1643.4185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0842137\n",
      "\tspeed: 0.0322s/iter; left time: 452.1778s\n",
      "\titers: 300, epoch: 5 | loss: 0.0804004\n",
      "\tspeed: 0.0322s/iter; left time: 448.8838s\n",
      "\titers: 400, epoch: 5 | loss: 0.0752303\n",
      "\tspeed: 0.0321s/iter; left time: 445.4589s\n",
      "\titers: 500, epoch: 5 | loss: 0.0730966\n",
      "\tspeed: 0.0322s/iter; left time: 442.6524s\n",
      "\titers: 600, epoch: 5 | loss: 0.0808004\n",
      "\tspeed: 0.0321s/iter; left time: 438.9825s\n",
      "\titers: 700, epoch: 5 | loss: 0.0692103\n",
      "\tspeed: 0.0322s/iter; left time: 435.9174s\n",
      "\titers: 800, epoch: 5 | loss: 0.0729667\n",
      "\tspeed: 0.0321s/iter; left time: 432.5703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 891 | Train Loss: 0.0757467 Vali Loss: 0.0779766 Test Loss: 0.0821475\n",
      "Validation loss decreased (0.078655 --> 0.077977).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0794582\n",
      "\tspeed: 0.1196s/iter; left time: 1586.0854s\n",
      "\titers: 200, epoch: 6 | loss: 0.0742182\n",
      "\tspeed: 0.0322s/iter; left time: 423.3052s\n",
      "\titers: 300, epoch: 6 | loss: 0.0680513\n",
      "\tspeed: 0.0322s/iter; left time: 420.0891s\n",
      "\titers: 400, epoch: 6 | loss: 0.0817684\n",
      "\tspeed: 0.0322s/iter; left time: 416.8804s\n",
      "\titers: 500, epoch: 6 | loss: 0.0715715\n",
      "\tspeed: 0.0322s/iter; left time: 413.8989s\n",
      "\titers: 600, epoch: 6 | loss: 0.0667566\n",
      "\tspeed: 0.0322s/iter; left time: 410.9577s\n",
      "\titers: 700, epoch: 6 | loss: 0.0734037\n",
      "\tspeed: 0.0322s/iter; left time: 407.7311s\n",
      "\titers: 800, epoch: 6 | loss: 0.0783387\n",
      "\tspeed: 0.0322s/iter; left time: 404.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.86s\n",
      "Steps: 891 | Train Loss: 0.0746000 Vali Loss: 0.0783727 Test Loss: 0.0826770\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0710132\n",
      "\tspeed: 0.1145s/iter; left time: 1416.6369s\n",
      "\titers: 200, epoch: 7 | loss: 0.0661061\n",
      "\tspeed: 0.0322s/iter; left time: 395.2192s\n",
      "\titers: 300, epoch: 7 | loss: 0.0766860\n",
      "\tspeed: 0.0322s/iter; left time: 391.7956s\n",
      "\titers: 400, epoch: 7 | loss: 0.0687478\n",
      "\tspeed: 0.0322s/iter; left time: 388.6955s\n",
      "\titers: 500, epoch: 7 | loss: 0.0712528\n",
      "\tspeed: 0.0322s/iter; left time: 385.6273s\n",
      "\titers: 600, epoch: 7 | loss: 0.0673774\n",
      "\tspeed: 0.0322s/iter; left time: 382.5288s\n",
      "\titers: 700, epoch: 7 | loss: 0.0765369\n",
      "\tspeed: 0.0322s/iter; left time: 379.2761s\n",
      "\titers: 800, epoch: 7 | loss: 0.0803387\n",
      "\tspeed: 0.0322s/iter; left time: 375.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.91s\n",
      "Steps: 891 | Train Loss: 0.0737328 Vali Loss: 0.0786801 Test Loss: 0.0828835\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0633661\n",
      "\tspeed: 0.1141s/iter; left time: 1310.3476s\n",
      "\titers: 200, epoch: 8 | loss: 0.0751442\n",
      "\tspeed: 0.0321s/iter; left time: 365.2662s\n",
      "\titers: 300, epoch: 8 | loss: 0.0601018\n",
      "\tspeed: 0.0321s/iter; left time: 362.1153s\n",
      "\titers: 400, epoch: 8 | loss: 0.0766440\n",
      "\tspeed: 0.0322s/iter; left time: 359.9807s\n",
      "\titers: 500, epoch: 8 | loss: 0.0723504\n",
      "\tspeed: 0.0322s/iter; left time: 356.6096s\n",
      "\titers: 600, epoch: 8 | loss: 0.0723612\n",
      "\tspeed: 0.0321s/iter; left time: 352.9792s\n",
      "\titers: 700, epoch: 8 | loss: 0.0695816\n",
      "\tspeed: 0.0322s/iter; left time: 350.8011s\n",
      "\titers: 800, epoch: 8 | loss: 0.0651355\n",
      "\tspeed: 0.0322s/iter; left time: 347.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 891 | Train Loss: 0.0728930 Vali Loss: 0.0785803 Test Loss: 0.0836746\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01838119514286518, rmse:0.1355772614479065, mae:0.08214754611253738, rse:0.5126322507858276\n",
      "Original data scale mse:2641473.75, rmse:1625.2611083984375, mae:1033.895751953125, rse:0.1143762618303299\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1547112\n",
      "\tspeed: 0.0344s/iter; left time: 608.7855s\n",
      "\titers: 200, epoch: 1 | loss: 0.1280472\n",
      "\tspeed: 0.0322s/iter; left time: 566.5224s\n",
      "\titers: 300, epoch: 1 | loss: 0.1204491\n",
      "\tspeed: 0.0321s/iter; left time: 563.1400s\n",
      "\titers: 400, epoch: 1 | loss: 0.1118644\n",
      "\tspeed: 0.0322s/iter; left time: 560.2635s\n",
      "\titers: 500, epoch: 1 | loss: 0.1065348\n",
      "\tspeed: 0.0322s/iter; left time: 557.1142s\n",
      "\titers: 600, epoch: 1 | loss: 0.1089516\n",
      "\tspeed: 0.0322s/iter; left time: 553.9533s\n",
      "\titers: 700, epoch: 1 | loss: 0.1064132\n",
      "\tspeed: 0.0322s/iter; left time: 550.6247s\n",
      "\titers: 800, epoch: 1 | loss: 0.1001407\n",
      "\tspeed: 0.0322s/iter; left time: 547.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 891 | Train Loss: 0.1224019 Vali Loss: 0.0981979 Test Loss: 0.0998905\n",
      "Validation loss decreased (inf --> 0.098198).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0878798\n",
      "\tspeed: 0.1174s/iter; left time: 1975.0078s\n",
      "\titers: 200, epoch: 2 | loss: 0.0957149\n",
      "\tspeed: 0.0321s/iter; left time: 537.3320s\n",
      "\titers: 300, epoch: 2 | loss: 0.0850085\n",
      "\tspeed: 0.0322s/iter; left time: 534.9514s\n",
      "\titers: 400, epoch: 2 | loss: 0.0845953\n",
      "\tspeed: 0.0321s/iter; left time: 531.3250s\n",
      "\titers: 500, epoch: 2 | loss: 0.0841834\n",
      "\tspeed: 0.0322s/iter; left time: 528.4448s\n",
      "\titers: 600, epoch: 2 | loss: 0.0822675\n",
      "\tspeed: 0.0322s/iter; left time: 525.0448s\n",
      "\titers: 700, epoch: 2 | loss: 0.0812373\n",
      "\tspeed: 0.0322s/iter; left time: 521.8112s\n",
      "\titers: 800, epoch: 2 | loss: 0.0873618\n",
      "\tspeed: 0.0322s/iter; left time: 518.6694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.86s\n",
      "Steps: 891 | Train Loss: 0.0857850 Vali Loss: 0.0801846 Test Loss: 0.0838236\n",
      "Validation loss decreased (0.098198 --> 0.080185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0805373\n",
      "\tspeed: 0.1167s/iter; left time: 1860.0739s\n",
      "\titers: 200, epoch: 3 | loss: 0.0746611\n",
      "\tspeed: 0.0321s/iter; left time: 508.8456s\n",
      "\titers: 300, epoch: 3 | loss: 0.0728470\n",
      "\tspeed: 0.0322s/iter; left time: 506.4939s\n",
      "\titers: 400, epoch: 3 | loss: 0.0809420\n",
      "\tspeed: 0.0321s/iter; left time: 502.7689s\n",
      "\titers: 500, epoch: 3 | loss: 0.0790712\n",
      "\tspeed: 0.0322s/iter; left time: 499.8178s\n",
      "\titers: 600, epoch: 3 | loss: 0.0757625\n",
      "\tspeed: 0.0321s/iter; left time: 496.3517s\n",
      "\titers: 700, epoch: 3 | loss: 0.0846543\n",
      "\tspeed: 0.0322s/iter; left time: 493.6579s\n",
      "\titers: 800, epoch: 3 | loss: 0.0802295\n",
      "\tspeed: 0.0322s/iter; left time: 490.1989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.90s\n",
      "Steps: 891 | Train Loss: 0.0791570 Vali Loss: 0.0798923 Test Loss: 0.0834251\n",
      "Validation loss decreased (0.080185 --> 0.079892).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0735692\n",
      "\tspeed: 0.1164s/iter; left time: 1752.1211s\n",
      "\titers: 200, epoch: 4 | loss: 0.0747815\n",
      "\tspeed: 0.0322s/iter; left time: 480.6505s\n",
      "\titers: 300, epoch: 4 | loss: 0.0702831\n",
      "\tspeed: 0.0322s/iter; left time: 477.6870s\n",
      "\titers: 400, epoch: 4 | loss: 0.0718620\n",
      "\tspeed: 0.0321s/iter; left time: 474.1330s\n",
      "\titers: 500, epoch: 4 | loss: 0.0753139\n",
      "\tspeed: 0.0322s/iter; left time: 471.3386s\n",
      "\titers: 600, epoch: 4 | loss: 0.0865133\n",
      "\tspeed: 0.0322s/iter; left time: 467.7340s\n",
      "\titers: 700, epoch: 4 | loss: 0.0705245\n",
      "\tspeed: 0.0322s/iter; left time: 464.9650s\n",
      "\titers: 800, epoch: 4 | loss: 0.0742623\n",
      "\tspeed: 0.0322s/iter; left time: 461.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 891 | Train Loss: 0.0773609 Vali Loss: 0.0792520 Test Loss: 0.0823785\n",
      "Validation loss decreased (0.079892 --> 0.079252).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0693293\n",
      "\tspeed: 0.1164s/iter; left time: 1647.4232s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765075\n",
      "\tspeed: 0.0322s/iter; left time: 452.0217s\n",
      "\titers: 300, epoch: 5 | loss: 0.0900125\n",
      "\tspeed: 0.0322s/iter; left time: 449.3900s\n",
      "\titers: 400, epoch: 5 | loss: 0.0886278\n",
      "\tspeed: 0.0322s/iter; left time: 445.9121s\n",
      "\titers: 500, epoch: 5 | loss: 0.0804177\n",
      "\tspeed: 0.0322s/iter; left time: 442.4622s\n",
      "\titers: 600, epoch: 5 | loss: 0.0815467\n",
      "\tspeed: 0.0321s/iter; left time: 438.8577s\n",
      "\titers: 700, epoch: 5 | loss: 0.0717957\n",
      "\tspeed: 0.0322s/iter; left time: 435.9439s\n",
      "\titers: 800, epoch: 5 | loss: 0.0741893\n",
      "\tspeed: 0.0321s/iter; left time: 432.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 891 | Train Loss: 0.0760055 Vali Loss: 0.0792141 Test Loss: 0.0825714\n",
      "Validation loss decreased (0.079252 --> 0.079214).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0660809\n",
      "\tspeed: 0.1170s/iter; left time: 1551.9621s\n",
      "\titers: 200, epoch: 6 | loss: 0.0807198\n",
      "\tspeed: 0.0322s/iter; left time: 423.8682s\n",
      "\titers: 300, epoch: 6 | loss: 0.0829986\n",
      "\tspeed: 0.0322s/iter; left time: 420.9487s\n",
      "\titers: 400, epoch: 6 | loss: 0.0728326\n",
      "\tspeed: 0.0322s/iter; left time: 417.4354s\n",
      "\titers: 500, epoch: 6 | loss: 0.0745011\n",
      "\tspeed: 0.0322s/iter; left time: 413.9960s\n",
      "\titers: 600, epoch: 6 | loss: 0.0675276\n",
      "\tspeed: 0.0322s/iter; left time: 410.9199s\n",
      "\titers: 700, epoch: 6 | loss: 0.0737795\n",
      "\tspeed: 0.0322s/iter; left time: 408.0392s\n",
      "\titers: 800, epoch: 6 | loss: 0.0830217\n",
      "\tspeed: 0.0322s/iter; left time: 404.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.94s\n",
      "Steps: 891 | Train Loss: 0.0749932 Vali Loss: 0.0797596 Test Loss: 0.0824995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0780509\n",
      "\tspeed: 0.1145s/iter; left time: 1416.3895s\n",
      "\titers: 200, epoch: 7 | loss: 0.0764229\n",
      "\tspeed: 0.0322s/iter; left time: 394.7701s\n",
      "\titers: 300, epoch: 7 | loss: 0.0892837\n",
      "\tspeed: 0.0322s/iter; left time: 391.5918s\n",
      "\titers: 400, epoch: 7 | loss: 0.0747710\n",
      "\tspeed: 0.0322s/iter; left time: 388.5637s\n",
      "\titers: 500, epoch: 7 | loss: 0.0708813\n",
      "\tspeed: 0.0322s/iter; left time: 385.0819s\n",
      "\titers: 600, epoch: 7 | loss: 0.0695488\n",
      "\tspeed: 0.0322s/iter; left time: 382.2886s\n",
      "\titers: 700, epoch: 7 | loss: 0.0693445\n",
      "\tspeed: 0.0322s/iter; left time: 378.9445s\n",
      "\titers: 800, epoch: 7 | loss: 0.0808278\n",
      "\tspeed: 0.0322s/iter; left time: 375.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.89s\n",
      "Steps: 891 | Train Loss: 0.0740662 Vali Loss: 0.0792481 Test Loss: 0.0827883\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0707986\n",
      "\tspeed: 0.1148s/iter; left time: 1318.2419s\n",
      "\titers: 200, epoch: 8 | loss: 0.0641760\n",
      "\tspeed: 0.0322s/iter; left time: 366.2745s\n",
      "\titers: 300, epoch: 8 | loss: 0.0725524\n",
      "\tspeed: 0.0322s/iter; left time: 363.4618s\n",
      "\titers: 400, epoch: 8 | loss: 0.0733588\n",
      "\tspeed: 0.0322s/iter; left time: 360.0844s\n",
      "\titers: 500, epoch: 8 | loss: 0.0800589\n",
      "\tspeed: 0.0322s/iter; left time: 356.4876s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702946\n",
      "\tspeed: 0.0322s/iter; left time: 353.6276s\n",
      "\titers: 700, epoch: 8 | loss: 0.0773885\n",
      "\tspeed: 0.0322s/iter; left time: 350.4743s\n",
      "\titers: 800, epoch: 8 | loss: 0.0750960\n",
      "\tspeed: 0.0322s/iter; left time: 347.1122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.92s\n",
      "Steps: 891 | Train Loss: 0.0732714 Vali Loss: 0.0794918 Test Loss: 0.0828576\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01889106072485447, rmse:0.13744474947452545, mae:0.08257140219211578, rse:0.5196934342384338\n",
      "Original data scale mse:2638311.75, rmse:1624.2880859375, mae:1032.549072265625, rse:0.11430779099464417\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1652369\n",
      "\tspeed: 0.0490s/iter; left time: 866.5692s\n",
      "\titers: 200, epoch: 1 | loss: 0.1241816\n",
      "\tspeed: 0.0325s/iter; left time: 570.9376s\n",
      "\titers: 300, epoch: 1 | loss: 0.1170381\n",
      "\tspeed: 0.0325s/iter; left time: 568.6258s\n",
      "\titers: 400, epoch: 1 | loss: 0.1237379\n",
      "\tspeed: 0.0326s/iter; left time: 565.7924s\n",
      "\titers: 500, epoch: 1 | loss: 0.1166823\n",
      "\tspeed: 0.0326s/iter; left time: 563.3468s\n",
      "\titers: 600, epoch: 1 | loss: 0.1114018\n",
      "\tspeed: 0.0326s/iter; left time: 559.9637s\n",
      "\titers: 700, epoch: 1 | loss: 0.1116604\n",
      "\tspeed: 0.0326s/iter; left time: 556.7431s\n",
      "\titers: 800, epoch: 1 | loss: 0.1052275\n",
      "\tspeed: 0.0326s/iter; left time: 553.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 889 | Train Loss: 0.1241218 Vali Loss: 0.1004518 Test Loss: 0.1016582\n",
      "Validation loss decreased (inf --> 0.100452).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0979188\n",
      "\tspeed: 0.1167s/iter; left time: 1958.9715s\n",
      "\titers: 200, epoch: 2 | loss: 0.0958629\n",
      "\tspeed: 0.0326s/iter; left time: 544.3612s\n",
      "\titers: 300, epoch: 2 | loss: 0.0975587\n",
      "\tspeed: 0.0325s/iter; left time: 539.5942s\n",
      "\titers: 400, epoch: 2 | loss: 0.0864070\n",
      "\tspeed: 0.0326s/iter; left time: 536.8189s\n",
      "\titers: 500, epoch: 2 | loss: 0.0895287\n",
      "\tspeed: 0.0326s/iter; left time: 533.7392s\n",
      "\titers: 600, epoch: 2 | loss: 0.0905237\n",
      "\tspeed: 0.0325s/iter; left time: 530.0796s\n",
      "\titers: 700, epoch: 2 | loss: 0.0827059\n",
      "\tspeed: 0.0326s/iter; left time: 527.5556s\n",
      "\titers: 800, epoch: 2 | loss: 0.0909425\n",
      "\tspeed: 0.0326s/iter; left time: 524.3375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.12s\n",
      "Steps: 889 | Train Loss: 0.0897755 Vali Loss: 0.0856224 Test Loss: 0.0880283\n",
      "Validation loss decreased (0.100452 --> 0.085622).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0824184\n",
      "\tspeed: 0.1174s/iter; left time: 1866.2924s\n",
      "\titers: 200, epoch: 3 | loss: 0.0862719\n",
      "\tspeed: 0.0325s/iter; left time: 514.3750s\n",
      "\titers: 300, epoch: 3 | loss: 0.0891321\n",
      "\tspeed: 0.0326s/iter; left time: 511.3891s\n",
      "\titers: 400, epoch: 3 | loss: 0.0867803\n",
      "\tspeed: 0.0326s/iter; left time: 508.2311s\n",
      "\titers: 500, epoch: 3 | loss: 0.0792341\n",
      "\tspeed: 0.0326s/iter; left time: 504.6779s\n",
      "\titers: 600, epoch: 3 | loss: 0.0781157\n",
      "\tspeed: 0.0326s/iter; left time: 501.9498s\n",
      "\titers: 700, epoch: 3 | loss: 0.0833267\n",
      "\tspeed: 0.0326s/iter; left time: 499.0793s\n",
      "\titers: 800, epoch: 3 | loss: 0.0839277\n",
      "\tspeed: 0.0326s/iter; left time: 495.4648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 889 | Train Loss: 0.0831550 Vali Loss: 0.0841925 Test Loss: 0.0877739\n",
      "Validation loss decreased (0.085622 --> 0.084192).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0816634\n",
      "\tspeed: 0.1150s/iter; left time: 1727.0749s\n",
      "\titers: 200, epoch: 4 | loss: 0.0786705\n",
      "\tspeed: 0.0325s/iter; left time: 485.3144s\n",
      "\titers: 300, epoch: 4 | loss: 0.0848514\n",
      "\tspeed: 0.0326s/iter; left time: 482.3971s\n",
      "\titers: 400, epoch: 4 | loss: 0.0787829\n",
      "\tspeed: 0.0326s/iter; left time: 479.2124s\n",
      "\titers: 500, epoch: 4 | loss: 0.0754429\n",
      "\tspeed: 0.0326s/iter; left time: 475.8581s\n",
      "\titers: 600, epoch: 4 | loss: 0.0769416\n",
      "\tspeed: 0.0326s/iter; left time: 472.5611s\n",
      "\titers: 700, epoch: 4 | loss: 0.0817359\n",
      "\tspeed: 0.0326s/iter; left time: 469.9307s\n",
      "\titers: 800, epoch: 4 | loss: 0.0803385\n",
      "\tspeed: 0.0325s/iter; left time: 465.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.11s\n",
      "Steps: 889 | Train Loss: 0.0810268 Vali Loss: 0.0841063 Test Loss: 0.0874366\n",
      "Validation loss decreased (0.084192 --> 0.084106).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0814832\n",
      "\tspeed: 0.1174s/iter; left time: 1658.6634s\n",
      "\titers: 200, epoch: 5 | loss: 0.0705573\n",
      "\tspeed: 0.0325s/iter; left time: 456.4403s\n",
      "\titers: 300, epoch: 5 | loss: 0.0796450\n",
      "\tspeed: 0.0326s/iter; left time: 453.6218s\n",
      "\titers: 400, epoch: 5 | loss: 0.0853031\n",
      "\tspeed: 0.0326s/iter; left time: 450.5208s\n",
      "\titers: 500, epoch: 5 | loss: 0.0821841\n",
      "\tspeed: 0.0326s/iter; left time: 447.0320s\n",
      "\titers: 600, epoch: 5 | loss: 0.0764277\n",
      "\tspeed: 0.0326s/iter; left time: 443.8717s\n",
      "\titers: 700, epoch: 5 | loss: 0.0824537\n",
      "\tspeed: 0.0326s/iter; left time: 440.8852s\n",
      "\titers: 800, epoch: 5 | loss: 0.0778101\n",
      "\tspeed: 0.0326s/iter; left time: 437.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 889 | Train Loss: 0.0792879 Vali Loss: 0.0841752 Test Loss: 0.0882557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0726924\n",
      "\tspeed: 0.1124s/iter; left time: 1488.1253s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813429\n",
      "\tspeed: 0.0325s/iter; left time: 427.5102s\n",
      "\titers: 300, epoch: 6 | loss: 0.0785214\n",
      "\tspeed: 0.0325s/iter; left time: 424.1949s\n",
      "\titers: 400, epoch: 6 | loss: 0.0715278\n",
      "\tspeed: 0.0326s/iter; left time: 421.2059s\n",
      "\titers: 500, epoch: 6 | loss: 0.0750119\n",
      "\tspeed: 0.0326s/iter; left time: 417.9182s\n",
      "\titers: 600, epoch: 6 | loss: 0.0752057\n",
      "\tspeed: 0.0326s/iter; left time: 415.3776s\n",
      "\titers: 700, epoch: 6 | loss: 0.0780466\n",
      "\tspeed: 0.0326s/iter; left time: 412.4034s\n",
      "\titers: 800, epoch: 6 | loss: 0.0754973\n",
      "\tspeed: 0.0327s/iter; left time: 409.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.15s\n",
      "Steps: 889 | Train Loss: 0.0780104 Vali Loss: 0.0861311 Test Loss: 0.0884621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0817233\n",
      "\tspeed: 0.1131s/iter; left time: 1396.8784s\n",
      "\titers: 200, epoch: 7 | loss: 0.0746553\n",
      "\tspeed: 0.0328s/iter; left time: 401.4379s\n",
      "\titers: 300, epoch: 7 | loss: 0.0846827\n",
      "\tspeed: 0.0327s/iter; left time: 397.7838s\n",
      "\titers: 400, epoch: 7 | loss: 0.0812078\n",
      "\tspeed: 0.0328s/iter; left time: 394.6601s\n",
      "\titers: 500, epoch: 7 | loss: 0.0763297\n",
      "\tspeed: 0.0328s/iter; left time: 391.4152s\n",
      "\titers: 600, epoch: 7 | loss: 0.0781970\n",
      "\tspeed: 0.0328s/iter; left time: 388.3468s\n",
      "\titers: 700, epoch: 7 | loss: 0.0717974\n",
      "\tspeed: 0.0340s/iter; left time: 399.4430s\n",
      "\titers: 800, epoch: 7 | loss: 0.0882720\n",
      "\tspeed: 0.0481s/iter; left time: 560.3793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.13s\n",
      "Steps: 889 | Train Loss: 0.0769935 Vali Loss: 0.0865264 Test Loss: 0.0892892\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020489852875471115, rmse:0.14314277470111847, mae:0.08743655681610107, rse:0.5416122078895569\n",
      "Original data scale mse:3125136.25, rmse:1767.8055419921875, mae:1126.43408203125, rse:0.12452451139688492\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1571310\n",
      "\tspeed: 0.0839s/iter; left time: 1483.3547s\n",
      "\titers: 200, epoch: 1 | loss: 0.1333701\n",
      "\tspeed: 0.0822s/iter; left time: 1444.9583s\n",
      "\titers: 300, epoch: 1 | loss: 0.1240424\n",
      "\tspeed: 0.0656s/iter; left time: 1146.8035s\n",
      "\titers: 400, epoch: 1 | loss: 0.1170751\n",
      "\tspeed: 0.0517s/iter; left time: 898.4607s\n",
      "\titers: 500, epoch: 1 | loss: 0.1168474\n",
      "\tspeed: 0.0932s/iter; left time: 1609.7464s\n",
      "\titers: 600, epoch: 1 | loss: 0.1104947\n",
      "\tspeed: 0.0855s/iter; left time: 1468.2950s\n",
      "\titers: 700, epoch: 1 | loss: 0.1119754\n",
      "\tspeed: 0.0461s/iter; left time: 787.4172s\n",
      "\titers: 800, epoch: 1 | loss: 0.1118596\n",
      "\tspeed: 0.0366s/iter; left time: 621.4713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:57.41s\n",
      "Steps: 889 | Train Loss: 0.1238160 Vali Loss: 0.1007575 Test Loss: 0.1019814\n",
      "Validation loss decreased (inf --> 0.100758).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0979399\n",
      "\tspeed: 0.1188s/iter; left time: 1994.6157s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932578\n",
      "\tspeed: 0.0327s/iter; left time: 545.9767s\n",
      "\titers: 300, epoch: 2 | loss: 0.0873403\n",
      "\tspeed: 0.0327s/iter; left time: 542.6782s\n",
      "\titers: 400, epoch: 2 | loss: 0.0887955\n",
      "\tspeed: 0.0328s/iter; left time: 540.9131s\n",
      "\titers: 500, epoch: 2 | loss: 0.0910590\n",
      "\tspeed: 0.0327s/iter; left time: 536.7184s\n",
      "\titers: 600, epoch: 2 | loss: 0.0873100\n",
      "\tspeed: 0.0327s/iter; left time: 532.4864s\n",
      "\titers: 700, epoch: 2 | loss: 0.0871343\n",
      "\tspeed: 0.0327s/iter; left time: 528.9323s\n",
      "\titers: 800, epoch: 2 | loss: 0.0851998\n",
      "\tspeed: 0.0326s/iter; left time: 525.3696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.31s\n",
      "Steps: 889 | Train Loss: 0.0897334 Vali Loss: 0.0857063 Test Loss: 0.0882008\n",
      "Validation loss decreased (0.100758 --> 0.085706).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0875653\n",
      "\tspeed: 0.1232s/iter; left time: 1959.8374s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855763\n",
      "\tspeed: 0.0326s/iter; left time: 515.5192s\n",
      "\titers: 300, epoch: 3 | loss: 0.0814581\n",
      "\tspeed: 0.0327s/iter; left time: 513.1641s\n",
      "\titers: 400, epoch: 3 | loss: 0.0873311\n",
      "\tspeed: 0.0327s/iter; left time: 509.9202s\n",
      "\titers: 500, epoch: 3 | loss: 0.0767904\n",
      "\tspeed: 0.0327s/iter; left time: 506.9580s\n",
      "\titers: 600, epoch: 3 | loss: 0.0830908\n",
      "\tspeed: 0.0328s/iter; left time: 504.7100s\n",
      "\titers: 700, epoch: 3 | loss: 0.0848068\n",
      "\tspeed: 0.0328s/iter; left time: 501.8117s\n",
      "\titers: 800, epoch: 3 | loss: 0.0801467\n",
      "\tspeed: 0.0328s/iter; left time: 498.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 889 | Train Loss: 0.0830926 Vali Loss: 0.0846757 Test Loss: 0.0875340\n",
      "Validation loss decreased (0.085706 --> 0.084676).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0844820\n",
      "\tspeed: 0.1179s/iter; left time: 1769.6256s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797190\n",
      "\tspeed: 0.0329s/iter; left time: 490.3653s\n",
      "\titers: 300, epoch: 4 | loss: 0.0878139\n",
      "\tspeed: 0.0329s/iter; left time: 487.6703s\n",
      "\titers: 400, epoch: 4 | loss: 0.0791153\n",
      "\tspeed: 0.0329s/iter; left time: 484.7907s\n",
      "\titers: 500, epoch: 4 | loss: 0.0818808\n",
      "\tspeed: 0.0329s/iter; left time: 481.1520s\n",
      "\titers: 600, epoch: 4 | loss: 0.0834403\n",
      "\tspeed: 0.0329s/iter; left time: 478.1946s\n",
      "\titers: 700, epoch: 4 | loss: 0.0811245\n",
      "\tspeed: 0.0329s/iter; left time: 474.0063s\n",
      "\titers: 800, epoch: 4 | loss: 0.0793772\n",
      "\tspeed: 0.0329s/iter; left time: 471.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:29.49s\n",
      "Steps: 889 | Train Loss: 0.0811833 Vali Loss: 0.0842506 Test Loss: 0.0871039\n",
      "Validation loss decreased (0.084676 --> 0.084251).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0784443\n",
      "\tspeed: 0.1171s/iter; left time: 1654.6034s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728498\n",
      "\tspeed: 0.0328s/iter; left time: 460.2101s\n",
      "\titers: 300, epoch: 5 | loss: 0.0847789\n",
      "\tspeed: 0.0327s/iter; left time: 455.9437s\n",
      "\titers: 400, epoch: 5 | loss: 0.0859600\n",
      "\tspeed: 0.0328s/iter; left time: 452.7709s\n",
      "\titers: 500, epoch: 5 | loss: 0.0814683\n",
      "\tspeed: 0.0327s/iter; left time: 449.2108s\n",
      "\titers: 600, epoch: 5 | loss: 0.0697299\n",
      "\tspeed: 0.0328s/iter; left time: 446.6344s\n",
      "\titers: 700, epoch: 5 | loss: 0.0803109\n",
      "\tspeed: 0.0328s/iter; left time: 443.0994s\n",
      "\titers: 800, epoch: 5 | loss: 0.0763105\n",
      "\tspeed: 0.0328s/iter; left time: 439.7575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 889 | Train Loss: 0.0796403 Vali Loss: 0.0844175 Test Loss: 0.0882975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0726000\n",
      "\tspeed: 0.1145s/iter; left time: 1515.6847s\n",
      "\titers: 200, epoch: 6 | loss: 0.0788484\n",
      "\tspeed: 0.0329s/iter; left time: 432.6571s\n",
      "\titers: 300, epoch: 6 | loss: 0.0848336\n",
      "\tspeed: 0.0328s/iter; left time: 427.3056s\n",
      "\titers: 400, epoch: 6 | loss: 0.0737767\n",
      "\tspeed: 0.0328s/iter; left time: 424.3432s\n",
      "\titers: 500, epoch: 6 | loss: 0.0824255\n",
      "\tspeed: 0.0328s/iter; left time: 421.1760s\n",
      "\titers: 600, epoch: 6 | loss: 0.0805373\n",
      "\tspeed: 0.0327s/iter; left time: 416.8430s\n",
      "\titers: 700, epoch: 6 | loss: 0.0795942\n",
      "\tspeed: 0.0327s/iter; left time: 413.7720s\n",
      "\titers: 800, epoch: 6 | loss: 0.0830558\n",
      "\tspeed: 0.0328s/iter; left time: 410.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.35s\n",
      "Steps: 889 | Train Loss: 0.0783631 Vali Loss: 0.0849069 Test Loss: 0.0893637\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0776093\n",
      "\tspeed: 0.1151s/iter; left time: 1420.8087s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822863\n",
      "\tspeed: 0.0327s/iter; left time: 400.3412s\n",
      "\titers: 300, epoch: 7 | loss: 0.0762961\n",
      "\tspeed: 0.0342s/iter; left time: 414.9113s\n",
      "\titers: 400, epoch: 7 | loss: 0.0799159\n",
      "\tspeed: 0.0604s/iter; left time: 727.8434s\n",
      "\titers: 500, epoch: 7 | loss: 0.0786617\n",
      "\tspeed: 0.0980s/iter; left time: 1171.2652s\n",
      "\titers: 600, epoch: 7 | loss: 0.0769959\n",
      "\tspeed: 0.0993s/iter; left time: 1176.6941s\n",
      "\titers: 700, epoch: 7 | loss: 0.0810160\n",
      "\tspeed: 0.0930s/iter; left time: 1092.0493s\n",
      "\titers: 800, epoch: 7 | loss: 0.0753454\n",
      "\tspeed: 0.0978s/iter; left time: 1138.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:03.33s\n",
      "Steps: 889 | Train Loss: 0.0773223 Vali Loss: 0.0850150 Test Loss: 0.0894548\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020019127056002617, rmse:0.1414889693260193, mae:0.0871039479970932, rse:0.5353546142578125\n",
      "Original data scale mse:3089354.0, rmse:1757.6558837890625, mae:1120.9505615234375, rse:0.1238095760345459\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.3813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0602</td>\n",
       "      <td>0.3814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.5031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.0834</td>\n",
       "      <td>0.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1356</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.5126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.5416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.5354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0102  0.1009  0.0600  0.3813\n",
       "              2         24        0.0102  0.1009  0.0602  0.3814\n",
       "              1         96        0.0177  0.1330  0.0839  0.5031\n",
       "              2         96        0.0177  0.1330  0.0834  0.5030\n",
       "              1         168       0.0192  0.1387  0.0891  0.5248\n",
       "              2         168       0.0191  0.1383  0.0889  0.5235\n",
       "MAE           1         24        0.0102  0.1008  0.0572  0.3810\n",
       "              2         24        0.0104  0.1018  0.0580  0.3849\n",
       "              1         96        0.0184  0.1356  0.0821  0.5126\n",
       "              2         96        0.0189  0.1374  0.0826  0.5197\n",
       "              1         168       0.0205  0.1431  0.0874  0.5416\n",
       "              2         168       0.0200  0.1415  0.0871  0.5354"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1345279.750</td>\n",
       "      <td>1159.8619</td>\n",
       "      <td>744.5026</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1345018.875</td>\n",
       "      <td>1159.7495</td>\n",
       "      <td>748.0704</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2733544.000</td>\n",
       "      <td>1653.3433</td>\n",
       "      <td>1080.4557</td>\n",
       "      <td>0.1164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2685297.500</td>\n",
       "      <td>1638.6877</td>\n",
       "      <td>1075.3787</td>\n",
       "      <td>0.1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3203129.750</td>\n",
       "      <td>1789.7290</td>\n",
       "      <td>1175.1929</td>\n",
       "      <td>0.1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3249148.250</td>\n",
       "      <td>1802.5394</td>\n",
       "      <td>1180.3934</td>\n",
       "      <td>0.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1196659.250</td>\n",
       "      <td>1093.9192</td>\n",
       "      <td>676.9175</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1235584.125</td>\n",
       "      <td>1111.5684</td>\n",
       "      <td>693.6528</td>\n",
       "      <td>0.0781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2641473.750</td>\n",
       "      <td>1625.2611</td>\n",
       "      <td>1033.8958</td>\n",
       "      <td>0.1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2638311.750</td>\n",
       "      <td>1624.2881</td>\n",
       "      <td>1032.5491</td>\n",
       "      <td>0.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3125136.250</td>\n",
       "      <td>1767.8055</td>\n",
       "      <td>1126.4341</td>\n",
       "      <td>0.1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3089354.000</td>\n",
       "      <td>1757.6559</td>\n",
       "      <td>1120.9506</td>\n",
       "      <td>0.1238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1345279.750  1159.8619   744.5026  0.0815\n",
       "              2         24        1345018.875  1159.7495   748.0704  0.0815\n",
       "              1         96        2733544.000  1653.3433  1080.4557  0.1164\n",
       "              2         96        2685297.500  1638.6877  1075.3787  0.1153\n",
       "              1         168       3203129.750  1789.7290  1175.1929  0.1261\n",
       "              2         168       3249148.250  1802.5394  1180.3934  0.1270\n",
       "MAE           1         24        1196659.250  1093.9192   676.9175  0.0769\n",
       "              2         24        1235584.125  1111.5684   693.6528  0.0781\n",
       "              1         96        2641473.750  1625.2611  1033.8958  0.1144\n",
       "              2         96        2638311.750  1624.2881  1032.5491  0.1143\n",
       "              1         168       3125136.250  1767.8055  1126.4341  0.1245\n",
       "              2         168       3089354.000  1757.6559  1120.9506  0.1238"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.3814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.5162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.5030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0873</td>\n",
       "      <td>0.5385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.5241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0103  0.1013  0.0576  0.3830\n",
       "         MSE            0.0102  0.1009  0.0601  0.3814\n",
       "96       MAE            0.0186  0.1365  0.0824  0.5162\n",
       "         MSE            0.0177  0.1330  0.0836  0.5030\n",
       "168      MAE            0.0203  0.1423  0.0873  0.5385\n",
       "         MSE            0.0192  0.1385  0.0890  0.5241"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_IT.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_IT.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.216122e+06</td>\n",
       "      <td>1102.7438</td>\n",
       "      <td>685.2851</td>\n",
       "      <td>0.0775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.345149e+06</td>\n",
       "      <td>1159.8057</td>\n",
       "      <td>746.2865</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.639893e+06</td>\n",
       "      <td>1624.7746</td>\n",
       "      <td>1033.2224</td>\n",
       "      <td>0.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.709421e+06</td>\n",
       "      <td>1646.0155</td>\n",
       "      <td>1077.9172</td>\n",
       "      <td>0.1158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.107245e+06</td>\n",
       "      <td>1762.7307</td>\n",
       "      <td>1123.6923</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.226139e+06</td>\n",
       "      <td>1796.1342</td>\n",
       "      <td>1177.7932</td>\n",
       "      <td>0.1265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.216122e+06  1102.7438   685.2851  0.0775\n",
       "         MSE            1.345149e+06  1159.8057   746.2865  0.0815\n",
       "96       MAE            2.639893e+06  1624.7746  1033.2224  0.1143\n",
       "         MSE            2.709421e+06  1646.0155  1077.9172  0.1158\n",
       "168      MAE            3.107245e+06  1762.7307  1123.6923  0.1242\n",
       "         MSE            3.226139e+06  1796.1342  1177.7932  0.1265"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_IT'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
