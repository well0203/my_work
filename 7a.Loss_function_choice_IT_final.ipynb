{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2655926\n",
      "\tspeed: 0.0524s/iter; left time: 944.4094s\n",
      "\titers: 200, epoch: 1 | loss: 1.1257330\n",
      "\tspeed: 0.0302s/iter; left time: 541.9914s\n",
      "\titers: 300, epoch: 1 | loss: 1.0365514\n",
      "\tspeed: 0.0308s/iter; left time: 549.7527s\n",
      "\titers: 400, epoch: 1 | loss: 1.0826616\n",
      "\tspeed: 0.0314s/iter; left time: 557.2914s\n",
      "\titers: 500, epoch: 1 | loss: 0.9831452\n",
      "\tspeed: 0.0307s/iter; left time: 540.9163s\n",
      "\titers: 600, epoch: 1 | loss: 0.9529172\n",
      "\tspeed: 0.0308s/iter; left time: 539.5018s\n",
      "\titers: 700, epoch: 1 | loss: 0.8132041\n",
      "\tspeed: 0.0341s/iter; left time: 594.5963s\n",
      "\titers: 800, epoch: 1 | loss: 0.8678878\n",
      "\tspeed: 0.0322s/iter; left time: 557.4417s\n",
      "\titers: 900, epoch: 1 | loss: 0.8668443\n",
      "\tspeed: 0.0305s/iter; left time: 524.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.09s\n",
      "Steps: 906 | Train Loss: 1.0168596 Vali Loss: 0.8487804 Test Loss: 0.9571623\n",
      "Validation loss decreased (inf --> 0.848780).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6205368\n",
      "\tspeed: 0.0875s/iter; left time: 1497.8456s\n",
      "\titers: 200, epoch: 2 | loss: 0.4253878\n",
      "\tspeed: 0.0304s/iter; left time: 516.9629s\n",
      "\titers: 300, epoch: 2 | loss: 0.3354857\n",
      "\tspeed: 0.0304s/iter; left time: 514.2398s\n",
      "\titers: 400, epoch: 2 | loss: 0.2754024\n",
      "\tspeed: 0.0310s/iter; left time: 521.2281s\n",
      "\titers: 500, epoch: 2 | loss: 0.3423934\n",
      "\tspeed: 0.0304s/iter; left time: 507.8521s\n",
      "\titers: 600, epoch: 2 | loss: 0.2980999\n",
      "\tspeed: 0.0302s/iter; left time: 501.8556s\n",
      "\titers: 700, epoch: 2 | loss: 0.2921608\n",
      "\tspeed: 0.0305s/iter; left time: 503.6856s\n",
      "\titers: 800, epoch: 2 | loss: 0.2983772\n",
      "\tspeed: 0.0311s/iter; left time: 510.0039s\n",
      "\titers: 900, epoch: 2 | loss: 0.2948388\n",
      "\tspeed: 0.0307s/iter; left time: 501.1986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 906 | Train Loss: 0.3569713 Vali Loss: 0.2462852 Test Loss: 0.2797472\n",
      "Validation loss decreased (0.848780 --> 0.246285).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2653996\n",
      "\tspeed: 0.0862s/iter; left time: 1397.4041s\n",
      "\titers: 200, epoch: 3 | loss: 0.2120890\n",
      "\tspeed: 0.0312s/iter; left time: 502.7968s\n",
      "\titers: 300, epoch: 3 | loss: 0.2602098\n",
      "\tspeed: 0.0322s/iter; left time: 516.0073s\n",
      "\titers: 400, epoch: 3 | loss: 0.2079800\n",
      "\tspeed: 0.0388s/iter; left time: 616.6091s\n",
      "\titers: 500, epoch: 3 | loss: 0.3032918\n",
      "\tspeed: 0.0310s/iter; left time: 489.4248s\n",
      "\titers: 600, epoch: 3 | loss: 0.2656105\n",
      "\tspeed: 0.0304s/iter; left time: 476.8994s\n",
      "\titers: 700, epoch: 3 | loss: 0.1913124\n",
      "\tspeed: 0.0306s/iter; left time: 477.5332s\n",
      "\titers: 800, epoch: 3 | loss: 0.2174596\n",
      "\tspeed: 0.0304s/iter; left time: 472.0387s\n",
      "\titers: 900, epoch: 3 | loss: 0.2116019\n",
      "\tspeed: 0.0312s/iter; left time: 481.4114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:29.09s\n",
      "Steps: 906 | Train Loss: 0.2390530 Vali Loss: 0.2166305 Test Loss: 0.2498899\n",
      "Validation loss decreased (0.246285 --> 0.216630).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1990468\n",
      "\tspeed: 0.0862s/iter; left time: 1319.2416s\n",
      "\titers: 200, epoch: 4 | loss: 0.1888942\n",
      "\tspeed: 0.0302s/iter; left time: 459.6472s\n",
      "\titers: 300, epoch: 4 | loss: 0.2250282\n",
      "\tspeed: 0.0307s/iter; left time: 463.3487s\n",
      "\titers: 400, epoch: 4 | loss: 0.2040859\n",
      "\tspeed: 0.0309s/iter; left time: 463.7188s\n",
      "\titers: 500, epoch: 4 | loss: 0.2031991\n",
      "\tspeed: 0.0306s/iter; left time: 455.3686s\n",
      "\titers: 600, epoch: 4 | loss: 0.2883396\n",
      "\tspeed: 0.0301s/iter; left time: 445.3067s\n",
      "\titers: 700, epoch: 4 | loss: 0.2602419\n",
      "\tspeed: 0.0336s/iter; left time: 494.3747s\n",
      "\titers: 800, epoch: 4 | loss: 0.2502171\n",
      "\tspeed: 0.0301s/iter; left time: 439.8927s\n",
      "\titers: 900, epoch: 4 | loss: 0.2754031\n",
      "\tspeed: 0.0301s/iter; left time: 435.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.11s\n",
      "Steps: 906 | Train Loss: 0.2162457 Vali Loss: 0.2035362 Test Loss: 0.2375945\n",
      "Validation loss decreased (0.216630 --> 0.203536).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1779218\n",
      "\tspeed: 0.0878s/iter; left time: 1264.3683s\n",
      "\titers: 200, epoch: 5 | loss: 0.1628965\n",
      "\tspeed: 0.0302s/iter; left time: 431.7690s\n",
      "\titers: 300, epoch: 5 | loss: 0.1668604\n",
      "\tspeed: 0.0306s/iter; left time: 434.1465s\n",
      "\titers: 400, epoch: 5 | loss: 0.1712749\n",
      "\tspeed: 0.0303s/iter; left time: 426.5854s\n",
      "\titers: 500, epoch: 5 | loss: 0.2286835\n",
      "\tspeed: 0.0305s/iter; left time: 427.1237s\n",
      "\titers: 600, epoch: 5 | loss: 0.1758938\n",
      "\tspeed: 0.0303s/iter; left time: 421.4016s\n",
      "\titers: 700, epoch: 5 | loss: 0.2287813\n",
      "\tspeed: 0.0316s/iter; left time: 435.4363s\n",
      "\titers: 800, epoch: 5 | loss: 0.1645952\n",
      "\tspeed: 0.0377s/iter; left time: 516.5512s\n",
      "\titers: 900, epoch: 5 | loss: 0.2300254\n",
      "\tspeed: 0.0397s/iter; left time: 539.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:29.67s\n",
      "Steps: 906 | Train Loss: 0.2023375 Vali Loss: 0.1983158 Test Loss: 0.2302715\n",
      "Validation loss decreased (0.203536 --> 0.198316).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1984994\n",
      "\tspeed: 0.1024s/iter; left time: 1381.8097s\n",
      "\titers: 200, epoch: 6 | loss: 0.2014216\n",
      "\tspeed: 0.0301s/iter; left time: 402.8015s\n",
      "\titers: 300, epoch: 6 | loss: 0.2673222\n",
      "\tspeed: 0.0303s/iter; left time: 402.2233s\n",
      "\titers: 400, epoch: 6 | loss: 0.2324974\n",
      "\tspeed: 0.0304s/iter; left time: 401.4666s\n",
      "\titers: 500, epoch: 6 | loss: 0.1736211\n",
      "\tspeed: 0.0302s/iter; left time: 394.9192s\n",
      "\titers: 600, epoch: 6 | loss: 0.2277704\n",
      "\tspeed: 0.0306s/iter; left time: 397.8479s\n",
      "\titers: 700, epoch: 6 | loss: 0.2457504\n",
      "\tspeed: 0.0307s/iter; left time: 395.2602s\n",
      "\titers: 800, epoch: 6 | loss: 0.1754776\n",
      "\tspeed: 0.0309s/iter; left time: 395.5527s\n",
      "\titers: 900, epoch: 6 | loss: 0.2075734\n",
      "\tspeed: 0.0308s/iter; left time: 391.4588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.91s\n",
      "Steps: 906 | Train Loss: 0.1929701 Vali Loss: 0.1915811 Test Loss: 0.2247654\n",
      "Validation loss decreased (0.198316 --> 0.191581).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1909763\n",
      "\tspeed: 0.0867s/iter; left time: 1091.1201s\n",
      "\titers: 200, epoch: 7 | loss: 0.1391223\n",
      "\tspeed: 0.0300s/iter; left time: 374.1504s\n",
      "\titers: 300, epoch: 7 | loss: 0.1620394\n",
      "\tspeed: 0.0300s/iter; left time: 371.3448s\n",
      "\titers: 400, epoch: 7 | loss: 0.1572613\n",
      "\tspeed: 0.0299s/iter; left time: 367.7928s\n",
      "\titers: 500, epoch: 7 | loss: 0.1740226\n",
      "\tspeed: 0.0299s/iter; left time: 364.3664s\n",
      "\titers: 600, epoch: 7 | loss: 0.1448199\n",
      "\tspeed: 0.0302s/iter; left time: 365.0665s\n",
      "\titers: 700, epoch: 7 | loss: 0.1617811\n",
      "\tspeed: 0.0300s/iter; left time: 359.1344s\n",
      "\titers: 800, epoch: 7 | loss: 0.2418114\n",
      "\tspeed: 0.0300s/iter; left time: 356.7035s\n",
      "\titers: 900, epoch: 7 | loss: 0.1763118\n",
      "\tspeed: 0.0306s/iter; left time: 360.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.60s\n",
      "Steps: 906 | Train Loss: 0.1855679 Vali Loss: 0.1916122 Test Loss: 0.2240161\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1528163\n",
      "\tspeed: 0.0853s/iter; left time: 996.1880s\n",
      "\titers: 200, epoch: 8 | loss: 0.1402654\n",
      "\tspeed: 0.0300s/iter; left time: 346.8176s\n",
      "\titers: 300, epoch: 8 | loss: 0.1994791\n",
      "\tspeed: 0.0298s/iter; left time: 341.9087s\n",
      "\titers: 400, epoch: 8 | loss: 0.1748054\n",
      "\tspeed: 0.0298s/iter; left time: 339.4530s\n",
      "\titers: 500, epoch: 8 | loss: 0.2032394\n",
      "\tspeed: 0.0301s/iter; left time: 339.9922s\n",
      "\titers: 600, epoch: 8 | loss: 0.1853030\n",
      "\tspeed: 0.0303s/iter; left time: 338.8999s\n",
      "\titers: 700, epoch: 8 | loss: 0.1588358\n",
      "\tspeed: 0.0343s/iter; left time: 380.0573s\n",
      "\titers: 800, epoch: 8 | loss: 0.1668811\n",
      "\tspeed: 0.0301s/iter; left time: 330.8946s\n",
      "\titers: 900, epoch: 8 | loss: 0.2083564\n",
      "\tspeed: 0.0300s/iter; left time: 326.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 906 | Train Loss: 0.1789123 Vali Loss: 0.1909796 Test Loss: 0.2257884\n",
      "Validation loss decreased (0.191581 --> 0.190980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1739116\n",
      "\tspeed: 0.0872s/iter; left time: 939.6577s\n",
      "\titers: 200, epoch: 9 | loss: 0.1993625\n",
      "\tspeed: 0.0302s/iter; left time: 322.1894s\n",
      "\titers: 300, epoch: 9 | loss: 0.1636563\n",
      "\tspeed: 0.0319s/iter; left time: 336.9813s\n",
      "\titers: 400, epoch: 9 | loss: 0.2166614\n",
      "\tspeed: 0.0298s/iter; left time: 311.9974s\n",
      "\titers: 500, epoch: 9 | loss: 0.1858605\n",
      "\tspeed: 0.0298s/iter; left time: 309.5298s\n",
      "\titers: 600, epoch: 9 | loss: 0.1781302\n",
      "\tspeed: 0.0312s/iter; left time: 320.1755s\n",
      "\titers: 700, epoch: 9 | loss: 0.1733542\n",
      "\tspeed: 0.0313s/iter; left time: 318.6184s\n",
      "\titers: 800, epoch: 9 | loss: 0.1696661\n",
      "\tspeed: 0.0306s/iter; left time: 308.6110s\n",
      "\titers: 900, epoch: 9 | loss: 0.1628733\n",
      "\tspeed: 0.0382s/iter; left time: 380.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.88s\n",
      "Steps: 906 | Train Loss: 0.1739853 Vali Loss: 0.1913661 Test Loss: 0.2280283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1886700\n",
      "\tspeed: 0.0845s/iter; left time: 833.6656s\n",
      "\titers: 200, epoch: 10 | loss: 0.1583662\n",
      "\tspeed: 0.0307s/iter; left time: 300.2481s\n",
      "\titers: 300, epoch: 10 | loss: 0.2071207\n",
      "\tspeed: 0.0313s/iter; left time: 302.9753s\n",
      "\titers: 400, epoch: 10 | loss: 0.1750381\n",
      "\tspeed: 0.0313s/iter; left time: 299.5027s\n",
      "\titers: 500, epoch: 10 | loss: 0.1599534\n",
      "\tspeed: 0.0314s/iter; left time: 296.9561s\n",
      "\titers: 600, epoch: 10 | loss: 0.1547934\n",
      "\tspeed: 0.0314s/iter; left time: 294.0820s\n",
      "\titers: 700, epoch: 10 | loss: 0.1641959\n",
      "\tspeed: 0.0314s/iter; left time: 290.7467s\n",
      "\titers: 800, epoch: 10 | loss: 0.1693465\n",
      "\tspeed: 0.0314s/iter; left time: 287.5603s\n",
      "\titers: 900, epoch: 10 | loss: 0.2088962\n",
      "\tspeed: 0.0314s/iter; left time: 284.6270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.54s\n",
      "Steps: 906 | Train Loss: 0.1698084 Vali Loss: 0.1913244 Test Loss: 0.2238524\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1410738\n",
      "\tspeed: 0.0841s/iter; left time: 754.0211s\n",
      "\titers: 200, epoch: 11 | loss: 0.1254946\n",
      "\tspeed: 0.0315s/iter; left time: 278.8131s\n",
      "\titers: 300, epoch: 11 | loss: 0.1921563\n",
      "\tspeed: 0.0314s/iter; left time: 274.6867s\n",
      "\titers: 400, epoch: 11 | loss: 0.1626051\n",
      "\tspeed: 0.0307s/iter; left time: 265.7582s\n",
      "\titers: 500, epoch: 11 | loss: 0.1395112\n",
      "\tspeed: 0.0304s/iter; left time: 260.2010s\n",
      "\titers: 600, epoch: 11 | loss: 0.1702996\n",
      "\tspeed: 0.0302s/iter; left time: 255.4562s\n",
      "\titers: 700, epoch: 11 | loss: 0.1565440\n",
      "\tspeed: 0.0302s/iter; left time: 252.6230s\n",
      "\titers: 800, epoch: 11 | loss: 0.1646023\n",
      "\tspeed: 0.0303s/iter; left time: 249.9372s\n",
      "\titers: 900, epoch: 11 | loss: 0.1816361\n",
      "\tspeed: 0.0303s/iter; left time: 247.0198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.06s\n",
      "Steps: 906 | Train Loss: 0.1661819 Vali Loss: 0.1863565 Test Loss: 0.2223691\n",
      "Validation loss decreased (0.190980 --> 0.186356).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2047073\n",
      "\tspeed: 0.0874s/iter; left time: 703.9571s\n",
      "\titers: 200, epoch: 12 | loss: 0.1806621\n",
      "\tspeed: 0.0301s/iter; left time: 239.7888s\n",
      "\titers: 300, epoch: 12 | loss: 0.2038715\n",
      "\tspeed: 0.0301s/iter; left time: 236.7215s\n",
      "\titers: 400, epoch: 12 | loss: 0.1419129\n",
      "\tspeed: 0.0304s/iter; left time: 235.6045s\n",
      "\titers: 500, epoch: 12 | loss: 0.1215186\n",
      "\tspeed: 0.0302s/iter; left time: 230.9095s\n",
      "\titers: 600, epoch: 12 | loss: 0.1550405\n",
      "\tspeed: 0.0302s/iter; left time: 228.3173s\n",
      "\titers: 700, epoch: 12 | loss: 0.1790772\n",
      "\tspeed: 0.0302s/iter; left time: 225.3314s\n",
      "\titers: 800, epoch: 12 | loss: 0.1482660\n",
      "\tspeed: 0.0301s/iter; left time: 221.5554s\n",
      "\titers: 900, epoch: 12 | loss: 0.1308462\n",
      "\tspeed: 0.0313s/iter; left time: 226.7781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.83s\n",
      "Steps: 906 | Train Loss: 0.1631092 Vali Loss: 0.1833248 Test Loss: 0.2202100\n",
      "Validation loss decreased (0.186356 --> 0.183325).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2019415\n",
      "\tspeed: 0.0896s/iter; left time: 640.2972s\n",
      "\titers: 200, epoch: 13 | loss: 0.1578228\n",
      "\tspeed: 0.0302s/iter; left time: 212.9237s\n",
      "\titers: 300, epoch: 13 | loss: 0.1638445\n",
      "\tspeed: 0.0319s/iter; left time: 221.6109s\n",
      "\titers: 400, epoch: 13 | loss: 0.1835979\n",
      "\tspeed: 0.0311s/iter; left time: 213.0360s\n",
      "\titers: 500, epoch: 13 | loss: 0.1297828\n",
      "\tspeed: 0.0304s/iter; left time: 205.1211s\n",
      "\titers: 600, epoch: 13 | loss: 0.1768717\n",
      "\tspeed: 0.0311s/iter; left time: 206.7687s\n",
      "\titers: 700, epoch: 13 | loss: 0.1593725\n",
      "\tspeed: 0.0303s/iter; left time: 198.5754s\n",
      "\titers: 800, epoch: 13 | loss: 0.1237680\n",
      "\tspeed: 0.0302s/iter; left time: 195.0139s\n",
      "\titers: 900, epoch: 13 | loss: 0.1891339\n",
      "\tspeed: 0.0302s/iter; left time: 191.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 906 | Train Loss: 0.1603260 Vali Loss: 0.1840722 Test Loss: 0.2198605\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1957013\n",
      "\tspeed: 0.0828s/iter; left time: 516.6776s\n",
      "\titers: 200, epoch: 14 | loss: 0.1663086\n",
      "\tspeed: 0.0302s/iter; left time: 185.3726s\n",
      "\titers: 300, epoch: 14 | loss: 0.1738329\n",
      "\tspeed: 0.0301s/iter; left time: 182.0809s\n",
      "\titers: 400, epoch: 14 | loss: 0.1429007\n",
      "\tspeed: 0.0302s/iter; left time: 179.5515s\n",
      "\titers: 500, epoch: 14 | loss: 0.1599222\n",
      "\tspeed: 0.0303s/iter; left time: 176.9481s\n",
      "\titers: 600, epoch: 14 | loss: 0.1743926\n",
      "\tspeed: 0.0302s/iter; left time: 173.5251s\n",
      "\titers: 700, epoch: 14 | loss: 0.1334641\n",
      "\tspeed: 0.0302s/iter; left time: 170.6081s\n",
      "\titers: 800, epoch: 14 | loss: 0.1281492\n",
      "\tspeed: 0.0302s/iter; left time: 167.1806s\n",
      "\titers: 900, epoch: 14 | loss: 0.1342761\n",
      "\tspeed: 0.0302s/iter; left time: 164.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.63s\n",
      "Steps: 906 | Train Loss: 0.1581648 Vali Loss: 0.1850006 Test Loss: 0.2216871\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1295189\n",
      "\tspeed: 0.0823s/iter; left time: 439.5019s\n",
      "\titers: 200, epoch: 15 | loss: 0.1223399\n",
      "\tspeed: 0.0302s/iter; left time: 158.0221s\n",
      "\titers: 300, epoch: 15 | loss: 0.1357728\n",
      "\tspeed: 0.0301s/iter; left time: 154.8402s\n",
      "\titers: 400, epoch: 15 | loss: 0.1444422\n",
      "\tspeed: 0.0302s/iter; left time: 151.9351s\n",
      "\titers: 500, epoch: 15 | loss: 0.1802864\n",
      "\tspeed: 0.0301s/iter; left time: 148.8159s\n",
      "\titers: 600, epoch: 15 | loss: 0.1279870\n",
      "\tspeed: 0.0302s/iter; left time: 145.9757s\n",
      "\titers: 700, epoch: 15 | loss: 0.1535772\n",
      "\tspeed: 0.0304s/iter; left time: 143.8637s\n",
      "\titers: 800, epoch: 15 | loss: 0.1905851\n",
      "\tspeed: 0.0302s/iter; left time: 140.0951s\n",
      "\titers: 900, epoch: 15 | loss: 0.1444526\n",
      "\tspeed: 0.0301s/iter; left time: 136.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.60s\n",
      "Steps: 906 | Train Loss: 0.1560168 Vali Loss: 0.1850767 Test Loss: 0.2227659\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22030074894428253, rmse:0.4693620800971985, mae:0.2934994399547577, rse:0.4298593997955322\n",
      "Original data scale mse:1680994.875, rmse:1296.5318603515625, mae:861.99560546875, rse:0.09111034870147705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1973295\n",
      "\tspeed: 0.0334s/iter; left time: 601.1463s\n",
      "\titers: 200, epoch: 1 | loss: 1.1421980\n",
      "\tspeed: 0.0305s/iter; left time: 546.2809s\n",
      "\titers: 300, epoch: 1 | loss: 1.0683498\n",
      "\tspeed: 0.0316s/iter; left time: 563.0244s\n",
      "\titers: 400, epoch: 1 | loss: 1.0709852\n",
      "\tspeed: 0.0319s/iter; left time: 565.6046s\n",
      "\titers: 500, epoch: 1 | loss: 0.9242501\n",
      "\tspeed: 0.0308s/iter; left time: 542.0347s\n",
      "\titers: 600, epoch: 1 | loss: 0.9109845\n",
      "\tspeed: 0.0301s/iter; left time: 527.2484s\n",
      "\titers: 700, epoch: 1 | loss: 0.8609775\n",
      "\tspeed: 0.0309s/iter; left time: 537.7522s\n",
      "\titers: 800, epoch: 1 | loss: 0.9410301\n",
      "\tspeed: 0.0304s/iter; left time: 525.6982s\n",
      "\titers: 900, epoch: 1 | loss: 0.8934740\n",
      "\tspeed: 0.0303s/iter; left time: 521.6973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.22s\n",
      "Steps: 906 | Train Loss: 1.0131149 Vali Loss: 0.8399439 Test Loss: 0.9540177\n",
      "Validation loss decreased (inf --> 0.839944).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5374418\n",
      "\tspeed: 0.0861s/iter; left time: 1473.2466s\n",
      "\titers: 200, epoch: 2 | loss: 0.4233172\n",
      "\tspeed: 0.0301s/iter; left time: 512.9310s\n",
      "\titers: 300, epoch: 2 | loss: 0.3481802\n",
      "\tspeed: 0.0301s/iter; left time: 509.7792s\n",
      "\titers: 400, epoch: 2 | loss: 0.3249161\n",
      "\tspeed: 0.0307s/iter; left time: 516.4932s\n",
      "\titers: 500, epoch: 2 | loss: 0.3003129\n",
      "\tspeed: 0.0304s/iter; left time: 508.5652s\n",
      "\titers: 600, epoch: 2 | loss: 0.3237344\n",
      "\tspeed: 0.0304s/iter; left time: 504.7644s\n",
      "\titers: 700, epoch: 2 | loss: 0.2852631\n",
      "\tspeed: 0.0299s/iter; left time: 493.0133s\n",
      "\titers: 800, epoch: 2 | loss: 0.2535228\n",
      "\tspeed: 0.0297s/iter; left time: 488.1348s\n",
      "\titers: 900, epoch: 2 | loss: 0.2464543\n",
      "\tspeed: 0.0298s/iter; left time: 485.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.62s\n",
      "Steps: 906 | Train Loss: 0.3592484 Vali Loss: 0.2497449 Test Loss: 0.2751626\n",
      "Validation loss decreased (0.839944 --> 0.249745).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2510317\n",
      "\tspeed: 0.0860s/iter; left time: 1394.3920s\n",
      "\titers: 200, epoch: 3 | loss: 0.2203990\n",
      "\tspeed: 0.0299s/iter; left time: 481.3868s\n",
      "\titers: 300, epoch: 3 | loss: 0.1857467\n",
      "\tspeed: 0.0299s/iter; left time: 478.6565s\n",
      "\titers: 400, epoch: 3 | loss: 0.2201314\n",
      "\tspeed: 0.0298s/iter; left time: 474.7591s\n",
      "\titers: 500, epoch: 3 | loss: 0.2493524\n",
      "\tspeed: 0.0298s/iter; left time: 471.1879s\n",
      "\titers: 600, epoch: 3 | loss: 0.2327100\n",
      "\tspeed: 0.0298s/iter; left time: 468.5377s\n",
      "\titers: 700, epoch: 3 | loss: 0.1974741\n",
      "\tspeed: 0.0299s/iter; left time: 465.9455s\n",
      "\titers: 800, epoch: 3 | loss: 0.2512345\n",
      "\tspeed: 0.0298s/iter; left time: 461.6469s\n",
      "\titers: 900, epoch: 3 | loss: 0.1945242\n",
      "\tspeed: 0.0298s/iter; left time: 458.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.36s\n",
      "Steps: 906 | Train Loss: 0.2380821 Vali Loss: 0.2192356 Test Loss: 0.2467774\n",
      "Validation loss decreased (0.249745 --> 0.219236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2088396\n",
      "\tspeed: 0.0891s/iter; left time: 1363.6705s\n",
      "\titers: 200, epoch: 4 | loss: 0.2268296\n",
      "\tspeed: 0.0298s/iter; left time: 453.1673s\n",
      "\titers: 300, epoch: 4 | loss: 0.2682111\n",
      "\tspeed: 0.0301s/iter; left time: 453.9335s\n",
      "\titers: 400, epoch: 4 | loss: 0.2142512\n",
      "\tspeed: 0.0301s/iter; left time: 451.8831s\n",
      "\titers: 500, epoch: 4 | loss: 0.2133008\n",
      "\tspeed: 0.0303s/iter; left time: 451.9181s\n",
      "\titers: 600, epoch: 4 | loss: 0.2556488\n",
      "\tspeed: 0.0304s/iter; left time: 450.5538s\n",
      "\titers: 700, epoch: 4 | loss: 0.1777005\n",
      "\tspeed: 0.0299s/iter; left time: 440.1571s\n",
      "\titers: 800, epoch: 4 | loss: 0.2581894\n",
      "\tspeed: 0.0300s/iter; left time: 438.3607s\n",
      "\titers: 900, epoch: 4 | loss: 0.1423981\n",
      "\tspeed: 0.0297s/iter; left time: 430.4617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.56s\n",
      "Steps: 906 | Train Loss: 0.2149451 Vali Loss: 0.2036094 Test Loss: 0.2357368\n",
      "Validation loss decreased (0.219236 --> 0.203609).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2451628\n",
      "\tspeed: 0.0865s/iter; left time: 1244.9693s\n",
      "\titers: 200, epoch: 5 | loss: 0.1844019\n",
      "\tspeed: 0.0297s/iter; left time: 424.5688s\n",
      "\titers: 300, epoch: 5 | loss: 0.1272023\n",
      "\tspeed: 0.0297s/iter; left time: 421.5443s\n",
      "\titers: 400, epoch: 5 | loss: 0.2236189\n",
      "\tspeed: 0.0297s/iter; left time: 418.7961s\n",
      "\titers: 500, epoch: 5 | loss: 0.1628642\n",
      "\tspeed: 0.0298s/iter; left time: 417.2581s\n",
      "\titers: 600, epoch: 5 | loss: 0.1402728\n",
      "\tspeed: 0.0298s/iter; left time: 414.7542s\n",
      "\titers: 700, epoch: 5 | loss: 0.2224473\n",
      "\tspeed: 0.0297s/iter; left time: 410.0275s\n",
      "\titers: 800, epoch: 5 | loss: 0.2364742\n",
      "\tspeed: 0.0299s/iter; left time: 408.8742s\n",
      "\titers: 900, epoch: 5 | loss: 0.2050458\n",
      "\tspeed: 0.0298s/iter; left time: 404.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.31s\n",
      "Steps: 906 | Train Loss: 0.2004238 Vali Loss: 0.1958581 Test Loss: 0.2253950\n",
      "Validation loss decreased (0.203609 --> 0.195858).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1923144\n",
      "\tspeed: 0.0873s/iter; left time: 1178.2156s\n",
      "\titers: 200, epoch: 6 | loss: 0.1665370\n",
      "\tspeed: 0.0298s/iter; left time: 398.7828s\n",
      "\titers: 300, epoch: 6 | loss: 0.1647235\n",
      "\tspeed: 0.0298s/iter; left time: 395.6624s\n",
      "\titers: 400, epoch: 6 | loss: 0.1797579\n",
      "\tspeed: 0.0298s/iter; left time: 392.9224s\n",
      "\titers: 500, epoch: 6 | loss: 0.1545018\n",
      "\tspeed: 0.0298s/iter; left time: 390.2057s\n",
      "\titers: 600, epoch: 6 | loss: 0.2259643\n",
      "\tspeed: 0.0298s/iter; left time: 386.6781s\n",
      "\titers: 700, epoch: 6 | loss: 0.1816601\n",
      "\tspeed: 0.0298s/iter; left time: 383.7922s\n",
      "\titers: 800, epoch: 6 | loss: 0.1513158\n",
      "\tspeed: 0.0298s/iter; left time: 380.7584s\n",
      "\titers: 900, epoch: 6 | loss: 0.1692653\n",
      "\tspeed: 0.0298s/iter; left time: 377.9823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.33s\n",
      "Steps: 906 | Train Loss: 0.1902713 Vali Loss: 0.1955038 Test Loss: 0.2277900\n",
      "Validation loss decreased (0.195858 --> 0.195504).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2298900\n",
      "\tspeed: 0.0853s/iter; left time: 1073.0383s\n",
      "\titers: 200, epoch: 7 | loss: 0.1472812\n",
      "\tspeed: 0.0298s/iter; left time: 371.5461s\n",
      "\titers: 300, epoch: 7 | loss: 0.1788663\n",
      "\tspeed: 0.0302s/iter; left time: 374.6412s\n",
      "\titers: 400, epoch: 7 | loss: 0.1623691\n",
      "\tspeed: 0.0301s/iter; left time: 369.9347s\n",
      "\titers: 500, epoch: 7 | loss: 0.1475256\n",
      "\tspeed: 0.0298s/iter; left time: 363.0725s\n",
      "\titers: 600, epoch: 7 | loss: 0.1393432\n",
      "\tspeed: 0.0299s/iter; left time: 361.1355s\n",
      "\titers: 700, epoch: 7 | loss: 0.1944267\n",
      "\tspeed: 0.0302s/iter; left time: 361.7453s\n",
      "\titers: 800, epoch: 7 | loss: 0.1804781\n",
      "\tspeed: 0.0300s/iter; left time: 356.0335s\n",
      "\titers: 900, epoch: 7 | loss: 0.1573293\n",
      "\tspeed: 0.0302s/iter; left time: 355.7672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.53s\n",
      "Steps: 906 | Train Loss: 0.1823200 Vali Loss: 0.1930710 Test Loss: 0.2249620\n",
      "Validation loss decreased (0.195504 --> 0.193071).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1789100\n",
      "\tspeed: 0.0864s/iter; left time: 1009.1083s\n",
      "\titers: 200, epoch: 8 | loss: 0.1614548\n",
      "\tspeed: 0.0297s/iter; left time: 343.8512s\n",
      "\titers: 300, epoch: 8 | loss: 0.1923694\n",
      "\tspeed: 0.0297s/iter; left time: 340.7699s\n",
      "\titers: 400, epoch: 8 | loss: 0.2199651\n",
      "\tspeed: 0.0297s/iter; left time: 337.5001s\n",
      "\titers: 500, epoch: 8 | loss: 0.1808472\n",
      "\tspeed: 0.0297s/iter; left time: 334.7962s\n",
      "\titers: 600, epoch: 8 | loss: 0.2397220\n",
      "\tspeed: 0.0297s/iter; left time: 331.5168s\n",
      "\titers: 700, epoch: 8 | loss: 0.2278471\n",
      "\tspeed: 0.0297s/iter; left time: 329.2632s\n",
      "\titers: 800, epoch: 8 | loss: 0.2043150\n",
      "\tspeed: 0.0297s/iter; left time: 325.9858s\n",
      "\titers: 900, epoch: 8 | loss: 0.1779005\n",
      "\tspeed: 0.0297s/iter; left time: 322.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 906 | Train Loss: 0.1759455 Vali Loss: 0.1875082 Test Loss: 0.2209941\n",
      "Validation loss decreased (0.193071 --> 0.187508).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1644031\n",
      "\tspeed: 0.0869s/iter; left time: 935.7666s\n",
      "\titers: 200, epoch: 9 | loss: 0.2507294\n",
      "\tspeed: 0.0297s/iter; left time: 316.7550s\n",
      "\titers: 300, epoch: 9 | loss: 0.2283448\n",
      "\tspeed: 0.0297s/iter; left time: 313.9346s\n",
      "\titers: 400, epoch: 9 | loss: 0.1817382\n",
      "\tspeed: 0.0297s/iter; left time: 310.7614s\n",
      "\titers: 500, epoch: 9 | loss: 0.1469816\n",
      "\tspeed: 0.0297s/iter; left time: 307.8554s\n",
      "\titers: 600, epoch: 9 | loss: 0.1369695\n",
      "\tspeed: 0.0297s/iter; left time: 305.0374s\n",
      "\titers: 700, epoch: 9 | loss: 0.1735614\n",
      "\tspeed: 0.0297s/iter; left time: 301.8397s\n",
      "\titers: 800, epoch: 9 | loss: 0.1863412\n",
      "\tspeed: 0.0298s/iter; left time: 299.9219s\n",
      "\titers: 900, epoch: 9 | loss: 0.1586168\n",
      "\tspeed: 0.0298s/iter; left time: 296.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.1704638 Vali Loss: 0.1869479 Test Loss: 0.2218861\n",
      "Validation loss decreased (0.187508 --> 0.186948).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1457572\n",
      "\tspeed: 0.0860s/iter; left time: 848.4719s\n",
      "\titers: 200, epoch: 10 | loss: 0.1251245\n",
      "\tspeed: 0.0298s/iter; left time: 290.7816s\n",
      "\titers: 300, epoch: 10 | loss: 0.1279689\n",
      "\tspeed: 0.0299s/iter; left time: 289.2970s\n",
      "\titers: 400, epoch: 10 | loss: 0.2251878\n",
      "\tspeed: 0.0301s/iter; left time: 287.9602s\n",
      "\titers: 500, epoch: 10 | loss: 0.1428768\n",
      "\tspeed: 0.0297s/iter; left time: 281.2376s\n",
      "\titers: 600, epoch: 10 | loss: 0.1350298\n",
      "\tspeed: 0.0299s/iter; left time: 280.4888s\n",
      "\titers: 700, epoch: 10 | loss: 0.1976508\n",
      "\tspeed: 0.0301s/iter; left time: 278.8939s\n",
      "\titers: 800, epoch: 10 | loss: 0.1537141\n",
      "\tspeed: 0.0301s/iter; left time: 276.1670s\n",
      "\titers: 900, epoch: 10 | loss: 0.1983796\n",
      "\tspeed: 0.0298s/iter; left time: 269.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.44s\n",
      "Steps: 906 | Train Loss: 0.1660709 Vali Loss: 0.1898970 Test Loss: 0.2283974\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1414833\n",
      "\tspeed: 0.0827s/iter; left time: 741.3964s\n",
      "\titers: 200, epoch: 11 | loss: 0.1964810\n",
      "\tspeed: 0.0298s/iter; left time: 263.9934s\n",
      "\titers: 300, epoch: 11 | loss: 0.1748426\n",
      "\tspeed: 0.0297s/iter; left time: 260.5536s\n",
      "\titers: 400, epoch: 11 | loss: 0.1310564\n",
      "\tspeed: 0.0297s/iter; left time: 257.5479s\n",
      "\titers: 500, epoch: 11 | loss: 0.1376743\n",
      "\tspeed: 0.0297s/iter; left time: 254.5355s\n",
      "\titers: 600, epoch: 11 | loss: 0.1773211\n",
      "\tspeed: 0.0297s/iter; left time: 251.6144s\n",
      "\titers: 700, epoch: 11 | loss: 0.1335469\n",
      "\tspeed: 0.0297s/iter; left time: 248.5330s\n",
      "\titers: 800, epoch: 11 | loss: 0.1604896\n",
      "\tspeed: 0.0297s/iter; left time: 245.4699s\n",
      "\titers: 900, epoch: 11 | loss: 0.1420005\n",
      "\tspeed: 0.0297s/iter; left time: 242.7384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.23s\n",
      "Steps: 906 | Train Loss: 0.1620493 Vali Loss: 0.1876232 Test Loss: 0.2207744\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1794909\n",
      "\tspeed: 0.0833s/iter; left time: 671.3637s\n",
      "\titers: 200, epoch: 12 | loss: 0.1482996\n",
      "\tspeed: 0.0297s/iter; left time: 235.9153s\n",
      "\titers: 300, epoch: 12 | loss: 0.1748915\n",
      "\tspeed: 0.0297s/iter; left time: 233.0027s\n",
      "\titers: 400, epoch: 12 | loss: 0.1930236\n",
      "\tspeed: 0.0297s/iter; left time: 230.1526s\n",
      "\titers: 500, epoch: 12 | loss: 0.1466676\n",
      "\tspeed: 0.0297s/iter; left time: 227.1138s\n",
      "\titers: 600, epoch: 12 | loss: 0.1437257\n",
      "\tspeed: 0.0297s/iter; left time: 224.5636s\n",
      "\titers: 700, epoch: 12 | loss: 0.2111108\n",
      "\tspeed: 0.0298s/iter; left time: 222.1609s\n",
      "\titers: 800, epoch: 12 | loss: 0.1766935\n",
      "\tspeed: 0.0299s/iter; left time: 220.0054s\n",
      "\titers: 900, epoch: 12 | loss: 0.1558518\n",
      "\tspeed: 0.0298s/iter; left time: 216.5097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 906 | Train Loss: 0.1592279 Vali Loss: 0.1830799 Test Loss: 0.2161524\n",
      "Validation loss decreased (0.186948 --> 0.183080).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1335872\n",
      "\tspeed: 0.0850s/iter; left time: 607.5166s\n",
      "\titers: 200, epoch: 13 | loss: 0.1904642\n",
      "\tspeed: 0.0298s/iter; left time: 210.1440s\n",
      "\titers: 300, epoch: 13 | loss: 0.1406990\n",
      "\tspeed: 0.0303s/iter; left time: 210.4167s\n",
      "\titers: 400, epoch: 13 | loss: 0.1491441\n",
      "\tspeed: 0.0301s/iter; left time: 206.2031s\n",
      "\titers: 500, epoch: 13 | loss: 0.1908478\n",
      "\tspeed: 0.0299s/iter; left time: 201.6155s\n",
      "\titers: 600, epoch: 13 | loss: 0.1886673\n",
      "\tspeed: 0.0445s/iter; left time: 295.7375s\n",
      "\titers: 700, epoch: 13 | loss: 0.1309064\n",
      "\tspeed: 0.0376s/iter; left time: 246.0211s\n",
      "\titers: 800, epoch: 13 | loss: 0.1589462\n",
      "\tspeed: 0.0303s/iter; left time: 195.1027s\n",
      "\titers: 900, epoch: 13 | loss: 0.1876475\n",
      "\tspeed: 0.0303s/iter; left time: 192.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 906 | Train Loss: 0.1563049 Vali Loss: 0.1856795 Test Loss: 0.2219029\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1495333\n",
      "\tspeed: 0.0845s/iter; left time: 527.7282s\n",
      "\titers: 200, epoch: 14 | loss: 0.0944232\n",
      "\tspeed: 0.0297s/iter; left time: 182.5003s\n",
      "\titers: 300, epoch: 14 | loss: 0.1575354\n",
      "\tspeed: 0.0297s/iter; left time: 179.6098s\n",
      "\titers: 400, epoch: 14 | loss: 0.1296602\n",
      "\tspeed: 0.0297s/iter; left time: 176.7110s\n",
      "\titers: 500, epoch: 14 | loss: 0.1424343\n",
      "\tspeed: 0.0306s/iter; left time: 178.9437s\n",
      "\titers: 600, epoch: 14 | loss: 0.1530355\n",
      "\tspeed: 0.0315s/iter; left time: 180.6188s\n",
      "\titers: 700, epoch: 14 | loss: 0.1749859\n",
      "\tspeed: 0.0308s/iter; left time: 174.0740s\n",
      "\titers: 800, epoch: 14 | loss: 0.1459346\n",
      "\tspeed: 0.0303s/iter; left time: 167.8053s\n",
      "\titers: 900, epoch: 14 | loss: 0.2009379\n",
      "\tspeed: 0.0304s/iter; left time: 165.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.74s\n",
      "Steps: 906 | Train Loss: 0.1537245 Vali Loss: 0.1861046 Test Loss: 0.2244890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1449612\n",
      "\tspeed: 0.0853s/iter; left time: 455.1487s\n",
      "\titers: 200, epoch: 15 | loss: 0.1392896\n",
      "\tspeed: 0.0299s/iter; left time: 156.6474s\n",
      "\titers: 300, epoch: 15 | loss: 0.1350373\n",
      "\tspeed: 0.0298s/iter; left time: 153.2841s\n",
      "\titers: 400, epoch: 15 | loss: 0.1786360\n",
      "\tspeed: 0.0298s/iter; left time: 149.9807s\n",
      "\titers: 500, epoch: 15 | loss: 0.1219083\n",
      "\tspeed: 0.0302s/iter; left time: 148.9820s\n",
      "\titers: 600, epoch: 15 | loss: 0.1108440\n",
      "\tspeed: 0.0300s/iter; left time: 145.2536s\n",
      "\titers: 700, epoch: 15 | loss: 0.1847629\n",
      "\tspeed: 0.0301s/iter; left time: 142.4328s\n",
      "\titers: 800, epoch: 15 | loss: 0.1144152\n",
      "\tspeed: 0.0298s/iter; left time: 138.1106s\n",
      "\titers: 900, epoch: 15 | loss: 0.1235651\n",
      "\tspeed: 0.0298s/iter; left time: 135.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.43s\n",
      "Steps: 906 | Train Loss: 0.1517470 Vali Loss: 0.1870975 Test Loss: 0.2185816\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21708616614341736, rmse:0.46592506766319275, mae:0.28623270988464355, rse:0.42671167850494385\n",
      "Original data scale mse:1580196.75, rmse:1257.0587158203125, mae:835.594482421875, rse:0.08833649009466171\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.2569711\n",
      "\tspeed: 0.0626s/iter; left time: 1124.9839s\n",
      "\titers: 200, epoch: 1 | loss: 1.1342064\n",
      "\tspeed: 0.0376s/iter; left time: 672.1970s\n",
      "\titers: 300, epoch: 1 | loss: 1.0191394\n",
      "\tspeed: 0.0373s/iter; left time: 663.5587s\n",
      "\titers: 400, epoch: 1 | loss: 1.0276276\n",
      "\tspeed: 0.0373s/iter; left time: 659.1006s\n",
      "\titers: 500, epoch: 1 | loss: 1.0607997\n",
      "\tspeed: 0.0373s/iter; left time: 656.3250s\n",
      "\titers: 600, epoch: 1 | loss: 1.0010128\n",
      "\tspeed: 0.0374s/iter; left time: 652.9576s\n",
      "\titers: 700, epoch: 1 | loss: 0.9738109\n",
      "\tspeed: 0.0374s/iter; left time: 649.6830s\n",
      "\titers: 800, epoch: 1 | loss: 0.9160896\n",
      "\tspeed: 0.0374s/iter; left time: 645.8238s\n",
      "\titers: 900, epoch: 1 | loss: 1.0073916\n",
      "\tspeed: 0.0374s/iter; left time: 641.8705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.52s\n",
      "Steps: 904 | Train Loss: 1.0452373 Vali Loss: 0.9750314 Test Loss: 1.1119167\n",
      "Validation loss decreased (inf --> 0.975031).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.7925690\n",
      "\tspeed: 0.1065s/iter; left time: 1819.2835s\n",
      "\titers: 200, epoch: 2 | loss: 0.7310765\n",
      "\tspeed: 0.0378s/iter; left time: 642.0799s\n",
      "\titers: 300, epoch: 2 | loss: 0.5723507\n",
      "\tspeed: 0.0378s/iter; left time: 638.3447s\n",
      "\titers: 400, epoch: 2 | loss: 0.5537190\n",
      "\tspeed: 0.0379s/iter; left time: 635.1556s\n",
      "\titers: 500, epoch: 2 | loss: 0.5312950\n",
      "\tspeed: 0.0374s/iter; left time: 624.3943s\n",
      "\titers: 600, epoch: 2 | loss: 0.5401709\n",
      "\tspeed: 0.0373s/iter; left time: 618.4462s\n",
      "\titers: 700, epoch: 2 | loss: 0.4922288\n",
      "\tspeed: 0.0373s/iter; left time: 614.9692s\n",
      "\titers: 800, epoch: 2 | loss: 0.4806575\n",
      "\tspeed: 0.0373s/iter; left time: 610.7576s\n",
      "\titers: 900, epoch: 2 | loss: 0.4383050\n",
      "\tspeed: 0.0373s/iter; left time: 606.8475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.26s\n",
      "Steps: 904 | Train Loss: 0.5834556 Vali Loss: 0.4372569 Test Loss: 0.4922570\n",
      "Validation loss decreased (0.975031 --> 0.437257).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4598078\n",
      "\tspeed: 0.1085s/iter; left time: 1754.2834s\n",
      "\titers: 200, epoch: 3 | loss: 0.4603759\n",
      "\tspeed: 0.0373s/iter; left time: 599.8152s\n",
      "\titers: 300, epoch: 3 | loss: 0.4671333\n",
      "\tspeed: 0.0373s/iter; left time: 596.3898s\n",
      "\titers: 400, epoch: 3 | loss: 0.4616690\n",
      "\tspeed: 0.0373s/iter; left time: 592.7550s\n",
      "\titers: 500, epoch: 3 | loss: 0.3741969\n",
      "\tspeed: 0.0373s/iter; left time: 588.5440s\n",
      "\titers: 600, epoch: 3 | loss: 0.4101180\n",
      "\tspeed: 0.0373s/iter; left time: 585.3286s\n",
      "\titers: 700, epoch: 3 | loss: 0.4089517\n",
      "\tspeed: 0.0374s/iter; left time: 581.8474s\n",
      "\titers: 800, epoch: 3 | loss: 0.4801561\n",
      "\tspeed: 0.0374s/iter; left time: 578.1506s\n",
      "\titers: 900, epoch: 3 | loss: 0.4650743\n",
      "\tspeed: 0.0373s/iter; left time: 573.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.07s\n",
      "Steps: 904 | Train Loss: 0.4371184 Vali Loss: 0.3859395 Test Loss: 0.4441888\n",
      "Validation loss decreased (0.437257 --> 0.385939).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3729490\n",
      "\tspeed: 0.1079s/iter; left time: 1647.0294s\n",
      "\titers: 200, epoch: 4 | loss: 0.3985529\n",
      "\tspeed: 0.0374s/iter; left time: 567.5267s\n",
      "\titers: 300, epoch: 4 | loss: 0.3592731\n",
      "\tspeed: 0.0373s/iter; left time: 562.3742s\n",
      "\titers: 400, epoch: 4 | loss: 0.4424825\n",
      "\tspeed: 0.0374s/iter; left time: 559.3301s\n",
      "\titers: 500, epoch: 4 | loss: 0.4073082\n",
      "\tspeed: 0.0373s/iter; left time: 555.0303s\n",
      "\titers: 600, epoch: 4 | loss: 0.3994013\n",
      "\tspeed: 0.0374s/iter; left time: 551.7300s\n",
      "\titers: 700, epoch: 4 | loss: 0.3654498\n",
      "\tspeed: 0.0374s/iter; left time: 548.0572s\n",
      "\titers: 800, epoch: 4 | loss: 0.3958062\n",
      "\tspeed: 0.0373s/iter; left time: 544.1066s\n",
      "\titers: 900, epoch: 4 | loss: 0.3822381\n",
      "\tspeed: 0.0374s/iter; left time: 540.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.10s\n",
      "Steps: 904 | Train Loss: 0.3965515 Vali Loss: 0.3619389 Test Loss: 0.4270026\n",
      "Validation loss decreased (0.385939 --> 0.361939).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3222974\n",
      "\tspeed: 0.1078s/iter; left time: 1548.4235s\n",
      "\titers: 200, epoch: 5 | loss: 0.3651301\n",
      "\tspeed: 0.0379s/iter; left time: 540.3637s\n",
      "\titers: 300, epoch: 5 | loss: 0.3570947\n",
      "\tspeed: 0.0379s/iter; left time: 537.0994s\n",
      "\titers: 400, epoch: 5 | loss: 0.4414485\n",
      "\tspeed: 0.0379s/iter; left time: 532.7599s\n",
      "\titers: 500, epoch: 5 | loss: 0.3828043\n",
      "\tspeed: 0.0378s/iter; left time: 528.5242s\n",
      "\titers: 600, epoch: 5 | loss: 0.3624260\n",
      "\tspeed: 0.0379s/iter; left time: 524.9975s\n",
      "\titers: 700, epoch: 5 | loss: 0.3725795\n",
      "\tspeed: 0.0379s/iter; left time: 521.4996s\n",
      "\titers: 800, epoch: 5 | loss: 0.3804747\n",
      "\tspeed: 0.0379s/iter; left time: 517.3920s\n",
      "\titers: 900, epoch: 5 | loss: 0.3168982\n",
      "\tspeed: 0.0379s/iter; left time: 513.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.58s\n",
      "Steps: 904 | Train Loss: 0.3697983 Vali Loss: 0.3524163 Test Loss: 0.4058910\n",
      "Validation loss decreased (0.361939 --> 0.352416).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2728748\n",
      "\tspeed: 0.1085s/iter; left time: 1460.5474s\n",
      "\titers: 200, epoch: 6 | loss: 0.3823706\n",
      "\tspeed: 0.0379s/iter; left time: 506.0650s\n",
      "\titers: 300, epoch: 6 | loss: 0.3546154\n",
      "\tspeed: 0.0379s/iter; left time: 502.3867s\n",
      "\titers: 400, epoch: 6 | loss: 0.4042630\n",
      "\tspeed: 0.0376s/iter; left time: 495.1589s\n",
      "\titers: 500, epoch: 6 | loss: 0.3702920\n",
      "\tspeed: 0.0379s/iter; left time: 494.8419s\n",
      "\titers: 600, epoch: 6 | loss: 0.3241486\n",
      "\tspeed: 0.0379s/iter; left time: 490.8040s\n",
      "\titers: 700, epoch: 6 | loss: 0.3131693\n",
      "\tspeed: 0.0376s/iter; left time: 483.8363s\n",
      "\titers: 800, epoch: 6 | loss: 0.3480716\n",
      "\tspeed: 0.0376s/iter; left time: 479.7454s\n",
      "\titers: 900, epoch: 6 | loss: 0.3385166\n",
      "\tspeed: 0.0379s/iter; left time: 479.7705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.47s\n",
      "Steps: 904 | Train Loss: 0.3520005 Vali Loss: 0.3427493 Test Loss: 0.3960691\n",
      "Validation loss decreased (0.352416 --> 0.342749).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3257978\n",
      "\tspeed: 0.1087s/iter; left time: 1365.0427s\n",
      "\titers: 200, epoch: 7 | loss: 0.3060265\n",
      "\tspeed: 0.0374s/iter; left time: 465.5115s\n",
      "\titers: 300, epoch: 7 | loss: 0.3213648\n",
      "\tspeed: 0.0374s/iter; left time: 461.6358s\n",
      "\titers: 400, epoch: 7 | loss: 0.3344079\n",
      "\tspeed: 0.0373s/iter; left time: 457.5813s\n",
      "\titers: 500, epoch: 7 | loss: 0.3139322\n",
      "\tspeed: 0.0374s/iter; left time: 454.1602s\n",
      "\titers: 600, epoch: 7 | loss: 0.4115975\n",
      "\tspeed: 0.0374s/iter; left time: 450.5411s\n",
      "\titers: 700, epoch: 7 | loss: 0.2711030\n",
      "\tspeed: 0.0374s/iter; left time: 446.7296s\n",
      "\titers: 800, epoch: 7 | loss: 0.2758523\n",
      "\tspeed: 0.0373s/iter; left time: 442.0235s\n",
      "\titers: 900, epoch: 7 | loss: 0.3337854\n",
      "\tspeed: 0.0373s/iter; left time: 438.2933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.06s\n",
      "Steps: 904 | Train Loss: 0.3387172 Vali Loss: 0.3388032 Test Loss: 0.3871162\n",
      "Validation loss decreased (0.342749 --> 0.338803).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3699013\n",
      "\tspeed: 0.1078s/iter; left time: 1255.9829s\n",
      "\titers: 200, epoch: 8 | loss: 0.3346795\n",
      "\tspeed: 0.0379s/iter; left time: 437.7585s\n",
      "\titers: 300, epoch: 8 | loss: 0.3431664\n",
      "\tspeed: 0.0378s/iter; left time: 433.4690s\n",
      "\titers: 400, epoch: 8 | loss: 0.3564419\n",
      "\tspeed: 0.0379s/iter; left time: 429.8924s\n",
      "\titers: 500, epoch: 8 | loss: 0.3564197\n",
      "\tspeed: 0.0378s/iter; left time: 425.5796s\n",
      "\titers: 600, epoch: 8 | loss: 0.3307476\n",
      "\tspeed: 0.0378s/iter; left time: 422.0032s\n",
      "\titers: 700, epoch: 8 | loss: 0.3357987\n",
      "\tspeed: 0.0378s/iter; left time: 418.0906s\n",
      "\titers: 800, epoch: 8 | loss: 0.3137912\n",
      "\tspeed: 0.0378s/iter; left time: 414.4928s\n",
      "\titers: 900, epoch: 8 | loss: 0.3292007\n",
      "\tspeed: 0.0379s/iter; left time: 410.8994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:34.52s\n",
      "Steps: 904 | Train Loss: 0.3280150 Vali Loss: 0.3429517 Test Loss: 0.3893808\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3336306\n",
      "\tspeed: 0.1042s/iter; left time: 1120.2322s\n",
      "\titers: 200, epoch: 9 | loss: 0.3561867\n",
      "\tspeed: 0.0373s/iter; left time: 397.7378s\n",
      "\titers: 300, epoch: 9 | loss: 0.2943734\n",
      "\tspeed: 0.0374s/iter; left time: 394.3676s\n",
      "\titers: 400, epoch: 9 | loss: 0.2829053\n",
      "\tspeed: 0.0373s/iter; left time: 390.0952s\n",
      "\titers: 500, epoch: 9 | loss: 0.3137992\n",
      "\tspeed: 0.0425s/iter; left time: 439.6151s\n",
      "\titers: 600, epoch: 9 | loss: 0.3047760\n",
      "\tspeed: 0.0512s/iter; left time: 524.9662s\n",
      "\titers: 700, epoch: 9 | loss: 0.3227414\n",
      "\tspeed: 0.0510s/iter; left time: 517.5346s\n",
      "\titers: 800, epoch: 9 | loss: 0.2641133\n",
      "\tspeed: 0.0525s/iter; left time: 527.1532s\n",
      "\titers: 900, epoch: 9 | loss: 0.3348793\n",
      "\tspeed: 0.0569s/iter; left time: 566.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.90s\n",
      "Steps: 904 | Train Loss: 0.3184911 Vali Loss: 0.3498064 Test Loss: 0.3849750\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2850826\n",
      "\tspeed: 0.1580s/iter; left time: 1555.7947s\n",
      "\titers: 200, epoch: 10 | loss: 0.3443137\n",
      "\tspeed: 0.0536s/iter; left time: 522.2391s\n",
      "\titers: 300, epoch: 10 | loss: 0.2872691\n",
      "\tspeed: 0.0509s/iter; left time: 491.2019s\n",
      "\titers: 400, epoch: 10 | loss: 0.3559181\n",
      "\tspeed: 0.0503s/iter; left time: 480.1463s\n",
      "\titers: 500, epoch: 10 | loss: 0.3043775\n",
      "\tspeed: 0.0515s/iter; left time: 486.2637s\n",
      "\titers: 600, epoch: 10 | loss: 0.2985881\n",
      "\tspeed: 0.0514s/iter; left time: 480.2895s\n",
      "\titers: 700, epoch: 10 | loss: 0.3465948\n",
      "\tspeed: 0.0514s/iter; left time: 474.8910s\n",
      "\titers: 800, epoch: 10 | loss: 0.2926311\n",
      "\tspeed: 0.0512s/iter; left time: 468.1977s\n",
      "\titers: 900, epoch: 10 | loss: 0.3161303\n",
      "\tspeed: 0.0508s/iter; left time: 459.3361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.34s\n",
      "Steps: 904 | Train Loss: 0.3113359 Vali Loss: 0.3422723 Test Loss: 0.3976985\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3869461119174957, rmse:0.6220499277114868, mae:0.4298822283744812, rse:0.5695518255233765\n",
      "Original data scale mse:3797896.5, rmse:1948.8192138671875, mae:1355.7371826171875, rse:0.13714636862277985\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1723758\n",
      "\tspeed: 0.0418s/iter; left time: 751.8811s\n",
      "\titers: 200, epoch: 1 | loss: 1.0923966\n",
      "\tspeed: 0.0381s/iter; left time: 681.9491s\n",
      "\titers: 300, epoch: 1 | loss: 1.0925870\n",
      "\tspeed: 0.0378s/iter; left time: 672.0557s\n",
      "\titers: 400, epoch: 1 | loss: 1.0087974\n",
      "\tspeed: 0.0372s/iter; left time: 658.2657s\n",
      "\titers: 500, epoch: 1 | loss: 1.0019892\n",
      "\tspeed: 0.0371s/iter; left time: 651.6012s\n",
      "\titers: 600, epoch: 1 | loss: 0.9927037\n",
      "\tspeed: 0.0371s/iter; left time: 648.7675s\n",
      "\titers: 700, epoch: 1 | loss: 0.9992495\n",
      "\tspeed: 0.0371s/iter; left time: 645.0368s\n",
      "\titers: 800, epoch: 1 | loss: 1.0245043\n",
      "\tspeed: 0.0372s/iter; left time: 642.3244s\n",
      "\titers: 900, epoch: 1 | loss: 0.9338506\n",
      "\tspeed: 0.0372s/iter; left time: 639.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.28s\n",
      "Steps: 904 | Train Loss: 1.0621205 Vali Loss: 0.9838994 Test Loss: 1.1189704\n",
      "Validation loss decreased (inf --> 0.983899).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.8372134\n",
      "\tspeed: 0.1068s/iter; left time: 1823.6365s\n",
      "\titers: 200, epoch: 2 | loss: 0.6357085\n",
      "\tspeed: 0.0373s/iter; left time: 633.7693s\n",
      "\titers: 300, epoch: 2 | loss: 0.5664890\n",
      "\tspeed: 0.0373s/iter; left time: 629.9422s\n",
      "\titers: 400, epoch: 2 | loss: 0.5707482\n",
      "\tspeed: 0.0373s/iter; left time: 626.1328s\n",
      "\titers: 500, epoch: 2 | loss: 0.5865315\n",
      "\tspeed: 0.0373s/iter; left time: 622.6760s\n",
      "\titers: 600, epoch: 2 | loss: 0.5052512\n",
      "\tspeed: 0.0373s/iter; left time: 618.5385s\n",
      "\titers: 700, epoch: 2 | loss: 0.5620601\n",
      "\tspeed: 0.0373s/iter; left time: 615.3627s\n",
      "\titers: 800, epoch: 2 | loss: 0.5172294\n",
      "\tspeed: 0.0374s/iter; left time: 611.8688s\n",
      "\titers: 900, epoch: 2 | loss: 0.4295986\n",
      "\tspeed: 0.0374s/iter; left time: 608.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.06s\n",
      "Steps: 904 | Train Loss: 0.5851381 Vali Loss: 0.4430731 Test Loss: 0.5037498\n",
      "Validation loss decreased (0.983899 --> 0.443073).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4629588\n",
      "\tspeed: 0.1062s/iter; left time: 1718.1258s\n",
      "\titers: 200, epoch: 3 | loss: 0.4606518\n",
      "\tspeed: 0.0374s/iter; left time: 601.2585s\n",
      "\titers: 300, epoch: 3 | loss: 0.5261849\n",
      "\tspeed: 0.0374s/iter; left time: 597.6874s\n",
      "\titers: 400, epoch: 3 | loss: 0.4196442\n",
      "\tspeed: 0.0374s/iter; left time: 593.7044s\n",
      "\titers: 500, epoch: 3 | loss: 0.4515103\n",
      "\tspeed: 0.0392s/iter; left time: 618.8047s\n",
      "\titers: 600, epoch: 3 | loss: 0.3916742\n",
      "\tspeed: 0.0473s/iter; left time: 741.4646s\n",
      "\titers: 700, epoch: 3 | loss: 0.4154952\n",
      "\tspeed: 0.0468s/iter; left time: 728.5522s\n",
      "\titers: 800, epoch: 3 | loss: 0.4041061\n",
      "\tspeed: 0.0456s/iter; left time: 706.2767s\n",
      "\titers: 900, epoch: 3 | loss: 0.3417810\n",
      "\tspeed: 0.0473s/iter; left time: 726.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 904 | Train Loss: 0.4395213 Vali Loss: 0.3931786 Test Loss: 0.4474282\n",
      "Validation loss decreased (0.443073 --> 0.393179).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3745271\n",
      "\tspeed: 0.1535s/iter; left time: 2343.8377s\n",
      "\titers: 200, epoch: 4 | loss: 0.3465845\n",
      "\tspeed: 0.0462s/iter; left time: 701.0897s\n",
      "\titers: 300, epoch: 4 | loss: 0.3974585\n",
      "\tspeed: 0.0486s/iter; left time: 732.3458s\n",
      "\titers: 400, epoch: 4 | loss: 0.3754985\n",
      "\tspeed: 0.0456s/iter; left time: 683.3190s\n",
      "\titers: 500, epoch: 4 | loss: 0.4005319\n",
      "\tspeed: 0.0500s/iter; left time: 743.0389s\n",
      "\titers: 600, epoch: 4 | loss: 0.3692600\n",
      "\tspeed: 0.0466s/iter; left time: 688.0581s\n",
      "\titers: 700, epoch: 4 | loss: 0.3257625\n",
      "\tspeed: 0.0486s/iter; left time: 713.1010s\n",
      "\titers: 800, epoch: 4 | loss: 0.3811104\n",
      "\tspeed: 0.0459s/iter; left time: 668.2965s\n",
      "\titers: 900, epoch: 4 | loss: 0.3639949\n",
      "\tspeed: 0.0449s/iter; left time: 650.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.3934052 Vali Loss: 0.3563040 Test Loss: 0.4036741\n",
      "Validation loss decreased (0.393179 --> 0.356304).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3561719\n",
      "\tspeed: 0.1454s/iter; left time: 2088.8004s\n",
      "\titers: 200, epoch: 5 | loss: 0.3490588\n",
      "\tspeed: 0.0452s/iter; left time: 645.0533s\n",
      "\titers: 300, epoch: 5 | loss: 0.3404695\n",
      "\tspeed: 0.0463s/iter; left time: 655.5944s\n",
      "\titers: 400, epoch: 5 | loss: 0.3833436\n",
      "\tspeed: 0.0478s/iter; left time: 672.8529s\n",
      "\titers: 500, epoch: 5 | loss: 0.3245205\n",
      "\tspeed: 0.0456s/iter; left time: 636.5425s\n",
      "\titers: 600, epoch: 5 | loss: 0.3219224\n",
      "\tspeed: 0.0484s/iter; left time: 671.6492s\n",
      "\titers: 700, epoch: 5 | loss: 0.3131517\n",
      "\tspeed: 0.0447s/iter; left time: 615.3839s\n",
      "\titers: 800, epoch: 5 | loss: 0.3589566\n",
      "\tspeed: 0.0448s/iter; left time: 612.2157s\n",
      "\titers: 900, epoch: 5 | loss: 0.3347214\n",
      "\tspeed: 0.0449s/iter; left time: 609.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.48s\n",
      "Steps: 904 | Train Loss: 0.3666206 Vali Loss: 0.3465115 Test Loss: 0.3926442\n",
      "Validation loss decreased (0.356304 --> 0.346512).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3823621\n",
      "\tspeed: 0.1472s/iter; left time: 1981.3614s\n",
      "\titers: 200, epoch: 6 | loss: 0.3662101\n",
      "\tspeed: 0.0467s/iter; left time: 624.4435s\n",
      "\titers: 300, epoch: 6 | loss: 0.3216882\n",
      "\tspeed: 0.0445s/iter; left time: 590.7681s\n",
      "\titers: 400, epoch: 6 | loss: 0.3586378\n",
      "\tspeed: 0.0450s/iter; left time: 592.1954s\n",
      "\titers: 500, epoch: 6 | loss: 0.3315167\n",
      "\tspeed: 0.0452s/iter; left time: 590.0733s\n",
      "\titers: 600, epoch: 6 | loss: 0.3494461\n",
      "\tspeed: 0.0464s/iter; left time: 601.6402s\n",
      "\titers: 700, epoch: 6 | loss: 0.3077664\n",
      "\tspeed: 0.0452s/iter; left time: 581.7390s\n",
      "\titers: 800, epoch: 6 | loss: 0.3269218\n",
      "\tspeed: 0.0447s/iter; left time: 571.0014s\n",
      "\titers: 900, epoch: 6 | loss: 0.3123038\n",
      "\tspeed: 0.0445s/iter; left time: 562.8729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.77s\n",
      "Steps: 904 | Train Loss: 0.3503757 Vali Loss: 0.3400441 Test Loss: 0.3847094\n",
      "Validation loss decreased (0.346512 --> 0.340044).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3126443\n",
      "\tspeed: 0.1410s/iter; left time: 1771.1454s\n",
      "\titers: 200, epoch: 7 | loss: 0.3303203\n",
      "\tspeed: 0.0450s/iter; left time: 561.0521s\n",
      "\titers: 300, epoch: 7 | loss: 0.3287971\n",
      "\tspeed: 0.0450s/iter; left time: 555.7154s\n",
      "\titers: 400, epoch: 7 | loss: 0.3490609\n",
      "\tspeed: 0.0445s/iter; left time: 545.8512s\n",
      "\titers: 500, epoch: 7 | loss: 0.2693724\n",
      "\tspeed: 0.0467s/iter; left time: 567.5763s\n",
      "\titers: 600, epoch: 7 | loss: 0.2930682\n",
      "\tspeed: 0.0472s/iter; left time: 569.2560s\n",
      "\titers: 700, epoch: 7 | loss: 0.3325933\n",
      "\tspeed: 0.0457s/iter; left time: 546.0960s\n",
      "\titers: 800, epoch: 7 | loss: 0.3239843\n",
      "\tspeed: 0.0452s/iter; left time: 536.4973s\n",
      "\titers: 900, epoch: 7 | loss: 0.2961379\n",
      "\tspeed: 0.0446s/iter; left time: 524.3109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 904 | Train Loss: 0.3381275 Vali Loss: 0.3352806 Test Loss: 0.3811566\n",
      "Validation loss decreased (0.340044 --> 0.335281).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2764473\n",
      "\tspeed: 0.1417s/iter; left time: 1651.1741s\n",
      "\titers: 200, epoch: 8 | loss: 0.3480836\n",
      "\tspeed: 0.0449s/iter; left time: 518.4192s\n",
      "\titers: 300, epoch: 8 | loss: 0.2834201\n",
      "\tspeed: 0.0448s/iter; left time: 512.7067s\n",
      "\titers: 400, epoch: 8 | loss: 0.3761880\n",
      "\tspeed: 0.0456s/iter; left time: 517.3813s\n",
      "\titers: 500, epoch: 8 | loss: 0.2917714\n",
      "\tspeed: 0.0452s/iter; left time: 508.5608s\n",
      "\titers: 600, epoch: 8 | loss: 0.2932826\n",
      "\tspeed: 0.0461s/iter; left time: 514.1499s\n",
      "\titers: 700, epoch: 8 | loss: 0.3534221\n",
      "\tspeed: 0.0448s/iter; left time: 495.3484s\n",
      "\titers: 800, epoch: 8 | loss: 0.3562366\n",
      "\tspeed: 0.0476s/iter; left time: 520.8331s\n",
      "\titers: 900, epoch: 8 | loss: 0.2764478\n",
      "\tspeed: 0.0480s/iter; left time: 520.5780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.20s\n",
      "Steps: 904 | Train Loss: 0.3291977 Vali Loss: 0.3339471 Test Loss: 0.3827856\n",
      "Validation loss decreased (0.335281 --> 0.333947).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3173279\n",
      "\tspeed: 0.1389s/iter; left time: 1492.7773s\n",
      "\titers: 200, epoch: 9 | loss: 0.3794719\n",
      "\tspeed: 0.0446s/iter; left time: 475.1650s\n",
      "\titers: 300, epoch: 9 | loss: 0.3150712\n",
      "\tspeed: 0.0450s/iter; left time: 474.5042s\n",
      "\titers: 400, epoch: 9 | loss: 0.3565120\n",
      "\tspeed: 0.0459s/iter; left time: 479.9620s\n",
      "\titers: 500, epoch: 9 | loss: 0.3088547\n",
      "\tspeed: 0.0452s/iter; left time: 467.8879s\n",
      "\titers: 600, epoch: 9 | loss: 0.3774909\n",
      "\tspeed: 0.0463s/iter; left time: 474.4216s\n",
      "\titers: 700, epoch: 9 | loss: 0.3000014\n",
      "\tspeed: 0.0446s/iter; left time: 452.3071s\n",
      "\titers: 800, epoch: 9 | loss: 0.3099265\n",
      "\tspeed: 0.0445s/iter; left time: 446.8175s\n",
      "\titers: 900, epoch: 9 | loss: 0.3110897\n",
      "\tspeed: 0.0449s/iter; left time: 446.3301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.44s\n",
      "Steps: 904 | Train Loss: 0.3213481 Vali Loss: 0.3301098 Test Loss: 0.3766771\n",
      "Validation loss decreased (0.333947 --> 0.330110).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3831125\n",
      "\tspeed: 0.1404s/iter; left time: 1382.3472s\n",
      "\titers: 200, epoch: 10 | loss: 0.2777443\n",
      "\tspeed: 0.0458s/iter; left time: 446.0613s\n",
      "\titers: 300, epoch: 10 | loss: 0.3540948\n",
      "\tspeed: 0.0448s/iter; left time: 431.7235s\n",
      "\titers: 400, epoch: 10 | loss: 0.3720734\n",
      "\tspeed: 0.0447s/iter; left time: 427.0912s\n",
      "\titers: 500, epoch: 10 | loss: 0.3050776\n",
      "\tspeed: 0.0457s/iter; left time: 432.0376s\n",
      "\titers: 600, epoch: 10 | loss: 0.2767486\n",
      "\tspeed: 0.0441s/iter; left time: 412.2731s\n",
      "\titers: 700, epoch: 10 | loss: 0.3265895\n",
      "\tspeed: 0.0445s/iter; left time: 411.5437s\n",
      "\titers: 800, epoch: 10 | loss: 0.3533163\n",
      "\tspeed: 0.0446s/iter; left time: 407.5800s\n",
      "\titers: 900, epoch: 10 | loss: 0.3168455\n",
      "\tspeed: 0.0446s/iter; left time: 403.0763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 904 | Train Loss: 0.3138227 Vali Loss: 0.3418336 Test Loss: 0.3832616\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3367609\n",
      "\tspeed: 0.1404s/iter; left time: 1255.6275s\n",
      "\titers: 200, epoch: 11 | loss: 0.2990838\n",
      "\tspeed: 0.0487s/iter; left time: 430.6278s\n",
      "\titers: 300, epoch: 11 | loss: 0.3398824\n",
      "\tspeed: 0.0451s/iter; left time: 394.1334s\n",
      "\titers: 400, epoch: 11 | loss: 0.3052417\n",
      "\tspeed: 0.0448s/iter; left time: 387.1837s\n",
      "\titers: 500, epoch: 11 | loss: 0.3445686\n",
      "\tspeed: 0.0446s/iter; left time: 380.9084s\n",
      "\titers: 600, epoch: 11 | loss: 0.2751019\n",
      "\tspeed: 0.0480s/iter; left time: 405.2115s\n",
      "\titers: 700, epoch: 11 | loss: 0.3558990\n",
      "\tspeed: 0.0458s/iter; left time: 382.2258s\n",
      "\titers: 800, epoch: 11 | loss: 0.3025568\n",
      "\tspeed: 0.0450s/iter; left time: 370.9716s\n",
      "\titers: 900, epoch: 11 | loss: 0.3103669\n",
      "\tspeed: 0.0452s/iter; left time: 367.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:42.31s\n",
      "Steps: 904 | Train Loss: 0.3083285 Vali Loss: 0.3477830 Test Loss: 0.3808105\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3132444\n",
      "\tspeed: 0.1347s/iter; left time: 1082.9617s\n",
      "\titers: 200, epoch: 12 | loss: 0.3461895\n",
      "\tspeed: 0.0446s/iter; left time: 354.0492s\n",
      "\titers: 300, epoch: 12 | loss: 0.3017998\n",
      "\tspeed: 0.0443s/iter; left time: 347.3677s\n",
      "\titers: 400, epoch: 12 | loss: 0.2672259\n",
      "\tspeed: 0.0442s/iter; left time: 342.1553s\n",
      "\titers: 500, epoch: 12 | loss: 0.3088981\n",
      "\tspeed: 0.0444s/iter; left time: 339.0542s\n",
      "\titers: 600, epoch: 12 | loss: 0.3092912\n",
      "\tspeed: 0.0443s/iter; left time: 333.5680s\n",
      "\titers: 700, epoch: 12 | loss: 0.2365459\n",
      "\tspeed: 0.0441s/iter; left time: 328.0164s\n",
      "\titers: 800, epoch: 12 | loss: 0.3353027\n",
      "\tspeed: 0.0443s/iter; left time: 325.0353s\n",
      "\titers: 900, epoch: 12 | loss: 0.3185291\n",
      "\tspeed: 0.0476s/iter; left time: 344.3486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 904 | Train Loss: 0.3030028 Vali Loss: 0.3382875 Test Loss: 0.3782726\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3770226240158081, rmse:0.6140216588973999, mae:0.41869065165519714, rse:0.5622011423110962\n",
      "Original data scale mse:3531860.5, rmse:1879.324462890625, mae:1300.529052734375, rse:0.13225574791431427\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.2147181\n",
      "\tspeed: 0.0915s/iter; left time: 1641.7168s\n",
      "\titers: 200, epoch: 1 | loss: 1.0167061\n",
      "\tspeed: 0.0526s/iter; left time: 937.6830s\n",
      "\titers: 300, epoch: 1 | loss: 1.1068282\n",
      "\tspeed: 0.0516s/iter; left time: 915.6676s\n",
      "\titers: 400, epoch: 1 | loss: 1.0391784\n",
      "\tspeed: 0.0519s/iter; left time: 914.8786s\n",
      "\titers: 500, epoch: 1 | loss: 1.0616466\n",
      "\tspeed: 0.0518s/iter; left time: 909.2079s\n",
      "\titers: 600, epoch: 1 | loss: 1.0500189\n",
      "\tspeed: 0.0517s/iter; left time: 901.0486s\n",
      "\titers: 700, epoch: 1 | loss: 0.9692436\n",
      "\tspeed: 0.0520s/iter; left time: 902.2341s\n",
      "\titers: 800, epoch: 1 | loss: 1.0926714\n",
      "\tspeed: 0.0515s/iter; left time: 888.0301s\n",
      "\titers: 900, epoch: 1 | loss: 0.9898307\n",
      "\tspeed: 0.0514s/iter; left time: 881.1636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.99s\n",
      "Steps: 902 | Train Loss: 1.0461775 Vali Loss: 0.9852436 Test Loss: 1.1069876\n",
      "Validation loss decreased (inf --> 0.985244).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.9353632\n",
      "\tspeed: 0.1555s/iter; left time: 2649.4137s\n",
      "\titers: 200, epoch: 2 | loss: 0.7754266\n",
      "\tspeed: 0.0518s/iter; left time: 876.8056s\n",
      "\titers: 300, epoch: 2 | loss: 0.7538111\n",
      "\tspeed: 0.0519s/iter; left time: 873.7351s\n",
      "\titers: 400, epoch: 2 | loss: 0.7300932\n",
      "\tspeed: 0.0532s/iter; left time: 890.4934s\n",
      "\titers: 500, epoch: 2 | loss: 0.6704146\n",
      "\tspeed: 0.0540s/iter; left time: 897.9873s\n",
      "\titers: 600, epoch: 2 | loss: 0.7159262\n",
      "\tspeed: 0.0528s/iter; left time: 873.4138s\n",
      "\titers: 700, epoch: 2 | loss: 0.6027539\n",
      "\tspeed: 0.0532s/iter; left time: 874.7242s\n",
      "\titers: 800, epoch: 2 | loss: 0.6362133\n",
      "\tspeed: 0.0529s/iter; left time: 863.7176s\n",
      "\titers: 900, epoch: 2 | loss: 0.6569429\n",
      "\tspeed: 0.0524s/iter; left time: 850.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.10s\n",
      "Steps: 902 | Train Loss: 0.7413848 Vali Loss: 0.6304079 Test Loss: 0.7144914\n",
      "Validation loss decreased (0.985244 --> 0.630408).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6347013\n",
      "\tspeed: 0.1660s/iter; left time: 2678.6129s\n",
      "\titers: 200, epoch: 3 | loss: 0.6313438\n",
      "\tspeed: 0.0521s/iter; left time: 835.9819s\n",
      "\titers: 300, epoch: 3 | loss: 0.6621436\n",
      "\tspeed: 0.0519s/iter; left time: 826.9744s\n",
      "\titers: 400, epoch: 3 | loss: 0.6615957\n",
      "\tspeed: 0.0522s/iter; left time: 827.0850s\n",
      "\titers: 500, epoch: 3 | loss: 0.6516954\n",
      "\tspeed: 0.0519s/iter; left time: 816.7319s\n",
      "\titers: 600, epoch: 3 | loss: 0.5854301\n",
      "\tspeed: 0.0520s/iter; left time: 812.6557s\n",
      "\titers: 700, epoch: 3 | loss: 0.5692053\n",
      "\tspeed: 0.0521s/iter; left time: 808.8021s\n",
      "\titers: 800, epoch: 3 | loss: 0.5779681\n",
      "\tspeed: 0.0518s/iter; left time: 800.2411s\n",
      "\titers: 900, epoch: 3 | loss: 0.5831131\n",
      "\tspeed: 0.0525s/iter; left time: 804.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.71s\n",
      "Steps: 902 | Train Loss: 0.6111346 Vali Loss: 0.5476540 Test Loss: 0.6404488\n",
      "Validation loss decreased (0.630408 --> 0.547654).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5693672\n",
      "\tspeed: 0.1682s/iter; left time: 2562.6631s\n",
      "\titers: 200, epoch: 4 | loss: 0.5306808\n",
      "\tspeed: 0.0529s/iter; left time: 800.1009s\n",
      "\titers: 300, epoch: 4 | loss: 0.5755481\n",
      "\tspeed: 0.0525s/iter; left time: 789.6064s\n",
      "\titers: 400, epoch: 4 | loss: 0.5084465\n",
      "\tspeed: 0.0527s/iter; left time: 786.8983s\n",
      "\titers: 500, epoch: 4 | loss: 0.5164704\n",
      "\tspeed: 0.0524s/iter; left time: 776.9768s\n",
      "\titers: 600, epoch: 4 | loss: 0.4489105\n",
      "\tspeed: 0.0534s/iter; left time: 786.6279s\n",
      "\titers: 700, epoch: 4 | loss: 0.5077611\n",
      "\tspeed: 0.0521s/iter; left time: 762.3490s\n",
      "\titers: 800, epoch: 4 | loss: 0.5135603\n",
      "\tspeed: 0.0540s/iter; left time: 784.6791s\n",
      "\titers: 900, epoch: 4 | loss: 0.4379234\n",
      "\tspeed: 0.0524s/iter; left time: 757.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.5116455 Vali Loss: 0.4331906 Test Loss: 0.4933012\n",
      "Validation loss decreased (0.547654 --> 0.433191).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4150350\n",
      "\tspeed: 0.1722s/iter; left time: 2468.2498s\n",
      "\titers: 200, epoch: 5 | loss: 0.4178660\n",
      "\tspeed: 0.0541s/iter; left time: 769.6448s\n",
      "\titers: 300, epoch: 5 | loss: 0.4711992\n",
      "\tspeed: 0.0522s/iter; left time: 737.7258s\n",
      "\titers: 400, epoch: 5 | loss: 0.4593130\n",
      "\tspeed: 0.0521s/iter; left time: 731.0883s\n",
      "\titers: 500, epoch: 5 | loss: 0.4621800\n",
      "\tspeed: 0.0524s/iter; left time: 730.3117s\n",
      "\titers: 600, epoch: 5 | loss: 0.4883125\n",
      "\tspeed: 0.0519s/iter; left time: 717.7441s\n",
      "\titers: 700, epoch: 5 | loss: 0.4997795\n",
      "\tspeed: 0.0519s/iter; left time: 712.2846s\n",
      "\titers: 800, epoch: 5 | loss: 0.4151840\n",
      "\tspeed: 0.0526s/iter; left time: 717.1320s\n",
      "\titers: 900, epoch: 5 | loss: 0.3846617\n",
      "\tspeed: 0.0524s/iter; left time: 709.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.4358802 Vali Loss: 0.3986667 Test Loss: 0.4549847\n",
      "Validation loss decreased (0.433191 --> 0.398667).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4053108\n",
      "\tspeed: 0.1666s/iter; left time: 2238.0373s\n",
      "\titers: 200, epoch: 6 | loss: 0.3978311\n",
      "\tspeed: 0.0535s/iter; left time: 713.8499s\n",
      "\titers: 300, epoch: 6 | loss: 0.3666820\n",
      "\tspeed: 0.0530s/iter; left time: 701.1315s\n",
      "\titers: 400, epoch: 6 | loss: 0.3955077\n",
      "\tspeed: 0.0524s/iter; left time: 688.2692s\n",
      "\titers: 500, epoch: 6 | loss: 0.3854752\n",
      "\tspeed: 0.0526s/iter; left time: 685.6981s\n",
      "\titers: 600, epoch: 6 | loss: 0.4167851\n",
      "\tspeed: 0.0524s/iter; left time: 677.5021s\n",
      "\titers: 700, epoch: 6 | loss: 0.3830214\n",
      "\tspeed: 0.0553s/iter; left time: 709.5673s\n",
      "\titers: 800, epoch: 6 | loss: 0.3848485\n",
      "\tspeed: 0.0564s/iter; left time: 718.3830s\n",
      "\titers: 900, epoch: 6 | loss: 0.3858470\n",
      "\tspeed: 0.0561s/iter; left time: 708.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 902 | Train Loss: 0.4081907 Vali Loss: 0.3870661 Test Loss: 0.4455177\n",
      "Validation loss decreased (0.398667 --> 0.387066).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4503771\n",
      "\tspeed: 0.1689s/iter; left time: 2116.7061s\n",
      "\titers: 200, epoch: 7 | loss: 0.4395337\n",
      "\tspeed: 0.0572s/iter; left time: 711.2022s\n",
      "\titers: 300, epoch: 7 | loss: 0.3524917\n",
      "\tspeed: 0.0576s/iter; left time: 710.3469s\n",
      "\titers: 400, epoch: 7 | loss: 0.4157000\n",
      "\tspeed: 0.0570s/iter; left time: 697.3422s\n",
      "\titers: 500, epoch: 7 | loss: 0.3965919\n",
      "\tspeed: 0.0549s/iter; left time: 666.0861s\n",
      "\titers: 600, epoch: 7 | loss: 0.3908841\n",
      "\tspeed: 0.0523s/iter; left time: 629.5745s\n",
      "\titers: 700, epoch: 7 | loss: 0.3795938\n",
      "\tspeed: 0.0537s/iter; left time: 640.3056s\n",
      "\titers: 800, epoch: 7 | loss: 0.3711993\n",
      "\tspeed: 0.0530s/iter; left time: 626.6602s\n",
      "\titers: 900, epoch: 7 | loss: 0.3606561\n",
      "\tspeed: 0.0530s/iter; left time: 621.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.60s\n",
      "Steps: 902 | Train Loss: 0.3910665 Vali Loss: 0.3876925 Test Loss: 0.4345537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3880823\n",
      "\tspeed: 0.1658s/iter; left time: 1927.7360s\n",
      "\titers: 200, epoch: 8 | loss: 0.3811528\n",
      "\tspeed: 0.0550s/iter; left time: 634.4632s\n",
      "\titers: 300, epoch: 8 | loss: 0.4339515\n",
      "\tspeed: 0.0528s/iter; left time: 602.8914s\n",
      "\titers: 400, epoch: 8 | loss: 0.3706779\n",
      "\tspeed: 0.0530s/iter; left time: 600.4877s\n",
      "\titers: 500, epoch: 8 | loss: 0.3922608\n",
      "\tspeed: 0.0528s/iter; left time: 592.4684s\n",
      "\titers: 600, epoch: 8 | loss: 0.3372646\n",
      "\tspeed: 0.0521s/iter; left time: 580.0028s\n",
      "\titers: 700, epoch: 8 | loss: 0.3345825\n",
      "\tspeed: 0.0521s/iter; left time: 574.7959s\n",
      "\titers: 800, epoch: 8 | loss: 0.3584860\n",
      "\tspeed: 0.0527s/iter; left time: 575.5595s\n",
      "\titers: 900, epoch: 8 | loss: 0.3618881\n",
      "\tspeed: 0.0524s/iter; left time: 567.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.49s\n",
      "Steps: 902 | Train Loss: 0.3788810 Vali Loss: 0.3786058 Test Loss: 0.4177624\n",
      "Validation loss decreased (0.387066 --> 0.378606).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3911105\n",
      "\tspeed: 0.1668s/iter; left time: 1789.1856s\n",
      "\titers: 200, epoch: 9 | loss: 0.3623602\n",
      "\tspeed: 0.0557s/iter; left time: 592.0548s\n",
      "\titers: 300, epoch: 9 | loss: 0.3635693\n",
      "\tspeed: 0.0553s/iter; left time: 582.2304s\n",
      "\titers: 400, epoch: 9 | loss: 0.3573028\n",
      "\tspeed: 0.0532s/iter; left time: 554.0924s\n",
      "\titers: 500, epoch: 9 | loss: 0.4644890\n",
      "\tspeed: 0.0549s/iter; left time: 566.6070s\n",
      "\titers: 600, epoch: 9 | loss: 0.3754826\n",
      "\tspeed: 0.0533s/iter; left time: 544.5347s\n",
      "\titers: 700, epoch: 9 | loss: 0.4114365\n",
      "\tspeed: 0.0525s/iter; left time: 531.6482s\n",
      "\titers: 800, epoch: 9 | loss: 0.3664558\n",
      "\tspeed: 0.0534s/iter; left time: 535.3473s\n",
      "\titers: 900, epoch: 9 | loss: 0.3348431\n",
      "\tspeed: 0.0530s/iter; left time: 526.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.37s\n",
      "Steps: 902 | Train Loss: 0.3689948 Vali Loss: 0.3753327 Test Loss: 0.4279090\n",
      "Validation loss decreased (0.378606 --> 0.375333).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3873818\n",
      "\tspeed: 0.1607s/iter; left time: 1578.5515s\n",
      "\titers: 200, epoch: 10 | loss: 0.3573802\n",
      "\tspeed: 0.0527s/iter; left time: 512.6089s\n",
      "\titers: 300, epoch: 10 | loss: 0.3110060\n",
      "\tspeed: 0.0537s/iter; left time: 516.2831s\n",
      "\titers: 400, epoch: 10 | loss: 0.3649977\n",
      "\tspeed: 0.0548s/iter; left time: 522.1752s\n",
      "\titers: 500, epoch: 10 | loss: 0.3911813\n",
      "\tspeed: 0.0546s/iter; left time: 514.8062s\n",
      "\titers: 600, epoch: 10 | loss: 0.3021829\n",
      "\tspeed: 0.0535s/iter; left time: 498.7393s\n",
      "\titers: 700, epoch: 10 | loss: 0.3501657\n",
      "\tspeed: 0.0524s/iter; left time: 483.5662s\n",
      "\titers: 800, epoch: 10 | loss: 0.3933826\n",
      "\tspeed: 0.0544s/iter; left time: 496.6623s\n",
      "\titers: 900, epoch: 10 | loss: 0.3612310\n",
      "\tspeed: 0.0527s/iter; left time: 475.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.3600891 Vali Loss: 0.3729810 Test Loss: 0.4183161\n",
      "Validation loss decreased (0.375333 --> 0.372981).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.4035973\n",
      "\tspeed: 0.1657s/iter; left time: 1478.6169s\n",
      "\titers: 200, epoch: 11 | loss: 0.2772275\n",
      "\tspeed: 0.0529s/iter; left time: 466.3895s\n",
      "\titers: 300, epoch: 11 | loss: 0.4043022\n",
      "\tspeed: 0.0527s/iter; left time: 459.2678s\n",
      "\titers: 400, epoch: 11 | loss: 0.3979796\n",
      "\tspeed: 0.0527s/iter; left time: 454.3471s\n",
      "\titers: 500, epoch: 11 | loss: 0.3674277\n",
      "\tspeed: 0.0529s/iter; left time: 451.1424s\n",
      "\titers: 600, epoch: 11 | loss: 0.3387622\n",
      "\tspeed: 0.0524s/iter; left time: 441.0479s\n",
      "\titers: 700, epoch: 11 | loss: 0.4200476\n",
      "\tspeed: 0.0524s/iter; left time: 435.8247s\n",
      "\titers: 800, epoch: 11 | loss: 0.3645056\n",
      "\tspeed: 0.0542s/iter; left time: 445.6470s\n",
      "\titers: 900, epoch: 11 | loss: 0.3942296\n",
      "\tspeed: 0.0523s/iter; left time: 424.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.3527447 Vali Loss: 0.3702950 Test Loss: 0.4193223\n",
      "Validation loss decreased (0.372981 --> 0.370295).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3663423\n",
      "\tspeed: 0.1654s/iter; left time: 1326.4058s\n",
      "\titers: 200, epoch: 12 | loss: 0.3199306\n",
      "\tspeed: 0.0531s/iter; left time: 420.5897s\n",
      "\titers: 300, epoch: 12 | loss: 0.3354211\n",
      "\tspeed: 0.0526s/iter; left time: 411.5802s\n",
      "\titers: 400, epoch: 12 | loss: 0.3089432\n",
      "\tspeed: 0.0528s/iter; left time: 407.3477s\n",
      "\titers: 500, epoch: 12 | loss: 0.3237096\n",
      "\tspeed: 0.0526s/iter; left time: 400.4030s\n",
      "\titers: 600, epoch: 12 | loss: 0.3408310\n",
      "\tspeed: 0.0526s/iter; left time: 395.3458s\n",
      "\titers: 700, epoch: 12 | loss: 0.3262950\n",
      "\tspeed: 0.0529s/iter; left time: 392.7569s\n",
      "\titers: 800, epoch: 12 | loss: 0.3188859\n",
      "\tspeed: 0.0525s/iter; left time: 384.3195s\n",
      "\titers: 900, epoch: 12 | loss: 0.3326680\n",
      "\tspeed: 0.0525s/iter; left time: 378.6808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.3463631 Vali Loss: 0.3712225 Test Loss: 0.4137136\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3695998\n",
      "\tspeed: 0.1643s/iter; left time: 1169.5112s\n",
      "\titers: 200, epoch: 13 | loss: 0.3577492\n",
      "\tspeed: 0.0563s/iter; left time: 394.9354s\n",
      "\titers: 300, epoch: 13 | loss: 0.3361263\n",
      "\tspeed: 0.0562s/iter; left time: 388.4677s\n",
      "\titers: 400, epoch: 13 | loss: 0.2906371\n",
      "\tspeed: 0.0558s/iter; left time: 380.0491s\n",
      "\titers: 500, epoch: 13 | loss: 0.3078147\n",
      "\tspeed: 0.0535s/iter; left time: 359.1590s\n",
      "\titers: 600, epoch: 13 | loss: 0.3537507\n",
      "\tspeed: 0.0519s/iter; left time: 343.5018s\n",
      "\titers: 700, epoch: 13 | loss: 0.3400373\n",
      "\tspeed: 0.0533s/iter; left time: 347.3759s\n",
      "\titers: 800, epoch: 13 | loss: 0.3614342\n",
      "\tspeed: 0.0522s/iter; left time: 335.1992s\n",
      "\titers: 900, epoch: 13 | loss: 0.3103076\n",
      "\tspeed: 0.0519s/iter; left time: 327.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:49.52s\n",
      "Steps: 902 | Train Loss: 0.3406159 Vali Loss: 0.3727784 Test Loss: 0.4103913\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.3683476\n",
      "\tspeed: 0.1639s/iter; left time: 1018.6173s\n",
      "\titers: 200, epoch: 14 | loss: 0.3251800\n",
      "\tspeed: 0.0544s/iter; left time: 332.5857s\n",
      "\titers: 300, epoch: 14 | loss: 0.3246317\n",
      "\tspeed: 0.0529s/iter; left time: 318.1064s\n",
      "\titers: 400, epoch: 14 | loss: 0.3714025\n",
      "\tspeed: 0.0529s/iter; left time: 313.0042s\n",
      "\titers: 500, epoch: 14 | loss: 0.3415084\n",
      "\tspeed: 0.0526s/iter; left time: 306.0634s\n",
      "\titers: 600, epoch: 14 | loss: 0.3368054\n",
      "\tspeed: 0.0520s/iter; left time: 297.2395s\n",
      "\titers: 700, epoch: 14 | loss: 0.3049992\n",
      "\tspeed: 0.0523s/iter; left time: 293.7230s\n",
      "\titers: 800, epoch: 14 | loss: 0.2789898\n",
      "\tspeed: 0.0523s/iter; left time: 288.3921s\n",
      "\titers: 900, epoch: 14 | loss: 0.3670358\n",
      "\tspeed: 0.0522s/iter; left time: 282.7966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.3354853 Vali Loss: 0.3822657 Test Loss: 0.4121031\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4194899797439575, rmse:0.6476804614067078, mae:0.4588198959827423, rse:0.5931959748268127\n",
      "Original data scale mse:4956448.0, rmse:2226.30810546875, mae:1516.3369140625, rse:0.15682151913642883\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1655840\n",
      "\tspeed: 0.0601s/iter; left time: 1077.3834s\n",
      "\titers: 200, epoch: 1 | loss: 1.0511764\n",
      "\tspeed: 0.0531s/iter; left time: 947.5361s\n",
      "\titers: 300, epoch: 1 | loss: 1.0640095\n",
      "\tspeed: 0.0529s/iter; left time: 938.9490s\n",
      "\titers: 400, epoch: 1 | loss: 1.0637138\n",
      "\tspeed: 0.0521s/iter; left time: 919.2831s\n",
      "\titers: 500, epoch: 1 | loss: 1.0263770\n",
      "\tspeed: 0.0521s/iter; left time: 913.4651s\n",
      "\titers: 600, epoch: 1 | loss: 1.0214175\n",
      "\tspeed: 0.0532s/iter; left time: 927.2817s\n",
      "\titers: 700, epoch: 1 | loss: 0.9905028\n",
      "\tspeed: 0.0527s/iter; left time: 913.1862s\n",
      "\titers: 800, epoch: 1 | loss: 0.9785476\n",
      "\tspeed: 0.0531s/iter; left time: 914.9196s\n",
      "\titers: 900, epoch: 1 | loss: 0.9685876\n",
      "\tspeed: 0.0524s/iter; left time: 898.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 1.0464421 Vali Loss: 0.9736041 Test Loss: 1.1094111\n",
      "Validation loss decreased (inf --> 0.973604).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.8390766\n",
      "\tspeed: 0.1672s/iter; left time: 2849.0049s\n",
      "\titers: 200, epoch: 2 | loss: 0.7458485\n",
      "\tspeed: 0.0522s/iter; left time: 884.8776s\n",
      "\titers: 300, epoch: 2 | loss: 0.7714166\n",
      "\tspeed: 0.0531s/iter; left time: 894.8963s\n",
      "\titers: 400, epoch: 2 | loss: 0.7220364\n",
      "\tspeed: 0.0537s/iter; left time: 898.8033s\n",
      "\titers: 500, epoch: 2 | loss: 0.7895324\n",
      "\tspeed: 0.0524s/iter; left time: 872.3047s\n",
      "\titers: 600, epoch: 2 | loss: 0.6619458\n",
      "\tspeed: 0.0520s/iter; left time: 859.5012s\n",
      "\titers: 700, epoch: 2 | loss: 0.7235180\n",
      "\tspeed: 0.0525s/iter; left time: 862.7935s\n",
      "\titers: 800, epoch: 2 | loss: 0.6239758\n",
      "\tspeed: 0.0528s/iter; left time: 862.2047s\n",
      "\titers: 900, epoch: 2 | loss: 0.6723674\n",
      "\tspeed: 0.0479s/iter; left time: 777.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.96s\n",
      "Steps: 902 | Train Loss: 0.7375900 Vali Loss: 0.6224101 Test Loss: 0.7162176\n",
      "Validation loss decreased (0.973604 --> 0.622410).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6410921\n",
      "\tspeed: 0.1331s/iter; left time: 2147.8335s\n",
      "\titers: 200, epoch: 3 | loss: 0.6416114\n",
      "\tspeed: 0.0466s/iter; left time: 747.7125s\n",
      "\titers: 300, epoch: 3 | loss: 0.6296296\n",
      "\tspeed: 0.0466s/iter; left time: 742.3189s\n",
      "\titers: 400, epoch: 3 | loss: 0.6626686\n",
      "\tspeed: 0.0466s/iter; left time: 737.7355s\n",
      "\titers: 500, epoch: 3 | loss: 0.5845461\n",
      "\tspeed: 0.0465s/iter; left time: 731.7667s\n",
      "\titers: 600, epoch: 3 | loss: 0.5587022\n",
      "\tspeed: 0.0467s/iter; left time: 730.5272s\n",
      "\titers: 700, epoch: 3 | loss: 0.5248883\n",
      "\tspeed: 0.0478s/iter; left time: 742.6562s\n",
      "\titers: 800, epoch: 3 | loss: 0.5764485\n",
      "\tspeed: 0.0476s/iter; left time: 734.8430s\n",
      "\titers: 900, epoch: 3 | loss: 0.5774642\n",
      "\tspeed: 0.0474s/iter; left time: 726.7611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.66s\n",
      "Steps: 902 | Train Loss: 0.6039485 Vali Loss: 0.5346621 Test Loss: 0.6204205\n",
      "Validation loss decreased (0.622410 --> 0.534662).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5430565\n",
      "\tspeed: 0.1307s/iter; left time: 1990.5501s\n",
      "\titers: 200, epoch: 4 | loss: 0.5418193\n",
      "\tspeed: 0.0473s/iter; left time: 715.6849s\n",
      "\titers: 300, epoch: 4 | loss: 0.5740551\n",
      "\tspeed: 0.0465s/iter; left time: 699.0283s\n",
      "\titers: 400, epoch: 4 | loss: 0.5191970\n",
      "\tspeed: 0.0463s/iter; left time: 692.0782s\n",
      "\titers: 500, epoch: 4 | loss: 0.4838539\n",
      "\tspeed: 0.0463s/iter; left time: 686.5272s\n",
      "\titers: 600, epoch: 4 | loss: 0.5054529\n",
      "\tspeed: 0.0463s/iter; left time: 682.5564s\n",
      "\titers: 700, epoch: 4 | loss: 0.4909984\n",
      "\tspeed: 0.0463s/iter; left time: 677.3005s\n",
      "\titers: 800, epoch: 4 | loss: 0.4362298\n",
      "\tspeed: 0.0463s/iter; left time: 672.6959s\n",
      "\titers: 900, epoch: 4 | loss: 0.4590242\n",
      "\tspeed: 0.0462s/iter; left time: 667.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.21s\n",
      "Steps: 902 | Train Loss: 0.5058078 Vali Loss: 0.4375512 Test Loss: 0.5008789\n",
      "Validation loss decreased (0.534662 --> 0.437551).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4321361\n",
      "\tspeed: 0.1293s/iter; left time: 1853.2748s\n",
      "\titers: 200, epoch: 5 | loss: 0.4532109\n",
      "\tspeed: 0.0464s/iter; left time: 659.9105s\n",
      "\titers: 300, epoch: 5 | loss: 0.4666269\n",
      "\tspeed: 0.0465s/iter; left time: 656.6357s\n",
      "\titers: 400, epoch: 5 | loss: 0.4492691\n",
      "\tspeed: 0.0462s/iter; left time: 648.1446s\n",
      "\titers: 500, epoch: 5 | loss: 0.4593451\n",
      "\tspeed: 0.0463s/iter; left time: 644.4682s\n",
      "\titers: 600, epoch: 5 | loss: 0.4213714\n",
      "\tspeed: 0.0464s/iter; left time: 642.0722s\n",
      "\titers: 700, epoch: 5 | loss: 0.4087714\n",
      "\tspeed: 0.0558s/iter; left time: 766.7703s\n",
      "\titers: 800, epoch: 5 | loss: 0.3892110\n",
      "\tspeed: 0.0467s/iter; left time: 636.5095s\n",
      "\titers: 900, epoch: 5 | loss: 0.4193296\n",
      "\tspeed: 0.0467s/iter; left time: 632.3572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 902 | Train Loss: 0.4325790 Vali Loss: 0.4041875 Test Loss: 0.4563365\n",
      "Validation loss decreased (0.437551 --> 0.404187).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3751336\n",
      "\tspeed: 0.1438s/iter; left time: 1931.4021s\n",
      "\titers: 200, epoch: 6 | loss: 0.4011744\n",
      "\tspeed: 0.0468s/iter; left time: 624.0096s\n",
      "\titers: 300, epoch: 6 | loss: 0.4407718\n",
      "\tspeed: 0.0469s/iter; left time: 619.9128s\n",
      "\titers: 400, epoch: 6 | loss: 0.4343729\n",
      "\tspeed: 0.0469s/iter; left time: 615.2913s\n",
      "\titers: 500, epoch: 6 | loss: 0.3417299\n",
      "\tspeed: 0.0489s/iter; left time: 637.7918s\n",
      "\titers: 600, epoch: 6 | loss: 0.4190248\n",
      "\tspeed: 0.0478s/iter; left time: 618.2469s\n",
      "\titers: 700, epoch: 6 | loss: 0.3822419\n",
      "\tspeed: 0.0464s/iter; left time: 595.3331s\n",
      "\titers: 800, epoch: 6 | loss: 0.3611960\n",
      "\tspeed: 0.0461s/iter; left time: 586.9034s\n",
      "\titers: 900, epoch: 6 | loss: 0.3905156\n",
      "\tspeed: 0.0462s/iter; left time: 583.3569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.59s\n",
      "Steps: 902 | Train Loss: 0.4065604 Vali Loss: 0.3937814 Test Loss: 0.4532544\n",
      "Validation loss decreased (0.404187 --> 0.393781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3974481\n",
      "\tspeed: 0.1307s/iter; left time: 1637.6729s\n",
      "\titers: 200, epoch: 7 | loss: 0.3828853\n",
      "\tspeed: 0.0471s/iter; left time: 584.8015s\n",
      "\titers: 300, epoch: 7 | loss: 0.4154547\n",
      "\tspeed: 0.0466s/iter; left time: 574.7518s\n",
      "\titers: 400, epoch: 7 | loss: 0.4468302\n",
      "\tspeed: 0.0486s/iter; left time: 593.9739s\n",
      "\titers: 500, epoch: 7 | loss: 0.3354870\n",
      "\tspeed: 0.0519s/iter; left time: 629.2333s\n",
      "\titers: 600, epoch: 7 | loss: 0.3583922\n",
      "\tspeed: 0.0467s/iter; left time: 561.9504s\n",
      "\titers: 700, epoch: 7 | loss: 0.4006066\n",
      "\tspeed: 0.0462s/iter; left time: 551.4668s\n",
      "\titers: 800, epoch: 7 | loss: 0.3655950\n",
      "\tspeed: 0.0462s/iter; left time: 546.5641s\n",
      "\titers: 900, epoch: 7 | loss: 0.3779635\n",
      "\tspeed: 0.0467s/iter; left time: 547.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 902 | Train Loss: 0.3912160 Vali Loss: 0.3754974 Test Loss: 0.4369135\n",
      "Validation loss decreased (0.393781 --> 0.375497).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3870946\n",
      "\tspeed: 0.1296s/iter; left time: 1506.9827s\n",
      "\titers: 200, epoch: 8 | loss: 0.4214657\n",
      "\tspeed: 0.0471s/iter; left time: 542.6158s\n",
      "\titers: 300, epoch: 8 | loss: 0.3871581\n",
      "\tspeed: 0.0467s/iter; left time: 534.0797s\n",
      "\titers: 400, epoch: 8 | loss: 0.4085595\n",
      "\tspeed: 0.0463s/iter; left time: 524.4351s\n",
      "\titers: 500, epoch: 8 | loss: 0.3870016\n",
      "\tspeed: 0.0462s/iter; left time: 519.1457s\n",
      "\titers: 600, epoch: 8 | loss: 0.3928266\n",
      "\tspeed: 0.0467s/iter; left time: 519.2051s\n",
      "\titers: 700, epoch: 8 | loss: 0.3973812\n",
      "\tspeed: 0.0516s/iter; left time: 569.2364s\n",
      "\titers: 800, epoch: 8 | loss: 0.3584932\n",
      "\tspeed: 0.0515s/iter; left time: 563.0737s\n",
      "\titers: 900, epoch: 8 | loss: 0.3710617\n",
      "\tspeed: 0.0462s/iter; left time: 500.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 902 | Train Loss: 0.3800395 Vali Loss: 0.3756704 Test Loss: 0.4353347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3249960\n",
      "\tspeed: 0.1274s/iter; left time: 1366.6820s\n",
      "\titers: 200, epoch: 9 | loss: 0.4016396\n",
      "\tspeed: 0.0464s/iter; left time: 493.2978s\n",
      "\titers: 300, epoch: 9 | loss: 0.4239801\n",
      "\tspeed: 0.0461s/iter; left time: 485.5428s\n",
      "\titers: 400, epoch: 9 | loss: 0.3946806\n",
      "\tspeed: 0.0461s/iter; left time: 480.8564s\n",
      "\titers: 500, epoch: 9 | loss: 0.3899369\n",
      "\tspeed: 0.0461s/iter; left time: 476.4516s\n",
      "\titers: 600, epoch: 9 | loss: 0.3555636\n",
      "\tspeed: 0.0465s/iter; left time: 475.4124s\n",
      "\titers: 700, epoch: 9 | loss: 0.3494029\n",
      "\tspeed: 0.0461s/iter; left time: 467.2670s\n",
      "\titers: 800, epoch: 9 | loss: 0.3780527\n",
      "\tspeed: 0.0463s/iter; left time: 464.0994s\n",
      "\titers: 900, epoch: 9 | loss: 0.3550397\n",
      "\tspeed: 0.0464s/iter; left time: 460.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 902 | Train Loss: 0.3705385 Vali Loss: 0.3751836 Test Loss: 0.4416038\n",
      "Validation loss decreased (0.375497 --> 0.375184).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3863989\n",
      "\tspeed: 0.1289s/iter; left time: 1266.6040s\n",
      "\titers: 200, epoch: 10 | loss: 0.4104721\n",
      "\tspeed: 0.0460s/iter; left time: 447.7433s\n",
      "\titers: 300, epoch: 10 | loss: 0.3469571\n",
      "\tspeed: 0.0461s/iter; left time: 443.4901s\n",
      "\titers: 400, epoch: 10 | loss: 0.3691392\n",
      "\tspeed: 0.0461s/iter; left time: 438.8801s\n",
      "\titers: 500, epoch: 10 | loss: 0.3131449\n",
      "\tspeed: 0.0461s/iter; left time: 434.3776s\n",
      "\titers: 600, epoch: 10 | loss: 0.3506526\n",
      "\tspeed: 0.0461s/iter; left time: 429.6665s\n",
      "\titers: 700, epoch: 10 | loss: 0.3850548\n",
      "\tspeed: 0.0461s/iter; left time: 425.0761s\n",
      "\titers: 800, epoch: 10 | loss: 0.3968053\n",
      "\tspeed: 0.0461s/iter; left time: 420.5616s\n",
      "\titers: 900, epoch: 10 | loss: 0.3695763\n",
      "\tspeed: 0.0461s/iter; left time: 415.6613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 902 | Train Loss: 0.3621573 Vali Loss: 0.3725274 Test Loss: 0.4360594\n",
      "Validation loss decreased (0.375184 --> 0.372527).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3781537\n",
      "\tspeed: 0.1328s/iter; left time: 1184.5420s\n",
      "\titers: 200, epoch: 11 | loss: 0.2782618\n",
      "\tspeed: 0.0461s/iter; left time: 406.3909s\n",
      "\titers: 300, epoch: 11 | loss: 0.3549007\n",
      "\tspeed: 0.0461s/iter; left time: 401.9595s\n",
      "\titers: 400, epoch: 11 | loss: 0.3913230\n",
      "\tspeed: 0.0461s/iter; left time: 397.0880s\n",
      "\titers: 500, epoch: 11 | loss: 0.3391007\n",
      "\tspeed: 0.0461s/iter; left time: 392.9755s\n",
      "\titers: 600, epoch: 11 | loss: 0.3682042\n",
      "\tspeed: 0.0461s/iter; left time: 388.0201s\n",
      "\titers: 700, epoch: 11 | loss: 0.3457897\n",
      "\tspeed: 0.0462s/iter; left time: 384.4838s\n",
      "\titers: 800, epoch: 11 | loss: 0.3658479\n",
      "\tspeed: 0.0461s/iter; left time: 379.2462s\n",
      "\titers: 900, epoch: 11 | loss: 0.3298305\n",
      "\tspeed: 0.0462s/iter; left time: 374.7972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 902 | Train Loss: 0.3559448 Vali Loss: 0.3679149 Test Loss: 0.4414060\n",
      "Validation loss decreased (0.372527 --> 0.367915).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3347536\n",
      "\tspeed: 0.1343s/iter; left time: 1076.5584s\n",
      "\titers: 200, epoch: 12 | loss: 0.3752465\n",
      "\tspeed: 0.0463s/iter; left time: 366.7728s\n",
      "\titers: 300, epoch: 12 | loss: 0.3274560\n",
      "\tspeed: 0.0461s/iter; left time: 360.5640s\n",
      "\titers: 400, epoch: 12 | loss: 0.3824339\n",
      "\tspeed: 0.0461s/iter; left time: 355.5346s\n",
      "\titers: 500, epoch: 12 | loss: 0.2984128\n",
      "\tspeed: 0.0462s/iter; left time: 351.9552s\n",
      "\titers: 600, epoch: 12 | loss: 0.3302579\n",
      "\tspeed: 0.0465s/iter; left time: 349.8063s\n",
      "\titers: 700, epoch: 12 | loss: 0.3630695\n",
      "\tspeed: 0.0461s/iter; left time: 341.8578s\n",
      "\titers: 800, epoch: 12 | loss: 0.3497867\n",
      "\tspeed: 0.0461s/iter; left time: 337.2341s\n",
      "\titers: 900, epoch: 12 | loss: 0.3151431\n",
      "\tspeed: 0.0465s/iter; left time: 335.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.34s\n",
      "Steps: 902 | Train Loss: 0.3497323 Vali Loss: 0.3692626 Test Loss: 0.4301620\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3379138\n",
      "\tspeed: 0.1275s/iter; left time: 907.5548s\n",
      "\titers: 200, epoch: 13 | loss: 0.3310381\n",
      "\tspeed: 0.0461s/iter; left time: 323.5379s\n",
      "\titers: 300, epoch: 13 | loss: 0.3067156\n",
      "\tspeed: 0.0461s/iter; left time: 319.1933s\n",
      "\titers: 400, epoch: 13 | loss: 0.3937933\n",
      "\tspeed: 0.0463s/iter; left time: 315.3638s\n",
      "\titers: 500, epoch: 13 | loss: 0.3488290\n",
      "\tspeed: 0.0462s/iter; left time: 310.0653s\n",
      "\titers: 600, epoch: 13 | loss: 0.3596279\n",
      "\tspeed: 0.0461s/iter; left time: 305.2077s\n",
      "\titers: 700, epoch: 13 | loss: 0.3971089\n",
      "\tspeed: 0.0461s/iter; left time: 300.7118s\n",
      "\titers: 800, epoch: 13 | loss: 0.3177629\n",
      "\tspeed: 0.0461s/iter; left time: 295.8957s\n",
      "\titers: 900, epoch: 13 | loss: 0.3692269\n",
      "\tspeed: 0.0465s/iter; left time: 293.7285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 902 | Train Loss: 0.3444925 Vali Loss: 0.3697178 Test Loss: 0.4455931\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.3261440\n",
      "\tspeed: 0.1504s/iter; left time: 934.6592s\n",
      "\titers: 200, epoch: 14 | loss: 0.3633143\n",
      "\tspeed: 0.0471s/iter; left time: 287.7271s\n",
      "\titers: 300, epoch: 14 | loss: 0.3475956\n",
      "\tspeed: 0.0463s/iter; left time: 278.7094s\n",
      "\titers: 400, epoch: 14 | loss: 0.3589987\n",
      "\tspeed: 0.0463s/iter; left time: 273.7423s\n",
      "\titers: 500, epoch: 14 | loss: 0.2889922\n",
      "\tspeed: 0.0465s/iter; left time: 270.5855s\n",
      "\titers: 600, epoch: 14 | loss: 0.3356747\n",
      "\tspeed: 0.0464s/iter; left time: 265.0212s\n",
      "\titers: 700, epoch: 14 | loss: 0.3881637\n",
      "\tspeed: 0.0471s/iter; left time: 264.6311s\n",
      "\titers: 800, epoch: 14 | loss: 0.3629037\n",
      "\tspeed: 0.0465s/iter; left time: 256.2202s\n",
      "\titers: 900, epoch: 14 | loss: 0.3473484\n",
      "\tspeed: 0.0464s/iter; left time: 251.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 902 | Train Loss: 0.3403612 Vali Loss: 0.3741261 Test Loss: 0.4313172\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4415864050388336, rmse:0.6645196676254272, mae:0.4715193510055542, rse:0.6086186170578003\n",
      "Original data scale mse:5682674.5, rmse:2383.836181640625, mae:1595.92529296875, rse:0.16791781783103943\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8982518\n",
      "\tspeed: 0.0509s/iter; left time: 917.2633s\n",
      "\titers: 200, epoch: 1 | loss: 0.8458576\n",
      "\tspeed: 0.0297s/iter; left time: 532.8410s\n",
      "\titers: 300, epoch: 1 | loss: 0.8074365\n",
      "\tspeed: 0.0297s/iter; left time: 529.5261s\n",
      "\titers: 400, epoch: 1 | loss: 0.8315028\n",
      "\tspeed: 0.0297s/iter; left time: 526.7074s\n",
      "\titers: 500, epoch: 1 | loss: 0.7915738\n",
      "\tspeed: 0.0297s/iter; left time: 522.6783s\n",
      "\titers: 600, epoch: 1 | loss: 0.7709562\n",
      "\tspeed: 0.0297s/iter; left time: 520.6141s\n",
      "\titers: 700, epoch: 1 | loss: 0.7027000\n",
      "\tspeed: 0.0297s/iter; left time: 517.2633s\n",
      "\titers: 800, epoch: 1 | loss: 0.7458278\n",
      "\tspeed: 0.0297s/iter; left time: 514.6375s\n",
      "\titers: 900, epoch: 1 | loss: 0.7395509\n",
      "\tspeed: 0.0327s/iter; left time: 562.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.93s\n",
      "Steps: 906 | Train Loss: 0.8002553 Vali Loss: 0.7254151 Test Loss: 0.7859074\n",
      "Validation loss decreased (inf --> 0.725415).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6148894\n",
      "\tspeed: 0.0858s/iter; left time: 1469.0765s\n",
      "\titers: 200, epoch: 2 | loss: 0.4927519\n",
      "\tspeed: 0.0297s/iter; left time: 504.8551s\n",
      "\titers: 300, epoch: 2 | loss: 0.4147166\n",
      "\tspeed: 0.0296s/iter; left time: 501.4986s\n",
      "\titers: 400, epoch: 2 | loss: 0.3876883\n",
      "\tspeed: 0.0298s/iter; left time: 500.9634s\n",
      "\titers: 500, epoch: 2 | loss: 0.4275194\n",
      "\tspeed: 0.0296s/iter; left time: 495.1860s\n",
      "\titers: 600, epoch: 2 | loss: 0.3958344\n",
      "\tspeed: 0.0318s/iter; left time: 528.5082s\n",
      "\titers: 700, epoch: 2 | loss: 0.3779832\n",
      "\tspeed: 0.0313s/iter; left time: 517.7429s\n",
      "\titers: 800, epoch: 2 | loss: 0.3738647\n",
      "\tspeed: 0.0305s/iter; left time: 500.7751s\n",
      "\titers: 900, epoch: 2 | loss: 0.3732349\n",
      "\tspeed: 0.0307s/iter; left time: 501.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.80s\n",
      "Steps: 906 | Train Loss: 0.4314672 Vali Loss: 0.3343946 Test Loss: 0.3576734\n",
      "Validation loss decreased (0.725415 --> 0.334395).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3488475\n",
      "\tspeed: 0.0890s/iter; left time: 1442.5385s\n",
      "\titers: 200, epoch: 3 | loss: 0.3256014\n",
      "\tspeed: 0.0302s/iter; left time: 486.1347s\n",
      "\titers: 300, epoch: 3 | loss: 0.3474699\n",
      "\tspeed: 0.0305s/iter; left time: 488.1916s\n",
      "\titers: 400, epoch: 3 | loss: 0.3086111\n",
      "\tspeed: 0.0300s/iter; left time: 476.5760s\n",
      "\titers: 500, epoch: 3 | loss: 0.3724214\n",
      "\tspeed: 0.0298s/iter; left time: 471.2996s\n",
      "\titers: 600, epoch: 3 | loss: 0.3401731\n",
      "\tspeed: 0.0300s/iter; left time: 470.6889s\n",
      "\titers: 700, epoch: 3 | loss: 0.2903460\n",
      "\tspeed: 0.0297s/iter; left time: 463.8172s\n",
      "\titers: 800, epoch: 3 | loss: 0.3162773\n",
      "\tspeed: 0.0297s/iter; left time: 461.1028s\n",
      "\titers: 900, epoch: 3 | loss: 0.2989454\n",
      "\tspeed: 0.0297s/iter; left time: 457.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.56s\n",
      "Steps: 906 | Train Loss: 0.3265869 Vali Loss: 0.3017584 Test Loss: 0.3241872\n",
      "Validation loss decreased (0.334395 --> 0.301758).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2934006\n",
      "\tspeed: 0.0857s/iter; left time: 1311.6137s\n",
      "\titers: 200, epoch: 4 | loss: 0.2847592\n",
      "\tspeed: 0.0305s/iter; left time: 463.6165s\n",
      "\titers: 300, epoch: 4 | loss: 0.2830035\n",
      "\tspeed: 0.0305s/iter; left time: 460.3550s\n",
      "\titers: 400, epoch: 4 | loss: 0.3007552\n",
      "\tspeed: 0.0304s/iter; left time: 455.9334s\n",
      "\titers: 500, epoch: 4 | loss: 0.2848407\n",
      "\tspeed: 0.0297s/iter; left time: 443.2381s\n",
      "\titers: 600, epoch: 4 | loss: 0.3638254\n",
      "\tspeed: 0.0297s/iter; left time: 440.1718s\n",
      "\titers: 700, epoch: 4 | loss: 0.3218064\n",
      "\tspeed: 0.0297s/iter; left time: 437.1588s\n",
      "\titers: 800, epoch: 4 | loss: 0.3125134\n",
      "\tspeed: 0.0297s/iter; left time: 434.2324s\n",
      "\titers: 900, epoch: 4 | loss: 0.3308379\n",
      "\tspeed: 0.0297s/iter; left time: 431.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.51s\n",
      "Steps: 906 | Train Loss: 0.3002852 Vali Loss: 0.2842374 Test Loss: 0.3071113\n",
      "Validation loss decreased (0.301758 --> 0.284237).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2778125\n",
      "\tspeed: 0.0866s/iter; left time: 1246.9169s\n",
      "\titers: 200, epoch: 5 | loss: 0.2598670\n",
      "\tspeed: 0.0297s/iter; left time: 424.0357s\n",
      "\titers: 300, epoch: 5 | loss: 0.2578112\n",
      "\tspeed: 0.0297s/iter; left time: 421.0142s\n",
      "\titers: 400, epoch: 5 | loss: 0.2655600\n",
      "\tspeed: 0.0296s/iter; left time: 417.7821s\n",
      "\titers: 500, epoch: 5 | loss: 0.2985246\n",
      "\tspeed: 0.0297s/iter; left time: 415.0861s\n",
      "\titers: 600, epoch: 5 | loss: 0.2696084\n",
      "\tspeed: 0.0296s/iter; left time: 411.8680s\n",
      "\titers: 700, epoch: 5 | loss: 0.3071485\n",
      "\tspeed: 0.0296s/iter; left time: 408.9463s\n",
      "\titers: 800, epoch: 5 | loss: 0.2650835\n",
      "\tspeed: 0.0297s/iter; left time: 406.2887s\n",
      "\titers: 900, epoch: 5 | loss: 0.3005427\n",
      "\tspeed: 0.0296s/iter; left time: 403.1317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 906 | Train Loss: 0.2854086 Vali Loss: 0.2762106 Test Loss: 0.2984711\n",
      "Validation loss decreased (0.284237 --> 0.276211).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2698609\n",
      "\tspeed: 0.0872s/iter; left time: 1176.1765s\n",
      "\titers: 200, epoch: 6 | loss: 0.2821735\n",
      "\tspeed: 0.0298s/iter; left time: 399.3437s\n",
      "\titers: 300, epoch: 6 | loss: 0.3199257\n",
      "\tspeed: 0.0297s/iter; left time: 395.2196s\n",
      "\titers: 400, epoch: 6 | loss: 0.3014683\n",
      "\tspeed: 0.0301s/iter; left time: 397.0959s\n",
      "\titers: 500, epoch: 6 | loss: 0.2745761\n",
      "\tspeed: 0.0300s/iter; left time: 392.9350s\n",
      "\titers: 600, epoch: 6 | loss: 0.3011068\n",
      "\tspeed: 0.0296s/iter; left time: 384.7463s\n",
      "\titers: 700, epoch: 6 | loss: 0.3174651\n",
      "\tspeed: 0.0297s/iter; left time: 382.8081s\n",
      "\titers: 800, epoch: 6 | loss: 0.2696464\n",
      "\tspeed: 0.0298s/iter; left time: 380.6853s\n",
      "\titers: 900, epoch: 6 | loss: 0.2929690\n",
      "\tspeed: 0.0299s/iter; left time: 379.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.42s\n",
      "Steps: 906 | Train Loss: 0.2763475 Vali Loss: 0.2698329 Test Loss: 0.2898619\n",
      "Validation loss decreased (0.276211 --> 0.269833).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2727868\n",
      "\tspeed: 0.0863s/iter; left time: 1085.5751s\n",
      "\titers: 200, epoch: 7 | loss: 0.2350268\n",
      "\tspeed: 0.0297s/iter; left time: 370.3395s\n",
      "\titers: 300, epoch: 7 | loss: 0.2592110\n",
      "\tspeed: 0.0296s/iter; left time: 367.0068s\n",
      "\titers: 400, epoch: 7 | loss: 0.2567597\n",
      "\tspeed: 0.0296s/iter; left time: 363.8758s\n",
      "\titers: 500, epoch: 7 | loss: 0.2733704\n",
      "\tspeed: 0.0296s/iter; left time: 360.7018s\n",
      "\titers: 600, epoch: 7 | loss: 0.2359796\n",
      "\tspeed: 0.0296s/iter; left time: 357.5299s\n",
      "\titers: 700, epoch: 7 | loss: 0.2640343\n",
      "\tspeed: 0.0296s/iter; left time: 354.7453s\n",
      "\titers: 800, epoch: 7 | loss: 0.3033043\n",
      "\tspeed: 0.0296s/iter; left time: 351.9876s\n",
      "\titers: 900, epoch: 7 | loss: 0.2588506\n",
      "\tspeed: 0.0296s/iter; left time: 349.0764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.14s\n",
      "Steps: 906 | Train Loss: 0.2694365 Vali Loss: 0.2679622 Test Loss: 0.2863183\n",
      "Validation loss decreased (0.269833 --> 0.267962).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2531316\n",
      "\tspeed: 0.0869s/iter; left time: 1014.7294s\n",
      "\titers: 200, epoch: 8 | loss: 0.2331702\n",
      "\tspeed: 0.0304s/iter; left time: 351.6087s\n",
      "\titers: 300, epoch: 8 | loss: 0.2810597\n",
      "\tspeed: 0.0297s/iter; left time: 340.8653s\n",
      "\titers: 400, epoch: 8 | loss: 0.2593723\n",
      "\tspeed: 0.0297s/iter; left time: 338.0204s\n",
      "\titers: 500, epoch: 8 | loss: 0.2738975\n",
      "\tspeed: 0.0301s/iter; left time: 339.7385s\n",
      "\titers: 600, epoch: 8 | loss: 0.2735357\n",
      "\tspeed: 0.0304s/iter; left time: 340.2251s\n",
      "\titers: 700, epoch: 8 | loss: 0.2414902\n",
      "\tspeed: 0.0304s/iter; left time: 337.1097s\n",
      "\titers: 800, epoch: 8 | loss: 0.2622409\n",
      "\tspeed: 0.0303s/iter; left time: 332.8949s\n",
      "\titers: 900, epoch: 8 | loss: 0.2747293\n",
      "\tspeed: 0.0297s/iter; left time: 322.9626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.60s\n",
      "Steps: 906 | Train Loss: 0.2640604 Vali Loss: 0.2653358 Test Loss: 0.2851748\n",
      "Validation loss decreased (0.267962 --> 0.265336).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2595016\n",
      "\tspeed: 0.0862s/iter; left time: 928.3190s\n",
      "\titers: 200, epoch: 9 | loss: 0.2779095\n",
      "\tspeed: 0.0297s/iter; left time: 317.4040s\n",
      "\titers: 300, epoch: 9 | loss: 0.2664872\n",
      "\tspeed: 0.0298s/iter; left time: 314.9809s\n",
      "\titers: 400, epoch: 9 | loss: 0.2874963\n",
      "\tspeed: 0.0297s/iter; left time: 311.1924s\n",
      "\titers: 500, epoch: 9 | loss: 0.2765655\n",
      "\tspeed: 0.0301s/iter; left time: 311.7679s\n",
      "\titers: 600, epoch: 9 | loss: 0.2846298\n",
      "\tspeed: 0.0302s/iter; left time: 310.3625s\n",
      "\titers: 700, epoch: 9 | loss: 0.2560660\n",
      "\tspeed: 0.0297s/iter; left time: 301.9699s\n",
      "\titers: 800, epoch: 9 | loss: 0.2671131\n",
      "\tspeed: 0.0298s/iter; left time: 300.2841s\n",
      "\titers: 900, epoch: 9 | loss: 0.2638635\n",
      "\tspeed: 0.0302s/iter; left time: 301.6611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.40s\n",
      "Steps: 906 | Train Loss: 0.2599821 Vali Loss: 0.2610800 Test Loss: 0.2821350\n",
      "Validation loss decreased (0.265336 --> 0.261080).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2800991\n",
      "\tspeed: 0.0927s/iter; left time: 914.6515s\n",
      "\titers: 200, epoch: 10 | loss: 0.2533764\n",
      "\tspeed: 0.0304s/iter; left time: 296.9359s\n",
      "\titers: 300, epoch: 10 | loss: 0.2552003\n",
      "\tspeed: 0.0304s/iter; left time: 293.7941s\n",
      "\titers: 400, epoch: 10 | loss: 0.2396801\n",
      "\tspeed: 0.0304s/iter; left time: 290.7625s\n",
      "\titers: 500, epoch: 10 | loss: 0.2476129\n",
      "\tspeed: 0.0304s/iter; left time: 287.5275s\n",
      "\titers: 600, epoch: 10 | loss: 0.2463096\n",
      "\tspeed: 0.0304s/iter; left time: 284.5733s\n",
      "\titers: 700, epoch: 10 | loss: 0.2813039\n",
      "\tspeed: 0.0301s/iter; left time: 279.2429s\n",
      "\titers: 800, epoch: 10 | loss: 0.2465423\n",
      "\tspeed: 0.0295s/iter; left time: 270.8819s\n",
      "\titers: 900, epoch: 10 | loss: 0.2718271\n",
      "\tspeed: 0.0296s/iter; left time: 268.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.84s\n",
      "Steps: 906 | Train Loss: 0.2567788 Vali Loss: 0.2563201 Test Loss: 0.2764029\n",
      "Validation loss decreased (0.261080 --> 0.256320).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2349428\n",
      "\tspeed: 0.0859s/iter; left time: 769.6579s\n",
      "\titers: 200, epoch: 11 | loss: 0.2101355\n",
      "\tspeed: 0.0297s/iter; left time: 262.9151s\n",
      "\titers: 300, epoch: 11 | loss: 0.2650644\n",
      "\tspeed: 0.0297s/iter; left time: 259.8867s\n",
      "\titers: 400, epoch: 11 | loss: 0.2470534\n",
      "\tspeed: 0.0296s/iter; left time: 256.7183s\n",
      "\titers: 500, epoch: 11 | loss: 0.2220689\n",
      "\tspeed: 0.0296s/iter; left time: 253.7038s\n",
      "\titers: 600, epoch: 11 | loss: 0.2561055\n",
      "\tspeed: 0.0296s/iter; left time: 250.7375s\n",
      "\titers: 700, epoch: 11 | loss: 0.2374993\n",
      "\tspeed: 0.0297s/iter; left time: 247.9697s\n",
      "\titers: 800, epoch: 11 | loss: 0.2698430\n",
      "\tspeed: 0.0296s/iter; left time: 244.8950s\n",
      "\titers: 900, epoch: 11 | loss: 0.2755079\n",
      "\tspeed: 0.0297s/iter; left time: 242.0702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.21s\n",
      "Steps: 906 | Train Loss: 0.2536946 Vali Loss: 0.2556883 Test Loss: 0.2753615\n",
      "Validation loss decreased (0.256320 --> 0.255688).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2882319\n",
      "\tspeed: 0.0868s/iter; left time: 699.3771s\n",
      "\titers: 200, epoch: 12 | loss: 0.2682012\n",
      "\tspeed: 0.0296s/iter; left time: 235.7375s\n",
      "\titers: 300, epoch: 12 | loss: 0.2818410\n",
      "\tspeed: 0.0296s/iter; left time: 232.8633s\n",
      "\titers: 400, epoch: 12 | loss: 0.2349325\n",
      "\tspeed: 0.0296s/iter; left time: 229.6394s\n",
      "\titers: 500, epoch: 12 | loss: 0.2266099\n",
      "\tspeed: 0.0296s/iter; left time: 226.7362s\n",
      "\titers: 600, epoch: 12 | loss: 0.2481263\n",
      "\tspeed: 0.0296s/iter; left time: 223.9285s\n",
      "\titers: 700, epoch: 12 | loss: 0.2797031\n",
      "\tspeed: 0.0301s/iter; left time: 224.1715s\n",
      "\titers: 800, epoch: 12 | loss: 0.2338008\n",
      "\tspeed: 0.0297s/iter; left time: 218.2541s\n",
      "\titers: 900, epoch: 12 | loss: 0.2118474\n",
      "\tspeed: 0.0302s/iter; left time: 218.7607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.28s\n",
      "Steps: 906 | Train Loss: 0.2514646 Vali Loss: 0.2569689 Test Loss: 0.2758863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2733481\n",
      "\tspeed: 0.0848s/iter; left time: 606.2492s\n",
      "\titers: 200, epoch: 13 | loss: 0.2261509\n",
      "\tspeed: 0.0300s/iter; left time: 211.2288s\n",
      "\titers: 300, epoch: 13 | loss: 0.2664162\n",
      "\tspeed: 0.0300s/iter; left time: 208.3355s\n",
      "\titers: 400, epoch: 13 | loss: 0.2684229\n",
      "\tspeed: 0.0297s/iter; left time: 203.4949s\n",
      "\titers: 500, epoch: 13 | loss: 0.2347163\n",
      "\tspeed: 0.0297s/iter; left time: 200.2692s\n",
      "\titers: 600, epoch: 13 | loss: 0.2607549\n",
      "\tspeed: 0.0297s/iter; left time: 197.3315s\n",
      "\titers: 700, epoch: 13 | loss: 0.2645776\n",
      "\tspeed: 0.0297s/iter; left time: 194.2683s\n",
      "\titers: 800, epoch: 13 | loss: 0.2235833\n",
      "\tspeed: 0.0298s/iter; left time: 192.1188s\n",
      "\titers: 900, epoch: 13 | loss: 0.2673401\n",
      "\tspeed: 0.0298s/iter; left time: 189.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.33s\n",
      "Steps: 906 | Train Loss: 0.2495886 Vali Loss: 0.2539084 Test Loss: 0.2739456\n",
      "Validation loss decreased (0.255688 --> 0.253908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2711326\n",
      "\tspeed: 0.0850s/iter; left time: 530.9200s\n",
      "\titers: 200, epoch: 14 | loss: 0.2620098\n",
      "\tspeed: 0.0297s/iter; left time: 182.2601s\n",
      "\titers: 300, epoch: 14 | loss: 0.2505479\n",
      "\tspeed: 0.0297s/iter; left time: 179.3485s\n",
      "\titers: 400, epoch: 14 | loss: 0.2493832\n",
      "\tspeed: 0.0297s/iter; left time: 176.2574s\n",
      "\titers: 500, epoch: 14 | loss: 0.2596759\n",
      "\tspeed: 0.0297s/iter; left time: 173.3380s\n",
      "\titers: 600, epoch: 14 | loss: 0.2682787\n",
      "\tspeed: 0.0297s/iter; left time: 170.3465s\n",
      "\titers: 700, epoch: 14 | loss: 0.2262208\n",
      "\tspeed: 0.0297s/iter; left time: 167.3407s\n",
      "\titers: 800, epoch: 14 | loss: 0.2294442\n",
      "\tspeed: 0.0297s/iter; left time: 164.3936s\n",
      "\titers: 900, epoch: 14 | loss: 0.2381168\n",
      "\tspeed: 0.0297s/iter; left time: 161.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.22s\n",
      "Steps: 906 | Train Loss: 0.2475619 Vali Loss: 0.2536014 Test Loss: 0.2733522\n",
      "Validation loss decreased (0.253908 --> 0.253601).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2370972\n",
      "\tspeed: 0.0869s/iter; left time: 463.5844s\n",
      "\titers: 200, epoch: 15 | loss: 0.2218398\n",
      "\tspeed: 0.0298s/iter; left time: 155.8063s\n",
      "\titers: 300, epoch: 15 | loss: 0.2296391\n",
      "\tspeed: 0.0297s/iter; left time: 152.4039s\n",
      "\titers: 400, epoch: 15 | loss: 0.2450830\n",
      "\tspeed: 0.0297s/iter; left time: 149.4907s\n",
      "\titers: 500, epoch: 15 | loss: 0.2539105\n",
      "\tspeed: 0.0297s/iter; left time: 146.4691s\n",
      "\titers: 600, epoch: 15 | loss: 0.2359191\n",
      "\tspeed: 0.0297s/iter; left time: 143.4747s\n",
      "\titers: 700, epoch: 15 | loss: 0.2427872\n",
      "\tspeed: 0.0297s/iter; left time: 140.5100s\n",
      "\titers: 800, epoch: 15 | loss: 0.2720754\n",
      "\tspeed: 0.0305s/iter; left time: 141.2766s\n",
      "\titers: 900, epoch: 15 | loss: 0.2266614\n",
      "\tspeed: 0.0299s/iter; left time: 135.8336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.31s\n",
      "Steps: 906 | Train Loss: 0.2461112 Vali Loss: 0.2515949 Test Loss: 0.2726883\n",
      "Validation loss decreased (0.253601 --> 0.251595).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2497180\n",
      "\tspeed: 0.0878s/iter; left time: 389.1190s\n",
      "\titers: 200, epoch: 16 | loss: 0.2179761\n",
      "\tspeed: 0.0299s/iter; left time: 129.4832s\n",
      "\titers: 300, epoch: 16 | loss: 0.2537304\n",
      "\tspeed: 0.0299s/iter; left time: 126.3525s\n",
      "\titers: 400, epoch: 16 | loss: 0.2146583\n",
      "\tspeed: 0.0299s/iter; left time: 123.5614s\n",
      "\titers: 500, epoch: 16 | loss: 0.2429717\n",
      "\tspeed: 0.0297s/iter; left time: 119.6558s\n",
      "\titers: 600, epoch: 16 | loss: 0.2603196\n",
      "\tspeed: 0.0297s/iter; left time: 116.5930s\n",
      "\titers: 700, epoch: 16 | loss: 0.2139096\n",
      "\tspeed: 0.0297s/iter; left time: 113.9439s\n",
      "\titers: 800, epoch: 16 | loss: 0.2822977\n",
      "\tspeed: 0.0297s/iter; left time: 110.6830s\n",
      "\titers: 900, epoch: 16 | loss: 0.2415431\n",
      "\tspeed: 0.0297s/iter; left time: 107.7234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.40s\n",
      "Steps: 906 | Train Loss: 0.2447823 Vali Loss: 0.2506451 Test Loss: 0.2708200\n",
      "Validation loss decreased (0.251595 --> 0.250645).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2776798\n",
      "\tspeed: 0.0849s/iter; left time: 299.3393s\n",
      "\titers: 200, epoch: 17 | loss: 0.2585074\n",
      "\tspeed: 0.0297s/iter; left time: 101.6320s\n",
      "\titers: 300, epoch: 17 | loss: 0.2394258\n",
      "\tspeed: 0.0297s/iter; left time: 98.6489s\n",
      "\titers: 400, epoch: 17 | loss: 0.2552698\n",
      "\tspeed: 0.0297s/iter; left time: 95.6413s\n",
      "\titers: 500, epoch: 17 | loss: 0.2025661\n",
      "\tspeed: 0.0300s/iter; left time: 93.6774s\n",
      "\titers: 600, epoch: 17 | loss: 0.2419886\n",
      "\tspeed: 0.0313s/iter; left time: 94.8320s\n",
      "\titers: 700, epoch: 17 | loss: 0.2193597\n",
      "\tspeed: 0.0313s/iter; left time: 91.6730s\n",
      "\titers: 800, epoch: 17 | loss: 0.2553150\n",
      "\tspeed: 0.0313s/iter; left time: 88.5597s\n",
      "\titers: 900, epoch: 17 | loss: 0.2422516\n",
      "\tspeed: 0.0314s/iter; left time: 85.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.94s\n",
      "Steps: 906 | Train Loss: 0.2437425 Vali Loss: 0.2494281 Test Loss: 0.2729142\n",
      "Validation loss decreased (0.250645 --> 0.249428).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2305934\n",
      "\tspeed: 0.0870s/iter; left time: 227.9110s\n",
      "\titers: 200, epoch: 18 | loss: 0.3099913\n",
      "\tspeed: 0.0305s/iter; left time: 76.8425s\n",
      "\titers: 300, epoch: 18 | loss: 0.2491073\n",
      "\tspeed: 0.0297s/iter; left time: 71.8873s\n",
      "\titers: 400, epoch: 18 | loss: 0.2230721\n",
      "\tspeed: 0.0297s/iter; left time: 68.8849s\n",
      "\titers: 500, epoch: 18 | loss: 0.2287904\n",
      "\tspeed: 0.0297s/iter; left time: 65.8882s\n",
      "\titers: 600, epoch: 18 | loss: 0.2555149\n",
      "\tspeed: 0.0297s/iter; left time: 62.8998s\n",
      "\titers: 700, epoch: 18 | loss: 0.2349044\n",
      "\tspeed: 0.0297s/iter; left time: 59.9041s\n",
      "\titers: 800, epoch: 18 | loss: 0.2563432\n",
      "\tspeed: 0.0297s/iter; left time: 56.9189s\n",
      "\titers: 900, epoch: 18 | loss: 0.2518946\n",
      "\tspeed: 0.0301s/iter; left time: 54.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.45s\n",
      "Steps: 906 | Train Loss: 0.2425837 Vali Loss: 0.2502056 Test Loss: 0.2719750\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2546939\n",
      "\tspeed: 0.0840s/iter; left time: 143.9220s\n",
      "\titers: 200, epoch: 19 | loss: 0.2464008\n",
      "\tspeed: 0.0297s/iter; left time: 47.8936s\n",
      "\titers: 300, epoch: 19 | loss: 0.2259780\n",
      "\tspeed: 0.0298s/iter; left time: 45.0457s\n",
      "\titers: 400, epoch: 19 | loss: 0.2565815\n",
      "\tspeed: 0.0299s/iter; left time: 42.2035s\n",
      "\titers: 500, epoch: 19 | loss: 0.2522539\n",
      "\tspeed: 0.0298s/iter; left time: 39.1160s\n",
      "\titers: 600, epoch: 19 | loss: 0.2340999\n",
      "\tspeed: 0.0302s/iter; left time: 36.6024s\n",
      "\titers: 700, epoch: 19 | loss: 0.2489940\n",
      "\tspeed: 0.0298s/iter; left time: 33.1467s\n",
      "\titers: 800, epoch: 19 | loss: 0.2335016\n",
      "\tspeed: 0.0297s/iter; left time: 30.1338s\n",
      "\titers: 900, epoch: 19 | loss: 0.2551128\n",
      "\tspeed: 0.0297s/iter; left time: 27.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:27.35s\n",
      "Steps: 906 | Train Loss: 0.2415383 Vali Loss: 0.2505901 Test Loss: 0.2700067\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2540413\n",
      "\tspeed: 0.0818s/iter; left time: 66.0306s\n",
      "\titers: 200, epoch: 20 | loss: 0.2746835\n",
      "\tspeed: 0.0297s/iter; left time: 20.9768s\n",
      "\titers: 300, epoch: 20 | loss: 0.2585455\n",
      "\tspeed: 0.0297s/iter; left time: 18.0286s\n",
      "\titers: 400, epoch: 20 | loss: 0.2225086\n",
      "\tspeed: 0.0297s/iter; left time: 15.0610s\n",
      "\titers: 500, epoch: 20 | loss: 0.2870366\n",
      "\tspeed: 0.0297s/iter; left time: 12.0837s\n",
      "\titers: 600, epoch: 20 | loss: 0.2433546\n",
      "\tspeed: 0.0297s/iter; left time: 9.1114s\n",
      "\titers: 700, epoch: 20 | loss: 0.2240592\n",
      "\tspeed: 0.0297s/iter; left time: 6.1432s\n",
      "\titers: 800, epoch: 20 | loss: 0.2773416\n",
      "\tspeed: 0.0303s/iter; left time: 3.2430s\n",
      "\titers: 900, epoch: 20 | loss: 0.2103368\n",
      "\tspeed: 0.0303s/iter; left time: 0.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.30s\n",
      "Steps: 906 | Train Loss: 0.2407939 Vali Loss: 0.2490563 Test Loss: 0.2700902\n",
      "Validation loss decreased (0.249428 --> 0.249056).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2122817486524582, rmse:0.46074044704437256, mae:0.2702677845954895, rse:0.4219633936882019\n",
      "Original data scale mse:1440519.5, rmse:1200.2164306640625, mae:759.9635620117188, rse:0.08434204012155533\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9303597\n",
      "\tspeed: 0.0340s/iter; left time: 612.9740s\n",
      "\titers: 200, epoch: 1 | loss: 0.8192927\n",
      "\tspeed: 0.0308s/iter; left time: 551.5194s\n",
      "\titers: 300, epoch: 1 | loss: 0.8756372\n",
      "\tspeed: 0.0301s/iter; left time: 536.1340s\n",
      "\titers: 400, epoch: 1 | loss: 0.7628884\n",
      "\tspeed: 0.0301s/iter; left time: 533.8584s\n",
      "\titers: 500, epoch: 1 | loss: 0.7693668\n",
      "\tspeed: 0.0305s/iter; left time: 538.2991s\n",
      "\titers: 600, epoch: 1 | loss: 0.7992023\n",
      "\tspeed: 0.0299s/iter; left time: 524.1519s\n",
      "\titers: 700, epoch: 1 | loss: 0.7673064\n",
      "\tspeed: 0.0300s/iter; left time: 522.2419s\n",
      "\titers: 800, epoch: 1 | loss: 0.7632505\n",
      "\tspeed: 0.0298s/iter; left time: 515.5706s\n",
      "\titers: 900, epoch: 1 | loss: 0.7252381\n",
      "\tspeed: 0.0298s/iter; left time: 512.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.73s\n",
      "Steps: 906 | Train Loss: 0.8191658 Vali Loss: 0.7367652 Test Loss: 0.8015324\n",
      "Validation loss decreased (inf --> 0.736765).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5939575\n",
      "\tspeed: 0.0883s/iter; left time: 1512.0794s\n",
      "\titers: 200, epoch: 2 | loss: 0.4519100\n",
      "\tspeed: 0.0296s/iter; left time: 504.4603s\n",
      "\titers: 300, epoch: 2 | loss: 0.4430814\n",
      "\tspeed: 0.0299s/iter; left time: 505.4798s\n",
      "\titers: 400, epoch: 2 | loss: 0.4072329\n",
      "\tspeed: 0.0299s/iter; left time: 502.2991s\n",
      "\titers: 500, epoch: 2 | loss: 0.3674377\n",
      "\tspeed: 0.0363s/iter; left time: 606.8573s\n",
      "\titers: 600, epoch: 2 | loss: 0.3417858\n",
      "\tspeed: 0.0458s/iter; left time: 760.5997s\n",
      "\titers: 700, epoch: 2 | loss: 0.3673163\n",
      "\tspeed: 0.0301s/iter; left time: 497.3415s\n",
      "\titers: 800, epoch: 2 | loss: 0.3352906\n",
      "\tspeed: 0.0299s/iter; left time: 490.6509s\n",
      "\titers: 900, epoch: 2 | loss: 0.3289691\n",
      "\tspeed: 0.0302s/iter; left time: 492.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 906 | Train Loss: 0.4283856 Vali Loss: 0.3295324 Test Loss: 0.3497426\n",
      "Validation loss decreased (0.736765 --> 0.329532).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3273184\n",
      "\tspeed: 0.0874s/iter; left time: 1416.8892s\n",
      "\titers: 200, epoch: 3 | loss: 0.3205146\n",
      "\tspeed: 0.0296s/iter; left time: 477.5866s\n",
      "\titers: 300, epoch: 3 | loss: 0.3572803\n",
      "\tspeed: 0.0296s/iter; left time: 474.2365s\n",
      "\titers: 400, epoch: 3 | loss: 0.3491791\n",
      "\tspeed: 0.0296s/iter; left time: 471.2816s\n",
      "\titers: 500, epoch: 3 | loss: 0.3285128\n",
      "\tspeed: 0.0296s/iter; left time: 468.3163s\n",
      "\titers: 600, epoch: 3 | loss: 0.3490100\n",
      "\tspeed: 0.0296s/iter; left time: 465.3911s\n",
      "\titers: 700, epoch: 3 | loss: 0.3510199\n",
      "\tspeed: 0.0296s/iter; left time: 462.5277s\n",
      "\titers: 800, epoch: 3 | loss: 0.3305733\n",
      "\tspeed: 0.0296s/iter; left time: 459.1594s\n",
      "\titers: 900, epoch: 3 | loss: 0.3242746\n",
      "\tspeed: 0.0296s/iter; left time: 456.7522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 906 | Train Loss: 0.3215313 Vali Loss: 0.3007587 Test Loss: 0.3236365\n",
      "Validation loss decreased (0.329532 --> 0.300759).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2934029\n",
      "\tspeed: 0.0884s/iter; left time: 1353.2446s\n",
      "\titers: 200, epoch: 4 | loss: 0.3443906\n",
      "\tspeed: 0.0301s/iter; left time: 456.8990s\n",
      "\titers: 300, epoch: 4 | loss: 0.3247115\n",
      "\tspeed: 0.0297s/iter; left time: 448.6977s\n",
      "\titers: 400, epoch: 4 | loss: 0.3113715\n",
      "\tspeed: 0.0297s/iter; left time: 445.0142s\n",
      "\titers: 500, epoch: 4 | loss: 0.2876775\n",
      "\tspeed: 0.0297s/iter; left time: 442.8245s\n",
      "\titers: 600, epoch: 4 | loss: 0.2765463\n",
      "\tspeed: 0.0297s/iter; left time: 439.1219s\n",
      "\titers: 700, epoch: 4 | loss: 0.2743662\n",
      "\tspeed: 0.0296s/iter; left time: 435.3245s\n",
      "\titers: 800, epoch: 4 | loss: 0.2984843\n",
      "\tspeed: 0.0297s/iter; left time: 433.1457s\n",
      "\titers: 900, epoch: 4 | loss: 0.2925319\n",
      "\tspeed: 0.0296s/iter; left time: 429.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.36s\n",
      "Steps: 906 | Train Loss: 0.2977832 Vali Loss: 0.2814059 Test Loss: 0.3024971\n",
      "Validation loss decreased (0.300759 --> 0.281406).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2975923\n",
      "\tspeed: 0.0857s/iter; left time: 1233.5330s\n",
      "\titers: 200, epoch: 5 | loss: 0.2624957\n",
      "\tspeed: 0.0297s/iter; left time: 424.2197s\n",
      "\titers: 300, epoch: 5 | loss: 0.2594224\n",
      "\tspeed: 0.0297s/iter; left time: 421.2319s\n",
      "\titers: 400, epoch: 5 | loss: 0.3374806\n",
      "\tspeed: 0.0297s/iter; left time: 418.2673s\n",
      "\titers: 500, epoch: 5 | loss: 0.2633976\n",
      "\tspeed: 0.0297s/iter; left time: 415.2597s\n",
      "\titers: 600, epoch: 5 | loss: 0.2445966\n",
      "\tspeed: 0.0297s/iter; left time: 412.3375s\n",
      "\titers: 700, epoch: 5 | loss: 0.2778179\n",
      "\tspeed: 0.0296s/iter; left time: 408.4117s\n",
      "\titers: 800, epoch: 5 | loss: 0.2677927\n",
      "\tspeed: 0.0296s/iter; left time: 405.1312s\n",
      "\titers: 900, epoch: 5 | loss: 0.3016306\n",
      "\tspeed: 0.0296s/iter; left time: 402.3750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.21s\n",
      "Steps: 906 | Train Loss: 0.2837949 Vali Loss: 0.2746767 Test Loss: 0.2949765\n",
      "Validation loss decreased (0.281406 --> 0.274677).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2517997\n",
      "\tspeed: 0.0845s/iter; left time: 1139.4526s\n",
      "\titers: 200, epoch: 6 | loss: 0.3100924\n",
      "\tspeed: 0.0296s/iter; left time: 395.9011s\n",
      "\titers: 300, epoch: 6 | loss: 0.2727546\n",
      "\tspeed: 0.0296s/iter; left time: 393.2768s\n",
      "\titers: 400, epoch: 6 | loss: 0.2320868\n",
      "\tspeed: 0.0296s/iter; left time: 390.1003s\n",
      "\titers: 500, epoch: 6 | loss: 0.2645080\n",
      "\tspeed: 0.0296s/iter; left time: 387.5011s\n",
      "\titers: 600, epoch: 6 | loss: 0.2786039\n",
      "\tspeed: 0.0296s/iter; left time: 384.3403s\n",
      "\titers: 700, epoch: 6 | loss: 0.2487097\n",
      "\tspeed: 0.0296s/iter; left time: 380.9551s\n",
      "\titers: 800, epoch: 6 | loss: 0.2429876\n",
      "\tspeed: 0.0296s/iter; left time: 377.9806s\n",
      "\titers: 900, epoch: 6 | loss: 0.2557825\n",
      "\tspeed: 0.0296s/iter; left time: 375.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.10s\n",
      "Steps: 906 | Train Loss: 0.2744221 Vali Loss: 0.2668014 Test Loss: 0.2890441\n",
      "Validation loss decreased (0.274677 --> 0.266801).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2778957\n",
      "\tspeed: 0.0843s/iter; left time: 1060.6193s\n",
      "\titers: 200, epoch: 7 | loss: 0.2636458\n",
      "\tspeed: 0.0296s/iter; left time: 369.7850s\n",
      "\titers: 300, epoch: 7 | loss: 0.2854033\n",
      "\tspeed: 0.0297s/iter; left time: 367.4182s\n",
      "\titers: 400, epoch: 7 | loss: 0.2845186\n",
      "\tspeed: 0.0296s/iter; left time: 364.1971s\n",
      "\titers: 500, epoch: 7 | loss: 0.2655800\n",
      "\tspeed: 0.0296s/iter; left time: 360.7278s\n",
      "\titers: 600, epoch: 7 | loss: 0.2446871\n",
      "\tspeed: 0.0296s/iter; left time: 357.8513s\n",
      "\titers: 700, epoch: 7 | loss: 0.3329983\n",
      "\tspeed: 0.0296s/iter; left time: 354.7203s\n",
      "\titers: 800, epoch: 7 | loss: 0.2764859\n",
      "\tspeed: 0.0296s/iter; left time: 351.8685s\n",
      "\titers: 900, epoch: 7 | loss: 0.2517844\n",
      "\tspeed: 0.0296s/iter; left time: 348.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.12s\n",
      "Steps: 906 | Train Loss: 0.2676544 Vali Loss: 0.2648553 Test Loss: 0.2808464\n",
      "Validation loss decreased (0.266801 --> 0.264855).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2560193\n",
      "\tspeed: 0.0852s/iter; left time: 994.4943s\n",
      "\titers: 200, epoch: 8 | loss: 0.2670867\n",
      "\tspeed: 0.0297s/iter; left time: 343.8508s\n",
      "\titers: 300, epoch: 8 | loss: 0.2400081\n",
      "\tspeed: 0.0297s/iter; left time: 341.0833s\n",
      "\titers: 400, epoch: 8 | loss: 0.2598019\n",
      "\tspeed: 0.0297s/iter; left time: 337.5117s\n",
      "\titers: 500, epoch: 8 | loss: 0.2636440\n",
      "\tspeed: 0.0296s/iter; left time: 334.4104s\n",
      "\titers: 600, epoch: 8 | loss: 0.2835736\n",
      "\tspeed: 0.0296s/iter; left time: 331.3258s\n",
      "\titers: 700, epoch: 8 | loss: 0.2559046\n",
      "\tspeed: 0.0296s/iter; left time: 328.4713s\n",
      "\titers: 800, epoch: 8 | loss: 0.2724702\n",
      "\tspeed: 0.0296s/iter; left time: 325.4542s\n",
      "\titers: 900, epoch: 8 | loss: 0.2947002\n",
      "\tspeed: 0.0297s/iter; left time: 322.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 906 | Train Loss: 0.2621302 Vali Loss: 0.2571634 Test Loss: 0.2844976\n",
      "Validation loss decreased (0.264855 --> 0.257163).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2716273\n",
      "\tspeed: 0.0869s/iter; left time: 935.7831s\n",
      "\titers: 200, epoch: 9 | loss: 0.2145229\n",
      "\tspeed: 0.0296s/iter; left time: 316.0859s\n",
      "\titers: 300, epoch: 9 | loss: 0.2432051\n",
      "\tspeed: 0.0296s/iter; left time: 313.1375s\n",
      "\titers: 400, epoch: 9 | loss: 0.2403807\n",
      "\tspeed: 0.0296s/iter; left time: 310.0795s\n",
      "\titers: 500, epoch: 9 | loss: 0.2410014\n",
      "\tspeed: 0.0296s/iter; left time: 307.1268s\n",
      "\titers: 600, epoch: 9 | loss: 0.2758222\n",
      "\tspeed: 0.0296s/iter; left time: 304.1021s\n",
      "\titers: 700, epoch: 9 | loss: 0.2780923\n",
      "\tspeed: 0.0296s/iter; left time: 301.2557s\n",
      "\titers: 800, epoch: 9 | loss: 0.2528399\n",
      "\tspeed: 0.0296s/iter; left time: 298.1636s\n",
      "\titers: 900, epoch: 9 | loss: 0.2815757\n",
      "\tspeed: 0.0296s/iter; left time: 295.5019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 906 | Train Loss: 0.2582970 Vali Loss: 0.2553545 Test Loss: 0.2808213\n",
      "Validation loss decreased (0.257163 --> 0.255355).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2581372\n",
      "\tspeed: 0.0850s/iter; left time: 838.6492s\n",
      "\titers: 200, epoch: 10 | loss: 0.2428953\n",
      "\tspeed: 0.0296s/iter; left time: 288.9820s\n",
      "\titers: 300, epoch: 10 | loss: 0.2504463\n",
      "\tspeed: 0.0296s/iter; left time: 286.0795s\n",
      "\titers: 400, epoch: 10 | loss: 0.2884009\n",
      "\tspeed: 0.0296s/iter; left time: 283.1181s\n",
      "\titers: 500, epoch: 10 | loss: 0.2555453\n",
      "\tspeed: 0.0296s/iter; left time: 280.2382s\n",
      "\titers: 600, epoch: 10 | loss: 0.2282630\n",
      "\tspeed: 0.0296s/iter; left time: 277.4997s\n",
      "\titers: 700, epoch: 10 | loss: 0.2553661\n",
      "\tspeed: 0.0296s/iter; left time: 274.1589s\n",
      "\titers: 800, epoch: 10 | loss: 0.2430495\n",
      "\tspeed: 0.0296s/iter; left time: 271.3726s\n",
      "\titers: 900, epoch: 10 | loss: 0.2311419\n",
      "\tspeed: 0.0296s/iter; left time: 268.3943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:27.12s\n",
      "Steps: 906 | Train Loss: 0.2546838 Vali Loss: 0.2557582 Test Loss: 0.2759125\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2596675\n",
      "\tspeed: 0.0827s/iter; left time: 741.3302s\n",
      "\titers: 200, epoch: 11 | loss: 0.2587310\n",
      "\tspeed: 0.0296s/iter; left time: 262.7181s\n",
      "\titers: 300, epoch: 11 | loss: 0.2235795\n",
      "\tspeed: 0.0296s/iter; left time: 259.7427s\n",
      "\titers: 400, epoch: 11 | loss: 0.2279402\n",
      "\tspeed: 0.0296s/iter; left time: 256.7616s\n",
      "\titers: 500, epoch: 11 | loss: 0.2848815\n",
      "\tspeed: 0.0297s/iter; left time: 253.8484s\n",
      "\titers: 600, epoch: 11 | loss: 0.2675300\n",
      "\tspeed: 0.0296s/iter; left time: 250.8405s\n",
      "\titers: 700, epoch: 11 | loss: 0.2346966\n",
      "\tspeed: 0.0296s/iter; left time: 247.7792s\n",
      "\titers: 800, epoch: 11 | loss: 0.2234470\n",
      "\tspeed: 0.0296s/iter; left time: 244.5869s\n",
      "\titers: 900, epoch: 11 | loss: 0.2768649\n",
      "\tspeed: 0.0296s/iter; left time: 241.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:27.13s\n",
      "Steps: 906 | Train Loss: 0.2518432 Vali Loss: 0.2534573 Test Loss: 0.2760886\n",
      "Validation loss decreased (0.255355 --> 0.253457).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2355793\n",
      "\tspeed: 0.0861s/iter; left time: 693.3572s\n",
      "\titers: 200, epoch: 12 | loss: 0.2460623\n",
      "\tspeed: 0.0296s/iter; left time: 235.3711s\n",
      "\titers: 300, epoch: 12 | loss: 0.2458866\n",
      "\tspeed: 0.0296s/iter; left time: 232.2402s\n",
      "\titers: 400, epoch: 12 | loss: 0.2901711\n",
      "\tspeed: 0.0296s/iter; left time: 229.4860s\n",
      "\titers: 500, epoch: 12 | loss: 0.2442312\n",
      "\tspeed: 0.0296s/iter; left time: 226.3491s\n",
      "\titers: 600, epoch: 12 | loss: 0.2325747\n",
      "\tspeed: 0.0296s/iter; left time: 223.4232s\n",
      "\titers: 700, epoch: 12 | loss: 0.2606840\n",
      "\tspeed: 0.0296s/iter; left time: 220.3360s\n",
      "\titers: 800, epoch: 12 | loss: 0.2331602\n",
      "\tspeed: 0.0296s/iter; left time: 217.5184s\n",
      "\titers: 900, epoch: 12 | loss: 0.2301960\n",
      "\tspeed: 0.0296s/iter; left time: 214.5650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.10s\n",
      "Steps: 906 | Train Loss: 0.2494160 Vali Loss: 0.2504608 Test Loss: 0.2713868\n",
      "Validation loss decreased (0.253457 --> 0.250461).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2390223\n",
      "\tspeed: 0.0852s/iter; left time: 609.1049s\n",
      "\titers: 200, epoch: 13 | loss: 0.2358641\n",
      "\tspeed: 0.0296s/iter; left time: 208.7987s\n",
      "\titers: 300, epoch: 13 | loss: 0.2319415\n",
      "\tspeed: 0.0296s/iter; left time: 205.3995s\n",
      "\titers: 400, epoch: 13 | loss: 0.2719097\n",
      "\tspeed: 0.0296s/iter; left time: 202.5164s\n",
      "\titers: 500, epoch: 13 | loss: 0.2816010\n",
      "\tspeed: 0.0296s/iter; left time: 199.7929s\n",
      "\titers: 600, epoch: 13 | loss: 0.2265584\n",
      "\tspeed: 0.0296s/iter; left time: 196.5760s\n",
      "\titers: 700, epoch: 13 | loss: 0.2560033\n",
      "\tspeed: 0.0296s/iter; left time: 193.6121s\n",
      "\titers: 800, epoch: 13 | loss: 0.2094005\n",
      "\tspeed: 0.0296s/iter; left time: 190.6472s\n",
      "\titers: 900, epoch: 13 | loss: 0.1995389\n",
      "\tspeed: 0.0296s/iter; left time: 187.8230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:27.11s\n",
      "Steps: 906 | Train Loss: 0.2474359 Vali Loss: 0.2490291 Test Loss: 0.2725363\n",
      "Validation loss decreased (0.250461 --> 0.249029).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2317441\n",
      "\tspeed: 0.0873s/iter; left time: 545.2977s\n",
      "\titers: 200, epoch: 14 | loss: 0.2502038\n",
      "\tspeed: 0.0296s/iter; left time: 181.9023s\n",
      "\titers: 300, epoch: 14 | loss: 0.2363130\n",
      "\tspeed: 0.0296s/iter; left time: 178.9288s\n",
      "\titers: 400, epoch: 14 | loss: 0.2655280\n",
      "\tspeed: 0.0296s/iter; left time: 175.9019s\n",
      "\titers: 500, epoch: 14 | loss: 0.2653955\n",
      "\tspeed: 0.0296s/iter; left time: 173.0949s\n",
      "\titers: 600, epoch: 14 | loss: 0.2435174\n",
      "\tspeed: 0.0296s/iter; left time: 169.9901s\n",
      "\titers: 700, epoch: 14 | loss: 0.2368079\n",
      "\tspeed: 0.0296s/iter; left time: 167.0843s\n",
      "\titers: 800, epoch: 14 | loss: 0.2336951\n",
      "\tspeed: 0.0296s/iter; left time: 164.3040s\n",
      "\titers: 900, epoch: 14 | loss: 0.2768160\n",
      "\tspeed: 0.0296s/iter; left time: 161.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:27.12s\n",
      "Steps: 906 | Train Loss: 0.2456541 Vali Loss: 0.2486161 Test Loss: 0.2733704\n",
      "Validation loss decreased (0.249029 --> 0.248616).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2262324\n",
      "\tspeed: 0.0852s/iter; left time: 454.9507s\n",
      "\titers: 200, epoch: 15 | loss: 0.2571841\n",
      "\tspeed: 0.0296s/iter; left time: 154.9631s\n",
      "\titers: 300, epoch: 15 | loss: 0.2922182\n",
      "\tspeed: 0.0296s/iter; left time: 152.0402s\n",
      "\titers: 400, epoch: 15 | loss: 0.2663425\n",
      "\tspeed: 0.0296s/iter; left time: 149.0197s\n",
      "\titers: 500, epoch: 15 | loss: 0.2416984\n",
      "\tspeed: 0.0296s/iter; left time: 146.0744s\n",
      "\titers: 600, epoch: 15 | loss: 0.2661588\n",
      "\tspeed: 0.0296s/iter; left time: 143.1773s\n",
      "\titers: 700, epoch: 15 | loss: 0.2324841\n",
      "\tspeed: 0.0296s/iter; left time: 140.1591s\n",
      "\titers: 800, epoch: 15 | loss: 0.2875350\n",
      "\tspeed: 0.0296s/iter; left time: 137.2096s\n",
      "\titers: 900, epoch: 15 | loss: 0.2483862\n",
      "\tspeed: 0.0296s/iter; left time: 134.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.09s\n",
      "Steps: 906 | Train Loss: 0.2442277 Vali Loss: 0.2486614 Test Loss: 0.2727549\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2580866\n",
      "\tspeed: 0.0836s/iter; left time: 370.5600s\n",
      "\titers: 200, epoch: 16 | loss: 0.2610742\n",
      "\tspeed: 0.0304s/iter; left time: 131.8128s\n",
      "\titers: 300, epoch: 16 | loss: 0.2428169\n",
      "\tspeed: 0.0302s/iter; left time: 127.9084s\n",
      "\titers: 400, epoch: 16 | loss: 0.2550306\n",
      "\tspeed: 0.0296s/iter; left time: 122.3010s\n",
      "\titers: 500, epoch: 16 | loss: 0.2314095\n",
      "\tspeed: 0.0296s/iter; left time: 119.3177s\n",
      "\titers: 600, epoch: 16 | loss: 0.2286934\n",
      "\tspeed: 0.0296s/iter; left time: 116.2098s\n",
      "\titers: 700, epoch: 16 | loss: 0.2168345\n",
      "\tspeed: 0.0296s/iter; left time: 113.2247s\n",
      "\titers: 800, epoch: 16 | loss: 0.2415393\n",
      "\tspeed: 0.0296s/iter; left time: 110.2964s\n",
      "\titers: 900, epoch: 16 | loss: 0.2262828\n",
      "\tspeed: 0.0296s/iter; left time: 107.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.34s\n",
      "Steps: 906 | Train Loss: 0.2424408 Vali Loss: 0.2466327 Test Loss: 0.2727647\n",
      "Validation loss decreased (0.248616 --> 0.246633).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.2161431\n",
      "\tspeed: 0.0842s/iter; left time: 296.7857s\n",
      "\titers: 200, epoch: 17 | loss: 0.2529179\n",
      "\tspeed: 0.0296s/iter; left time: 101.5351s\n",
      "\titers: 300, epoch: 17 | loss: 0.2262137\n",
      "\tspeed: 0.0296s/iter; left time: 98.4908s\n",
      "\titers: 400, epoch: 17 | loss: 0.1929938\n",
      "\tspeed: 0.0296s/iter; left time: 95.5261s\n",
      "\titers: 500, epoch: 17 | loss: 0.2696162\n",
      "\tspeed: 0.0296s/iter; left time: 92.5615s\n",
      "\titers: 600, epoch: 17 | loss: 0.2311496\n",
      "\tspeed: 0.0296s/iter; left time: 89.5968s\n",
      "\titers: 700, epoch: 17 | loss: 0.2199807\n",
      "\tspeed: 0.0296s/iter; left time: 86.6317s\n",
      "\titers: 800, epoch: 17 | loss: 0.2416278\n",
      "\tspeed: 0.0296s/iter; left time: 83.7004s\n",
      "\titers: 900, epoch: 17 | loss: 0.2810754\n",
      "\tspeed: 0.0296s/iter; left time: 80.7492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.13s\n",
      "Steps: 906 | Train Loss: 0.2413637 Vali Loss: 0.2464718 Test Loss: 0.2705329\n",
      "Validation loss decreased (0.246633 --> 0.246472).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.2167058\n",
      "\tspeed: 0.0869s/iter; left time: 227.4958s\n",
      "\titers: 200, epoch: 18 | loss: 0.2368382\n",
      "\tspeed: 0.0296s/iter; left time: 74.5484s\n",
      "\titers: 300, epoch: 18 | loss: 0.2192357\n",
      "\tspeed: 0.0296s/iter; left time: 71.5536s\n",
      "\titers: 400, epoch: 18 | loss: 0.2327405\n",
      "\tspeed: 0.0296s/iter; left time: 68.5869s\n",
      "\titers: 500, epoch: 18 | loss: 0.2245473\n",
      "\tspeed: 0.0296s/iter; left time: 65.6565s\n",
      "\titers: 600, epoch: 18 | loss: 0.2043872\n",
      "\tspeed: 0.0296s/iter; left time: 62.6511s\n",
      "\titers: 700, epoch: 18 | loss: 0.2337856\n",
      "\tspeed: 0.0296s/iter; left time: 59.6924s\n",
      "\titers: 800, epoch: 18 | loss: 0.2345974\n",
      "\tspeed: 0.0296s/iter; left time: 56.7378s\n",
      "\titers: 900, epoch: 18 | loss: 0.2442849\n",
      "\tspeed: 0.0296s/iter; left time: 53.8221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:27.09s\n",
      "Steps: 906 | Train Loss: 0.2403704 Vali Loss: 0.2465864 Test Loss: 0.2721342\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.2852758\n",
      "\tspeed: 0.0832s/iter; left time: 142.4636s\n",
      "\titers: 200, epoch: 19 | loss: 0.2500556\n",
      "\tspeed: 0.0295s/iter; left time: 47.6616s\n",
      "\titers: 300, epoch: 19 | loss: 0.2271177\n",
      "\tspeed: 0.0296s/iter; left time: 44.7242s\n",
      "\titers: 400, epoch: 19 | loss: 0.1958688\n",
      "\tspeed: 0.0296s/iter; left time: 41.7621s\n",
      "\titers: 500, epoch: 19 | loss: 0.2321912\n",
      "\tspeed: 0.0296s/iter; left time: 38.8073s\n",
      "\titers: 600, epoch: 19 | loss: 0.2199782\n",
      "\tspeed: 0.0296s/iter; left time: 35.8535s\n",
      "\titers: 700, epoch: 19 | loss: 0.2116968\n",
      "\tspeed: 0.0296s/iter; left time: 32.9530s\n",
      "\titers: 800, epoch: 19 | loss: 0.2390930\n",
      "\tspeed: 0.0296s/iter; left time: 29.9610s\n",
      "\titers: 900, epoch: 19 | loss: 0.2520115\n",
      "\tspeed: 0.0296s/iter; left time: 27.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:27.06s\n",
      "Steps: 906 | Train Loss: 0.2395252 Vali Loss: 0.2471846 Test Loss: 0.2706857\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.2002559\n",
      "\tspeed: 0.0829s/iter; left time: 66.9393s\n",
      "\titers: 200, epoch: 20 | loss: 0.2317692\n",
      "\tspeed: 0.0296s/iter; left time: 20.9363s\n",
      "\titers: 300, epoch: 20 | loss: 0.2474830\n",
      "\tspeed: 0.0296s/iter; left time: 17.9851s\n",
      "\titers: 400, epoch: 20 | loss: 0.2230704\n",
      "\tspeed: 0.0296s/iter; left time: 15.0228s\n",
      "\titers: 500, epoch: 20 | loss: 0.2750233\n",
      "\tspeed: 0.0296s/iter; left time: 12.0600s\n",
      "\titers: 600, epoch: 20 | loss: 0.2412827\n",
      "\tspeed: 0.0296s/iter; left time: 9.0939s\n",
      "\titers: 700, epoch: 20 | loss: 0.2620236\n",
      "\tspeed: 0.0296s/iter; left time: 6.1371s\n",
      "\titers: 800, epoch: 20 | loss: 0.2424151\n",
      "\tspeed: 0.0296s/iter; left time: 3.1709s\n",
      "\titers: 900, epoch: 20 | loss: 0.2197125\n",
      "\tspeed: 0.0296s/iter; left time: 0.2074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:27.12s\n",
      "Steps: 906 | Train Loss: 0.2387766 Vali Loss: 0.2458301 Test Loss: 0.2699371\n",
      "Validation loss decreased (0.246472 --> 0.245830).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21430844068527222, rmse:0.46293458342552185, mae:0.26991504430770874, rse:0.42397287487983704\n",
      "Original data scale mse:1422171.75, rmse:1192.5484619140625, mae:752.7681274414062, rse:0.083803191781044\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8924678\n",
      "\tspeed: 0.0619s/iter; left time: 1112.1612s\n",
      "\titers: 200, epoch: 1 | loss: 0.8552704\n",
      "\tspeed: 0.0373s/iter; left time: 666.2234s\n",
      "\titers: 300, epoch: 1 | loss: 0.8087169\n",
      "\tspeed: 0.0374s/iter; left time: 664.2412s\n",
      "\titers: 400, epoch: 1 | loss: 0.8165908\n",
      "\tspeed: 0.0373s/iter; left time: 659.4875s\n",
      "\titers: 500, epoch: 1 | loss: 0.8305601\n",
      "\tspeed: 0.0373s/iter; left time: 656.3773s\n",
      "\titers: 600, epoch: 1 | loss: 0.8097811\n",
      "\tspeed: 0.0374s/iter; left time: 653.1138s\n",
      "\titers: 700, epoch: 1 | loss: 0.8000586\n",
      "\tspeed: 0.0374s/iter; left time: 649.4998s\n",
      "\titers: 800, epoch: 1 | loss: 0.7591743\n",
      "\tspeed: 0.0374s/iter; left time: 646.3215s\n",
      "\titers: 900, epoch: 1 | loss: 0.8073985\n",
      "\tspeed: 0.0374s/iter; left time: 642.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.46s\n",
      "Steps: 904 | Train Loss: 0.8209887 Vali Loss: 0.7851841 Test Loss: 0.8573559\n",
      "Validation loss decreased (inf --> 0.785184).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.7153817\n",
      "\tspeed: 0.1085s/iter; left time: 1853.7008s\n",
      "\titers: 200, epoch: 2 | loss: 0.6748725\n",
      "\tspeed: 0.0379s/iter; left time: 643.4102s\n",
      "\titers: 300, epoch: 2 | loss: 0.5799940\n",
      "\tspeed: 0.0379s/iter; left time: 639.1971s\n",
      "\titers: 400, epoch: 2 | loss: 0.5727319\n",
      "\tspeed: 0.0379s/iter; left time: 635.6280s\n",
      "\titers: 500, epoch: 2 | loss: 0.5555871\n",
      "\tspeed: 0.0379s/iter; left time: 631.7528s\n",
      "\titers: 600, epoch: 2 | loss: 0.5474285\n",
      "\tspeed: 0.0379s/iter; left time: 627.6504s\n",
      "\titers: 700, epoch: 2 | loss: 0.5286592\n",
      "\tspeed: 0.0374s/iter; left time: 616.7902s\n",
      "\titers: 800, epoch: 2 | loss: 0.5187691\n",
      "\tspeed: 0.0374s/iter; left time: 612.3298s\n",
      "\titers: 900, epoch: 2 | loss: 0.4872763\n",
      "\tspeed: 0.0374s/iter; left time: 608.8167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:34.43s\n",
      "Steps: 904 | Train Loss: 0.5843379 Vali Loss: 0.4868374 Test Loss: 0.5245005\n",
      "Validation loss decreased (0.785184 --> 0.486837).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4967108\n",
      "\tspeed: 0.1079s/iter; left time: 1744.5081s\n",
      "\titers: 200, epoch: 3 | loss: 0.4951444\n",
      "\tspeed: 0.0380s/iter; left time: 610.3015s\n",
      "\titers: 300, epoch: 3 | loss: 0.5005293\n",
      "\tspeed: 0.0379s/iter; left time: 605.5241s\n",
      "\titers: 400, epoch: 3 | loss: 0.4877960\n",
      "\tspeed: 0.0379s/iter; left time: 601.3663s\n",
      "\titers: 500, epoch: 3 | loss: 0.4445902\n",
      "\tspeed: 0.0379s/iter; left time: 597.5952s\n",
      "\titers: 600, epoch: 3 | loss: 0.4617152\n",
      "\tspeed: 0.0379s/iter; left time: 593.8037s\n",
      "\titers: 700, epoch: 3 | loss: 0.4696015\n",
      "\tspeed: 0.0379s/iter; left time: 590.8356s\n",
      "\titers: 800, epoch: 3 | loss: 0.4945424\n",
      "\tspeed: 0.0379s/iter; left time: 586.6413s\n",
      "\titers: 900, epoch: 3 | loss: 0.4769808\n",
      "\tspeed: 0.0379s/iter; left time: 582.7148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:34.55s\n",
      "Steps: 904 | Train Loss: 0.4748954 Vali Loss: 0.4309563 Test Loss: 0.4664349\n",
      "Validation loss decreased (0.486837 --> 0.430956).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4356037\n",
      "\tspeed: 0.1086s/iter; left time: 1657.4647s\n",
      "\titers: 200, epoch: 4 | loss: 0.4442886\n",
      "\tspeed: 0.0380s/iter; left time: 576.2075s\n",
      "\titers: 300, epoch: 4 | loss: 0.4059523\n",
      "\tspeed: 0.0380s/iter; left time: 571.9694s\n",
      "\titers: 400, epoch: 4 | loss: 0.4535042\n",
      "\tspeed: 0.0379s/iter; left time: 567.9970s\n",
      "\titers: 500, epoch: 4 | loss: 0.4350600\n",
      "\tspeed: 0.0377s/iter; left time: 560.1470s\n",
      "\titers: 600, epoch: 4 | loss: 0.4347092\n",
      "\tspeed: 0.0374s/iter; left time: 552.1520s\n",
      "\titers: 700, epoch: 4 | loss: 0.4179144\n",
      "\tspeed: 0.0373s/iter; left time: 547.6208s\n",
      "\titers: 800, epoch: 4 | loss: 0.4328313\n",
      "\tspeed: 0.0373s/iter; left time: 543.8149s\n",
      "\titers: 900, epoch: 4 | loss: 0.4117389\n",
      "\tspeed: 0.0373s/iter; left time: 540.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.32s\n",
      "Steps: 904 | Train Loss: 0.4374243 Vali Loss: 0.4132145 Test Loss: 0.4635957\n",
      "Validation loss decreased (0.430956 --> 0.413215).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3970404\n",
      "\tspeed: 0.1073s/iter; left time: 1541.6645s\n",
      "\titers: 200, epoch: 5 | loss: 0.4210733\n",
      "\tspeed: 0.0375s/iter; left time: 534.5260s\n",
      "\titers: 300, epoch: 5 | loss: 0.4140360\n",
      "\tspeed: 0.0377s/iter; left time: 534.4120s\n",
      "\titers: 400, epoch: 5 | loss: 0.4629141\n",
      "\tspeed: 0.0378s/iter; left time: 531.8370s\n",
      "\titers: 500, epoch: 5 | loss: 0.4260851\n",
      "\tspeed: 0.0373s/iter; left time: 521.5419s\n",
      "\titers: 600, epoch: 5 | loss: 0.4173710\n",
      "\tspeed: 0.0374s/iter; left time: 517.8846s\n",
      "\titers: 700, epoch: 5 | loss: 0.4166731\n",
      "\tspeed: 0.0373s/iter; left time: 514.0224s\n",
      "\titers: 800, epoch: 5 | loss: 0.4283570\n",
      "\tspeed: 0.0377s/iter; left time: 515.8448s\n",
      "\titers: 900, epoch: 5 | loss: 0.3858593\n",
      "\tspeed: 0.0375s/iter; left time: 508.7855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.22s\n",
      "Steps: 904 | Train Loss: 0.4183095 Vali Loss: 0.3987996 Test Loss: 0.4368952\n",
      "Validation loss decreased (0.413215 --> 0.398800).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3703642\n",
      "\tspeed: 0.1090s/iter; left time: 1467.3656s\n",
      "\titers: 200, epoch: 6 | loss: 0.4253498\n",
      "\tspeed: 0.0373s/iter; left time: 498.6431s\n",
      "\titers: 300, epoch: 6 | loss: 0.4080736\n",
      "\tspeed: 0.0373s/iter; left time: 494.4520s\n",
      "\titers: 400, epoch: 6 | loss: 0.4510202\n",
      "\tspeed: 0.0374s/iter; left time: 492.2100s\n",
      "\titers: 500, epoch: 6 | loss: 0.4044337\n",
      "\tspeed: 0.0374s/iter; left time: 488.7626s\n",
      "\titers: 600, epoch: 6 | loss: 0.3818032\n",
      "\tspeed: 0.0374s/iter; left time: 484.9023s\n",
      "\titers: 700, epoch: 6 | loss: 0.3774590\n",
      "\tspeed: 0.0373s/iter; left time: 480.1321s\n",
      "\titers: 800, epoch: 6 | loss: 0.4066144\n",
      "\tspeed: 0.0373s/iter; left time: 476.2976s\n",
      "\titers: 900, epoch: 6 | loss: 0.4033196\n",
      "\tspeed: 0.0376s/iter; left time: 475.5500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.12s\n",
      "Steps: 904 | Train Loss: 0.4052695 Vali Loss: 0.3929883 Test Loss: 0.4284729\n",
      "Validation loss decreased (0.398800 --> 0.392988).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3988694\n",
      "\tspeed: 0.1061s/iter; left time: 1332.1157s\n",
      "\titers: 200, epoch: 7 | loss: 0.3781427\n",
      "\tspeed: 0.0380s/iter; left time: 473.1544s\n",
      "\titers: 300, epoch: 7 | loss: 0.3939885\n",
      "\tspeed: 0.0380s/iter; left time: 469.1150s\n",
      "\titers: 400, epoch: 7 | loss: 0.3908892\n",
      "\tspeed: 0.0380s/iter; left time: 465.9417s\n",
      "\titers: 500, epoch: 7 | loss: 0.3854514\n",
      "\tspeed: 0.0380s/iter; left time: 461.6914s\n",
      "\titers: 600, epoch: 7 | loss: 0.4397357\n",
      "\tspeed: 0.0380s/iter; left time: 458.1832s\n",
      "\titers: 700, epoch: 7 | loss: 0.3476251\n",
      "\tspeed: 0.0380s/iter; left time: 454.4316s\n",
      "\titers: 800, epoch: 7 | loss: 0.3591777\n",
      "\tspeed: 0.0380s/iter; left time: 450.2595s\n",
      "\titers: 900, epoch: 7 | loss: 0.3888686\n",
      "\tspeed: 0.0380s/iter; left time: 446.8691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.63s\n",
      "Steps: 904 | Train Loss: 0.3959724 Vali Loss: 0.3864358 Test Loss: 0.4143176\n",
      "Validation loss decreased (0.392988 --> 0.386436).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4162530\n",
      "\tspeed: 0.1054s/iter; left time: 1228.3873s\n",
      "\titers: 200, epoch: 8 | loss: 0.3711434\n",
      "\tspeed: 0.0378s/iter; left time: 437.0859s\n",
      "\titers: 300, epoch: 8 | loss: 0.3961549\n",
      "\tspeed: 0.0378s/iter; left time: 432.5317s\n",
      "\titers: 400, epoch: 8 | loss: 0.4077929\n",
      "\tspeed: 0.0373s/iter; left time: 423.5941s\n",
      "\titers: 500, epoch: 8 | loss: 0.4127837\n",
      "\tspeed: 0.0373s/iter; left time: 420.0110s\n",
      "\titers: 600, epoch: 8 | loss: 0.3772440\n",
      "\tspeed: 0.0373s/iter; left time: 416.2761s\n",
      "\titers: 700, epoch: 8 | loss: 0.3940263\n",
      "\tspeed: 0.0373s/iter; left time: 412.4760s\n",
      "\titers: 800, epoch: 8 | loss: 0.3834263\n",
      "\tspeed: 0.0373s/iter; left time: 408.7775s\n",
      "\titers: 900, epoch: 8 | loss: 0.3984240\n",
      "\tspeed: 0.0373s/iter; left time: 405.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:34.18s\n",
      "Steps: 904 | Train Loss: 0.3875524 Vali Loss: 0.3867569 Test Loss: 0.4123820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3803415\n",
      "\tspeed: 0.1047s/iter; left time: 1124.9152s\n",
      "\titers: 200, epoch: 9 | loss: 0.4042706\n",
      "\tspeed: 0.0373s/iter; left time: 397.6393s\n",
      "\titers: 300, epoch: 9 | loss: 0.3673797\n",
      "\tspeed: 0.0373s/iter; left time: 393.9308s\n",
      "\titers: 400, epoch: 9 | loss: 0.3605452\n",
      "\tspeed: 0.0373s/iter; left time: 389.9885s\n",
      "\titers: 500, epoch: 9 | loss: 0.3708380\n",
      "\tspeed: 0.0373s/iter; left time: 386.2298s\n",
      "\titers: 600, epoch: 9 | loss: 0.3803269\n",
      "\tspeed: 0.0373s/iter; left time: 382.6629s\n",
      "\titers: 700, epoch: 9 | loss: 0.3840871\n",
      "\tspeed: 0.0373s/iter; left time: 378.8240s\n",
      "\titers: 800, epoch: 9 | loss: 0.3490540\n",
      "\tspeed: 0.0373s/iter; left time: 375.1322s\n",
      "\titers: 900, epoch: 9 | loss: 0.3987399\n",
      "\tspeed: 0.0373s/iter; left time: 371.5847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:34.08s\n",
      "Steps: 904 | Train Loss: 0.3807226 Vali Loss: 0.3789786 Test Loss: 0.4111935\n",
      "Validation loss decreased (0.386436 --> 0.378979).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3571538\n",
      "\tspeed: 0.1067s/iter; left time: 1050.0665s\n",
      "\titers: 200, epoch: 10 | loss: 0.3926348\n",
      "\tspeed: 0.0373s/iter; left time: 363.6967s\n",
      "\titers: 300, epoch: 10 | loss: 0.3550519\n",
      "\tspeed: 0.0373s/iter; left time: 359.8712s\n",
      "\titers: 400, epoch: 10 | loss: 0.3973148\n",
      "\tspeed: 0.0373s/iter; left time: 356.1056s\n",
      "\titers: 500, epoch: 10 | loss: 0.3739792\n",
      "\tspeed: 0.0373s/iter; left time: 352.3925s\n",
      "\titers: 600, epoch: 10 | loss: 0.3574772\n",
      "\tspeed: 0.0373s/iter; left time: 348.5314s\n",
      "\titers: 700, epoch: 10 | loss: 0.4012173\n",
      "\tspeed: 0.0373s/iter; left time: 345.1334s\n",
      "\titers: 800, epoch: 10 | loss: 0.3662159\n",
      "\tspeed: 0.0373s/iter; left time: 341.2376s\n",
      "\titers: 900, epoch: 10 | loss: 0.3801857\n",
      "\tspeed: 0.0373s/iter; left time: 337.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:34.01s\n",
      "Steps: 904 | Train Loss: 0.3751889 Vali Loss: 0.3768012 Test Loss: 0.4082024\n",
      "Validation loss decreased (0.378979 --> 0.376801).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3661891\n",
      "\tspeed: 0.1079s/iter; left time: 964.5700s\n",
      "\titers: 200, epoch: 11 | loss: 0.3973256\n",
      "\tspeed: 0.0374s/iter; left time: 330.2133s\n",
      "\titers: 300, epoch: 11 | loss: 0.3599370\n",
      "\tspeed: 0.0373s/iter; left time: 326.2749s\n",
      "\titers: 400, epoch: 11 | loss: 0.3449017\n",
      "\tspeed: 0.0373s/iter; left time: 322.7140s\n",
      "\titers: 500, epoch: 11 | loss: 0.3642965\n",
      "\tspeed: 0.0373s/iter; left time: 318.9492s\n",
      "\titers: 600, epoch: 11 | loss: 0.3529836\n",
      "\tspeed: 0.0373s/iter; left time: 315.1429s\n",
      "\titers: 700, epoch: 11 | loss: 0.3737069\n",
      "\tspeed: 0.0373s/iter; left time: 311.4666s\n",
      "\titers: 800, epoch: 11 | loss: 0.3639170\n",
      "\tspeed: 0.0373s/iter; left time: 307.3431s\n",
      "\titers: 900, epoch: 11 | loss: 0.3798115\n",
      "\tspeed: 0.0373s/iter; left time: 303.4985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:34.03s\n",
      "Steps: 904 | Train Loss: 0.3706057 Vali Loss: 0.3737461 Test Loss: 0.4073395\n",
      "Validation loss decreased (0.376801 --> 0.373746).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3652874\n",
      "\tspeed: 0.1064s/iter; left time: 855.1866s\n",
      "\titers: 200, epoch: 12 | loss: 0.3603056\n",
      "\tspeed: 0.0373s/iter; left time: 295.7279s\n",
      "\titers: 300, epoch: 12 | loss: 0.3556455\n",
      "\tspeed: 0.0373s/iter; left time: 292.1512s\n",
      "\titers: 400, epoch: 12 | loss: 0.3748062\n",
      "\tspeed: 0.0373s/iter; left time: 288.5352s\n",
      "\titers: 500, epoch: 12 | loss: 0.3467007\n",
      "\tspeed: 0.0373s/iter; left time: 284.5428s\n",
      "\titers: 600, epoch: 12 | loss: 0.3723220\n",
      "\tspeed: 0.0373s/iter; left time: 280.9785s\n",
      "\titers: 700, epoch: 12 | loss: 0.3882639\n",
      "\tspeed: 0.0373s/iter; left time: 277.2359s\n",
      "\titers: 800, epoch: 12 | loss: 0.3506689\n",
      "\tspeed: 0.0373s/iter; left time: 273.6031s\n",
      "\titers: 900, epoch: 12 | loss: 0.3620559\n",
      "\tspeed: 0.0373s/iter; left time: 269.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:33.98s\n",
      "Steps: 904 | Train Loss: 0.3659720 Vali Loss: 0.3708376 Test Loss: 0.4019832\n",
      "Validation loss decreased (0.373746 --> 0.370838).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3761593\n",
      "\tspeed: 0.1089s/iter; left time: 776.9193s\n",
      "\titers: 200, epoch: 13 | loss: 0.3653590\n",
      "\tspeed: 0.0374s/iter; left time: 263.1347s\n",
      "\titers: 300, epoch: 13 | loss: 0.3718610\n",
      "\tspeed: 0.0428s/iter; left time: 296.8233s\n",
      "\titers: 400, epoch: 13 | loss: 0.3743576\n",
      "\tspeed: 0.0506s/iter; left time: 345.8885s\n",
      "\titers: 500, epoch: 13 | loss: 0.3736706\n",
      "\tspeed: 0.0485s/iter; left time: 326.3613s\n",
      "\titers: 600, epoch: 13 | loss: 0.3324582\n",
      "\tspeed: 0.0492s/iter; left time: 326.5093s\n",
      "\titers: 700, epoch: 13 | loss: 0.3541279\n",
      "\tspeed: 0.0506s/iter; left time: 330.5985s\n",
      "\titers: 800, epoch: 13 | loss: 0.3737999\n",
      "\tspeed: 0.0528s/iter; left time: 339.5459s\n",
      "\titers: 900, epoch: 13 | loss: 0.3700500\n",
      "\tspeed: 0.0487s/iter; left time: 308.3287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.43s\n",
      "Steps: 904 | Train Loss: 0.3628254 Vali Loss: 0.3717381 Test Loss: 0.4045743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.3598758\n",
      "\tspeed: 0.1521s/iter; left time: 947.2522s\n",
      "\titers: 200, epoch: 14 | loss: 0.3759094\n",
      "\tspeed: 0.0502s/iter; left time: 307.7279s\n",
      "\titers: 300, epoch: 14 | loss: 0.3499198\n",
      "\tspeed: 0.0499s/iter; left time: 301.0736s\n",
      "\titers: 400, epoch: 14 | loss: 0.3406655\n",
      "\tspeed: 0.0503s/iter; left time: 298.4530s\n",
      "\titers: 500, epoch: 14 | loss: 0.3442841\n",
      "\tspeed: 0.0500s/iter; left time: 291.2650s\n",
      "\titers: 600, epoch: 14 | loss: 0.3511613\n",
      "\tspeed: 0.0500s/iter; left time: 286.5382s\n",
      "\titers: 700, epoch: 14 | loss: 0.3569548\n",
      "\tspeed: 0.0512s/iter; left time: 287.9574s\n",
      "\titers: 800, epoch: 14 | loss: 0.3963260\n",
      "\tspeed: 0.0501s/iter; left time: 277.1634s\n",
      "\titers: 900, epoch: 14 | loss: 0.3713683\n",
      "\tspeed: 0.0502s/iter; left time: 272.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 904 | Train Loss: 0.3596776 Vali Loss: 0.3684863 Test Loss: 0.3981346\n",
      "Validation loss decreased (0.370838 --> 0.368486).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3678452\n",
      "\tspeed: 0.1572s/iter; left time: 837.2874s\n",
      "\titers: 200, epoch: 15 | loss: 0.3713709\n",
      "\tspeed: 0.0512s/iter; left time: 267.5551s\n",
      "\titers: 300, epoch: 15 | loss: 0.3587652\n",
      "\tspeed: 0.0522s/iter; left time: 267.7471s\n",
      "\titers: 400, epoch: 15 | loss: 0.3239684\n",
      "\tspeed: 0.0515s/iter; left time: 258.7493s\n",
      "\titers: 500, epoch: 15 | loss: 0.3521868\n",
      "\tspeed: 0.0511s/iter; left time: 251.4662s\n",
      "\titers: 600, epoch: 15 | loss: 0.3672183\n",
      "\tspeed: 0.0504s/iter; left time: 243.0832s\n",
      "\titers: 700, epoch: 15 | loss: 0.3628301\n",
      "\tspeed: 0.0501s/iter; left time: 236.8894s\n",
      "\titers: 800, epoch: 15 | loss: 0.3233464\n",
      "\tspeed: 0.0516s/iter; left time: 238.4384s\n",
      "\titers: 900, epoch: 15 | loss: 0.3398476\n",
      "\tspeed: 0.0510s/iter; left time: 230.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 904 | Train Loss: 0.3566460 Vali Loss: 0.3700235 Test Loss: 0.4024010\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.3442712\n",
      "\tspeed: 0.1560s/iter; left time: 689.6041s\n",
      "\titers: 200, epoch: 16 | loss: 0.3694592\n",
      "\tspeed: 0.0513s/iter; left time: 221.5193s\n",
      "\titers: 300, epoch: 16 | loss: 0.3290903\n",
      "\tspeed: 0.0517s/iter; left time: 218.0747s\n",
      "\titers: 400, epoch: 16 | loss: 0.3155095\n",
      "\tspeed: 0.0468s/iter; left time: 192.9359s\n",
      "\titers: 500, epoch: 16 | loss: 0.3467883\n",
      "\tspeed: 0.0392s/iter; left time: 157.4864s\n",
      "\titers: 600, epoch: 16 | loss: 0.3572109\n",
      "\tspeed: 0.0389s/iter; left time: 152.5107s\n",
      "\titers: 700, epoch: 16 | loss: 0.3552343\n",
      "\tspeed: 0.0382s/iter; left time: 145.9118s\n",
      "\titers: 800, epoch: 16 | loss: 0.3513011\n",
      "\tspeed: 0.0379s/iter; left time: 140.9872s\n",
      "\titers: 900, epoch: 16 | loss: 0.3555185\n",
      "\tspeed: 0.0378s/iter; left time: 137.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 904 | Train Loss: 0.3541659 Vali Loss: 0.3686598 Test Loss: 0.3985809\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3474201\n",
      "\tspeed: 0.1038s/iter; left time: 364.9769s\n",
      "\titers: 200, epoch: 17 | loss: 0.3755631\n",
      "\tspeed: 0.0380s/iter; left time: 129.6941s\n",
      "\titers: 300, epoch: 17 | loss: 0.3760085\n",
      "\tspeed: 0.0380s/iter; left time: 126.0366s\n",
      "\titers: 400, epoch: 17 | loss: 0.3231269\n",
      "\tspeed: 0.0378s/iter; left time: 121.7584s\n",
      "\titers: 500, epoch: 17 | loss: 0.3674728\n",
      "\tspeed: 0.0378s/iter; left time: 117.6997s\n",
      "\titers: 600, epoch: 17 | loss: 0.3527449\n",
      "\tspeed: 0.0374s/iter; left time: 112.8475s\n",
      "\titers: 700, epoch: 17 | loss: 0.3575794\n",
      "\tspeed: 0.0373s/iter; left time: 108.7285s\n",
      "\titers: 800, epoch: 17 | loss: 0.3128138\n",
      "\tspeed: 0.0377s/iter; left time: 106.3210s\n",
      "\titers: 900, epoch: 17 | loss: 0.3449649\n",
      "\tspeed: 0.0374s/iter; left time: 101.4834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:34.37s\n",
      "Steps: 904 | Train Loss: 0.3522257 Vali Loss: 0.3673126 Test Loss: 0.3989522\n",
      "Validation loss decreased (0.368486 --> 0.367313).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3301871\n",
      "\tspeed: 0.1067s/iter; left time: 278.8773s\n",
      "\titers: 200, epoch: 18 | loss: 0.3390364\n",
      "\tspeed: 0.0380s/iter; left time: 95.5167s\n",
      "\titers: 300, epoch: 18 | loss: 0.3150220\n",
      "\tspeed: 0.0375s/iter; left time: 90.4705s\n",
      "\titers: 400, epoch: 18 | loss: 0.3910287\n",
      "\tspeed: 0.0375s/iter; left time: 86.6888s\n",
      "\titers: 500, epoch: 18 | loss: 0.3544911\n",
      "\tspeed: 0.0374s/iter; left time: 82.8221s\n",
      "\titers: 600, epoch: 18 | loss: 0.3400359\n",
      "\tspeed: 0.0379s/iter; left time: 80.0032s\n",
      "\titers: 700, epoch: 18 | loss: 0.3274244\n",
      "\tspeed: 0.0379s/iter; left time: 76.3913s\n",
      "\titers: 800, epoch: 18 | loss: 0.3581196\n",
      "\tspeed: 0.0380s/iter; left time: 72.6271s\n",
      "\titers: 900, epoch: 18 | loss: 0.3195712\n",
      "\tspeed: 0.0380s/iter; left time: 68.8574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:34.46s\n",
      "Steps: 904 | Train Loss: 0.3501526 Vali Loss: 0.3670064 Test Loss: 0.3972716\n",
      "Validation loss decreased (0.367313 --> 0.367006).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.3520624\n",
      "\tspeed: 0.1141s/iter; left time: 195.0298s\n",
      "\titers: 200, epoch: 19 | loss: 0.3606013\n",
      "\tspeed: 0.0463s/iter; left time: 74.4364s\n",
      "\titers: 300, epoch: 19 | loss: 0.3488351\n",
      "\tspeed: 0.0465s/iter; left time: 70.2049s\n",
      "\titers: 400, epoch: 19 | loss: 0.3483140\n",
      "\tspeed: 0.0452s/iter; left time: 63.7254s\n",
      "\titers: 500, epoch: 19 | loss: 0.3712033\n",
      "\tspeed: 0.0467s/iter; left time: 61.0946s\n",
      "\titers: 600, epoch: 19 | loss: 0.3613670\n",
      "\tspeed: 0.0444s/iter; left time: 53.6994s\n",
      "\titers: 700, epoch: 19 | loss: 0.3575230\n",
      "\tspeed: 0.0452s/iter; left time: 50.1119s\n",
      "\titers: 800, epoch: 19 | loss: 0.3199439\n",
      "\tspeed: 0.0444s/iter; left time: 44.8342s\n",
      "\titers: 900, epoch: 19 | loss: 0.3244304\n",
      "\tspeed: 0.0446s/iter; left time: 40.5311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:41.38s\n",
      "Steps: 904 | Train Loss: 0.3484346 Vali Loss: 0.3667833 Test Loss: 0.3945830\n",
      "Validation loss decreased (0.367006 --> 0.366783).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.3334037\n",
      "\tspeed: 0.1467s/iter; left time: 118.0535s\n",
      "\titers: 200, epoch: 20 | loss: 0.3355766\n",
      "\tspeed: 0.0467s/iter; left time: 32.9067s\n",
      "\titers: 300, epoch: 20 | loss: 0.3652014\n",
      "\tspeed: 0.0477s/iter; left time: 28.8818s\n",
      "\titers: 400, epoch: 20 | loss: 0.3516469\n",
      "\tspeed: 0.0448s/iter; left time: 22.5999s\n",
      "\titers: 500, epoch: 20 | loss: 0.3502616\n",
      "\tspeed: 0.0461s/iter; left time: 18.6904s\n",
      "\titers: 600, epoch: 20 | loss: 0.3505624\n",
      "\tspeed: 0.0453s/iter; left time: 13.8279s\n",
      "\titers: 700, epoch: 20 | loss: 0.3749192\n",
      "\tspeed: 0.0445s/iter; left time: 9.1223s\n",
      "\titers: 800, epoch: 20 | loss: 0.3460981\n",
      "\tspeed: 0.0440s/iter; left time: 4.6244s\n",
      "\titers: 900, epoch: 20 | loss: 0.3410740\n",
      "\tspeed: 0.0452s/iter; left time: 0.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:42.15s\n",
      "Steps: 904 | Train Loss: 0.3468028 Vali Loss: 0.3660991 Test Loss: 0.3977407\n",
      "Validation loss decreased (0.366783 --> 0.366099).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4035509526729584, rmse:0.6352565884590149, mae:0.3978092670440674, rse:0.5816439390182495\n",
      "Original data scale mse:3235874.0, rmse:1798.853515625, mae:1184.22607421875, rse:0.12659266591072083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9401219\n",
      "\tspeed: 0.0560s/iter; left time: 1007.2542s\n",
      "\titers: 200, epoch: 1 | loss: 0.8965876\n",
      "\tspeed: 0.0446s/iter; left time: 797.2812s\n",
      "\titers: 300, epoch: 1 | loss: 0.8733780\n",
      "\tspeed: 0.0446s/iter; left time: 792.2196s\n",
      "\titers: 400, epoch: 1 | loss: 0.8447787\n",
      "\tspeed: 0.0450s/iter; left time: 795.6386s\n",
      "\titers: 500, epoch: 1 | loss: 0.8080447\n",
      "\tspeed: 0.0441s/iter; left time: 774.9638s\n",
      "\titers: 600, epoch: 1 | loss: 0.8304662\n",
      "\tspeed: 0.0447s/iter; left time: 780.7967s\n",
      "\titers: 700, epoch: 1 | loss: 0.8255876\n",
      "\tspeed: 0.0448s/iter; left time: 779.0072s\n",
      "\titers: 800, epoch: 1 | loss: 0.7789768\n",
      "\tspeed: 0.0446s/iter; left time: 770.3438s\n",
      "\titers: 900, epoch: 1 | loss: 0.8108875\n",
      "\tspeed: 0.0450s/iter; left time: 773.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 904 | Train Loss: 0.8494384 Vali Loss: 0.7971478 Test Loss: 0.8710811\n",
      "Validation loss decreased (inf --> 0.797148).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.7326304\n",
      "\tspeed: 0.1446s/iter; left time: 2469.3759s\n",
      "\titers: 200, epoch: 2 | loss: 0.6602769\n",
      "\tspeed: 0.0456s/iter; left time: 774.1996s\n",
      "\titers: 300, epoch: 2 | loss: 0.5638440\n",
      "\tspeed: 0.0448s/iter; left time: 755.5039s\n",
      "\titers: 400, epoch: 2 | loss: 0.5334097\n",
      "\tspeed: 0.0447s/iter; left time: 750.7657s\n",
      "\titers: 500, epoch: 2 | loss: 0.5454442\n",
      "\tspeed: 0.0450s/iter; left time: 750.5107s\n",
      "\titers: 600, epoch: 2 | loss: 0.5219631\n",
      "\tspeed: 0.0446s/iter; left time: 740.0512s\n",
      "\titers: 700, epoch: 2 | loss: 0.4726389\n",
      "\tspeed: 0.0447s/iter; left time: 736.7955s\n",
      "\titers: 800, epoch: 2 | loss: 0.5309203\n",
      "\tspeed: 0.0451s/iter; left time: 739.0575s\n",
      "\titers: 900, epoch: 2 | loss: 0.4962853\n",
      "\tspeed: 0.0466s/iter; left time: 758.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 904 | Train Loss: 0.5818114 Vali Loss: 0.4876393 Test Loss: 0.5176049\n",
      "Validation loss decreased (0.797148 --> 0.487639).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5073497\n",
      "\tspeed: 0.1443s/iter; left time: 2333.5838s\n",
      "\titers: 200, epoch: 3 | loss: 0.4743623\n",
      "\tspeed: 0.0461s/iter; left time: 740.2972s\n",
      "\titers: 300, epoch: 3 | loss: 0.5120586\n",
      "\tspeed: 0.0453s/iter; left time: 724.0748s\n",
      "\titers: 400, epoch: 3 | loss: 0.5074393\n",
      "\tspeed: 0.0445s/iter; left time: 706.3492s\n",
      "\titers: 500, epoch: 3 | loss: 0.4579069\n",
      "\tspeed: 0.0449s/iter; left time: 708.2600s\n",
      "\titers: 600, epoch: 3 | loss: 0.4457837\n",
      "\tspeed: 0.0447s/iter; left time: 700.1707s\n",
      "\titers: 700, epoch: 3 | loss: 0.4732681\n",
      "\tspeed: 0.0450s/iter; left time: 700.9744s\n",
      "\titers: 800, epoch: 3 | loss: 0.4365345\n",
      "\tspeed: 0.0457s/iter; left time: 707.5089s\n",
      "\titers: 900, epoch: 3 | loss: 0.4504232\n",
      "\tspeed: 0.0456s/iter; left time: 701.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 904 | Train Loss: 0.4774575 Vali Loss: 0.4386027 Test Loss: 0.4691541\n",
      "Validation loss decreased (0.487639 --> 0.438603).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4531013\n",
      "\tspeed: 0.1438s/iter; left time: 2196.4416s\n",
      "\titers: 200, epoch: 4 | loss: 0.4409775\n",
      "\tspeed: 0.0446s/iter; left time: 676.0737s\n",
      "\titers: 300, epoch: 4 | loss: 0.4351166\n",
      "\tspeed: 0.0467s/iter; left time: 703.7617s\n",
      "\titers: 400, epoch: 4 | loss: 0.4036928\n",
      "\tspeed: 0.0445s/iter; left time: 666.4273s\n",
      "\titers: 500, epoch: 4 | loss: 0.3994589\n",
      "\tspeed: 0.0446s/iter; left time: 662.9034s\n",
      "\titers: 600, epoch: 4 | loss: 0.4175158\n",
      "\tspeed: 0.0443s/iter; left time: 654.1934s\n",
      "\titers: 700, epoch: 4 | loss: 0.4083522\n",
      "\tspeed: 0.0462s/iter; left time: 678.3084s\n",
      "\titers: 800, epoch: 4 | loss: 0.4060982\n",
      "\tspeed: 0.0446s/iter; left time: 649.8883s\n",
      "\titers: 900, epoch: 4 | loss: 0.4340017\n",
      "\tspeed: 0.0446s/iter; left time: 644.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 904 | Train Loss: 0.4379937 Vali Loss: 0.4110311 Test Loss: 0.4412461\n",
      "Validation loss decreased (0.438603 --> 0.411031).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3948069\n",
      "\tspeed: 0.1395s/iter; left time: 2003.4853s\n",
      "\titers: 200, epoch: 5 | loss: 0.4520392\n",
      "\tspeed: 0.0448s/iter; left time: 638.4122s\n",
      "\titers: 300, epoch: 5 | loss: 0.4236452\n",
      "\tspeed: 0.0445s/iter; left time: 631.0275s\n",
      "\titers: 400, epoch: 5 | loss: 0.4376723\n",
      "\tspeed: 0.0452s/iter; left time: 635.9792s\n",
      "\titers: 500, epoch: 5 | loss: 0.4000784\n",
      "\tspeed: 0.0448s/iter; left time: 626.2189s\n",
      "\titers: 600, epoch: 5 | loss: 0.4201700\n",
      "\tspeed: 0.0450s/iter; left time: 624.1471s\n",
      "\titers: 700, epoch: 5 | loss: 0.4056989\n",
      "\tspeed: 0.0454s/iter; left time: 624.6179s\n",
      "\titers: 800, epoch: 5 | loss: 0.4201973\n",
      "\tspeed: 0.0458s/iter; left time: 626.5323s\n",
      "\titers: 900, epoch: 5 | loss: 0.4435297\n",
      "\tspeed: 0.0453s/iter; left time: 614.7688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.53s\n",
      "Steps: 904 | Train Loss: 0.4135974 Vali Loss: 0.3920527 Test Loss: 0.4244966\n",
      "Validation loss decreased (0.411031 --> 0.392053).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4106001\n",
      "\tspeed: 0.1440s/iter; left time: 1937.8237s\n",
      "\titers: 200, epoch: 6 | loss: 0.3908345\n",
      "\tspeed: 0.0443s/iter; left time: 591.7429s\n",
      "\titers: 300, epoch: 6 | loss: 0.3956393\n",
      "\tspeed: 0.0460s/iter; left time: 609.6497s\n",
      "\titers: 400, epoch: 6 | loss: 0.3944299\n",
      "\tspeed: 0.0457s/iter; left time: 601.7594s\n",
      "\titers: 500, epoch: 6 | loss: 0.4294834\n",
      "\tspeed: 0.0456s/iter; left time: 595.6800s\n",
      "\titers: 600, epoch: 6 | loss: 0.3736836\n",
      "\tspeed: 0.0445s/iter; left time: 576.9358s\n",
      "\titers: 700, epoch: 6 | loss: 0.4121814\n",
      "\tspeed: 0.0451s/iter; left time: 579.7235s\n",
      "\titers: 800, epoch: 6 | loss: 0.3910367\n",
      "\tspeed: 0.0451s/iter; left time: 575.9189s\n",
      "\titers: 900, epoch: 6 | loss: 0.3571696\n",
      "\tspeed: 0.0460s/iter; left time: 582.5007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.59s\n",
      "Steps: 904 | Train Loss: 0.3932818 Vali Loss: 0.3790114 Test Loss: 0.4141468\n",
      "Validation loss decreased (0.392053 --> 0.379011).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3951776\n",
      "\tspeed: 0.1437s/iter; left time: 1804.0667s\n",
      "\titers: 200, epoch: 7 | loss: 0.3725768\n",
      "\tspeed: 0.0445s/iter; left time: 554.6265s\n",
      "\titers: 300, epoch: 7 | loss: 0.3844080\n",
      "\tspeed: 0.0446s/iter; left time: 550.6955s\n",
      "\titers: 400, epoch: 7 | loss: 0.3941038\n",
      "\tspeed: 0.0456s/iter; left time: 558.3652s\n",
      "\titers: 500, epoch: 7 | loss: 0.3681940\n",
      "\tspeed: 0.0444s/iter; left time: 539.8454s\n",
      "\titers: 600, epoch: 7 | loss: 0.4041126\n",
      "\tspeed: 0.0444s/iter; left time: 535.6753s\n",
      "\titers: 700, epoch: 7 | loss: 0.3801317\n",
      "\tspeed: 0.0449s/iter; left time: 536.5678s\n",
      "\titers: 800, epoch: 7 | loss: 0.3776351\n",
      "\tspeed: 0.0449s/iter; left time: 531.7883s\n",
      "\titers: 900, epoch: 7 | loss: 0.4145096\n",
      "\tspeed: 0.0442s/iter; left time: 519.6089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 904 | Train Loss: 0.3813105 Vali Loss: 0.3724387 Test Loss: 0.4001022\n",
      "Validation loss decreased (0.379011 --> 0.372439).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3910064\n",
      "\tspeed: 0.1477s/iter; left time: 1721.5006s\n",
      "\titers: 200, epoch: 8 | loss: 0.3791862\n",
      "\tspeed: 0.0478s/iter; left time: 552.1541s\n",
      "\titers: 300, epoch: 8 | loss: 0.3766276\n",
      "\tspeed: 0.0448s/iter; left time: 513.0545s\n",
      "\titers: 400, epoch: 8 | loss: 0.3718477\n",
      "\tspeed: 0.0450s/iter; left time: 511.2753s\n",
      "\titers: 500, epoch: 8 | loss: 0.3759646\n",
      "\tspeed: 0.0449s/iter; left time: 504.9948s\n",
      "\titers: 600, epoch: 8 | loss: 0.4014482\n",
      "\tspeed: 0.0452s/iter; left time: 504.1975s\n",
      "\titers: 700, epoch: 8 | loss: 0.3673986\n",
      "\tspeed: 0.0460s/iter; left time: 508.7699s\n",
      "\titers: 800, epoch: 8 | loss: 0.3508477\n",
      "\tspeed: 0.0446s/iter; left time: 488.6264s\n",
      "\titers: 900, epoch: 8 | loss: 0.3477184\n",
      "\tspeed: 0.0444s/iter; left time: 482.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.18s\n",
      "Steps: 904 | Train Loss: 0.3725541 Vali Loss: 0.3688162 Test Loss: 0.3968866\n",
      "Validation loss decreased (0.372439 --> 0.368816).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4084655\n",
      "\tspeed: 0.1450s/iter; left time: 1558.8812s\n",
      "\titers: 200, epoch: 9 | loss: 0.3396572\n",
      "\tspeed: 0.0450s/iter; left time: 479.0470s\n",
      "\titers: 300, epoch: 9 | loss: 0.3632009\n",
      "\tspeed: 0.0454s/iter; left time: 478.8990s\n",
      "\titers: 400, epoch: 9 | loss: 0.3707467\n",
      "\tspeed: 0.0442s/iter; left time: 462.1324s\n",
      "\titers: 500, epoch: 9 | loss: 0.3699534\n",
      "\tspeed: 0.0461s/iter; left time: 476.9382s\n",
      "\titers: 600, epoch: 9 | loss: 0.3642143\n",
      "\tspeed: 0.0456s/iter; left time: 467.6396s\n",
      "\titers: 700, epoch: 9 | loss: 0.3543306\n",
      "\tspeed: 0.0447s/iter; left time: 454.1657s\n",
      "\titers: 800, epoch: 9 | loss: 0.3931099\n",
      "\tspeed: 0.0450s/iter; left time: 452.5435s\n",
      "\titers: 900, epoch: 9 | loss: 0.3341699\n",
      "\tspeed: 0.0451s/iter; left time: 448.4926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 904 | Train Loss: 0.3665043 Vali Loss: 0.3653193 Test Loss: 0.3973235\n",
      "Validation loss decreased (0.368816 --> 0.365319).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3462125\n",
      "\tspeed: 0.1412s/iter; left time: 1390.5976s\n",
      "\titers: 200, epoch: 10 | loss: 0.3734470\n",
      "\tspeed: 0.0446s/iter; left time: 434.4307s\n",
      "\titers: 300, epoch: 10 | loss: 0.3763371\n",
      "\tspeed: 0.0468s/iter; left time: 451.4409s\n",
      "\titers: 400, epoch: 10 | loss: 0.3768697\n",
      "\tspeed: 0.0451s/iter; left time: 430.5238s\n",
      "\titers: 500, epoch: 10 | loss: 0.3325243\n",
      "\tspeed: 0.0465s/iter; left time: 439.0301s\n",
      "\titers: 600, epoch: 10 | loss: 0.3433881\n",
      "\tspeed: 0.0483s/iter; left time: 450.9552s\n",
      "\titers: 700, epoch: 10 | loss: 0.3345084\n",
      "\tspeed: 0.0444s/iter; left time: 410.1074s\n",
      "\titers: 800, epoch: 10 | loss: 0.3721381\n",
      "\tspeed: 0.0450s/iter; left time: 411.8922s\n",
      "\titers: 900, epoch: 10 | loss: 0.3894514\n",
      "\tspeed: 0.0454s/iter; left time: 410.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 904 | Train Loss: 0.3615328 Vali Loss: 0.3640761 Test Loss: 0.3922825\n",
      "Validation loss decreased (0.365319 --> 0.364076).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3524895\n",
      "\tspeed: 0.1498s/iter; left time: 1339.3403s\n",
      "\titers: 200, epoch: 11 | loss: 0.3441373\n",
      "\tspeed: 0.0455s/iter; left time: 402.0686s\n",
      "\titers: 300, epoch: 11 | loss: 0.3647605\n",
      "\tspeed: 0.0461s/iter; left time: 403.0430s\n",
      "\titers: 400, epoch: 11 | loss: 0.4306288\n",
      "\tspeed: 0.0451s/iter; left time: 389.5089s\n",
      "\titers: 500, epoch: 11 | loss: 0.3335594\n",
      "\tspeed: 0.0445s/iter; left time: 379.6557s\n",
      "\titers: 600, epoch: 11 | loss: 0.3716986\n",
      "\tspeed: 0.0455s/iter; left time: 384.3816s\n",
      "\titers: 700, epoch: 11 | loss: 0.3628899\n",
      "\tspeed: 0.0458s/iter; left time: 381.6957s\n",
      "\titers: 800, epoch: 11 | loss: 0.3520874\n",
      "\tspeed: 0.0447s/iter; left time: 368.4261s\n",
      "\titers: 900, epoch: 11 | loss: 0.3633041\n",
      "\tspeed: 0.0444s/iter; left time: 361.2862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.3573923 Vali Loss: 0.3607634 Test Loss: 0.3899616\n",
      "Validation loss decreased (0.364076 --> 0.360763).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3713934\n",
      "\tspeed: 0.1452s/iter; left time: 1167.1368s\n",
      "\titers: 200, epoch: 12 | loss: 0.3468812\n",
      "\tspeed: 0.0440s/iter; left time: 349.3941s\n",
      "\titers: 300, epoch: 12 | loss: 0.3609662\n",
      "\tspeed: 0.0445s/iter; left time: 348.6455s\n",
      "\titers: 400, epoch: 12 | loss: 0.3269851\n",
      "\tspeed: 0.0450s/iter; left time: 348.0690s\n",
      "\titers: 500, epoch: 12 | loss: 0.3825550\n",
      "\tspeed: 0.0468s/iter; left time: 357.4391s\n",
      "\titers: 600, epoch: 12 | loss: 0.3665098\n",
      "\tspeed: 0.0463s/iter; left time: 348.8885s\n",
      "\titers: 700, epoch: 12 | loss: 0.3404690\n",
      "\tspeed: 0.0452s/iter; left time: 336.5133s\n",
      "\titers: 800, epoch: 12 | loss: 0.3383901\n",
      "\tspeed: 0.0446s/iter; left time: 326.8767s\n",
      "\titers: 900, epoch: 12 | loss: 0.3241701\n",
      "\tspeed: 0.0445s/iter; left time: 322.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 904 | Train Loss: 0.3541785 Vali Loss: 0.3589448 Test Loss: 0.3926058\n",
      "Validation loss decreased (0.360763 --> 0.358945).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3301399\n",
      "\tspeed: 0.1390s/iter; left time: 991.6573s\n",
      "\titers: 200, epoch: 13 | loss: 0.3351562\n",
      "\tspeed: 0.0445s/iter; left time: 313.0728s\n",
      "\titers: 300, epoch: 13 | loss: 0.3371715\n",
      "\tspeed: 0.0450s/iter; left time: 312.1786s\n",
      "\titers: 400, epoch: 13 | loss: 0.3684586\n",
      "\tspeed: 0.0445s/iter; left time: 303.7801s\n",
      "\titers: 500, epoch: 13 | loss: 0.3329403\n",
      "\tspeed: 0.0442s/iter; left time: 297.5873s\n",
      "\titers: 600, epoch: 13 | loss: 0.3295333\n",
      "\tspeed: 0.0463s/iter; left time: 307.2525s\n",
      "\titers: 700, epoch: 13 | loss: 0.3590633\n",
      "\tspeed: 0.0456s/iter; left time: 297.9123s\n",
      "\titers: 800, epoch: 13 | loss: 0.3533353\n",
      "\tspeed: 0.0465s/iter; left time: 299.2682s\n",
      "\titers: 900, epoch: 13 | loss: 0.3595417\n",
      "\tspeed: 0.0465s/iter; left time: 294.4764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.3510866 Vali Loss: 0.3600708 Test Loss: 0.3893572\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.3544692\n",
      "\tspeed: 0.1490s/iter; left time: 928.0970s\n",
      "\titers: 200, epoch: 14 | loss: 0.3507481\n",
      "\tspeed: 0.0485s/iter; left time: 297.4926s\n",
      "\titers: 300, epoch: 14 | loss: 0.3223914\n",
      "\tspeed: 0.0486s/iter; left time: 293.0923s\n",
      "\titers: 400, epoch: 14 | loss: 0.3238970\n",
      "\tspeed: 0.0449s/iter; left time: 266.1357s\n",
      "\titers: 500, epoch: 14 | loss: 0.3538510\n",
      "\tspeed: 0.0455s/iter; left time: 265.3921s\n",
      "\titers: 600, epoch: 14 | loss: 0.3462601\n",
      "\tspeed: 0.0477s/iter; left time: 273.0398s\n",
      "\titers: 700, epoch: 14 | loss: 0.3357623\n",
      "\tspeed: 0.0460s/iter; left time: 259.0084s\n",
      "\titers: 800, epoch: 14 | loss: 0.3523507\n",
      "\tspeed: 0.0449s/iter; left time: 248.0518s\n",
      "\titers: 900, epoch: 14 | loss: 0.3342578\n",
      "\tspeed: 0.0448s/iter; left time: 243.4268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:42.91s\n",
      "Steps: 904 | Train Loss: 0.3490496 Vali Loss: 0.3601304 Test Loss: 0.3892490\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3492403\n",
      "\tspeed: 0.1433s/iter; left time: 762.8374s\n",
      "\titers: 200, epoch: 15 | loss: 0.3813530\n",
      "\tspeed: 0.0452s/iter; left time: 235.9334s\n",
      "\titers: 300, epoch: 15 | loss: 0.3274371\n",
      "\tspeed: 0.0456s/iter; left time: 233.7837s\n",
      "\titers: 400, epoch: 15 | loss: 0.3733148\n",
      "\tspeed: 0.0450s/iter; left time: 226.0710s\n",
      "\titers: 500, epoch: 15 | loss: 0.3466003\n",
      "\tspeed: 0.0492s/iter; left time: 242.5444s\n",
      "\titers: 600, epoch: 15 | loss: 0.3686531\n",
      "\tspeed: 0.0472s/iter; left time: 227.7790s\n",
      "\titers: 700, epoch: 15 | loss: 0.3742017\n",
      "\tspeed: 0.0443s/iter; left time: 209.4396s\n",
      "\titers: 800, epoch: 15 | loss: 0.3385742\n",
      "\tspeed: 0.0443s/iter; left time: 205.0422s\n",
      "\titers: 900, epoch: 15 | loss: 0.3302878\n",
      "\tspeed: 0.0459s/iter; left time: 207.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 904 | Train Loss: 0.3466244 Vali Loss: 0.3585026 Test Loss: 0.3883943\n",
      "Validation loss decreased (0.358945 --> 0.358503).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.3541804\n",
      "\tspeed: 0.1462s/iter; left time: 646.5414s\n",
      "\titers: 200, epoch: 16 | loss: 0.3336308\n",
      "\tspeed: 0.0454s/iter; left time: 195.9677s\n",
      "\titers: 300, epoch: 16 | loss: 0.3599910\n",
      "\tspeed: 0.0444s/iter; left time: 187.3885s\n",
      "\titers: 400, epoch: 16 | loss: 0.3616647\n",
      "\tspeed: 0.0447s/iter; left time: 184.0929s\n",
      "\titers: 500, epoch: 16 | loss: 0.3293418\n",
      "\tspeed: 0.0451s/iter; left time: 181.5061s\n",
      "\titers: 600, epoch: 16 | loss: 0.3238918\n",
      "\tspeed: 0.0448s/iter; left time: 175.7996s\n",
      "\titers: 700, epoch: 16 | loss: 0.3102309\n",
      "\tspeed: 0.0472s/iter; left time: 180.3020s\n",
      "\titers: 800, epoch: 16 | loss: 0.3554370\n",
      "\tspeed: 0.0464s/iter; left time: 172.5053s\n",
      "\titers: 900, epoch: 16 | loss: 0.3244724\n",
      "\tspeed: 0.0448s/iter; left time: 162.0423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:41.47s\n",
      "Steps: 904 | Train Loss: 0.3448076 Vali Loss: 0.3570277 Test Loss: 0.3895315\n",
      "Validation loss decreased (0.358503 --> 0.357028).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3332981\n",
      "\tspeed: 0.1413s/iter; left time: 496.9498s\n",
      "\titers: 200, epoch: 17 | loss: 0.3241345\n",
      "\tspeed: 0.0459s/iter; left time: 156.8263s\n",
      "\titers: 300, epoch: 17 | loss: 0.3558530\n",
      "\tspeed: 0.0451s/iter; left time: 149.5951s\n",
      "\titers: 400, epoch: 17 | loss: 0.3896123\n",
      "\tspeed: 0.0454s/iter; left time: 146.0344s\n",
      "\titers: 500, epoch: 17 | loss: 0.3341238\n",
      "\tspeed: 0.0444s/iter; left time: 138.3100s\n",
      "\titers: 600, epoch: 17 | loss: 0.3382587\n",
      "\tspeed: 0.0441s/iter; left time: 133.0448s\n",
      "\titers: 700, epoch: 17 | loss: 0.3473431\n",
      "\tspeed: 0.0441s/iter; left time: 128.5650s\n",
      "\titers: 800, epoch: 17 | loss: 0.3462836\n",
      "\tspeed: 0.0468s/iter; left time: 131.9216s\n",
      "\titers: 900, epoch: 17 | loss: 0.3442922\n",
      "\tspeed: 0.0445s/iter; left time: 120.7973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 904 | Train Loss: 0.3430955 Vali Loss: 0.3574605 Test Loss: 0.3906929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3389592\n",
      "\tspeed: 0.1379s/iter; left time: 360.4534s\n",
      "\titers: 200, epoch: 18 | loss: 0.3468793\n",
      "\tspeed: 0.0453s/iter; left time: 113.9142s\n",
      "\titers: 300, epoch: 18 | loss: 0.3450112\n",
      "\tspeed: 0.0460s/iter; left time: 111.0101s\n",
      "\titers: 400, epoch: 18 | loss: 0.3697629\n",
      "\tspeed: 0.0448s/iter; left time: 103.5631s\n",
      "\titers: 500, epoch: 18 | loss: 0.3357013\n",
      "\tspeed: 0.0440s/iter; left time: 97.4557s\n",
      "\titers: 600, epoch: 18 | loss: 0.3254082\n",
      "\tspeed: 0.0453s/iter; left time: 95.7417s\n",
      "\titers: 700, epoch: 18 | loss: 0.3237455\n",
      "\tspeed: 0.0446s/iter; left time: 89.7642s\n",
      "\titers: 800, epoch: 18 | loss: 0.3470093\n",
      "\tspeed: 0.0460s/iter; left time: 87.9982s\n",
      "\titers: 900, epoch: 18 | loss: 0.3574697\n",
      "\tspeed: 0.0452s/iter; left time: 81.8857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 904 | Train Loss: 0.3414109 Vali Loss: 0.3563099 Test Loss: 0.3915943\n",
      "Validation loss decreased (0.357028 --> 0.356310).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.3570470\n",
      "\tspeed: 0.1380s/iter; left time: 235.8988s\n",
      "\titers: 200, epoch: 19 | loss: 0.3343245\n",
      "\tspeed: 0.0478s/iter; left time: 76.9759s\n",
      "\titers: 300, epoch: 19 | loss: 0.3617332\n",
      "\tspeed: 0.0448s/iter; left time: 67.5919s\n",
      "\titers: 400, epoch: 19 | loss: 0.3604740\n",
      "\tspeed: 0.0456s/iter; left time: 64.2667s\n",
      "\titers: 500, epoch: 19 | loss: 0.3494175\n",
      "\tspeed: 0.0443s/iter; left time: 58.0438s\n",
      "\titers: 600, epoch: 19 | loss: 0.3175916\n",
      "\tspeed: 0.0445s/iter; left time: 53.8427s\n",
      "\titers: 700, epoch: 19 | loss: 0.3276371\n",
      "\tspeed: 0.0442s/iter; left time: 49.0168s\n",
      "\titers: 800, epoch: 19 | loss: 0.3380050\n",
      "\tspeed: 0.0446s/iter; left time: 45.0501s\n",
      "\titers: 900, epoch: 19 | loss: 0.3424624\n",
      "\tspeed: 0.0447s/iter; left time: 40.6380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:41.53s\n",
      "Steps: 904 | Train Loss: 0.3401909 Vali Loss: 0.3577078 Test Loss: 0.3879216\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.3226430\n",
      "\tspeed: 0.1388s/iter; left time: 111.7182s\n",
      "\titers: 200, epoch: 20 | loss: 0.3071016\n",
      "\tspeed: 0.0443s/iter; left time: 31.2583s\n",
      "\titers: 300, epoch: 20 | loss: 0.3653539\n",
      "\tspeed: 0.0444s/iter; left time: 26.8429s\n",
      "\titers: 400, epoch: 20 | loss: 0.3141488\n",
      "\tspeed: 0.0443s/iter; left time: 22.3545s\n",
      "\titers: 500, epoch: 20 | loss: 0.3368319\n",
      "\tspeed: 0.0460s/iter; left time: 18.6292s\n",
      "\titers: 600, epoch: 20 | loss: 0.3520629\n",
      "\tspeed: 0.0442s/iter; left time: 13.4841s\n",
      "\titers: 700, epoch: 20 | loss: 0.3348227\n",
      "\tspeed: 0.0445s/iter; left time: 9.1275s\n",
      "\titers: 800, epoch: 20 | loss: 0.3508748\n",
      "\tspeed: 0.0458s/iter; left time: 4.8084s\n",
      "\titers: 900, epoch: 20 | loss: 0.3358635\n",
      "\tspeed: 0.0446s/iter; left time: 0.2231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:41.42s\n",
      "Steps: 904 | Train Loss: 0.3392616 Vali Loss: 0.3561274 Test Loss: 0.3907578\n",
      "Validation loss decreased (0.356310 --> 0.356127).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.39727452397346497, rmse:0.6302971839904785, mae:0.390890896320343, rse:0.5771030187606812\n",
      "Original data scale mse:3134767.5, rmse:1770.5274658203125, mae:1156.8477783203125, rse:0.12459924817085266\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8819869\n",
      "\tspeed: 0.0998s/iter; left time: 1789.8897s\n",
      "\titers: 200, epoch: 1 | loss: 0.8182579\n",
      "\tspeed: 0.0519s/iter; left time: 925.7597s\n",
      "\titers: 300, epoch: 1 | loss: 0.8456621\n",
      "\tspeed: 0.0526s/iter; left time: 932.5661s\n",
      "\titers: 400, epoch: 1 | loss: 0.8321542\n",
      "\tspeed: 0.0535s/iter; left time: 944.0348s\n",
      "\titers: 500, epoch: 1 | loss: 0.8331147\n",
      "\tspeed: 0.0520s/iter; left time: 912.6133s\n",
      "\titers: 600, epoch: 1 | loss: 0.8240833\n",
      "\tspeed: 0.0521s/iter; left time: 909.4908s\n",
      "\titers: 700, epoch: 1 | loss: 0.7947810\n",
      "\tspeed: 0.0524s/iter; left time: 907.8606s\n",
      "\titers: 800, epoch: 1 | loss: 0.8356001\n",
      "\tspeed: 0.0529s/iter; left time: 912.6546s\n",
      "\titers: 900, epoch: 1 | loss: 0.7976663\n",
      "\tspeed: 0.0528s/iter; left time: 905.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.86s\n",
      "Steps: 902 | Train Loss: 0.8216986 Vali Loss: 0.7893083 Test Loss: 0.8531909\n",
      "Validation loss decreased (inf --> 0.789308).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.7752579\n",
      "\tspeed: 0.1625s/iter; left time: 2769.1777s\n",
      "\titers: 200, epoch: 2 | loss: 0.7019701\n",
      "\tspeed: 0.0526s/iter; left time: 890.5391s\n",
      "\titers: 300, epoch: 2 | loss: 0.6808155\n",
      "\tspeed: 0.0522s/iter; left time: 878.5083s\n",
      "\titers: 400, epoch: 2 | loss: 0.6635557\n",
      "\tspeed: 0.0522s/iter; left time: 874.2958s\n",
      "\titers: 500, epoch: 2 | loss: 0.6273445\n",
      "\tspeed: 0.0530s/iter; left time: 881.9993s\n",
      "\titers: 600, epoch: 2 | loss: 0.6516729\n",
      "\tspeed: 0.0520s/iter; left time: 859.5188s\n",
      "\titers: 700, epoch: 2 | loss: 0.5966997\n",
      "\tspeed: 0.0520s/iter; left time: 854.7361s\n",
      "\titers: 800, epoch: 2 | loss: 0.6028574\n",
      "\tspeed: 0.0521s/iter; left time: 850.8463s\n",
      "\titers: 900, epoch: 2 | loss: 0.6182635\n",
      "\tspeed: 0.0522s/iter; left time: 847.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.82s\n",
      "Steps: 902 | Train Loss: 0.6698633 Vali Loss: 0.6011027 Test Loss: 0.6472732\n",
      "Validation loss decreased (0.789308 --> 0.601103).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6073555\n",
      "\tspeed: 0.1704s/iter; left time: 2749.0361s\n",
      "\titers: 200, epoch: 3 | loss: 0.6042293\n",
      "\tspeed: 0.0563s/iter; left time: 903.6576s\n",
      "\titers: 300, epoch: 3 | loss: 0.6231385\n",
      "\tspeed: 0.0549s/iter; left time: 874.3384s\n",
      "\titers: 400, epoch: 3 | loss: 0.6105006\n",
      "\tspeed: 0.0534s/iter; left time: 845.9997s\n",
      "\titers: 500, epoch: 3 | loss: 0.6187766\n",
      "\tspeed: 0.0563s/iter; left time: 886.1151s\n",
      "\titers: 600, epoch: 3 | loss: 0.5755016\n",
      "\tspeed: 0.0533s/iter; left time: 833.3355s\n",
      "\titers: 700, epoch: 3 | loss: 0.5748839\n",
      "\tspeed: 0.0539s/iter; left time: 838.0127s\n",
      "\titers: 800, epoch: 3 | loss: 0.5587885\n",
      "\tspeed: 0.0541s/iter; left time: 835.0224s\n",
      "\titers: 900, epoch: 3 | loss: 0.5659210\n",
      "\tspeed: 0.0525s/iter; left time: 805.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.96s\n",
      "Steps: 902 | Train Loss: 0.5889315 Vali Loss: 0.5479580 Test Loss: 0.6011218\n",
      "Validation loss decreased (0.601103 --> 0.547958).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5592669\n",
      "\tspeed: 0.1646s/iter; left time: 2507.5142s\n",
      "\titers: 200, epoch: 4 | loss: 0.5327833\n",
      "\tspeed: 0.0538s/iter; left time: 813.6010s\n",
      "\titers: 300, epoch: 4 | loss: 0.5616955\n",
      "\tspeed: 0.0541s/iter; left time: 813.2505s\n",
      "\titers: 400, epoch: 4 | loss: 0.5308626\n",
      "\tspeed: 0.0523s/iter; left time: 780.4017s\n",
      "\titers: 500, epoch: 4 | loss: 0.5343955\n",
      "\tspeed: 0.0547s/iter; left time: 812.1225s\n",
      "\titers: 600, epoch: 4 | loss: 0.4946850\n",
      "\tspeed: 0.0532s/iter; left time: 783.2899s\n",
      "\titers: 700, epoch: 4 | loss: 0.5329369\n",
      "\tspeed: 0.0531s/iter; left time: 777.2546s\n",
      "\titers: 800, epoch: 4 | loss: 0.5323547\n",
      "\tspeed: 0.0529s/iter; left time: 769.1196s\n",
      "\titers: 900, epoch: 4 | loss: 0.4889320\n",
      "\tspeed: 0.0546s/iter; left time: 788.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.20s\n",
      "Steps: 902 | Train Loss: 0.5275742 Vali Loss: 0.4810653 Test Loss: 0.5268802\n",
      "Validation loss decreased (0.547958 --> 0.481065).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4825484\n",
      "\tspeed: 0.1666s/iter; left time: 2388.2195s\n",
      "\titers: 200, epoch: 5 | loss: 0.4774724\n",
      "\tspeed: 0.0530s/iter; left time: 754.1211s\n",
      "\titers: 300, epoch: 5 | loss: 0.5026664\n",
      "\tspeed: 0.0529s/iter; left time: 747.2324s\n",
      "\titers: 400, epoch: 5 | loss: 0.5026263\n",
      "\tspeed: 0.0531s/iter; left time: 744.6173s\n",
      "\titers: 500, epoch: 5 | loss: 0.5119578\n",
      "\tspeed: 0.0557s/iter; left time: 776.0253s\n",
      "\titers: 600, epoch: 5 | loss: 0.5129703\n",
      "\tspeed: 0.0537s/iter; left time: 742.1826s\n",
      "\titers: 700, epoch: 5 | loss: 0.5283630\n",
      "\tspeed: 0.0542s/iter; left time: 744.9722s\n",
      "\titers: 800, epoch: 5 | loss: 0.4677511\n",
      "\tspeed: 0.0530s/iter; left time: 723.1269s\n",
      "\titers: 900, epoch: 5 | loss: 0.4497795\n",
      "\tspeed: 0.0523s/iter; left time: 708.2379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.28s\n",
      "Steps: 902 | Train Loss: 0.4846612 Vali Loss: 0.4541727 Test Loss: 0.5002118\n",
      "Validation loss decreased (0.481065 --> 0.454173).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4614700\n",
      "\tspeed: 0.1642s/iter; left time: 2205.1889s\n",
      "\titers: 200, epoch: 6 | loss: 0.4652235\n",
      "\tspeed: 0.0533s/iter; left time: 710.7237s\n",
      "\titers: 300, epoch: 6 | loss: 0.4383273\n",
      "\tspeed: 0.0527s/iter; left time: 697.5968s\n",
      "\titers: 400, epoch: 6 | loss: 0.4602909\n",
      "\tspeed: 0.0529s/iter; left time: 694.5159s\n",
      "\titers: 500, epoch: 6 | loss: 0.4486452\n",
      "\tspeed: 0.0529s/iter; left time: 689.8434s\n",
      "\titers: 600, epoch: 6 | loss: 0.4697146\n",
      "\tspeed: 0.0538s/iter; left time: 695.8618s\n",
      "\titers: 700, epoch: 6 | loss: 0.4509828\n",
      "\tspeed: 0.0525s/iter; left time: 674.2327s\n",
      "\titers: 800, epoch: 6 | loss: 0.4465503\n",
      "\tspeed: 0.0530s/iter; left time: 675.1461s\n",
      "\titers: 900, epoch: 6 | loss: 0.4541139\n",
      "\tspeed: 0.0534s/iter; left time: 674.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.4624773 Vali Loss: 0.4400636 Test Loss: 0.4812725\n",
      "Validation loss decreased (0.454173 --> 0.440064).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4756216\n",
      "\tspeed: 0.1649s/iter; left time: 2066.4935s\n",
      "\titers: 200, epoch: 7 | loss: 0.4757348\n",
      "\tspeed: 0.0524s/iter; left time: 651.5464s\n",
      "\titers: 300, epoch: 7 | loss: 0.4303803\n",
      "\tspeed: 0.0526s/iter; left time: 648.5647s\n",
      "\titers: 400, epoch: 7 | loss: 0.4593174\n",
      "\tspeed: 0.0529s/iter; left time: 647.2420s\n",
      "\titers: 500, epoch: 7 | loss: 0.4445295\n",
      "\tspeed: 0.0522s/iter; left time: 632.6685s\n",
      "\titers: 600, epoch: 7 | loss: 0.4527037\n",
      "\tspeed: 0.0523s/iter; left time: 628.7692s\n",
      "\titers: 700, epoch: 7 | loss: 0.4377709\n",
      "\tspeed: 0.0527s/iter; left time: 628.5982s\n",
      "\titers: 800, epoch: 7 | loss: 0.4347252\n",
      "\tspeed: 0.0563s/iter; left time: 665.9705s\n",
      "\titers: 900, epoch: 7 | loss: 0.4168527\n",
      "\tspeed: 0.0564s/iter; left time: 661.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.18s\n",
      "Steps: 902 | Train Loss: 0.4457934 Vali Loss: 0.4281343 Test Loss: 0.4686051\n",
      "Validation loss decreased (0.440064 --> 0.428134).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4314710\n",
      "\tspeed: 0.1701s/iter; left time: 1978.0400s\n",
      "\titers: 200, epoch: 8 | loss: 0.4329057\n",
      "\tspeed: 0.0560s/iter; left time: 645.7052s\n",
      "\titers: 300, epoch: 8 | loss: 0.4571958\n",
      "\tspeed: 0.0524s/iter; left time: 599.2962s\n",
      "\titers: 400, epoch: 8 | loss: 0.4283210\n",
      "\tspeed: 0.0527s/iter; left time: 596.8074s\n",
      "\titers: 500, epoch: 8 | loss: 0.4478619\n",
      "\tspeed: 0.0525s/iter; left time: 589.7595s\n",
      "\titers: 600, epoch: 8 | loss: 0.3992873\n",
      "\tspeed: 0.0522s/iter; left time: 581.0745s\n",
      "\titers: 700, epoch: 8 | loss: 0.4073610\n",
      "\tspeed: 0.0529s/iter; left time: 583.6001s\n",
      "\titers: 800, epoch: 8 | loss: 0.4260164\n",
      "\tspeed: 0.0559s/iter; left time: 611.3289s\n",
      "\titers: 900, epoch: 8 | loss: 0.4292736\n",
      "\tspeed: 0.0529s/iter; left time: 572.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.37s\n",
      "Steps: 902 | Train Loss: 0.4322398 Vali Loss: 0.4127171 Test Loss: 0.4482037\n",
      "Validation loss decreased (0.428134 --> 0.412717).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4320936\n",
      "\tspeed: 0.1710s/iter; left time: 1834.3609s\n",
      "\titers: 200, epoch: 9 | loss: 0.4167304\n",
      "\tspeed: 0.0552s/iter; left time: 586.9343s\n",
      "\titers: 300, epoch: 9 | loss: 0.4110746\n",
      "\tspeed: 0.0528s/iter; left time: 555.7140s\n",
      "\titers: 400, epoch: 9 | loss: 0.4117878\n",
      "\tspeed: 0.0524s/iter; left time: 546.3903s\n",
      "\titers: 500, epoch: 9 | loss: 0.4746594\n",
      "\tspeed: 0.0524s/iter; left time: 540.6140s\n",
      "\titers: 600, epoch: 9 | loss: 0.4213751\n",
      "\tspeed: 0.0526s/iter; left time: 538.0974s\n",
      "\titers: 700, epoch: 9 | loss: 0.4473234\n",
      "\tspeed: 0.0521s/iter; left time: 527.4294s\n",
      "\titers: 800, epoch: 9 | loss: 0.4225575\n",
      "\tspeed: 0.0527s/iter; left time: 528.2225s\n",
      "\titers: 900, epoch: 9 | loss: 0.4082318\n",
      "\tspeed: 0.0522s/iter; left time: 518.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.81s\n",
      "Steps: 902 | Train Loss: 0.4204757 Vali Loss: 0.4070354 Test Loss: 0.4490732\n",
      "Validation loss decreased (0.412717 --> 0.407035).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.4320517\n",
      "\tspeed: 0.1670s/iter; left time: 1640.9225s\n",
      "\titers: 200, epoch: 10 | loss: 0.4096839\n",
      "\tspeed: 0.0534s/iter; left time: 518.8252s\n",
      "\titers: 300, epoch: 10 | loss: 0.3842196\n",
      "\tspeed: 0.0525s/iter; left time: 504.9619s\n",
      "\titers: 400, epoch: 10 | loss: 0.4123096\n",
      "\tspeed: 0.0524s/iter; left time: 498.9523s\n",
      "\titers: 500, epoch: 10 | loss: 0.4280197\n",
      "\tspeed: 0.0548s/iter; left time: 516.2105s\n",
      "\titers: 600, epoch: 10 | loss: 0.3742115\n",
      "\tspeed: 0.0565s/iter; left time: 526.9687s\n",
      "\titers: 700, epoch: 10 | loss: 0.3955335\n",
      "\tspeed: 0.0550s/iter; left time: 506.8886s\n",
      "\titers: 800, epoch: 10 | loss: 0.4171923\n",
      "\tspeed: 0.0526s/iter; left time: 479.8934s\n",
      "\titers: 900, epoch: 10 | loss: 0.4059484\n",
      "\tspeed: 0.0531s/iter; left time: 478.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:49.26s\n",
      "Steps: 902 | Train Loss: 0.4112087 Vali Loss: 0.3979410 Test Loss: 0.4378215\n",
      "Validation loss decreased (0.407035 --> 0.397941).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.4245059\n",
      "\tspeed: 0.1675s/iter; left time: 1493.9291s\n",
      "\titers: 200, epoch: 11 | loss: 0.3538513\n",
      "\tspeed: 0.0522s/iter; left time: 460.6642s\n",
      "\titers: 300, epoch: 11 | loss: 0.4307034\n",
      "\tspeed: 0.0521s/iter; left time: 454.7351s\n",
      "\titers: 400, epoch: 11 | loss: 0.4442674\n",
      "\tspeed: 0.0521s/iter; left time: 449.4372s\n",
      "\titers: 500, epoch: 11 | loss: 0.4092966\n",
      "\tspeed: 0.0523s/iter; left time: 445.8138s\n",
      "\titers: 600, epoch: 11 | loss: 0.4004249\n",
      "\tspeed: 0.0519s/iter; left time: 437.3246s\n",
      "\titers: 700, epoch: 11 | loss: 0.4484455\n",
      "\tspeed: 0.0521s/iter; left time: 433.4377s\n",
      "\titers: 800, epoch: 11 | loss: 0.3993065\n",
      "\tspeed: 0.0566s/iter; left time: 464.9652s\n",
      "\titers: 900, epoch: 11 | loss: 0.4246595\n",
      "\tspeed: 0.0563s/iter; left time: 457.3630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.95s\n",
      "Steps: 902 | Train Loss: 0.4041459 Vali Loss: 0.3918942 Test Loss: 0.4382986\n",
      "Validation loss decreased (0.397941 --> 0.391894).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.4034102\n",
      "\tspeed: 0.1676s/iter; left time: 1344.1809s\n",
      "\titers: 200, epoch: 12 | loss: 0.3823237\n",
      "\tspeed: 0.0525s/iter; left time: 415.6376s\n",
      "\titers: 300, epoch: 12 | loss: 0.3958455\n",
      "\tspeed: 0.0533s/iter; left time: 416.5381s\n",
      "\titers: 400, epoch: 12 | loss: 0.3835133\n",
      "\tspeed: 0.0522s/iter; left time: 402.7063s\n",
      "\titers: 500, epoch: 12 | loss: 0.3794090\n",
      "\tspeed: 0.0521s/iter; left time: 396.6390s\n",
      "\titers: 600, epoch: 12 | loss: 0.4060288\n",
      "\tspeed: 0.0520s/iter; left time: 390.8933s\n",
      "\titers: 700, epoch: 12 | loss: 0.3823387\n",
      "\tspeed: 0.0526s/iter; left time: 390.1140s\n",
      "\titers: 800, epoch: 12 | loss: 0.3816468\n",
      "\tspeed: 0.0525s/iter; left time: 384.3034s\n",
      "\titers: 900, epoch: 12 | loss: 0.3906040\n",
      "\tspeed: 0.0534s/iter; left time: 385.3297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.32s\n",
      "Steps: 902 | Train Loss: 0.3985903 Vali Loss: 0.3921908 Test Loss: 0.4293328\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.4034697\n",
      "\tspeed: 0.1592s/iter; left time: 1133.1405s\n",
      "\titers: 200, epoch: 13 | loss: 0.4147956\n",
      "\tspeed: 0.0546s/iter; left time: 382.9955s\n",
      "\titers: 300, epoch: 13 | loss: 0.3809929\n",
      "\tspeed: 0.0566s/iter; left time: 391.5113s\n",
      "\titers: 400, epoch: 13 | loss: 0.3605865\n",
      "\tspeed: 0.0565s/iter; left time: 385.1352s\n",
      "\titers: 500, epoch: 13 | loss: 0.3815692\n",
      "\tspeed: 0.0561s/iter; left time: 376.7576s\n",
      "\titers: 600, epoch: 13 | loss: 0.4047941\n",
      "\tspeed: 0.0528s/iter; left time: 349.6605s\n",
      "\titers: 700, epoch: 13 | loss: 0.3936124\n",
      "\tspeed: 0.0528s/iter; left time: 343.9695s\n",
      "\titers: 800, epoch: 13 | loss: 0.4178047\n",
      "\tspeed: 0.0532s/iter; left time: 341.6919s\n",
      "\titers: 900, epoch: 13 | loss: 0.3766045\n",
      "\tspeed: 0.0527s/iter; left time: 332.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:49.70s\n",
      "Steps: 902 | Train Loss: 0.3940377 Vali Loss: 0.3887614 Test Loss: 0.4294221\n",
      "Validation loss decreased (0.391894 --> 0.388761).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.4046707\n",
      "\tspeed: 0.1630s/iter; left time: 1013.1165s\n",
      "\titers: 200, epoch: 14 | loss: 0.3819060\n",
      "\tspeed: 0.0533s/iter; left time: 326.0194s\n",
      "\titers: 300, epoch: 14 | loss: 0.3829066\n",
      "\tspeed: 0.0532s/iter; left time: 319.9152s\n",
      "\titers: 400, epoch: 14 | loss: 0.4185883\n",
      "\tspeed: 0.0535s/iter; left time: 316.2697s\n",
      "\titers: 500, epoch: 14 | loss: 0.3912957\n",
      "\tspeed: 0.0529s/iter; left time: 307.8624s\n",
      "\titers: 600, epoch: 14 | loss: 0.3941938\n",
      "\tspeed: 0.0531s/iter; left time: 303.3787s\n",
      "\titers: 700, epoch: 14 | loss: 0.3772071\n",
      "\tspeed: 0.0537s/iter; left time: 301.3783s\n",
      "\titers: 800, epoch: 14 | loss: 0.3461259\n",
      "\tspeed: 0.0532s/iter; left time: 293.6381s\n",
      "\titers: 900, epoch: 14 | loss: 0.4046910\n",
      "\tspeed: 0.0531s/iter; left time: 287.4268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.78s\n",
      "Steps: 902 | Train Loss: 0.3901293 Vali Loss: 0.3893678 Test Loss: 0.4329423\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3939880\n",
      "\tspeed: 0.1577s/iter; left time: 837.7303s\n",
      "\titers: 200, epoch: 15 | loss: 0.3842575\n",
      "\tspeed: 0.0549s/iter; left time: 286.4255s\n",
      "\titers: 300, epoch: 15 | loss: 0.3670168\n",
      "\tspeed: 0.0560s/iter; left time: 286.2828s\n",
      "\titers: 400, epoch: 15 | loss: 0.3761633\n",
      "\tspeed: 0.0526s/iter; left time: 263.7077s\n",
      "\titers: 500, epoch: 15 | loss: 0.3706408\n",
      "\tspeed: 0.0523s/iter; left time: 257.1208s\n",
      "\titers: 600, epoch: 15 | loss: 0.4207102\n",
      "\tspeed: 0.0524s/iter; left time: 252.0140s\n",
      "\titers: 700, epoch: 15 | loss: 0.3923627\n",
      "\tspeed: 0.0523s/iter; left time: 246.4363s\n",
      "\titers: 800, epoch: 15 | loss: 0.3778534\n",
      "\tspeed: 0.0525s/iter; left time: 242.1788s\n",
      "\titers: 900, epoch: 15 | loss: 0.4083329\n",
      "\tspeed: 0.0524s/iter; left time: 236.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.3872539 Vali Loss: 0.3865728 Test Loss: 0.4337345\n",
      "Validation loss decreased (0.388761 --> 0.386573).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.3566824\n",
      "\tspeed: 0.1688s/iter; left time: 744.7383s\n",
      "\titers: 200, epoch: 16 | loss: 0.3909092\n",
      "\tspeed: 0.0558s/iter; left time: 240.6177s\n",
      "\titers: 300, epoch: 16 | loss: 0.3580456\n",
      "\tspeed: 0.0558s/iter; left time: 234.8558s\n",
      "\titers: 400, epoch: 16 | loss: 0.3910920\n",
      "\tspeed: 0.0557s/iter; left time: 228.8714s\n",
      "\titers: 500, epoch: 16 | loss: 0.3813345\n",
      "\tspeed: 0.0558s/iter; left time: 223.7423s\n",
      "\titers: 600, epoch: 16 | loss: 0.3786902\n",
      "\tspeed: 0.0559s/iter; left time: 218.6879s\n",
      "\titers: 700, epoch: 16 | loss: 0.3787574\n",
      "\tspeed: 0.0568s/iter; left time: 216.4633s\n",
      "\titers: 800, epoch: 16 | loss: 0.3762503\n",
      "\tspeed: 0.0525s/iter; left time: 194.6778s\n",
      "\titers: 900, epoch: 16 | loss: 0.3695222\n",
      "\tspeed: 0.0526s/iter; left time: 190.0360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:50.79s\n",
      "Steps: 902 | Train Loss: 0.3846973 Vali Loss: 0.3854063 Test Loss: 0.4311568\n",
      "Validation loss decreased (0.386573 --> 0.385406).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3856308\n",
      "\tspeed: 0.1627s/iter; left time: 570.8831s\n",
      "\titers: 200, epoch: 17 | loss: 0.4110024\n",
      "\tspeed: 0.0521s/iter; left time: 177.7547s\n",
      "\titers: 300, epoch: 17 | loss: 0.3772717\n",
      "\tspeed: 0.0523s/iter; left time: 173.0499s\n",
      "\titers: 400, epoch: 17 | loss: 0.3863395\n",
      "\tspeed: 0.0522s/iter; left time: 167.4300s\n",
      "\titers: 500, epoch: 17 | loss: 0.3778346\n",
      "\tspeed: 0.0523s/iter; left time: 162.4519s\n",
      "\titers: 600, epoch: 17 | loss: 0.3545914\n",
      "\tspeed: 0.0522s/iter; left time: 156.9532s\n",
      "\titers: 700, epoch: 17 | loss: 0.3708241\n",
      "\tspeed: 0.0524s/iter; left time: 152.3621s\n",
      "\titers: 800, epoch: 17 | loss: 0.3837389\n",
      "\tspeed: 0.0521s/iter; left time: 146.3621s\n",
      "\titers: 900, epoch: 17 | loss: 0.3732589\n",
      "\tspeed: 0.0523s/iter; left time: 141.6427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.04s\n",
      "Steps: 902 | Train Loss: 0.3822962 Vali Loss: 0.3816574 Test Loss: 0.4266738\n",
      "Validation loss decreased (0.385406 --> 0.381657).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3809699\n",
      "\tspeed: 0.1652s/iter; left time: 430.6360s\n",
      "\titers: 200, epoch: 18 | loss: 0.3776944\n",
      "\tspeed: 0.0522s/iter; left time: 130.8284s\n",
      "\titers: 300, epoch: 18 | loss: 0.3802282\n",
      "\tspeed: 0.0533s/iter; left time: 128.2408s\n",
      "\titers: 400, epoch: 18 | loss: 0.3721300\n",
      "\tspeed: 0.0518s/iter; left time: 119.3907s\n",
      "\titers: 500, epoch: 18 | loss: 0.3640247\n",
      "\tspeed: 0.0520s/iter; left time: 114.8721s\n",
      "\titers: 600, epoch: 18 | loss: 0.4151905\n",
      "\tspeed: 0.0522s/iter; left time: 109.9858s\n",
      "\titers: 700, epoch: 18 | loss: 0.3711193\n",
      "\tspeed: 0.0526s/iter; left time: 105.5242s\n",
      "\titers: 800, epoch: 18 | loss: 0.3726124\n",
      "\tspeed: 0.0526s/iter; left time: 100.3315s\n",
      "\titers: 900, epoch: 18 | loss: 0.3840319\n",
      "\tspeed: 0.0545s/iter; left time: 98.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.3803442 Vali Loss: 0.3824373 Test Loss: 0.4266402\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.3900446\n",
      "\tspeed: 0.1720s/iter; left time: 293.3145s\n",
      "\titers: 200, epoch: 19 | loss: 0.4003004\n",
      "\tspeed: 0.0567s/iter; left time: 91.0493s\n",
      "\titers: 300, epoch: 19 | loss: 0.3685568\n",
      "\tspeed: 0.0563s/iter; left time: 84.7586s\n",
      "\titers: 400, epoch: 19 | loss: 0.3998932\n",
      "\tspeed: 0.0545s/iter; left time: 76.5830s\n",
      "\titers: 500, epoch: 19 | loss: 0.4093933\n",
      "\tspeed: 0.0546s/iter; left time: 71.1909s\n",
      "\titers: 600, epoch: 19 | loss: 0.3882525\n",
      "\tspeed: 0.0522s/iter; left time: 62.8922s\n",
      "\titers: 700, epoch: 19 | loss: 0.3922662\n",
      "\tspeed: 0.0533s/iter; left time: 58.8503s\n",
      "\titers: 800, epoch: 19 | loss: 0.3811262\n",
      "\tspeed: 0.0525s/iter; left time: 52.7190s\n",
      "\titers: 900, epoch: 19 | loss: 0.3731397\n",
      "\tspeed: 0.0526s/iter; left time: 47.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:49.94s\n",
      "Steps: 902 | Train Loss: 0.3786299 Vali Loss: 0.3787292 Test Loss: 0.4282996\n",
      "Validation loss decreased (0.381657 --> 0.378729).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.3861902\n",
      "\tspeed: 0.1642s/iter; left time: 131.8383s\n",
      "\titers: 200, epoch: 20 | loss: 0.3881338\n",
      "\tspeed: 0.0534s/iter; left time: 37.5209s\n",
      "\titers: 300, epoch: 20 | loss: 0.4146951\n",
      "\tspeed: 0.0566s/iter; left time: 34.1130s\n",
      "\titers: 400, epoch: 20 | loss: 0.3646977\n",
      "\tspeed: 0.0535s/iter; left time: 26.8940s\n",
      "\titers: 500, epoch: 20 | loss: 0.3674475\n",
      "\tspeed: 0.0529s/iter; left time: 21.3059s\n",
      "\titers: 600, epoch: 20 | loss: 0.3861868\n",
      "\tspeed: 0.0526s/iter; left time: 15.9354s\n",
      "\titers: 700, epoch: 20 | loss: 0.3580301\n",
      "\tspeed: 0.0520s/iter; left time: 10.5604s\n",
      "\titers: 800, epoch: 20 | loss: 0.3856676\n",
      "\tspeed: 0.0526s/iter; left time: 5.4167s\n",
      "\titers: 900, epoch: 20 | loss: 0.3707045\n",
      "\tspeed: 0.0558s/iter; left time: 0.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:49.29s\n",
      "Steps: 902 | Train Loss: 0.3770021 Vali Loss: 0.3808348 Test Loss: 0.4262469\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.43003854155540466, rmse:0.6557732224464417, mae:0.42832452058792114, rse:0.6006079316139221\n",
      "Original data scale mse:4295732.0, rmse:2072.61474609375, mae:1351.13037109375, rse:0.1459953337907791\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8940808\n",
      "\tspeed: 0.0625s/iter; left time: 1122.1354s\n",
      "\titers: 200, epoch: 1 | loss: 0.8611429\n",
      "\tspeed: 0.0529s/iter; left time: 944.5715s\n",
      "\titers: 300, epoch: 1 | loss: 0.8389642\n",
      "\tspeed: 0.0524s/iter; left time: 928.9604s\n",
      "\titers: 400, epoch: 1 | loss: 0.8624576\n",
      "\tspeed: 0.0535s/iter; left time: 943.7409s\n",
      "\titers: 500, epoch: 1 | loss: 0.7952817\n",
      "\tspeed: 0.0525s/iter; left time: 920.1648s\n",
      "\titers: 600, epoch: 1 | loss: 0.7964891\n",
      "\tspeed: 0.0531s/iter; left time: 925.6255s\n",
      "\titers: 700, epoch: 1 | loss: 0.8273822\n",
      "\tspeed: 0.0523s/iter; left time: 906.3882s\n",
      "\titers: 800, epoch: 1 | loss: 0.7913608\n",
      "\tspeed: 0.0545s/iter; left time: 940.1862s\n",
      "\titers: 900, epoch: 1 | loss: 0.8045938\n",
      "\tspeed: 0.0527s/iter; left time: 902.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.85s\n",
      "Steps: 902 | Train Loss: 0.8375298 Vali Loss: 0.7939717 Test Loss: 0.8540891\n",
      "Validation loss decreased (inf --> 0.793972).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.7656100\n",
      "\tspeed: 0.1691s/iter; left time: 2882.0107s\n",
      "\titers: 200, epoch: 2 | loss: 0.7213438\n",
      "\tspeed: 0.0527s/iter; left time: 893.0696s\n",
      "\titers: 300, epoch: 2 | loss: 0.6721373\n",
      "\tspeed: 0.0528s/iter; left time: 888.5068s\n",
      "\titers: 400, epoch: 2 | loss: 0.6609972\n",
      "\tspeed: 0.0526s/iter; left time: 880.0332s\n",
      "\titers: 500, epoch: 2 | loss: 0.6570266\n",
      "\tspeed: 0.0538s/iter; left time: 894.4667s\n",
      "\titers: 600, epoch: 2 | loss: 0.6468780\n",
      "\tspeed: 0.0528s/iter; left time: 873.2824s\n",
      "\titers: 700, epoch: 2 | loss: 0.6311356\n",
      "\tspeed: 0.0526s/iter; left time: 865.4247s\n",
      "\titers: 800, epoch: 2 | loss: 0.6028475\n",
      "\tspeed: 0.0527s/iter; left time: 861.0998s\n",
      "\titers: 900, epoch: 2 | loss: 0.6050076\n",
      "\tspeed: 0.0539s/iter; left time: 875.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.6663757 Vali Loss: 0.5993119 Test Loss: 0.6468171\n",
      "Validation loss decreased (0.793972 --> 0.599312).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5952828\n",
      "\tspeed: 0.1677s/iter; left time: 2705.9237s\n",
      "\titers: 200, epoch: 3 | loss: 0.6371334\n",
      "\tspeed: 0.0526s/iter; left time: 843.5153s\n",
      "\titers: 300, epoch: 3 | loss: 0.6233168\n",
      "\tspeed: 0.0526s/iter; left time: 838.6974s\n",
      "\titers: 400, epoch: 3 | loss: 0.5955738\n",
      "\tspeed: 0.0523s/iter; left time: 828.5475s\n",
      "\titers: 500, epoch: 3 | loss: 0.5835165\n",
      "\tspeed: 0.0523s/iter; left time: 822.5542s\n",
      "\titers: 600, epoch: 3 | loss: 0.5889494\n",
      "\tspeed: 0.0530s/iter; left time: 829.0355s\n",
      "\titers: 700, epoch: 3 | loss: 0.5671400\n",
      "\tspeed: 0.0555s/iter; left time: 862.6866s\n",
      "\titers: 800, epoch: 3 | loss: 0.5702595\n",
      "\tspeed: 0.0523s/iter; left time: 807.2136s\n",
      "\titers: 900, epoch: 3 | loss: 0.5619345\n",
      "\tspeed: 0.0531s/iter; left time: 814.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.5881756 Vali Loss: 0.5517750 Test Loss: 0.5983230\n",
      "Validation loss decreased (0.599312 --> 0.551775).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5555900\n",
      "\tspeed: 0.1684s/iter; left time: 2565.3866s\n",
      "\titers: 200, epoch: 4 | loss: 0.5595531\n",
      "\tspeed: 0.0530s/iter; left time: 801.8002s\n",
      "\titers: 300, epoch: 4 | loss: 0.5371490\n",
      "\tspeed: 0.0526s/iter; left time: 790.6847s\n",
      "\titers: 400, epoch: 4 | loss: 0.5400713\n",
      "\tspeed: 0.0554s/iter; left time: 826.9227s\n",
      "\titers: 500, epoch: 4 | loss: 0.5087572\n",
      "\tspeed: 0.0520s/iter; left time: 770.8574s\n",
      "\titers: 600, epoch: 4 | loss: 0.5244243\n",
      "\tspeed: 0.0522s/iter; left time: 769.0825s\n",
      "\titers: 700, epoch: 4 | loss: 0.5468994\n",
      "\tspeed: 0.0520s/iter; left time: 760.4551s\n",
      "\titers: 800, epoch: 4 | loss: 0.5445222\n",
      "\tspeed: 0.0526s/iter; left time: 764.3157s\n",
      "\titers: 900, epoch: 4 | loss: 0.5314744\n",
      "\tspeed: 0.0524s/iter; left time: 756.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.5355580 Vali Loss: 0.4874037 Test Loss: 0.5328764\n",
      "Validation loss decreased (0.551775 --> 0.487404).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.5162680\n",
      "\tspeed: 0.1687s/iter; left time: 2417.4117s\n",
      "\titers: 200, epoch: 5 | loss: 0.4565894\n",
      "\tspeed: 0.0539s/iter; left time: 766.5254s\n",
      "\titers: 300, epoch: 5 | loss: 0.4756848\n",
      "\tspeed: 0.0537s/iter; left time: 759.5077s\n",
      "\titers: 400, epoch: 5 | loss: 0.5173793\n",
      "\tspeed: 0.0525s/iter; left time: 737.2622s\n",
      "\titers: 500, epoch: 5 | loss: 0.4723926\n",
      "\tspeed: 0.0545s/iter; left time: 758.6803s\n",
      "\titers: 600, epoch: 5 | loss: 0.4965570\n",
      "\tspeed: 0.0533s/iter; left time: 737.8868s\n",
      "\titers: 700, epoch: 5 | loss: 0.4874129\n",
      "\tspeed: 0.0528s/iter; left time: 724.5668s\n",
      "\titers: 800, epoch: 5 | loss: 0.4967771\n",
      "\tspeed: 0.0543s/iter; left time: 740.0658s\n",
      "\titers: 900, epoch: 5 | loss: 0.4584923\n",
      "\tspeed: 0.0566s/iter; left time: 765.3616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.57s\n",
      "Steps: 902 | Train Loss: 0.4893422 Vali Loss: 0.4584540 Test Loss: 0.4969733\n",
      "Validation loss decreased (0.487404 --> 0.458454).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4665026\n",
      "\tspeed: 0.1679s/iter; left time: 2255.4160s\n",
      "\titers: 200, epoch: 6 | loss: 0.4887747\n",
      "\tspeed: 0.0523s/iter; left time: 696.6278s\n",
      "\titers: 300, epoch: 6 | loss: 0.4598165\n",
      "\tspeed: 0.0524s/iter; left time: 693.8392s\n",
      "\titers: 400, epoch: 6 | loss: 0.4957727\n",
      "\tspeed: 0.0524s/iter; left time: 687.9174s\n",
      "\titers: 500, epoch: 6 | loss: 0.4227773\n",
      "\tspeed: 0.0523s/iter; left time: 681.0500s\n",
      "\titers: 600, epoch: 6 | loss: 0.4462117\n",
      "\tspeed: 0.0521s/iter; left time: 673.4038s\n",
      "\titers: 700, epoch: 6 | loss: 0.4600897\n",
      "\tspeed: 0.0525s/iter; left time: 674.1443s\n",
      "\titers: 800, epoch: 6 | loss: 0.4664954\n",
      "\tspeed: 0.0560s/iter; left time: 713.3769s\n",
      "\titers: 900, epoch: 6 | loss: 0.4553107\n",
      "\tspeed: 0.0567s/iter; left time: 716.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.02s\n",
      "Steps: 902 | Train Loss: 0.4651387 Vali Loss: 0.4386972 Test Loss: 0.4754119\n",
      "Validation loss decreased (0.458454 --> 0.438697).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4444264\n",
      "\tspeed: 0.1696s/iter; left time: 2124.7904s\n",
      "\titers: 200, epoch: 7 | loss: 0.4424238\n",
      "\tspeed: 0.0532s/iter; left time: 660.9548s\n",
      "\titers: 300, epoch: 7 | loss: 0.4298046\n",
      "\tspeed: 0.0573s/iter; left time: 706.2626s\n",
      "\titers: 400, epoch: 7 | loss: 0.4786917\n",
      "\tspeed: 0.0523s/iter; left time: 640.0007s\n",
      "\titers: 500, epoch: 7 | loss: 0.4443670\n",
      "\tspeed: 0.0528s/iter; left time: 640.4150s\n",
      "\titers: 600, epoch: 7 | loss: 0.4631684\n",
      "\tspeed: 0.0524s/iter; left time: 629.7851s\n",
      "\titers: 700, epoch: 7 | loss: 0.4732630\n",
      "\tspeed: 0.0525s/iter; left time: 626.4747s\n",
      "\titers: 800, epoch: 7 | loss: 0.4105953\n",
      "\tspeed: 0.0525s/iter; left time: 620.8671s\n",
      "\titers: 900, epoch: 7 | loss: 0.4491479\n",
      "\tspeed: 0.0528s/iter; left time: 618.7235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.90s\n",
      "Steps: 902 | Train Loss: 0.4491131 Vali Loss: 0.4281450 Test Loss: 0.4622429\n",
      "Validation loss decreased (0.438697 --> 0.428145).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4320168\n",
      "\tspeed: 0.1659s/iter; left time: 1928.6624s\n",
      "\titers: 200, epoch: 8 | loss: 0.4612559\n",
      "\tspeed: 0.0531s/iter; left time: 612.0125s\n",
      "\titers: 300, epoch: 8 | loss: 0.4390482\n",
      "\tspeed: 0.0528s/iter; left time: 603.6394s\n",
      "\titers: 400, epoch: 8 | loss: 0.4618885\n",
      "\tspeed: 0.0540s/iter; left time: 611.7182s\n",
      "\titers: 500, epoch: 8 | loss: 0.4099835\n",
      "\tspeed: 0.0530s/iter; left time: 595.0334s\n",
      "\titers: 600, epoch: 8 | loss: 0.4298792\n",
      "\tspeed: 0.0538s/iter; left time: 598.6822s\n",
      "\titers: 700, epoch: 8 | loss: 0.4558850\n",
      "\tspeed: 0.0565s/iter; left time: 623.1276s\n",
      "\titers: 800, epoch: 8 | loss: 0.4453193\n",
      "\tspeed: 0.0554s/iter; left time: 605.0899s\n",
      "\titers: 900, epoch: 8 | loss: 0.4494904\n",
      "\tspeed: 0.0529s/iter; left time: 572.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 902 | Train Loss: 0.4364244 Vali Loss: 0.4197651 Test Loss: 0.4506871\n",
      "Validation loss decreased (0.428145 --> 0.419765).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4587062\n",
      "\tspeed: 0.1697s/iter; left time: 1819.9307s\n",
      "\titers: 200, epoch: 9 | loss: 0.4284580\n",
      "\tspeed: 0.0527s/iter; left time: 559.9209s\n",
      "\titers: 300, epoch: 9 | loss: 0.4763379\n",
      "\tspeed: 0.0527s/iter; left time: 555.1701s\n",
      "\titers: 400, epoch: 9 | loss: 0.4237123\n",
      "\tspeed: 0.0529s/iter; left time: 551.6827s\n",
      "\titers: 500, epoch: 9 | loss: 0.4535974\n",
      "\tspeed: 0.0526s/iter; left time: 542.7349s\n",
      "\titers: 600, epoch: 9 | loss: 0.4284566\n",
      "\tspeed: 0.0527s/iter; left time: 538.9057s\n",
      "\titers: 700, epoch: 9 | loss: 0.4198983\n",
      "\tspeed: 0.0525s/iter; left time: 531.6104s\n",
      "\titers: 800, epoch: 9 | loss: 0.4408635\n",
      "\tspeed: 0.0526s/iter; left time: 527.7269s\n",
      "\titers: 900, epoch: 9 | loss: 0.4397855\n",
      "\tspeed: 0.0520s/iter; left time: 516.4764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.4257043 Vali Loss: 0.4132690 Test Loss: 0.4445792\n",
      "Validation loss decreased (0.419765 --> 0.413269).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.4180886\n",
      "\tspeed: 0.1629s/iter; left time: 1600.1148s\n",
      "\titers: 200, epoch: 10 | loss: 0.3660601\n",
      "\tspeed: 0.0528s/iter; left time: 513.5441s\n",
      "\titers: 300, epoch: 10 | loss: 0.4029427\n",
      "\tspeed: 0.0554s/iter; left time: 533.3416s\n",
      "\titers: 400, epoch: 10 | loss: 0.4181599\n",
      "\tspeed: 0.0567s/iter; left time: 540.2683s\n",
      "\titers: 500, epoch: 10 | loss: 0.3948919\n",
      "\tspeed: 0.0545s/iter; left time: 513.4587s\n",
      "\titers: 600, epoch: 10 | loss: 0.4390718\n",
      "\tspeed: 0.0536s/iter; left time: 499.6465s\n",
      "\titers: 700, epoch: 10 | loss: 0.4382435\n",
      "\tspeed: 0.0526s/iter; left time: 485.3896s\n",
      "\titers: 800, epoch: 10 | loss: 0.4240828\n",
      "\tspeed: 0.0525s/iter; left time: 478.8971s\n",
      "\titers: 900, epoch: 10 | loss: 0.4066506\n",
      "\tspeed: 0.0525s/iter; left time: 473.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:49.24s\n",
      "Steps: 902 | Train Loss: 0.4171446 Vali Loss: 0.4079167 Test Loss: 0.4421404\n",
      "Validation loss decreased (0.413269 --> 0.407917).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.4045157\n",
      "\tspeed: 0.1742s/iter; left time: 1553.9110s\n",
      "\titers: 200, epoch: 11 | loss: 0.4235138\n",
      "\tspeed: 0.0570s/iter; left time: 502.4121s\n",
      "\titers: 300, epoch: 11 | loss: 0.4258954\n",
      "\tspeed: 0.0565s/iter; left time: 492.5347s\n",
      "\titers: 400, epoch: 11 | loss: 0.4021030\n",
      "\tspeed: 0.0569s/iter; left time: 490.5976s\n",
      "\titers: 500, epoch: 11 | loss: 0.3918464\n",
      "\tspeed: 0.0524s/iter; left time: 446.7330s\n",
      "\titers: 600, epoch: 11 | loss: 0.4011517\n",
      "\tspeed: 0.0542s/iter; left time: 456.1456s\n",
      "\titers: 700, epoch: 11 | loss: 0.4097311\n",
      "\tspeed: 0.0530s/iter; left time: 441.1333s\n",
      "\titers: 800, epoch: 11 | loss: 0.3998973\n",
      "\tspeed: 0.0528s/iter; left time: 433.9444s\n",
      "\titers: 900, epoch: 11 | loss: 0.4209518\n",
      "\tspeed: 0.0530s/iter; left time: 430.7042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.40s\n",
      "Steps: 902 | Train Loss: 0.4099939 Vali Loss: 0.4001519 Test Loss: 0.4400200\n",
      "Validation loss decreased (0.407917 --> 0.400152).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.4035627\n",
      "\tspeed: 0.1651s/iter; left time: 1323.5998s\n",
      "\titers: 200, epoch: 12 | loss: 0.4065045\n",
      "\tspeed: 0.0527s/iter; left time: 417.2131s\n",
      "\titers: 300, epoch: 12 | loss: 0.4313858\n",
      "\tspeed: 0.0534s/iter; left time: 417.4852s\n",
      "\titers: 400, epoch: 12 | loss: 0.3770432\n",
      "\tspeed: 0.0530s/iter; left time: 408.7689s\n",
      "\titers: 500, epoch: 12 | loss: 0.4090132\n",
      "\tspeed: 0.0532s/iter; left time: 405.5297s\n",
      "\titers: 600, epoch: 12 | loss: 0.3721530\n",
      "\tspeed: 0.0532s/iter; left time: 399.8918s\n",
      "\titers: 700, epoch: 12 | loss: 0.3916483\n",
      "\tspeed: 0.0528s/iter; left time: 391.8256s\n",
      "\titers: 800, epoch: 12 | loss: 0.3991884\n",
      "\tspeed: 0.0528s/iter; left time: 386.1725s\n",
      "\titers: 900, epoch: 12 | loss: 0.4012117\n",
      "\tspeed: 0.0526s/iter; left time: 379.8545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.4047157 Vali Loss: 0.3954264 Test Loss: 0.4404162\n",
      "Validation loss decreased (0.400152 --> 0.395426).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3854378\n",
      "\tspeed: 0.1640s/iter; left time: 1166.9845s\n",
      "\titers: 200, epoch: 13 | loss: 0.3726030\n",
      "\tspeed: 0.0537s/iter; left time: 376.5123s\n",
      "\titers: 300, epoch: 13 | loss: 0.4034091\n",
      "\tspeed: 0.0532s/iter; left time: 367.6473s\n",
      "\titers: 400, epoch: 13 | loss: 0.3840955\n",
      "\tspeed: 0.0529s/iter; left time: 360.4722s\n",
      "\titers: 500, epoch: 13 | loss: 0.3845934\n",
      "\tspeed: 0.0527s/iter; left time: 354.1831s\n",
      "\titers: 600, epoch: 13 | loss: 0.4003067\n",
      "\tspeed: 0.0526s/iter; left time: 348.0280s\n",
      "\titers: 700, epoch: 13 | loss: 0.3887165\n",
      "\tspeed: 0.0526s/iter; left time: 342.9736s\n",
      "\titers: 800, epoch: 13 | loss: 0.4048885\n",
      "\tspeed: 0.0528s/iter; left time: 338.6641s\n",
      "\titers: 900, epoch: 13 | loss: 0.3701485\n",
      "\tspeed: 0.0529s/iter; left time: 334.3883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:48.49s\n",
      "Steps: 902 | Train Loss: 0.4004446 Vali Loss: 0.3951605 Test Loss: 0.4344887\n",
      "Validation loss decreased (0.395426 --> 0.395161).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.4029275\n",
      "\tspeed: 0.1696s/iter; left time: 1054.2942s\n",
      "\titers: 200, epoch: 14 | loss: 0.4064845\n",
      "\tspeed: 0.0564s/iter; left time: 345.0798s\n",
      "\titers: 300, epoch: 14 | loss: 0.3825898\n",
      "\tspeed: 0.0531s/iter; left time: 319.4793s\n",
      "\titers: 400, epoch: 14 | loss: 0.4010499\n",
      "\tspeed: 0.0528s/iter; left time: 312.1606s\n",
      "\titers: 500, epoch: 14 | loss: 0.4299234\n",
      "\tspeed: 0.0538s/iter; left time: 313.0263s\n",
      "\titers: 600, epoch: 14 | loss: 0.3910013\n",
      "\tspeed: 0.0565s/iter; left time: 323.1160s\n",
      "\titers: 700, epoch: 14 | loss: 0.3919680\n",
      "\tspeed: 0.0568s/iter; left time: 318.7697s\n",
      "\titers: 800, epoch: 14 | loss: 0.3802820\n",
      "\tspeed: 0.0565s/iter; left time: 311.5597s\n",
      "\titers: 900, epoch: 14 | loss: 0.3931938\n",
      "\tspeed: 0.0529s/iter; left time: 286.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:50.39s\n",
      "Steps: 902 | Train Loss: 0.3964745 Vali Loss: 0.3965368 Test Loss: 0.4289684\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3650388\n",
      "\tspeed: 0.1605s/iter; left time: 852.8777s\n",
      "\titers: 200, epoch: 15 | loss: 0.3996830\n",
      "\tspeed: 0.0525s/iter; left time: 273.8572s\n",
      "\titers: 300, epoch: 15 | loss: 0.4108607\n",
      "\tspeed: 0.0524s/iter; left time: 268.0942s\n",
      "\titers: 400, epoch: 15 | loss: 0.3792270\n",
      "\tspeed: 0.0525s/iter; left time: 263.2272s\n",
      "\titers: 500, epoch: 15 | loss: 0.4110880\n",
      "\tspeed: 0.0523s/iter; left time: 256.8368s\n",
      "\titers: 600, epoch: 15 | loss: 0.4003460\n",
      "\tspeed: 0.0524s/iter; left time: 252.3066s\n",
      "\titers: 700, epoch: 15 | loss: 0.3689666\n",
      "\tspeed: 0.0521s/iter; left time: 245.5149s\n",
      "\titers: 800, epoch: 15 | loss: 0.3952844\n",
      "\tspeed: 0.0520s/iter; left time: 239.9399s\n",
      "\titers: 900, epoch: 15 | loss: 0.3989704\n",
      "\tspeed: 0.0520s/iter; left time: 234.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:48.06s\n",
      "Steps: 902 | Train Loss: 0.3934260 Vali Loss: 0.3898616 Test Loss: 0.4373012\n",
      "Validation loss decreased (0.395161 --> 0.389862).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.3757619\n",
      "\tspeed: 0.1736s/iter; left time: 765.7379s\n",
      "\titers: 200, epoch: 16 | loss: 0.3824095\n",
      "\tspeed: 0.0525s/iter; left time: 226.1159s\n",
      "\titers: 300, epoch: 16 | loss: 0.3765213\n",
      "\tspeed: 0.0528s/iter; left time: 222.3087s\n",
      "\titers: 400, epoch: 16 | loss: 0.3609475\n",
      "\tspeed: 0.0524s/iter; left time: 215.4571s\n",
      "\titers: 500, epoch: 16 | loss: 0.4025492\n",
      "\tspeed: 0.0527s/iter; left time: 211.4396s\n",
      "\titers: 600, epoch: 16 | loss: 0.3870821\n",
      "\tspeed: 0.0528s/iter; left time: 206.3249s\n",
      "\titers: 700, epoch: 16 | loss: 0.3838887\n",
      "\tspeed: 0.0527s/iter; left time: 200.9406s\n",
      "\titers: 800, epoch: 16 | loss: 0.4021677\n",
      "\tspeed: 0.0527s/iter; left time: 195.5259s\n",
      "\titers: 900, epoch: 16 | loss: 0.3795058\n",
      "\tspeed: 0.0526s/iter; left time: 189.7962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.3906672 Vali Loss: 0.3935899 Test Loss: 0.4345525\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3952819\n",
      "\tspeed: 0.1634s/iter; left time: 573.3946s\n",
      "\titers: 200, epoch: 17 | loss: 0.3463528\n",
      "\tspeed: 0.0527s/iter; left time: 179.5774s\n",
      "\titers: 300, epoch: 17 | loss: 0.3944566\n",
      "\tspeed: 0.0537s/iter; left time: 177.5881s\n",
      "\titers: 400, epoch: 17 | loss: 0.4100914\n",
      "\tspeed: 0.0547s/iter; left time: 175.5933s\n",
      "\titers: 500, epoch: 17 | loss: 0.3832229\n",
      "\tspeed: 0.0533s/iter; left time: 165.5630s\n",
      "\titers: 600, epoch: 17 | loss: 0.4172918\n",
      "\tspeed: 0.0538s/iter; left time: 161.9562s\n",
      "\titers: 700, epoch: 17 | loss: 0.3933931\n",
      "\tspeed: 0.0528s/iter; left time: 153.4560s\n",
      "\titers: 800, epoch: 17 | loss: 0.3944566\n",
      "\tspeed: 0.0529s/iter; left time: 148.6938s\n",
      "\titers: 900, epoch: 17 | loss: 0.3799826\n",
      "\tspeed: 0.0533s/iter; left time: 144.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.87s\n",
      "Steps: 902 | Train Loss: 0.3884112 Vali Loss: 0.3877619 Test Loss: 0.4309665\n",
      "Validation loss decreased (0.389862 --> 0.387762).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3934892\n",
      "\tspeed: 0.1687s/iter; left time: 439.9261s\n",
      "\titers: 200, epoch: 18 | loss: 0.4065211\n",
      "\tspeed: 0.0525s/iter; left time: 131.6296s\n",
      "\titers: 300, epoch: 18 | loss: 0.3982643\n",
      "\tspeed: 0.0529s/iter; left time: 127.4398s\n",
      "\titers: 400, epoch: 18 | loss: 0.3746166\n",
      "\tspeed: 0.0524s/iter; left time: 120.9095s\n",
      "\titers: 500, epoch: 18 | loss: 0.3798529\n",
      "\tspeed: 0.0530s/iter; left time: 117.0684s\n",
      "\titers: 600, epoch: 18 | loss: 0.3680928\n",
      "\tspeed: 0.0527s/iter; left time: 111.1372s\n",
      "\titers: 700, epoch: 18 | loss: 0.4027520\n",
      "\tspeed: 0.0523s/iter; left time: 104.9111s\n",
      "\titers: 800, epoch: 18 | loss: 0.3902778\n",
      "\tspeed: 0.0522s/iter; left time: 99.6306s\n",
      "\titers: 900, epoch: 18 | loss: 0.3714223\n",
      "\tspeed: 0.0523s/iter; left time: 94.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.3863798 Vali Loss: 0.3889369 Test Loss: 0.4264081\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.3870558\n",
      "\tspeed: 0.1635s/iter; left time: 278.7486s\n",
      "\titers: 200, epoch: 19 | loss: 0.4019725\n",
      "\tspeed: 0.0526s/iter; left time: 84.4859s\n",
      "\titers: 300, epoch: 19 | loss: 0.3911411\n",
      "\tspeed: 0.0524s/iter; left time: 78.9241s\n",
      "\titers: 400, epoch: 19 | loss: 0.3889028\n",
      "\tspeed: 0.0529s/iter; left time: 74.3076s\n",
      "\titers: 500, epoch: 19 | loss: 0.3721893\n",
      "\tspeed: 0.0526s/iter; left time: 68.6047s\n",
      "\titers: 600, epoch: 19 | loss: 0.4024518\n",
      "\tspeed: 0.0526s/iter; left time: 63.4220s\n",
      "\titers: 700, epoch: 19 | loss: 0.3838448\n",
      "\tspeed: 0.0529s/iter; left time: 58.4350s\n",
      "\titers: 800, epoch: 19 | loss: 0.3864633\n",
      "\tspeed: 0.0525s/iter; left time: 52.7597s\n",
      "\titers: 900, epoch: 19 | loss: 0.3880137\n",
      "\tspeed: 0.0559s/iter; left time: 50.5453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:48.81s\n",
      "Steps: 902 | Train Loss: 0.3845800 Vali Loss: 0.3859915 Test Loss: 0.4319353\n",
      "Validation loss decreased (0.387762 --> 0.385991).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.3865471\n",
      "\tspeed: 0.1650s/iter; left time: 132.5039s\n",
      "\titers: 200, epoch: 20 | loss: 0.3809934\n",
      "\tspeed: 0.0523s/iter; left time: 36.7690s\n",
      "\titers: 300, epoch: 20 | loss: 0.4014682\n",
      "\tspeed: 0.0523s/iter; left time: 31.5410s\n",
      "\titers: 400, epoch: 20 | loss: 0.3942917\n",
      "\tspeed: 0.0525s/iter; left time: 26.4211s\n",
      "\titers: 500, epoch: 20 | loss: 0.3470175\n",
      "\tspeed: 0.0524s/iter; left time: 21.1006s\n",
      "\titers: 600, epoch: 20 | loss: 0.3638296\n",
      "\tspeed: 0.0546s/iter; left time: 16.5296s\n",
      "\titers: 700, epoch: 20 | loss: 0.4016121\n",
      "\tspeed: 0.0527s/iter; left time: 10.6907s\n",
      "\titers: 800, epoch: 20 | loss: 0.3654594\n",
      "\tspeed: 0.0525s/iter; left time: 5.4065s\n",
      "\titers: 900, epoch: 20 | loss: 0.3704196\n",
      "\tspeed: 0.0532s/iter; left time: 0.1597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.3830496 Vali Loss: 0.3859885 Test Loss: 0.4310412\n",
      "Validation loss decreased (0.385991 --> 0.385989).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4308476150035858, rmse:0.6563898324966431, mae:0.43107345700263977, rse:0.601172685623169\n",
      "Original data scale mse:4343271.0, rmse:2084.051513671875, mae:1365.04150390625, rse:0.1468009501695633\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.00001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.2935</td>\n",
       "      <td>0.4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.4659</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.4267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3869</td>\n",
       "      <td>0.6220</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>0.5696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.5622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4195</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.5932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.6645</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.4220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.6353</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.5816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3973</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.5771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.4283</td>\n",
       "      <td>0.6006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>0.6012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2203  0.4694  0.2935  0.4299\n",
       "              2         24        0.2171  0.4659  0.2862  0.4267\n",
       "              1         96        0.3869  0.6220  0.4299  0.5696\n",
       "              2         96        0.3770  0.6140  0.4187  0.5622\n",
       "              1         168       0.4195  0.6477  0.4588  0.5932\n",
       "              2         168       0.4416  0.6645  0.4715  0.6086\n",
       "MAE           1         24        0.2123  0.4607  0.2703  0.4220\n",
       "              2         24        0.2143  0.4629  0.2699  0.4240\n",
       "              1         96        0.4036  0.6353  0.3978  0.5816\n",
       "              2         96        0.3973  0.6303  0.3909  0.5771\n",
       "              1         168       0.4300  0.6558  0.4283  0.6006\n",
       "              2         168       0.4308  0.6564  0.4311  0.6012"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1680994.875</td>\n",
       "      <td>1296.5319</td>\n",
       "      <td>861.9956</td>\n",
       "      <td>0.0911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1580196.750</td>\n",
       "      <td>1257.0587</td>\n",
       "      <td>835.5945</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3797896.500</td>\n",
       "      <td>1948.8192</td>\n",
       "      <td>1355.7372</td>\n",
       "      <td>0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3531860.500</td>\n",
       "      <td>1879.3245</td>\n",
       "      <td>1300.5291</td>\n",
       "      <td>0.1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4956448.000</td>\n",
       "      <td>2226.3081</td>\n",
       "      <td>1516.3369</td>\n",
       "      <td>0.1568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>5682674.500</td>\n",
       "      <td>2383.8362</td>\n",
       "      <td>1595.9253</td>\n",
       "      <td>0.1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1440519.500</td>\n",
       "      <td>1200.2164</td>\n",
       "      <td>759.9636</td>\n",
       "      <td>0.0843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1422171.750</td>\n",
       "      <td>1192.5485</td>\n",
       "      <td>752.7681</td>\n",
       "      <td>0.0838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3235874.000</td>\n",
       "      <td>1798.8535</td>\n",
       "      <td>1184.2261</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3134767.500</td>\n",
       "      <td>1770.5275</td>\n",
       "      <td>1156.8478</td>\n",
       "      <td>0.1246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4295732.000</td>\n",
       "      <td>2072.6147</td>\n",
       "      <td>1351.1304</td>\n",
       "      <td>0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4343271.000</td>\n",
       "      <td>2084.0515</td>\n",
       "      <td>1365.0415</td>\n",
       "      <td>0.1468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1680994.875  1296.5319   861.9956  0.0911\n",
       "              2         24        1580196.750  1257.0587   835.5945  0.0883\n",
       "              1         96        3797896.500  1948.8192  1355.7372  0.1371\n",
       "              2         96        3531860.500  1879.3245  1300.5291  0.1323\n",
       "              1         168       4956448.000  2226.3081  1516.3369  0.1568\n",
       "              2         168       5682674.500  2383.8362  1595.9253  0.1679\n",
       "MAE           1         24        1440519.500  1200.2164   759.9636  0.0843\n",
       "              2         24        1422171.750  1192.5485   752.7681  0.0838\n",
       "              1         96        3235874.000  1798.8535  1184.2261  0.1266\n",
       "              2         96        3134767.500  1770.5275  1156.8478  0.1246\n",
       "              1         168       4295732.000  2072.6147  1351.1304  0.1460\n",
       "              2         168       4343271.000  2084.0515  1365.0415  0.1468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.4618</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.4676</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4004</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.3944</td>\n",
       "      <td>0.5794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3820</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4304</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.4297</td>\n",
       "      <td>0.6009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.6561</td>\n",
       "      <td>0.4652</td>\n",
       "      <td>0.6009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2133  0.4618  0.2701  0.4230\n",
       "         MSE            0.2187  0.4676  0.2899  0.4283\n",
       "96       MAE            0.4004  0.6328  0.3944  0.5794\n",
       "         MSE            0.3820  0.6180  0.4243  0.5659\n",
       "168      MAE            0.4304  0.6561  0.4297  0.6009\n",
       "         MSE            0.4305  0.6561  0.4652  0.6009"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.431346e+06</td>\n",
       "      <td>1196.3824</td>\n",
       "      <td>756.3658</td>\n",
       "      <td>0.0841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.630596e+06</td>\n",
       "      <td>1276.7953</td>\n",
       "      <td>848.7950</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.185321e+06</td>\n",
       "      <td>1784.6905</td>\n",
       "      <td>1170.5369</td>\n",
       "      <td>0.1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.664878e+06</td>\n",
       "      <td>1914.0718</td>\n",
       "      <td>1328.1331</td>\n",
       "      <td>0.1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.319502e+06</td>\n",
       "      <td>2078.3331</td>\n",
       "      <td>1358.0859</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>5.319561e+06</td>\n",
       "      <td>2305.0721</td>\n",
       "      <td>1556.1311</td>\n",
       "      <td>0.1624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.431346e+06  1196.3824   756.3658  0.0841\n",
       "         MSE            1.630596e+06  1276.7953   848.7950  0.0897\n",
       "96       MAE            3.185321e+06  1784.6905  1170.5369  0.1256\n",
       "         MSE            3.664878e+06  1914.0718  1328.1331  0.1347\n",
       "168      MAE            4.319502e+06  2078.3331  1358.0859  0.1464\n",
       "         MSE            5.319561e+06  2305.0721  1556.1311  0.1624"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7115721\n",
      "\tspeed: 0.1332s/iter; left time: 2366.1598s\n",
      "\titers: 200, epoch: 1 | loss: 0.5507042\n",
      "\tspeed: 0.1030s/iter; left time: 1819.1503s\n",
      "\titers: 300, epoch: 1 | loss: 0.4904538\n",
      "\tspeed: 0.1065s/iter; left time: 1869.7176s\n",
      "\titers: 400, epoch: 1 | loss: 0.4336677\n",
      "\tspeed: 0.0992s/iter; left time: 1731.5620s\n",
      "\titers: 500, epoch: 1 | loss: 0.5502787\n",
      "\tspeed: 0.1078s/iter; left time: 1870.7456s\n",
      "\titers: 600, epoch: 1 | loss: 0.4105817\n",
      "\tspeed: 0.1203s/iter; left time: 2075.9347s\n",
      "\titers: 700, epoch: 1 | loss: 0.3281822\n",
      "\tspeed: 0.1053s/iter; left time: 1806.8662s\n",
      "\titers: 800, epoch: 1 | loss: 0.3063668\n",
      "\tspeed: 0.0999s/iter; left time: 1705.0237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:34.15s\n",
      "Steps: 893 | Train Loss: 0.5158445 Vali Loss: 0.3272034 Test Loss: 0.3433180\n",
      "Validation loss decreased (inf --> 0.327203).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2450888\n",
      "\tspeed: 0.5671s/iter; left time: 9565.6777s\n",
      "\titers: 200, epoch: 2 | loss: 0.2045712\n",
      "\tspeed: 0.0935s/iter; left time: 1568.1779s\n",
      "\titers: 300, epoch: 2 | loss: 0.3276693\n",
      "\tspeed: 0.0969s/iter; left time: 1615.4203s\n",
      "\titers: 400, epoch: 2 | loss: 0.2449387\n",
      "\tspeed: 0.0966s/iter; left time: 1600.9805s\n",
      "\titers: 500, epoch: 2 | loss: 0.1909926\n",
      "\tspeed: 0.0945s/iter; left time: 1556.1233s\n",
      "\titers: 600, epoch: 2 | loss: 0.1344917\n",
      "\tspeed: 0.0976s/iter; left time: 1597.9358s\n",
      "\titers: 700, epoch: 2 | loss: 0.2044084\n",
      "\tspeed: 0.1134s/iter; left time: 1844.5024s\n",
      "\titers: 800, epoch: 2 | loss: 0.1776914\n",
      "\tspeed: 0.1002s/iter; left time: 1619.6428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:29.44s\n",
      "Steps: 893 | Train Loss: 0.2219412 Vali Loss: 0.1973972 Test Loss: 0.2222147\n",
      "Validation loss decreased (0.327203 --> 0.197397).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1550447\n",
      "\tspeed: 0.5941s/iter; left time: 9490.3217s\n",
      "\titers: 200, epoch: 3 | loss: 0.2049012\n",
      "\tspeed: 0.0961s/iter; left time: 1525.5932s\n",
      "\titers: 300, epoch: 3 | loss: 0.1628761\n",
      "\tspeed: 0.0901s/iter; left time: 1421.0603s\n",
      "\titers: 400, epoch: 3 | loss: 0.1779979\n",
      "\tspeed: 0.0870s/iter; left time: 1363.7594s\n",
      "\titers: 500, epoch: 3 | loss: 0.1302713\n",
      "\tspeed: 0.1054s/iter; left time: 1641.6990s\n",
      "\titers: 600, epoch: 3 | loss: 0.2445797\n",
      "\tspeed: 0.1036s/iter; left time: 1603.2013s\n",
      "\titers: 700, epoch: 3 | loss: 0.1402915\n",
      "\tspeed: 0.1031s/iter; left time: 1585.5351s\n",
      "\titers: 800, epoch: 3 | loss: 0.2342398\n",
      "\tspeed: 0.0944s/iter; left time: 1442.4302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.06s\n",
      "Steps: 893 | Train Loss: 0.1909966 Vali Loss: 0.1881811 Test Loss: 0.2058878\n",
      "Validation loss decreased (0.197397 --> 0.188181).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1791987\n",
      "\tspeed: 0.5418s/iter; left time: 8172.0568s\n",
      "\titers: 200, epoch: 4 | loss: 0.1499173\n",
      "\tspeed: 0.0909s/iter; left time: 1361.8146s\n",
      "\titers: 300, epoch: 4 | loss: 0.1817994\n",
      "\tspeed: 0.1002s/iter; left time: 1490.7790s\n",
      "\titers: 400, epoch: 4 | loss: 0.1488673\n",
      "\tspeed: 0.1028s/iter; left time: 1519.5324s\n",
      "\titers: 500, epoch: 4 | loss: 0.1863056\n",
      "\tspeed: 0.1012s/iter; left time: 1485.7725s\n",
      "\titers: 600, epoch: 4 | loss: 0.1504370\n",
      "\tspeed: 0.0915s/iter; left time: 1333.9583s\n",
      "\titers: 700, epoch: 4 | loss: 0.2184440\n",
      "\tspeed: 0.0982s/iter; left time: 1422.6632s\n",
      "\titers: 800, epoch: 4 | loss: 0.1995789\n",
      "\tspeed: 0.1018s/iter; left time: 1464.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.04s\n",
      "Steps: 893 | Train Loss: 0.1824290 Vali Loss: 0.1877502 Test Loss: 0.2050086\n",
      "Validation loss decreased (0.188181 --> 0.187750).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2297120\n",
      "\tspeed: 0.5485s/iter; left time: 7782.3528s\n",
      "\titers: 200, epoch: 5 | loss: 0.1467914\n",
      "\tspeed: 0.1011s/iter; left time: 1424.5043s\n",
      "\titers: 300, epoch: 5 | loss: 0.2450626\n",
      "\tspeed: 0.0977s/iter; left time: 1367.0163s\n",
      "\titers: 400, epoch: 5 | loss: 0.2573461\n",
      "\tspeed: 0.0944s/iter; left time: 1311.6007s\n",
      "\titers: 500, epoch: 5 | loss: 0.1579923\n",
      "\tspeed: 0.1007s/iter; left time: 1388.7002s\n",
      "\titers: 600, epoch: 5 | loss: 0.1456550\n",
      "\tspeed: 0.1078s/iter; left time: 1475.1426s\n",
      "\titers: 700, epoch: 5 | loss: 0.1548489\n",
      "\tspeed: 0.1004s/iter; left time: 1364.4359s\n",
      "\titers: 800, epoch: 5 | loss: 0.1215519\n",
      "\tspeed: 0.0852s/iter; left time: 1149.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.52s\n",
      "Steps: 893 | Train Loss: 0.1770157 Vali Loss: 0.1825214 Test Loss: 0.2023349\n",
      "Validation loss decreased (0.187750 --> 0.182521).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1890004\n",
      "\tspeed: 0.5721s/iter; left time: 7606.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.1832414\n",
      "\tspeed: 0.0765s/iter; left time: 1009.0697s\n",
      "\titers: 300, epoch: 6 | loss: 0.1470521\n",
      "\tspeed: 0.0528s/iter; left time: 691.3846s\n",
      "\titers: 400, epoch: 6 | loss: 0.1725373\n",
      "\tspeed: 0.0454s/iter; left time: 589.5688s\n",
      "\titers: 500, epoch: 6 | loss: 0.1658833\n",
      "\tspeed: 0.0379s/iter; left time: 489.1658s\n",
      "\titers: 600, epoch: 6 | loss: 0.2045155\n",
      "\tspeed: 0.0377s/iter; left time: 482.0544s\n",
      "\titers: 700, epoch: 6 | loss: 0.0993592\n",
      "\tspeed: 0.0368s/iter; left time: 467.6462s\n",
      "\titers: 800, epoch: 6 | loss: 0.1488251\n",
      "\tspeed: 0.0334s/iter; left time: 420.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 893 | Train Loss: 0.1727726 Vali Loss: 0.1814266 Test Loss: 0.2005763\n",
      "Validation loss decreased (0.182521 --> 0.181427).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1828355\n",
      "\tspeed: 0.1184s/iter; left time: 1468.7810s\n",
      "\titers: 200, epoch: 7 | loss: 0.1245444\n",
      "\tspeed: 0.0314s/iter; left time: 386.0802s\n",
      "\titers: 300, epoch: 7 | loss: 0.1342298\n",
      "\tspeed: 0.0313s/iter; left time: 382.4898s\n",
      "\titers: 400, epoch: 7 | loss: 0.1847023\n",
      "\tspeed: 0.0314s/iter; left time: 379.7794s\n",
      "\titers: 500, epoch: 7 | loss: 0.1565119\n",
      "\tspeed: 0.0314s/iter; left time: 376.4614s\n",
      "\titers: 600, epoch: 7 | loss: 0.1247160\n",
      "\tspeed: 0.0313s/iter; left time: 372.9117s\n",
      "\titers: 700, epoch: 7 | loss: 0.1267635\n",
      "\tspeed: 0.0313s/iter; left time: 369.8707s\n",
      "\titers: 800, epoch: 7 | loss: 0.1291117\n",
      "\tspeed: 0.0314s/iter; left time: 367.3004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.31s\n",
      "Steps: 893 | Train Loss: 0.1693574 Vali Loss: 0.1807181 Test Loss: 0.2035200\n",
      "Validation loss decreased (0.181427 --> 0.180718).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1983522\n",
      "\tspeed: 0.1174s/iter; left time: 1350.8071s\n",
      "\titers: 200, epoch: 8 | loss: 0.1680878\n",
      "\tspeed: 0.0313s/iter; left time: 357.4338s\n",
      "\titers: 300, epoch: 8 | loss: 0.1934931\n",
      "\tspeed: 0.0314s/iter; left time: 354.5876s\n",
      "\titers: 400, epoch: 8 | loss: 0.1547793\n",
      "\tspeed: 0.0314s/iter; left time: 352.5398s\n",
      "\titers: 500, epoch: 8 | loss: 0.1743437\n",
      "\tspeed: 0.0315s/iter; left time: 349.5190s\n",
      "\titers: 600, epoch: 8 | loss: 0.1659480\n",
      "\tspeed: 0.0314s/iter; left time: 345.7223s\n",
      "\titers: 700, epoch: 8 | loss: 0.1698437\n",
      "\tspeed: 0.0314s/iter; left time: 343.1033s\n",
      "\titers: 800, epoch: 8 | loss: 0.1259636\n",
      "\tspeed: 0.0315s/iter; left time: 340.2934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 893 | Train Loss: 0.1664935 Vali Loss: 0.1776384 Test Loss: 0.2019370\n",
      "Validation loss decreased (0.180718 --> 0.177638).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1974452\n",
      "\tspeed: 0.1166s/iter; left time: 1238.0742s\n",
      "\titers: 200, epoch: 9 | loss: 0.1930901\n",
      "\tspeed: 0.0316s/iter; left time: 332.0010s\n",
      "\titers: 300, epoch: 9 | loss: 0.1371461\n",
      "\tspeed: 0.0316s/iter; left time: 328.9353s\n",
      "\titers: 400, epoch: 9 | loss: 0.1667616\n",
      "\tspeed: 0.0316s/iter; left time: 325.8119s\n",
      "\titers: 500, epoch: 9 | loss: 0.1464733\n",
      "\tspeed: 0.0316s/iter; left time: 322.7700s\n",
      "\titers: 600, epoch: 9 | loss: 0.1184142\n",
      "\tspeed: 0.0316s/iter; left time: 319.4672s\n",
      "\titers: 700, epoch: 9 | loss: 0.1472315\n",
      "\tspeed: 0.0316s/iter; left time: 316.1258s\n",
      "\titers: 800, epoch: 9 | loss: 0.1284741\n",
      "\tspeed: 0.0316s/iter; left time: 313.2203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 893 | Train Loss: 0.1642179 Vali Loss: 0.1814527 Test Loss: 0.2042053\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1529788\n",
      "\tspeed: 0.1151s/iter; left time: 1119.1486s\n",
      "\titers: 200, epoch: 10 | loss: 0.1823331\n",
      "\tspeed: 0.0316s/iter; left time: 304.5160s\n",
      "\titers: 300, epoch: 10 | loss: 0.1132455\n",
      "\tspeed: 0.0316s/iter; left time: 301.0159s\n",
      "\titers: 400, epoch: 10 | loss: 0.1696854\n",
      "\tspeed: 0.0316s/iter; left time: 297.9060s\n",
      "\titers: 500, epoch: 10 | loss: 0.1151098\n",
      "\tspeed: 0.0316s/iter; left time: 294.9295s\n",
      "\titers: 600, epoch: 10 | loss: 0.1350601\n",
      "\tspeed: 0.0316s/iter; left time: 291.4103s\n",
      "\titers: 700, epoch: 10 | loss: 0.1453555\n",
      "\tspeed: 0.0316s/iter; left time: 288.1550s\n",
      "\titers: 800, epoch: 10 | loss: 0.1759953\n",
      "\tspeed: 0.0316s/iter; left time: 285.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:28.52s\n",
      "Steps: 893 | Train Loss: 0.1621108 Vali Loss: 0.1814588 Test Loss: 0.2033812\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1450501\n",
      "\tspeed: 0.1149s/iter; left time: 1014.7221s\n",
      "\titers: 200, epoch: 11 | loss: 0.1679197\n",
      "\tspeed: 0.0317s/iter; left time: 276.3787s\n",
      "\titers: 300, epoch: 11 | loss: 0.1391447\n",
      "\tspeed: 0.0316s/iter; left time: 273.1223s\n",
      "\titers: 400, epoch: 11 | loss: 0.1507022\n",
      "\tspeed: 0.0317s/iter; left time: 270.3148s\n",
      "\titers: 500, epoch: 11 | loss: 0.1312802\n",
      "\tspeed: 0.0317s/iter; left time: 267.2634s\n",
      "\titers: 600, epoch: 11 | loss: 0.1089376\n",
      "\tspeed: 0.0317s/iter; left time: 264.1895s\n",
      "\titers: 700, epoch: 11 | loss: 0.1551562\n",
      "\tspeed: 0.0318s/iter; left time: 261.5949s\n",
      "\titers: 800, epoch: 11 | loss: 0.1736612\n",
      "\tspeed: 0.0318s/iter; left time: 258.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 893 | Train Loss: 0.1595131 Vali Loss: 0.1816549 Test Loss: 0.2038076\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2019370049238205, rmse:0.4493740200996399, mae:0.27185386419296265, rse:0.4115535616874695\n",
      "Original data scale mse:1312173.25, rmse:1145.5013427734375, mae:756.471923828125, rse:0.08049707859754562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7219309\n",
      "\tspeed: 0.0335s/iter; left time: 594.9654s\n",
      "\titers: 200, epoch: 1 | loss: 0.6133953\n",
      "\tspeed: 0.0319s/iter; left time: 562.7808s\n",
      "\titers: 300, epoch: 1 | loss: 0.5185424\n",
      "\tspeed: 0.0319s/iter; left time: 559.9126s\n",
      "\titers: 400, epoch: 1 | loss: 0.4917779\n",
      "\tspeed: 0.0319s/iter; left time: 557.0582s\n",
      "\titers: 500, epoch: 1 | loss: 0.4100563\n",
      "\tspeed: 0.0318s/iter; left time: 552.7290s\n",
      "\titers: 600, epoch: 1 | loss: 0.3435362\n",
      "\tspeed: 0.0317s/iter; left time: 547.0829s\n",
      "\titers: 700, epoch: 1 | loss: 0.3281915\n",
      "\tspeed: 0.0317s/iter; left time: 543.6528s\n",
      "\titers: 800, epoch: 1 | loss: 0.4416419\n",
      "\tspeed: 0.0317s/iter; left time: 540.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:28.59s\n",
      "Steps: 893 | Train Loss: 0.5115161 Vali Loss: 0.3302354 Test Loss: 0.3427135\n",
      "Validation loss decreased (inf --> 0.330235).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2239200\n",
      "\tspeed: 0.1232s/iter; left time: 2078.4613s\n",
      "\titers: 200, epoch: 2 | loss: 0.2190194\n",
      "\tspeed: 0.0316s/iter; left time: 530.6088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1713692\n",
      "\tspeed: 0.0317s/iter; left time: 528.0282s\n",
      "\titers: 400, epoch: 2 | loss: 0.2273610\n",
      "\tspeed: 0.0317s/iter; left time: 524.6313s\n",
      "\titers: 500, epoch: 2 | loss: 0.2745308\n",
      "\tspeed: 0.0318s/iter; left time: 522.9816s\n",
      "\titers: 600, epoch: 2 | loss: 0.1923447\n",
      "\tspeed: 0.0320s/iter; left time: 523.2653s\n",
      "\titers: 700, epoch: 2 | loss: 0.1729581\n",
      "\tspeed: 0.0319s/iter; left time: 519.4922s\n",
      "\titers: 800, epoch: 2 | loss: 0.2283264\n",
      "\tspeed: 0.0523s/iter; left time: 845.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.76s\n",
      "Steps: 893 | Train Loss: 0.2211204 Vali Loss: 0.1950946 Test Loss: 0.2135102\n",
      "Validation loss decreased (0.330235 --> 0.195095).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2614579\n",
      "\tspeed: 0.1578s/iter; left time: 2520.7944s\n",
      "\titers: 200, epoch: 3 | loss: 0.2411612\n",
      "\tspeed: 0.0316s/iter; left time: 502.1447s\n",
      "\titers: 300, epoch: 3 | loss: 0.2170652\n",
      "\tspeed: 0.0320s/iter; left time: 504.8198s\n",
      "\titers: 400, epoch: 3 | loss: 0.2033328\n",
      "\tspeed: 0.0666s/iter; left time: 1043.2910s\n",
      "\titers: 500, epoch: 3 | loss: 0.1873829\n",
      "\tspeed: 0.0977s/iter; left time: 1520.9496s\n",
      "\titers: 600, epoch: 3 | loss: 0.2088000\n",
      "\tspeed: 0.0936s/iter; left time: 1447.7063s\n",
      "\titers: 700, epoch: 3 | loss: 0.2535047\n",
      "\tspeed: 0.1105s/iter; left time: 1699.1065s\n",
      "\titers: 800, epoch: 3 | loss: 0.1580636\n",
      "\tspeed: 0.1077s/iter; left time: 1645.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:06.99s\n",
      "Steps: 893 | Train Loss: 0.1901281 Vali Loss: 0.1918507 Test Loss: 0.2148287\n",
      "Validation loss decreased (0.195095 --> 0.191851).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1910846\n",
      "\tspeed: 0.5662s/iter; left time: 8539.9181s\n",
      "\titers: 200, epoch: 4 | loss: 0.1841216\n",
      "\tspeed: 0.0937s/iter; left time: 1403.5152s\n",
      "\titers: 300, epoch: 4 | loss: 0.1567620\n",
      "\tspeed: 0.0981s/iter; left time: 1459.9193s\n",
      "\titers: 400, epoch: 4 | loss: 0.1277536\n",
      "\tspeed: 0.1013s/iter; left time: 1497.2575s\n",
      "\titers: 500, epoch: 4 | loss: 0.2447009\n",
      "\tspeed: 0.0929s/iter; left time: 1364.3393s\n",
      "\titers: 600, epoch: 4 | loss: 0.1902483\n",
      "\tspeed: 0.1061s/iter; left time: 1546.8394s\n",
      "\titers: 700, epoch: 4 | loss: 0.1348345\n",
      "\tspeed: 0.0926s/iter; left time: 1341.0928s\n",
      "\titers: 800, epoch: 4 | loss: 0.1853374\n",
      "\tspeed: 0.0979s/iter; left time: 1407.6136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:27.92s\n",
      "Steps: 893 | Train Loss: 0.1818103 Vali Loss: 0.1882270 Test Loss: 0.2059754\n",
      "Validation loss decreased (0.191851 --> 0.188227).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1398451\n",
      "\tspeed: 0.5127s/iter; left time: 7275.3554s\n",
      "\titers: 200, epoch: 5 | loss: 0.1592869\n",
      "\tspeed: 0.0395s/iter; left time: 556.5832s\n",
      "\titers: 300, epoch: 5 | loss: 0.1833869\n",
      "\tspeed: 0.0350s/iter; left time: 490.0833s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195400\n",
      "\tspeed: 0.0329s/iter; left time: 457.0736s\n",
      "\titers: 500, epoch: 5 | loss: 0.1530256\n",
      "\tspeed: 0.0318s/iter; left time: 437.8236s\n",
      "\titers: 600, epoch: 5 | loss: 0.1513401\n",
      "\tspeed: 0.0317s/iter; left time: 434.1181s\n",
      "\titers: 700, epoch: 5 | loss: 0.1396977\n",
      "\tspeed: 0.0317s/iter; left time: 430.9008s\n",
      "\titers: 800, epoch: 5 | loss: 0.1531565\n",
      "\tspeed: 0.0317s/iter; left time: 427.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.56s\n",
      "Steps: 893 | Train Loss: 0.1766973 Vali Loss: 0.1827646 Test Loss: 0.2044723\n",
      "Validation loss decreased (0.188227 --> 0.182765).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1789286\n",
      "\tspeed: 0.1365s/iter; left time: 1814.9882s\n",
      "\titers: 200, epoch: 6 | loss: 0.1609799\n",
      "\tspeed: 0.0315s/iter; left time: 415.6287s\n",
      "\titers: 300, epoch: 6 | loss: 0.2101550\n",
      "\tspeed: 0.0314s/iter; left time: 411.4933s\n",
      "\titers: 400, epoch: 6 | loss: 0.2002501\n",
      "\tspeed: 0.0315s/iter; left time: 408.7342s\n",
      "\titers: 500, epoch: 6 | loss: 0.1507419\n",
      "\tspeed: 0.0314s/iter; left time: 404.7779s\n",
      "\titers: 600, epoch: 6 | loss: 0.1424685\n",
      "\tspeed: 0.0313s/iter; left time: 400.7029s\n",
      "\titers: 700, epoch: 6 | loss: 0.1468622\n",
      "\tspeed: 0.0313s/iter; left time: 397.4615s\n",
      "\titers: 800, epoch: 6 | loss: 0.1674400\n",
      "\tspeed: 0.0313s/iter; left time: 394.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:28.39s\n",
      "Steps: 893 | Train Loss: 0.1723761 Vali Loss: 0.1818055 Test Loss: 0.2037120\n",
      "Validation loss decreased (0.182765 --> 0.181806).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2041469\n",
      "\tspeed: 0.1165s/iter; left time: 1444.5530s\n",
      "\titers: 200, epoch: 7 | loss: 0.1680109\n",
      "\tspeed: 0.0315s/iter; left time: 387.6677s\n",
      "\titers: 300, epoch: 7 | loss: 0.1412251\n",
      "\tspeed: 0.0316s/iter; left time: 385.4527s\n",
      "\titers: 400, epoch: 7 | loss: 0.2074238\n",
      "\tspeed: 0.0315s/iter; left time: 381.3566s\n",
      "\titers: 500, epoch: 7 | loss: 0.2165565\n",
      "\tspeed: 0.0315s/iter; left time: 378.6711s\n",
      "\titers: 600, epoch: 7 | loss: 0.1447392\n",
      "\tspeed: 0.0316s/iter; left time: 375.7019s\n",
      "\titers: 700, epoch: 7 | loss: 0.1693653\n",
      "\tspeed: 0.0316s/iter; left time: 372.7369s\n",
      "\titers: 800, epoch: 7 | loss: 0.1250626\n",
      "\tspeed: 0.0316s/iter; left time: 369.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:28.42s\n",
      "Steps: 893 | Train Loss: 0.1686634 Vali Loss: 0.1813426 Test Loss: 0.2043023\n",
      "Validation loss decreased (0.181806 --> 0.181343).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1835176\n",
      "\tspeed: 0.1163s/iter; left time: 1339.1676s\n",
      "\titers: 200, epoch: 8 | loss: 0.1446326\n",
      "\tspeed: 0.0316s/iter; left time: 360.8062s\n",
      "\titers: 300, epoch: 8 | loss: 0.1494437\n",
      "\tspeed: 0.0316s/iter; left time: 357.9448s\n",
      "\titers: 400, epoch: 8 | loss: 0.1911340\n",
      "\tspeed: 0.0317s/iter; left time: 355.2012s\n",
      "\titers: 500, epoch: 8 | loss: 0.1761708\n",
      "\tspeed: 0.0317s/iter; left time: 352.0221s\n",
      "\titers: 600, epoch: 8 | loss: 0.1726518\n",
      "\tspeed: 0.0317s/iter; left time: 349.3513s\n",
      "\titers: 700, epoch: 8 | loss: 0.1172048\n",
      "\tspeed: 0.0317s/iter; left time: 346.1074s\n",
      "\titers: 800, epoch: 8 | loss: 0.1619110\n",
      "\tspeed: 0.0318s/iter; left time: 343.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 893 | Train Loss: 0.1658784 Vali Loss: 0.1814213 Test Loss: 0.2043181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1688373\n",
      "\tspeed: 0.1151s/iter; left time: 1221.5921s\n",
      "\titers: 200, epoch: 9 | loss: 0.1561201\n",
      "\tspeed: 0.0317s/iter; left time: 333.2294s\n",
      "\titers: 300, epoch: 9 | loss: 0.1608616\n",
      "\tspeed: 0.0317s/iter; left time: 330.1071s\n",
      "\titers: 400, epoch: 9 | loss: 0.1582914\n",
      "\tspeed: 0.0317s/iter; left time: 327.2983s\n",
      "\titers: 500, epoch: 9 | loss: 0.1720232\n",
      "\tspeed: 0.0316s/iter; left time: 323.2962s\n",
      "\titers: 600, epoch: 9 | loss: 0.1456776\n",
      "\tspeed: 0.0316s/iter; left time: 320.1144s\n",
      "\titers: 700, epoch: 9 | loss: 0.2187583\n",
      "\tspeed: 0.0317s/iter; left time: 317.1090s\n",
      "\titers: 800, epoch: 9 | loss: 0.1321400\n",
      "\tspeed: 0.0317s/iter; left time: 314.0198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.57s\n",
      "Steps: 893 | Train Loss: 0.1632227 Vali Loss: 0.1805984 Test Loss: 0.2044907\n",
      "Validation loss decreased (0.181343 --> 0.180598).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1470544\n",
      "\tspeed: 0.1176s/iter; left time: 1143.8867s\n",
      "\titers: 200, epoch: 10 | loss: 0.1544752\n",
      "\tspeed: 0.0316s/iter; left time: 304.4762s\n",
      "\titers: 300, epoch: 10 | loss: 0.1257343\n",
      "\tspeed: 0.0316s/iter; left time: 301.1529s\n",
      "\titers: 400, epoch: 10 | loss: 0.1215282\n",
      "\tspeed: 0.0316s/iter; left time: 298.2333s\n",
      "\titers: 500, epoch: 10 | loss: 0.2250792\n",
      "\tspeed: 0.0317s/iter; left time: 295.4228s\n",
      "\titers: 600, epoch: 10 | loss: 0.1515349\n",
      "\tspeed: 0.0342s/iter; left time: 315.1673s\n",
      "\titers: 700, epoch: 10 | loss: 0.1528929\n",
      "\tspeed: 0.0389s/iter; left time: 354.5093s\n",
      "\titers: 800, epoch: 10 | loss: 0.1416255\n",
      "\tspeed: 0.0940s/iter; left time: 848.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.71s\n",
      "Steps: 893 | Train Loss: 0.1608201 Vali Loss: 0.1832188 Test Loss: 0.2045684\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1754676\n",
      "\tspeed: 0.5554s/iter; left time: 4904.4530s\n",
      "\titers: 200, epoch: 11 | loss: 0.1908560\n",
      "\tspeed: 0.0975s/iter; left time: 851.0897s\n",
      "\titers: 300, epoch: 11 | loss: 0.1844759\n",
      "\tspeed: 0.1018s/iter; left time: 878.7133s\n",
      "\titers: 400, epoch: 11 | loss: 0.1556458\n",
      "\tspeed: 0.0995s/iter; left time: 848.6993s\n",
      "\titers: 500, epoch: 11 | loss: 0.1511192\n",
      "\tspeed: 0.0956s/iter; left time: 805.6359s\n",
      "\titers: 600, epoch: 11 | loss: 0.1412127\n",
      "\tspeed: 0.0965s/iter; left time: 803.5917s\n",
      "\titers: 700, epoch: 11 | loss: 0.2110361\n",
      "\tspeed: 0.0983s/iter; left time: 808.8101s\n",
      "\titers: 800, epoch: 11 | loss: 0.1739367\n",
      "\tspeed: 0.1075s/iter; left time: 873.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:29.59s\n",
      "Steps: 893 | Train Loss: 0.1587278 Vali Loss: 0.1799454 Test Loss: 0.2052253\n",
      "Validation loss decreased (0.180598 --> 0.179945).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1697270\n",
      "\tspeed: 0.5586s/iter; left time: 4434.4320s\n",
      "\titers: 200, epoch: 12 | loss: 0.1378167\n",
      "\tspeed: 0.0961s/iter; left time: 753.5128s\n",
      "\titers: 300, epoch: 12 | loss: 0.1450365\n",
      "\tspeed: 0.0978s/iter; left time: 756.7053s\n",
      "\titers: 400, epoch: 12 | loss: 0.1571363\n",
      "\tspeed: 0.0978s/iter; left time: 746.9879s\n",
      "\titers: 500, epoch: 12 | loss: 0.1391631\n",
      "\tspeed: 0.1004s/iter; left time: 756.6114s\n",
      "\titers: 600, epoch: 12 | loss: 0.1349751\n",
      "\tspeed: 0.0940s/iter; left time: 699.1179s\n",
      "\titers: 700, epoch: 12 | loss: 0.1458865\n",
      "\tspeed: 0.0971s/iter; left time: 712.7036s\n",
      "\titers: 800, epoch: 12 | loss: 0.1599350\n",
      "\tspeed: 0.0980s/iter; left time: 709.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:27.54s\n",
      "Steps: 893 | Train Loss: 0.1572258 Vali Loss: 0.1820960 Test Loss: 0.2085653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2127008\n",
      "\tspeed: 0.5660s/iter; left time: 3987.4831s\n",
      "\titers: 200, epoch: 13 | loss: 0.1334345\n",
      "\tspeed: 0.0898s/iter; left time: 623.8077s\n",
      "\titers: 300, epoch: 13 | loss: 0.1691724\n",
      "\tspeed: 0.0980s/iter; left time: 670.9854s\n",
      "\titers: 400, epoch: 13 | loss: 0.1516244\n",
      "\tspeed: 0.0982s/iter; left time: 662.2658s\n",
      "\titers: 500, epoch: 13 | loss: 0.1543733\n",
      "\tspeed: 0.0982s/iter; left time: 652.3264s\n",
      "\titers: 600, epoch: 13 | loss: 0.1174439\n",
      "\tspeed: 0.0940s/iter; left time: 615.5124s\n",
      "\titers: 700, epoch: 13 | loss: 0.1098477\n",
      "\tspeed: 0.0971s/iter; left time: 625.5307s\n",
      "\titers: 800, epoch: 13 | loss: 0.1474336\n",
      "\tspeed: 0.0926s/iter; left time: 587.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:25.86s\n",
      "Steps: 893 | Train Loss: 0.1556374 Vali Loss: 0.1811722 Test Loss: 0.2080009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1454503\n",
      "\tspeed: 0.5498s/iter; left time: 3382.3129s\n",
      "\titers: 200, epoch: 14 | loss: 0.1211724\n",
      "\tspeed: 0.0981s/iter; left time: 593.7162s\n",
      "\titers: 300, epoch: 14 | loss: 0.1491771\n",
      "\tspeed: 0.0949s/iter; left time: 565.1193s\n",
      "\titers: 400, epoch: 14 | loss: 0.1382432\n",
      "\tspeed: 0.0985s/iter; left time: 576.2474s\n",
      "\titers: 500, epoch: 14 | loss: 0.1228036\n",
      "\tspeed: 0.0974s/iter; left time: 560.0460s\n",
      "\titers: 600, epoch: 14 | loss: 0.1343849\n",
      "\tspeed: 0.1013s/iter; left time: 572.7764s\n",
      "\titers: 700, epoch: 14 | loss: 0.1528351\n",
      "\tspeed: 0.1017s/iter; left time: 564.4005s\n",
      "\titers: 800, epoch: 14 | loss: 0.1507266\n",
      "\tspeed: 0.0974s/iter; left time: 530.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:29.00s\n",
      "Steps: 893 | Train Loss: 0.1541659 Vali Loss: 0.1827271 Test Loss: 0.2086433\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.20522522926330566, rmse:0.453017920255661, mae:0.27248555421829224, rse:0.4148908257484436\n",
      "Original data scale mse:1321465.125, rmse:1149.5499267578125, mae:759.6286010742188, rse:0.08078158646821976\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8687953\n",
      "\tspeed: 0.1611s/iter; left time: 2854.8032s\n",
      "\titers: 200, epoch: 1 | loss: 0.6752395\n",
      "\tspeed: 0.0905s/iter; left time: 1595.2079s\n",
      "\titers: 300, epoch: 1 | loss: 0.6096700\n",
      "\tspeed: 0.0934s/iter; left time: 1635.5965s\n",
      "\titers: 400, epoch: 1 | loss: 0.4843620\n",
      "\tspeed: 0.1009s/iter; left time: 1758.0197s\n",
      "\titers: 500, epoch: 1 | loss: 0.4535579\n",
      "\tspeed: 0.1033s/iter; left time: 1789.6247s\n",
      "\titers: 600, epoch: 1 | loss: 0.4970736\n",
      "\tspeed: 0.1050s/iter; left time: 1809.0399s\n",
      "\titers: 700, epoch: 1 | loss: 0.4186538\n",
      "\tspeed: 0.1021s/iter; left time: 1748.4186s\n",
      "\titers: 800, epoch: 1 | loss: 0.4138215\n",
      "\tspeed: 0.0994s/iter; left time: 1692.6707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.19s\n",
      "Steps: 891 | Train Loss: 0.5873678 Vali Loss: 0.4241488 Test Loss: 0.4349606\n",
      "Validation loss decreased (inf --> 0.424149).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4331522\n",
      "\tspeed: 0.5491s/iter; left time: 9240.9248s\n",
      "\titers: 200, epoch: 2 | loss: 0.2740224\n",
      "\tspeed: 0.0945s/iter; left time: 1581.2175s\n",
      "\titers: 300, epoch: 2 | loss: 0.3394139\n",
      "\tspeed: 0.0915s/iter; left time: 1521.7764s\n",
      "\titers: 400, epoch: 2 | loss: 0.3355964\n",
      "\tspeed: 0.0977s/iter; left time: 1614.1721s\n",
      "\titers: 500, epoch: 2 | loss: 0.3067711\n",
      "\tspeed: 0.1123s/iter; left time: 1845.2726s\n",
      "\titers: 600, epoch: 2 | loss: 0.3417076\n",
      "\tspeed: 0.1035s/iter; left time: 1690.1519s\n",
      "\titers: 700, epoch: 2 | loss: 0.3917704\n",
      "\tspeed: 0.1038s/iter; left time: 1685.1828s\n",
      "\titers: 800, epoch: 2 | loss: 0.3547277\n",
      "\tspeed: 0.0890s/iter; left time: 1435.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.43s\n",
      "Steps: 891 | Train Loss: 0.3611521 Vali Loss: 0.3410858 Test Loss: 0.3542138\n",
      "Validation loss decreased (0.424149 --> 0.341086).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3436865\n",
      "\tspeed: 0.5412s/iter; left time: 8625.6105s\n",
      "\titers: 200, epoch: 3 | loss: 0.3284120\n",
      "\tspeed: 0.0950s/iter; left time: 1504.4020s\n",
      "\titers: 300, epoch: 3 | loss: 0.2872005\n",
      "\tspeed: 0.0921s/iter; left time: 1449.8257s\n",
      "\titers: 400, epoch: 3 | loss: 0.3130924\n",
      "\tspeed: 0.1017s/iter; left time: 1590.4062s\n",
      "\titers: 500, epoch: 3 | loss: 0.3699544\n",
      "\tspeed: 0.1045s/iter; left time: 1623.8056s\n",
      "\titers: 600, epoch: 3 | loss: 0.3171983\n",
      "\tspeed: 0.1005s/iter; left time: 1552.2290s\n",
      "\titers: 700, epoch: 3 | loss: 0.3574215\n",
      "\tspeed: 0.0974s/iter; left time: 1494.6212s\n",
      "\titers: 800, epoch: 3 | loss: 0.2528096\n",
      "\tspeed: 0.0907s/iter; left time: 1382.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:27.35s\n",
      "Steps: 891 | Train Loss: 0.3261789 Vali Loss: 0.3329804 Test Loss: 0.3541793\n",
      "Validation loss decreased (0.341086 --> 0.332980).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4034785\n",
      "\tspeed: 0.5414s/iter; left time: 8146.9354s\n",
      "\titers: 200, epoch: 4 | loss: 0.3417699\n",
      "\tspeed: 0.0874s/iter; left time: 1306.3896s\n",
      "\titers: 300, epoch: 4 | loss: 0.3784653\n",
      "\tspeed: 0.0906s/iter; left time: 1345.1966s\n",
      "\titers: 400, epoch: 4 | loss: 0.3640740\n",
      "\tspeed: 0.0886s/iter; left time: 1306.7006s\n",
      "\titers: 500, epoch: 4 | loss: 0.3861934\n",
      "\tspeed: 0.0942s/iter; left time: 1380.5371s\n",
      "\titers: 600, epoch: 4 | loss: 0.3308927\n",
      "\tspeed: 0.1011s/iter; left time: 1470.3167s\n",
      "\titers: 700, epoch: 4 | loss: 0.3022046\n",
      "\tspeed: 0.0933s/iter; left time: 1347.3320s\n",
      "\titers: 800, epoch: 4 | loss: 0.3465479\n",
      "\tspeed: 0.0899s/iter; left time: 1290.0503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:23.42s\n",
      "Steps: 891 | Train Loss: 0.3142648 Vali Loss: 0.3350371 Test Loss: 0.3627731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3167041\n",
      "\tspeed: 0.5437s/iter; left time: 7696.6345s\n",
      "\titers: 200, epoch: 5 | loss: 0.3534675\n",
      "\tspeed: 0.0863s/iter; left time: 1213.2786s\n",
      "\titers: 300, epoch: 5 | loss: 0.3455953\n",
      "\tspeed: 0.0942s/iter; left time: 1314.5495s\n",
      "\titers: 400, epoch: 5 | loss: 0.2774753\n",
      "\tspeed: 0.0896s/iter; left time: 1241.6512s\n",
      "\titers: 500, epoch: 5 | loss: 0.2820708\n",
      "\tspeed: 0.0954s/iter; left time: 1312.4147s\n",
      "\titers: 600, epoch: 5 | loss: 0.3190175\n",
      "\tspeed: 0.0828s/iter; left time: 1130.9946s\n",
      "\titers: 700, epoch: 5 | loss: 0.2429793\n",
      "\tspeed: 0.0944s/iter; left time: 1280.0686s\n",
      "\titers: 800, epoch: 5 | loss: 0.2792119\n",
      "\tspeed: 0.0950s/iter; left time: 1278.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:22.27s\n",
      "Steps: 891 | Train Loss: 0.3012146 Vali Loss: 0.3476683 Test Loss: 0.3655497\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3442821\n",
      "\tspeed: 0.5687s/iter; left time: 7544.3079s\n",
      "\titers: 200, epoch: 6 | loss: 0.2784532\n",
      "\tspeed: 0.0878s/iter; left time: 1156.5454s\n",
      "\titers: 300, epoch: 6 | loss: 0.2469601\n",
      "\tspeed: 0.0894s/iter; left time: 1168.3381s\n",
      "\titers: 400, epoch: 6 | loss: 0.3586939\n",
      "\tspeed: 0.1000s/iter; left time: 1296.7660s\n",
      "\titers: 500, epoch: 6 | loss: 0.2707564\n",
      "\tspeed: 0.0988s/iter; left time: 1271.2417s\n",
      "\titers: 600, epoch: 6 | loss: 0.2368994\n",
      "\tspeed: 0.0905s/iter; left time: 1155.6705s\n",
      "\titers: 700, epoch: 6 | loss: 0.2981693\n",
      "\tspeed: 0.0928s/iter; left time: 1175.7649s\n",
      "\titers: 800, epoch: 6 | loss: 0.3097724\n",
      "\tspeed: 0.1019s/iter; left time: 1280.2355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:25.73s\n",
      "Steps: 891 | Train Loss: 0.2898923 Vali Loss: 0.3634784 Test Loss: 0.3777666\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.35417935252189636, rmse:0.595129668712616, mae:0.3813801109790802, rse:0.5449035167694092\n",
      "Original data scale mse:2694919.0, rmse:1641.620849609375, mae:1102.18798828125, rse:0.11552756279706955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7851738\n",
      "\tspeed: 0.1044s/iter; left time: 1850.4533s\n",
      "\titers: 200, epoch: 1 | loss: 0.6105053\n",
      "\tspeed: 0.0945s/iter; left time: 1664.4910s\n",
      "\titers: 300, epoch: 1 | loss: 0.5314367\n",
      "\tspeed: 0.0871s/iter; left time: 1525.3353s\n",
      "\titers: 400, epoch: 1 | loss: 0.4953493\n",
      "\tspeed: 0.0869s/iter; left time: 1514.7240s\n",
      "\titers: 500, epoch: 1 | loss: 0.4712453\n",
      "\tspeed: 0.0954s/iter; left time: 1652.4903s\n",
      "\titers: 600, epoch: 1 | loss: 0.5267744\n",
      "\tspeed: 0.0969s/iter; left time: 1668.7608s\n",
      "\titers: 700, epoch: 1 | loss: 0.4998352\n",
      "\tspeed: 0.0999s/iter; left time: 1711.1996s\n",
      "\titers: 800, epoch: 1 | loss: 0.4044023\n",
      "\tspeed: 0.0932s/iter; left time: 1586.9545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:24.95s\n",
      "Steps: 891 | Train Loss: 0.5843011 Vali Loss: 0.4263145 Test Loss: 0.4385482\n",
      "Validation loss decreased (inf --> 0.426315).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4811377\n",
      "\tspeed: 0.5647s/iter; left time: 9503.8719s\n",
      "\titers: 200, epoch: 2 | loss: 0.3932590\n",
      "\tspeed: 0.1144s/iter; left time: 1914.2047s\n",
      "\titers: 300, epoch: 2 | loss: 0.3535902\n",
      "\tspeed: 0.1039s/iter; left time: 1728.1587s\n",
      "\titers: 400, epoch: 2 | loss: 0.2928059\n",
      "\tspeed: 0.0938s/iter; left time: 1551.2718s\n",
      "\titers: 500, epoch: 2 | loss: 0.3092028\n",
      "\tspeed: 0.0934s/iter; left time: 1535.1094s\n",
      "\titers: 600, epoch: 2 | loss: 0.3792779\n",
      "\tspeed: 0.0895s/iter; left time: 1460.8858s\n",
      "\titers: 700, epoch: 2 | loss: 0.3401310\n",
      "\tspeed: 0.0864s/iter; left time: 1402.6454s\n",
      "\titers: 800, epoch: 2 | loss: 0.3505719\n",
      "\tspeed: 0.0922s/iter; left time: 1486.6631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:26.90s\n",
      "Steps: 891 | Train Loss: 0.3610939 Vali Loss: 0.3339284 Test Loss: 0.3566892\n",
      "Validation loss decreased (0.426315 --> 0.333928).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3481597\n",
      "\tspeed: 0.5516s/iter; left time: 8791.8691s\n",
      "\titers: 200, epoch: 3 | loss: 0.2898208\n",
      "\tspeed: 0.0964s/iter; left time: 1527.5692s\n",
      "\titers: 300, epoch: 3 | loss: 0.3266286\n",
      "\tspeed: 0.0949s/iter; left time: 1493.3577s\n",
      "\titers: 400, epoch: 3 | loss: 0.3000391\n",
      "\tspeed: 0.0933s/iter; left time: 1459.8960s\n",
      "\titers: 500, epoch: 3 | loss: 0.2742831\n",
      "\tspeed: 0.0806s/iter; left time: 1253.0320s\n",
      "\titers: 600, epoch: 3 | loss: 0.3130276\n",
      "\tspeed: 0.0941s/iter; left time: 1453.4234s\n",
      "\titers: 700, epoch: 3 | loss: 0.3235125\n",
      "\tspeed: 0.0886s/iter; left time: 1359.3762s\n",
      "\titers: 800, epoch: 3 | loss: 0.2952645\n",
      "\tspeed: 0.0945s/iter; left time: 1439.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:23.59s\n",
      "Steps: 891 | Train Loss: 0.3276658 Vali Loss: 0.3379722 Test Loss: 0.3532803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3226508\n",
      "\tspeed: 0.5465s/iter; left time: 8223.1052s\n",
      "\titers: 200, epoch: 4 | loss: 0.3677955\n",
      "\tspeed: 0.0992s/iter; left time: 1482.9211s\n",
      "\titers: 300, epoch: 4 | loss: 0.3277742\n",
      "\tspeed: 0.0895s/iter; left time: 1329.1981s\n",
      "\titers: 400, epoch: 4 | loss: 0.2929807\n",
      "\tspeed: 0.0901s/iter; left time: 1329.0583s\n",
      "\titers: 500, epoch: 4 | loss: 0.3178971\n",
      "\tspeed: 0.0851s/iter; left time: 1246.2963s\n",
      "\titers: 600, epoch: 4 | loss: 0.3013581\n",
      "\tspeed: 0.0900s/iter; left time: 1309.2372s\n",
      "\titers: 700, epoch: 4 | loss: 0.3198916\n",
      "\tspeed: 0.1055s/iter; left time: 1524.9440s\n",
      "\titers: 800, epoch: 4 | loss: 0.3611475\n",
      "\tspeed: 0.1015s/iter; left time: 1456.6281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:25.78s\n",
      "Steps: 891 | Train Loss: 0.3161601 Vali Loss: 0.3317240 Test Loss: 0.3525242\n",
      "Validation loss decreased (0.333928 --> 0.331724).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3422648\n",
      "\tspeed: 0.5294s/iter; left time: 7495.1599s\n",
      "\titers: 200, epoch: 5 | loss: 0.2471191\n",
      "\tspeed: 0.0984s/iter; left time: 1383.6177s\n",
      "\titers: 300, epoch: 5 | loss: 0.2370705\n",
      "\tspeed: 0.0889s/iter; left time: 1241.2578s\n",
      "\titers: 400, epoch: 5 | loss: 0.3224496\n",
      "\tspeed: 0.0928s/iter; left time: 1285.6429s\n",
      "\titers: 500, epoch: 5 | loss: 0.2995226\n",
      "\tspeed: 0.0837s/iter; left time: 1151.2157s\n",
      "\titers: 600, epoch: 5 | loss: 0.2766058\n",
      "\tspeed: 0.0916s/iter; left time: 1251.4859s\n",
      "\titers: 700, epoch: 5 | loss: 0.3354356\n",
      "\tspeed: 0.0897s/iter; left time: 1215.8063s\n",
      "\titers: 800, epoch: 5 | loss: 0.3222758\n",
      "\tspeed: 0.0887s/iter; left time: 1193.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:21.02s\n",
      "Steps: 891 | Train Loss: 0.3039154 Vali Loss: 0.3418694 Test Loss: 0.3641959\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2671846\n",
      "\tspeed: 0.5138s/iter; left time: 6816.5912s\n",
      "\titers: 200, epoch: 6 | loss: 0.2691176\n",
      "\tspeed: 0.0958s/iter; left time: 1261.6135s\n",
      "\titers: 300, epoch: 6 | loss: 0.2525728\n",
      "\tspeed: 0.0899s/iter; left time: 1175.1114s\n",
      "\titers: 400, epoch: 6 | loss: 0.2659838\n",
      "\tspeed: 0.0934s/iter; left time: 1211.5925s\n",
      "\titers: 500, epoch: 6 | loss: 0.2840540\n",
      "\tspeed: 0.0954s/iter; left time: 1227.4367s\n",
      "\titers: 600, epoch: 6 | loss: 0.3546274\n",
      "\tspeed: 0.0892s/iter; left time: 1138.2101s\n",
      "\titers: 700, epoch: 6 | loss: 0.2477082\n",
      "\tspeed: 0.0939s/iter; left time: 1189.5050s\n",
      "\titers: 800, epoch: 6 | loss: 0.2783850\n",
      "\tspeed: 0.0921s/iter; left time: 1157.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:24.75s\n",
      "Steps: 891 | Train Loss: 0.2932275 Vali Loss: 0.3636852 Test Loss: 0.3717092\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2467491\n",
      "\tspeed: 0.5699s/iter; left time: 7052.3099s\n",
      "\titers: 200, epoch: 7 | loss: 0.3023964\n",
      "\tspeed: 0.0855s/iter; left time: 1049.1340s\n",
      "\titers: 300, epoch: 7 | loss: 0.3874838\n",
      "\tspeed: 0.0886s/iter; left time: 1079.1819s\n",
      "\titers: 400, epoch: 7 | loss: 0.3654455\n",
      "\tspeed: 0.0961s/iter; left time: 1160.2366s\n",
      "\titers: 500, epoch: 7 | loss: 0.3107609\n",
      "\tspeed: 0.0870s/iter; left time: 1041.5506s\n",
      "\titers: 600, epoch: 7 | loss: 0.3386610\n",
      "\tspeed: 0.0957s/iter; left time: 1136.8789s\n",
      "\titers: 700, epoch: 7 | loss: 0.2955678\n",
      "\tspeed: 0.1001s/iter; left time: 1178.2172s\n",
      "\titers: 800, epoch: 7 | loss: 0.2618113\n",
      "\tspeed: 0.0980s/iter; left time: 1144.3633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:25.34s\n",
      "Steps: 891 | Train Loss: 0.2838475 Vali Loss: 0.3612177 Test Loss: 0.3787090\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.352524071931839, rmse:0.5937373638153076, mae:0.37898802757263184, rse:0.5436287522315979\n",
      "Original data scale mse:2625019.0, rmse:1620.1910400390625, mae:1093.866455078125, rse:0.11401946097612381\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8537032\n",
      "\tspeed: 0.1450s/iter; left time: 2562.9555s\n",
      "\titers: 200, epoch: 1 | loss: 0.5695519\n",
      "\tspeed: 0.0969s/iter; left time: 1703.9535s\n",
      "\titers: 300, epoch: 1 | loss: 0.5451734\n",
      "\tspeed: 0.1039s/iter; left time: 1816.2081s\n",
      "\titers: 400, epoch: 1 | loss: 0.6487391\n",
      "\tspeed: 0.0940s/iter; left time: 1634.5425s\n",
      "\titers: 500, epoch: 1 | loss: 0.5722955\n",
      "\tspeed: 0.0986s/iter; left time: 1704.6587s\n",
      "\titers: 600, epoch: 1 | loss: 0.5328101\n",
      "\tspeed: 0.1053s/iter; left time: 1809.2100s\n",
      "\titers: 700, epoch: 1 | loss: 0.5296453\n",
      "\tspeed: 0.0934s/iter; left time: 1594.5764s\n",
      "\titers: 800, epoch: 1 | loss: 0.4887833\n",
      "\tspeed: 0.0888s/iter; left time: 1508.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:27.05s\n",
      "Steps: 889 | Train Loss: 0.6048403 Vali Loss: 0.4450696 Test Loss: 0.4478828\n",
      "Validation loss decreased (inf --> 0.445070).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4536391\n",
      "\tspeed: 0.5430s/iter; left time: 9117.9925s\n",
      "\titers: 200, epoch: 2 | loss: 0.4180069\n",
      "\tspeed: 0.1053s/iter; left time: 1757.5090s\n",
      "\titers: 300, epoch: 2 | loss: 0.4597606\n",
      "\tspeed: 0.1059s/iter; left time: 1757.8447s\n",
      "\titers: 400, epoch: 2 | loss: 0.3618578\n",
      "\tspeed: 0.0881s/iter; left time: 1452.9641s\n",
      "\titers: 500, epoch: 2 | loss: 0.3676082\n",
      "\tspeed: 0.0990s/iter; left time: 1623.2425s\n",
      "\titers: 600, epoch: 2 | loss: 0.4104816\n",
      "\tspeed: 0.0943s/iter; left time: 1536.1908s\n",
      "\titers: 700, epoch: 2 | loss: 0.3547207\n",
      "\tspeed: 0.0965s/iter; left time: 1562.6111s\n",
      "\titers: 800, epoch: 2 | loss: 0.4136699\n",
      "\tspeed: 0.0917s/iter; left time: 1475.4771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:27.10s\n",
      "Steps: 889 | Train Loss: 0.3887345 Vali Loss: 0.3712647 Test Loss: 0.3798449\n",
      "Validation loss decreased (0.445070 --> 0.371265).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3531785\n",
      "\tspeed: 0.5367s/iter; left time: 8535.7669s\n",
      "\titers: 200, epoch: 3 | loss: 0.3907917\n",
      "\tspeed: 0.0970s/iter; left time: 1533.1761s\n",
      "\titers: 300, epoch: 3 | loss: 0.4181572\n",
      "\tspeed: 0.0874s/iter; left time: 1372.1734s\n",
      "\titers: 400, epoch: 3 | loss: 0.3879940\n",
      "\tspeed: 0.0870s/iter; left time: 1357.1365s\n",
      "\titers: 500, epoch: 3 | loss: 0.3243119\n",
      "\tspeed: 0.0951s/iter; left time: 1474.3907s\n",
      "\titers: 600, epoch: 3 | loss: 0.3153468\n",
      "\tspeed: 0.0968s/iter; left time: 1490.5492s\n",
      "\titers: 700, epoch: 3 | loss: 0.3420871\n",
      "\tspeed: 0.0978s/iter; left time: 1495.9543s\n",
      "\titers: 800, epoch: 3 | loss: 0.3690082\n",
      "\tspeed: 0.0976s/iter; left time: 1483.4181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:24.37s\n",
      "Steps: 889 | Train Loss: 0.3530936 Vali Loss: 0.3692195 Test Loss: 0.3829071\n",
      "Validation loss decreased (0.371265 --> 0.369219).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3389340\n",
      "\tspeed: 0.5266s/iter; left time: 7906.9658s\n",
      "\titers: 200, epoch: 4 | loss: 0.3184113\n",
      "\tspeed: 0.0960s/iter; left time: 1432.2927s\n",
      "\titers: 300, epoch: 4 | loss: 0.3661776\n",
      "\tspeed: 0.0963s/iter; left time: 1426.7808s\n",
      "\titers: 400, epoch: 4 | loss: 0.3185847\n",
      "\tspeed: 0.0992s/iter; left time: 1459.4756s\n",
      "\titers: 500, epoch: 4 | loss: 0.2722640\n",
      "\tspeed: 0.1041s/iter; left time: 1521.8446s\n",
      "\titers: 600, epoch: 4 | loss: 0.2940600\n",
      "\tspeed: 0.0994s/iter; left time: 1442.0998s\n",
      "\titers: 700, epoch: 4 | loss: 0.3337396\n",
      "\tspeed: 0.0903s/iter; left time: 1302.1322s\n",
      "\titers: 800, epoch: 4 | loss: 0.3283527\n",
      "\tspeed: 0.0961s/iter; left time: 1375.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:26.06s\n",
      "Steps: 889 | Train Loss: 0.3385745 Vali Loss: 0.3827470 Test Loss: 0.3955583\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3435049\n",
      "\tspeed: 0.5362s/iter; left time: 7574.2641s\n",
      "\titers: 200, epoch: 5 | loss: 0.2807623\n",
      "\tspeed: 0.0877s/iter; left time: 1229.6115s\n",
      "\titers: 300, epoch: 5 | loss: 0.3043932\n",
      "\tspeed: 0.0970s/iter; left time: 1351.3029s\n",
      "\titers: 400, epoch: 5 | loss: 0.3380823\n",
      "\tspeed: 0.0923s/iter; left time: 1276.6875s\n",
      "\titers: 500, epoch: 5 | loss: 0.3248403\n",
      "\tspeed: 0.0901s/iter; left time: 1237.1425s\n",
      "\titers: 600, epoch: 5 | loss: 0.2928286\n",
      "\tspeed: 0.0908s/iter; left time: 1237.7886s\n",
      "\titers: 700, epoch: 5 | loss: 0.3670836\n",
      "\tspeed: 0.0924s/iter; left time: 1250.1545s\n",
      "\titers: 800, epoch: 5 | loss: 0.3272755\n",
      "\tspeed: 0.0950s/iter; left time: 1274.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:23.32s\n",
      "Steps: 889 | Train Loss: 0.3244906 Vali Loss: 0.3741144 Test Loss: 0.4142777\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2680669\n",
      "\tspeed: 0.5333s/iter; left time: 7058.4472s\n",
      "\titers: 200, epoch: 6 | loss: 0.3396250\n",
      "\tspeed: 0.0826s/iter; left time: 1084.6054s\n",
      "\titers: 300, epoch: 6 | loss: 0.3213683\n",
      "\tspeed: 0.0990s/iter; left time: 1290.4248s\n",
      "\titers: 400, epoch: 6 | loss: 0.2747234\n",
      "\tspeed: 0.0957s/iter; left time: 1238.2516s\n",
      "\titers: 500, epoch: 6 | loss: 0.2895899\n",
      "\tspeed: 0.0994s/iter; left time: 1275.6596s\n",
      "\titers: 600, epoch: 6 | loss: 0.3004614\n",
      "\tspeed: 0.0992s/iter; left time: 1263.5223s\n",
      "\titers: 700, epoch: 6 | loss: 0.3177295\n",
      "\tspeed: 0.0837s/iter; left time: 1057.4820s\n",
      "\titers: 800, epoch: 6 | loss: 0.2946863\n",
      "\tspeed: 0.0970s/iter; left time: 1216.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:24.95s\n",
      "Steps: 889 | Train Loss: 0.3110130 Vali Loss: 0.3948340 Test Loss: 0.4245331\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3829072415828705, rmse:0.6187949776649475, mae:0.40458106994628906, rse:0.5667403936386108\n",
      "Original data scale mse:3139875.25, rmse:1771.9693603515625, mae:1196.216552734375, rse:0.12481781840324402\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7753379\n",
      "\tspeed: 0.1104s/iter; left time: 1952.2588s\n",
      "\titers: 200, epoch: 1 | loss: 0.6809441\n",
      "\tspeed: 0.0906s/iter; left time: 1593.4265s\n",
      "\titers: 300, epoch: 1 | loss: 0.6004956\n",
      "\tspeed: 0.0872s/iter; left time: 1523.4839s\n",
      "\titers: 400, epoch: 1 | loss: 0.5337401\n",
      "\tspeed: 0.0996s/iter; left time: 1731.3389s\n",
      "\titers: 500, epoch: 1 | loss: 0.5757738\n",
      "\tspeed: 0.0963s/iter; left time: 1663.9984s\n",
      "\titers: 600, epoch: 1 | loss: 0.5145159\n",
      "\tspeed: 0.0967s/iter; left time: 1660.6952s\n",
      "\titers: 700, epoch: 1 | loss: 0.4887009\n",
      "\tspeed: 0.1022s/iter; left time: 1746.4400s\n",
      "\titers: 800, epoch: 1 | loss: 0.4870414\n",
      "\tspeed: 0.1042s/iter; left time: 1769.4050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:26.60s\n",
      "Steps: 889 | Train Loss: 0.6012810 Vali Loss: 0.4462638 Test Loss: 0.4495331\n",
      "Validation loss decreased (inf --> 0.446264).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4142169\n",
      "\tspeed: 0.5161s/iter; left time: 8667.1264s\n",
      "\titers: 200, epoch: 2 | loss: 0.4274948\n",
      "\tspeed: 0.0888s/iter; left time: 1481.8020s\n",
      "\titers: 300, epoch: 2 | loss: 0.4309711\n",
      "\tspeed: 0.0907s/iter; left time: 1504.1118s\n",
      "\titers: 400, epoch: 2 | loss: 0.3883498\n",
      "\tspeed: 0.0966s/iter; left time: 1593.6206s\n",
      "\titers: 500, epoch: 2 | loss: 0.4314784\n",
      "\tspeed: 0.0970s/iter; left time: 1590.0047s\n",
      "\titers: 600, epoch: 2 | loss: 0.3775866\n",
      "\tspeed: 0.0897s/iter; left time: 1460.9928s\n",
      "\titers: 700, epoch: 2 | loss: 0.3924968\n",
      "\tspeed: 0.0958s/iter; left time: 1550.8064s\n",
      "\titers: 800, epoch: 2 | loss: 0.3988679\n",
      "\tspeed: 0.0939s/iter; left time: 1510.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:24.14s\n",
      "Steps: 889 | Train Loss: 0.3877668 Vali Loss: 0.3688564 Test Loss: 0.3796367\n",
      "Validation loss decreased (0.446264 --> 0.368856).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3502907\n",
      "\tspeed: 0.5477s/iter; left time: 8710.4286s\n",
      "\titers: 200, epoch: 3 | loss: 0.3600634\n",
      "\tspeed: 0.0962s/iter; left time: 1520.7191s\n",
      "\titers: 300, epoch: 3 | loss: 0.3186027\n",
      "\tspeed: 0.0956s/iter; left time: 1500.6580s\n",
      "\titers: 400, epoch: 3 | loss: 0.3588612\n",
      "\tspeed: 0.0901s/iter; left time: 1406.1529s\n",
      "\titers: 500, epoch: 3 | loss: 0.3601991\n",
      "\tspeed: 0.0998s/iter; left time: 1547.8445s\n",
      "\titers: 600, epoch: 3 | loss: 0.3274461\n",
      "\tspeed: 0.1097s/iter; left time: 1689.3361s\n",
      "\titers: 700, epoch: 3 | loss: 0.3670895\n",
      "\tspeed: 0.1192s/iter; left time: 1823.8644s\n",
      "\titers: 800, epoch: 3 | loss: 0.3449373\n",
      "\tspeed: 0.1104s/iter; left time: 1677.7327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:31.63s\n",
      "Steps: 889 | Train Loss: 0.3521828 Vali Loss: 0.3717173 Test Loss: 0.3826810\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3695828\n",
      "\tspeed: 0.5360s/iter; left time: 8047.8369s\n",
      "\titers: 200, epoch: 4 | loss: 0.3586979\n",
      "\tspeed: 0.0938s/iter; left time: 1398.2678s\n",
      "\titers: 300, epoch: 4 | loss: 0.3045539\n",
      "\tspeed: 0.0985s/iter; left time: 1459.8786s\n",
      "\titers: 400, epoch: 4 | loss: 0.3626105\n",
      "\tspeed: 0.0897s/iter; left time: 1320.4217s\n",
      "\titers: 500, epoch: 4 | loss: 0.3160306\n",
      "\tspeed: 0.0963s/iter; left time: 1407.1111s\n",
      "\titers: 600, epoch: 4 | loss: 0.3227006\n",
      "\tspeed: 0.1022s/iter; left time: 1483.1063s\n",
      "\titers: 700, epoch: 4 | loss: 0.3472717\n",
      "\tspeed: 0.0967s/iter; left time: 1393.6109s\n",
      "\titers: 800, epoch: 4 | loss: 0.3122483\n",
      "\tspeed: 0.0939s/iter; left time: 1344.3314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:24.98s\n",
      "Steps: 889 | Train Loss: 0.3372330 Vali Loss: 0.3813899 Test Loss: 0.3986235\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3665446\n",
      "\tspeed: 0.5386s/iter; left time: 7607.8455s\n",
      "\titers: 200, epoch: 5 | loss: 0.3180199\n",
      "\tspeed: 0.0892s/iter; left time: 1251.0428s\n",
      "\titers: 300, epoch: 5 | loss: 0.3623837\n",
      "\tspeed: 0.0983s/iter; left time: 1369.1625s\n",
      "\titers: 400, epoch: 5 | loss: 0.3258888\n",
      "\tspeed: 0.0979s/iter; left time: 1354.0943s\n",
      "\titers: 500, epoch: 5 | loss: 0.3628269\n",
      "\tspeed: 0.1008s/iter; left time: 1382.8549s\n",
      "\titers: 600, epoch: 5 | loss: 0.3343900\n",
      "\tspeed: 0.1001s/iter; left time: 1363.9820s\n",
      "\titers: 700, epoch: 5 | loss: 0.3423249\n",
      "\tspeed: 0.0997s/iter; left time: 1348.9849s\n",
      "\titers: 800, epoch: 5 | loss: 0.3108262\n",
      "\tspeed: 0.1052s/iter; left time: 1412.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.74s\n",
      "Steps: 889 | Train Loss: 0.3220020 Vali Loss: 0.3818478 Test Loss: 0.4030247\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.37963664531707764, rmse:0.6161466240882874, mae:0.4080275297164917, rse:0.5643148422241211\n",
      "Original data scale mse:3260984.75, rmse:1805.8197021484375, mae:1226.39453125, rse:0.12720224261283875\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6555070\n",
      "\tspeed: 0.1550s/iter; left time: 2752.0784s\n",
      "\titers: 200, epoch: 1 | loss: 0.5591167\n",
      "\tspeed: 0.0917s/iter; left time: 1619.1716s\n",
      "\titers: 300, epoch: 1 | loss: 0.4975783\n",
      "\tspeed: 0.0959s/iter; left time: 1683.6370s\n",
      "\titers: 400, epoch: 1 | loss: 0.4610074\n",
      "\tspeed: 0.0965s/iter; left time: 1685.5083s\n",
      "\titers: 500, epoch: 1 | loss: 0.5216176\n",
      "\tspeed: 0.0918s/iter; left time: 1592.9268s\n",
      "\titers: 600, epoch: 1 | loss: 0.4650809\n",
      "\tspeed: 0.0912s/iter; left time: 1574.1877s\n",
      "\titers: 700, epoch: 1 | loss: 0.4156896\n",
      "\tspeed: 0.0974s/iter; left time: 1671.9205s\n",
      "\titers: 800, epoch: 1 | loss: 0.4012448\n",
      "\tspeed: 0.0961s/iter; left time: 1639.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:24.33s\n",
      "Steps: 893 | Train Loss: 0.5172169 Vali Loss: 0.3909419 Test Loss: 0.4012013\n",
      "Validation loss decreased (inf --> 0.390942).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.3329136\n",
      "\tspeed: 0.5496s/iter; left time: 9270.6923s\n",
      "\titers: 200, epoch: 2 | loss: 0.3051157\n",
      "\tspeed: 0.0985s/iter; left time: 1652.3740s\n",
      "\titers: 300, epoch: 2 | loss: 0.3783871\n",
      "\tspeed: 0.0944s/iter; left time: 1572.8587s\n",
      "\titers: 400, epoch: 2 | loss: 0.3210444\n",
      "\tspeed: 0.1012s/iter; left time: 1677.0544s\n",
      "\titers: 500, epoch: 2 | loss: 0.2767418\n",
      "\tspeed: 0.0999s/iter; left time: 1645.4648s\n",
      "\titers: 600, epoch: 2 | loss: 0.2397419\n",
      "\tspeed: 0.1012s/iter; left time: 1656.4338s\n",
      "\titers: 700, epoch: 2 | loss: 0.2917682\n",
      "\tspeed: 0.0954s/iter; left time: 1552.1175s\n",
      "\titers: 800, epoch: 2 | loss: 0.2611503\n",
      "\tspeed: 0.0999s/iter; left time: 1614.9565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.55s\n",
      "Steps: 893 | Train Loss: 0.3086804 Vali Loss: 0.2775987 Test Loss: 0.2896311\n",
      "Validation loss decreased (0.390942 --> 0.277599).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2639548\n",
      "\tspeed: 0.6102s/iter; left time: 9748.6475s\n",
      "\titers: 200, epoch: 3 | loss: 0.2729660\n",
      "\tspeed: 0.1133s/iter; left time: 1798.9628s\n",
      "\titers: 300, epoch: 3 | loss: 0.2605044\n",
      "\tspeed: 0.0993s/iter; left time: 1565.9691s\n",
      "\titers: 400, epoch: 3 | loss: 0.2788781\n",
      "\tspeed: 0.1067s/iter; left time: 1671.7442s\n",
      "\titers: 500, epoch: 3 | loss: 0.2373098\n",
      "\tspeed: 0.1091s/iter; left time: 1698.7818s\n",
      "\titers: 600, epoch: 3 | loss: 0.2859555\n",
      "\tspeed: 0.1015s/iter; left time: 1569.9814s\n",
      "\titers: 700, epoch: 3 | loss: 0.2379736\n",
      "\tspeed: 0.1026s/iter; left time: 1577.3021s\n",
      "\titers: 800, epoch: 3 | loss: 0.3003955\n",
      "\tspeed: 0.0974s/iter; left time: 1488.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:33.51s\n",
      "Steps: 893 | Train Loss: 0.2741227 Vali Loss: 0.2677004 Test Loss: 0.2767538\n",
      "Validation loss decreased (0.277599 --> 0.267700).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2731439\n",
      "\tspeed: 0.5899s/iter; left time: 8897.3808s\n",
      "\titers: 200, epoch: 4 | loss: 0.2443695\n",
      "\tspeed: 0.1094s/iter; left time: 1639.6389s\n",
      "\titers: 300, epoch: 4 | loss: 0.2708040\n",
      "\tspeed: 0.1040s/iter; left time: 1547.5302s\n",
      "\titers: 400, epoch: 4 | loss: 0.2337376\n",
      "\tspeed: 0.1162s/iter; left time: 1717.4159s\n",
      "\titers: 500, epoch: 4 | loss: 0.2652700\n",
      "\tspeed: 0.1090s/iter; left time: 1600.4916s\n",
      "\titers: 600, epoch: 4 | loss: 0.2374048\n",
      "\tspeed: 0.0996s/iter; left time: 1451.8363s\n",
      "\titers: 700, epoch: 4 | loss: 0.2728975\n",
      "\tspeed: 0.1100s/iter; left time: 1593.0692s\n",
      "\titers: 800, epoch: 4 | loss: 0.2796249\n",
      "\tspeed: 0.0984s/iter; left time: 1414.8261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:34.24s\n",
      "Steps: 893 | Train Loss: 0.2644213 Vali Loss: 0.2624713 Test Loss: 0.2716621\n",
      "Validation loss decreased (0.267700 --> 0.262471).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2930860\n",
      "\tspeed: 0.5522s/iter; left time: 7835.4804s\n",
      "\titers: 200, epoch: 5 | loss: 0.2316188\n",
      "\tspeed: 0.1000s/iter; left time: 1409.4918s\n",
      "\titers: 300, epoch: 5 | loss: 0.2892490\n",
      "\tspeed: 0.1132s/iter; left time: 1583.6263s\n",
      "\titers: 400, epoch: 5 | loss: 0.2983845\n",
      "\tspeed: 0.0939s/iter; left time: 1304.3770s\n",
      "\titers: 500, epoch: 5 | loss: 0.2540570\n",
      "\tspeed: 0.0925s/iter; left time: 1275.0094s\n",
      "\titers: 600, epoch: 5 | loss: 0.2259790\n",
      "\tspeed: 0.0941s/iter; left time: 1287.6065s\n",
      "\titers: 700, epoch: 5 | loss: 0.2447995\n",
      "\tspeed: 0.0979s/iter; left time: 1329.9184s\n",
      "\titers: 800, epoch: 5 | loss: 0.2169718\n",
      "\tspeed: 0.0946s/iter; left time: 1276.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:26.95s\n",
      "Steps: 893 | Train Loss: 0.2586045 Vali Loss: 0.2581793 Test Loss: 0.2673375\n",
      "Validation loss decreased (0.262471 --> 0.258179).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2630603\n",
      "\tspeed: 0.5560s/iter; left time: 7392.4079s\n",
      "\titers: 200, epoch: 6 | loss: 0.2661979\n",
      "\tspeed: 0.0900s/iter; left time: 1187.9990s\n",
      "\titers: 300, epoch: 6 | loss: 0.2495898\n",
      "\tspeed: 0.0879s/iter; left time: 1151.7692s\n",
      "\titers: 400, epoch: 6 | loss: 0.2557808\n",
      "\tspeed: 0.0964s/iter; left time: 1252.4351s\n",
      "\titers: 500, epoch: 6 | loss: 0.2527471\n",
      "\tspeed: 0.0963s/iter; left time: 1241.4021s\n",
      "\titers: 600, epoch: 6 | loss: 0.2774071\n",
      "\tspeed: 0.1040s/iter; left time: 1331.2817s\n",
      "\titers: 700, epoch: 6 | loss: 0.1960831\n",
      "\tspeed: 0.0952s/iter; left time: 1208.0958s\n",
      "\titers: 800, epoch: 6 | loss: 0.2443065\n",
      "\tspeed: 0.1090s/iter; left time: 1373.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:27.28s\n",
      "Steps: 893 | Train Loss: 0.2542046 Vali Loss: 0.2567239 Test Loss: 0.2653377\n",
      "Validation loss decreased (0.258179 --> 0.256724).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2689722\n",
      "\tspeed: 0.5448s/iter; left time: 6757.5690s\n",
      "\titers: 200, epoch: 7 | loss: 0.2188629\n",
      "\tspeed: 0.0893s/iter; left time: 1098.3374s\n",
      "\titers: 300, epoch: 7 | loss: 0.2244141\n",
      "\tspeed: 0.1046s/iter; left time: 1276.6342s\n",
      "\titers: 400, epoch: 7 | loss: 0.2601210\n",
      "\tspeed: 0.1047s/iter; left time: 1266.6700s\n",
      "\titers: 500, epoch: 7 | loss: 0.2543232\n",
      "\tspeed: 0.1067s/iter; left time: 1280.9553s\n",
      "\titers: 600, epoch: 7 | loss: 0.2206755\n",
      "\tspeed: 0.0947s/iter; left time: 1126.7806s\n",
      "\titers: 700, epoch: 7 | loss: 0.2188539\n",
      "\tspeed: 0.0986s/iter; left time: 1163.8609s\n",
      "\titers: 800, epoch: 7 | loss: 0.2206604\n",
      "\tspeed: 0.0963s/iter; left time: 1127.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:28.89s\n",
      "Steps: 893 | Train Loss: 0.2510932 Vali Loss: 0.2566962 Test Loss: 0.2657960\n",
      "Validation loss decreased (0.256724 --> 0.256696).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2573139\n",
      "\tspeed: 0.5735s/iter; left time: 6600.8706s\n",
      "\titers: 200, epoch: 8 | loss: 0.2472233\n",
      "\tspeed: 0.0949s/iter; left time: 1082.7077s\n",
      "\titers: 300, epoch: 8 | loss: 0.2776766\n",
      "\tspeed: 0.0847s/iter; left time: 958.1536s\n",
      "\titers: 400, epoch: 8 | loss: 0.2366810\n",
      "\tspeed: 0.0910s/iter; left time: 1020.0259s\n",
      "\titers: 500, epoch: 8 | loss: 0.2523938\n",
      "\tspeed: 0.0937s/iter; left time: 1040.7140s\n",
      "\titers: 600, epoch: 8 | loss: 0.2504436\n",
      "\tspeed: 0.0890s/iter; left time: 980.3683s\n",
      "\titers: 700, epoch: 8 | loss: 0.2564319\n",
      "\tspeed: 0.0962s/iter; left time: 1049.7143s\n",
      "\titers: 800, epoch: 8 | loss: 0.2213441\n",
      "\tspeed: 0.0930s/iter; left time: 1005.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:23.66s\n",
      "Steps: 893 | Train Loss: 0.2482514 Vali Loss: 0.2533533 Test Loss: 0.2626646\n",
      "Validation loss decreased (0.256696 --> 0.253353).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2737295\n",
      "\tspeed: 0.5706s/iter; left time: 6058.0118s\n",
      "\titers: 200, epoch: 9 | loss: 0.2716286\n",
      "\tspeed: 0.0842s/iter; left time: 885.5961s\n",
      "\titers: 300, epoch: 9 | loss: 0.2171892\n",
      "\tspeed: 0.0886s/iter; left time: 922.5918s\n",
      "\titers: 400, epoch: 9 | loss: 0.2534241\n",
      "\tspeed: 0.0898s/iter; left time: 926.4959s\n",
      "\titers: 500, epoch: 9 | loss: 0.2308261\n",
      "\tspeed: 0.0934s/iter; left time: 954.5710s\n",
      "\titers: 600, epoch: 9 | loss: 0.2262620\n",
      "\tspeed: 0.0998s/iter; left time: 1010.1596s\n",
      "\titers: 700, epoch: 9 | loss: 0.2345880\n",
      "\tspeed: 0.0957s/iter; left time: 959.0716s\n",
      "\titers: 800, epoch: 9 | loss: 0.2201943\n",
      "\tspeed: 0.0947s/iter; left time: 939.4009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:25.13s\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'val (Python 3.11.5)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>0.4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.3017</td>\n",
       "      <td>0.4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.5526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3615</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>0.5505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.3057</td>\n",
       "      <td>0.4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>0.4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.6002</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2347</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.4275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3723</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3947</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2163  0.4650  0.2981  0.4259\n",
       "              2         24        0.2257  0.4751  0.3017  0.4351\n",
       "              1         96        0.3643  0.6036  0.3992  0.5526\n",
       "              2         96        0.3615  0.6012  0.3974  0.5505\n",
       "              1         168       0.3864  0.6216  0.4178  0.5693\n",
       "              2         168       0.3866  0.6218  0.4179  0.5695\n",
       "RMSE          1         24        0.2188  0.4678  0.3057  0.4284\n",
       "              2         24        0.2228  0.4720  0.2965  0.4323\n",
       "              1         96        0.3633  0.6027  0.3975  0.5519\n",
       "              2         96        0.3603  0.6002  0.3956  0.5496\n",
       "              1         168       0.3849  0.6204  0.4157  0.5682\n",
       "              2         168       0.3846  0.6202  0.4157  0.5680\n",
       "MAE           1         24        0.2347  0.4844  0.3008  0.4436\n",
       "              2         24        0.2179  0.4668  0.2705  0.4275\n",
       "              1         96        0.3723  0.6102  0.3903  0.5587\n",
       "              2         96        0.3720  0.6099  0.3905  0.5585\n",
       "              1         168       0.3949  0.6284  0.4102  0.5755\n",
       "              2         168       0.3947  0.6283  0.4102  0.5754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1452499.000</td>\n",
       "      <td>1205.1967</td>\n",
       "      <td>853.6146</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1513613.875</td>\n",
       "      <td>1230.2902</td>\n",
       "      <td>866.8263</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3107539.250</td>\n",
       "      <td>1762.8214</td>\n",
       "      <td>1208.1465</td>\n",
       "      <td>0.1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066246.250</td>\n",
       "      <td>1751.0701</td>\n",
       "      <td>1197.7284</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3617150.250</td>\n",
       "      <td>1901.8807</td>\n",
       "      <td>1296.1769</td>\n",
       "      <td>0.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3511273.500</td>\n",
       "      <td>1873.8392</td>\n",
       "      <td>1283.4158</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1550383.250</td>\n",
       "      <td>1245.1439</td>\n",
       "      <td>886.2724</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1480387.625</td>\n",
       "      <td>1216.7118</td>\n",
       "      <td>848.0317</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3056700.250</td>\n",
       "      <td>1748.3422</td>\n",
       "      <td>1198.0056</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3011115.000</td>\n",
       "      <td>1735.2565</td>\n",
       "      <td>1186.3693</td>\n",
       "      <td>0.1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3557823.250</td>\n",
       "      <td>1886.2194</td>\n",
       "      <td>1284.5880</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453479.000</td>\n",
       "      <td>1858.3539</td>\n",
       "      <td>1271.8232</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1737740.625</td>\n",
       "      <td>1318.2339</td>\n",
       "      <td>870.5349</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1284505.750</td>\n",
       "      <td>1133.3604</td>\n",
       "      <td>733.4088</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2971120.250</td>\n",
       "      <td>1723.6937</td>\n",
       "      <td>1153.3737</td>\n",
       "      <td>0.1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2962697.000</td>\n",
       "      <td>1721.2487</td>\n",
       "      <td>1151.7640</td>\n",
       "      <td>0.1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3482605.250</td>\n",
       "      <td>1866.1740</td>\n",
       "      <td>1247.3425</td>\n",
       "      <td>0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453181.500</td>\n",
       "      <td>1858.2738</td>\n",
       "      <td>1243.2384</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1452499.000  1205.1967   853.6146  0.0847\n",
       "              2         24        1513613.875  1230.2902   866.8263  0.0865\n",
       "              1         96        3107539.250  1762.8214  1208.1465  0.1241\n",
       "              2         96        3066246.250  1751.0701  1197.7284  0.1232\n",
       "              1         168       3617150.250  1901.8807  1296.1769  0.1340\n",
       "              2         168       3511273.500  1873.8392  1283.4158  0.1320\n",
       "RMSE          1         24        1550383.250  1245.1439   886.2724  0.0875\n",
       "              2         24        1480387.625  1216.7118   848.0317  0.0855\n",
       "              1         96        3056700.250  1748.3422  1198.0056  0.1230\n",
       "              2         96        3011115.000  1735.2565  1186.3693  0.1221\n",
       "              1         168       3557823.250  1886.2194  1284.5880  0.1329\n",
       "              2         168       3453479.000  1858.3539  1271.8232  0.1309\n",
       "MAE           1         24        1737740.625  1318.2339   870.5349  0.0926\n",
       "              2         24        1284505.750  1133.3604   733.4088  0.0796\n",
       "              1         96        2971120.250  1723.6937  1153.3737  0.1213\n",
       "              2         96        2962697.000  1721.2487  1151.7640  0.1211\n",
       "              1         168       3482605.250  1866.1740  1247.3425  0.1315\n",
       "              2         168       3453181.500  1858.2738  1243.2384  0.1309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>0.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3722</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2263  0.4756  0.2857  0.4356\n",
       "         MSE            0.2210  0.4701  0.2999  0.4305\n",
       "         RMSE           0.2208  0.4699  0.3011  0.4303\n",
       "96       MAE            0.3722  0.6100  0.3904  0.5586\n",
       "         MSE            0.3629  0.6024  0.3983  0.5516\n",
       "         RMSE           0.3618  0.6015  0.3965  0.5507\n",
       "168      MAE            0.3948  0.6283  0.4102  0.5755\n",
       "         MSE            0.3865  0.6217  0.4178  0.5694\n",
       "         RMSE           0.3848  0.6203  0.4157  0.5681"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.511123e+06</td>\n",
       "      <td>1225.7971</td>\n",
       "      <td>801.9718</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.483056e+06</td>\n",
       "      <td>1217.7434</td>\n",
       "      <td>860.2204</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.515385e+06</td>\n",
       "      <td>1230.9279</td>\n",
       "      <td>867.1521</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.966909e+06</td>\n",
       "      <td>1722.4712</td>\n",
       "      <td>1152.5688</td>\n",
       "      <td>0.1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.086893e+06</td>\n",
       "      <td>1756.9457</td>\n",
       "      <td>1202.9374</td>\n",
       "      <td>0.1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.033908e+06</td>\n",
       "      <td>1741.7993</td>\n",
       "      <td>1192.1874</td>\n",
       "      <td>0.1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.467893e+06</td>\n",
       "      <td>1862.2239</td>\n",
       "      <td>1245.2905</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.564212e+06</td>\n",
       "      <td>1887.8600</td>\n",
       "      <td>1289.7963</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.505651e+06</td>\n",
       "      <td>1872.2866</td>\n",
       "      <td>1278.2056</td>\n",
       "      <td>0.1319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.511123e+06  1225.7971   801.9718  0.0861\n",
       "         MSE            1.483056e+06  1217.7434   860.2204  0.0856\n",
       "         RMSE           1.515385e+06  1230.9279   867.1521  0.0865\n",
       "96       MAE            2.966909e+06  1722.4712  1152.5688  0.1212\n",
       "         MSE            3.086893e+06  1756.9457  1202.9374  0.1236\n",
       "         RMSE           3.033908e+06  1741.7993  1192.1874  0.1226\n",
       "168      MAE            3.467893e+06  1862.2239  1245.2905  0.1312\n",
       "         MSE            3.564212e+06  1887.8600  1289.7963  0.1330\n",
       "         RMSE           3.505651e+06  1872.2866  1278.2056  0.1319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled_IT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1015439\n",
      "\tspeed: 0.1310s/iter; left time: 1173.7397s\n",
      "\titers: 200, epoch: 1 | loss: 0.0780112\n",
      "\tspeed: 0.0415s/iter; left time: 367.9963s\n",
      "\titers: 300, epoch: 1 | loss: 0.0634276\n",
      "\tspeed: 0.0448s/iter; left time: 392.8263s\n",
      "\titers: 400, epoch: 1 | loss: 0.0499723\n",
      "\tspeed: 0.0433s/iter; left time: 375.1178s\n",
      "\titers: 500, epoch: 1 | loss: 0.0366096\n",
      "\tspeed: 0.0404s/iter; left time: 346.2343s\n",
      "\titers: 600, epoch: 1 | loss: 0.0305542\n",
      "\tspeed: 0.0406s/iter; left time: 343.7792s\n",
      "\titers: 700, epoch: 1 | loss: 0.0254408\n",
      "\tspeed: 0.0405s/iter; left time: 338.9794s\n",
      "\titers: 800, epoch: 1 | loss: 0.0277302\n",
      "\tspeed: 0.0410s/iter; left time: 339.0201s\n",
      "\titers: 900, epoch: 1 | loss: 0.0307077\n",
      "\tspeed: 0.0406s/iter; left time: 331.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.60s\n",
      "Steps: 906 | Train Loss: 0.0542530 Vali Loss: 0.0167840 Test Loss: 0.0182139\n",
      "Validation loss decreased (inf --> 0.016784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0249653\n",
      "\tspeed: 0.1038s/iter; left time: 835.7988s\n",
      "\titers: 200, epoch: 2 | loss: 0.0205376\n",
      "\tspeed: 0.0408s/iter; left time: 324.2999s\n",
      "\titers: 300, epoch: 2 | loss: 0.0144465\n",
      "\tspeed: 0.0418s/iter; left time: 328.1696s\n",
      "\titers: 400, epoch: 2 | loss: 0.0110110\n",
      "\tspeed: 0.0443s/iter; left time: 343.9046s\n",
      "\titers: 500, epoch: 2 | loss: 0.0148877\n",
      "\tspeed: 0.0449s/iter; left time: 343.9901s\n",
      "\titers: 600, epoch: 2 | loss: 0.0146665\n",
      "\tspeed: 0.0452s/iter; left time: 341.2740s\n",
      "\titers: 700, epoch: 2 | loss: 0.0117732\n",
      "\tspeed: 0.0456s/iter; left time: 340.0806s\n",
      "\titers: 800, epoch: 2 | loss: 0.0135435\n",
      "\tspeed: 0.0419s/iter; left time: 308.5073s\n",
      "\titers: 900, epoch: 2 | loss: 0.0127468\n",
      "\tspeed: 0.0439s/iter; left time: 318.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.67s\n",
      "Steps: 906 | Train Loss: 0.0155822 Vali Loss: 0.0117499 Test Loss: 0.0131114\n",
      "Validation loss decreased (0.016784 --> 0.011750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0114066\n",
      "\tspeed: 0.1068s/iter; left time: 763.1871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0089474\n",
      "\tspeed: 0.0411s/iter; left time: 289.5808s\n",
      "\titers: 300, epoch: 3 | loss: 0.0102706\n",
      "\tspeed: 0.0433s/iter; left time: 300.5452s\n",
      "\titers: 400, epoch: 3 | loss: 0.0080307\n",
      "\tspeed: 0.0414s/iter; left time: 283.3393s\n",
      "\titers: 500, epoch: 3 | loss: 0.0117475\n",
      "\tspeed: 0.0418s/iter; left time: 282.0641s\n",
      "\titers: 600, epoch: 3 | loss: 0.0127674\n",
      "\tspeed: 0.0408s/iter; left time: 271.2909s\n",
      "\titers: 700, epoch: 3 | loss: 0.0085980\n",
      "\tspeed: 0.0407s/iter; left time: 266.3854s\n",
      "\titers: 800, epoch: 3 | loss: 0.0090622\n",
      "\tspeed: 0.0418s/iter; left time: 269.8809s\n",
      "\titers: 900, epoch: 3 | loss: 0.0092529\n",
      "\tspeed: 0.0407s/iter; left time: 258.5249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 906 | Train Loss: 0.0107991 Vali Loss: 0.0098243 Test Loss: 0.0119410\n",
      "Validation loss decreased (0.011750 --> 0.009824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0092516\n",
      "\tspeed: 0.1028s/iter; left time: 641.7830s\n",
      "\titers: 200, epoch: 4 | loss: 0.0081608\n",
      "\tspeed: 0.0405s/iter; left time: 248.9594s\n",
      "\titers: 300, epoch: 4 | loss: 0.0097082\n",
      "\tspeed: 0.0414s/iter; left time: 250.0619s\n",
      "\titers: 400, epoch: 4 | loss: 0.0108099\n",
      "\tspeed: 0.0414s/iter; left time: 245.9300s\n",
      "\titers: 500, epoch: 4 | loss: 0.0078915\n",
      "\tspeed: 0.0418s/iter; left time: 244.3197s\n",
      "\titers: 600, epoch: 4 | loss: 0.0114540\n",
      "\tspeed: 0.0410s/iter; left time: 235.5187s\n",
      "\titers: 700, epoch: 4 | loss: 0.0109546\n",
      "\tspeed: 0.0454s/iter; left time: 255.9517s\n",
      "\titers: 800, epoch: 4 | loss: 0.0103235\n",
      "\tspeed: 0.0450s/iter; left time: 249.4279s\n",
      "\titers: 900, epoch: 4 | loss: 0.0106262\n",
      "\tspeed: 0.0447s/iter; left time: 243.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 906 | Train Loss: 0.0093414 Vali Loss: 0.0090817 Test Loss: 0.0107185\n",
      "Validation loss decreased (0.009824 --> 0.009082).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0079604\n",
      "\tspeed: 0.1040s/iter; left time: 555.2854s\n",
      "\titers: 200, epoch: 5 | loss: 0.0065428\n",
      "\tspeed: 0.0449s/iter; left time: 235.1357s\n",
      "\titers: 300, epoch: 5 | loss: 0.0076818\n",
      "\tspeed: 0.0451s/iter; left time: 231.5861s\n",
      "\titers: 400, epoch: 5 | loss: 0.0070810\n",
      "\tspeed: 0.0450s/iter; left time: 226.8368s\n",
      "\titers: 500, epoch: 5 | loss: 0.0086843\n",
      "\tspeed: 0.0449s/iter; left time: 221.6744s\n",
      "\titers: 600, epoch: 5 | loss: 0.0058556\n",
      "\tspeed: 0.0447s/iter; left time: 216.1470s\n",
      "\titers: 700, epoch: 5 | loss: 0.0103446\n",
      "\tspeed: 0.0458s/iter; left time: 217.1356s\n",
      "\titers: 800, epoch: 5 | loss: 0.0082625\n",
      "\tspeed: 0.0437s/iter; left time: 202.8233s\n",
      "\titers: 900, epoch: 5 | loss: 0.0090409\n",
      "\tspeed: 0.0447s/iter; left time: 202.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.85s\n",
      "Steps: 906 | Train Loss: 0.0083556 Vali Loss: 0.0096571 Test Loss: 0.0109171\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0064203\n",
      "\tspeed: 0.0997s/iter; left time: 441.5518s\n",
      "\titers: 200, epoch: 6 | loss: 0.0072406\n",
      "\tspeed: 0.0454s/iter; left time: 196.7311s\n",
      "\titers: 300, epoch: 6 | loss: 0.0118000\n",
      "\tspeed: 0.0449s/iter; left time: 189.9531s\n",
      "\titers: 400, epoch: 6 | loss: 0.0090705\n",
      "\tspeed: 0.0444s/iter; left time: 183.3947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0073423\n",
      "\tspeed: 0.0450s/iter; left time: 181.4222s\n",
      "\titers: 600, epoch: 6 | loss: 0.0087076\n",
      "\tspeed: 0.0447s/iter; left time: 175.8631s\n",
      "\titers: 700, epoch: 6 | loss: 0.0080332\n",
      "\tspeed: 0.0455s/iter; left time: 174.3984s\n",
      "\titers: 800, epoch: 6 | loss: 0.0068916\n",
      "\tspeed: 0.0454s/iter; left time: 169.4103s\n",
      "\titers: 900, epoch: 6 | loss: 0.0086625\n",
      "\tspeed: 0.0447s/iter; left time: 162.3169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.99s\n",
      "Steps: 906 | Train Loss: 0.0077443 Vali Loss: 0.0101560 Test Loss: 0.0128229\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0068713\n",
      "\tspeed: 0.0968s/iter; left time: 341.1281s\n",
      "\titers: 200, epoch: 7 | loss: 0.0056414\n",
      "\tspeed: 0.0409s/iter; left time: 140.1466s\n",
      "\titers: 300, epoch: 7 | loss: 0.0055930\n",
      "\tspeed: 0.0406s/iter; left time: 135.0289s\n",
      "\titers: 400, epoch: 7 | loss: 0.0067463\n",
      "\tspeed: 0.0408s/iter; left time: 131.6137s\n",
      "\titers: 500, epoch: 7 | loss: 0.0064569\n",
      "\tspeed: 0.0428s/iter; left time: 133.6938s\n",
      "\titers: 600, epoch: 7 | loss: 0.0050494\n",
      "\tspeed: 0.0444s/iter; left time: 134.4179s\n",
      "\titers: 700, epoch: 7 | loss: 0.0066490\n",
      "\tspeed: 0.0450s/iter; left time: 131.7498s\n",
      "\titers: 800, epoch: 7 | loss: 0.0080448\n",
      "\tspeed: 0.0444s/iter; left time: 125.4707s\n",
      "\titers: 900, epoch: 7 | loss: 0.0078710\n",
      "\tspeed: 0.0407s/iter; left time: 110.7877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 906 | Train Loss: 0.0071003 Vali Loss: 0.0097350 Test Loss: 0.0120525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010717766359448433, rmse:0.10352664440870285, mae:0.06321258097887039, rse:0.391234427690506\n",
      "Original data scale mse:1526122.125, rmse:1235.3631591796875, mae:813.0914916992188, rse:0.08681188523769379\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1072771\n",
      "\tspeed: 0.0466s/iter; left time: 417.2858s\n",
      "\titers: 200, epoch: 1 | loss: 0.0727854\n",
      "\tspeed: 0.0452s/iter; left time: 400.8090s\n",
      "\titers: 300, epoch: 1 | loss: 0.0564901\n",
      "\tspeed: 0.0291s/iter; left time: 254.8711s\n",
      "\titers: 400, epoch: 1 | loss: 0.0384456\n",
      "\tspeed: 0.0281s/iter; left time: 243.4099s\n",
      "\titers: 500, epoch: 1 | loss: 0.0314287\n",
      "\tspeed: 0.0281s/iter; left time: 240.6022s\n",
      "\titers: 600, epoch: 1 | loss: 0.0333188\n",
      "\tspeed: 0.0312s/iter; left time: 264.3165s\n",
      "\titers: 700, epoch: 1 | loss: 0.0309556\n",
      "\tspeed: 0.0450s/iter; left time: 376.1455s\n",
      "\titers: 800, epoch: 1 | loss: 0.0317015\n",
      "\tspeed: 0.0433s/iter; left time: 357.4865s\n",
      "\titers: 900, epoch: 1 | loss: 0.0256815\n",
      "\tspeed: 0.0409s/iter; left time: 333.3969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:34.05s\n",
      "Steps: 906 | Train Loss: 0.0540615 Vali Loss: 0.0167371 Test Loss: 0.0184141\n",
      "Validation loss decreased (inf --> 0.016737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0195280\n",
      "\tspeed: 0.1017s/iter; left time: 819.5498s\n",
      "\titers: 200, epoch: 2 | loss: 0.0186638\n",
      "\tspeed: 0.0412s/iter; left time: 328.0544s\n",
      "\titers: 300, epoch: 2 | loss: 0.0144677\n",
      "\tspeed: 0.0411s/iter; left time: 322.7769s\n",
      "\titers: 400, epoch: 2 | loss: 0.0139153\n",
      "\tspeed: 0.0409s/iter; left time: 317.2043s\n",
      "\titers: 500, epoch: 2 | loss: 0.0180252\n",
      "\tspeed: 0.0413s/iter; left time: 316.3473s\n",
      "\titers: 600, epoch: 2 | loss: 0.0111117\n",
      "\tspeed: 0.0412s/iter; left time: 311.0344s\n",
      "\titers: 700, epoch: 2 | loss: 0.0108622\n",
      "\tspeed: 0.0411s/iter; left time: 306.7167s\n",
      "\titers: 800, epoch: 2 | loss: 0.0091546\n",
      "\tspeed: 0.0413s/iter; left time: 303.4726s\n",
      "\titers: 900, epoch: 2 | loss: 0.0104582\n",
      "\tspeed: 0.0412s/iter; left time: 299.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0158579 Vali Loss: 0.0106347 Test Loss: 0.0121935\n",
      "Validation loss decreased (0.016737 --> 0.010635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0106450\n",
      "\tspeed: 0.0978s/iter; left time: 699.0452s\n",
      "\titers: 200, epoch: 3 | loss: 0.0105016\n",
      "\tspeed: 0.0418s/iter; left time: 294.3921s\n",
      "\titers: 300, epoch: 3 | loss: 0.0131094\n",
      "\tspeed: 0.0414s/iter; left time: 287.3878s\n",
      "\titers: 400, epoch: 3 | loss: 0.0087256\n",
      "\tspeed: 0.0418s/iter; left time: 286.1287s\n",
      "\titers: 500, epoch: 3 | loss: 0.0092445\n",
      "\tspeed: 0.0410s/iter; left time: 276.9930s\n",
      "\titers: 600, epoch: 3 | loss: 0.0089797\n",
      "\tspeed: 0.0408s/iter; left time: 271.3292s\n",
      "\titers: 700, epoch: 3 | loss: 0.0099697\n",
      "\tspeed: 0.0409s/iter; left time: 267.6165s\n",
      "\titers: 800, epoch: 3 | loss: 0.0115768\n",
      "\tspeed: 0.0412s/iter; left time: 265.7591s\n",
      "\titers: 900, epoch: 3 | loss: 0.0107241\n",
      "\tspeed: 0.0410s/iter; left time: 260.3120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0109342 Vali Loss: 0.0096202 Test Loss: 0.0108889\n",
      "Validation loss decreased (0.010635 --> 0.009620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0122454\n",
      "\tspeed: 0.0967s/iter; left time: 603.9196s\n",
      "\titers: 200, epoch: 4 | loss: 0.0103315\n",
      "\tspeed: 0.0413s/iter; left time: 253.6873s\n",
      "\titers: 300, epoch: 4 | loss: 0.0183899\n",
      "\tspeed: 0.0414s/iter; left time: 250.3466s\n",
      "\titers: 400, epoch: 4 | loss: 0.0099227\n",
      "\tspeed: 0.0411s/iter; left time: 244.1338s\n",
      "\titers: 500, epoch: 4 | loss: 0.0106649\n",
      "\tspeed: 0.0415s/iter; left time: 242.2621s\n",
      "\titers: 600, epoch: 4 | loss: 0.0087657\n",
      "\tspeed: 0.0414s/iter; left time: 237.8428s\n",
      "\titers: 700, epoch: 4 | loss: 0.0059044\n",
      "\tspeed: 0.0414s/iter; left time: 233.3948s\n",
      "\titers: 800, epoch: 4 | loss: 0.0082942\n",
      "\tspeed: 0.0415s/iter; left time: 230.0344s\n",
      "\titers: 900, epoch: 4 | loss: 0.0090943\n",
      "\tspeed: 0.0410s/iter; left time: 223.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.63s\n",
      "Steps: 906 | Train Loss: 0.0096520 Vali Loss: 0.0101080 Test Loss: 0.0116650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0084265\n",
      "\tspeed: 0.0966s/iter; left time: 515.6285s\n",
      "\titers: 200, epoch: 5 | loss: 0.0112829\n",
      "\tspeed: 0.0453s/iter; left time: 236.9820s\n",
      "\titers: 300, epoch: 5 | loss: 0.0086787\n",
      "\tspeed: 0.0450s/iter; left time: 230.9672s\n",
      "\titers: 400, epoch: 5 | loss: 0.0081475\n",
      "\tspeed: 0.0452s/iter; left time: 227.5051s\n",
      "\titers: 500, epoch: 5 | loss: 0.0099095\n",
      "\tspeed: 0.0451s/iter; left time: 222.4889s\n",
      "\titers: 600, epoch: 5 | loss: 0.0075935\n",
      "\tspeed: 0.0450s/iter; left time: 217.6005s\n",
      "\titers: 700, epoch: 5 | loss: 0.0097166\n",
      "\tspeed: 0.0443s/iter; left time: 209.9948s\n",
      "\titers: 800, epoch: 5 | loss: 0.0067493\n",
      "\tspeed: 0.0412s/iter; left time: 191.1842s\n",
      "\titers: 900, epoch: 5 | loss: 0.0083288\n",
      "\tspeed: 0.0453s/iter; left time: 205.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 906 | Train Loss: 0.0085997 Vali Loss: 0.0092223 Test Loss: 0.0108748\n",
      "Validation loss decreased (0.009620 --> 0.009222).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0091523\n",
      "\tspeed: 0.1000s/iter; left time: 443.0962s\n",
      "\titers: 200, epoch: 6 | loss: 0.0071133\n",
      "\tspeed: 0.0416s/iter; left time: 180.2960s\n",
      "\titers: 300, epoch: 6 | loss: 0.0082193\n",
      "\tspeed: 0.0418s/iter; left time: 176.8737s\n",
      "\titers: 400, epoch: 6 | loss: 0.0080703\n",
      "\tspeed: 0.0413s/iter; left time: 170.5997s\n",
      "\titers: 500, epoch: 6 | loss: 0.0076564\n",
      "\tspeed: 0.0413s/iter; left time: 166.6557s\n",
      "\titers: 600, epoch: 6 | loss: 0.0077170\n",
      "\tspeed: 0.0415s/iter; left time: 163.1258s\n",
      "\titers: 700, epoch: 6 | loss: 0.0069852\n",
      "\tspeed: 0.0411s/iter; left time: 157.4837s\n",
      "\titers: 800, epoch: 6 | loss: 0.0069441\n",
      "\tspeed: 0.0410s/iter; left time: 152.9914s\n",
      "\titers: 900, epoch: 6 | loss: 0.0075413\n",
      "\tspeed: 0.0415s/iter; left time: 150.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.0081203 Vali Loss: 0.0096952 Test Loss: 0.0113186\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0061328\n",
      "\tspeed: 0.0942s/iter; left time: 332.0654s\n",
      "\titers: 200, epoch: 7 | loss: 0.0075554\n",
      "\tspeed: 0.0416s/iter; left time: 142.4430s\n",
      "\titers: 300, epoch: 7 | loss: 0.0073546\n",
      "\tspeed: 0.0415s/iter; left time: 138.1309s\n",
      "\titers: 400, epoch: 7 | loss: 0.0069964\n",
      "\tspeed: 0.0416s/iter; left time: 134.2166s\n",
      "\titers: 500, epoch: 7 | loss: 0.0069561\n",
      "\tspeed: 0.0417s/iter; left time: 130.2927s\n",
      "\titers: 600, epoch: 7 | loss: 0.0066977\n",
      "\tspeed: 0.0418s/iter; left time: 126.5644s\n",
      "\titers: 700, epoch: 7 | loss: 0.0093124\n",
      "\tspeed: 0.0408s/iter; left time: 119.3629s\n",
      "\titers: 800, epoch: 7 | loss: 0.0061187\n",
      "\tspeed: 0.0416s/iter; left time: 117.4203s\n",
      "\titers: 900, epoch: 7 | loss: 0.0054671\n",
      "\tspeed: 0.0414s/iter; left time: 112.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 906 | Train Loss: 0.0074914 Vali Loss: 0.0099514 Test Loss: 0.0116304\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0064661\n",
      "\tspeed: 0.0944s/iter; left time: 247.1204s\n",
      "\titers: 200, epoch: 8 | loss: 0.0056693\n",
      "\tspeed: 0.0410s/iter; left time: 103.1883s\n",
      "\titers: 300, epoch: 8 | loss: 0.0065405\n",
      "\tspeed: 0.0412s/iter; left time: 99.7724s\n",
      "\titers: 400, epoch: 8 | loss: 0.0057899\n",
      "\tspeed: 0.0416s/iter; left time: 96.4946s\n",
      "\titers: 500, epoch: 8 | loss: 0.0082420\n",
      "\tspeed: 0.0404s/iter; left time: 89.7155s\n",
      "\titers: 600, epoch: 8 | loss: 0.0066698\n",
      "\tspeed: 0.0411s/iter; left time: 87.1092s\n",
      "\titers: 700, epoch: 8 | loss: 0.0070464\n",
      "\tspeed: 0.0407s/iter; left time: 82.0825s\n",
      "\titers: 800, epoch: 8 | loss: 0.0054594\n",
      "\tspeed: 0.0404s/iter; left time: 77.5172s\n",
      "\titers: 900, epoch: 8 | loss: 0.0076695\n",
      "\tspeed: 0.0411s/iter; left time: 74.7435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.26s\n",
      "Steps: 906 | Train Loss: 0.0069357 Vali Loss: 0.0098625 Test Loss: 0.0113585\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010888392105698586, rmse:0.10434745997190475, mae:0.06476157903671265, rse:0.3943363130092621\n",
      "Original data scale mse:1720168.5, rmse:1311.552001953125, mae:849.8506469726562, rse:0.09216585010290146\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0965978\n",
      "\tspeed: 0.0762s/iter; left time: 681.0253s\n",
      "\titers: 200, epoch: 1 | loss: 0.0763174\n",
      "\tspeed: 0.0473s/iter; left time: 418.4102s\n",
      "\titers: 300, epoch: 1 | loss: 0.0624324\n",
      "\tspeed: 0.0473s/iter; left time: 413.8774s\n",
      "\titers: 400, epoch: 1 | loss: 0.0575895\n",
      "\tspeed: 0.0474s/iter; left time: 409.8899s\n",
      "\titers: 500, epoch: 1 | loss: 0.0522829\n",
      "\tspeed: 0.0474s/iter; left time: 404.4719s\n",
      "\titers: 600, epoch: 1 | loss: 0.0474165\n",
      "\tspeed: 0.0471s/iter; left time: 397.9874s\n",
      "\titers: 700, epoch: 1 | loss: 0.0446128\n",
      "\tspeed: 0.0474s/iter; left time: 394.9680s\n",
      "\titers: 800, epoch: 1 | loss: 0.0429181\n",
      "\tspeed: 0.0473s/iter; left time: 389.4987s\n",
      "\titers: 900, epoch: 1 | loss: 0.0435803\n",
      "\tspeed: 0.0456s/iter; left time: 370.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.0626754 Vali Loss: 0.0342747 Test Loss: 0.0396404\n",
      "Validation loss decreased (inf --> 0.034275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0316409\n",
      "\tspeed: 0.1136s/iter; left time: 912.7016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0300582\n",
      "\tspeed: 0.0474s/iter; left time: 376.3983s\n",
      "\titers: 300, epoch: 2 | loss: 0.0245600\n",
      "\tspeed: 0.0472s/iter; left time: 369.9472s\n",
      "\titers: 400, epoch: 2 | loss: 0.0222255\n",
      "\tspeed: 0.0473s/iter; left time: 365.9265s\n",
      "\titers: 500, epoch: 2 | loss: 0.0221407\n",
      "\tspeed: 0.0474s/iter; left time: 361.7758s\n",
      "\titers: 600, epoch: 2 | loss: 0.0229814\n",
      "\tspeed: 0.0473s/iter; left time: 356.4701s\n",
      "\titers: 700, epoch: 2 | loss: 0.0199335\n",
      "\tspeed: 0.0473s/iter; left time: 351.5507s\n",
      "\titers: 800, epoch: 2 | loss: 0.0198781\n",
      "\tspeed: 0.0473s/iter; left time: 346.9803s\n",
      "\titers: 900, epoch: 2 | loss: 0.0168008\n",
      "\tspeed: 0.0473s/iter; left time: 342.1705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.95s\n",
      "Steps: 904 | Train Loss: 0.0248720 Vali Loss: 0.0181293 Test Loss: 0.0190602\n",
      "Validation loss decreased (0.034275 --> 0.018129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185513\n",
      "\tspeed: 0.1158s/iter; left time: 826.1195s\n",
      "\titers: 200, epoch: 3 | loss: 0.0179213\n",
      "\tspeed: 0.0472s/iter; left time: 331.6582s\n",
      "\titers: 300, epoch: 3 | loss: 0.0190399\n",
      "\tspeed: 0.0472s/iter; left time: 327.2241s\n",
      "\titers: 400, epoch: 3 | loss: 0.0179476\n",
      "\tspeed: 0.0472s/iter; left time: 322.3024s\n",
      "\titers: 500, epoch: 3 | loss: 0.0167958\n",
      "\tspeed: 0.0473s/iter; left time: 318.3566s\n",
      "\titers: 600, epoch: 3 | loss: 0.0156560\n",
      "\tspeed: 0.0473s/iter; left time: 313.9871s\n",
      "\titers: 700, epoch: 3 | loss: 0.0143740\n",
      "\tspeed: 0.0473s/iter; left time: 308.8785s\n",
      "\titers: 800, epoch: 3 | loss: 0.0194579\n",
      "\tspeed: 0.0474s/iter; left time: 304.8830s\n",
      "\titers: 900, epoch: 3 | loss: 0.0194166\n",
      "\tspeed: 0.0473s/iter; left time: 299.7215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.0173184 Vali Loss: 0.0168388 Test Loss: 0.0188488\n",
      "Validation loss decreased (0.018129 --> 0.016839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0145729\n",
      "\tspeed: 0.1141s/iter; left time: 710.9329s\n",
      "\titers: 200, epoch: 4 | loss: 0.0157704\n",
      "\tspeed: 0.0475s/iter; left time: 291.2584s\n",
      "\titers: 300, epoch: 4 | loss: 0.0148348\n",
      "\tspeed: 0.0476s/iter; left time: 287.2766s\n",
      "\titers: 400, epoch: 4 | loss: 0.0170949\n",
      "\tspeed: 0.0476s/iter; left time: 282.3401s\n",
      "\titers: 500, epoch: 4 | loss: 0.0174292\n",
      "\tspeed: 0.0475s/iter; left time: 277.0821s\n",
      "\titers: 600, epoch: 4 | loss: 0.0169957\n",
      "\tspeed: 0.0476s/iter; left time: 272.8387s\n",
      "\titers: 700, epoch: 4 | loss: 0.0144556\n",
      "\tspeed: 0.0476s/iter; left time: 268.0350s\n",
      "\titers: 800, epoch: 4 | loss: 0.0159345\n",
      "\tspeed: 0.0476s/iter; left time: 263.3802s\n",
      "\titers: 900, epoch: 4 | loss: 0.0133411\n",
      "\tspeed: 0.0477s/iter; left time: 258.7137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.21s\n",
      "Steps: 904 | Train Loss: 0.0155758 Vali Loss: 0.0160214 Test Loss: 0.0188094\n",
      "Validation loss decreased (0.016839 --> 0.016021).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0125320\n",
      "\tspeed: 0.1154s/iter; left time: 614.7517s\n",
      "\titers: 200, epoch: 5 | loss: 0.0142376\n",
      "\tspeed: 0.0475s/iter; left time: 247.9534s\n",
      "\titers: 300, epoch: 5 | loss: 0.0147045\n",
      "\tspeed: 0.0475s/iter; left time: 243.4648s\n",
      "\titers: 400, epoch: 5 | loss: 0.0165673\n",
      "\tspeed: 0.0475s/iter; left time: 238.7636s\n",
      "\titers: 500, epoch: 5 | loss: 0.0136447\n",
      "\tspeed: 0.0473s/iter; left time: 232.8595s\n",
      "\titers: 600, epoch: 5 | loss: 0.0137602\n",
      "\tspeed: 0.0474s/iter; left time: 228.7746s\n",
      "\titers: 700, epoch: 5 | loss: 0.0156750\n",
      "\tspeed: 0.0473s/iter; left time: 223.7079s\n",
      "\titers: 800, epoch: 5 | loss: 0.0154189\n",
      "\tspeed: 0.0475s/iter; left time: 219.6795s\n",
      "\titers: 900, epoch: 5 | loss: 0.0126147\n",
      "\tspeed: 0.0474s/iter; left time: 214.5903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.0141869 Vali Loss: 0.0175523 Test Loss: 0.0200307\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0091899\n",
      "\tspeed: 0.1115s/iter; left time: 492.9849s\n",
      "\titers: 200, epoch: 6 | loss: 0.0141560\n",
      "\tspeed: 0.0476s/iter; left time: 205.4736s\n",
      "\titers: 300, epoch: 6 | loss: 0.0133619\n",
      "\tspeed: 0.0475s/iter; left time: 200.2932s\n",
      "\titers: 400, epoch: 6 | loss: 0.0147298\n",
      "\tspeed: 0.0474s/iter; left time: 195.3883s\n",
      "\titers: 500, epoch: 6 | loss: 0.0129567\n",
      "\tspeed: 0.0474s/iter; left time: 190.5601s\n",
      "\titers: 600, epoch: 6 | loss: 0.0123693\n",
      "\tspeed: 0.0474s/iter; left time: 185.9515s\n",
      "\titers: 700, epoch: 6 | loss: 0.0106462\n",
      "\tspeed: 0.0475s/iter; left time: 181.3720s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129582\n",
      "\tspeed: 0.0475s/iter; left time: 176.7794s\n",
      "\titers: 900, epoch: 6 | loss: 0.0141232\n",
      "\tspeed: 0.0476s/iter; left time: 172.4487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.0129504 Vali Loss: 0.0182900 Test Loss: 0.0199193\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0112996\n",
      "\tspeed: 0.1111s/iter; left time: 390.6785s\n",
      "\titers: 200, epoch: 7 | loss: 0.0106417\n",
      "\tspeed: 0.0474s/iter; left time: 161.9596s\n",
      "\titers: 300, epoch: 7 | loss: 0.0122807\n",
      "\tspeed: 0.0472s/iter; left time: 156.6039s\n",
      "\titers: 400, epoch: 7 | loss: 0.0110445\n",
      "\tspeed: 0.0473s/iter; left time: 152.0657s\n",
      "\titers: 500, epoch: 7 | loss: 0.0100627\n",
      "\tspeed: 0.0468s/iter; left time: 145.8580s\n",
      "\titers: 600, epoch: 7 | loss: 0.0139700\n",
      "\tspeed: 0.0465s/iter; left time: 140.3984s\n",
      "\titers: 700, epoch: 7 | loss: 0.0108820\n",
      "\tspeed: 0.0473s/iter; left time: 137.9081s\n",
      "\titers: 800, epoch: 7 | loss: 0.0082813\n",
      "\tspeed: 0.0473s/iter; left time: 133.2190s\n",
      "\titers: 900, epoch: 7 | loss: 0.0116650\n",
      "\tspeed: 0.0476s/iter; left time: 129.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.0116611 Vali Loss: 0.0171298 Test Loss: 0.0204476\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018819740042090416, rmse:0.13718505203723907, mae:0.08882778137922287, rse:0.518711507320404\n",
      "Original data scale mse:3564554.25, rmse:1888.002685546875, mae:1239.82080078125, rse:0.13286645710468292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0987037\n",
      "\tspeed: 0.0375s/iter; left time: 335.5127s\n",
      "\titers: 200, epoch: 1 | loss: 0.0884736\n",
      "\tspeed: 0.0354s/iter; left time: 312.7682s\n",
      "\titers: 300, epoch: 1 | loss: 0.0708279\n",
      "\tspeed: 0.0428s/iter; left time: 373.9243s\n",
      "\titers: 400, epoch: 1 | loss: 0.0658146\n",
      "\tspeed: 0.0354s/iter; left time: 305.8593s\n",
      "\titers: 500, epoch: 1 | loss: 0.0579624\n",
      "\tspeed: 0.0354s/iter; left time: 302.5463s\n",
      "\titers: 600, epoch: 1 | loss: 0.0521227\n",
      "\tspeed: 0.0354s/iter; left time: 298.8751s\n",
      "\titers: 700, epoch: 1 | loss: 0.0463430\n",
      "\tspeed: 0.0473s/iter; left time: 394.3204s\n",
      "\titers: 800, epoch: 1 | loss: 0.0407464\n",
      "\tspeed: 0.0478s/iter; left time: 394.2186s\n",
      "\titers: 900, epoch: 1 | loss: 0.0368132\n",
      "\tspeed: 0.0476s/iter; left time: 387.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.72s\n",
      "Steps: 904 | Train Loss: 0.0656269 Vali Loss: 0.0303077 Test Loss: 0.0346506\n",
      "Validation loss decreased (inf --> 0.030308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0314901\n",
      "\tspeed: 0.1178s/iter; left time: 946.4329s\n",
      "\titers: 200, epoch: 2 | loss: 0.0277157\n",
      "\tspeed: 0.0476s/iter; left time: 378.1330s\n",
      "\titers: 300, epoch: 2 | loss: 0.0278407\n",
      "\tspeed: 0.0474s/iter; left time: 371.7138s\n",
      "\titers: 400, epoch: 2 | loss: 0.0232088\n",
      "\tspeed: 0.0476s/iter; left time: 368.0031s\n",
      "\titers: 500, epoch: 2 | loss: 0.0220202\n",
      "\tspeed: 0.0477s/iter; left time: 364.3466s\n",
      "\titers: 600, epoch: 2 | loss: 0.0238796\n",
      "\tspeed: 0.0476s/iter; left time: 358.4986s\n",
      "\titers: 700, epoch: 2 | loss: 0.0221600\n",
      "\tspeed: 0.0474s/iter; left time: 352.2041s\n",
      "\titers: 800, epoch: 2 | loss: 0.0193208\n",
      "\tspeed: 0.0476s/iter; left time: 349.2448s\n",
      "\titers: 900, epoch: 2 | loss: 0.0164941\n",
      "\tspeed: 0.0477s/iter; left time: 345.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.0246974 Vali Loss: 0.0191642 Test Loss: 0.0209797\n",
      "Validation loss decreased (0.030308 --> 0.019164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0168466\n",
      "\tspeed: 0.1139s/iter; left time: 812.1294s\n",
      "\titers: 200, epoch: 3 | loss: 0.0170843\n",
      "\tspeed: 0.0472s/iter; left time: 332.1354s\n",
      "\titers: 300, epoch: 3 | loss: 0.0168764\n",
      "\tspeed: 0.0471s/iter; left time: 326.6742s\n",
      "\titers: 400, epoch: 3 | loss: 0.0185967\n",
      "\tspeed: 0.0472s/iter; left time: 322.6500s\n",
      "\titers: 500, epoch: 3 | loss: 0.0171801\n",
      "\tspeed: 0.0473s/iter; left time: 318.4292s\n",
      "\titers: 600, epoch: 3 | loss: 0.0186517\n",
      "\tspeed: 0.0472s/iter; left time: 313.0755s\n",
      "\titers: 700, epoch: 3 | loss: 0.0172052\n",
      "\tspeed: 0.0472s/iter; left time: 308.2848s\n",
      "\titers: 800, epoch: 3 | loss: 0.0153880\n",
      "\tspeed: 0.0472s/iter; left time: 303.3904s\n",
      "\titers: 900, epoch: 3 | loss: 0.0160327\n",
      "\tspeed: 0.0472s/iter; left time: 298.6118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.84s\n",
      "Steps: 904 | Train Loss: 0.0175482 Vali Loss: 0.0187653 Test Loss: 0.0193137\n",
      "Validation loss decreased (0.019164 --> 0.018765).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0164750\n",
      "\tspeed: 0.1144s/iter; left time: 712.5761s\n",
      "\titers: 200, epoch: 4 | loss: 0.0166649\n",
      "\tspeed: 0.0472s/iter; left time: 289.3087s\n",
      "\titers: 300, epoch: 4 | loss: 0.0179890\n",
      "\tspeed: 0.0471s/iter; left time: 283.7901s\n",
      "\titers: 400, epoch: 4 | loss: 0.0157988\n",
      "\tspeed: 0.0470s/iter; left time: 278.8068s\n",
      "\titers: 500, epoch: 4 | loss: 0.0155213\n",
      "\tspeed: 0.0472s/iter; left time: 274.9645s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151332\n",
      "\tspeed: 0.0471s/iter; left time: 269.9226s\n",
      "\titers: 700, epoch: 4 | loss: 0.0159517\n",
      "\tspeed: 0.0472s/iter; left time: 265.4620s\n",
      "\titers: 800, epoch: 4 | loss: 0.0151334\n",
      "\tspeed: 0.0472s/iter; left time: 260.7976s\n",
      "\titers: 900, epoch: 4 | loss: 0.0128318\n",
      "\tspeed: 0.0471s/iter; left time: 255.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.83s\n",
      "Steps: 904 | Train Loss: 0.0159095 Vali Loss: 0.0161542 Test Loss: 0.0184494\n",
      "Validation loss decreased (0.018765 --> 0.016154).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0147134\n",
      "\tspeed: 0.1140s/iter; left time: 607.0038s\n",
      "\titers: 200, epoch: 5 | loss: 0.0142841\n",
      "\tspeed: 0.0474s/iter; left time: 247.8148s\n",
      "\titers: 300, epoch: 5 | loss: 0.0152451\n",
      "\tspeed: 0.0474s/iter; left time: 242.8952s\n",
      "\titers: 400, epoch: 5 | loss: 0.0152598\n",
      "\tspeed: 0.0472s/iter; left time: 237.2849s\n",
      "\titers: 500, epoch: 5 | loss: 0.0143808\n",
      "\tspeed: 0.0473s/iter; left time: 233.0658s\n",
      "\titers: 600, epoch: 5 | loss: 0.0165163\n",
      "\tspeed: 0.0473s/iter; left time: 228.2278s\n",
      "\titers: 700, epoch: 5 | loss: 0.0169006\n",
      "\tspeed: 0.0475s/iter; left time: 224.3815s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150849\n",
      "\tspeed: 0.0473s/iter; left time: 218.9098s\n",
      "\titers: 900, epoch: 5 | loss: 0.0129701\n",
      "\tspeed: 0.0472s/iter; left time: 213.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0145653 Vali Loss: 0.0167866 Test Loss: 0.0182130\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0144543\n",
      "\tspeed: 0.1105s/iter; left time: 488.5565s\n",
      "\titers: 200, epoch: 6 | loss: 0.0131637\n",
      "\tspeed: 0.0477s/iter; left time: 206.2026s\n",
      "\titers: 300, epoch: 6 | loss: 0.0150082\n",
      "\tspeed: 0.0473s/iter; left time: 199.5008s\n",
      "\titers: 400, epoch: 6 | loss: 0.0124514\n",
      "\tspeed: 0.0476s/iter; left time: 196.1149s\n",
      "\titers: 500, epoch: 6 | loss: 0.0153600\n",
      "\tspeed: 0.0464s/iter; left time: 186.7413s\n",
      "\titers: 600, epoch: 6 | loss: 0.0130928\n",
      "\tspeed: 0.0473s/iter; left time: 185.3577s\n",
      "\titers: 700, epoch: 6 | loss: 0.0130013\n",
      "\tspeed: 0.0474s/iter; left time: 181.0134s\n",
      "\titers: 800, epoch: 6 | loss: 0.0135275\n",
      "\tspeed: 0.0474s/iter; left time: 176.5605s\n",
      "\titers: 900, epoch: 6 | loss: 0.0117891\n",
      "\tspeed: 0.0477s/iter; left time: 172.5988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.0134384 Vali Loss: 0.0176615 Test Loss: 0.0193987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0139532\n",
      "\tspeed: 0.1115s/iter; left time: 392.0331s\n",
      "\titers: 200, epoch: 7 | loss: 0.0113275\n",
      "\tspeed: 0.0471s/iter; left time: 160.9963s\n",
      "\titers: 300, epoch: 7 | loss: 0.0125756\n",
      "\tspeed: 0.0471s/iter; left time: 156.2567s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121575\n",
      "\tspeed: 0.0471s/iter; left time: 151.5473s\n",
      "\titers: 500, epoch: 7 | loss: 0.0122219\n",
      "\tspeed: 0.0472s/iter; left time: 147.0921s\n",
      "\titers: 600, epoch: 7 | loss: 0.0115706\n",
      "\tspeed: 0.0471s/iter; left time: 142.0904s\n",
      "\titers: 700, epoch: 7 | loss: 0.0109862\n",
      "\tspeed: 0.0473s/iter; left time: 137.8901s\n",
      "\titers: 800, epoch: 7 | loss: 0.0125606\n",
      "\tspeed: 0.0472s/iter; left time: 132.9607s\n",
      "\titers: 900, epoch: 7 | loss: 0.0116496\n",
      "\tspeed: 0.0473s/iter; left time: 128.5439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.0122618 Vali Loss: 0.0180657 Test Loss: 0.0196466\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018441960215568542, rmse:0.13580118119716644, mae:0.08805994689464569, rse:0.5134788751602173\n",
      "Original data scale mse:3233782.0, rmse:1798.27197265625, mae:1197.27587890625, rse:0.12655173242092133\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0974921\n",
      "\tspeed: 0.0825s/iter; left time: 735.7528s\n",
      "\titers: 200, epoch: 1 | loss: 0.0737297\n",
      "\tspeed: 0.0534s/iter; left time: 470.8799s\n",
      "\titers: 300, epoch: 1 | loss: 0.0746729\n",
      "\tspeed: 0.0535s/iter; left time: 466.7414s\n",
      "\titers: 400, epoch: 1 | loss: 0.0646961\n",
      "\tspeed: 0.0535s/iter; left time: 461.1368s\n",
      "\titers: 500, epoch: 1 | loss: 0.0622333\n",
      "\tspeed: 0.0535s/iter; left time: 456.1089s\n",
      "\titers: 600, epoch: 1 | loss: 0.0593816\n",
      "\tspeed: 0.0535s/iter; left time: 450.1662s\n",
      "\titers: 700, epoch: 1 | loss: 0.0558329\n",
      "\tspeed: 0.0536s/iter; left time: 445.7981s\n",
      "\titers: 800, epoch: 1 | loss: 0.0576991\n",
      "\tspeed: 0.0534s/iter; left time: 438.9984s\n",
      "\titers: 900, epoch: 1 | loss: 0.0550442\n",
      "\tspeed: 0.0536s/iter; left time: 435.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.95s\n",
      "Steps: 902 | Train Loss: 0.0695445 Vali Loss: 0.0452942 Test Loss: 0.0526632\n",
      "Validation loss decreased (inf --> 0.045294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0437670\n",
      "\tspeed: 0.1333s/iter; left time: 1069.2581s\n",
      "\titers: 200, epoch: 2 | loss: 0.0377229\n",
      "\tspeed: 0.0536s/iter; left time: 424.6213s\n",
      "\titers: 300, epoch: 2 | loss: 0.0359136\n",
      "\tspeed: 0.0535s/iter; left time: 418.1643s\n",
      "\titers: 400, epoch: 2 | loss: 0.0271950\n",
      "\tspeed: 0.0536s/iter; left time: 414.0493s\n",
      "\titers: 500, epoch: 2 | loss: 0.0231806\n",
      "\tspeed: 0.0536s/iter; left time: 408.4090s\n",
      "\titers: 600, epoch: 2 | loss: 0.0230975\n",
      "\tspeed: 0.0537s/iter; left time: 403.6334s\n",
      "\titers: 700, epoch: 2 | loss: 0.0187729\n",
      "\tspeed: 0.0538s/iter; left time: 398.8894s\n",
      "\titers: 800, epoch: 2 | loss: 0.0190174\n",
      "\tspeed: 0.0538s/iter; left time: 393.7135s\n",
      "\titers: 900, epoch: 2 | loss: 0.0191427\n",
      "\tspeed: 0.0533s/iter; left time: 384.5845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.0297272 Vali Loss: 0.0194273 Test Loss: 0.0212550\n",
      "Validation loss decreased (0.045294 --> 0.019427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185710\n",
      "\tspeed: 0.1317s/iter; left time: 937.2025s\n",
      "\titers: 200, epoch: 3 | loss: 0.0202392\n",
      "\tspeed: 0.0537s/iter; left time: 376.4998s\n",
      "\titers: 300, epoch: 3 | loss: 0.0209719\n",
      "\tspeed: 0.0536s/iter; left time: 370.9046s\n",
      "\titers: 400, epoch: 3 | loss: 0.0212731\n",
      "\tspeed: 0.0536s/iter; left time: 365.2491s\n",
      "\titers: 500, epoch: 3 | loss: 0.0211410\n",
      "\tspeed: 0.0536s/iter; left time: 360.0919s\n",
      "\titers: 600, epoch: 3 | loss: 0.0179709\n",
      "\tspeed: 0.0535s/iter; left time: 353.9707s\n",
      "\titers: 700, epoch: 3 | loss: 0.0172771\n",
      "\tspeed: 0.0535s/iter; left time: 348.9777s\n",
      "\titers: 800, epoch: 3 | loss: 0.0189959\n",
      "\tspeed: 0.0536s/iter; left time: 344.1826s\n",
      "\titers: 900, epoch: 3 | loss: 0.0183518\n",
      "\tspeed: 0.0536s/iter; left time: 338.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.0192145 Vali Loss: 0.0187917 Test Loss: 0.0198753\n",
      "Validation loss decreased (0.019427 --> 0.018792).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0182034\n",
      "\tspeed: 0.1316s/iter; left time: 817.9436s\n",
      "\titers: 200, epoch: 4 | loss: 0.0170556\n",
      "\tspeed: 0.0535s/iter; left time: 327.0335s\n",
      "\titers: 300, epoch: 4 | loss: 0.0216248\n",
      "\tspeed: 0.0536s/iter; left time: 322.5213s\n",
      "\titers: 400, epoch: 4 | loss: 0.0158034\n",
      "\tspeed: 0.0535s/iter; left time: 316.5500s\n",
      "\titers: 500, epoch: 4 | loss: 0.0156982\n",
      "\tspeed: 0.0536s/iter; left time: 311.7207s\n",
      "\titers: 600, epoch: 4 | loss: 0.0158063\n",
      "\tspeed: 0.0536s/iter; left time: 306.5031s\n",
      "\titers: 700, epoch: 4 | loss: 0.0180456\n",
      "\tspeed: 0.0536s/iter; left time: 300.7023s\n",
      "\titers: 800, epoch: 4 | loss: 0.0191916\n",
      "\tspeed: 0.0536s/iter; left time: 295.5241s\n",
      "\titers: 900, epoch: 4 | loss: 0.0169604\n",
      "\tspeed: 0.0535s/iter; left time: 289.4934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.0172478 Vali Loss: 0.0177593 Test Loss: 0.0202066\n",
      "Validation loss decreased (0.018792 --> 0.017759).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0134522\n",
      "\tspeed: 0.1338s/iter; left time: 710.7707s\n",
      "\titers: 200, epoch: 5 | loss: 0.0142919\n",
      "\tspeed: 0.0533s/iter; left time: 277.7485s\n",
      "\titers: 300, epoch: 5 | loss: 0.0167201\n",
      "\tspeed: 0.0535s/iter; left time: 273.7144s\n",
      "\titers: 400, epoch: 5 | loss: 0.0171382\n",
      "\tspeed: 0.0533s/iter; left time: 267.1030s\n",
      "\titers: 500, epoch: 5 | loss: 0.0173544\n",
      "\tspeed: 0.0534s/iter; left time: 262.2365s\n",
      "\titers: 600, epoch: 5 | loss: 0.0171960\n",
      "\tspeed: 0.0534s/iter; left time: 256.7834s\n",
      "\titers: 700, epoch: 5 | loss: 0.0171616\n",
      "\tspeed: 0.0535s/iter; left time: 251.9577s\n",
      "\titers: 800, epoch: 5 | loss: 0.0146170\n",
      "\tspeed: 0.0532s/iter; left time: 245.6127s\n",
      "\titers: 900, epoch: 5 | loss: 0.0154075\n",
      "\tspeed: 0.0531s/iter; left time: 239.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.31s\n",
      "Steps: 902 | Train Loss: 0.0157436 Vali Loss: 0.0180761 Test Loss: 0.0218641\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0139048\n",
      "\tspeed: 0.1291s/iter; left time: 569.3290s\n",
      "\titers: 200, epoch: 6 | loss: 0.0145707\n",
      "\tspeed: 0.0534s/iter; left time: 230.3934s\n",
      "\titers: 300, epoch: 6 | loss: 0.0134117\n",
      "\tspeed: 0.0537s/iter; left time: 226.3076s\n",
      "\titers: 400, epoch: 6 | loss: 0.0142503\n",
      "\tspeed: 0.0546s/iter; left time: 224.2976s\n",
      "\titers: 500, epoch: 6 | loss: 0.0131306\n",
      "\tspeed: 0.0543s/iter; left time: 217.6128s\n",
      "\titers: 600, epoch: 6 | loss: 0.0130733\n",
      "\tspeed: 0.0545s/iter; left time: 213.1281s\n",
      "\titers: 700, epoch: 6 | loss: 0.0129872\n",
      "\tspeed: 0.0543s/iter; left time: 206.8636s\n",
      "\titers: 800, epoch: 6 | loss: 0.0133410\n",
      "\tspeed: 0.0542s/iter; left time: 200.9958s\n",
      "\titers: 900, epoch: 6 | loss: 0.0126120\n",
      "\tspeed: 0.0540s/iter; left time: 195.1716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.96s\n",
      "Steps: 902 | Train Loss: 0.0142612 Vali Loss: 0.0194945 Test Loss: 0.0218930\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0139907\n",
      "\tspeed: 0.1289s/iter; left time: 452.4482s\n",
      "\titers: 200, epoch: 7 | loss: 0.0136648\n",
      "\tspeed: 0.0535s/iter; left time: 182.3061s\n",
      "\titers: 300, epoch: 7 | loss: 0.0112592\n",
      "\tspeed: 0.0535s/iter; left time: 176.9092s\n",
      "\titers: 400, epoch: 7 | loss: 0.0125166\n",
      "\tspeed: 0.0536s/iter; left time: 171.9065s\n",
      "\titers: 500, epoch: 7 | loss: 0.0131221\n",
      "\tspeed: 0.0535s/iter; left time: 166.2066s\n",
      "\titers: 600, epoch: 7 | loss: 0.0132257\n",
      "\tspeed: 0.0535s/iter; left time: 160.9143s\n",
      "\titers: 700, epoch: 7 | loss: 0.0126774\n",
      "\tspeed: 0.0535s/iter; left time: 155.5203s\n",
      "\titers: 800, epoch: 7 | loss: 0.0114170\n",
      "\tspeed: 0.0534s/iter; left time: 150.1093s\n",
      "\titers: 900, epoch: 7 | loss: 0.0112940\n",
      "\tspeed: 0.0534s/iter; left time: 144.5609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.44s\n",
      "Steps: 902 | Train Loss: 0.0128613 Vali Loss: 0.0195691 Test Loss: 0.0236121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020197875797748566, rmse:0.14211922883987427, mae:0.09424823522567749, rse:0.5377394556999207\n",
      "Original data scale mse:4201466.0, rmse:2049.747802734375, mae:1339.478515625, rse:0.14438457787036896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0880133\n",
      "\tspeed: 0.0552s/iter; left time: 492.2436s\n",
      "\titers: 200, epoch: 1 | loss: 0.0756381\n",
      "\tspeed: 0.0538s/iter; left time: 474.2967s\n",
      "\titers: 300, epoch: 1 | loss: 0.0622192\n",
      "\tspeed: 0.0536s/iter; left time: 467.7347s\n",
      "\titers: 400, epoch: 1 | loss: 0.0637600\n",
      "\tspeed: 0.0538s/iter; left time: 463.9864s\n",
      "\titers: 500, epoch: 1 | loss: 0.0594108\n",
      "\tspeed: 0.0535s/iter; left time: 456.2175s\n",
      "\titers: 600, epoch: 1 | loss: 0.0529074\n",
      "\tspeed: 0.0536s/iter; left time: 451.0078s\n",
      "\titers: 700, epoch: 1 | loss: 0.0529065\n",
      "\tspeed: 0.0538s/iter; left time: 447.7386s\n",
      "\titers: 800, epoch: 1 | loss: 0.0508091\n",
      "\tspeed: 0.0538s/iter; left time: 442.0815s\n",
      "\titers: 900, epoch: 1 | loss: 0.0500937\n",
      "\tspeed: 0.0538s/iter; left time: 436.6090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0661808 Vali Loss: 0.0413559 Test Loss: 0.0479795\n",
      "Validation loss decreased (inf --> 0.041356).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0433474\n",
      "\tspeed: 0.1356s/iter; left time: 1087.1189s\n",
      "\titers: 200, epoch: 2 | loss: 0.0373783\n",
      "\tspeed: 0.0536s/iter; left time: 424.4293s\n",
      "\titers: 300, epoch: 2 | loss: 0.0313706\n",
      "\tspeed: 0.0535s/iter; left time: 418.0906s\n",
      "\titers: 400, epoch: 2 | loss: 0.0255383\n",
      "\tspeed: 0.0536s/iter; left time: 413.6664s\n",
      "\titers: 500, epoch: 2 | loss: 0.0288372\n",
      "\tspeed: 0.0536s/iter; left time: 408.3424s\n",
      "\titers: 600, epoch: 2 | loss: 0.0199318\n",
      "\tspeed: 0.0534s/iter; left time: 401.1755s\n",
      "\titers: 700, epoch: 2 | loss: 0.0209868\n",
      "\tspeed: 0.0532s/iter; left time: 394.5953s\n",
      "\titers: 800, epoch: 2 | loss: 0.0186831\n",
      "\tspeed: 0.0535s/iter; left time: 391.5688s\n",
      "\titers: 900, epoch: 2 | loss: 0.0215274\n",
      "\tspeed: 0.0532s/iter; left time: 383.7659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.44s\n",
      "Steps: 902 | Train Loss: 0.0290190 Vali Loss: 0.0191896 Test Loss: 0.0217418\n",
      "Validation loss decreased (0.041356 --> 0.019190).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0228122\n",
      "\tspeed: 0.1339s/iter; left time: 953.0939s\n",
      "\titers: 200, epoch: 3 | loss: 0.0186541\n",
      "\tspeed: 0.0535s/iter; left time: 375.4153s\n",
      "\titers: 300, epoch: 3 | loss: 0.0188690\n",
      "\tspeed: 0.0535s/iter; left time: 370.1147s\n",
      "\titers: 400, epoch: 3 | loss: 0.0197870\n",
      "\tspeed: 0.0534s/iter; left time: 363.9003s\n",
      "\titers: 500, epoch: 3 | loss: 0.0179528\n",
      "\tspeed: 0.0534s/iter; left time: 358.7001s\n",
      "\titers: 600, epoch: 3 | loss: 0.0193526\n",
      "\tspeed: 0.0533s/iter; left time: 352.5694s\n",
      "\titers: 700, epoch: 3 | loss: 0.0176058\n",
      "\tspeed: 0.0533s/iter; left time: 347.1464s\n",
      "\titers: 800, epoch: 3 | loss: 0.0200834\n",
      "\tspeed: 0.0532s/iter; left time: 341.6545s\n",
      "\titers: 900, epoch: 3 | loss: 0.0206543\n",
      "\tspeed: 0.0533s/iter; left time: 336.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.0192441 Vali Loss: 0.0189449 Test Loss: 0.0203193\n",
      "Validation loss decreased (0.019190 --> 0.018945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0186950\n",
      "\tspeed: 0.1366s/iter; left time: 849.0916s\n",
      "\titers: 200, epoch: 4 | loss: 0.0169173\n",
      "\tspeed: 0.0533s/iter; left time: 325.8142s\n",
      "\titers: 300, epoch: 4 | loss: 0.0162353\n",
      "\tspeed: 0.0535s/iter; left time: 321.7313s\n",
      "\titers: 400, epoch: 4 | loss: 0.0181942\n",
      "\tspeed: 0.0534s/iter; left time: 315.7704s\n",
      "\titers: 500, epoch: 4 | loss: 0.0174420\n",
      "\tspeed: 0.0536s/iter; left time: 311.7832s\n",
      "\titers: 600, epoch: 4 | loss: 0.0158387\n",
      "\tspeed: 0.0537s/iter; left time: 306.9508s\n",
      "\titers: 700, epoch: 4 | loss: 0.0159433\n",
      "\tspeed: 0.0537s/iter; left time: 301.2956s\n",
      "\titers: 800, epoch: 4 | loss: 0.0187397\n",
      "\tspeed: 0.0538s/iter; left time: 296.4794s\n",
      "\titers: 900, epoch: 4 | loss: 0.0150236\n",
      "\tspeed: 0.0536s/iter; left time: 290.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.0172565 Vali Loss: 0.0178393 Test Loss: 0.0205282\n",
      "Validation loss decreased (0.018945 --> 0.017839).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0164729\n",
      "\tspeed: 0.1350s/iter; left time: 717.1105s\n",
      "\titers: 200, epoch: 5 | loss: 0.0161181\n",
      "\tspeed: 0.0533s/iter; left time: 277.8203s\n",
      "\titers: 300, epoch: 5 | loss: 0.0165497\n",
      "\tspeed: 0.0534s/iter; left time: 272.8465s\n",
      "\titers: 400, epoch: 5 | loss: 0.0168216\n",
      "\tspeed: 0.0535s/iter; left time: 268.4181s\n",
      "\titers: 500, epoch: 5 | loss: 0.0152248\n",
      "\tspeed: 0.0536s/iter; left time: 263.5084s\n",
      "\titers: 600, epoch: 5 | loss: 0.0158233\n",
      "\tspeed: 0.0535s/iter; left time: 257.3457s\n",
      "\titers: 700, epoch: 5 | loss: 0.0145402\n",
      "\tspeed: 0.0537s/iter; left time: 253.0563s\n",
      "\titers: 800, epoch: 5 | loss: 0.0146539\n",
      "\tspeed: 0.0537s/iter; left time: 247.8315s\n",
      "\titers: 900, epoch: 5 | loss: 0.0144568\n",
      "\tspeed: 0.0538s/iter; left time: 242.8567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.0156204 Vali Loss: 0.0194440 Test Loss: 0.0200516\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0173520\n",
      "\tspeed: 0.1292s/iter; left time: 570.0364s\n",
      "\titers: 200, epoch: 6 | loss: 0.0135571\n",
      "\tspeed: 0.0534s/iter; left time: 230.3637s\n",
      "\titers: 300, epoch: 6 | loss: 0.0146123\n",
      "\tspeed: 0.0534s/iter; left time: 225.0571s\n",
      "\titers: 400, epoch: 6 | loss: 0.0143503\n",
      "\tspeed: 0.0534s/iter; left time: 219.6636s\n",
      "\titers: 500, epoch: 6 | loss: 0.0160940\n",
      "\tspeed: 0.0536s/iter; left time: 214.9079s\n",
      "\titers: 600, epoch: 6 | loss: 0.0147968\n",
      "\tspeed: 0.0534s/iter; left time: 208.7783s\n",
      "\titers: 700, epoch: 6 | loss: 0.0148049\n",
      "\tspeed: 0.0533s/iter; left time: 203.1789s\n",
      "\titers: 800, epoch: 6 | loss: 0.0126878\n",
      "\tspeed: 0.0535s/iter; left time: 198.4702s\n",
      "\titers: 900, epoch: 6 | loss: 0.0131650\n",
      "\tspeed: 0.0530s/iter; left time: 191.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.0141731 Vali Loss: 0.0193749 Test Loss: 0.0208626\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0144330\n",
      "\tspeed: 0.1301s/iter; left time: 456.3769s\n",
      "\titers: 200, epoch: 7 | loss: 0.0120475\n",
      "\tspeed: 0.0534s/iter; left time: 181.9750s\n",
      "\titers: 300, epoch: 7 | loss: 0.0135179\n",
      "\tspeed: 0.0538s/iter; left time: 178.0603s\n",
      "\titers: 400, epoch: 7 | loss: 0.0155561\n",
      "\tspeed: 0.0535s/iter; left time: 171.8344s\n",
      "\titers: 500, epoch: 7 | loss: 0.0116965\n",
      "\tspeed: 0.0537s/iter; left time: 166.9060s\n",
      "\titers: 600, epoch: 7 | loss: 0.0115004\n",
      "\tspeed: 0.0537s/iter; left time: 161.5230s\n",
      "\titers: 700, epoch: 7 | loss: 0.0121655\n",
      "\tspeed: 0.0536s/iter; left time: 156.0456s\n",
      "\titers: 800, epoch: 7 | loss: 0.0107254\n",
      "\tspeed: 0.0537s/iter; left time: 150.7323s\n",
      "\titers: 900, epoch: 7 | loss: 0.0114145\n",
      "\tspeed: 0.0540s/iter; left time: 146.1563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0126369 Vali Loss: 0.0208729 Test Loss: 0.0223272\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020525574684143066, rmse:0.14326749742031097, mae:0.09577973932027817, rse:0.5420841574668884\n",
      "Original data scale mse:4258257.5, rmse:2063.5546875, mae:1360.009521484375, rse:0.1453571319580078\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3182604\n",
      "\tspeed: 0.0716s/iter; left time: 641.2754s\n",
      "\titers: 200, epoch: 1 | loss: 0.2770974\n",
      "\tspeed: 0.0420s/iter; left time: 371.7654s\n",
      "\titers: 300, epoch: 1 | loss: 0.2441429\n",
      "\tspeed: 0.0411s/iter; left time: 360.2982s\n",
      "\titers: 400, epoch: 1 | loss: 0.2138520\n",
      "\tspeed: 0.0422s/iter; left time: 365.7111s\n",
      "\titers: 500, epoch: 1 | loss: 0.1800770\n",
      "\tspeed: 0.0416s/iter; left time: 355.7371s\n",
      "\titers: 600, epoch: 1 | loss: 0.1667540\n",
      "\tspeed: 0.0421s/iter; left time: 356.5201s\n",
      "\titers: 700, epoch: 1 | loss: 0.1557548\n",
      "\tspeed: 0.0417s/iter; left time: 348.3195s\n",
      "\titers: 800, epoch: 1 | loss: 0.1619005\n",
      "\tspeed: 0.0421s/iter; left time: 347.7277s\n",
      "\titers: 900, epoch: 1 | loss: 0.1687815\n",
      "\tspeed: 0.0419s/iter; left time: 341.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 906 | Train Loss: 0.2193276 Vali Loss: 0.0159234 Test Loss: 0.0171577\n",
      "Validation loss decreased (inf --> 0.015923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1524664\n",
      "\tspeed: 0.0979s/iter; left time: 788.3034s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471833\n",
      "\tspeed: 0.0411s/iter; left time: 326.6227s\n",
      "\titers: 300, epoch: 2 | loss: 0.1178364\n",
      "\tspeed: 0.0409s/iter; left time: 321.1649s\n",
      "\titers: 400, epoch: 2 | loss: 0.1025365\n",
      "\tspeed: 0.0417s/iter; left time: 323.0284s\n",
      "\titers: 500, epoch: 2 | loss: 0.1178664\n",
      "\tspeed: 0.0410s/iter; left time: 313.9844s\n",
      "\titers: 600, epoch: 2 | loss: 0.1164678\n",
      "\tspeed: 0.0410s/iter; left time: 309.9430s\n",
      "\titers: 700, epoch: 2 | loss: 0.1081067\n",
      "\tspeed: 0.0411s/iter; left time: 306.4010s\n",
      "\titers: 800, epoch: 2 | loss: 0.1138696\n",
      "\tspeed: 0.0422s/iter; left time: 310.0353s\n",
      "\titers: 900, epoch: 2 | loss: 0.1096448\n",
      "\tspeed: 0.0423s/iter; left time: 306.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.68s\n",
      "Steps: 906 | Train Loss: 0.1213882 Vali Loss: 0.0106168 Test Loss: 0.0117372\n",
      "Validation loss decreased (0.015923 --> 0.010617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1067631\n",
      "\tspeed: 0.1017s/iter; left time: 726.9278s\n",
      "\titers: 200, epoch: 3 | loss: 0.0951836\n",
      "\tspeed: 0.0409s/iter; left time: 288.2038s\n",
      "\titers: 300, epoch: 3 | loss: 0.0984001\n",
      "\tspeed: 0.0410s/iter; left time: 284.8004s\n",
      "\titers: 400, epoch: 3 | loss: 0.0898459\n",
      "\tspeed: 0.0409s/iter; left time: 280.4395s\n",
      "\titers: 500, epoch: 3 | loss: 0.1085829\n",
      "\tspeed: 0.0406s/iter; left time: 274.2096s\n",
      "\titers: 600, epoch: 3 | loss: 0.1113385\n",
      "\tspeed: 0.0406s/iter; left time: 269.7543s\n",
      "\titers: 700, epoch: 3 | loss: 0.0902102\n",
      "\tspeed: 0.0408s/iter; left time: 267.1824s\n",
      "\titers: 800, epoch: 3 | loss: 0.0938348\n",
      "\tspeed: 0.0413s/iter; left time: 266.1449s\n",
      "\titers: 900, epoch: 3 | loss: 0.0945645\n",
      "\tspeed: 0.0407s/iter; left time: 258.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.35s\n",
      "Steps: 906 | Train Loss: 0.1017762 Vali Loss: 0.0097399 Test Loss: 0.0118244\n",
      "Validation loss decreased (0.010617 --> 0.009740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0939657\n",
      "\tspeed: 0.1211s/iter; left time: 756.2410s\n",
      "\titers: 200, epoch: 4 | loss: 0.0882766\n",
      "\tspeed: 0.0415s/iter; left time: 254.6917s\n",
      "\titers: 300, epoch: 4 | loss: 0.0982791\n",
      "\tspeed: 0.0415s/iter; left time: 251.0807s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011343\n",
      "\tspeed: 0.0423s/iter; left time: 251.5908s\n",
      "\titers: 500, epoch: 4 | loss: 0.0886876\n",
      "\tspeed: 0.0421s/iter; left time: 245.9089s\n",
      "\titers: 600, epoch: 4 | loss: 0.1053476\n",
      "\tspeed: 0.0412s/iter; left time: 236.5156s\n",
      "\titers: 700, epoch: 4 | loss: 0.1022160\n",
      "\tspeed: 0.0419s/iter; left time: 236.4574s\n",
      "\titers: 800, epoch: 4 | loss: 0.1016116\n",
      "\tspeed: 0.0415s/iter; left time: 229.9223s\n",
      "\titers: 900, epoch: 4 | loss: 0.1024074\n",
      "\tspeed: 0.0415s/iter; left time: 225.9438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.0948879 Vali Loss: 0.0091693 Test Loss: 0.0108764\n",
      "Validation loss decreased (0.009740 --> 0.009169).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859901\n",
      "\tspeed: 0.0977s/iter; left time: 521.3319s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802012\n",
      "\tspeed: 0.0419s/iter; left time: 219.6377s\n",
      "\titers: 300, epoch: 5 | loss: 0.0922981\n",
      "\tspeed: 0.0415s/iter; left time: 213.0535s\n",
      "\titers: 400, epoch: 5 | loss: 0.0850021\n",
      "\tspeed: 0.0412s/iter; left time: 207.4662s\n",
      "\titers: 500, epoch: 5 | loss: 0.0914865\n",
      "\tspeed: 0.0416s/iter; left time: 205.1606s\n",
      "\titers: 600, epoch: 5 | loss: 0.0781691\n",
      "\tspeed: 0.0411s/iter; left time: 198.9582s\n",
      "\titers: 700, epoch: 5 | loss: 0.1035452\n",
      "\tspeed: 0.0414s/iter; left time: 196.2305s\n",
      "\titers: 800, epoch: 5 | loss: 0.0874057\n",
      "\tspeed: 0.0411s/iter; left time: 190.4587s\n",
      "\titers: 900, epoch: 5 | loss: 0.0946838\n",
      "\tspeed: 0.0407s/iter; left time: 184.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.0898690 Vali Loss: 0.0101848 Test Loss: 0.0112890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777053\n",
      "\tspeed: 0.0809s/iter; left time: 358.5837s\n",
      "\titers: 200, epoch: 6 | loss: 0.0830942\n",
      "\tspeed: 0.0284s/iter; left time: 122.9781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0984198\n",
      "\tspeed: 0.0359s/iter; left time: 151.8389s\n",
      "\titers: 400, epoch: 6 | loss: 0.0952906\n",
      "\tspeed: 0.0341s/iter; left time: 140.9086s\n",
      "\titers: 500, epoch: 6 | loss: 0.0854248\n",
      "\tspeed: 0.0284s/iter; left time: 114.5715s\n",
      "\titers: 600, epoch: 6 | loss: 0.0935238\n",
      "\tspeed: 0.0284s/iter; left time: 111.6021s\n",
      "\titers: 700, epoch: 6 | loss: 0.0869963\n",
      "\tspeed: 0.0284s/iter; left time: 108.9317s\n",
      "\titers: 800, epoch: 6 | loss: 0.0817814\n",
      "\tspeed: 0.0284s/iter; left time: 106.0273s\n",
      "\titers: 900, epoch: 6 | loss: 0.0914296\n",
      "\tspeed: 0.0284s/iter; left time: 103.1880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.25s\n",
      "Steps: 906 | Train Loss: 0.0859213 Vali Loss: 0.0103888 Test Loss: 0.0133877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0810883\n",
      "\tspeed: 0.0930s/iter; left time: 327.8318s\n",
      "\titers: 200, epoch: 7 | loss: 0.0840721\n",
      "\tspeed: 0.0415s/iter; left time: 141.9881s\n",
      "\titers: 300, epoch: 7 | loss: 0.0760165\n",
      "\tspeed: 0.0411s/iter; left time: 136.7089s\n",
      "\titers: 400, epoch: 7 | loss: 0.0797312\n",
      "\tspeed: 0.0414s/iter; left time: 133.3998s\n",
      "\titers: 500, epoch: 7 | loss: 0.0769169\n",
      "\tspeed: 0.0415s/iter; left time: 129.8118s\n",
      "\titers: 600, epoch: 7 | loss: 0.0663107\n",
      "\tspeed: 0.0411s/iter; left time: 124.3310s\n",
      "\titers: 700, epoch: 7 | loss: 0.0769300\n",
      "\tspeed: 0.0407s/iter; left time: 118.9592s\n",
      "\titers: 800, epoch: 7 | loss: 0.0851740\n",
      "\tspeed: 0.0419s/iter; left time: 118.4615s\n",
      "\titers: 900, epoch: 7 | loss: 0.0794168\n",
      "\tspeed: 0.0416s/iter; left time: 113.2410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0821731 Vali Loss: 0.0096805 Test Loss: 0.0119052\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010888553224503994, rmse:0.10434822738170624, mae:0.0634869635105133, rse:0.39433926343917847\n",
      "Original data scale mse:1534866.75, rmse:1238.8973388671875, mae:812.377197265625, rse:0.08706024289131165\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3249058\n",
      "\tspeed: 0.0429s/iter; left time: 384.3226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2643020\n",
      "\tspeed: 0.0407s/iter; left time: 360.6692s\n",
      "\titers: 300, epoch: 1 | loss: 0.2268334\n",
      "\tspeed: 0.0412s/iter; left time: 360.7888s\n",
      "\titers: 400, epoch: 1 | loss: 0.1881913\n",
      "\tspeed: 0.0415s/iter; left time: 359.5493s\n",
      "\titers: 500, epoch: 1 | loss: 0.1727815\n",
      "\tspeed: 0.0408s/iter; left time: 349.4728s\n",
      "\titers: 600, epoch: 1 | loss: 0.1763984\n",
      "\tspeed: 0.0418s/iter; left time: 353.4515s\n",
      "\titers: 700, epoch: 1 | loss: 0.1701801\n",
      "\tspeed: 0.0424s/iter; left time: 354.6989s\n",
      "\titers: 800, epoch: 1 | loss: 0.1725375\n",
      "\tspeed: 0.0425s/iter; left time: 350.7218s\n",
      "\titers: 900, epoch: 1 | loss: 0.1567586\n",
      "\tspeed: 0.0423s/iter; left time: 344.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 906 | Train Loss: 0.2171405 Vali Loss: 0.0161332 Test Loss: 0.0176991\n",
      "Validation loss decreased (inf --> 0.016133).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1346782\n",
      "\tspeed: 0.0992s/iter; left time: 799.1743s\n",
      "\titers: 200, epoch: 2 | loss: 0.1427562\n",
      "\tspeed: 0.0440s/iter; left time: 349.8737s\n",
      "\titers: 300, epoch: 2 | loss: 0.1232258\n",
      "\tspeed: 0.0448s/iter; left time: 351.7260s\n",
      "\titers: 400, epoch: 2 | loss: 0.1206460\n",
      "\tspeed: 0.0413s/iter; left time: 319.9968s\n",
      "\titers: 500, epoch: 2 | loss: 0.1229743\n",
      "\tspeed: 0.0420s/iter; left time: 321.1400s\n",
      "\titers: 600, epoch: 2 | loss: 0.0942307\n",
      "\tspeed: 0.0413s/iter; left time: 312.3597s\n",
      "\titers: 700, epoch: 2 | loss: 0.1056243\n",
      "\tspeed: 0.0417s/iter; left time: 310.7263s\n",
      "\titers: 800, epoch: 2 | loss: 0.0898980\n",
      "\tspeed: 0.0420s/iter; left time: 308.8767s\n",
      "\titers: 900, epoch: 2 | loss: 0.0971111\n",
      "\tspeed: 0.0415s/iter; left time: 301.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 906 | Train Loss: 0.1220734 Vali Loss: 0.0107910 Test Loss: 0.0118928\n",
      "Validation loss decreased (0.016133 --> 0.010791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0994909\n",
      "\tspeed: 0.1011s/iter; left time: 723.0283s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011429\n",
      "\tspeed: 0.0422s/iter; left time: 297.6204s\n",
      "\titers: 300, epoch: 3 | loss: 0.1120767\n",
      "\tspeed: 0.0424s/iter; left time: 294.3011s\n",
      "\titers: 400, epoch: 3 | loss: 0.0906715\n",
      "\tspeed: 0.0421s/iter; left time: 288.2626s\n",
      "\titers: 500, epoch: 3 | loss: 0.0948843\n",
      "\tspeed: 0.0425s/iter; left time: 286.5540s\n",
      "\titers: 600, epoch: 3 | loss: 0.0924422\n",
      "\tspeed: 0.0424s/iter; left time: 282.0193s\n",
      "\titers: 700, epoch: 3 | loss: 0.0997984\n",
      "\tspeed: 0.0419s/iter; left time: 274.1567s\n",
      "\titers: 800, epoch: 3 | loss: 0.1009684\n",
      "\tspeed: 0.0421s/iter; left time: 271.3685s\n",
      "\titers: 900, epoch: 3 | loss: 0.1017207\n",
      "\tspeed: 0.0422s/iter; left time: 267.7834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 906 | Train Loss: 0.1023464 Vali Loss: 0.0095821 Test Loss: 0.0107349\n",
      "Validation loss decreased (0.010791 --> 0.009582).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117368\n",
      "\tspeed: 0.1050s/iter; left time: 655.4046s\n",
      "\titers: 200, epoch: 4 | loss: 0.0998291\n",
      "\tspeed: 0.0428s/iter; left time: 262.9923s\n",
      "\titers: 300, epoch: 4 | loss: 0.1429095\n",
      "\tspeed: 0.0424s/iter; left time: 256.0993s\n",
      "\titers: 400, epoch: 4 | loss: 0.0983246\n",
      "\tspeed: 0.0424s/iter; left time: 251.8715s\n",
      "\titers: 500, epoch: 4 | loss: 0.1017309\n",
      "\tspeed: 0.0428s/iter; left time: 249.8884s\n",
      "\titers: 600, epoch: 4 | loss: 0.0921886\n",
      "\tspeed: 0.0422s/iter; left time: 242.1613s\n",
      "\titers: 700, epoch: 4 | loss: 0.0749214\n",
      "\tspeed: 0.0428s/iter; left time: 241.4805s\n",
      "\titers: 800, epoch: 4 | loss: 0.0893823\n",
      "\tspeed: 0.0412s/iter; left time: 228.4818s\n",
      "\titers: 900, epoch: 4 | loss: 0.0917266\n",
      "\tspeed: 0.0421s/iter; left time: 228.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 906 | Train Loss: 0.0965951 Vali Loss: 0.0100754 Test Loss: 0.0116149\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0910494\n",
      "\tspeed: 0.0948s/iter; left time: 505.8962s\n",
      "\titers: 200, epoch: 5 | loss: 0.1032694\n",
      "\tspeed: 0.0415s/iter; left time: 217.5820s\n",
      "\titers: 300, epoch: 5 | loss: 0.0915657\n",
      "\tspeed: 0.0419s/iter; left time: 215.3326s\n",
      "\titers: 400, epoch: 5 | loss: 0.0895251\n",
      "\tspeed: 0.0423s/iter; left time: 213.2501s\n",
      "\titers: 500, epoch: 5 | loss: 0.0972055\n",
      "\tspeed: 0.0421s/iter; left time: 208.0637s\n",
      "\titers: 600, epoch: 5 | loss: 0.0843432\n",
      "\tspeed: 0.0420s/iter; left time: 203.1072s\n",
      "\titers: 700, epoch: 5 | loss: 0.1003992\n",
      "\tspeed: 0.0419s/iter; left time: 198.3618s\n",
      "\titers: 800, epoch: 5 | loss: 0.0822892\n",
      "\tspeed: 0.0410s/iter; left time: 190.1573s\n",
      "\titers: 900, epoch: 5 | loss: 0.0875018\n",
      "\tspeed: 0.0412s/iter; left time: 186.7643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.0912888 Vali Loss: 0.0095399 Test Loss: 0.0112318\n",
      "Validation loss decreased (0.009582 --> 0.009540).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0916704\n",
      "\tspeed: 0.0987s/iter; left time: 437.2875s\n",
      "\titers: 200, epoch: 6 | loss: 0.0794364\n",
      "\tspeed: 0.0413s/iter; left time: 178.6745s\n",
      "\titers: 300, epoch: 6 | loss: 0.0904049\n",
      "\tspeed: 0.0420s/iter; left time: 177.6642s\n",
      "\titers: 400, epoch: 6 | loss: 0.0893343\n",
      "\tspeed: 0.0416s/iter; left time: 171.6832s\n",
      "\titers: 500, epoch: 6 | loss: 0.0879736\n",
      "\tspeed: 0.0416s/iter; left time: 167.7502s\n",
      "\titers: 600, epoch: 6 | loss: 0.0845218\n",
      "\tspeed: 0.0408s/iter; left time: 160.3519s\n",
      "\titers: 700, epoch: 6 | loss: 0.0837633\n",
      "\tspeed: 0.0420s/iter; left time: 160.7438s\n",
      "\titers: 800, epoch: 6 | loss: 0.0816363\n",
      "\tspeed: 0.0412s/iter; left time: 153.6590s\n",
      "\titers: 900, epoch: 6 | loss: 0.0853578\n",
      "\tspeed: 0.0406s/iter; left time: 147.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 906 | Train Loss: 0.0881462 Vali Loss: 0.0098351 Test Loss: 0.0113337\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776963\n",
      "\tspeed: 0.0951s/iter; left time: 335.1890s\n",
      "\titers: 200, epoch: 7 | loss: 0.0805482\n",
      "\tspeed: 0.0417s/iter; left time: 142.9027s\n",
      "\titers: 300, epoch: 7 | loss: 0.0822162\n",
      "\tspeed: 0.0417s/iter; left time: 138.7009s\n",
      "\titers: 400, epoch: 7 | loss: 0.0841111\n",
      "\tspeed: 0.0413s/iter; left time: 133.1032s\n",
      "\titers: 500, epoch: 7 | loss: 0.0785663\n",
      "\tspeed: 0.0413s/iter; left time: 129.0893s\n",
      "\titers: 600, epoch: 7 | loss: 0.0783009\n",
      "\tspeed: 0.0414s/iter; left time: 125.1993s\n",
      "\titers: 700, epoch: 7 | loss: 0.0904575\n",
      "\tspeed: 0.0419s/iter; left time: 122.4429s\n",
      "\titers: 800, epoch: 7 | loss: 0.0775695\n",
      "\tspeed: 0.0412s/iter; left time: 116.5235s\n",
      "\titers: 900, epoch: 7 | loss: 0.0721560\n",
      "\tspeed: 0.0413s/iter; left time: 112.6520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0841262 Vali Loss: 0.0105104 Test Loss: 0.0121925\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777827\n",
      "\tspeed: 0.0943s/iter; left time: 246.8707s\n",
      "\titers: 200, epoch: 8 | loss: 0.0705804\n",
      "\tspeed: 0.0416s/iter; left time: 104.7503s\n",
      "\titers: 300, epoch: 8 | loss: 0.0777941\n",
      "\tspeed: 0.0419s/iter; left time: 101.4501s\n",
      "\titers: 400, epoch: 8 | loss: 0.0780481\n",
      "\tspeed: 0.0418s/iter; left time: 96.9204s\n",
      "\titers: 500, epoch: 8 | loss: 0.0863282\n",
      "\tspeed: 0.0415s/iter; left time: 92.0732s\n",
      "\titers: 600, epoch: 8 | loss: 0.0793224\n",
      "\tspeed: 0.0420s/iter; left time: 88.9502s\n",
      "\titers: 700, epoch: 8 | loss: 0.0807142\n",
      "\tspeed: 0.0417s/iter; left time: 84.2875s\n",
      "\titers: 800, epoch: 8 | loss: 0.0704703\n",
      "\tspeed: 0.0423s/iter; left time: 81.2521s\n",
      "\titers: 900, epoch: 8 | loss: 0.0806989\n",
      "\tspeed: 0.0421s/iter; left time: 76.5006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 906 | Train Loss: 0.0803950 Vali Loss: 0.0100393 Test Loss: 0.0121175\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011233567260205746, rmse:0.1059885248541832, mae:0.06507769227027893, rse:0.40053799748420715\n",
      "Original data scale mse:1773736.375, rmse:1331.81689453125, mae:851.7637939453125, rse:0.0935899168252945\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3093516\n",
      "\tspeed: 0.0791s/iter; left time: 707.2536s\n",
      "\titers: 200, epoch: 1 | loss: 0.2738091\n",
      "\tspeed: 0.0475s/iter; left time: 420.1360s\n",
      "\titers: 300, epoch: 1 | loss: 0.2461182\n",
      "\tspeed: 0.0474s/iter; left time: 414.1914s\n",
      "\titers: 400, epoch: 1 | loss: 0.2357789\n",
      "\tspeed: 0.0473s/iter; left time: 408.7942s\n",
      "\titers: 500, epoch: 1 | loss: 0.2247297\n",
      "\tspeed: 0.0472s/iter; left time: 403.0200s\n",
      "\titers: 600, epoch: 1 | loss: 0.2151177\n",
      "\tspeed: 0.0472s/iter; left time: 398.5754s\n",
      "\titers: 700, epoch: 1 | loss: 0.2076221\n",
      "\tspeed: 0.0473s/iter; left time: 394.3565s\n",
      "\titers: 800, epoch: 1 | loss: 0.2049244\n",
      "\tspeed: 0.0470s/iter; left time: 387.1357s\n",
      "\titers: 900, epoch: 1 | loss: 0.2059878\n",
      "\tspeed: 0.0472s/iter; left time: 384.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.65s\n",
      "Steps: 904 | Train Loss: 0.2443136 Vali Loss: 0.0333227 Test Loss: 0.0384182\n",
      "Validation loss decreased (inf --> 0.033323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1822715\n",
      "\tspeed: 0.1152s/iter; left time: 926.2195s\n",
      "\titers: 200, epoch: 2 | loss: 0.1671452\n",
      "\tspeed: 0.0474s/iter; left time: 376.0191s\n",
      "\titers: 300, epoch: 2 | loss: 0.1565934\n",
      "\tspeed: 0.0474s/iter; left time: 371.1391s\n",
      "\titers: 400, epoch: 2 | loss: 0.1451148\n",
      "\tspeed: 0.0471s/iter; left time: 364.3411s\n",
      "\titers: 500, epoch: 2 | loss: 0.1437272\n",
      "\tspeed: 0.0472s/iter; left time: 360.7014s\n",
      "\titers: 600, epoch: 2 | loss: 0.1491941\n",
      "\tspeed: 0.0473s/iter; left time: 356.6832s\n",
      "\titers: 700, epoch: 2 | loss: 0.1374314\n",
      "\tspeed: 0.0473s/iter; left time: 351.9057s\n",
      "\titers: 800, epoch: 2 | loss: 0.1391107\n",
      "\tspeed: 0.0473s/iter; left time: 347.0267s\n",
      "\titers: 900, epoch: 2 | loss: 0.1286135\n",
      "\tspeed: 0.0473s/iter; left time: 342.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 904 | Train Loss: 0.1541158 Vali Loss: 0.0181501 Test Loss: 0.0187154\n",
      "Validation loss decreased (0.033323 --> 0.018150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1340026\n",
      "\tspeed: 0.1231s/iter; left time: 877.9084s\n",
      "\titers: 200, epoch: 3 | loss: 0.1307715\n",
      "\tspeed: 0.0474s/iter; left time: 333.6583s\n",
      "\titers: 300, epoch: 3 | loss: 0.1367581\n",
      "\tspeed: 0.0475s/iter; left time: 329.4653s\n",
      "\titers: 400, epoch: 3 | loss: 0.1319982\n",
      "\tspeed: 0.0474s/iter; left time: 323.8161s\n",
      "\titers: 500, epoch: 3 | loss: 0.1290497\n",
      "\tspeed: 0.0473s/iter; left time: 318.5530s\n",
      "\titers: 600, epoch: 3 | loss: 0.1244611\n",
      "\tspeed: 0.0473s/iter; left time: 314.0446s\n",
      "\titers: 700, epoch: 3 | loss: 0.1183973\n",
      "\tspeed: 0.0475s/iter; left time: 310.1993s\n",
      "\titers: 800, epoch: 3 | loss: 0.1375077\n",
      "\tspeed: 0.0475s/iter; left time: 305.4937s\n",
      "\titers: 900, epoch: 3 | loss: 0.1373645\n",
      "\tspeed: 0.0477s/iter; left time: 301.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.1296189 Vali Loss: 0.0169026 Test Loss: 0.0189925\n",
      "Validation loss decreased (0.018150 --> 0.016903).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1206669\n",
      "\tspeed: 0.1193s/iter; left time: 743.0393s\n",
      "\titers: 200, epoch: 4 | loss: 0.1230979\n",
      "\tspeed: 0.0504s/iter; left time: 309.1026s\n",
      "\titers: 300, epoch: 4 | loss: 0.1206558\n",
      "\tspeed: 0.0505s/iter; left time: 304.4835s\n",
      "\titers: 400, epoch: 4 | loss: 0.1287496\n",
      "\tspeed: 0.0504s/iter; left time: 299.0186s\n",
      "\titers: 500, epoch: 4 | loss: 0.1311547\n",
      "\tspeed: 0.0505s/iter; left time: 294.1444s\n",
      "\titers: 600, epoch: 4 | loss: 0.1281368\n",
      "\tspeed: 0.0505s/iter; left time: 289.2386s\n",
      "\titers: 700, epoch: 4 | loss: 0.1205751\n",
      "\tspeed: 0.0475s/iter; left time: 267.5811s\n",
      "\titers: 800, epoch: 4 | loss: 0.1238125\n",
      "\tspeed: 0.0469s/iter; left time: 259.3429s\n",
      "\titers: 900, epoch: 4 | loss: 0.1135014\n",
      "\tspeed: 0.0473s/iter; left time: 256.9885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 904 | Train Loss: 0.1227720 Vali Loss: 0.0161618 Test Loss: 0.0187646\n",
      "Validation loss decreased (0.016903 --> 0.016162).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1118904\n",
      "\tspeed: 0.1154s/iter; left time: 614.6522s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183519\n",
      "\tspeed: 0.0473s/iter; left time: 247.1001s\n",
      "\titers: 300, epoch: 5 | loss: 0.1187731\n",
      "\tspeed: 0.0472s/iter; left time: 242.0070s\n",
      "\titers: 400, epoch: 5 | loss: 0.1281916\n",
      "\tspeed: 0.0466s/iter; left time: 234.1237s\n",
      "\titers: 500, epoch: 5 | loss: 0.1133893\n",
      "\tspeed: 0.0409s/iter; left time: 201.5333s\n",
      "\titers: 600, epoch: 5 | loss: 0.1150367\n",
      "\tspeed: 0.0354s/iter; left time: 170.8016s\n",
      "\titers: 700, epoch: 5 | loss: 0.1234257\n",
      "\tspeed: 0.0354s/iter; left time: 167.3867s\n",
      "\titers: 800, epoch: 5 | loss: 0.1167801\n",
      "\tspeed: 0.0354s/iter; left time: 163.6354s\n",
      "\titers: 900, epoch: 5 | loss: 0.1119384\n",
      "\tspeed: 0.0353s/iter; left time: 159.8321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.41s\n",
      "Steps: 904 | Train Loss: 0.1166390 Vali Loss: 0.0180569 Test Loss: 0.0201445\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0955252\n",
      "\tspeed: 0.1115s/iter; left time: 492.8507s\n",
      "\titers: 200, epoch: 6 | loss: 0.1180441\n",
      "\tspeed: 0.0473s/iter; left time: 204.3640s\n",
      "\titers: 300, epoch: 6 | loss: 0.1125253\n",
      "\tspeed: 0.0470s/iter; left time: 198.5857s\n",
      "\titers: 400, epoch: 6 | loss: 0.1174403\n",
      "\tspeed: 0.0474s/iter; left time: 195.1706s\n",
      "\titers: 500, epoch: 6 | loss: 0.1112897\n",
      "\tspeed: 0.0472s/iter; left time: 189.6462s\n",
      "\titers: 600, epoch: 6 | loss: 0.1109653\n",
      "\tspeed: 0.0472s/iter; left time: 185.0726s\n",
      "\titers: 700, epoch: 6 | loss: 0.0987567\n",
      "\tspeed: 0.0470s/iter; left time: 179.4818s\n",
      "\titers: 800, epoch: 6 | loss: 0.1128278\n",
      "\tspeed: 0.0470s/iter; left time: 175.0519s\n",
      "\titers: 900, epoch: 6 | loss: 0.1145909\n",
      "\tspeed: 0.0463s/iter; left time: 167.7519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.76s\n",
      "Steps: 904 | Train Loss: 0.1111408 Vali Loss: 0.0182058 Test Loss: 0.0206058\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026105\n",
      "\tspeed: 0.1121s/iter; left time: 394.2949s\n",
      "\titers: 200, epoch: 7 | loss: 0.1005317\n",
      "\tspeed: 0.0474s/iter; left time: 161.8218s\n",
      "\titers: 300, epoch: 7 | loss: 0.1091398\n",
      "\tspeed: 0.0473s/iter; left time: 156.8418s\n",
      "\titers: 400, epoch: 7 | loss: 0.1002923\n",
      "\tspeed: 0.0472s/iter; left time: 151.7066s\n",
      "\titers: 500, epoch: 7 | loss: 0.1028722\n",
      "\tspeed: 0.0474s/iter; left time: 147.8414s\n",
      "\titers: 600, epoch: 7 | loss: 0.1124648\n",
      "\tspeed: 0.0472s/iter; left time: 142.4139s\n",
      "\titers: 700, epoch: 7 | loss: 0.0987508\n",
      "\tspeed: 0.0472s/iter; left time: 137.5483s\n",
      "\titers: 800, epoch: 7 | loss: 0.0898055\n",
      "\tspeed: 0.0473s/iter; left time: 133.3129s\n",
      "\titers: 900, epoch: 7 | loss: 0.1027407\n",
      "\tspeed: 0.0470s/iter; left time: 127.8326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.1049334 Vali Loss: 0.0180185 Test Loss: 0.0222405\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01876760646700859, rmse:0.13699491322040558, mae:0.08846016228199005, rse:0.5179925560951233\n",
      "Original data scale mse:3390077.0, rmse:1841.2161865234375, mae:1212.3902587890625, rse:0.12957391142845154\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3128209\n",
      "\tspeed: 0.0494s/iter; left time: 441.3614s\n",
      "\titers: 200, epoch: 1 | loss: 0.2955156\n",
      "\tspeed: 0.0476s/iter; left time: 420.9630s\n",
      "\titers: 300, epoch: 1 | loss: 0.2620749\n",
      "\tspeed: 0.0477s/iter; left time: 417.1716s\n",
      "\titers: 400, epoch: 1 | loss: 0.2516717\n",
      "\tspeed: 0.0476s/iter; left time: 411.4821s\n",
      "\titers: 500, epoch: 1 | loss: 0.2320990\n",
      "\tspeed: 0.0477s/iter; left time: 407.6792s\n",
      "\titers: 600, epoch: 1 | loss: 0.2213243\n",
      "\tspeed: 0.0476s/iter; left time: 401.7715s\n",
      "\titers: 700, epoch: 1 | loss: 0.2081433\n",
      "\tspeed: 0.0466s/iter; left time: 389.0156s\n",
      "\titers: 800, epoch: 1 | loss: 0.1962108\n",
      "\tspeed: 0.0476s/iter; left time: 392.1444s\n",
      "\titers: 900, epoch: 1 | loss: 0.1879538\n",
      "\tspeed: 0.0474s/iter; left time: 385.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.2476883 Vali Loss: 0.0290575 Test Loss: 0.0331817\n",
      "Validation loss decreased (inf --> 0.029058).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1764619\n",
      "\tspeed: 0.1160s/iter; left time: 932.3588s\n",
      "\titers: 200, epoch: 2 | loss: 0.1683673\n",
      "\tspeed: 0.0470s/iter; left time: 373.2908s\n",
      "\titers: 300, epoch: 2 | loss: 0.1619842\n",
      "\tspeed: 0.0472s/iter; left time: 369.8399s\n",
      "\titers: 400, epoch: 2 | loss: 0.1518464\n",
      "\tspeed: 0.0473s/iter; left time: 366.2454s\n",
      "\titers: 500, epoch: 2 | loss: 0.1466087\n",
      "\tspeed: 0.0471s/iter; left time: 359.6874s\n",
      "\titers: 600, epoch: 2 | loss: 0.1508116\n",
      "\tspeed: 0.0468s/iter; left time: 352.9120s\n",
      "\titers: 700, epoch: 2 | loss: 0.1465930\n",
      "\tspeed: 0.0471s/iter; left time: 350.5781s\n",
      "\titers: 800, epoch: 2 | loss: 0.1357613\n",
      "\tspeed: 0.0472s/iter; left time: 346.4459s\n",
      "\titers: 900, epoch: 2 | loss: 0.1240935\n",
      "\tspeed: 0.0469s/iter; left time: 339.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 904 | Train Loss: 0.1536848 Vali Loss: 0.0179040 Test Loss: 0.0197165\n",
      "Validation loss decreased (0.029058 --> 0.017904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1294200\n",
      "\tspeed: 0.1192s/iter; left time: 849.9884s\n",
      "\titers: 200, epoch: 3 | loss: 0.1286483\n",
      "\tspeed: 0.0478s/iter; left time: 336.0429s\n",
      "\titers: 300, epoch: 3 | loss: 0.1275968\n",
      "\tspeed: 0.0474s/iter; left time: 328.7727s\n",
      "\titers: 400, epoch: 3 | loss: 0.1349039\n",
      "\tspeed: 0.0479s/iter; left time: 327.1305s\n",
      "\titers: 500, epoch: 3 | loss: 0.1299272\n",
      "\tspeed: 0.0478s/iter; left time: 321.7381s\n",
      "\titers: 600, epoch: 3 | loss: 0.1388921\n",
      "\tspeed: 0.0476s/iter; left time: 315.8851s\n",
      "\titers: 700, epoch: 3 | loss: 0.1323673\n",
      "\tspeed: 0.0477s/iter; left time: 311.5752s\n",
      "\titers: 800, epoch: 3 | loss: 0.1230982\n",
      "\tspeed: 0.0478s/iter; left time: 307.5521s\n",
      "\titers: 900, epoch: 3 | loss: 0.1216354\n",
      "\tspeed: 0.0463s/iter; left time: 293.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.1304383 Vali Loss: 0.0174966 Test Loss: 0.0184413\n",
      "Validation loss decreased (0.017904 --> 0.017497).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1273170\n",
      "\tspeed: 0.1157s/iter; left time: 720.9661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1274066\n",
      "\tspeed: 0.0473s/iter; left time: 290.0291s\n",
      "\titers: 300, epoch: 4 | loss: 0.1370937\n",
      "\tspeed: 0.0475s/iter; left time: 286.5481s\n",
      "\titers: 400, epoch: 4 | loss: 0.1244887\n",
      "\tspeed: 0.0475s/iter; left time: 281.7104s\n",
      "\titers: 500, epoch: 4 | loss: 0.1210962\n",
      "\tspeed: 0.0470s/iter; left time: 274.1290s\n",
      "\titers: 600, epoch: 4 | loss: 0.1220659\n",
      "\tspeed: 0.0472s/iter; left time: 270.5318s\n",
      "\titers: 700, epoch: 4 | loss: 0.1266540\n",
      "\tspeed: 0.0475s/iter; left time: 267.6302s\n",
      "\titers: 800, epoch: 4 | loss: 0.1187862\n",
      "\tspeed: 0.0474s/iter; left time: 262.2091s\n",
      "\titers: 900, epoch: 4 | loss: 0.1119336\n",
      "\tspeed: 0.0472s/iter; left time: 256.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.02s\n",
      "Steps: 904 | Train Loss: 0.1242702 Vali Loss: 0.0162720 Test Loss: 0.0183281\n",
      "Validation loss decreased (0.017497 --> 0.016272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1207941\n",
      "\tspeed: 0.1168s/iter; left time: 621.8121s\n",
      "\titers: 200, epoch: 5 | loss: 0.1195423\n",
      "\tspeed: 0.0474s/iter; left time: 247.7547s\n",
      "\titers: 300, epoch: 5 | loss: 0.1203133\n",
      "\tspeed: 0.0473s/iter; left time: 242.5092s\n",
      "\titers: 400, epoch: 5 | loss: 0.1215813\n",
      "\tspeed: 0.0474s/iter; left time: 238.3320s\n",
      "\titers: 500, epoch: 5 | loss: 0.1187193\n",
      "\tspeed: 0.0476s/iter; left time: 234.4606s\n",
      "\titers: 600, epoch: 5 | loss: 0.1240349\n",
      "\tspeed: 0.0477s/iter; left time: 230.1495s\n",
      "\titers: 700, epoch: 5 | loss: 0.1272121\n",
      "\tspeed: 0.0456s/iter; left time: 215.2866s\n",
      "\titers: 800, epoch: 5 | loss: 0.1198318\n",
      "\tspeed: 0.0474s/iter; left time: 219.2031s\n",
      "\titers: 900, epoch: 5 | loss: 0.1121756\n",
      "\tspeed: 0.0474s/iter; left time: 214.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.1187592 Vali Loss: 0.0167673 Test Loss: 0.0185229\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1198316\n",
      "\tspeed: 0.1121s/iter; left time: 495.4451s\n",
      "\titers: 200, epoch: 6 | loss: 0.1141960\n",
      "\tspeed: 0.0472s/iter; left time: 203.8468s\n",
      "\titers: 300, epoch: 6 | loss: 0.1226976\n",
      "\tspeed: 0.0474s/iter; left time: 200.1406s\n",
      "\titers: 400, epoch: 6 | loss: 0.1084806\n",
      "\tspeed: 0.0473s/iter; left time: 194.8309s\n",
      "\titers: 500, epoch: 6 | loss: 0.1220213\n",
      "\tspeed: 0.0473s/iter; left time: 190.0457s\n",
      "\titers: 600, epoch: 6 | loss: 0.1114138\n",
      "\tspeed: 0.0474s/iter; left time: 185.9047s\n",
      "\titers: 700, epoch: 6 | loss: 0.1136626\n",
      "\tspeed: 0.0459s/iter; left time: 175.2370s\n",
      "\titers: 800, epoch: 6 | loss: 0.1129887\n",
      "\tspeed: 0.0473s/iter; left time: 175.9469s\n",
      "\titers: 900, epoch: 6 | loss: 0.1044783\n",
      "\tspeed: 0.0475s/iter; left time: 172.0149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.1139844 Vali Loss: 0.0173552 Test Loss: 0.0193293\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1130000\n",
      "\tspeed: 0.1127s/iter; left time: 396.5220s\n",
      "\titers: 200, epoch: 7 | loss: 0.1024909\n",
      "\tspeed: 0.0471s/iter; left time: 160.8255s\n",
      "\titers: 300, epoch: 7 | loss: 0.1091288\n",
      "\tspeed: 0.0475s/iter; left time: 157.6906s\n",
      "\titers: 400, epoch: 7 | loss: 0.1049215\n",
      "\tspeed: 0.0474s/iter; left time: 152.5315s\n",
      "\titers: 500, epoch: 7 | loss: 0.1069582\n",
      "\tspeed: 0.0470s/iter; left time: 146.3583s\n",
      "\titers: 600, epoch: 7 | loss: 0.1061765\n",
      "\tspeed: 0.0470s/iter; left time: 141.8038s\n",
      "\titers: 700, epoch: 7 | loss: 0.1013205\n",
      "\tspeed: 0.0477s/iter; left time: 139.0143s\n",
      "\titers: 800, epoch: 7 | loss: 0.1089787\n",
      "\tspeed: 0.0476s/iter; left time: 134.1126s\n",
      "\titers: 900, epoch: 7 | loss: 0.1058136\n",
      "\tspeed: 0.0477s/iter; left time: 129.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.06s\n",
      "Steps: 904 | Train Loss: 0.1079938 Vali Loss: 0.0177931 Test Loss: 0.0200110\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018318794667720795, rmse:0.13534694910049438, mae:0.08790011703968048, rse:0.5117613673210144\n",
      "Original data scale mse:3278264.25, rmse:1810.5977783203125, mae:1197.8482666015625, rse:0.12741915881633759\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3112887\n",
      "\tspeed: 0.0825s/iter; left time: 735.6923s\n",
      "\titers: 200, epoch: 1 | loss: 0.2701333\n",
      "\tspeed: 0.0537s/iter; left time: 474.0526s\n",
      "\titers: 300, epoch: 1 | loss: 0.2705595\n",
      "\tspeed: 0.0537s/iter; left time: 468.4028s\n",
      "\titers: 400, epoch: 1 | loss: 0.2516117\n",
      "\tspeed: 0.0535s/iter; left time: 461.6536s\n",
      "\titers: 500, epoch: 1 | loss: 0.2469053\n",
      "\tspeed: 0.0536s/iter; left time: 456.6427s\n",
      "\titers: 600, epoch: 1 | loss: 0.2417244\n",
      "\tspeed: 0.0537s/iter; left time: 451.8177s\n",
      "\titers: 700, epoch: 1 | loss: 0.2345901\n",
      "\tspeed: 0.0536s/iter; left time: 445.6770s\n",
      "\titers: 800, epoch: 1 | loss: 0.2377720\n",
      "\tspeed: 0.0532s/iter; left time: 437.3073s\n",
      "\titers: 900, epoch: 1 | loss: 0.2321623\n",
      "\tspeed: 0.0536s/iter; left time: 434.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.06s\n",
      "Steps: 902 | Train Loss: 0.2595995 Vali Loss: 0.0446152 Test Loss: 0.0519481\n",
      "Validation loss decreased (inf --> 0.044615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2095231\n",
      "\tspeed: 0.1338s/iter; left time: 1073.1568s\n",
      "\titers: 200, epoch: 2 | loss: 0.1930412\n",
      "\tspeed: 0.0532s/iter; left time: 421.6841s\n",
      "\titers: 300, epoch: 2 | loss: 0.1828628\n",
      "\tspeed: 0.0529s/iter; left time: 413.9831s\n",
      "\titers: 400, epoch: 2 | loss: 0.1591913\n",
      "\tspeed: 0.0532s/iter; left time: 410.8479s\n",
      "\titers: 500, epoch: 2 | loss: 0.1478090\n",
      "\tspeed: 0.0532s/iter; left time: 405.5744s\n",
      "\titers: 600, epoch: 2 | loss: 0.1490079\n",
      "\tspeed: 0.0537s/iter; left time: 403.5480s\n",
      "\titers: 700, epoch: 2 | loss: 0.1323661\n",
      "\tspeed: 0.0519s/iter; left time: 385.0773s\n",
      "\titers: 800, epoch: 2 | loss: 0.1343427\n",
      "\tspeed: 0.0426s/iter; left time: 311.8499s\n",
      "\titers: 900, epoch: 2 | loss: 0.1348851\n",
      "\tspeed: 0.0426s/iter; left time: 307.7877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.1666839 Vali Loss: 0.0195425 Test Loss: 0.0213045\n",
      "Validation loss decreased (0.044615 --> 0.019543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1338077\n",
      "\tspeed: 0.1328s/iter; left time: 944.8767s\n",
      "\titers: 200, epoch: 3 | loss: 0.1401786\n",
      "\tspeed: 0.0538s/iter; left time: 377.2157s\n",
      "\titers: 300, epoch: 3 | loss: 0.1417433\n",
      "\tspeed: 0.0537s/iter; left time: 371.6811s\n",
      "\titers: 400, epoch: 3 | loss: 0.1445573\n",
      "\tspeed: 0.0536s/iter; left time: 365.6255s\n",
      "\titers: 500, epoch: 3 | loss: 0.1437448\n",
      "\tspeed: 0.0536s/iter; left time: 359.8686s\n",
      "\titers: 600, epoch: 3 | loss: 0.1327194\n",
      "\tspeed: 0.0499s/iter; left time: 330.3635s\n",
      "\titers: 700, epoch: 3 | loss: 0.1307158\n",
      "\tspeed: 0.0532s/iter; left time: 346.8615s\n",
      "\titers: 800, epoch: 3 | loss: 0.1380625\n",
      "\tspeed: 0.0536s/iter; left time: 343.7401s\n",
      "\titers: 900, epoch: 3 | loss: 0.1341755\n",
      "\tspeed: 0.0538s/iter; left time: 339.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.23s\n",
      "Steps: 902 | Train Loss: 0.1367471 Vali Loss: 0.0188825 Test Loss: 0.0199922\n",
      "Validation loss decreased (0.019543 --> 0.018882).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1325566\n",
      "\tspeed: 0.1370s/iter; left time: 851.7444s\n",
      "\titers: 200, epoch: 4 | loss: 0.1291571\n",
      "\tspeed: 0.0532s/iter; left time: 325.5793s\n",
      "\titers: 300, epoch: 4 | loss: 0.1449718\n",
      "\tspeed: 0.0536s/iter; left time: 322.1288s\n",
      "\titers: 400, epoch: 4 | loss: 0.1253113\n",
      "\tspeed: 0.0535s/iter; left time: 316.4423s\n",
      "\titers: 500, epoch: 4 | loss: 0.1236327\n",
      "\tspeed: 0.0533s/iter; left time: 309.8147s\n",
      "\titers: 600, epoch: 4 | loss: 0.1235445\n",
      "\tspeed: 0.0535s/iter; left time: 305.7284s\n",
      "\titers: 700, epoch: 4 | loss: 0.1320168\n",
      "\tspeed: 0.0533s/iter; left time: 299.2516s\n",
      "\titers: 800, epoch: 4 | loss: 0.1361436\n",
      "\tspeed: 0.0537s/iter; left time: 295.8888s\n",
      "\titers: 900, epoch: 4 | loss: 0.1281451\n",
      "\tspeed: 0.0536s/iter; left time: 290.1657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.1295634 Vali Loss: 0.0176831 Test Loss: 0.0205406\n",
      "Validation loss decreased (0.018882 --> 0.017683).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1150929\n",
      "\tspeed: 0.1321s/iter; left time: 702.0196s\n",
      "\titers: 200, epoch: 5 | loss: 0.1167147\n",
      "\tspeed: 0.0533s/iter; left time: 278.0462s\n",
      "\titers: 300, epoch: 5 | loss: 0.1266226\n",
      "\tspeed: 0.0537s/iter; left time: 274.3381s\n",
      "\titers: 400, epoch: 5 | loss: 0.1278830\n",
      "\tspeed: 0.0534s/iter; left time: 267.6566s\n",
      "\titers: 500, epoch: 5 | loss: 0.1277956\n",
      "\tspeed: 0.0534s/iter; left time: 262.2331s\n",
      "\titers: 600, epoch: 5 | loss: 0.1261985\n",
      "\tspeed: 0.0534s/iter; left time: 257.1861s\n",
      "\titers: 700, epoch: 5 | loss: 0.1258485\n",
      "\tspeed: 0.0534s/iter; left time: 251.4575s\n",
      "\titers: 800, epoch: 5 | loss: 0.1196405\n",
      "\tspeed: 0.0533s/iter; left time: 245.7857s\n",
      "\titers: 900, epoch: 5 | loss: 0.1235818\n",
      "\tspeed: 0.0537s/iter; left time: 242.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.44s\n",
      "Steps: 902 | Train Loss: 0.1232680 Vali Loss: 0.0182817 Test Loss: 0.0220861\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1156967\n",
      "\tspeed: 0.1298s/iter; left time: 572.3652s\n",
      "\titers: 200, epoch: 6 | loss: 0.1169142\n",
      "\tspeed: 0.0532s/iter; left time: 229.4148s\n",
      "\titers: 300, epoch: 6 | loss: 0.1136387\n",
      "\tspeed: 0.0536s/iter; left time: 225.6471s\n",
      "\titers: 400, epoch: 6 | loss: 0.1170498\n",
      "\tspeed: 0.0534s/iter; left time: 219.5016s\n",
      "\titers: 500, epoch: 6 | loss: 0.1119323\n",
      "\tspeed: 0.0534s/iter; left time: 214.2342s\n",
      "\titers: 600, epoch: 6 | loss: 0.1116978\n",
      "\tspeed: 0.0538s/iter; left time: 210.4088s\n",
      "\titers: 700, epoch: 6 | loss: 0.1114990\n",
      "\tspeed: 0.0537s/iter; left time: 204.6228s\n",
      "\titers: 800, epoch: 6 | loss: 0.1117063\n",
      "\tspeed: 0.0534s/iter; left time: 198.1729s\n",
      "\titers: 900, epoch: 6 | loss: 0.1119812\n",
      "\tspeed: 0.0534s/iter; left time: 192.8020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.1164972 Vali Loss: 0.0206008 Test Loss: 0.0228311\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1143144\n",
      "\tspeed: 0.1285s/iter; left time: 451.0081s\n",
      "\titers: 200, epoch: 7 | loss: 0.1144165\n",
      "\tspeed: 0.0531s/iter; left time: 181.1541s\n",
      "\titers: 300, epoch: 7 | loss: 0.1029689\n",
      "\tspeed: 0.0535s/iter; left time: 176.9808s\n",
      "\titers: 400, epoch: 7 | loss: 0.1095792\n",
      "\tspeed: 0.0534s/iter; left time: 171.2356s\n",
      "\titers: 500, epoch: 7 | loss: 0.1093956\n",
      "\tspeed: 0.0534s/iter; left time: 166.0192s\n",
      "\titers: 600, epoch: 7 | loss: 0.1144555\n",
      "\tspeed: 0.0533s/iter; left time: 160.4881s\n",
      "\titers: 700, epoch: 7 | loss: 0.1100785\n",
      "\tspeed: 0.0531s/iter; left time: 154.4243s\n",
      "\titers: 800, epoch: 7 | loss: 0.1042493\n",
      "\tspeed: 0.0534s/iter; left time: 149.9875s\n",
      "\titers: 900, epoch: 7 | loss: 0.1019507\n",
      "\tspeed: 0.0530s/iter; left time: 143.5090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.23s\n",
      "Steps: 902 | Train Loss: 0.1097639 Vali Loss: 0.0205848 Test Loss: 0.0239609\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020536771044135094, rmse:0.14330656826496124, mae:0.09462139755487442, rse:0.5422319769859314\n",
      "Original data scale mse:4204012.5, rmse:2050.368896484375, mae:1340.250732421875, rse:0.1444283425807953\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2946924\n",
      "\tspeed: 0.0552s/iter; left time: 492.7706s\n",
      "\titers: 200, epoch: 1 | loss: 0.2727692\n",
      "\tspeed: 0.0538s/iter; left time: 474.4335s\n",
      "\titers: 300, epoch: 1 | loss: 0.2474688\n",
      "\tspeed: 0.0538s/iter; left time: 469.5520s\n",
      "\titers: 400, epoch: 1 | loss: 0.2492456\n",
      "\tspeed: 0.0536s/iter; left time: 461.9037s\n",
      "\titers: 500, epoch: 1 | loss: 0.2408135\n",
      "\tspeed: 0.0535s/iter; left time: 456.0903s\n",
      "\titers: 600, epoch: 1 | loss: 0.2271375\n",
      "\tspeed: 0.0537s/iter; left time: 451.8885s\n",
      "\titers: 700, epoch: 1 | loss: 0.2273930\n",
      "\tspeed: 0.0536s/iter; left time: 445.9574s\n",
      "\titers: 800, epoch: 1 | loss: 0.2224111\n",
      "\tspeed: 0.0536s/iter; left time: 440.9934s\n",
      "\titers: 900, epoch: 1 | loss: 0.2213976\n",
      "\tspeed: 0.0536s/iter; left time: 435.1031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 0.2528524 Vali Loss: 0.0405547 Test Loss: 0.0472158\n",
      "Validation loss decreased (inf --> 0.040555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2126475\n",
      "\tspeed: 0.1354s/iter; left time: 1085.9551s\n",
      "\titers: 200, epoch: 2 | loss: 0.1908140\n",
      "\tspeed: 0.0536s/iter; left time: 424.4064s\n",
      "\titers: 300, epoch: 2 | loss: 0.1739328\n",
      "\tspeed: 0.0536s/iter; left time: 419.4592s\n",
      "\titers: 400, epoch: 2 | loss: 0.1522334\n",
      "\tspeed: 0.0536s/iter; left time: 413.8778s\n",
      "\titers: 500, epoch: 2 | loss: 0.1636279\n",
      "\tspeed: 0.0537s/iter; left time: 409.2218s\n",
      "\titers: 600, epoch: 2 | loss: 0.1378988\n",
      "\tspeed: 0.0536s/iter; left time: 403.0689s\n",
      "\titers: 700, epoch: 2 | loss: 0.1439680\n",
      "\tspeed: 0.0535s/iter; left time: 397.2218s\n",
      "\titers: 800, epoch: 2 | loss: 0.1361979\n",
      "\tspeed: 0.0536s/iter; left time: 391.9755s\n",
      "\titers: 900, epoch: 2 | loss: 0.1441313\n",
      "\tspeed: 0.0536s/iter; left time: 386.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.1653762 Vali Loss: 0.0199595 Test Loss: 0.0222983\n",
      "Validation loss decreased (0.040555 --> 0.019959).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1493491\n",
      "\tspeed: 0.1381s/iter; left time: 982.8557s\n",
      "\titers: 200, epoch: 3 | loss: 0.1346568\n",
      "\tspeed: 0.0536s/iter; left time: 375.8053s\n",
      "\titers: 300, epoch: 3 | loss: 0.1362912\n",
      "\tspeed: 0.0535s/iter; left time: 370.3832s\n",
      "\titers: 400, epoch: 3 | loss: 0.1394345\n",
      "\tspeed: 0.0537s/iter; left time: 365.8996s\n",
      "\titers: 500, epoch: 3 | loss: 0.1331303\n",
      "\tspeed: 0.0536s/iter; left time: 360.3122s\n",
      "\titers: 600, epoch: 3 | loss: 0.1393345\n",
      "\tspeed: 0.0536s/iter; left time: 354.4942s\n",
      "\titers: 700, epoch: 3 | loss: 0.1299409\n",
      "\tspeed: 0.0538s/iter; left time: 350.7849s\n",
      "\titers: 800, epoch: 3 | loss: 0.1384254\n",
      "\tspeed: 0.0536s/iter; left time: 343.6746s\n",
      "\titers: 900, epoch: 3 | loss: 0.1396079\n",
      "\tspeed: 0.0537s/iter; left time: 339.1172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.1366752 Vali Loss: 0.0187700 Test Loss: 0.0201410\n",
      "Validation loss decreased (0.019959 --> 0.018770).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1338240\n",
      "\tspeed: 0.1717s/iter; left time: 1067.1219s\n",
      "\titers: 200, epoch: 4 | loss: 0.1282149\n",
      "\tspeed: 0.0536s/iter; left time: 327.9180s\n",
      "\titers: 300, epoch: 4 | loss: 0.1255529\n",
      "\tspeed: 0.0537s/iter; left time: 322.7052s\n",
      "\titers: 400, epoch: 4 | loss: 0.1347245\n",
      "\tspeed: 0.0536s/iter; left time: 317.0174s\n",
      "\titers: 500, epoch: 4 | loss: 0.1311705\n",
      "\tspeed: 0.0537s/iter; left time: 312.0740s\n",
      "\titers: 600, epoch: 4 | loss: 0.1248666\n",
      "\tspeed: 0.0536s/iter; left time: 306.5678s\n",
      "\titers: 700, epoch: 4 | loss: 0.1231481\n",
      "\tspeed: 0.0537s/iter; left time: 301.4458s\n",
      "\titers: 800, epoch: 4 | loss: 0.1336111\n",
      "\tspeed: 0.0537s/iter; left time: 296.3403s\n",
      "\titers: 900, epoch: 4 | loss: 0.1212290\n",
      "\tspeed: 0.0537s/iter; left time: 290.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.1292714 Vali Loss: 0.0177111 Test Loss: 0.0204296\n",
      "Validation loss decreased (0.018770 --> 0.017711).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1234529\n",
      "\tspeed: 0.1352s/iter; left time: 718.3571s\n",
      "\titers: 200, epoch: 5 | loss: 0.1218383\n",
      "\tspeed: 0.0529s/iter; left time: 275.9253s\n",
      "\titers: 300, epoch: 5 | loss: 0.1262273\n",
      "\tspeed: 0.0535s/iter; left time: 273.3354s\n",
      "\titers: 400, epoch: 5 | loss: 0.1278754\n",
      "\tspeed: 0.0538s/iter; left time: 269.6483s\n",
      "\titers: 500, epoch: 5 | loss: 0.1240764\n",
      "\tspeed: 0.0536s/iter; left time: 263.2243s\n",
      "\titers: 600, epoch: 5 | loss: 0.1216050\n",
      "\tspeed: 0.0535s/iter; left time: 257.3236s\n",
      "\titers: 700, epoch: 5 | loss: 0.1151582\n",
      "\tspeed: 0.0536s/iter; left time: 252.6482s\n",
      "\titers: 800, epoch: 5 | loss: 0.1192179\n",
      "\tspeed: 0.0536s/iter; left time: 247.4831s\n",
      "\titers: 900, epoch: 5 | loss: 0.1187990\n",
      "\tspeed: 0.0536s/iter; left time: 241.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 902 | Train Loss: 0.1222272 Vali Loss: 0.0192881 Test Loss: 0.0205918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1269725\n",
      "\tspeed: 0.1299s/iter; left time: 573.1448s\n",
      "\titers: 200, epoch: 6 | loss: 0.1139024\n",
      "\tspeed: 0.0537s/iter; left time: 231.3023s\n",
      "\titers: 300, epoch: 6 | loss: 0.1152724\n",
      "\tspeed: 0.0532s/iter; left time: 224.1063s\n",
      "\titers: 400, epoch: 6 | loss: 0.1153143\n",
      "\tspeed: 0.0534s/iter; left time: 219.5725s\n",
      "\titers: 500, epoch: 6 | loss: 0.1218429\n",
      "\tspeed: 0.0535s/iter; left time: 214.4162s\n",
      "\titers: 600, epoch: 6 | loss: 0.1179661\n",
      "\tspeed: 0.0534s/iter; left time: 208.8307s\n",
      "\titers: 700, epoch: 6 | loss: 0.1186708\n",
      "\tspeed: 0.0534s/iter; left time: 203.4186s\n",
      "\titers: 800, epoch: 6 | loss: 0.1072247\n",
      "\tspeed: 0.0534s/iter; left time: 198.3054s\n",
      "\titers: 900, epoch: 6 | loss: 0.1118134\n",
      "\tspeed: 0.0542s/iter; left time: 195.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.1156325 Vali Loss: 0.0195381 Test Loss: 0.0220591\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1112536\n",
      "\tspeed: 0.1306s/iter; left time: 458.4017s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043497\n",
      "\tspeed: 0.0535s/iter; left time: 182.5304s\n",
      "\titers: 300, epoch: 7 | loss: 0.1131319\n",
      "\tspeed: 0.0539s/iter; left time: 178.2385s\n",
      "\titers: 400, epoch: 7 | loss: 0.1199129\n",
      "\tspeed: 0.0536s/iter; left time: 172.0274s\n",
      "\titers: 500, epoch: 7 | loss: 0.1025044\n",
      "\tspeed: 0.0534s/iter; left time: 165.9288s\n",
      "\titers: 600, epoch: 7 | loss: 0.1039046\n",
      "\tspeed: 0.0536s/iter; left time: 161.1780s\n",
      "\titers: 700, epoch: 7 | loss: 0.1046316\n",
      "\tspeed: 0.0537s/iter; left time: 156.1181s\n",
      "\titers: 800, epoch: 7 | loss: 0.1025476\n",
      "\tspeed: 0.0536s/iter; left time: 150.6755s\n",
      "\titers: 900, epoch: 7 | loss: 0.1025557\n",
      "\tspeed: 0.0536s/iter; left time: 145.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.1081127 Vali Loss: 0.0209927 Test Loss: 0.0224661\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02042943425476551, rmse:0.14293156564235687, mae:0.09454325586557388, rse:0.5408130884170532\n",
      "Original data scale mse:4257367.0, rmse:2063.3388671875, mae:1350.48828125, rse:0.1453419327735901\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2368102\n",
      "\tspeed: 0.0712s/iter; left time: 638.0534s\n",
      "\titers: 200, epoch: 1 | loss: 0.1976145\n",
      "\tspeed: 0.0417s/iter; left time: 369.5399s\n",
      "\titers: 300, epoch: 1 | loss: 0.1820158\n",
      "\tspeed: 0.0417s/iter; left time: 365.1668s\n",
      "\titers: 400, epoch: 1 | loss: 0.1763024\n",
      "\tspeed: 0.0417s/iter; left time: 360.8912s\n",
      "\titers: 500, epoch: 1 | loss: 0.1667152\n",
      "\tspeed: 0.0414s/iter; left time: 354.6597s\n",
      "\titers: 600, epoch: 1 | loss: 0.1668866\n",
      "\tspeed: 0.0414s/iter; left time: 349.9806s\n",
      "\titers: 700, epoch: 1 | loss: 0.1545057\n",
      "\tspeed: 0.0415s/iter; left time: 346.8767s\n",
      "\titers: 800, epoch: 1 | loss: 0.1634929\n",
      "\tspeed: 0.0416s/iter; left time: 344.0347s\n",
      "\titers: 900, epoch: 1 | loss: 0.1671590\n",
      "\tspeed: 0.0411s/iter; left time: 335.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 906 | Train Loss: 0.1831342 Vali Loss: 0.1416364 Test Loss: 0.1593144\n",
      "Validation loss decreased (inf --> 0.141636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1567799\n",
      "\tspeed: 0.0980s/iter; left time: 789.3895s\n",
      "\titers: 200, epoch: 2 | loss: 0.1347314\n",
      "\tspeed: 0.0419s/iter; left time: 333.3247s\n",
      "\titers: 300, epoch: 2 | loss: 0.0954429\n",
      "\tspeed: 0.0415s/iter; left time: 325.9367s\n",
      "\titers: 400, epoch: 2 | loss: 0.0659710\n",
      "\tspeed: 0.0411s/iter; left time: 318.8248s\n",
      "\titers: 500, epoch: 2 | loss: 0.0784877\n",
      "\tspeed: 0.0419s/iter; left time: 320.5171s\n",
      "\titers: 600, epoch: 2 | loss: 0.0708326\n",
      "\tspeed: 0.0409s/iter; left time: 308.9285s\n",
      "\titers: 700, epoch: 2 | loss: 0.0691726\n",
      "\tspeed: 0.0418s/iter; left time: 311.4909s\n",
      "\titers: 800, epoch: 2 | loss: 0.0743973\n",
      "\tspeed: 0.0416s/iter; left time: 306.1699s\n",
      "\titers: 900, epoch: 2 | loss: 0.0698419\n",
      "\tspeed: 0.0413s/iter; left time: 299.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 906 | Train Loss: 0.0935563 Vali Loss: 0.0675837 Test Loss: 0.0692845\n",
      "Validation loss decreased (0.141636 --> 0.067584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0667837\n",
      "\tspeed: 0.0969s/iter; left time: 692.7236s\n",
      "\titers: 200, epoch: 3 | loss: 0.0628219\n",
      "\tspeed: 0.0405s/iter; left time: 285.2175s\n",
      "\titers: 300, epoch: 3 | loss: 0.0620333\n",
      "\tspeed: 0.0409s/iter; left time: 284.2573s\n",
      "\titers: 400, epoch: 3 | loss: 0.0580120\n",
      "\tspeed: 0.0405s/iter; left time: 277.3138s\n",
      "\titers: 500, epoch: 3 | loss: 0.0724367\n",
      "\tspeed: 0.0406s/iter; left time: 274.2748s\n",
      "\titers: 600, epoch: 3 | loss: 0.0686133\n",
      "\tspeed: 0.0404s/iter; left time: 268.3333s\n",
      "\titers: 700, epoch: 3 | loss: 0.0544494\n",
      "\tspeed: 0.0411s/iter; left time: 269.1719s\n",
      "\titers: 800, epoch: 3 | loss: 0.0651684\n",
      "\tspeed: 0.0407s/iter; left time: 262.2730s\n",
      "\titers: 900, epoch: 3 | loss: 0.0568570\n",
      "\tspeed: 0.0408s/iter; left time: 258.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.09s\n",
      "Steps: 906 | Train Loss: 0.0631371 Vali Loss: 0.0593375 Test Loss: 0.0664737\n",
      "Validation loss decreased (0.067584 --> 0.059338).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0625494\n",
      "\tspeed: 0.0971s/iter; left time: 606.4911s\n",
      "\titers: 200, epoch: 4 | loss: 0.0533406\n",
      "\tspeed: 0.0416s/iter; left time: 255.3307s\n",
      "\titers: 300, epoch: 4 | loss: 0.0576288\n",
      "\tspeed: 0.0410s/iter; left time: 247.8326s\n",
      "\titers: 400, epoch: 4 | loss: 0.0586074\n",
      "\tspeed: 0.0409s/iter; left time: 243.1164s\n",
      "\titers: 500, epoch: 4 | loss: 0.0580517\n",
      "\tspeed: 0.0409s/iter; left time: 238.7017s\n",
      "\titers: 600, epoch: 4 | loss: 0.0680938\n",
      "\tspeed: 0.0406s/iter; left time: 233.4110s\n",
      "\titers: 700, epoch: 4 | loss: 0.0595984\n",
      "\tspeed: 0.0408s/iter; left time: 230.4083s\n",
      "\titers: 800, epoch: 4 | loss: 0.0616186\n",
      "\tspeed: 0.0405s/iter; left time: 224.7522s\n",
      "\titers: 900, epoch: 4 | loss: 0.0607496\n",
      "\tspeed: 0.0406s/iter; left time: 220.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.0583044 Vali Loss: 0.0594619 Test Loss: 0.0648209\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0508268\n",
      "\tspeed: 0.0935s/iter; left time: 499.2689s\n",
      "\titers: 200, epoch: 5 | loss: 0.0465041\n",
      "\tspeed: 0.0408s/iter; left time: 213.7084s\n",
      "\titers: 300, epoch: 5 | loss: 0.0510423\n",
      "\tspeed: 0.0409s/iter; left time: 210.0478s\n",
      "\titers: 400, epoch: 5 | loss: 0.0523918\n",
      "\tspeed: 0.0411s/iter; left time: 207.1005s\n",
      "\titers: 500, epoch: 5 | loss: 0.0598315\n",
      "\tspeed: 0.0421s/iter; left time: 207.7896s\n",
      "\titers: 600, epoch: 5 | loss: 0.0490402\n",
      "\tspeed: 0.0416s/iter; left time: 201.1613s\n",
      "\titers: 700, epoch: 5 | loss: 0.0619671\n",
      "\tspeed: 0.0414s/iter; left time: 195.9439s\n",
      "\titers: 800, epoch: 5 | loss: 0.0528487\n",
      "\tspeed: 0.0408s/iter; left time: 189.4135s\n",
      "\titers: 900, epoch: 5 | loss: 0.0534129\n",
      "\tspeed: 0.0409s/iter; left time: 185.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.0549647 Vali Loss: 0.0630590 Test Loss: 0.0669836\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0482354\n",
      "\tspeed: 0.0944s/iter; left time: 418.1274s\n",
      "\titers: 200, epoch: 6 | loss: 0.0546013\n",
      "\tspeed: 0.0406s/iter; left time: 175.9608s\n",
      "\titers: 300, epoch: 6 | loss: 0.0570758\n",
      "\tspeed: 0.0413s/iter; left time: 174.7038s\n",
      "\titers: 400, epoch: 6 | loss: 0.0596123\n",
      "\tspeed: 0.0405s/iter; left time: 167.4209s\n",
      "\titers: 500, epoch: 6 | loss: 0.0551656\n",
      "\tspeed: 0.0405s/iter; left time: 163.4208s\n",
      "\titers: 600, epoch: 6 | loss: 0.0586615\n",
      "\tspeed: 0.0406s/iter; left time: 159.5553s\n",
      "\titers: 700, epoch: 6 | loss: 0.0553976\n",
      "\tspeed: 0.0410s/iter; left time: 156.8940s\n",
      "\titers: 800, epoch: 6 | loss: 0.0517439\n",
      "\tspeed: 0.0405s/iter; left time: 150.9326s\n",
      "\titers: 900, epoch: 6 | loss: 0.0614059\n",
      "\tspeed: 0.0409s/iter; left time: 148.3436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.15s\n",
      "Steps: 906 | Train Loss: 0.0526655 Vali Loss: 0.0566184 Test Loss: 0.0645697\n",
      "Validation loss decreased (0.059338 --> 0.056618).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0527649\n",
      "\tspeed: 0.0901s/iter; left time: 317.6721s\n",
      "\titers: 200, epoch: 7 | loss: 0.0461824\n",
      "\tspeed: 0.0282s/iter; left time: 96.6433s\n",
      "\titers: 300, epoch: 7 | loss: 0.0488837\n",
      "\tspeed: 0.0282s/iter; left time: 93.8066s\n",
      "\titers: 400, epoch: 7 | loss: 0.0497226\n",
      "\tspeed: 0.0282s/iter; left time: 91.0615s\n",
      "\titers: 500, epoch: 7 | loss: 0.0484969\n",
      "\tspeed: 0.0282s/iter; left time: 88.2365s\n",
      "\titers: 600, epoch: 7 | loss: 0.0423569\n",
      "\tspeed: 0.0282s/iter; left time: 85.3462s\n",
      "\titers: 700, epoch: 7 | loss: 0.0470160\n",
      "\tspeed: 0.0283s/iter; left time: 82.6647s\n",
      "\titers: 800, epoch: 7 | loss: 0.0575899\n",
      "\tspeed: 0.0282s/iter; left time: 79.7431s\n",
      "\titers: 900, epoch: 7 | loss: 0.0479537\n",
      "\tspeed: 0.0283s/iter; left time: 76.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.91s\n",
      "Steps: 906 | Train Loss: 0.0508175 Vali Loss: 0.0561616 Test Loss: 0.0629275\n",
      "Validation loss decreased (0.056618 --> 0.056162).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0453912\n",
      "\tspeed: 0.0966s/iter; left time: 253.0347s\n",
      "\titers: 200, epoch: 8 | loss: 0.0434858\n",
      "\tspeed: 0.0406s/iter; left time: 102.3126s\n",
      "\titers: 300, epoch: 8 | loss: 0.0531948\n",
      "\tspeed: 0.0406s/iter; left time: 98.3216s\n",
      "\titers: 400, epoch: 8 | loss: 0.0452402\n",
      "\tspeed: 0.0404s/iter; left time: 93.7591s\n",
      "\titers: 500, epoch: 8 | loss: 0.0539990\n",
      "\tspeed: 0.0405s/iter; left time: 89.9707s\n",
      "\titers: 600, epoch: 8 | loss: 0.0542634\n",
      "\tspeed: 0.0409s/iter; left time: 86.7441s\n",
      "\titers: 700, epoch: 8 | loss: 0.0458029\n",
      "\tspeed: 0.0405s/iter; left time: 81.7955s\n",
      "\titers: 800, epoch: 8 | loss: 0.0414126\n",
      "\tspeed: 0.0406s/iter; left time: 77.9568s\n",
      "\titers: 900, epoch: 8 | loss: 0.0540792\n",
      "\tspeed: 0.0405s/iter; left time: 73.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.09s\n",
      "Steps: 906 | Train Loss: 0.0489464 Vali Loss: 0.0573378 Test Loss: 0.0645426\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0454752\n",
      "\tspeed: 0.0957s/iter; left time: 164.0005s\n",
      "\titers: 200, epoch: 9 | loss: 0.0501344\n",
      "\tspeed: 0.0411s/iter; left time: 66.3269s\n",
      "\titers: 300, epoch: 9 | loss: 0.0486988\n",
      "\tspeed: 0.0419s/iter; left time: 63.4375s\n",
      "\titers: 400, epoch: 9 | loss: 0.0566403\n",
      "\tspeed: 0.0416s/iter; left time: 58.7914s\n",
      "\titers: 500, epoch: 9 | loss: 0.0500063\n",
      "\tspeed: 0.0406s/iter; left time: 53.3525s\n",
      "\titers: 600, epoch: 9 | loss: 0.0535145\n",
      "\tspeed: 0.0412s/iter; left time: 49.9371s\n",
      "\titers: 700, epoch: 9 | loss: 0.0479669\n",
      "\tspeed: 0.0414s/iter; left time: 46.0735s\n",
      "\titers: 800, epoch: 9 | loss: 0.0512015\n",
      "\tspeed: 0.0410s/iter; left time: 41.4899s\n",
      "\titers: 900, epoch: 9 | loss: 0.0509077\n",
      "\tspeed: 0.0411s/iter; left time: 37.5164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.63s\n",
      "Steps: 906 | Train Loss: 0.0472082 Vali Loss: 0.0564906 Test Loss: 0.0648163\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465797\n",
      "\tspeed: 0.0885s/iter; left time: 71.4220s\n",
      "\titers: 200, epoch: 10 | loss: 0.0429502\n",
      "\tspeed: 0.0411s/iter; left time: 29.0685s\n",
      "\titers: 300, epoch: 10 | loss: 0.0492641\n",
      "\tspeed: 0.0407s/iter; left time: 24.6997s\n",
      "\titers: 400, epoch: 10 | loss: 0.0430836\n",
      "\tspeed: 0.0409s/iter; left time: 20.7244s\n",
      "\titers: 500, epoch: 10 | loss: 0.0444101\n",
      "\tspeed: 0.0408s/iter; left time: 16.6193s\n",
      "\titers: 600, epoch: 10 | loss: 0.0426973\n",
      "\tspeed: 0.0404s/iter; left time: 12.4028s\n",
      "\titers: 700, epoch: 10 | loss: 0.0503525\n",
      "\tspeed: 0.0409s/iter; left time: 8.4645s\n",
      "\titers: 800, epoch: 10 | loss: 0.0387502\n",
      "\tspeed: 0.0413s/iter; left time: 4.4145s\n",
      "\titers: 900, epoch: 10 | loss: 0.0532494\n",
      "\tspeed: 0.0409s/iter; left time: 0.2864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.66s\n",
      "Steps: 906 | Train Loss: 0.0456444 Vali Loss: 0.0574741 Test Loss: 0.0645414\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011482995003461838, rmse:0.10715873539447784, mae:0.06290280073881149, rse:0.4049603343009949\n",
      "Original data scale mse:1691501.875, rmse:1300.5775146484375, mae:802.243408203125, rse:0.09139464795589447\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2293039\n",
      "\tspeed: 0.0440s/iter; left time: 394.4993s\n",
      "\titers: 200, epoch: 1 | loss: 0.1949999\n",
      "\tspeed: 0.0415s/iter; left time: 367.7592s\n",
      "\titers: 300, epoch: 1 | loss: 0.1854941\n",
      "\tspeed: 0.0410s/iter; left time: 358.8304s\n",
      "\titers: 400, epoch: 1 | loss: 0.1584033\n",
      "\tspeed: 0.0407s/iter; left time: 352.0863s\n",
      "\titers: 500, epoch: 1 | loss: 0.1715456\n",
      "\tspeed: 0.0408s/iter; left time: 349.1541s\n",
      "\titers: 600, epoch: 1 | loss: 0.1699277\n",
      "\tspeed: 0.0406s/iter; left time: 343.8288s\n",
      "\titers: 700, epoch: 1 | loss: 0.1542774\n",
      "\tspeed: 0.0406s/iter; left time: 339.7839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516741\n",
      "\tspeed: 0.0414s/iter; left time: 341.7199s\n",
      "\titers: 900, epoch: 1 | loss: 0.1462401\n",
      "\tspeed: 0.0410s/iter; left time: 334.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.47s\n",
      "Steps: 906 | Train Loss: 0.1825827 Vali Loss: 0.1343112 Test Loss: 0.1503070\n",
      "Validation loss decreased (inf --> 0.134311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1107656\n",
      "\tspeed: 0.0989s/iter; left time: 796.7470s\n",
      "\titers: 200, epoch: 2 | loss: 0.1030795\n",
      "\tspeed: 0.0417s/iter; left time: 331.9653s\n",
      "\titers: 300, epoch: 2 | loss: 0.0860572\n",
      "\tspeed: 0.0417s/iter; left time: 327.7018s\n",
      "\titers: 400, epoch: 2 | loss: 0.0752717\n",
      "\tspeed: 0.0424s/iter; left time: 328.5950s\n",
      "\titers: 500, epoch: 2 | loss: 0.0827808\n",
      "\tspeed: 0.0412s/iter; left time: 315.5587s\n",
      "\titers: 600, epoch: 2 | loss: 0.0736229\n",
      "\tspeed: 0.0417s/iter; left time: 314.8256s\n",
      "\titers: 700, epoch: 2 | loss: 0.0723702\n",
      "\tspeed: 0.0412s/iter; left time: 307.1595s\n",
      "\titers: 800, epoch: 2 | loss: 0.0665644\n",
      "\tspeed: 0.0417s/iter; left time: 306.4962s\n",
      "\titers: 900, epoch: 2 | loss: 0.0643604\n",
      "\tspeed: 0.0414s/iter; left time: 300.7116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 906 | Train Loss: 0.0861478 Vali Loss: 0.0631266 Test Loss: 0.0667304\n",
      "Validation loss decreased (0.134311 --> 0.063127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693751\n",
      "\tspeed: 0.1034s/iter; left time: 739.4476s\n",
      "\titers: 200, epoch: 3 | loss: 0.0592428\n",
      "\tspeed: 0.0421s/iter; left time: 296.9034s\n",
      "\titers: 300, epoch: 3 | loss: 0.0610428\n",
      "\tspeed: 0.0422s/iter; left time: 293.5499s\n",
      "\titers: 400, epoch: 3 | loss: 0.0658390\n",
      "\tspeed: 0.0420s/iter; left time: 287.8221s\n",
      "\titers: 500, epoch: 3 | loss: 0.0666335\n",
      "\tspeed: 0.0412s/iter; left time: 278.0228s\n",
      "\titers: 600, epoch: 3 | loss: 0.0606009\n",
      "\tspeed: 0.0411s/iter; left time: 273.3607s\n",
      "\titers: 700, epoch: 3 | loss: 0.0581337\n",
      "\tspeed: 0.0405s/iter; left time: 265.5538s\n",
      "\titers: 800, epoch: 3 | loss: 0.0582383\n",
      "\tspeed: 0.0415s/iter; left time: 267.9168s\n",
      "\titers: 900, epoch: 3 | loss: 0.0596758\n",
      "\tspeed: 0.0413s/iter; left time: 262.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.0641978 Vali Loss: 0.0611058 Test Loss: 0.0658730\n",
      "Validation loss decreased (0.063127 --> 0.061106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0562136\n",
      "\tspeed: 0.0998s/iter; left time: 623.1873s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655172\n",
      "\tspeed: 0.0412s/iter; left time: 253.1975s\n",
      "\titers: 300, epoch: 4 | loss: 0.0593281\n",
      "\tspeed: 0.0412s/iter; left time: 248.8640s\n",
      "\titers: 400, epoch: 4 | loss: 0.0546823\n",
      "\tspeed: 0.0406s/iter; left time: 241.5464s\n",
      "\titers: 500, epoch: 4 | loss: 0.0553918\n",
      "\tspeed: 0.0407s/iter; left time: 237.9398s\n",
      "\titers: 600, epoch: 4 | loss: 0.0603409\n",
      "\tspeed: 0.0409s/iter; left time: 234.9392s\n",
      "\titers: 700, epoch: 4 | loss: 0.0628517\n",
      "\tspeed: 0.0410s/iter; left time: 231.5435s\n",
      "\titers: 800, epoch: 4 | loss: 0.0533420\n",
      "\tspeed: 0.0408s/iter; left time: 226.3870s\n",
      "\titers: 900, epoch: 4 | loss: 0.0497529\n",
      "\tspeed: 0.0408s/iter; left time: 221.8164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.38s\n",
      "Steps: 906 | Train Loss: 0.0593306 Vali Loss: 0.0581195 Test Loss: 0.0622350\n",
      "Validation loss decreased (0.061106 --> 0.058120).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0587280\n",
      "\tspeed: 0.0979s/iter; left time: 522.5709s\n",
      "\titers: 200, epoch: 5 | loss: 0.0496650\n",
      "\tspeed: 0.0413s/iter; left time: 216.4735s\n",
      "\titers: 300, epoch: 5 | loss: 0.0512741\n",
      "\tspeed: 0.0411s/iter; left time: 211.2610s\n",
      "\titers: 400, epoch: 5 | loss: 0.0494401\n",
      "\tspeed: 0.0409s/iter; left time: 206.0223s\n",
      "\titers: 500, epoch: 5 | loss: 0.0611358\n",
      "\tspeed: 0.0412s/iter; left time: 203.3781s\n",
      "\titers: 600, epoch: 5 | loss: 0.0572452\n",
      "\tspeed: 0.0417s/iter; left time: 201.7430s\n",
      "\titers: 700, epoch: 5 | loss: 0.0612310\n",
      "\tspeed: 0.0406s/iter; left time: 192.3878s\n",
      "\titers: 800, epoch: 5 | loss: 0.0486969\n",
      "\tspeed: 0.0412s/iter; left time: 191.1214s\n",
      "\titers: 900, epoch: 5 | loss: 0.0643084\n",
      "\tspeed: 0.0412s/iter; left time: 186.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.59s\n",
      "Steps: 906 | Train Loss: 0.0560262 Vali Loss: 0.0554300 Test Loss: 0.0610669\n",
      "Validation loss decreased (0.058120 --> 0.055430).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0596108\n",
      "\tspeed: 0.0991s/iter; left time: 438.9817s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585680\n",
      "\tspeed: 0.0425s/iter; left time: 183.9326s\n",
      "\titers: 300, epoch: 6 | loss: 0.0506056\n",
      "\tspeed: 0.0422s/iter; left time: 178.7083s\n",
      "\titers: 400, epoch: 6 | loss: 0.0554475\n",
      "\tspeed: 0.0420s/iter; left time: 173.6498s\n",
      "\titers: 500, epoch: 6 | loss: 0.0471394\n",
      "\tspeed: 0.0413s/iter; left time: 166.6214s\n",
      "\titers: 600, epoch: 6 | loss: 0.0487447\n",
      "\tspeed: 0.0420s/iter; left time: 165.0913s\n",
      "\titers: 700, epoch: 6 | loss: 0.0455151\n",
      "\tspeed: 0.0413s/iter; left time: 158.1296s\n",
      "\titers: 800, epoch: 6 | loss: 0.0467743\n",
      "\tspeed: 0.0418s/iter; left time: 155.7936s\n",
      "\titers: 900, epoch: 6 | loss: 0.0532170\n",
      "\tspeed: 0.0416s/iter; left time: 151.2130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 906 | Train Loss: 0.0540781 Vali Loss: 0.0558894 Test Loss: 0.0634225\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0499279\n",
      "\tspeed: 0.0954s/iter; left time: 336.1861s\n",
      "\titers: 200, epoch: 7 | loss: 0.0548485\n",
      "\tspeed: 0.0412s/iter; left time: 141.2768s\n",
      "\titers: 300, epoch: 7 | loss: 0.0522096\n",
      "\tspeed: 0.0414s/iter; left time: 137.7741s\n",
      "\titers: 400, epoch: 7 | loss: 0.0482700\n",
      "\tspeed: 0.0414s/iter; left time: 133.5169s\n",
      "\titers: 500, epoch: 7 | loss: 0.0502691\n",
      "\tspeed: 0.0416s/iter; left time: 130.0006s\n",
      "\titers: 600, epoch: 7 | loss: 0.0580107\n",
      "\tspeed: 0.0414s/iter; left time: 125.1401s\n",
      "\titers: 700, epoch: 7 | loss: 0.0561222\n",
      "\tspeed: 0.0408s/iter; left time: 119.4559s\n",
      "\titers: 800, epoch: 7 | loss: 0.0497233\n",
      "\tspeed: 0.0408s/iter; left time: 115.3270s\n",
      "\titers: 900, epoch: 7 | loss: 0.0482512\n",
      "\tspeed: 0.0416s/iter; left time: 113.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.70s\n",
      "Steps: 906 | Train Loss: 0.0516833 Vali Loss: 0.0570287 Test Loss: 0.0636291\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0507852\n",
      "\tspeed: 0.0943s/iter; left time: 247.0311s\n",
      "\titers: 200, epoch: 8 | loss: 0.0477182\n",
      "\tspeed: 0.0405s/iter; left time: 101.9260s\n",
      "\titers: 300, epoch: 8 | loss: 0.0415919\n",
      "\tspeed: 0.0412s/iter; left time: 99.5689s\n",
      "\titers: 400, epoch: 8 | loss: 0.0505819\n",
      "\tspeed: 0.0410s/iter; left time: 94.9782s\n",
      "\titers: 500, epoch: 8 | loss: 0.0492290\n",
      "\tspeed: 0.0408s/iter; left time: 90.5867s\n",
      "\titers: 600, epoch: 8 | loss: 0.0508336\n",
      "\tspeed: 0.0409s/iter; left time: 86.7708s\n",
      "\titers: 700, epoch: 8 | loss: 0.0446340\n",
      "\tspeed: 0.0406s/iter; left time: 81.9453s\n",
      "\titers: 800, epoch: 8 | loss: 0.0494645\n",
      "\tspeed: 0.0411s/iter; left time: 78.8533s\n",
      "\titers: 900, epoch: 8 | loss: 0.0484836\n",
      "\tspeed: 0.0408s/iter; left time: 74.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.0502655 Vali Loss: 0.0593058 Test Loss: 0.0663687\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01105409674346447, rmse:0.10513846576213837, mae:0.061079539358615875, rse:0.3973256051540375\n",
      "Original data scale mse:1389721.625, rmse:1178.864501953125, mae:748.0409545898438, rse:0.08284159004688263\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2243602\n",
      "\tspeed: 0.0767s/iter; left time: 686.1226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2027065\n",
      "\tspeed: 0.0476s/iter; left time: 420.6963s\n",
      "\titers: 300, epoch: 1 | loss: 0.1868845\n",
      "\tspeed: 0.0473s/iter; left time: 413.8237s\n",
      "\titers: 400, epoch: 1 | loss: 0.1847196\n",
      "\tspeed: 0.0460s/iter; left time: 397.5533s\n",
      "\titers: 500, epoch: 1 | loss: 0.1851151\n",
      "\tspeed: 0.0478s/iter; left time: 408.3032s\n",
      "\titers: 600, epoch: 1 | loss: 0.1763308\n",
      "\tspeed: 0.0477s/iter; left time: 402.7618s\n",
      "\titers: 700, epoch: 1 | loss: 0.1776650\n",
      "\tspeed: 0.0478s/iter; left time: 398.8537s\n",
      "\titers: 800, epoch: 1 | loss: 0.1680425\n",
      "\tspeed: 0.0477s/iter; left time: 393.2185s\n",
      "\titers: 900, epoch: 1 | loss: 0.1724489\n",
      "\tspeed: 0.0479s/iter; left time: 389.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.67s\n",
      "Steps: 904 | Train Loss: 0.1918924 Vali Loss: 0.1596796 Test Loss: 0.1781078\n",
      "Validation loss decreased (inf --> 0.159680).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1530025\n",
      "\tspeed: 0.1178s/iter; left time: 946.6485s\n",
      "\titers: 200, epoch: 2 | loss: 0.1297616\n",
      "\tspeed: 0.0475s/iter; left time: 376.7796s\n",
      "\titers: 300, epoch: 2 | loss: 0.1149904\n",
      "\tspeed: 0.0476s/iter; left time: 373.3182s\n",
      "\titers: 400, epoch: 2 | loss: 0.1057039\n",
      "\tspeed: 0.0477s/iter; left time: 368.8188s\n",
      "\titers: 500, epoch: 2 | loss: 0.1026849\n",
      "\tspeed: 0.0475s/iter; left time: 362.8403s\n",
      "\titers: 600, epoch: 2 | loss: 0.1063231\n",
      "\tspeed: 0.0455s/iter; left time: 342.6285s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957590\n",
      "\tspeed: 0.0475s/iter; left time: 353.2155s\n",
      "\titers: 800, epoch: 2 | loss: 0.0971975\n",
      "\tspeed: 0.0475s/iter; left time: 348.8500s\n",
      "\titers: 900, epoch: 2 | loss: 0.0866247\n",
      "\tspeed: 0.0475s/iter; left time: 343.4672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.97s\n",
      "Steps: 904 | Train Loss: 0.1147572 Vali Loss: 0.0918063 Test Loss: 0.0950631\n",
      "Validation loss decreased (0.159680 --> 0.091806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0887786\n",
      "\tspeed: 0.1243s/iter; left time: 886.5882s\n",
      "\titers: 200, epoch: 3 | loss: 0.0895701\n",
      "\tspeed: 0.0474s/iter; left time: 333.1588s\n",
      "\titers: 300, epoch: 3 | loss: 0.0920746\n",
      "\tspeed: 0.0472s/iter; left time: 326.9817s\n",
      "\titers: 400, epoch: 3 | loss: 0.0863848\n",
      "\tspeed: 0.0473s/iter; left time: 323.1555s\n",
      "\titers: 500, epoch: 3 | loss: 0.0874794\n",
      "\tspeed: 0.0474s/iter; left time: 319.2563s\n",
      "\titers: 600, epoch: 3 | loss: 0.0857909\n",
      "\tspeed: 0.0471s/iter; left time: 312.6884s\n",
      "\titers: 700, epoch: 3 | loss: 0.0795361\n",
      "\tspeed: 0.0473s/iter; left time: 309.3042s\n",
      "\titers: 800, epoch: 3 | loss: 0.0905731\n",
      "\tspeed: 0.0470s/iter; left time: 302.3265s\n",
      "\titers: 900, epoch: 3 | loss: 0.0883819\n",
      "\tspeed: 0.0472s/iter; left time: 298.7633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.0859464 Vali Loss: 0.0834362 Test Loss: 0.0888495\n",
      "Validation loss decreased (0.091806 --> 0.083436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770556\n",
      "\tspeed: 0.1150s/iter; left time: 716.5504s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817428\n",
      "\tspeed: 0.0471s/iter; left time: 288.5582s\n",
      "\titers: 300, epoch: 4 | loss: 0.0759583\n",
      "\tspeed: 0.0471s/iter; left time: 283.7167s\n",
      "\titers: 400, epoch: 4 | loss: 0.0846592\n",
      "\tspeed: 0.0471s/iter; left time: 279.3253s\n",
      "\titers: 500, epoch: 4 | loss: 0.0812071\n",
      "\tspeed: 0.0472s/iter; left time: 275.3366s\n",
      "\titers: 600, epoch: 4 | loss: 0.0800486\n",
      "\tspeed: 0.0471s/iter; left time: 269.7768s\n",
      "\titers: 700, epoch: 4 | loss: 0.0755152\n",
      "\tspeed: 0.0471s/iter; left time: 265.3926s\n",
      "\titers: 800, epoch: 4 | loss: 0.0806880\n",
      "\tspeed: 0.0468s/iter; left time: 258.7435s\n",
      "\titers: 900, epoch: 4 | loss: 0.0723897\n",
      "\tspeed: 0.0471s/iter; left time: 255.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.0793150 Vali Loss: 0.0786396 Test Loss: 0.0888349\n",
      "Validation loss decreased (0.083436 --> 0.078640).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0715495\n",
      "\tspeed: 0.1153s/iter; left time: 614.0485s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792769\n",
      "\tspeed: 0.0473s/iter; left time: 247.0987s\n",
      "\titers: 300, epoch: 5 | loss: 0.0732970\n",
      "\tspeed: 0.0473s/iter; left time: 242.3837s\n",
      "\titers: 400, epoch: 5 | loss: 0.0858842\n",
      "\tspeed: 0.0473s/iter; left time: 237.8546s\n",
      "\titers: 500, epoch: 5 | loss: 0.0754363\n",
      "\tspeed: 0.0473s/iter; left time: 233.1763s\n",
      "\titers: 600, epoch: 5 | loss: 0.0764097\n",
      "\tspeed: 0.0472s/iter; left time: 227.6236s\n",
      "\titers: 700, epoch: 5 | loss: 0.0786430\n",
      "\tspeed: 0.0472s/iter; left time: 222.9780s\n",
      "\titers: 800, epoch: 5 | loss: 0.0794202\n",
      "\tspeed: 0.0474s/iter; left time: 219.2312s\n",
      "\titers: 900, epoch: 5 | loss: 0.0708164\n",
      "\tspeed: 0.0474s/iter; left time: 214.5815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.0752230 Vali Loss: 0.0787254 Test Loss: 0.0872884\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605731\n",
      "\tspeed: 0.1114s/iter; left time: 492.4020s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735579\n",
      "\tspeed: 0.0471s/iter; left time: 203.5601s\n",
      "\titers: 300, epoch: 6 | loss: 0.0757417\n",
      "\tspeed: 0.0471s/iter; left time: 198.8017s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776769\n",
      "\tspeed: 0.0471s/iter; left time: 194.2973s\n",
      "\titers: 500, epoch: 6 | loss: 0.0724421\n",
      "\tspeed: 0.0470s/iter; left time: 189.0419s\n",
      "\titers: 600, epoch: 6 | loss: 0.0672777\n",
      "\tspeed: 0.0472s/iter; left time: 185.1111s\n",
      "\titers: 700, epoch: 6 | loss: 0.0635118\n",
      "\tspeed: 0.0471s/iter; left time: 179.9935s\n",
      "\titers: 800, epoch: 6 | loss: 0.0738846\n",
      "\tspeed: 0.0471s/iter; left time: 175.0887s\n",
      "\titers: 900, epoch: 6 | loss: 0.0723136\n",
      "\tspeed: 0.0472s/iter; left time: 170.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.80s\n",
      "Steps: 904 | Train Loss: 0.0717300 Vali Loss: 0.0797349 Test Loss: 0.0892030\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0677241\n",
      "\tspeed: 0.1123s/iter; left time: 395.0050s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646913\n",
      "\tspeed: 0.0469s/iter; left time: 160.2284s\n",
      "\titers: 300, epoch: 7 | loss: 0.0696629\n",
      "\tspeed: 0.0475s/iter; left time: 157.6190s\n",
      "\titers: 400, epoch: 7 | loss: 0.0655409\n",
      "\tspeed: 0.0475s/iter; left time: 152.7913s\n",
      "\titers: 500, epoch: 7 | loss: 0.0625962\n",
      "\tspeed: 0.0474s/iter; left time: 147.6344s\n",
      "\titers: 600, epoch: 7 | loss: 0.0773934\n",
      "\tspeed: 0.0475s/iter; left time: 143.3745s\n",
      "\titers: 700, epoch: 7 | loss: 0.0629039\n",
      "\tspeed: 0.0475s/iter; left time: 138.4763s\n",
      "\titers: 800, epoch: 7 | loss: 0.0599256\n",
      "\tspeed: 0.0475s/iter; left time: 133.8986s\n",
      "\titers: 900, epoch: 7 | loss: 0.0667820\n",
      "\tspeed: 0.0476s/iter; left time: 129.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.0682445 Vali Loss: 0.0809954 Test Loss: 0.0913115\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019984431564807892, rmse:0.14136630296707153, mae:0.0888453871011734, rse:0.534521222114563\n",
      "Original data scale mse:3605560.25, rmse:1898.831298828125, mae:1205.3231201171875, rse:0.13362851738929749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2240398\n",
      "\tspeed: 0.0502s/iter; left time: 448.5318s\n",
      "\titers: 200, epoch: 1 | loss: 0.2105331\n",
      "\tspeed: 0.0480s/iter; left time: 424.7962s\n",
      "\titers: 300, epoch: 1 | loss: 0.1883464\n",
      "\tspeed: 0.0474s/iter; left time: 414.2431s\n",
      "\titers: 400, epoch: 1 | loss: 0.1845039\n",
      "\tspeed: 0.0478s/iter; left time: 412.7784s\n",
      "\titers: 500, epoch: 1 | loss: 0.1790367\n",
      "\tspeed: 0.0477s/iter; left time: 407.4003s\n",
      "\titers: 600, epoch: 1 | loss: 0.1824718\n",
      "\tspeed: 0.0478s/iter; left time: 403.8657s\n",
      "\titers: 700, epoch: 1 | loss: 0.1725546\n",
      "\tspeed: 0.0478s/iter; left time: 398.5019s\n",
      "\titers: 800, epoch: 1 | loss: 0.1700925\n",
      "\tspeed: 0.0478s/iter; left time: 393.8054s\n",
      "\titers: 900, epoch: 1 | loss: 0.1613553\n",
      "\tspeed: 0.0478s/iter; left time: 389.0894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.49s\n",
      "Steps: 904 | Train Loss: 0.1915094 Vali Loss: 0.1579992 Test Loss: 0.1774052\n",
      "Validation loss decreased (inf --> 0.157999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470376\n",
      "\tspeed: 0.1158s/iter; left time: 930.3071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1239771\n",
      "\tspeed: 0.0478s/iter; left time: 379.5583s\n",
      "\titers: 300, epoch: 2 | loss: 0.1165423\n",
      "\tspeed: 0.0479s/iter; left time: 375.1930s\n",
      "\titers: 400, epoch: 2 | loss: 0.1071929\n",
      "\tspeed: 0.0479s/iter; left time: 370.6951s\n",
      "\titers: 500, epoch: 2 | loss: 0.1061287\n",
      "\tspeed: 0.0478s/iter; left time: 365.3921s\n",
      "\titers: 600, epoch: 2 | loss: 0.1077616\n",
      "\tspeed: 0.0475s/iter; left time: 358.3735s\n",
      "\titers: 700, epoch: 2 | loss: 0.1017539\n",
      "\tspeed: 0.0474s/iter; left time: 352.3390s\n",
      "\titers: 800, epoch: 2 | loss: 0.0951709\n",
      "\tspeed: 0.0466s/iter; left time: 342.0989s\n",
      "\titers: 900, epoch: 2 | loss: 0.0865274\n",
      "\tspeed: 0.0475s/iter; left time: 343.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.1142872 Vali Loss: 0.0897007 Test Loss: 0.0939150\n",
      "Validation loss decreased (0.157999 --> 0.089701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0840477\n",
      "\tspeed: 0.1169s/iter; left time: 834.0878s\n",
      "\titers: 200, epoch: 3 | loss: 0.0851544\n",
      "\tspeed: 0.0475s/iter; left time: 333.8247s\n",
      "\titers: 300, epoch: 3 | loss: 0.0887517\n",
      "\tspeed: 0.0474s/iter; left time: 328.9420s\n",
      "\titers: 400, epoch: 3 | loss: 0.0920378\n",
      "\tspeed: 0.0477s/iter; left time: 326.1445s\n",
      "\titers: 500, epoch: 3 | loss: 0.0844317\n",
      "\tspeed: 0.0479s/iter; left time: 322.4737s\n",
      "\titers: 600, epoch: 3 | loss: 0.0899497\n",
      "\tspeed: 0.0479s/iter; left time: 317.7516s\n",
      "\titers: 700, epoch: 3 | loss: 0.0846821\n",
      "\tspeed: 0.0477s/iter; left time: 311.7969s\n",
      "\titers: 800, epoch: 3 | loss: 0.0789549\n",
      "\tspeed: 0.0477s/iter; left time: 306.6669s\n",
      "\titers: 900, epoch: 3 | loss: 0.0810189\n",
      "\tspeed: 0.0479s/iter; left time: 303.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.40s\n",
      "Steps: 904 | Train Loss: 0.0866498 Vali Loss: 0.0863490 Test Loss: 0.0889597\n",
      "Validation loss decreased (0.089701 --> 0.086349).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0819868\n",
      "\tspeed: 0.1168s/iter; left time: 727.7127s\n",
      "\titers: 200, epoch: 4 | loss: 0.0814292\n",
      "\tspeed: 0.0467s/iter; left time: 286.0030s\n",
      "\titers: 300, epoch: 4 | loss: 0.0853356\n",
      "\tspeed: 0.0479s/iter; left time: 289.0133s\n",
      "\titers: 400, epoch: 4 | loss: 0.0793281\n",
      "\tspeed: 0.0479s/iter; left time: 283.8274s\n",
      "\titers: 500, epoch: 4 | loss: 0.0783759\n",
      "\tspeed: 0.0480s/iter; left time: 279.6255s\n",
      "\titers: 600, epoch: 4 | loss: 0.0773403\n",
      "\tspeed: 0.0477s/iter; left time: 273.5178s\n",
      "\titers: 700, epoch: 4 | loss: 0.0798870\n",
      "\tspeed: 0.0478s/iter; left time: 269.2479s\n",
      "\titers: 800, epoch: 4 | loss: 0.0750341\n",
      "\tspeed: 0.0479s/iter; left time: 264.8317s\n",
      "\titers: 900, epoch: 4 | loss: 0.0692645\n",
      "\tspeed: 0.0478s/iter; left time: 259.6956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.39s\n",
      "Steps: 904 | Train Loss: 0.0802790 Vali Loss: 0.0805011 Test Loss: 0.0879182\n",
      "Validation loss decreased (0.086349 --> 0.080501).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0772444\n",
      "\tspeed: 0.1155s/iter; left time: 615.0323s\n",
      "\titers: 200, epoch: 5 | loss: 0.0743210\n",
      "\tspeed: 0.0471s/iter; left time: 246.2216s\n",
      "\titers: 300, epoch: 5 | loss: 0.0736933\n",
      "\tspeed: 0.0472s/iter; left time: 242.0452s\n",
      "\titers: 400, epoch: 5 | loss: 0.0747714\n",
      "\tspeed: 0.0473s/iter; left time: 237.8036s\n",
      "\titers: 500, epoch: 5 | loss: 0.0765212\n",
      "\tspeed: 0.0475s/iter; left time: 233.7236s\n",
      "\titers: 600, epoch: 5 | loss: 0.0804278\n",
      "\tspeed: 0.0474s/iter; left time: 228.6670s\n",
      "\titers: 700, epoch: 5 | loss: 0.0784457\n",
      "\tspeed: 0.0475s/iter; left time: 224.6252s\n",
      "\titers: 800, epoch: 5 | loss: 0.0800255\n",
      "\tspeed: 0.0474s/iter; left time: 219.2930s\n",
      "\titers: 900, epoch: 5 | loss: 0.0701285\n",
      "\tspeed: 0.0475s/iter; left time: 214.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.0760173 Vali Loss: 0.0785532 Test Loss: 0.0887440\n",
      "Validation loss decreased (0.080501 --> 0.078553).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737377\n",
      "\tspeed: 0.1183s/iter; left time: 522.8410s\n",
      "\titers: 200, epoch: 6 | loss: 0.0705482\n",
      "\tspeed: 0.0472s/iter; left time: 204.1348s\n",
      "\titers: 300, epoch: 6 | loss: 0.0787471\n",
      "\tspeed: 0.0477s/iter; left time: 201.2439s\n",
      "\titers: 400, epoch: 6 | loss: 0.0691097\n",
      "\tspeed: 0.0477s/iter; left time: 196.5368s\n",
      "\titers: 500, epoch: 6 | loss: 0.0787415\n",
      "\tspeed: 0.0477s/iter; left time: 191.7652s\n",
      "\titers: 600, epoch: 6 | loss: 0.0688312\n",
      "\tspeed: 0.0475s/iter; left time: 186.3779s\n",
      "\titers: 700, epoch: 6 | loss: 0.0719894\n",
      "\tspeed: 0.0477s/iter; left time: 182.0970s\n",
      "\titers: 800, epoch: 6 | loss: 0.0703194\n",
      "\tspeed: 0.0477s/iter; left time: 177.4717s\n",
      "\titers: 900, epoch: 6 | loss: 0.0661363\n",
      "\tspeed: 0.0476s/iter; left time: 172.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.0725727 Vali Loss: 0.0793032 Test Loss: 0.0889991\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0726100\n",
      "\tspeed: 0.1119s/iter; left time: 393.4853s\n",
      "\titers: 200, epoch: 7 | loss: 0.0638280\n",
      "\tspeed: 0.0473s/iter; left time: 161.6024s\n",
      "\titers: 300, epoch: 7 | loss: 0.0714715\n",
      "\tspeed: 0.0473s/iter; left time: 156.8270s\n",
      "\titers: 400, epoch: 7 | loss: 0.0687825\n",
      "\tspeed: 0.0473s/iter; left time: 152.1248s\n",
      "\titers: 500, epoch: 7 | loss: 0.0678533\n",
      "\tspeed: 0.0465s/iter; left time: 144.8768s\n",
      "\titers: 600, epoch: 7 | loss: 0.0674889\n",
      "\tspeed: 0.0474s/iter; left time: 143.0084s\n",
      "\titers: 700, epoch: 7 | loss: 0.0599818\n",
      "\tspeed: 0.0474s/iter; left time: 138.2006s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693051\n",
      "\tspeed: 0.0475s/iter; left time: 133.8327s\n",
      "\titers: 900, epoch: 7 | loss: 0.0677483\n",
      "\tspeed: 0.0474s/iter; left time: 128.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.93s\n",
      "Steps: 904 | Train Loss: 0.0693443 Vali Loss: 0.0803082 Test Loss: 0.0903231\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0680132\n",
      "\tspeed: 0.1124s/iter; left time: 293.5955s\n",
      "\titers: 200, epoch: 8 | loss: 0.0651403\n",
      "\tspeed: 0.0477s/iter; left time: 119.7791s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652519\n",
      "\tspeed: 0.0477s/iter; left time: 115.0940s\n",
      "\titers: 400, epoch: 8 | loss: 0.0637966\n",
      "\tspeed: 0.0477s/iter; left time: 110.3705s\n",
      "\titers: 500, epoch: 8 | loss: 0.0607010\n",
      "\tspeed: 0.0477s/iter; left time: 105.5669s\n",
      "\titers: 600, epoch: 8 | loss: 0.0625788\n",
      "\tspeed: 0.0478s/iter; left time: 100.9017s\n",
      "\titers: 700, epoch: 8 | loss: 0.0660454\n",
      "\tspeed: 0.0476s/iter; left time: 95.7366s\n",
      "\titers: 800, epoch: 8 | loss: 0.0644100\n",
      "\tspeed: 0.0476s/iter; left time: 91.0729s\n",
      "\titers: 900, epoch: 8 | loss: 0.0647821\n",
      "\tspeed: 0.0476s/iter; left time: 86.2740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.0664464 Vali Loss: 0.0813904 Test Loss: 0.0939181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0203001257032156, rmse:0.14247851073741913, mae:0.08875438570976257, rse:0.5387266278266907\n",
      "Original data scale mse:3148950.0, rmse:1774.528076171875, mae:1153.3165283203125, rse:0.12488079071044922\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2298318\n",
      "\tspeed: 0.0825s/iter; left time: 736.3882s\n",
      "\titers: 200, epoch: 1 | loss: 0.1998459\n",
      "\tspeed: 0.0534s/iter; left time: 470.8385s\n",
      "\titers: 300, epoch: 1 | loss: 0.2001658\n",
      "\tspeed: 0.0533s/iter; left time: 464.9805s\n",
      "\titers: 400, epoch: 1 | loss: 0.1908817\n",
      "\tspeed: 0.0534s/iter; left time: 460.0223s\n",
      "\titers: 500, epoch: 1 | loss: 0.1891606\n",
      "\tspeed: 0.0535s/iter; left time: 455.9600s\n",
      "\titers: 600, epoch: 1 | loss: 0.1892172\n",
      "\tspeed: 0.0534s/iter; left time: 449.4187s\n",
      "\titers: 700, epoch: 1 | loss: 0.1822665\n",
      "\tspeed: 0.0535s/iter; left time: 445.4146s\n",
      "\titers: 800, epoch: 1 | loss: 0.1839132\n",
      "\tspeed: 0.0533s/iter; left time: 438.3533s\n",
      "\titers: 900, epoch: 1 | loss: 0.1841313\n",
      "\tspeed: 0.0534s/iter; left time: 433.5217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.90s\n",
      "Steps: 902 | Train Loss: 0.1967058 Vali Loss: 0.1674167 Test Loss: 0.1840987\n",
      "Validation loss decreased (inf --> 0.167417).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1718581\n",
      "\tspeed: 0.1348s/iter; left time: 1080.9632s\n",
      "\titers: 200, epoch: 2 | loss: 0.1566561\n",
      "\tspeed: 0.0535s/iter; left time: 423.4127s\n",
      "\titers: 300, epoch: 2 | loss: 0.1566442\n",
      "\tspeed: 0.0537s/iter; left time: 420.0192s\n",
      "\titers: 400, epoch: 2 | loss: 0.1416597\n",
      "\tspeed: 0.0535s/iter; left time: 413.2291s\n",
      "\titers: 500, epoch: 2 | loss: 0.1273803\n",
      "\tspeed: 0.0538s/iter; left time: 409.6028s\n",
      "\titers: 600, epoch: 2 | loss: 0.1301640\n",
      "\tspeed: 0.0534s/iter; left time: 401.6584s\n",
      "\titers: 700, epoch: 2 | loss: 0.1060042\n",
      "\tspeed: 0.0536s/iter; left time: 397.3919s\n",
      "\titers: 800, epoch: 2 | loss: 0.0993617\n",
      "\tspeed: 0.0536s/iter; left time: 392.3517s\n",
      "\titers: 900, epoch: 2 | loss: 0.0959845\n",
      "\tspeed: 0.0535s/iter; left time: 386.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.1376420 Vali Loss: 0.0958561 Test Loss: 0.1030837\n",
      "Validation loss decreased (0.167417 --> 0.095856).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0903104\n",
      "\tspeed: 0.1475s/iter; left time: 1049.9315s\n",
      "\titers: 200, epoch: 3 | loss: 0.0961597\n",
      "\tspeed: 0.0536s/iter; left time: 375.9214s\n",
      "\titers: 300, epoch: 3 | loss: 0.0976604\n",
      "\tspeed: 0.0535s/iter; left time: 369.7555s\n",
      "\titers: 400, epoch: 3 | loss: 0.0974886\n",
      "\tspeed: 0.0535s/iter; left time: 364.5856s\n",
      "\titers: 500, epoch: 3 | loss: 0.0988006\n",
      "\tspeed: 0.0536s/iter; left time: 359.8330s\n",
      "\titers: 600, epoch: 3 | loss: 0.0879664\n",
      "\tspeed: 0.0537s/iter; left time: 355.0943s\n",
      "\titers: 700, epoch: 3 | loss: 0.0922868\n",
      "\tspeed: 0.0536s/iter; left time: 349.2342s\n",
      "\titers: 800, epoch: 3 | loss: 0.0906126\n",
      "\tspeed: 0.0536s/iter; left time: 343.6364s\n",
      "\titers: 900, epoch: 3 | loss: 0.0882223\n",
      "\tspeed: 0.0529s/iter; left time: 333.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0932331 Vali Loss: 0.0870312 Test Loss: 0.0972080\n",
      "Validation loss decreased (0.095856 --> 0.087031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886278\n",
      "\tspeed: 0.1350s/iter; left time: 838.7277s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887057\n",
      "\tspeed: 0.0537s/iter; left time: 328.1023s\n",
      "\titers: 300, epoch: 4 | loss: 0.0948177\n",
      "\tspeed: 0.0536s/iter; left time: 322.3888s\n",
      "\titers: 400, epoch: 4 | loss: 0.0810935\n",
      "\tspeed: 0.0537s/iter; left time: 317.6143s\n",
      "\titers: 500, epoch: 4 | loss: 0.0813296\n",
      "\tspeed: 0.0536s/iter; left time: 311.5330s\n",
      "\titers: 600, epoch: 4 | loss: 0.0820543\n",
      "\tspeed: 0.0536s/iter; left time: 306.0416s\n",
      "\titers: 700, epoch: 4 | loss: 0.0880838\n",
      "\tspeed: 0.0536s/iter; left time: 300.9334s\n",
      "\titers: 800, epoch: 4 | loss: 0.0881585\n",
      "\tspeed: 0.0536s/iter; left time: 295.6368s\n",
      "\titers: 900, epoch: 4 | loss: 0.0856838\n",
      "\tspeed: 0.0535s/iter; left time: 289.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.40s\n",
      "Steps: 902 | Train Loss: 0.0858926 Vali Loss: 0.0852741 Test Loss: 0.0950092\n",
      "Validation loss decreased (0.087031 --> 0.085274).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764841\n",
      "\tspeed: 0.1376s/iter; left time: 731.2550s\n",
      "\titers: 200, epoch: 5 | loss: 0.0780453\n",
      "\tspeed: 0.0538s/iter; left time: 280.2100s\n",
      "\titers: 300, epoch: 5 | loss: 0.0825350\n",
      "\tspeed: 0.0536s/iter; left time: 274.2535s\n",
      "\titers: 400, epoch: 5 | loss: 0.0867204\n",
      "\tspeed: 0.0537s/iter; left time: 269.1990s\n",
      "\titers: 500, epoch: 5 | loss: 0.0856278\n",
      "\tspeed: 0.0537s/iter; left time: 263.7113s\n",
      "\titers: 600, epoch: 5 | loss: 0.0901060\n",
      "\tspeed: 0.0536s/iter; left time: 257.8315s\n",
      "\titers: 700, epoch: 5 | loss: 0.0878257\n",
      "\tspeed: 0.0536s/iter; left time: 252.5243s\n",
      "\titers: 800, epoch: 5 | loss: 0.0791946\n",
      "\tspeed: 0.0536s/iter; left time: 247.1623s\n",
      "\titers: 900, epoch: 5 | loss: 0.0788658\n",
      "\tspeed: 0.0536s/iter; left time: 242.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.0813541 Vali Loss: 0.0838442 Test Loss: 0.0949016\n",
      "Validation loss decreased (0.085274 --> 0.083844).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0780597\n",
      "\tspeed: 0.1327s/iter; left time: 585.3461s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760589\n",
      "\tspeed: 0.0533s/iter; left time: 229.9676s\n",
      "\titers: 300, epoch: 6 | loss: 0.0752045\n",
      "\tspeed: 0.0534s/iter; left time: 224.9412s\n",
      "\titers: 400, epoch: 6 | loss: 0.0775517\n",
      "\tspeed: 0.0536s/iter; left time: 220.1926s\n",
      "\titers: 500, epoch: 6 | loss: 0.0747982\n",
      "\tspeed: 0.0535s/iter; left time: 214.4630s\n",
      "\titers: 600, epoch: 6 | loss: 0.0752919\n",
      "\tspeed: 0.0535s/iter; left time: 209.1105s\n",
      "\titers: 700, epoch: 6 | loss: 0.0737840\n",
      "\tspeed: 0.0532s/iter; left time: 202.8696s\n",
      "\titers: 800, epoch: 6 | loss: 0.0741504\n",
      "\tspeed: 0.0533s/iter; left time: 197.9036s\n",
      "\titers: 900, epoch: 6 | loss: 0.0761954\n",
      "\tspeed: 0.0534s/iter; left time: 192.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.0776061 Vali Loss: 0.0840367 Test Loss: 0.0930206\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769571\n",
      "\tspeed: 0.1295s/iter; left time: 454.2588s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793617\n",
      "\tspeed: 0.0538s/iter; left time: 183.4518s\n",
      "\titers: 300, epoch: 7 | loss: 0.0704730\n",
      "\tspeed: 0.0537s/iter; left time: 177.7622s\n",
      "\titers: 400, epoch: 7 | loss: 0.0761969\n",
      "\tspeed: 0.0537s/iter; left time: 172.4685s\n",
      "\titers: 500, epoch: 7 | loss: 0.0744571\n",
      "\tspeed: 0.0536s/iter; left time: 166.5060s\n",
      "\titers: 600, epoch: 7 | loss: 0.0700828\n",
      "\tspeed: 0.0537s/iter; left time: 161.5185s\n",
      "\titers: 700, epoch: 7 | loss: 0.0725735\n",
      "\tspeed: 0.0537s/iter; left time: 156.1507s\n",
      "\titers: 800, epoch: 7 | loss: 0.0692064\n",
      "\tspeed: 0.0537s/iter; left time: 150.9383s\n",
      "\titers: 900, epoch: 7 | loss: 0.0691122\n",
      "\tspeed: 0.0536s/iter; left time: 145.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0740751 Vali Loss: 0.0850344 Test Loss: 0.0976326\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0709344\n",
      "\tspeed: 0.1295s/iter; left time: 337.5863s\n",
      "\titers: 200, epoch: 8 | loss: 0.0714713\n",
      "\tspeed: 0.0535s/iter; left time: 134.1754s\n",
      "\titers: 300, epoch: 8 | loss: 0.0738888\n",
      "\tspeed: 0.0537s/iter; left time: 129.3121s\n",
      "\titers: 400, epoch: 8 | loss: 0.0697268\n",
      "\tspeed: 0.0537s/iter; left time: 123.9243s\n",
      "\titers: 500, epoch: 8 | loss: 0.0722686\n",
      "\tspeed: 0.0536s/iter; left time: 118.3762s\n",
      "\titers: 600, epoch: 8 | loss: 0.0642004\n",
      "\tspeed: 0.0536s/iter; left time: 112.8968s\n",
      "\titers: 700, epoch: 8 | loss: 0.0685385\n",
      "\tspeed: 0.0536s/iter; left time: 107.6008s\n",
      "\titers: 800, epoch: 8 | loss: 0.0682947\n",
      "\tspeed: 0.0537s/iter; left time: 102.4311s\n",
      "\titers: 900, epoch: 8 | loss: 0.0678271\n",
      "\tspeed: 0.0536s/iter; left time: 96.9129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.0704684 Vali Loss: 0.0865647 Test Loss: 0.0950548\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02299390733242035, rmse:0.15163742005825043, mae:0.09486686438322067, rse:0.5737535953521729\n",
      "Original data scale mse:3959525.75, rmse:1989.855712890625, mae:1283.2562255859375, rse:0.140165776014328\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2355672\n",
      "\tspeed: 0.0550s/iter; left time: 490.9036s\n",
      "\titers: 200, epoch: 1 | loss: 0.2082962\n",
      "\tspeed: 0.0534s/iter; left time: 471.4107s\n",
      "\titers: 300, epoch: 1 | loss: 0.2001346\n",
      "\tspeed: 0.0535s/iter; left time: 466.3010s\n",
      "\titers: 400, epoch: 1 | loss: 0.1898813\n",
      "\tspeed: 0.0505s/iter; left time: 435.6436s\n",
      "\titers: 500, epoch: 1 | loss: 0.1939274\n",
      "\tspeed: 0.0536s/iter; left time: 456.8865s\n",
      "\titers: 600, epoch: 1 | loss: 0.1758054\n",
      "\tspeed: 0.0538s/iter; left time: 453.1958s\n",
      "\titers: 700, epoch: 1 | loss: 0.1830661\n",
      "\tspeed: 0.0536s/iter; left time: 446.1904s\n",
      "\titers: 800, epoch: 1 | loss: 0.1783938\n",
      "\tspeed: 0.0536s/iter; left time: 440.3851s\n",
      "\titers: 900, epoch: 1 | loss: 0.1776050\n",
      "\tspeed: 0.0537s/iter; left time: 435.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.27s\n",
      "Steps: 902 | Train Loss: 0.1993217 Vali Loss: 0.1684725 Test Loss: 0.1856237\n",
      "Validation loss decreased (inf --> 0.168473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1772077\n",
      "\tspeed: 0.1382s/iter; left time: 1108.5755s\n",
      "\titers: 200, epoch: 2 | loss: 0.1593870\n",
      "\tspeed: 0.0535s/iter; left time: 424.0562s\n",
      "\titers: 300, epoch: 2 | loss: 0.1458719\n",
      "\tspeed: 0.0537s/iter; left time: 419.5145s\n",
      "\titers: 400, epoch: 2 | loss: 0.1398193\n",
      "\tspeed: 0.0534s/iter; left time: 412.2365s\n",
      "\titers: 500, epoch: 2 | loss: 0.1258138\n",
      "\tspeed: 0.0536s/iter; left time: 408.5763s\n",
      "\titers: 600, epoch: 2 | loss: 0.1268865\n",
      "\tspeed: 0.0537s/iter; left time: 403.5820s\n",
      "\titers: 700, epoch: 2 | loss: 0.1063164\n",
      "\tspeed: 0.0534s/iter; left time: 396.2074s\n",
      "\titers: 800, epoch: 2 | loss: 0.1085631\n",
      "\tspeed: 0.0537s/iter; left time: 392.7548s\n",
      "\titers: 900, epoch: 2 | loss: 0.1064118\n",
      "\tspeed: 0.0535s/iter; left time: 385.9334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.1362844 Vali Loss: 0.0990677 Test Loss: 0.1042230\n",
      "Validation loss decreased (0.168473 --> 0.099068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0998725\n",
      "\tspeed: 0.1361s/iter; left time: 968.4711s\n",
      "\titers: 200, epoch: 3 | loss: 0.0983012\n",
      "\tspeed: 0.0536s/iter; left time: 375.8272s\n",
      "\titers: 300, epoch: 3 | loss: 0.0917605\n",
      "\tspeed: 0.0536s/iter; left time: 370.9441s\n",
      "\titers: 400, epoch: 3 | loss: 0.0950676\n",
      "\tspeed: 0.0532s/iter; left time: 362.9610s\n",
      "\titers: 500, epoch: 3 | loss: 0.0909999\n",
      "\tspeed: 0.0534s/iter; left time: 358.7169s\n",
      "\titers: 600, epoch: 3 | loss: 0.0889725\n",
      "\tspeed: 0.0535s/iter; left time: 354.3174s\n",
      "\titers: 700, epoch: 3 | loss: 0.0891478\n",
      "\tspeed: 0.0534s/iter; left time: 348.2011s\n",
      "\titers: 800, epoch: 3 | loss: 0.0936719\n",
      "\tspeed: 0.0536s/iter; left time: 344.2168s\n",
      "\titers: 900, epoch: 3 | loss: 0.0865493\n",
      "\tspeed: 0.0536s/iter; left time: 338.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.51s\n",
      "Steps: 902 | Train Loss: 0.0931072 Vali Loss: 0.0867504 Test Loss: 0.0969969\n",
      "Validation loss decreased (0.099068 --> 0.086750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0893613\n",
      "\tspeed: 0.1335s/iter; left time: 829.5846s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867445\n",
      "\tspeed: 0.0537s/iter; left time: 328.1827s\n",
      "\titers: 300, epoch: 4 | loss: 0.0891742\n",
      "\tspeed: 0.0537s/iter; left time: 322.7572s\n",
      "\titers: 400, epoch: 4 | loss: 0.0909827\n",
      "\tspeed: 0.0536s/iter; left time: 316.9791s\n",
      "\titers: 500, epoch: 4 | loss: 0.0847673\n",
      "\tspeed: 0.0536s/iter; left time: 311.5998s\n",
      "\titers: 600, epoch: 4 | loss: 0.0848179\n",
      "\tspeed: 0.0536s/iter; left time: 306.1912s\n",
      "\titers: 700, epoch: 4 | loss: 0.0837448\n",
      "\tspeed: 0.0537s/iter; left time: 301.2962s\n",
      "\titers: 800, epoch: 4 | loss: 0.0826288\n",
      "\tspeed: 0.0537s/iter; left time: 296.1636s\n",
      "\titers: 900, epoch: 4 | loss: 0.0867797\n",
      "\tspeed: 0.0536s/iter; left time: 290.0531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.0861360 Vali Loss: 0.0855893 Test Loss: 0.0923006\n",
      "Validation loss decreased (0.086750 --> 0.085589).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0843569\n",
      "\tspeed: 0.1323s/iter; left time: 702.6738s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802317\n",
      "\tspeed: 0.0533s/iter; left time: 277.7716s\n",
      "\titers: 300, epoch: 5 | loss: 0.0815511\n",
      "\tspeed: 0.0444s/iter; left time: 226.9064s\n",
      "\titers: 400, epoch: 5 | loss: 0.0857412\n",
      "\tspeed: 0.0493s/iter; left time: 247.2085s\n",
      "\titers: 500, epoch: 5 | loss: 0.0838052\n",
      "\tspeed: 0.0535s/iter; left time: 262.8507s\n",
      "\titers: 600, epoch: 5 | loss: 0.0853470\n",
      "\tspeed: 0.0534s/iter; left time: 256.9961s\n",
      "\titers: 700, epoch: 5 | loss: 0.0854153\n",
      "\tspeed: 0.0534s/iter; left time: 251.4942s\n",
      "\titers: 800, epoch: 5 | loss: 0.0780036\n",
      "\tspeed: 0.0537s/iter; left time: 247.5287s\n",
      "\titers: 900, epoch: 5 | loss: 0.0753279\n",
      "\tspeed: 0.0535s/iter; left time: 241.4745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 902 | Train Loss: 0.0815848 Vali Loss: 0.0841493 Test Loss: 0.0947114\n",
      "Validation loss decreased (0.085589 --> 0.084149).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0812029\n",
      "\tspeed: 0.1327s/iter; left time: 585.3540s\n",
      "\titers: 200, epoch: 6 | loss: 0.0748727\n",
      "\tspeed: 0.0536s/iter; left time: 230.9717s\n",
      "\titers: 300, epoch: 6 | loss: 0.0804090\n",
      "\tspeed: 0.0534s/iter; left time: 224.8703s\n",
      "\titers: 400, epoch: 6 | loss: 0.0886825\n",
      "\tspeed: 0.0536s/iter; left time: 220.2488s\n",
      "\titers: 500, epoch: 6 | loss: 0.0724488\n",
      "\tspeed: 0.0536s/iter; left time: 215.1116s\n",
      "\titers: 600, epoch: 6 | loss: 0.0776584\n",
      "\tspeed: 0.0534s/iter; left time: 209.0327s\n",
      "\titers: 700, epoch: 6 | loss: 0.0772588\n",
      "\tspeed: 0.0534s/iter; left time: 203.4286s\n",
      "\titers: 800, epoch: 6 | loss: 0.0730131\n",
      "\tspeed: 0.0534s/iter; left time: 198.0591s\n",
      "\titers: 900, epoch: 6 | loss: 0.0727902\n",
      "\tspeed: 0.0537s/iter; left time: 193.7541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.0776841 Vali Loss: 0.0844284 Test Loss: 0.0970682\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0801010\n",
      "\tspeed: 0.1291s/iter; left time: 452.9455s\n",
      "\titers: 200, epoch: 7 | loss: 0.0696431\n",
      "\tspeed: 0.0534s/iter; left time: 182.0305s\n",
      "\titers: 300, epoch: 7 | loss: 0.0785697\n",
      "\tspeed: 0.0535s/iter; left time: 176.9202s\n",
      "\titers: 400, epoch: 7 | loss: 0.0787124\n",
      "\tspeed: 0.0535s/iter; left time: 171.7072s\n",
      "\titers: 500, epoch: 7 | loss: 0.0768499\n",
      "\tspeed: 0.0536s/iter; left time: 166.4997s\n",
      "\titers: 600, epoch: 7 | loss: 0.0727005\n",
      "\tspeed: 0.0535s/iter; left time: 160.9517s\n",
      "\titers: 700, epoch: 7 | loss: 0.0715927\n",
      "\tspeed: 0.0529s/iter; left time: 153.8591s\n",
      "\titers: 800, epoch: 7 | loss: 0.0703656\n",
      "\tspeed: 0.0535s/iter; left time: 150.2613s\n",
      "\titers: 900, epoch: 7 | loss: 0.0697115\n",
      "\tspeed: 0.0536s/iter; left time: 145.1048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.0739525 Vali Loss: 0.0846868 Test Loss: 0.0978098\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0693346\n",
      "\tspeed: 0.1290s/iter; left time: 336.4067s\n",
      "\titers: 200, epoch: 8 | loss: 0.0674614\n",
      "\tspeed: 0.0536s/iter; left time: 134.3733s\n",
      "\titers: 300, epoch: 8 | loss: 0.0711595\n",
      "\tspeed: 0.0532s/iter; left time: 128.1560s\n",
      "\titers: 400, epoch: 8 | loss: 0.0698352\n",
      "\tspeed: 0.0535s/iter; left time: 123.4025s\n",
      "\titers: 500, epoch: 8 | loss: 0.0765227\n",
      "\tspeed: 0.0534s/iter; left time: 117.8613s\n",
      "\titers: 600, epoch: 8 | loss: 0.0681868\n",
      "\tspeed: 0.0535s/iter; left time: 112.7772s\n",
      "\titers: 700, epoch: 8 | loss: 0.0718112\n",
      "\tspeed: 0.0533s/iter; left time: 106.9776s\n",
      "\titers: 800, epoch: 8 | loss: 0.0683741\n",
      "\tspeed: 0.0532s/iter; left time: 101.5390s\n",
      "\titers: 900, epoch: 8 | loss: 0.0696974\n",
      "\tspeed: 0.0534s/iter; left time: 96.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.41s\n",
      "Steps: 902 | Train Loss: 0.0703952 Vali Loss: 0.0860372 Test Loss: 0.0952666\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02248666062951088, rmse:0.14995552599430084, mae:0.09472323209047318, rse:0.5673897862434387\n",
      "Original data scale mse:4440883.0, rmse:2107.34033203125, mae:1338.431884765625, rse:0.1484414041042328\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.00001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.3912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.3943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.5135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>0.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1043</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.3943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.5422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.5408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.5738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.5674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0107  0.1035  0.0632  0.3912\n",
       "              2         24        0.0109  0.1043  0.0648  0.3943\n",
       "              1         96        0.0188  0.1372  0.0888  0.5187\n",
       "              2         96        0.0184  0.1358  0.0881  0.5135\n",
       "              1         168       0.0202  0.1421  0.0942  0.5377\n",
       "              2         168       0.0205  0.1433  0.0958  0.5421\n",
       "RMSE          1         24        0.0109  0.1043  0.0635  0.3943\n",
       "              2         24        0.0112  0.1060  0.0651  0.4005\n",
       "              1         96        0.0188  0.1370  0.0885  0.5180\n",
       "              2         96        0.0183  0.1353  0.0879  0.5118\n",
       "              1         168       0.0205  0.1433  0.0946  0.5422\n",
       "              2         168       0.0204  0.1429  0.0945  0.5408\n",
       "MAE           1         24        0.0115  0.1072  0.0629  0.4050\n",
       "              2         24        0.0111  0.1051  0.0611  0.3973\n",
       "              1         96        0.0200  0.1414  0.0888  0.5345\n",
       "              2         96        0.0203  0.1425  0.0888  0.5387\n",
       "              1         168       0.0230  0.1516  0.0949  0.5738\n",
       "              2         168       0.0225  0.1500  0.0947  0.5674"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1526122.125</td>\n",
       "      <td>1235.3632</td>\n",
       "      <td>813.0915</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1720168.500</td>\n",
       "      <td>1311.5520</td>\n",
       "      <td>849.8506</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3564554.250</td>\n",
       "      <td>1888.0027</td>\n",
       "      <td>1239.8208</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3233782.000</td>\n",
       "      <td>1798.2720</td>\n",
       "      <td>1197.2759</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4201466.000</td>\n",
       "      <td>2049.7478</td>\n",
       "      <td>1339.4785</td>\n",
       "      <td>0.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4258257.500</td>\n",
       "      <td>2063.5547</td>\n",
       "      <td>1360.0095</td>\n",
       "      <td>0.1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1534866.750</td>\n",
       "      <td>1238.8973</td>\n",
       "      <td>812.3772</td>\n",
       "      <td>0.0871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1773736.375</td>\n",
       "      <td>1331.8169</td>\n",
       "      <td>851.7638</td>\n",
       "      <td>0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3390077.000</td>\n",
       "      <td>1841.2162</td>\n",
       "      <td>1212.3903</td>\n",
       "      <td>0.1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3278264.250</td>\n",
       "      <td>1810.5978</td>\n",
       "      <td>1197.8483</td>\n",
       "      <td>0.1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4204012.500</td>\n",
       "      <td>2050.3689</td>\n",
       "      <td>1340.2507</td>\n",
       "      <td>0.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4257367.000</td>\n",
       "      <td>2063.3389</td>\n",
       "      <td>1350.4883</td>\n",
       "      <td>0.1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1691501.875</td>\n",
       "      <td>1300.5775</td>\n",
       "      <td>802.2434</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1389721.625</td>\n",
       "      <td>1178.8645</td>\n",
       "      <td>748.0410</td>\n",
       "      <td>0.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3605560.250</td>\n",
       "      <td>1898.8313</td>\n",
       "      <td>1205.3231</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3148950.000</td>\n",
       "      <td>1774.5281</td>\n",
       "      <td>1153.3165</td>\n",
       "      <td>0.1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3959525.750</td>\n",
       "      <td>1989.8557</td>\n",
       "      <td>1283.2562</td>\n",
       "      <td>0.1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4440883.000</td>\n",
       "      <td>2107.3403</td>\n",
       "      <td>1338.4319</td>\n",
       "      <td>0.1484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1526122.125  1235.3632   813.0915  0.0868\n",
       "              2         24        1720168.500  1311.5520   849.8506  0.0922\n",
       "              1         96        3564554.250  1888.0027  1239.8208  0.1329\n",
       "              2         96        3233782.000  1798.2720  1197.2759  0.1266\n",
       "              1         168       4201466.000  2049.7478  1339.4785  0.1444\n",
       "              2         168       4258257.500  2063.5547  1360.0095  0.1454\n",
       "RMSE          1         24        1534866.750  1238.8973   812.3772  0.0871\n",
       "              2         24        1773736.375  1331.8169   851.7638  0.0936\n",
       "              1         96        3390077.000  1841.2162  1212.3903  0.1296\n",
       "              2         96        3278264.250  1810.5978  1197.8483  0.1274\n",
       "              1         168       4204012.500  2050.3689  1340.2507  0.1444\n",
       "              2         168       4257367.000  2063.3389  1350.4883  0.1453\n",
       "MAE           1         24        1691501.875  1300.5775   802.2434  0.0914\n",
       "              2         24        1389721.625  1178.8645   748.0410  0.0828\n",
       "              1         96        3605560.250  1898.8313  1205.3231  0.1336\n",
       "              2         96        3148950.000  1774.5281  1153.3165  0.1249\n",
       "              1         168       3959525.750  1989.8557  1283.2562  0.1402\n",
       "              2         168       4440883.000  2107.3403  1338.4319  0.1484"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.3928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0643</td>\n",
       "      <td>0.3974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1419</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.5161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.5149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.5706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.5415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0113  0.1061  0.0620  0.4011\n",
       "         MSE            0.0108  0.1039  0.0640  0.3928\n",
       "         RMSE           0.0111  0.1052  0.0643  0.3974\n",
       "96       MAE            0.0201  0.1419  0.0888  0.5366\n",
       "         MSE            0.0186  0.1365  0.0884  0.5161\n",
       "         RMSE           0.0185  0.1362  0.0882  0.5149\n",
       "168      MAE            0.0227  0.1508  0.0948  0.5706\n",
       "         MSE            0.0204  0.1427  0.0950  0.5399\n",
       "         RMSE           0.0205  0.1431  0.0946  0.5415"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.540612e+06</td>\n",
       "      <td>1239.7210</td>\n",
       "      <td>775.1422</td>\n",
       "      <td>0.0871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.623145e+06</td>\n",
       "      <td>1273.4576</td>\n",
       "      <td>831.4711</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.654302e+06</td>\n",
       "      <td>1285.3571</td>\n",
       "      <td>832.0705</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.377255e+06</td>\n",
       "      <td>1836.6797</td>\n",
       "      <td>1179.3198</td>\n",
       "      <td>0.1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.399168e+06</td>\n",
       "      <td>1843.1373</td>\n",
       "      <td>1218.5483</td>\n",
       "      <td>0.1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.334171e+06</td>\n",
       "      <td>1825.9070</td>\n",
       "      <td>1205.1193</td>\n",
       "      <td>0.1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.200204e+06</td>\n",
       "      <td>2048.5980</td>\n",
       "      <td>1310.8441</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.229862e+06</td>\n",
       "      <td>2056.6512</td>\n",
       "      <td>1349.7440</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.230690e+06</td>\n",
       "      <td>2056.8539</td>\n",
       "      <td>1345.3695</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.540612e+06  1239.7210   775.1422  0.0871\n",
       "         MSE            1.623145e+06  1273.4576   831.4711  0.0895\n",
       "         RMSE           1.654302e+06  1285.3571   832.0705  0.0903\n",
       "96       MAE            3.377255e+06  1836.6797  1179.3198  0.1293\n",
       "         MSE            3.399168e+06  1843.1373  1218.5483  0.1297\n",
       "         RMSE           3.334171e+06  1825.9070  1205.1193  0.1285\n",
       "168      MAE            4.200204e+06  2048.5980  1310.8441  0.1443\n",
       "         MSE            4.229862e+06  2056.6512  1349.7440  0.1449\n",
       "         RMSE           4.230690e+06  2056.8539  1345.3695  0.1449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0179542\n",
      "\tspeed: 0.0552s/iter; left time: 487.2250s\n",
      "\titers: 200, epoch: 1 | loss: 0.0138904\n",
      "\tspeed: 0.0273s/iter; left time: 238.1074s\n",
      "\titers: 300, epoch: 1 | loss: 0.0134035\n",
      "\tspeed: 0.0273s/iter; left time: 235.6602s\n",
      "\titers: 400, epoch: 1 | loss: 0.0135565\n",
      "\tspeed: 0.0274s/iter; left time: 233.9331s\n",
      "\titers: 500, epoch: 1 | loss: 0.0133962\n",
      "\tspeed: 0.0274s/iter; left time: 231.2300s\n",
      "\titers: 600, epoch: 1 | loss: 0.0119742\n",
      "\tspeed: 0.0274s/iter; left time: 228.4587s\n",
      "\titers: 700, epoch: 1 | loss: 0.0094369\n",
      "\tspeed: 0.0274s/iter; left time: 225.4702s\n",
      "\titers: 800, epoch: 1 | loss: 0.0085627\n",
      "\tspeed: 0.0274s/iter; left time: 222.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 893 | Train Loss: 0.0136738 Vali Loss: 0.0103639 Test Loss: 0.0115427\n",
      "Validation loss decreased (inf --> 0.010364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0108790\n",
      "\tspeed: 0.1052s/iter; left time: 835.0876s\n",
      "\titers: 200, epoch: 2 | loss: 0.0106265\n",
      "\tspeed: 0.0273s/iter; left time: 214.2982s\n",
      "\titers: 300, epoch: 2 | loss: 0.0171496\n",
      "\tspeed: 0.0273s/iter; left time: 211.5469s\n",
      "\titers: 400, epoch: 2 | loss: 0.0108691\n",
      "\tspeed: 0.0274s/iter; left time: 209.1198s\n",
      "\titers: 500, epoch: 2 | loss: 0.0096130\n",
      "\tspeed: 0.0273s/iter; left time: 205.9187s\n",
      "\titers: 600, epoch: 2 | loss: 0.0067438\n",
      "\tspeed: 0.0273s/iter; left time: 203.2502s\n",
      "\titers: 700, epoch: 2 | loss: 0.0092933\n",
      "\tspeed: 0.0273s/iter; left time: 200.6816s\n",
      "\titers: 800, epoch: 2 | loss: 0.0094463\n",
      "\tspeed: 0.0274s/iter; left time: 198.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0112482 Vali Loss: 0.0105930 Test Loss: 0.0121308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082705\n",
      "\tspeed: 0.1032s/iter; left time: 727.0771s\n",
      "\titers: 200, epoch: 3 | loss: 0.0104382\n",
      "\tspeed: 0.0274s/iter; left time: 189.9706s\n",
      "\titers: 300, epoch: 3 | loss: 0.0095984\n",
      "\tspeed: 0.0273s/iter; left time: 187.1716s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099487\n",
      "\tspeed: 0.0273s/iter; left time: 184.2654s\n",
      "\titers: 500, epoch: 3 | loss: 0.0085704\n",
      "\tspeed: 0.0273s/iter; left time: 181.6043s\n",
      "\titers: 600, epoch: 3 | loss: 0.0132205\n",
      "\tspeed: 0.0273s/iter; left time: 178.8964s\n",
      "\titers: 700, epoch: 3 | loss: 0.0080598\n",
      "\tspeed: 0.0273s/iter; left time: 176.2561s\n",
      "\titers: 800, epoch: 3 | loss: 0.0189686\n",
      "\tspeed: 0.0274s/iter; left time: 173.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 893 | Train Loss: 0.0108874 Vali Loss: 0.0112805 Test Loss: 0.0129576\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136215\n",
      "\tspeed: 0.1034s/iter; left time: 635.8994s\n",
      "\titers: 200, epoch: 4 | loss: 0.0101591\n",
      "\tspeed: 0.0273s/iter; left time: 165.2181s\n",
      "\titers: 300, epoch: 4 | loss: 0.0112350\n",
      "\tspeed: 0.0273s/iter; left time: 162.5542s\n",
      "\titers: 400, epoch: 4 | loss: 0.0081314\n",
      "\tspeed: 0.0273s/iter; left time: 159.9038s\n",
      "\titers: 500, epoch: 4 | loss: 0.0093440\n",
      "\tspeed: 0.0273s/iter; left time: 157.1197s\n",
      "\titers: 600, epoch: 4 | loss: 0.0082074\n",
      "\tspeed: 0.0273s/iter; left time: 154.3747s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132336\n",
      "\tspeed: 0.0273s/iter; left time: 151.6975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0107905\n",
      "\tspeed: 0.0273s/iter; left time: 148.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 893 | Train Loss: 0.0102207 Vali Loss: 0.0100708 Test Loss: 0.0113745\n",
      "Validation loss decreased (0.010364 --> 0.010071).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0115043\n",
      "\tspeed: 0.1043s/iter; left time: 548.3836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0084141\n",
      "\tspeed: 0.0273s/iter; left time: 140.9637s\n",
      "\titers: 300, epoch: 5 | loss: 0.0127091\n",
      "\tspeed: 0.0273s/iter; left time: 138.1543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0153487\n",
      "\tspeed: 0.0273s/iter; left time: 135.5170s\n",
      "\titers: 500, epoch: 5 | loss: 0.0081473\n",
      "\tspeed: 0.0273s/iter; left time: 132.7334s\n",
      "\titers: 600, epoch: 5 | loss: 0.0102224\n",
      "\tspeed: 0.0274s/iter; left time: 130.2442s\n",
      "\titers: 700, epoch: 5 | loss: 0.0080581\n",
      "\tspeed: 0.0274s/iter; left time: 127.5125s\n",
      "\titers: 800, epoch: 5 | loss: 0.0064560\n",
      "\tspeed: 0.0274s/iter; left time: 124.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.0096187 Vali Loss: 0.0101121 Test Loss: 0.0111427\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0088460\n",
      "\tspeed: 0.1025s/iter; left time: 447.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0091043\n",
      "\tspeed: 0.0273s/iter; left time: 116.5049s\n",
      "\titers: 300, epoch: 6 | loss: 0.0085249\n",
      "\tspeed: 0.0273s/iter; left time: 113.7709s\n",
      "\titers: 400, epoch: 6 | loss: 0.0152927\n",
      "\tspeed: 0.0273s/iter; left time: 111.1869s\n",
      "\titers: 500, epoch: 6 | loss: 0.0070305\n",
      "\tspeed: 0.0273s/iter; left time: 108.3764s\n",
      "\titers: 600, epoch: 6 | loss: 0.0100624\n",
      "\tspeed: 0.0273s/iter; left time: 105.5898s\n",
      "\titers: 700, epoch: 6 | loss: 0.0063936\n",
      "\tspeed: 0.0273s/iter; left time: 102.9194s\n",
      "\titers: 800, epoch: 6 | loss: 0.0066943\n",
      "\tspeed: 0.0274s/iter; left time: 100.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0088890 Vali Loss: 0.0101707 Test Loss: 0.0111860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0083871\n",
      "\tspeed: 0.1026s/iter; left time: 356.3202s\n",
      "\titers: 200, epoch: 7 | loss: 0.0053402\n",
      "\tspeed: 0.0273s/iter; left time: 92.0997s\n",
      "\titers: 300, epoch: 7 | loss: 0.0097876\n",
      "\tspeed: 0.0274s/iter; left time: 89.5210s\n",
      "\titers: 400, epoch: 7 | loss: 0.0099697\n",
      "\tspeed: 0.0274s/iter; left time: 86.8617s\n",
      "\titers: 500, epoch: 7 | loss: 0.0062928\n",
      "\tspeed: 0.0274s/iter; left time: 84.1095s\n",
      "\titers: 600, epoch: 7 | loss: 0.0058842\n",
      "\tspeed: 0.0275s/iter; left time: 81.6776s\n",
      "\titers: 700, epoch: 7 | loss: 0.0072408\n",
      "\tspeed: 0.0273s/iter; left time: 78.4893s\n",
      "\titers: 800, epoch: 7 | loss: 0.0060141\n",
      "\tspeed: 0.0273s/iter; left time: 75.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 893 | Train Loss: 0.0082139 Vali Loss: 0.0104854 Test Loss: 0.0114490\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011374467983841896, rmse:0.10665114969015121, mae:0.06564203649759293, rse:0.40304216742515564\n",
      "Original data scale mse:1649581.25, rmse:1284.3602294921875, mae:850.4398803710938, rse:0.09025502949953079\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0166307\n",
      "\tspeed: 0.0299s/iter; left time: 263.9967s\n",
      "\titers: 200, epoch: 1 | loss: 0.0166566\n",
      "\tspeed: 0.0273s/iter; left time: 238.6638s\n",
      "\titers: 300, epoch: 1 | loss: 0.0141988\n",
      "\tspeed: 0.0274s/iter; left time: 236.3787s\n",
      "\titers: 400, epoch: 1 | loss: 0.0141700\n",
      "\tspeed: 0.0274s/iter; left time: 233.4709s\n",
      "\titers: 500, epoch: 1 | loss: 0.0141194\n",
      "\tspeed: 0.0274s/iter; left time: 230.6842s\n",
      "\titers: 600, epoch: 1 | loss: 0.0084427\n",
      "\tspeed: 0.0273s/iter; left time: 227.7201s\n",
      "\titers: 700, epoch: 1 | loss: 0.0085769\n",
      "\tspeed: 0.0274s/iter; left time: 225.5102s\n",
      "\titers: 800, epoch: 1 | loss: 0.0109168\n",
      "\tspeed: 0.0274s/iter; left time: 222.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0138819 Vali Loss: 0.0103448 Test Loss: 0.0114709\n",
      "Validation loss decreased (inf --> 0.010345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0129929\n",
      "\tspeed: 0.1051s/iter; left time: 834.6183s\n",
      "\titers: 200, epoch: 2 | loss: 0.0109798\n",
      "\tspeed: 0.0274s/iter; left time: 214.7107s\n",
      "\titers: 300, epoch: 2 | loss: 0.0116839\n",
      "\tspeed: 0.0274s/iter; left time: 212.1379s\n",
      "\titers: 400, epoch: 2 | loss: 0.0110836\n",
      "\tspeed: 0.0273s/iter; left time: 208.8368s\n",
      "\titers: 500, epoch: 2 | loss: 0.0118132\n",
      "\tspeed: 0.0274s/iter; left time: 206.7823s\n",
      "\titers: 600, epoch: 2 | loss: 0.0090276\n",
      "\tspeed: 0.0274s/iter; left time: 204.1027s\n",
      "\titers: 700, epoch: 2 | loss: 0.0093626\n",
      "\tspeed: 0.0273s/iter; left time: 200.5686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0107725\n",
      "\tspeed: 0.0273s/iter; left time: 197.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 893 | Train Loss: 0.0112159 Vali Loss: 0.0109890 Test Loss: 0.0122895\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082013\n",
      "\tspeed: 0.1034s/iter; left time: 728.3026s\n",
      "\titers: 200, epoch: 3 | loss: 0.0094840\n",
      "\tspeed: 0.0272s/iter; left time: 188.9278s\n",
      "\titers: 300, epoch: 3 | loss: 0.0102744\n",
      "\tspeed: 0.0272s/iter; left time: 186.1707s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099393\n",
      "\tspeed: 0.0272s/iter; left time: 183.5389s\n",
      "\titers: 500, epoch: 3 | loss: 0.0106268\n",
      "\tspeed: 0.0272s/iter; left time: 180.4941s\n",
      "\titers: 600, epoch: 3 | loss: 0.0128014\n",
      "\tspeed: 0.0274s/iter; left time: 179.3906s\n",
      "\titers: 700, epoch: 3 | loss: 0.0077773\n",
      "\tspeed: 0.0274s/iter; left time: 176.8723s\n",
      "\titers: 800, epoch: 3 | loss: 0.0084611\n",
      "\tspeed: 0.0272s/iter; left time: 172.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0103463 Vali Loss: 0.0102759 Test Loss: 0.0115329\n",
      "Validation loss decreased (0.010345 --> 0.010276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0077549\n",
      "\tspeed: 0.1058s/iter; left time: 651.0412s\n",
      "\titers: 200, epoch: 4 | loss: 0.0082192\n",
      "\tspeed: 0.0274s/iter; left time: 165.7412s\n",
      "\titers: 300, epoch: 4 | loss: 0.0111770\n",
      "\tspeed: 0.0273s/iter; left time: 162.7405s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101953\n",
      "\tspeed: 0.0274s/iter; left time: 160.0846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0088418\n",
      "\tspeed: 0.0274s/iter; left time: 157.3829s\n",
      "\titers: 600, epoch: 4 | loss: 0.0097280\n",
      "\tspeed: 0.0274s/iter; left time: 154.6599s\n",
      "\titers: 700, epoch: 4 | loss: 0.0072450\n",
      "\tspeed: 0.0274s/iter; left time: 151.9348s\n",
      "\titers: 800, epoch: 4 | loss: 0.0095672\n",
      "\tspeed: 0.0274s/iter; left time: 149.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0096818 Vali Loss: 0.0104526 Test Loss: 0.0117177\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0081902\n",
      "\tspeed: 0.1034s/iter; left time: 543.9136s\n",
      "\titers: 200, epoch: 5 | loss: 0.0095075\n",
      "\tspeed: 0.0276s/iter; left time: 142.1739s\n",
      "\titers: 300, epoch: 5 | loss: 0.0122090\n",
      "\tspeed: 0.0276s/iter; left time: 139.4676s\n",
      "\titers: 400, epoch: 5 | loss: 0.0068247\n",
      "\tspeed: 0.0276s/iter; left time: 136.8705s\n",
      "\titers: 500, epoch: 5 | loss: 0.0092223\n",
      "\tspeed: 0.0276s/iter; left time: 134.0687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0071447\n",
      "\tspeed: 0.0275s/iter; left time: 131.0474s\n",
      "\titers: 700, epoch: 5 | loss: 0.0104501\n",
      "\tspeed: 0.0276s/iter; left time: 128.4322s\n",
      "\titers: 800, epoch: 5 | loss: 0.0105895\n",
      "\tspeed: 0.0275s/iter; left time: 125.5672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 893 | Train Loss: 0.0092726 Vali Loss: 0.0104986 Test Loss: 0.0117461\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0108101\n",
      "\tspeed: 0.1039s/iter; left time: 453.8211s\n",
      "\titers: 200, epoch: 6 | loss: 0.0076216\n",
      "\tspeed: 0.0276s/iter; left time: 117.7827s\n",
      "\titers: 300, epoch: 6 | loss: 0.0076059\n",
      "\tspeed: 0.0275s/iter; left time: 114.7628s\n",
      "\titers: 400, epoch: 6 | loss: 0.0092112\n",
      "\tspeed: 0.0276s/iter; left time: 112.3754s\n",
      "\titers: 500, epoch: 6 | loss: 0.0112508\n",
      "\tspeed: 0.0271s/iter; left time: 107.6380s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075125\n",
      "\tspeed: 0.0272s/iter; left time: 104.9773s\n",
      "\titers: 700, epoch: 6 | loss: 0.0073639\n",
      "\tspeed: 0.0272s/iter; left time: 102.2479s\n",
      "\titers: 800, epoch: 6 | loss: 0.0104844\n",
      "\tspeed: 0.0273s/iter; left time: 100.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.0086391 Vali Loss: 0.0105031 Test Loss: 0.0113079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011532868258655071, rmse:0.10739119350910187, mae:0.06529892235994339, rse:0.40583881735801697\n",
      "Original data scale mse:1637449.875, rmse:1279.6287841796875, mae:845.58740234375, rse:0.08992253243923187\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0263875\n",
      "\tspeed: 0.0550s/iter; left time: 484.5276s\n",
      "\titers: 200, epoch: 1 | loss: 0.0218959\n",
      "\tspeed: 0.0275s/iter; left time: 239.5755s\n",
      "\titers: 300, epoch: 1 | loss: 0.0232871\n",
      "\tspeed: 0.0275s/iter; left time: 236.6156s\n",
      "\titers: 400, epoch: 1 | loss: 0.0175504\n",
      "\tspeed: 0.0275s/iter; left time: 233.7479s\n",
      "\titers: 500, epoch: 1 | loss: 0.0178115\n",
      "\tspeed: 0.0275s/iter; left time: 230.9166s\n",
      "\titers: 600, epoch: 1 | loss: 0.0190175\n",
      "\tspeed: 0.0275s/iter; left time: 228.1475s\n",
      "\titers: 700, epoch: 1 | loss: 0.0164534\n",
      "\tspeed: 0.0275s/iter; left time: 225.7372s\n",
      "\titers: 800, epoch: 1 | loss: 0.0149383\n",
      "\tspeed: 0.0275s/iter; left time: 222.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0202432 Vali Loss: 0.0170104 Test Loss: 0.0181856\n",
      "Validation loss decreased (inf --> 0.017010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0198332\n",
      "\tspeed: 0.1035s/iter; left time: 820.0447s\n",
      "\titers: 200, epoch: 2 | loss: 0.0126811\n",
      "\tspeed: 0.0274s/iter; left time: 214.5012s\n",
      "\titers: 300, epoch: 2 | loss: 0.0172694\n",
      "\tspeed: 0.0274s/iter; left time: 211.7450s\n",
      "\titers: 400, epoch: 2 | loss: 0.0172652\n",
      "\tspeed: 0.0274s/iter; left time: 208.5730s\n",
      "\titers: 500, epoch: 2 | loss: 0.0150981\n",
      "\tspeed: 0.0274s/iter; left time: 206.2350s\n",
      "\titers: 600, epoch: 2 | loss: 0.0165091\n",
      "\tspeed: 0.0274s/iter; left time: 203.0811s\n",
      "\titers: 700, epoch: 2 | loss: 0.0191504\n",
      "\tspeed: 0.0274s/iter; left time: 200.3715s\n",
      "\titers: 800, epoch: 2 | loss: 0.0176131\n",
      "\tspeed: 0.0274s/iter; left time: 197.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 891 | Train Loss: 0.0178884 Vali Loss: 0.0187196 Test Loss: 0.0195916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0162321\n",
      "\tspeed: 0.1041s/iter; left time: 731.3762s\n",
      "\titers: 200, epoch: 3 | loss: 0.0164735\n",
      "\tspeed: 0.0277s/iter; left time: 191.9194s\n",
      "\titers: 300, epoch: 3 | loss: 0.0150039\n",
      "\tspeed: 0.0277s/iter; left time: 189.4536s\n",
      "\titers: 400, epoch: 3 | loss: 0.0172733\n",
      "\tspeed: 0.0277s/iter; left time: 186.2656s\n",
      "\titers: 500, epoch: 3 | loss: 0.0167668\n",
      "\tspeed: 0.0277s/iter; left time: 183.7205s\n",
      "\titers: 600, epoch: 3 | loss: 0.0138447\n",
      "\tspeed: 0.0277s/iter; left time: 180.6407s\n",
      "\titers: 700, epoch: 3 | loss: 0.0161234\n",
      "\tspeed: 0.0277s/iter; left time: 177.9997s\n",
      "\titers: 800, epoch: 3 | loss: 0.0136648\n",
      "\tspeed: 0.0277s/iter; left time: 175.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.96s\n",
      "Steps: 891 | Train Loss: 0.0153205 Vali Loss: 0.0192233 Test Loss: 0.0199144\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136606\n",
      "\tspeed: 0.1044s/iter; left time: 640.6647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178643\n",
      "\tspeed: 0.0278s/iter; left time: 167.7844s\n",
      "\titers: 300, epoch: 4 | loss: 0.0123156\n",
      "\tspeed: 0.0278s/iter; left time: 164.8036s\n",
      "\titers: 400, epoch: 4 | loss: 0.0127967\n",
      "\tspeed: 0.0277s/iter; left time: 161.5033s\n",
      "\titers: 500, epoch: 4 | loss: 0.0209878\n",
      "\tspeed: 0.0277s/iter; left time: 158.8467s\n",
      "\titers: 600, epoch: 4 | loss: 0.0116704\n",
      "\tspeed: 0.0276s/iter; left time: 155.7819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132667\n",
      "\tspeed: 0.0276s/iter; left time: 153.0243s\n",
      "\titers: 800, epoch: 4 | loss: 0.0128624\n",
      "\tspeed: 0.0276s/iter; left time: 150.1039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0129043 Vali Loss: 0.0200244 Test Loss: 0.0225289\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01818559132516384, rmse:0.13485395908355713, mae:0.08711884915828705, rse:0.5098973512649536\n",
      "Original data scale mse:3181651.5, rmse:1783.718505859375, mae:1182.0157470703125, rse:0.1255275458097458\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0228928\n",
      "\tspeed: 0.0303s/iter; left time: 266.6980s\n",
      "\titers: 200, epoch: 1 | loss: 0.0217010\n",
      "\tspeed: 0.0276s/iter; left time: 240.3312s\n",
      "\titers: 300, epoch: 1 | loss: 0.0180449\n",
      "\tspeed: 0.0276s/iter; left time: 237.7914s\n",
      "\titers: 400, epoch: 1 | loss: 0.0172134\n",
      "\tspeed: 0.0276s/iter; left time: 234.8575s\n",
      "\titers: 500, epoch: 1 | loss: 0.0184300\n",
      "\tspeed: 0.0276s/iter; left time: 232.1817s\n",
      "\titers: 600, epoch: 1 | loss: 0.0183138\n",
      "\tspeed: 0.0276s/iter; left time: 229.3931s\n",
      "\titers: 700, epoch: 1 | loss: 0.0156772\n",
      "\tspeed: 0.0276s/iter; left time: 226.6315s\n",
      "\titers: 800, epoch: 1 | loss: 0.0192672\n",
      "\tspeed: 0.0276s/iter; left time: 224.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0202957 Vali Loss: 0.0168783 Test Loss: 0.0180804\n",
      "Validation loss decreased (inf --> 0.016878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0215709\n",
      "\tspeed: 0.1063s/iter; left time: 841.5654s\n",
      "\titers: 200, epoch: 2 | loss: 0.0182619\n",
      "\tspeed: 0.0275s/iter; left time: 215.1483s\n",
      "\titers: 300, epoch: 2 | loss: 0.0155779\n",
      "\tspeed: 0.0275s/iter; left time: 212.3227s\n",
      "\titers: 400, epoch: 2 | loss: 0.0211766\n",
      "\tspeed: 0.0275s/iter; left time: 209.6543s\n",
      "\titers: 500, epoch: 2 | loss: 0.0140793\n",
      "\tspeed: 0.0274s/iter; left time: 206.3725s\n",
      "\titers: 600, epoch: 2 | loss: 0.0237876\n",
      "\tspeed: 0.0274s/iter; left time: 203.2644s\n",
      "\titers: 700, epoch: 2 | loss: 0.0155597\n",
      "\tspeed: 0.0274s/iter; left time: 200.6269s\n",
      "\titers: 800, epoch: 2 | loss: 0.0165534\n",
      "\tspeed: 0.0278s/iter; left time: 200.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.0180016 Vali Loss: 0.0177291 Test Loss: 0.0195989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0150112\n",
      "\tspeed: 0.1022s/iter; left time: 718.3428s\n",
      "\titers: 200, epoch: 3 | loss: 0.0136525\n",
      "\tspeed: 0.0276s/iter; left time: 191.1572s\n",
      "\titers: 300, epoch: 3 | loss: 0.0159441\n",
      "\tspeed: 0.0275s/iter; left time: 188.0802s\n",
      "\titers: 400, epoch: 3 | loss: 0.0138051\n",
      "\tspeed: 0.0275s/iter; left time: 185.2923s\n",
      "\titers: 500, epoch: 3 | loss: 0.0130835\n",
      "\tspeed: 0.0275s/iter; left time: 182.2703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0189182\n",
      "\tspeed: 0.0275s/iter; left time: 179.2806s\n",
      "\titers: 700, epoch: 3 | loss: 0.0147348\n",
      "\tspeed: 0.0274s/iter; left time: 176.4514s\n",
      "\titers: 800, epoch: 3 | loss: 0.0128391\n",
      "\tspeed: 0.0274s/iter; left time: 173.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0153594 Vali Loss: 0.0182596 Test Loss: 0.0197869\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0169716\n",
      "\tspeed: 0.1020s/iter; left time: 626.2548s\n",
      "\titers: 200, epoch: 4 | loss: 0.0135279\n",
      "\tspeed: 0.0274s/iter; left time: 165.6003s\n",
      "\titers: 300, epoch: 4 | loss: 0.0121340\n",
      "\tspeed: 0.0275s/iter; left time: 163.1170s\n",
      "\titers: 400, epoch: 4 | loss: 0.0120603\n",
      "\tspeed: 0.0275s/iter; left time: 160.6846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0123591\n",
      "\tspeed: 0.0275s/iter; left time: 157.8752s\n",
      "\titers: 600, epoch: 4 | loss: 0.0127861\n",
      "\tspeed: 0.0275s/iter; left time: 155.1358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0133667\n",
      "\tspeed: 0.0275s/iter; left time: 152.4337s\n",
      "\titers: 800, epoch: 4 | loss: 0.0132274\n",
      "\tspeed: 0.0275s/iter; left time: 149.7101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0134171 Vali Loss: 0.0191772 Test Loss: 0.0216198\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018080413341522217, rmse:0.13446342945098877, mae:0.08679895102977753, rse:0.5084207057952881\n",
      "Original data scale mse:3139555.5, rmse:1771.8790283203125, mae:1171.673583984375, rse:0.12469436973333359\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0236162\n",
      "\tspeed: 0.0534s/iter; left time: 469.0630s\n",
      "\titers: 200, epoch: 1 | loss: 0.0183719\n",
      "\tspeed: 0.0280s/iter; left time: 243.0752s\n",
      "\titers: 300, epoch: 1 | loss: 0.0199116\n",
      "\tspeed: 0.0279s/iter; left time: 240.0900s\n",
      "\titers: 400, epoch: 1 | loss: 0.0255526\n",
      "\tspeed: 0.0280s/iter; left time: 237.7154s\n",
      "\titers: 500, epoch: 1 | loss: 0.0240575\n",
      "\tspeed: 0.0280s/iter; left time: 235.1871s\n",
      "\titers: 600, epoch: 1 | loss: 0.0206351\n",
      "\tspeed: 0.0280s/iter; left time: 232.1718s\n",
      "\titers: 700, epoch: 1 | loss: 0.0214608\n",
      "\tspeed: 0.0280s/iter; left time: 229.3636s\n",
      "\titers: 800, epoch: 1 | loss: 0.0190965\n",
      "\tspeed: 0.0280s/iter; left time: 226.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.0215779 Vali Loss: 0.0185147 Test Loss: 0.0193631\n",
      "Validation loss decreased (inf --> 0.018515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0219754\n",
      "\tspeed: 0.1074s/iter; left time: 848.9284s\n",
      "\titers: 200, epoch: 2 | loss: 0.0184724\n",
      "\tspeed: 0.0280s/iter; left time: 218.6829s\n",
      "\titers: 300, epoch: 2 | loss: 0.0209752\n",
      "\tspeed: 0.0280s/iter; left time: 215.9832s\n",
      "\titers: 400, epoch: 2 | loss: 0.0174810\n",
      "\tspeed: 0.0280s/iter; left time: 213.0747s\n",
      "\titers: 500, epoch: 2 | loss: 0.0179584\n",
      "\tspeed: 0.0280s/iter; left time: 210.2927s\n",
      "\titers: 600, epoch: 2 | loss: 0.0199438\n",
      "\tspeed: 0.0280s/iter; left time: 207.3693s\n",
      "\titers: 700, epoch: 2 | loss: 0.0223011\n",
      "\tspeed: 0.0280s/iter; left time: 204.2497s\n",
      "\titers: 800, epoch: 2 | loss: 0.0188354\n",
      "\tspeed: 0.0280s/iter; left time: 201.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 889 | Train Loss: 0.0191857 Vali Loss: 0.0196306 Test Loss: 0.0218072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0145795\n",
      "\tspeed: 0.1031s/iter; left time: 723.0902s\n",
      "\titers: 200, epoch: 3 | loss: 0.0162144\n",
      "\tspeed: 0.0280s/iter; left time: 193.3139s\n",
      "\titers: 300, epoch: 3 | loss: 0.0173045\n",
      "\tspeed: 0.0280s/iter; left time: 190.6228s\n",
      "\titers: 400, epoch: 3 | loss: 0.0162256\n",
      "\tspeed: 0.0280s/iter; left time: 187.8791s\n",
      "\titers: 500, epoch: 3 | loss: 0.0127041\n",
      "\tspeed: 0.0280s/iter; left time: 184.9851s\n",
      "\titers: 600, epoch: 3 | loss: 0.0130897\n",
      "\tspeed: 0.0280s/iter; left time: 182.3079s\n",
      "\titers: 700, epoch: 3 | loss: 0.0149259\n",
      "\tspeed: 0.0280s/iter; left time: 179.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0167985\n",
      "\tspeed: 0.0280s/iter; left time: 176.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.07s\n",
      "Steps: 889 | Train Loss: 0.0155784 Vali Loss: 0.0220581 Test Loss: 0.0241300\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120209\n",
      "\tspeed: 0.1029s/iter; left time: 630.3915s\n",
      "\titers: 200, epoch: 4 | loss: 0.0117652\n",
      "\tspeed: 0.0280s/iter; left time: 168.9182s\n",
      "\titers: 300, epoch: 4 | loss: 0.0127462\n",
      "\tspeed: 0.0281s/iter; left time: 166.2134s\n",
      "\titers: 400, epoch: 4 | loss: 0.0109700\n",
      "\tspeed: 0.0280s/iter; left time: 163.3150s\n",
      "\titers: 500, epoch: 4 | loss: 0.0098459\n",
      "\tspeed: 0.0280s/iter; left time: 160.2756s\n",
      "\titers: 600, epoch: 4 | loss: 0.0106720\n",
      "\tspeed: 0.0280s/iter; left time: 157.2570s\n",
      "\titers: 700, epoch: 4 | loss: 0.0115856\n",
      "\tspeed: 0.0280s/iter; left time: 154.5354s\n",
      "\titers: 800, epoch: 4 | loss: 0.0168614\n",
      "\tspeed: 0.0280s/iter; left time: 151.7719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0126771 Vali Loss: 0.0232748 Test Loss: 0.0249381\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019363099709153175, rmse:0.13915134966373444, mae:0.09162752330303192, rse:0.5265098214149475\n",
      "Original data scale mse:3698332.25, rmse:1923.1048583984375, mae:1273.1566162109375, rse:0.13546383380889893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0247541\n",
      "\tspeed: 0.0300s/iter; left time: 263.9974s\n",
      "\titers: 200, epoch: 1 | loss: 0.0261065\n",
      "\tspeed: 0.0281s/iter; left time: 244.0573s\n",
      "\titers: 300, epoch: 1 | loss: 0.0198978\n",
      "\tspeed: 0.0281s/iter; left time: 241.2585s\n",
      "\titers: 400, epoch: 1 | loss: 0.0230611\n",
      "\tspeed: 0.0281s/iter; left time: 238.3196s\n",
      "\titers: 500, epoch: 1 | loss: 0.0194879\n",
      "\tspeed: 0.0281s/iter; left time: 235.5011s\n",
      "\titers: 600, epoch: 1 | loss: 0.0192141\n",
      "\tspeed: 0.0281s/iter; left time: 232.7507s\n",
      "\titers: 700, epoch: 1 | loss: 0.0171524\n",
      "\tspeed: 0.0281s/iter; left time: 229.8912s\n",
      "\titers: 800, epoch: 1 | loss: 0.0183360\n",
      "\tspeed: 0.0280s/iter; left time: 226.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0216471 Vali Loss: 0.0184627 Test Loss: 0.0193748\n",
      "Validation loss decreased (inf --> 0.018463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0233741\n",
      "\tspeed: 0.1062s/iter; left time: 839.1494s\n",
      "\titers: 200, epoch: 2 | loss: 0.0204443\n",
      "\tspeed: 0.0281s/iter; left time: 218.9538s\n",
      "\titers: 300, epoch: 2 | loss: 0.0225896\n",
      "\tspeed: 0.0281s/iter; left time: 216.2066s\n",
      "\titers: 400, epoch: 2 | loss: 0.0158943\n",
      "\tspeed: 0.0281s/iter; left time: 213.2772s\n",
      "\titers: 500, epoch: 2 | loss: 0.0184105\n",
      "\tspeed: 0.0280s/iter; left time: 210.3145s\n",
      "\titers: 600, epoch: 2 | loss: 0.0190272\n",
      "\tspeed: 0.0280s/iter; left time: 207.4345s\n",
      "\titers: 700, epoch: 2 | loss: 0.0172599\n",
      "\tspeed: 0.0280s/iter; left time: 204.5007s\n",
      "\titers: 800, epoch: 2 | loss: 0.0152705\n",
      "\tspeed: 0.0280s/iter; left time: 201.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0187181 Vali Loss: 0.0192850 Test Loss: 0.0239670\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0159321\n",
      "\tspeed: 0.1033s/iter; left time: 724.6270s\n",
      "\titers: 200, epoch: 3 | loss: 0.0163656\n",
      "\tspeed: 0.0280s/iter; left time: 193.3770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0158224\n",
      "\tspeed: 0.0280s/iter; left time: 190.5241s\n",
      "\titers: 400, epoch: 3 | loss: 0.0133546\n",
      "\tspeed: 0.0280s/iter; left time: 187.6772s\n",
      "\titers: 500, epoch: 3 | loss: 0.0165057\n",
      "\tspeed: 0.0279s/iter; left time: 184.8106s\n",
      "\titers: 600, epoch: 3 | loss: 0.0140909\n",
      "\tspeed: 0.0279s/iter; left time: 182.0064s\n",
      "\titers: 700, epoch: 3 | loss: 0.0140744\n",
      "\tspeed: 0.0280s/iter; left time: 179.4765s\n",
      "\titers: 800, epoch: 3 | loss: 0.0151225\n",
      "\tspeed: 0.0280s/iter; left time: 176.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0149630 Vali Loss: 0.0216498 Test Loss: 0.0257693\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121486\n",
      "\tspeed: 0.1039s/iter; left time: 636.4021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113173\n",
      "\tspeed: 0.0280s/iter; left time: 168.6476s\n",
      "\titers: 300, epoch: 4 | loss: 0.0110981\n",
      "\tspeed: 0.0280s/iter; left time: 165.8878s\n",
      "\titers: 400, epoch: 4 | loss: 0.0113187\n",
      "\tspeed: 0.0280s/iter; left time: 162.9382s\n",
      "\titers: 500, epoch: 4 | loss: 0.0126804\n",
      "\tspeed: 0.0279s/iter; left time: 159.9819s\n",
      "\titers: 600, epoch: 4 | loss: 0.0112432\n",
      "\tspeed: 0.0280s/iter; left time: 157.3162s\n",
      "\titers: 700, epoch: 4 | loss: 0.0113324\n",
      "\tspeed: 0.0280s/iter; left time: 154.4275s\n",
      "\titers: 800, epoch: 4 | loss: 0.0100309\n",
      "\tspeed: 0.0280s/iter; left time: 151.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.11s\n",
      "Steps: 889 | Train Loss: 0.0113790 Vali Loss: 0.0225733 Test Loss: 0.0267746\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01937480829656124, rmse:0.13919341564178467, mae:0.09127473831176758, rse:0.526668906211853\n",
      "Original data scale mse:3587113.5, rmse:1893.9676513671875, mae:1255.863525390625, rse:0.13341140747070312\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1336230\n",
      "\tspeed: 0.0553s/iter; left time: 488.2585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1155068\n",
      "\tspeed: 0.0272s/iter; left time: 237.5775s\n",
      "\titers: 300, epoch: 1 | loss: 0.1121432\n",
      "\tspeed: 0.0272s/iter; left time: 234.9864s\n",
      "\titers: 400, epoch: 1 | loss: 0.1140316\n",
      "\tspeed: 0.0272s/iter; left time: 231.8497s\n",
      "\titers: 500, epoch: 1 | loss: 0.1130750\n",
      "\tspeed: 0.0272s/iter; left time: 229.3489s\n",
      "\titers: 600, epoch: 1 | loss: 0.1088183\n",
      "\tspeed: 0.0272s/iter; left time: 226.4775s\n",
      "\titers: 700, epoch: 1 | loss: 0.0967024\n",
      "\tspeed: 0.0272s/iter; left time: 223.8843s\n",
      "\titers: 800, epoch: 1 | loss: 0.0916955\n",
      "\tspeed: 0.0272s/iter; left time: 221.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.1131722 Vali Loss: 0.0101976 Test Loss: 0.0113959\n",
      "Validation loss decreased (inf --> 0.010198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1050137\n",
      "\tspeed: 0.1035s/iter; left time: 821.3278s\n",
      "\titers: 200, epoch: 2 | loss: 0.1007863\n",
      "\tspeed: 0.0273s/iter; left time: 213.6088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1326872\n",
      "\tspeed: 0.0272s/iter; left time: 210.1571s\n",
      "\titers: 400, epoch: 2 | loss: 0.1074101\n",
      "\tspeed: 0.0272s/iter; left time: 207.9068s\n",
      "\titers: 500, epoch: 2 | loss: 0.1004094\n",
      "\tspeed: 0.0272s/iter; left time: 204.7980s\n",
      "\titers: 600, epoch: 2 | loss: 0.0910867\n",
      "\tspeed: 0.0272s/iter; left time: 202.0179s\n",
      "\titers: 700, epoch: 2 | loss: 0.1073109\n",
      "\tspeed: 0.0272s/iter; left time: 199.4069s\n",
      "\titers: 800, epoch: 2 | loss: 0.0984889\n",
      "\tspeed: 0.0273s/iter; left time: 197.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 893 | Train Loss: 0.1070746 Vali Loss: 0.0108972 Test Loss: 0.0123732\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0865848\n",
      "\tspeed: 0.1031s/iter; left time: 726.0789s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020046\n",
      "\tspeed: 0.0273s/iter; left time: 189.4461s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922649\n",
      "\tspeed: 0.0275s/iter; left time: 188.0378s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004084\n",
      "\tspeed: 0.0275s/iter; left time: 185.1835s\n",
      "\titers: 500, epoch: 3 | loss: 0.0948766\n",
      "\tspeed: 0.0273s/iter; left time: 181.1685s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179055\n",
      "\tspeed: 0.0272s/iter; left time: 177.9232s\n",
      "\titers: 700, epoch: 3 | loss: 0.0856405\n",
      "\tspeed: 0.0272s/iter; left time: 175.1191s\n",
      "\titers: 800, epoch: 3 | loss: 0.1091467\n",
      "\tspeed: 0.0272s/iter; left time: 172.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.1025416 Vali Loss: 0.0103346 Test Loss: 0.0115246\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1041363\n",
      "\tspeed: 0.1026s/iter; left time: 631.4290s\n",
      "\titers: 200, epoch: 4 | loss: 0.0963972\n",
      "\tspeed: 0.0272s/iter; left time: 164.7449s\n",
      "\titers: 300, epoch: 4 | loss: 0.1047586\n",
      "\tspeed: 0.0272s/iter; left time: 161.7208s\n",
      "\titers: 400, epoch: 4 | loss: 0.0921619\n",
      "\tspeed: 0.0271s/iter; left time: 158.8169s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976954\n",
      "\tspeed: 0.0272s/iter; left time: 156.4304s\n",
      "\titers: 600, epoch: 4 | loss: 0.0881593\n",
      "\tspeed: 0.0273s/iter; left time: 154.0539s\n",
      "\titers: 700, epoch: 4 | loss: 0.1065766\n",
      "\tspeed: 0.0272s/iter; left time: 151.2442s\n",
      "\titers: 800, epoch: 4 | loss: 0.1049190\n",
      "\tspeed: 0.0273s/iter; left time: 148.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0997130 Vali Loss: 0.0104954 Test Loss: 0.0120944\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011395939625799656, rmse:0.10675176978111267, mae:0.06576605141162872, rse:0.40342235565185547\n",
      "Original data scale mse:1851359.875, rmse:1360.6468505859375, mae:874.3543701171875, rse:0.09561585634946823\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1388093\n",
      "\tspeed: 0.0292s/iter; left time: 258.0713s\n",
      "\titers: 200, epoch: 1 | loss: 0.1117809\n",
      "\tspeed: 0.0274s/iter; left time: 238.8148s\n",
      "\titers: 300, epoch: 1 | loss: 0.1294807\n",
      "\tspeed: 0.0273s/iter; left time: 236.0087s\n",
      "\titers: 400, epoch: 1 | loss: 0.1107772\n",
      "\tspeed: 0.0271s/iter; left time: 231.6098s\n",
      "\titers: 500, epoch: 1 | loss: 0.0995625\n",
      "\tspeed: 0.0271s/iter; left time: 228.3454s\n",
      "\titers: 600, epoch: 1 | loss: 0.1074394\n",
      "\tspeed: 0.0273s/iter; left time: 227.3726s\n",
      "\titers: 700, epoch: 1 | loss: 0.1001715\n",
      "\tspeed: 0.0273s/iter; left time: 224.7820s\n",
      "\titers: 800, epoch: 1 | loss: 0.0994926\n",
      "\tspeed: 0.0273s/iter; left time: 221.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.1137531 Vali Loss: 0.0103037 Test Loss: 0.0114750\n",
      "Validation loss decreased (inf --> 0.010304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1124581\n",
      "\tspeed: 0.1047s/iter; left time: 831.3677s\n",
      "\titers: 200, epoch: 2 | loss: 0.1012988\n",
      "\tspeed: 0.0273s/iter; left time: 213.9236s\n",
      "\titers: 300, epoch: 2 | loss: 0.1143391\n",
      "\tspeed: 0.0273s/iter; left time: 211.2506s\n",
      "\titers: 400, epoch: 2 | loss: 0.1000488\n",
      "\tspeed: 0.0272s/iter; left time: 208.0139s\n",
      "\titers: 500, epoch: 2 | loss: 0.0999656\n",
      "\tspeed: 0.0272s/iter; left time: 204.9040s\n",
      "\titers: 600, epoch: 2 | loss: 0.0956163\n",
      "\tspeed: 0.0272s/iter; left time: 202.1540s\n",
      "\titers: 700, epoch: 2 | loss: 0.0920859\n",
      "\tspeed: 0.0272s/iter; left time: 199.5921s\n",
      "\titers: 800, epoch: 2 | loss: 0.1179271\n",
      "\tspeed: 0.0272s/iter; left time: 196.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.1058963 Vali Loss: 0.0107609 Test Loss: 0.0120347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982848\n",
      "\tspeed: 0.1019s/iter; left time: 718.0865s\n",
      "\titers: 200, epoch: 3 | loss: 0.1196185\n",
      "\tspeed: 0.0273s/iter; left time: 189.7404s\n",
      "\titers: 300, epoch: 3 | loss: 0.0814890\n",
      "\tspeed: 0.0272s/iter; left time: 186.3990s\n",
      "\titers: 400, epoch: 3 | loss: 0.0979836\n",
      "\tspeed: 0.0272s/iter; left time: 183.7628s\n",
      "\titers: 500, epoch: 3 | loss: 0.0956824\n",
      "\tspeed: 0.0272s/iter; left time: 181.0141s\n",
      "\titers: 600, epoch: 3 | loss: 0.0909160\n",
      "\tspeed: 0.0272s/iter; left time: 178.0660s\n",
      "\titers: 700, epoch: 3 | loss: 0.1006822\n",
      "\tspeed: 0.0272s/iter; left time: 175.4138s\n",
      "\titers: 800, epoch: 3 | loss: 0.0918016\n",
      "\tspeed: 0.0272s/iter; left time: 172.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.1021115 Vali Loss: 0.0104125 Test Loss: 0.0117827\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912620\n",
      "\tspeed: 0.1024s/iter; left time: 630.1537s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102126\n",
      "\tspeed: 0.0275s/iter; left time: 166.3765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0985254\n",
      "\tspeed: 0.0275s/iter; left time: 163.4348s\n",
      "\titers: 400, epoch: 4 | loss: 0.0976668\n",
      "\tspeed: 0.0274s/iter; left time: 160.5018s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039490\n",
      "\tspeed: 0.0272s/iter; left time: 156.5369s\n",
      "\titers: 600, epoch: 4 | loss: 0.0898440\n",
      "\tspeed: 0.0272s/iter; left time: 153.7540s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876081\n",
      "\tspeed: 0.0273s/iter; left time: 151.3703s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061534\n",
      "\tspeed: 0.0272s/iter; left time: 148.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 893 | Train Loss: 0.0986301 Vali Loss: 0.0107811 Test Loss: 0.0123823\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01147499494254589, rmse:0.10712140053510666, mae:0.066454216837883, rse:0.4048192799091339\n",
      "Original data scale mse:1904325.375, rmse:1379.9730224609375, mae:891.10009765625, rse:0.0969739556312561\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1612096\n",
      "\tspeed: 0.0554s/iter; left time: 488.5091s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467356\n",
      "\tspeed: 0.0275s/iter; left time: 239.5342s\n",
      "\titers: 300, epoch: 1 | loss: 0.1518958\n",
      "\tspeed: 0.0275s/iter; left time: 236.5573s\n",
      "\titers: 400, epoch: 1 | loss: 0.1317786\n",
      "\tspeed: 0.0275s/iter; left time: 233.9197s\n",
      "\titers: 500, epoch: 1 | loss: 0.1327047\n",
      "\tspeed: 0.0275s/iter; left time: 231.0283s\n",
      "\titers: 600, epoch: 1 | loss: 0.1364689\n",
      "\tspeed: 0.0275s/iter; left time: 228.2888s\n",
      "\titers: 700, epoch: 1 | loss: 0.1275773\n",
      "\tspeed: 0.0275s/iter; left time: 225.8782s\n",
      "\titers: 800, epoch: 1 | loss: 0.1212199\n",
      "\tspeed: 0.0275s/iter; left time: 222.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.98s\n",
      "Steps: 891 | Train Loss: 0.1405650 Vali Loss: 0.0169173 Test Loss: 0.0181296\n",
      "Validation loss decreased (inf --> 0.016917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407798\n",
      "\tspeed: 0.1039s/iter; left time: 823.0167s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132862\n",
      "\tspeed: 0.0275s/iter; left time: 215.1548s\n",
      "\titers: 300, epoch: 2 | loss: 0.1313431\n",
      "\tspeed: 0.0276s/iter; left time: 213.0305s\n",
      "\titers: 400, epoch: 2 | loss: 0.1309543\n",
      "\tspeed: 0.0276s/iter; left time: 210.4537s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231728\n",
      "\tspeed: 0.0276s/iter; left time: 207.6381s\n",
      "\titers: 600, epoch: 2 | loss: 0.1290840\n",
      "\tspeed: 0.0276s/iter; left time: 204.6861s\n",
      "\titers: 700, epoch: 2 | loss: 0.1367119\n",
      "\tspeed: 0.0276s/iter; left time: 202.1426s\n",
      "\titers: 800, epoch: 2 | loss: 0.1343888\n",
      "\tspeed: 0.0276s/iter; left time: 199.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.1342701 Vali Loss: 0.0187091 Test Loss: 0.0192857\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1257509\n",
      "\tspeed: 0.1021s/iter; left time: 717.5881s\n",
      "\titers: 200, epoch: 3 | loss: 0.1280146\n",
      "\tspeed: 0.0273s/iter; left time: 189.2340s\n",
      "\titers: 300, epoch: 3 | loss: 0.1178980\n",
      "\tspeed: 0.0273s/iter; left time: 186.5112s\n",
      "\titers: 400, epoch: 3 | loss: 0.1302711\n",
      "\tspeed: 0.0273s/iter; left time: 183.7821s\n",
      "\titers: 500, epoch: 3 | loss: 0.1262439\n",
      "\tspeed: 0.0274s/iter; left time: 181.9604s\n",
      "\titers: 600, epoch: 3 | loss: 0.1175837\n",
      "\tspeed: 0.0275s/iter; left time: 179.4664s\n",
      "\titers: 700, epoch: 3 | loss: 0.1250318\n",
      "\tspeed: 0.0274s/iter; left time: 176.3853s\n",
      "\titers: 800, epoch: 3 | loss: 0.1148603\n",
      "\tspeed: 0.0274s/iter; left time: 173.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 891 | Train Loss: 0.1230018 Vali Loss: 0.0192505 Test Loss: 0.0204372\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1223086\n",
      "\tspeed: 0.1020s/iter; left time: 625.8356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1278397\n",
      "\tspeed: 0.0276s/iter; left time: 166.5951s\n",
      "\titers: 300, epoch: 4 | loss: 0.1042883\n",
      "\tspeed: 0.0276s/iter; left time: 163.6585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1116099\n",
      "\tspeed: 0.0276s/iter; left time: 160.8600s\n",
      "\titers: 500, epoch: 4 | loss: 0.1929631\n",
      "\tspeed: 0.0275s/iter; left time: 158.0444s\n",
      "\titers: 600, epoch: 4 | loss: 0.1039310\n",
      "\tspeed: 0.0276s/iter; left time: 155.4701s\n",
      "\titers: 700, epoch: 4 | loss: 0.1109765\n",
      "\tspeed: 0.0276s/iter; left time: 152.6531s\n",
      "\titers: 800, epoch: 4 | loss: 0.1156806\n",
      "\tspeed: 0.0276s/iter; left time: 149.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 891 | Train Loss: 0.1124573 Vali Loss: 0.0200614 Test Loss: 0.0231085\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018129628151655197, rmse:0.13464631140232086, mae:0.08668393641710281, rse:0.5091121792793274\n",
      "Original data scale mse:3113013.75, rmse:1764.3734130859375, mae:1168.9976806640625, rse:0.12416616082191467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1495688\n",
      "\tspeed: 0.0294s/iter; left time: 259.1273s\n",
      "\titers: 200, epoch: 1 | loss: 0.1463868\n",
      "\tspeed: 0.0274s/iter; left time: 238.9611s\n",
      "\titers: 300, epoch: 1 | loss: 0.1333702\n",
      "\tspeed: 0.0274s/iter; left time: 236.1130s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300492\n",
      "\tspeed: 0.0274s/iter; left time: 233.3643s\n",
      "\titers: 500, epoch: 1 | loss: 0.1337928\n",
      "\tspeed: 0.0274s/iter; left time: 230.7367s\n",
      "\titers: 600, epoch: 1 | loss: 0.1342798\n",
      "\tspeed: 0.0274s/iter; left time: 227.9619s\n",
      "\titers: 700, epoch: 1 | loss: 0.1246924\n",
      "\tspeed: 0.0276s/iter; left time: 226.4948s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377941\n",
      "\tspeed: 0.0275s/iter; left time: 223.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.1405721 Vali Loss: 0.0167831 Test Loss: 0.0180072\n",
      "Validation loss decreased (inf --> 0.016783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1467238\n",
      "\tspeed: 0.1037s/iter; left time: 821.6762s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360969\n",
      "\tspeed: 0.0275s/iter; left time: 214.8438s\n",
      "\titers: 300, epoch: 2 | loss: 0.1264257\n",
      "\tspeed: 0.0275s/iter; left time: 212.0823s\n",
      "\titers: 400, epoch: 2 | loss: 0.1452207\n",
      "\tspeed: 0.0275s/iter; left time: 209.2331s\n",
      "\titers: 500, epoch: 2 | loss: 0.1207512\n",
      "\tspeed: 0.0274s/iter; left time: 206.3639s\n",
      "\titers: 600, epoch: 2 | loss: 0.1442054\n",
      "\tspeed: 0.0274s/iter; left time: 203.5868s\n",
      "\titers: 700, epoch: 2 | loss: 0.1262565\n",
      "\tspeed: 0.0274s/iter; left time: 200.7346s\n",
      "\titers: 800, epoch: 2 | loss: 0.1496262\n",
      "\tspeed: 0.0274s/iter; left time: 197.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1342886 Vali Loss: 0.0179572 Test Loss: 0.0197570\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1195421\n",
      "\tspeed: 0.1019s/iter; left time: 716.0260s\n",
      "\titers: 200, epoch: 3 | loss: 0.1202214\n",
      "\tspeed: 0.0275s/iter; left time: 190.2595s\n",
      "\titers: 300, epoch: 3 | loss: 0.1266964\n",
      "\tspeed: 0.0275s/iter; left time: 187.5472s\n",
      "\titers: 400, epoch: 3 | loss: 0.1236266\n",
      "\tspeed: 0.0274s/iter; left time: 184.7001s\n",
      "\titers: 500, epoch: 3 | loss: 0.1166376\n",
      "\tspeed: 0.0275s/iter; left time: 182.0828s\n",
      "\titers: 600, epoch: 3 | loss: 0.1360387\n",
      "\tspeed: 0.0275s/iter; left time: 179.2470s\n",
      "\titers: 700, epoch: 3 | loss: 0.1262230\n",
      "\tspeed: 0.0275s/iter; left time: 176.5138s\n",
      "\titers: 800, epoch: 3 | loss: 0.1146488\n",
      "\tspeed: 0.0275s/iter; left time: 173.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1250462 Vali Loss: 0.0183877 Test Loss: 0.0199011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1335205\n",
      "\tspeed: 0.1019s/iter; left time: 625.5570s\n",
      "\titers: 200, epoch: 4 | loss: 0.1363225\n",
      "\tspeed: 0.0276s/iter; left time: 166.4817s\n",
      "\titers: 300, epoch: 4 | loss: 0.1124470\n",
      "\tspeed: 0.0276s/iter; left time: 163.7063s\n",
      "\titers: 400, epoch: 4 | loss: 0.1130551\n",
      "\tspeed: 0.0276s/iter; left time: 160.9372s\n",
      "\titers: 500, epoch: 4 | loss: 0.1142171\n",
      "\tspeed: 0.0275s/iter; left time: 158.0765s\n",
      "\titers: 600, epoch: 4 | loss: 0.1137453\n",
      "\tspeed: 0.0275s/iter; left time: 155.2392s\n",
      "\titers: 700, epoch: 4 | loss: 0.1127641\n",
      "\tspeed: 0.0275s/iter; left time: 152.2473s\n",
      "\titers: 800, epoch: 4 | loss: 0.1094655\n",
      "\tspeed: 0.0275s/iter; left time: 149.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.1167262 Vali Loss: 0.0200590 Test Loss: 0.0232277\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018007179722189903, rmse:0.13419082760810852, mae:0.0862976536154747, rse:0.5073899626731873\n",
      "Original data scale mse:3066430.25, rmse:1751.12255859375, mae:1157.38037109375, rse:0.12323364615440369\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1526763\n",
      "\tspeed: 0.0567s/iter; left time: 498.1957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348829\n",
      "\tspeed: 0.0282s/iter; left time: 244.9739s\n",
      "\titers: 300, epoch: 1 | loss: 0.1405146\n",
      "\tspeed: 0.0282s/iter; left time: 242.0161s\n",
      "\titers: 400, epoch: 1 | loss: 0.1588301\n",
      "\tspeed: 0.0281s/iter; left time: 238.4071s\n",
      "\titers: 500, epoch: 1 | loss: 0.1540524\n",
      "\tspeed: 0.0281s/iter; left time: 235.5241s\n",
      "\titers: 600, epoch: 1 | loss: 0.1427126\n",
      "\tspeed: 0.0280s/iter; left time: 232.2965s\n",
      "\titers: 700, epoch: 1 | loss: 0.1456371\n",
      "\tspeed: 0.0281s/iter; left time: 229.7898s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377048\n",
      "\tspeed: 0.0282s/iter; left time: 228.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.48s\n",
      "Steps: 889 | Train Loss: 0.1453442 Vali Loss: 0.0184368 Test Loss: 0.0192923\n",
      "Validation loss decreased (inf --> 0.018437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480042\n",
      "\tspeed: 0.1075s/iter; left time: 849.7872s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339409\n",
      "\tspeed: 0.0283s/iter; left time: 220.7146s\n",
      "\titers: 300, epoch: 2 | loss: 0.1472317\n",
      "\tspeed: 0.0284s/iter; left time: 219.0707s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334711\n",
      "\tspeed: 0.0284s/iter; left time: 216.2757s\n",
      "\titers: 500, epoch: 2 | loss: 0.1341700\n",
      "\tspeed: 0.0284s/iter; left time: 212.6936s\n",
      "\titers: 600, epoch: 2 | loss: 0.1413193\n",
      "\tspeed: 0.0285s/iter; left time: 210.6591s\n",
      "\titers: 700, epoch: 2 | loss: 0.1294785\n",
      "\tspeed: 0.0284s/iter; left time: 207.5759s\n",
      "\titers: 800, epoch: 2 | loss: 0.1371240\n",
      "\tspeed: 0.0284s/iter; left time: 204.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 889 | Train Loss: 0.1377887 Vali Loss: 0.0194952 Test Loss: 0.0224702\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1238881\n",
      "\tspeed: 0.1062s/iter; left time: 744.7159s\n",
      "\titers: 200, epoch: 3 | loss: 0.1281789\n",
      "\tspeed: 0.0281s/iter; left time: 194.2146s\n",
      "\titers: 300, epoch: 3 | loss: 0.1261756\n",
      "\tspeed: 0.0282s/iter; left time: 192.4381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1239973\n",
      "\tspeed: 0.0282s/iter; left time: 189.4659s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175015\n",
      "\tspeed: 0.0282s/iter; left time: 186.6579s\n",
      "\titers: 600, epoch: 3 | loss: 0.1132074\n",
      "\tspeed: 0.0282s/iter; left time: 183.7128s\n",
      "\titers: 700, epoch: 3 | loss: 0.1198484\n",
      "\tspeed: 0.0282s/iter; left time: 180.9089s\n",
      "\titers: 800, epoch: 3 | loss: 0.1233855\n",
      "\tspeed: 0.0281s/iter; left time: 177.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 889 | Train Loss: 0.1231958 Vali Loss: 0.0220815 Test Loss: 0.0253941\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124273\n",
      "\tspeed: 0.1044s/iter; left time: 639.1454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091032\n",
      "\tspeed: 0.0282s/iter; left time: 169.8217s\n",
      "\titers: 300, epoch: 4 | loss: 0.1198413\n",
      "\tspeed: 0.0282s/iter; left time: 167.2789s\n",
      "\titers: 400, epoch: 4 | loss: 0.1105534\n",
      "\tspeed: 0.0284s/iter; left time: 165.3854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1048551\n",
      "\tspeed: 0.0282s/iter; left time: 161.6502s\n",
      "\titers: 600, epoch: 4 | loss: 0.1314389\n",
      "\tspeed: 0.0282s/iter; left time: 158.7624s\n",
      "\titers: 700, epoch: 4 | loss: 0.1183181\n",
      "\tspeed: 0.0282s/iter; left time: 155.8765s\n",
      "\titers: 800, epoch: 4 | loss: 0.1056019\n",
      "\tspeed: 0.0283s/iter; left time: 153.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1099546 Vali Loss: 0.0234355 Test Loss: 0.0249912\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01929234340786934, rmse:0.1388968825340271, mae:0.09116160124540329, rse:0.5255469679832458\n",
      "Original data scale mse:3630107.25, rmse:1905.2840576171875, mae:1260.4178466796875, rse:0.1342085301876068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1561739\n",
      "\tspeed: 0.0307s/iter; left time: 269.4648s\n",
      "\titers: 200, epoch: 1 | loss: 0.1605728\n",
      "\tspeed: 0.0283s/iter; left time: 245.8203s\n",
      "\titers: 300, epoch: 1 | loss: 0.1400924\n",
      "\tspeed: 0.0282s/iter; left time: 242.3826s\n",
      "\titers: 400, epoch: 1 | loss: 0.1510603\n",
      "\tspeed: 0.0282s/iter; left time: 239.5200s\n",
      "\titers: 500, epoch: 1 | loss: 0.1386138\n",
      "\tspeed: 0.0283s/iter; left time: 237.1322s\n",
      "\titers: 600, epoch: 1 | loss: 0.1376126\n",
      "\tspeed: 0.0282s/iter; left time: 234.2168s\n",
      "\titers: 700, epoch: 1 | loss: 0.1298753\n",
      "\tspeed: 0.0282s/iter; left time: 231.1451s\n",
      "\titers: 800, epoch: 1 | loss: 0.1350235\n",
      "\tspeed: 0.0282s/iter; left time: 228.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.1455408 Vali Loss: 0.0183783 Test Loss: 0.0192681\n",
      "Validation loss decreased (inf --> 0.018378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1540410\n",
      "\tspeed: 0.1087s/iter; left time: 858.7673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1433096\n",
      "\tspeed: 0.0282s/iter; left time: 220.0220s\n",
      "\titers: 300, epoch: 2 | loss: 0.1515379\n",
      "\tspeed: 0.0282s/iter; left time: 217.2163s\n",
      "\titers: 400, epoch: 2 | loss: 0.1265191\n",
      "\tspeed: 0.0280s/iter; left time: 212.5000s\n",
      "\titers: 500, epoch: 2 | loss: 0.1357703\n",
      "\tspeed: 0.0282s/iter; left time: 211.5971s\n",
      "\titers: 600, epoch: 2 | loss: 0.1384776\n",
      "\tspeed: 0.0283s/iter; left time: 209.2869s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279574\n",
      "\tspeed: 0.0283s/iter; left time: 206.6641s\n",
      "\titers: 800, epoch: 2 | loss: 0.1234654\n",
      "\tspeed: 0.0283s/iter; left time: 203.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.36s\n",
      "Steps: 889 | Train Loss: 0.1373205 Vali Loss: 0.0197247 Test Loss: 0.0248364\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1267300\n",
      "\tspeed: 0.1047s/iter; left time: 734.6082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1273013\n",
      "\tspeed: 0.0281s/iter; left time: 194.4381s\n",
      "\titers: 300, epoch: 3 | loss: 0.1333112\n",
      "\tspeed: 0.0283s/iter; left time: 192.5230s\n",
      "\titers: 400, epoch: 3 | loss: 0.1214130\n",
      "\tspeed: 0.0282s/iter; left time: 189.4316s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233395\n",
      "\tspeed: 0.0282s/iter; left time: 186.6820s\n",
      "\titers: 600, epoch: 3 | loss: 0.1203233\n",
      "\tspeed: 0.0282s/iter; left time: 183.8856s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158218\n",
      "\tspeed: 0.0282s/iter; left time: 181.0448s\n",
      "\titers: 800, epoch: 3 | loss: 0.1173633\n",
      "\tspeed: 0.0282s/iter; left time: 178.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 889 | Train Loss: 0.1231975 Vali Loss: 0.0220960 Test Loss: 0.0254985\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1178611\n",
      "\tspeed: 0.1064s/iter; left time: 651.8720s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095064\n",
      "\tspeed: 0.0284s/iter; left time: 170.8841s\n",
      "\titers: 300, epoch: 4 | loss: 0.1147172\n",
      "\tspeed: 0.0282s/iter; left time: 167.2012s\n",
      "\titers: 400, epoch: 4 | loss: 0.1098857\n",
      "\tspeed: 0.0282s/iter; left time: 164.0700s\n",
      "\titers: 500, epoch: 4 | loss: 0.1116106\n",
      "\tspeed: 0.0282s/iter; left time: 161.5191s\n",
      "\titers: 600, epoch: 4 | loss: 0.1040639\n",
      "\tspeed: 0.0282s/iter; left time: 158.6095s\n",
      "\titers: 700, epoch: 4 | loss: 0.1096108\n",
      "\tspeed: 0.0283s/iter; left time: 156.3893s\n",
      "\titers: 800, epoch: 4 | loss: 0.0992196\n",
      "\tspeed: 0.0283s/iter; left time: 153.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1056597 Vali Loss: 0.0242961 Test Loss: 0.0272296\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019268110394477844, rmse:0.13880962133407593, mae:0.0907384529709816, rse:0.5252167582511902\n",
      "Original data scale mse:3512351.75, rmse:1874.126953125, mae:1241.5947265625, rse:0.13201381266117096\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0910473\n",
      "\tspeed: 0.0553s/iter; left time: 488.4476s\n",
      "\titers: 200, epoch: 1 | loss: 0.0794505\n",
      "\tspeed: 0.0272s/iter; left time: 237.6089s\n",
      "\titers: 300, epoch: 1 | loss: 0.0759636\n",
      "\tspeed: 0.0272s/iter; left time: 234.6548s\n",
      "\titers: 400, epoch: 1 | loss: 0.0731807\n",
      "\tspeed: 0.0272s/iter; left time: 232.1330s\n",
      "\titers: 500, epoch: 1 | loss: 0.0727000\n",
      "\tspeed: 0.0273s/iter; left time: 230.4277s\n",
      "\titers: 600, epoch: 1 | loss: 0.0689269\n",
      "\tspeed: 0.0273s/iter; left time: 227.3161s\n",
      "\titers: 700, epoch: 1 | loss: 0.0640382\n",
      "\tspeed: 0.0274s/iter; left time: 225.6406s\n",
      "\titers: 800, epoch: 1 | loss: 0.0586276\n",
      "\tspeed: 0.0274s/iter; left time: 222.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.90s\n",
      "Steps: 893 | Train Loss: 0.0754870 Vali Loss: 0.0624566 Test Loss: 0.0650983\n",
      "Validation loss decreased (inf --> 0.062457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746917\n",
      "\tspeed: 0.1031s/iter; left time: 818.6855s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670957\n",
      "\tspeed: 0.0273s/iter; left time: 213.9416s\n",
      "\titers: 300, epoch: 2 | loss: 0.0867313\n",
      "\tspeed: 0.0274s/iter; left time: 211.6879s\n",
      "\titers: 400, epoch: 2 | loss: 0.0686259\n",
      "\tspeed: 0.0274s/iter; left time: 209.0276s\n",
      "\titers: 500, epoch: 2 | loss: 0.0666773\n",
      "\tspeed: 0.0274s/iter; left time: 206.3718s\n",
      "\titers: 600, epoch: 2 | loss: 0.0521042\n",
      "\tspeed: 0.0272s/iter; left time: 202.3813s\n",
      "\titers: 700, epoch: 2 | loss: 0.0632667\n",
      "\tspeed: 0.0273s/iter; left time: 200.0943s\n",
      "\titers: 800, epoch: 2 | loss: 0.0575946\n",
      "\tspeed: 0.0273s/iter; left time: 197.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.0690810 Vali Loss: 0.0626315 Test Loss: 0.0653662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546044\n",
      "\tspeed: 0.1023s/iter; left time: 720.4089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0539697\n",
      "\tspeed: 0.0272s/iter; left time: 188.9977s\n",
      "\titers: 300, epoch: 3 | loss: 0.0572773\n",
      "\tspeed: 0.0272s/iter; left time: 186.4035s\n",
      "\titers: 400, epoch: 3 | loss: 0.0586237\n",
      "\tspeed: 0.0272s/iter; left time: 183.5448s\n",
      "\titers: 500, epoch: 3 | loss: 0.0520420\n",
      "\tspeed: 0.0272s/iter; left time: 180.9132s\n",
      "\titers: 600, epoch: 3 | loss: 0.0595647\n",
      "\tspeed: 0.0272s/iter; left time: 178.1133s\n",
      "\titers: 700, epoch: 3 | loss: 0.0531289\n",
      "\tspeed: 0.0272s/iter; left time: 175.3212s\n",
      "\titers: 800, epoch: 3 | loss: 0.0639382\n",
      "\tspeed: 0.0272s/iter; left time: 172.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.0586708 Vali Loss: 0.0584809 Test Loss: 0.0608546\n",
      "Validation loss decreased (0.062457 --> 0.058481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0601936\n",
      "\tspeed: 0.1041s/iter; left time: 640.7063s\n",
      "\titers: 200, epoch: 4 | loss: 0.0545148\n",
      "\tspeed: 0.0274s/iter; left time: 166.0841s\n",
      "\titers: 300, epoch: 4 | loss: 0.0584930\n",
      "\tspeed: 0.0274s/iter; left time: 162.8830s\n",
      "\titers: 400, epoch: 4 | loss: 0.0498120\n",
      "\tspeed: 0.0272s/iter; left time: 159.3882s\n",
      "\titers: 500, epoch: 4 | loss: 0.0515589\n",
      "\tspeed: 0.0273s/iter; left time: 156.7834s\n",
      "\titers: 600, epoch: 4 | loss: 0.0490566\n",
      "\tspeed: 0.0272s/iter; left time: 153.7343s\n",
      "\titers: 700, epoch: 4 | loss: 0.0592232\n",
      "\tspeed: 0.0272s/iter; left time: 150.9939s\n",
      "\titers: 800, epoch: 4 | loss: 0.0573731\n",
      "\tspeed: 0.0272s/iter; left time: 148.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0566463 Vali Loss: 0.0575501 Test Loss: 0.0600113\n",
      "Validation loss decreased (0.058481 --> 0.057550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616790\n",
      "\tspeed: 0.1045s/iter; left time: 549.3555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0507358\n",
      "\tspeed: 0.0272s/iter; left time: 140.2540s\n",
      "\titers: 300, epoch: 5 | loss: 0.0606048\n",
      "\tspeed: 0.0274s/iter; left time: 138.7255s\n",
      "\titers: 400, epoch: 5 | loss: 0.0653844\n",
      "\tspeed: 0.0274s/iter; left time: 135.8857s\n",
      "\titers: 500, epoch: 5 | loss: 0.0538452\n",
      "\tspeed: 0.0276s/iter; left time: 134.2376s\n",
      "\titers: 600, epoch: 5 | loss: 0.0470062\n",
      "\tspeed: 0.0275s/iter; left time: 130.9189s\n",
      "\titers: 700, epoch: 5 | loss: 0.0503518\n",
      "\tspeed: 0.0274s/iter; left time: 127.7542s\n",
      "\titers: 800, epoch: 5 | loss: 0.0466454\n",
      "\tspeed: 0.0272s/iter; left time: 123.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.0546173 Vali Loss: 0.0563897 Test Loss: 0.0583857\n",
      "Validation loss decreased (0.057550 --> 0.056390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582530\n",
      "\tspeed: 0.1036s/iter; left time: 452.3057s\n",
      "\titers: 200, epoch: 6 | loss: 0.0565379\n",
      "\tspeed: 0.0272s/iter; left time: 116.1865s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718446\n",
      "\tspeed: 0.0272s/iter; left time: 113.4779s\n",
      "\titers: 400, epoch: 6 | loss: 0.0540270\n",
      "\tspeed: 0.0272s/iter; left time: 110.7569s\n",
      "\titers: 500, epoch: 6 | loss: 0.0500298\n",
      "\tspeed: 0.0271s/iter; left time: 107.6661s\n",
      "\titers: 600, epoch: 6 | loss: 0.0561089\n",
      "\tspeed: 0.0271s/iter; left time: 104.8665s\n",
      "\titers: 700, epoch: 6 | loss: 0.0410015\n",
      "\tspeed: 0.0271s/iter; left time: 102.2103s\n",
      "\titers: 800, epoch: 6 | loss: 0.0512881\n",
      "\tspeed: 0.0271s/iter; left time: 99.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.0532083 Vali Loss: 0.0569526 Test Loss: 0.0597836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531806\n",
      "\tspeed: 0.1012s/iter; left time: 351.4625s\n",
      "\titers: 200, epoch: 7 | loss: 0.0461118\n",
      "\tspeed: 0.0272s/iter; left time: 91.6802s\n",
      "\titers: 300, epoch: 7 | loss: 0.0501736\n",
      "\tspeed: 0.0273s/iter; left time: 89.2604s\n",
      "\titers: 400, epoch: 7 | loss: 0.0543070\n",
      "\tspeed: 0.0273s/iter; left time: 86.6364s\n",
      "\titers: 500, epoch: 7 | loss: 0.0510931\n",
      "\tspeed: 0.0270s/iter; left time: 82.8417s\n",
      "\titers: 600, epoch: 7 | loss: 0.0482978\n",
      "\tspeed: 0.0270s/iter; left time: 80.1242s\n",
      "\titers: 700, epoch: 7 | loss: 0.0444117\n",
      "\tspeed: 0.0272s/iter; left time: 78.2658s\n",
      "\titers: 800, epoch: 7 | loss: 0.0442912\n",
      "\tspeed: 0.0272s/iter; left time: 75.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0514513 Vali Loss: 0.0569198 Test Loss: 0.0590043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0531063\n",
      "\tspeed: 0.1022s/iter; left time: 263.7179s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489339\n",
      "\tspeed: 0.0275s/iter; left time: 68.1674s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549303\n",
      "\tspeed: 0.0272s/iter; left time: 64.8130s\n",
      "\titers: 400, epoch: 8 | loss: 0.0488694\n",
      "\tspeed: 0.0272s/iter; left time: 61.9901s\n",
      "\titers: 500, epoch: 8 | loss: 0.0514850\n",
      "\tspeed: 0.0273s/iter; left time: 59.4784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523009\n",
      "\tspeed: 0.0273s/iter; left time: 56.8083s\n",
      "\titers: 700, epoch: 8 | loss: 0.0520393\n",
      "\tspeed: 0.0273s/iter; left time: 54.0450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0511650\n",
      "\tspeed: 0.0272s/iter; left time: 51.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0501382 Vali Loss: 0.0566781 Test Loss: 0.0581417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01028512418270111, rmse:0.10141560435295105, mae:0.05838574469089508, rse:0.3832566440105438\n",
      "Original data scale mse:1229446.0, rmse:1108.8038330078125, mae:701.6743774414062, rse:0.07791826128959656\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975641\n",
      "\tspeed: 0.0293s/iter; left time: 258.9420s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777413\n",
      "\tspeed: 0.0273s/iter; left time: 238.4598s\n",
      "\titers: 300, epoch: 1 | loss: 0.0768691\n",
      "\tspeed: 0.0273s/iter; left time: 235.4037s\n",
      "\titers: 400, epoch: 1 | loss: 0.0726286\n",
      "\tspeed: 0.0273s/iter; left time: 232.5244s\n",
      "\titers: 500, epoch: 1 | loss: 0.0716908\n",
      "\tspeed: 0.0273s/iter; left time: 229.8772s\n",
      "\titers: 600, epoch: 1 | loss: 0.0617660\n",
      "\tspeed: 0.0272s/iter; left time: 226.9776s\n",
      "\titers: 700, epoch: 1 | loss: 0.0626643\n",
      "\tspeed: 0.0273s/iter; left time: 224.4578s\n",
      "\titers: 800, epoch: 1 | loss: 0.0655708\n",
      "\tspeed: 0.0272s/iter; left time: 221.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0756596 Vali Loss: 0.0627629 Test Loss: 0.0651303\n",
      "Validation loss decreased (inf --> 0.062763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0722900\n",
      "\tspeed: 0.1040s/iter; left time: 825.4871s\n",
      "\titers: 200, epoch: 2 | loss: 0.0733775\n",
      "\tspeed: 0.0272s/iter; left time: 212.9218s\n",
      "\titers: 300, epoch: 2 | loss: 0.0716743\n",
      "\tspeed: 0.0272s/iter; left time: 210.1759s\n",
      "\titers: 400, epoch: 2 | loss: 0.0700278\n",
      "\tspeed: 0.0272s/iter; left time: 207.5393s\n",
      "\titers: 500, epoch: 2 | loss: 0.0712918\n",
      "\tspeed: 0.0272s/iter; left time: 204.8897s\n",
      "\titers: 600, epoch: 2 | loss: 0.0671054\n",
      "\tspeed: 0.0272s/iter; left time: 202.1212s\n",
      "\titers: 700, epoch: 2 | loss: 0.0511962\n",
      "\tspeed: 0.0272s/iter; left time: 199.8970s\n",
      "\titers: 800, epoch: 2 | loss: 0.0579681\n",
      "\tspeed: 0.0274s/iter; left time: 197.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0687280 Vali Loss: 0.0642013 Test Loss: 0.0670042\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546441\n",
      "\tspeed: 0.1016s/iter; left time: 715.5404s\n",
      "\titers: 200, epoch: 3 | loss: 0.0511300\n",
      "\tspeed: 0.0272s/iter; left time: 188.8772s\n",
      "\titers: 300, epoch: 3 | loss: 0.0653810\n",
      "\tspeed: 0.0272s/iter; left time: 186.4060s\n",
      "\titers: 400, epoch: 3 | loss: 0.0579011\n",
      "\tspeed: 0.0273s/iter; left time: 183.9577s\n",
      "\titers: 500, epoch: 3 | loss: 0.0563735\n",
      "\tspeed: 0.0271s/iter; left time: 180.3892s\n",
      "\titers: 600, epoch: 3 | loss: 0.0537993\n",
      "\tspeed: 0.0273s/iter; left time: 178.6976s\n",
      "\titers: 700, epoch: 3 | loss: 0.0503184\n",
      "\tspeed: 0.0273s/iter; left time: 175.9395s\n",
      "\titers: 800, epoch: 3 | loss: 0.0616823\n",
      "\tspeed: 0.0273s/iter; left time: 173.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.0596183 Vali Loss: 0.0602274 Test Loss: 0.0631756\n",
      "Validation loss decreased (0.062763 --> 0.060227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0566016\n",
      "\tspeed: 0.1034s/iter; left time: 636.2913s\n",
      "\titers: 200, epoch: 4 | loss: 0.0607590\n",
      "\tspeed: 0.0274s/iter; left time: 165.7392s\n",
      "\titers: 300, epoch: 4 | loss: 0.0590630\n",
      "\tspeed: 0.0273s/iter; left time: 162.3564s\n",
      "\titers: 400, epoch: 4 | loss: 0.0577303\n",
      "\tspeed: 0.0275s/iter; left time: 160.8193s\n",
      "\titers: 500, epoch: 4 | loss: 0.0543574\n",
      "\tspeed: 0.0274s/iter; left time: 157.6705s\n",
      "\titers: 600, epoch: 4 | loss: 0.0560706\n",
      "\tspeed: 0.0274s/iter; left time: 154.8340s\n",
      "\titers: 700, epoch: 4 | loss: 0.0535994\n",
      "\tspeed: 0.0273s/iter; left time: 151.6173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0558486\n",
      "\tspeed: 0.0273s/iter; left time: 148.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0577159 Vali Loss: 0.0600420 Test Loss: 0.0633396\n",
      "Validation loss decreased (0.060227 --> 0.060042).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585898\n",
      "\tspeed: 0.1047s/iter; left time: 550.6945s\n",
      "\titers: 200, epoch: 5 | loss: 0.0554182\n",
      "\tspeed: 0.0273s/iter; left time: 140.9073s\n",
      "\titers: 300, epoch: 5 | loss: 0.0534251\n",
      "\tspeed: 0.0273s/iter; left time: 138.2541s\n",
      "\titers: 400, epoch: 5 | loss: 0.0573839\n",
      "\tspeed: 0.0274s/iter; left time: 135.9504s\n",
      "\titers: 500, epoch: 5 | loss: 0.0654479\n",
      "\tspeed: 0.0274s/iter; left time: 132.9638s\n",
      "\titers: 600, epoch: 5 | loss: 0.0548622\n",
      "\tspeed: 0.0274s/iter; left time: 130.3175s\n",
      "\titers: 700, epoch: 5 | loss: 0.0537886\n",
      "\tspeed: 0.0274s/iter; left time: 127.5791s\n",
      "\titers: 800, epoch: 5 | loss: 0.0669306\n",
      "\tspeed: 0.0274s/iter; left time: 124.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0556455 Vali Loss: 0.0566821 Test Loss: 0.0597330\n",
      "Validation loss decreased (0.060042 --> 0.056682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597068\n",
      "\tspeed: 0.1034s/iter; left time: 451.6137s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576773\n",
      "\tspeed: 0.0273s/iter; left time: 116.4474s\n",
      "\titers: 300, epoch: 6 | loss: 0.0541847\n",
      "\tspeed: 0.0273s/iter; left time: 113.8685s\n",
      "\titers: 400, epoch: 6 | loss: 0.0544486\n",
      "\tspeed: 0.0273s/iter; left time: 111.0857s\n",
      "\titers: 500, epoch: 6 | loss: 0.0583042\n",
      "\tspeed: 0.0273s/iter; left time: 108.4008s\n",
      "\titers: 600, epoch: 6 | loss: 0.0583834\n",
      "\tspeed: 0.0273s/iter; left time: 105.4225s\n",
      "\titers: 700, epoch: 6 | loss: 0.0603294\n",
      "\tspeed: 0.0273s/iter; left time: 102.8035s\n",
      "\titers: 800, epoch: 6 | loss: 0.0498330\n",
      "\tspeed: 0.0273s/iter; left time: 100.0575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.0539432 Vali Loss: 0.0568931 Test Loss: 0.0590978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543028\n",
      "\tspeed: 0.1013s/iter; left time: 351.7732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535316\n",
      "\tspeed: 0.0272s/iter; left time: 91.5892s\n",
      "\titers: 300, epoch: 7 | loss: 0.0476825\n",
      "\tspeed: 0.0271s/iter; left time: 88.8612s\n",
      "\titers: 400, epoch: 7 | loss: 0.0455986\n",
      "\tspeed: 0.0272s/iter; left time: 86.1572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0611927\n",
      "\tspeed: 0.0272s/iter; left time: 83.4797s\n",
      "\titers: 600, epoch: 7 | loss: 0.0537777\n",
      "\tspeed: 0.0272s/iter; left time: 80.7806s\n",
      "\titers: 700, epoch: 7 | loss: 0.0457810\n",
      "\tspeed: 0.0272s/iter; left time: 78.0918s\n",
      "\titers: 800, epoch: 7 | loss: 0.0555975\n",
      "\tspeed: 0.0272s/iter; left time: 75.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0523131 Vali Loss: 0.0568664 Test Loss: 0.0589486\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0444779\n",
      "\tspeed: 0.1026s/iter; left time: 264.5918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0471091\n",
      "\tspeed: 0.0275s/iter; left time: 68.1242s\n",
      "\titers: 300, epoch: 8 | loss: 0.0528419\n",
      "\tspeed: 0.0275s/iter; left time: 65.3533s\n",
      "\titers: 400, epoch: 8 | loss: 0.0582183\n",
      "\tspeed: 0.0274s/iter; left time: 62.4948s\n",
      "\titers: 500, epoch: 8 | loss: 0.0537932\n",
      "\tspeed: 0.0275s/iter; left time: 59.8843s\n",
      "\titers: 600, epoch: 8 | loss: 0.0470188\n",
      "\tspeed: 0.0275s/iter; left time: 57.1329s\n",
      "\titers: 700, epoch: 8 | loss: 0.0450193\n",
      "\tspeed: 0.0275s/iter; left time: 54.4315s\n",
      "\titers: 800, epoch: 8 | loss: 0.0499783\n",
      "\tspeed: 0.0274s/iter; left time: 51.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0512041 Vali Loss: 0.0569716 Test Loss: 0.0592024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010606962256133556, rmse:0.10299010574817657, mae:0.05973299592733383, rse:0.38920682668685913\n",
      "Original data scale mse:1335150.25, rmse:1155.487060546875, mae:726.6997680664062, rse:0.0811987966299057\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1105081\n",
      "\tspeed: 0.0557s/iter; left time: 491.0879s\n",
      "\titers: 200, epoch: 1 | loss: 0.0996064\n",
      "\tspeed: 0.0276s/iter; left time: 240.1496s\n",
      "\titers: 300, epoch: 1 | loss: 0.1031656\n",
      "\tspeed: 0.0276s/iter; left time: 238.0412s\n",
      "\titers: 400, epoch: 1 | loss: 0.0851174\n",
      "\tspeed: 0.0277s/iter; left time: 235.3552s\n",
      "\titers: 500, epoch: 1 | loss: 0.0866854\n",
      "\tspeed: 0.0276s/iter; left time: 232.5178s\n",
      "\titers: 600, epoch: 1 | loss: 0.0902673\n",
      "\tspeed: 0.0277s/iter; left time: 229.8870s\n",
      "\titers: 700, epoch: 1 | loss: 0.0830515\n",
      "\tspeed: 0.0277s/iter; left time: 227.2108s\n",
      "\titers: 800, epoch: 1 | loss: 0.0793476\n",
      "\tspeed: 0.0276s/iter; left time: 223.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 891 | Train Loss: 0.0937454 Vali Loss: 0.0822166 Test Loss: 0.0856704\n",
      "Validation loss decreased (inf --> 0.082217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964225\n",
      "\tspeed: 0.1043s/iter; left time: 825.9565s\n",
      "\titers: 200, epoch: 2 | loss: 0.0774365\n",
      "\tspeed: 0.0275s/iter; left time: 214.7657s\n",
      "\titers: 300, epoch: 2 | loss: 0.0834263\n",
      "\tspeed: 0.0275s/iter; left time: 211.9282s\n",
      "\titers: 400, epoch: 2 | loss: 0.0835805\n",
      "\tspeed: 0.0275s/iter; left time: 209.2406s\n",
      "\titers: 500, epoch: 2 | loss: 0.0785982\n",
      "\tspeed: 0.0274s/iter; left time: 206.3997s\n",
      "\titers: 600, epoch: 2 | loss: 0.0789744\n",
      "\tspeed: 0.0274s/iter; left time: 203.6677s\n",
      "\titers: 700, epoch: 2 | loss: 0.0887654\n",
      "\tspeed: 0.0275s/iter; left time: 201.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.0835906\n",
      "\tspeed: 0.0275s/iter; left time: 198.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0864526 Vali Loss: 0.0831924 Test Loss: 0.0863210\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888632\n",
      "\tspeed: 0.1011s/iter; left time: 710.3952s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798621\n",
      "\tspeed: 0.0275s/iter; left time: 190.8001s\n",
      "\titers: 300, epoch: 3 | loss: 0.0709843\n",
      "\tspeed: 0.0276s/iter; left time: 188.2727s\n",
      "\titers: 400, epoch: 3 | loss: 0.0765194\n",
      "\tspeed: 0.0277s/iter; left time: 186.5185s\n",
      "\titers: 500, epoch: 3 | loss: 0.0815379\n",
      "\tspeed: 0.0278s/iter; left time: 184.1734s\n",
      "\titers: 600, epoch: 3 | loss: 0.0730954\n",
      "\tspeed: 0.0279s/iter; left time: 181.9433s\n",
      "\titers: 700, epoch: 3 | loss: 0.0865044\n",
      "\tspeed: 0.0276s/iter; left time: 177.6965s\n",
      "\titers: 800, epoch: 3 | loss: 0.0689433\n",
      "\tspeed: 0.0276s/iter; left time: 174.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.0780314 Vali Loss: 0.0818157 Test Loss: 0.0857488\n",
      "Validation loss decreased (0.082217 --> 0.081816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818749\n",
      "\tspeed: 0.1029s/iter; left time: 631.3753s\n",
      "\titers: 200, epoch: 4 | loss: 0.0822757\n",
      "\tspeed: 0.0274s/iter; left time: 165.6094s\n",
      "\titers: 300, epoch: 4 | loss: 0.0778840\n",
      "\tspeed: 0.0275s/iter; left time: 163.1373s\n",
      "\titers: 400, epoch: 4 | loss: 0.0758914\n",
      "\tspeed: 0.0276s/iter; left time: 160.8885s\n",
      "\titers: 500, epoch: 4 | loss: 0.0926706\n",
      "\tspeed: 0.0276s/iter; left time: 158.6033s\n",
      "\titers: 600, epoch: 4 | loss: 0.0729162\n",
      "\tspeed: 0.0277s/iter; left time: 156.1014s\n",
      "\titers: 700, epoch: 4 | loss: 0.0779274\n",
      "\tspeed: 0.0277s/iter; left time: 153.4515s\n",
      "\titers: 800, epoch: 4 | loss: 0.0670786\n",
      "\tspeed: 0.0275s/iter; left time: 149.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0747541 Vali Loss: 0.0829245 Test Loss: 0.0867970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0757331\n",
      "\tspeed: 0.1007s/iter; left time: 528.1917s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728932\n",
      "\tspeed: 0.0276s/iter; left time: 141.9621s\n",
      "\titers: 300, epoch: 5 | loss: 0.0734011\n",
      "\tspeed: 0.0275s/iter; left time: 139.0087s\n",
      "\titers: 400, epoch: 5 | loss: 0.0735156\n",
      "\tspeed: 0.0276s/iter; left time: 136.2995s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631086\n",
      "\tspeed: 0.0275s/iter; left time: 133.4610s\n",
      "\titers: 600, epoch: 5 | loss: 0.0768523\n",
      "\tspeed: 0.0276s/iter; left time: 130.9842s\n",
      "\titers: 700, epoch: 5 | loss: 0.0680443\n",
      "\tspeed: 0.0277s/iter; left time: 128.5577s\n",
      "\titers: 800, epoch: 5 | loss: 0.0671747\n",
      "\tspeed: 0.0276s/iter; left time: 125.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0709043 Vali Loss: 0.0810450 Test Loss: 0.0866122\n",
      "Validation loss decreased (0.081816 --> 0.081045).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741014\n",
      "\tspeed: 0.1047s/iter; left time: 456.0453s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688873\n",
      "\tspeed: 0.0275s/iter; left time: 117.1964s\n",
      "\titers: 300, epoch: 6 | loss: 0.0628658\n",
      "\tspeed: 0.0275s/iter; left time: 114.3372s\n",
      "\titers: 400, epoch: 6 | loss: 0.0743414\n",
      "\tspeed: 0.0276s/iter; left time: 111.8775s\n",
      "\titers: 500, epoch: 6 | loss: 0.0634853\n",
      "\tspeed: 0.0275s/iter; left time: 108.9567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0571122\n",
      "\tspeed: 0.0276s/iter; left time: 106.2458s\n",
      "\titers: 700, epoch: 6 | loss: 0.0648721\n",
      "\tspeed: 0.0274s/iter; left time: 103.0115s\n",
      "\titers: 800, epoch: 6 | loss: 0.0680667\n",
      "\tspeed: 0.0274s/iter; left time: 100.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0659990 Vali Loss: 0.0834558 Test Loss: 0.0894878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0690747\n",
      "\tspeed: 0.1014s/iter; left time: 351.4710s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606300\n",
      "\tspeed: 0.0275s/iter; left time: 92.6739s\n",
      "\titers: 300, epoch: 7 | loss: 0.0632668\n",
      "\tspeed: 0.0275s/iter; left time: 89.7871s\n",
      "\titers: 400, epoch: 7 | loss: 0.0688783\n",
      "\tspeed: 0.0275s/iter; left time: 87.1181s\n",
      "\titers: 500, epoch: 7 | loss: 0.0662787\n",
      "\tspeed: 0.0275s/iter; left time: 84.2109s\n",
      "\titers: 600, epoch: 7 | loss: 0.0551271\n",
      "\tspeed: 0.0275s/iter; left time: 81.4969s\n",
      "\titers: 700, epoch: 7 | loss: 0.0581844\n",
      "\tspeed: 0.0279s/iter; left time: 79.8114s\n",
      "\titers: 800, epoch: 7 | loss: 0.0640281\n",
      "\tspeed: 0.0279s/iter; left time: 77.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 891 | Train Loss: 0.0618867 Vali Loss: 0.0832266 Test Loss: 0.0898357\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513199\n",
      "\tspeed: 0.1022s/iter; left time: 263.0413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0782013\n",
      "\tspeed: 0.0277s/iter; left time: 68.6314s\n",
      "\titers: 300, epoch: 8 | loss: 0.0491225\n",
      "\tspeed: 0.0277s/iter; left time: 65.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0580266\n",
      "\tspeed: 0.0278s/iter; left time: 63.1637s\n",
      "\titers: 500, epoch: 8 | loss: 0.0587969\n",
      "\tspeed: 0.0278s/iter; left time: 60.3784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0479266\n",
      "\tspeed: 0.0276s/iter; left time: 57.2363s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576645\n",
      "\tspeed: 0.0276s/iter; left time: 54.4550s\n",
      "\titers: 800, epoch: 8 | loss: 0.0481737\n",
      "\tspeed: 0.0276s/iter; left time: 51.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.88s\n",
      "Steps: 891 | Train Loss: 0.0572285 Vali Loss: 0.0836563 Test Loss: 0.0915003\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021427039057016373, rmse:0.14637978374958038, mae:0.08661221712827682, rse:0.5534777045249939\n",
      "Original data scale mse:2624052.5, rmse:1619.8927001953125, mae:1041.3607177734375, rse:0.11399847269058228\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1045499\n",
      "\tspeed: 0.0294s/iter; left time: 259.1068s\n",
      "\titers: 200, epoch: 1 | loss: 0.0942988\n",
      "\tspeed: 0.0274s/iter; left time: 238.8377s\n",
      "\titers: 300, epoch: 1 | loss: 0.0955527\n",
      "\tspeed: 0.0274s/iter; left time: 236.2447s\n",
      "\titers: 400, epoch: 1 | loss: 0.0876866\n",
      "\tspeed: 0.0278s/iter; left time: 236.4848s\n",
      "\titers: 500, epoch: 1 | loss: 0.0838357\n",
      "\tspeed: 0.0275s/iter; left time: 231.3410s\n",
      "\titers: 600, epoch: 1 | loss: 0.0872190\n",
      "\tspeed: 0.0274s/iter; left time: 228.0833s\n",
      "\titers: 700, epoch: 1 | loss: 0.0871359\n",
      "\tspeed: 0.0276s/iter; left time: 226.2911s\n",
      "\titers: 800, epoch: 1 | loss: 0.0799396\n",
      "\tspeed: 0.0275s/iter; left time: 223.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0938517 Vali Loss: 0.0821118 Test Loss: 0.0857604\n",
      "Validation loss decreased (inf --> 0.082112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913598\n",
      "\tspeed: 0.1067s/iter; left time: 845.2780s\n",
      "\titers: 200, epoch: 2 | loss: 0.0965336\n",
      "\tspeed: 0.0279s/iter; left time: 218.3456s\n",
      "\titers: 300, epoch: 2 | loss: 0.0905271\n",
      "\tspeed: 0.0279s/iter; left time: 215.1444s\n",
      "\titers: 400, epoch: 2 | loss: 0.0860040\n",
      "\tspeed: 0.0279s/iter; left time: 212.6764s\n",
      "\titers: 500, epoch: 2 | loss: 0.0879794\n",
      "\tspeed: 0.0279s/iter; left time: 209.7249s\n",
      "\titers: 600, epoch: 2 | loss: 0.0794324\n",
      "\tspeed: 0.0279s/iter; left time: 206.6952s\n",
      "\titers: 700, epoch: 2 | loss: 0.0820050\n",
      "\tspeed: 0.0279s/iter; left time: 204.2072s\n",
      "\titers: 800, epoch: 2 | loss: 0.0899950\n",
      "\tspeed: 0.0278s/iter; left time: 200.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 891 | Train Loss: 0.0877869 Vali Loss: 0.0833377 Test Loss: 0.0864561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0824860\n",
      "\tspeed: 0.1032s/iter; left time: 725.3639s\n",
      "\titers: 200, epoch: 3 | loss: 0.0761332\n",
      "\tspeed: 0.0277s/iter; left time: 192.0090s\n",
      "\titers: 300, epoch: 3 | loss: 0.0737090\n",
      "\tspeed: 0.0277s/iter; left time: 189.0776s\n",
      "\titers: 400, epoch: 3 | loss: 0.0849798\n",
      "\tspeed: 0.0277s/iter; left time: 186.2115s\n",
      "\titers: 500, epoch: 3 | loss: 0.0765213\n",
      "\tspeed: 0.0277s/iter; left time: 183.5519s\n",
      "\titers: 600, epoch: 3 | loss: 0.0724109\n",
      "\tspeed: 0.0278s/iter; left time: 181.2114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0826410\n",
      "\tspeed: 0.0277s/iter; left time: 178.2232s\n",
      "\titers: 800, epoch: 3 | loss: 0.0783634\n",
      "\tspeed: 0.0277s/iter; left time: 175.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0792087 Vali Loss: 0.0850541 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0753194\n",
      "\tspeed: 0.1041s/iter; left time: 638.8625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0721694\n",
      "\tspeed: 0.0279s/iter; left time: 168.3910s\n",
      "\titers: 300, epoch: 4 | loss: 0.0677039\n",
      "\tspeed: 0.0279s/iter; left time: 165.5042s\n",
      "\titers: 400, epoch: 4 | loss: 0.0699360\n",
      "\tspeed: 0.0275s/iter; left time: 160.8117s\n",
      "\titers: 500, epoch: 4 | loss: 0.0759124\n",
      "\tspeed: 0.0275s/iter; left time: 157.7168s\n",
      "\titers: 600, epoch: 4 | loss: 0.0900504\n",
      "\tspeed: 0.0275s/iter; left time: 155.0775s\n",
      "\titers: 700, epoch: 4 | loss: 0.0657946\n",
      "\tspeed: 0.0275s/iter; left time: 152.0975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0746171\n",
      "\tspeed: 0.0274s/iter; left time: 149.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.0764817 Vali Loss: 0.0789856 Test Loss: 0.0851568\n",
      "Validation loss decreased (0.082112 --> 0.078986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0663137\n",
      "\tspeed: 0.1037s/iter; left time: 544.1926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0731977\n",
      "\tspeed: 0.0276s/iter; left time: 141.8379s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844509\n",
      "\tspeed: 0.0275s/iter; left time: 138.9748s\n",
      "\titers: 400, epoch: 5 | loss: 0.0784731\n",
      "\tspeed: 0.0275s/iter; left time: 136.1952s\n",
      "\titers: 500, epoch: 5 | loss: 0.0762210\n",
      "\tspeed: 0.0276s/iter; left time: 133.7498s\n",
      "\titers: 600, epoch: 5 | loss: 0.0740356\n",
      "\tspeed: 0.0276s/iter; left time: 130.8398s\n",
      "\titers: 700, epoch: 5 | loss: 0.0737937\n",
      "\tspeed: 0.0275s/iter; left time: 127.7239s\n",
      "\titers: 800, epoch: 5 | loss: 0.0710074\n",
      "\tspeed: 0.0275s/iter; left time: 125.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.0719726 Vali Loss: 0.0809696 Test Loss: 0.0867843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612981\n",
      "\tspeed: 0.1014s/iter; left time: 441.7285s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708099\n",
      "\tspeed: 0.0274s/iter; left time: 116.7236s\n",
      "\titers: 300, epoch: 6 | loss: 0.0721445\n",
      "\tspeed: 0.0275s/iter; left time: 114.1800s\n",
      "\titers: 400, epoch: 6 | loss: 0.0615193\n",
      "\tspeed: 0.0275s/iter; left time: 111.7191s\n",
      "\titers: 500, epoch: 6 | loss: 0.0626318\n",
      "\tspeed: 0.0275s/iter; left time: 108.9667s\n",
      "\titers: 600, epoch: 6 | loss: 0.0559747\n",
      "\tspeed: 0.0276s/iter; left time: 106.4437s\n",
      "\titers: 700, epoch: 6 | loss: 0.0643778\n",
      "\tspeed: 0.0275s/iter; left time: 103.4658s\n",
      "\titers: 800, epoch: 6 | loss: 0.0708977\n",
      "\tspeed: 0.0275s/iter; left time: 100.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0675554 Vali Loss: 0.0832063 Test Loss: 0.0866704\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648114\n",
      "\tspeed: 0.1013s/iter; left time: 351.1349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0653329\n",
      "\tspeed: 0.0275s/iter; left time: 92.5449s\n",
      "\titers: 300, epoch: 7 | loss: 0.0769019\n",
      "\tspeed: 0.0276s/iter; left time: 89.9993s\n",
      "\titers: 400, epoch: 7 | loss: 0.0619589\n",
      "\tspeed: 0.0276s/iter; left time: 87.2128s\n",
      "\titers: 500, epoch: 7 | loss: 0.0582421\n",
      "\tspeed: 0.0275s/iter; left time: 84.4353s\n",
      "\titers: 600, epoch: 7 | loss: 0.0584133\n",
      "\tspeed: 0.0276s/iter; left time: 81.7081s\n",
      "\titers: 700, epoch: 7 | loss: 0.0624822\n",
      "\tspeed: 0.0276s/iter; left time: 78.9521s\n",
      "\titers: 800, epoch: 7 | loss: 0.0700237\n",
      "\tspeed: 0.0276s/iter; left time: 76.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0625225 Vali Loss: 0.0852454 Test Loss: 0.0872330\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020278727635741234, rmse:0.14240339398384094, mae:0.08515677601099014, rse:0.5384426116943359\n",
      "Original data scale mse:2622210.25, rmse:1619.323974609375, mae:1035.57177734375, rse:0.1139584481716156\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1059616\n",
      "\tspeed: 0.0556s/iter; left time: 489.0309s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925271\n",
      "\tspeed: 0.0281s/iter; left time: 243.9435s\n",
      "\titers: 300, epoch: 1 | loss: 0.0948087\n",
      "\tspeed: 0.0280s/iter; left time: 240.5591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1033951\n",
      "\tspeed: 0.0281s/iter; left time: 238.4128s\n",
      "\titers: 500, epoch: 1 | loss: 0.1001987\n",
      "\tspeed: 0.0281s/iter; left time: 235.3876s\n",
      "\titers: 600, epoch: 1 | loss: 0.0933774\n",
      "\tspeed: 0.0280s/iter; left time: 232.4289s\n",
      "\titers: 700, epoch: 1 | loss: 0.0946327\n",
      "\tspeed: 0.0281s/iter; left time: 230.3044s\n",
      "\titers: 800, epoch: 1 | loss: 0.0881099\n",
      "\tspeed: 0.0281s/iter; left time: 227.5806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.41s\n",
      "Steps: 889 | Train Loss: 0.0974119 Vali Loss: 0.0868911 Test Loss: 0.0899986\n",
      "Validation loss decreased (inf --> 0.086891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1020916\n",
      "\tspeed: 0.1049s/iter; left time: 828.7534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901684\n",
      "\tspeed: 0.0281s/iter; left time: 219.0411s\n",
      "\titers: 300, epoch: 2 | loss: 0.0959429\n",
      "\tspeed: 0.0280s/iter; left time: 215.8091s\n",
      "\titers: 400, epoch: 2 | loss: 0.0896802\n",
      "\tspeed: 0.0280s/iter; left time: 212.7746s\n",
      "\titers: 500, epoch: 2 | loss: 0.0897216\n",
      "\tspeed: 0.0280s/iter; left time: 210.0979s\n",
      "\titers: 600, epoch: 2 | loss: 0.0874215\n",
      "\tspeed: 0.0280s/iter; left time: 207.2917s\n",
      "\titers: 700, epoch: 2 | loss: 0.0849532\n",
      "\tspeed: 0.0280s/iter; left time: 204.4806s\n",
      "\titers: 800, epoch: 2 | loss: 0.0962499\n",
      "\tspeed: 0.0280s/iter; left time: 201.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 889 | Train Loss: 0.0912460 Vali Loss: 0.0920862 Test Loss: 0.0919890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0816956\n",
      "\tspeed: 0.1020s/iter; left time: 715.4454s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831593\n",
      "\tspeed: 0.0281s/iter; left time: 194.4577s\n",
      "\titers: 300, epoch: 3 | loss: 0.0901702\n",
      "\tspeed: 0.0281s/iter; left time: 191.7269s\n",
      "\titers: 400, epoch: 3 | loss: 0.0834232\n",
      "\tspeed: 0.0281s/iter; left time: 188.7216s\n",
      "\titers: 500, epoch: 3 | loss: 0.0726667\n",
      "\tspeed: 0.0281s/iter; left time: 185.6703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0877903\n",
      "\tspeed: 0.0281s/iter; left time: 183.0311s\n",
      "\titers: 700, epoch: 3 | loss: 0.0849057\n",
      "\tspeed: 0.0281s/iter; left time: 180.3086s\n",
      "\titers: 800, epoch: 3 | loss: 0.0813427\n",
      "\tspeed: 0.0281s/iter; left time: 177.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.0823801 Vali Loss: 0.0893270 Test Loss: 0.0928033\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0783064\n",
      "\tspeed: 0.1021s/iter; left time: 625.2114s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768117\n",
      "\tspeed: 0.0280s/iter; left time: 168.9315s\n",
      "\titers: 300, epoch: 4 | loss: 0.0803863\n",
      "\tspeed: 0.0279s/iter; left time: 165.1620s\n",
      "\titers: 400, epoch: 4 | loss: 0.0834070\n",
      "\tspeed: 0.0279s/iter; left time: 162.4391s\n",
      "\titers: 500, epoch: 4 | loss: 0.0716773\n",
      "\tspeed: 0.0279s/iter; left time: 159.6676s\n",
      "\titers: 600, epoch: 4 | loss: 0.0775080\n",
      "\tspeed: 0.0279s/iter; left time: 156.7710s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838788\n",
      "\tspeed: 0.0281s/iter; left time: 155.0253s\n",
      "\titers: 800, epoch: 4 | loss: 0.0776621\n",
      "\tspeed: 0.0281s/iter; left time: 152.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0776832 Vali Loss: 0.0887898 Test Loss: 0.0905043\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0197745431214571, rmse:0.14062198996543884, mae:0.08999864012002945, rse:0.5320742726325989\n",
      "Original data scale mse:3422754.75, rmse:1850.06884765625, mae:1207.7420654296875, rse:0.13031916320323944\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1084314\n",
      "\tspeed: 0.0302s/iter; left time: 265.4684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079780\n",
      "\tspeed: 0.0281s/iter; left time: 244.2277s\n",
      "\titers: 300, epoch: 1 | loss: 0.0920241\n",
      "\tspeed: 0.0281s/iter; left time: 241.5918s\n",
      "\titers: 400, epoch: 1 | loss: 0.0974978\n",
      "\tspeed: 0.0281s/iter; left time: 238.6649s\n",
      "\titers: 500, epoch: 1 | loss: 0.0915105\n",
      "\tspeed: 0.0281s/iter; left time: 235.9022s\n",
      "\titers: 600, epoch: 1 | loss: 0.0927587\n",
      "\tspeed: 0.0281s/iter; left time: 232.9231s\n",
      "\titers: 700, epoch: 1 | loss: 0.0884221\n",
      "\tspeed: 0.0282s/iter; left time: 230.7792s\n",
      "\titers: 800, epoch: 1 | loss: 0.0889496\n",
      "\tspeed: 0.0281s/iter; left time: 227.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 889 | Train Loss: 0.0975213 Vali Loss: 0.0868709 Test Loss: 0.0899723\n",
      "Validation loss decreased (inf --> 0.086871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052320\n",
      "\tspeed: 0.1059s/iter; left time: 836.5984s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990840\n",
      "\tspeed: 0.0281s/iter; left time: 219.4619s\n",
      "\titers: 300, epoch: 2 | loss: 0.0991621\n",
      "\tspeed: 0.0282s/iter; left time: 216.8983s\n",
      "\titers: 400, epoch: 2 | loss: 0.0781823\n",
      "\tspeed: 0.0281s/iter; left time: 213.5949s\n",
      "\titers: 500, epoch: 2 | loss: 0.0846231\n",
      "\tspeed: 0.0280s/iter; left time: 210.4189s\n",
      "\titers: 600, epoch: 2 | loss: 0.0931173\n",
      "\tspeed: 0.0280s/iter; left time: 207.2008s\n",
      "\titers: 700, epoch: 2 | loss: 0.0860006\n",
      "\tspeed: 0.0281s/iter; left time: 205.0403s\n",
      "\titers: 800, epoch: 2 | loss: 0.0766494\n",
      "\tspeed: 0.0281s/iter; left time: 202.2758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 889 | Train Loss: 0.0901386 Vali Loss: 0.0884175 Test Loss: 0.0907820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802124\n",
      "\tspeed: 0.1026s/iter; left time: 719.6549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815620\n",
      "\tspeed: 0.0281s/iter; left time: 193.9808s\n",
      "\titers: 300, epoch: 3 | loss: 0.0839815\n",
      "\tspeed: 0.0281s/iter; left time: 191.3583s\n",
      "\titers: 400, epoch: 3 | loss: 0.0790244\n",
      "\tspeed: 0.0282s/iter; left time: 189.0413s\n",
      "\titers: 500, epoch: 3 | loss: 0.0828257\n",
      "\tspeed: 0.0283s/iter; left time: 187.1084s\n",
      "\titers: 600, epoch: 3 | loss: 0.0853539\n",
      "\tspeed: 0.0281s/iter; left time: 182.8044s\n",
      "\titers: 700, epoch: 3 | loss: 0.0793968\n",
      "\tspeed: 0.0281s/iter; left time: 180.2423s\n",
      "\titers: 800, epoch: 3 | loss: 0.0808210\n",
      "\tspeed: 0.0281s/iter; left time: 177.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0807323 Vali Loss: 0.0869236 Test Loss: 0.0910492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790713\n",
      "\tspeed: 0.1025s/iter; left time: 627.5350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761492\n",
      "\tspeed: 0.0280s/iter; left time: 168.7715s\n",
      "\titers: 300, epoch: 4 | loss: 0.0809847\n",
      "\tspeed: 0.0281s/iter; left time: 166.5376s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769964\n",
      "\tspeed: 0.0281s/iter; left time: 163.5850s\n",
      "\titers: 500, epoch: 4 | loss: 0.0794484\n",
      "\tspeed: 0.0280s/iter; left time: 160.1380s\n",
      "\titers: 600, epoch: 4 | loss: 0.0832798\n",
      "\tspeed: 0.0280s/iter; left time: 157.5623s\n",
      "\titers: 700, epoch: 4 | loss: 0.0840414\n",
      "\tspeed: 0.0280s/iter; left time: 154.9441s\n",
      "\titers: 800, epoch: 4 | loss: 0.0749400\n",
      "\tspeed: 0.0281s/iter; left time: 152.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.0768347 Vali Loss: 0.0873793 Test Loss: 0.0922181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01980746164917946, rmse:0.14073897898197174, mae:0.0899723544716835, rse:0.5325169563293457\n",
      "Original data scale mse:3396051.75, rmse:1842.8380126953125, mae:1203.2320556640625, rse:0.12980982661247253\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.4048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.3892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0114  0.1067  0.0656  0.4030\n",
       "              2         24        0.0115  0.1074  0.0653  0.4058\n",
       "              1         96        0.0182  0.1349  0.0871  0.5099\n",
       "              2         96        0.0181  0.1345  0.0868  0.5084\n",
       "              1         168       0.0194  0.1392  0.0916  0.5265\n",
       "              2         168       0.0194  0.1392  0.0913  0.5267\n",
       "RMSE          1         24        0.0114  0.1068  0.0658  0.4034\n",
       "              2         24        0.0115  0.1071  0.0665  0.4048\n",
       "              1         96        0.0181  0.1346  0.0867  0.5091\n",
       "              2         96        0.0180  0.1342  0.0863  0.5074\n",
       "              1         168       0.0193  0.1389  0.0912  0.5255\n",
       "              2         168       0.0193  0.1388  0.0907  0.5252\n",
       "MAE           1         24        0.0103  0.1014  0.0584  0.3833\n",
       "              2         24        0.0106  0.1030  0.0597  0.3892\n",
       "              1         96        0.0214  0.1464  0.0866  0.5535\n",
       "              2         96        0.0203  0.1424  0.0852  0.5384\n",
       "              1         168       0.0198  0.1406  0.0900  0.5321\n",
       "              2         168       0.0198  0.1407  0.0900  0.5325"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_relu_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1649581.250</td>\n",
       "      <td>1284.3602</td>\n",
       "      <td>850.4399</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1637449.875</td>\n",
       "      <td>1279.6288</td>\n",
       "      <td>845.5874</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3181651.500</td>\n",
       "      <td>1783.7185</td>\n",
       "      <td>1182.0157</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3139555.500</td>\n",
       "      <td>1771.8790</td>\n",
       "      <td>1171.6736</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3698332.250</td>\n",
       "      <td>1923.1049</td>\n",
       "      <td>1273.1566</td>\n",
       "      <td>0.1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3587113.500</td>\n",
       "      <td>1893.9677</td>\n",
       "      <td>1255.8635</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1851359.875</td>\n",
       "      <td>1360.6469</td>\n",
       "      <td>874.3544</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1904325.375</td>\n",
       "      <td>1379.9730</td>\n",
       "      <td>891.1001</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3113013.750</td>\n",
       "      <td>1764.3734</td>\n",
       "      <td>1168.9977</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066430.250</td>\n",
       "      <td>1751.1226</td>\n",
       "      <td>1157.3804</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3630107.250</td>\n",
       "      <td>1905.2841</td>\n",
       "      <td>1260.4178</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3512351.750</td>\n",
       "      <td>1874.1270</td>\n",
       "      <td>1241.5947</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1229446.000</td>\n",
       "      <td>1108.8038</td>\n",
       "      <td>701.6744</td>\n",
       "      <td>0.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1335150.250</td>\n",
       "      <td>1155.4871</td>\n",
       "      <td>726.6998</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2624052.500</td>\n",
       "      <td>1619.8927</td>\n",
       "      <td>1041.3607</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2622210.250</td>\n",
       "      <td>1619.3240</td>\n",
       "      <td>1035.5718</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3422754.750</td>\n",
       "      <td>1850.0688</td>\n",
       "      <td>1207.7421</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3396051.750</td>\n",
       "      <td>1842.8380</td>\n",
       "      <td>1203.2321</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1649581.250  1284.3602   850.4399  0.0903\n",
       "              2         24        1637449.875  1279.6288   845.5874  0.0899\n",
       "              1         96        3181651.500  1783.7185  1182.0157  0.1255\n",
       "              2         96        3139555.500  1771.8790  1171.6736  0.1247\n",
       "              1         168       3698332.250  1923.1049  1273.1566  0.1355\n",
       "              2         168       3587113.500  1893.9677  1255.8635  0.1334\n",
       "RMSE          1         24        1851359.875  1360.6469   874.3544  0.0956\n",
       "              2         24        1904325.375  1379.9730   891.1001  0.0970\n",
       "              1         96        3113013.750  1764.3734  1168.9977  0.1242\n",
       "              2         96        3066430.250  1751.1226  1157.3804  0.1232\n",
       "              1         168       3630107.250  1905.2841  1260.4178  0.1342\n",
       "              2         168       3512351.750  1874.1270  1241.5947  0.1320\n",
       "MAE           1         24        1229446.000  1108.8038   701.6744  0.0779\n",
       "              2         24        1335150.250  1155.4871   726.6998  0.0812\n",
       "              1         96        2624052.500  1619.8927  1041.3607  0.1140\n",
       "              2         96        2622210.250  1619.3240  1035.5718  0.1140\n",
       "              1         168       3422754.750  1850.0688  1207.7421  0.1303\n",
       "              2         168       3396051.750  1842.8380  1203.2321  0.1298"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0104  0.1022  0.0591  0.3862\n",
       "         MSE            0.0115  0.1070  0.0655  0.4044\n",
       "         RMSE           0.0114  0.1069  0.0661  0.4041\n",
       "96       MAE            0.0209  0.1444  0.0859  0.5460\n",
       "         MSE            0.0181  0.1347  0.0870  0.5092\n",
       "         RMSE           0.0181  0.1344  0.0865  0.5083\n",
       "168      MAE            0.0198  0.1407  0.0900  0.5323\n",
       "         MSE            0.0194  0.1392  0.0915  0.5266\n",
       "         RMSE           0.0193  0.1389  0.0910  0.5254"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.282298e+06</td>\n",
       "      <td>1132.1454</td>\n",
       "      <td>714.1871</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.643516e+06</td>\n",
       "      <td>1281.9945</td>\n",
       "      <td>848.0136</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.877843e+06</td>\n",
       "      <td>1370.3099</td>\n",
       "      <td>882.7272</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.623131e+06</td>\n",
       "      <td>1619.6083</td>\n",
       "      <td>1038.4662</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.160604e+06</td>\n",
       "      <td>1777.7988</td>\n",
       "      <td>1176.8447</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.089722e+06</td>\n",
       "      <td>1757.7480</td>\n",
       "      <td>1163.1890</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.409403e+06</td>\n",
       "      <td>1846.4534</td>\n",
       "      <td>1205.4871</td>\n",
       "      <td>0.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.642723e+06</td>\n",
       "      <td>1908.5363</td>\n",
       "      <td>1264.5101</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.571230e+06</td>\n",
       "      <td>1889.7055</td>\n",
       "      <td>1251.0063</td>\n",
       "      <td>0.1331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.282298e+06  1132.1454   714.1871  0.0796\n",
       "         MSE            1.643516e+06  1281.9945   848.0136  0.0901\n",
       "         RMSE           1.877843e+06  1370.3099   882.7272  0.0963\n",
       "96       MAE            2.623131e+06  1619.6083  1038.4662  0.1140\n",
       "         MSE            3.160604e+06  1777.7988  1176.8447  0.1251\n",
       "         RMSE           3.089722e+06  1757.7480  1163.1890  0.1237\n",
       "168      MAE            3.409403e+06  1846.4534  1205.4871  0.1301\n",
       "         MSE            3.642723e+06  1908.5363  1264.5101  0.1344\n",
       "         RMSE           3.571230e+06  1889.7055  1251.0063  0.1331"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_IT'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
