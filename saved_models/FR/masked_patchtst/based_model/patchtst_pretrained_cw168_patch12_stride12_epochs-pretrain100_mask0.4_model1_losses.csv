train_loss,valid_loss
0.967021,0.863855
0.875508,0.834944
0.850839,0.825848
0.835060,0.815394
0.826119,0.813603
0.818174,0.811533
0.812721,0.811591
0.807732,0.804055
0.805134,0.804574
0.802614,0.803089
0.799513,0.803000
0.799269,0.798624
0.797721,0.801417
0.796596,0.802583
0.794398,0.799735
0.794607,0.803830
0.760803,0.505833
0.500298,0.435288
0.471702,0.426445
0.461441,0.417150
0.456849,0.414161
0.444955,0.410921
0.391199,0.336744
0.324345,0.243652
0.273180,0.208208
0.243475,0.191449
0.228754,0.180978
0.219027,0.173384
0.210148,0.167078
0.203780,0.163289
0.203509,0.159502
0.195104,0.156504
0.191821,0.149891
0.188840,0.149496
0.186111,0.147734
0.182733,0.141959
0.180335,0.144768
0.177639,0.141470
0.175766,0.139434
0.173763,0.142147
0.171822,0.142065
0.171173,0.136802
0.169100,0.134321
0.168610,0.132030
0.166084,0.136644
0.164497,0.133120
0.163949,0.134171
0.161749,0.131941
0.164156,0.135474
0.161470,0.131999
0.161106,0.130339
0.158587,0.129545
0.161616,0.127662
0.157708,0.128071
0.156773,0.132119
0.155541,0.126153
0.155286,0.127484
0.154722,0.126355
0.153322,0.128464
0.153042,0.124497
0.152190,0.125358
0.152303,0.128157
0.150690,0.127417
0.150546,0.126029
0.150754,0.123786
0.149388,0.127968
0.148747,0.127534
0.148349,0.125273
0.149271,0.126246
0.148833,0.125960
0.147806,0.124082
