{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST](#3-patchtst)\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2191984\n",
      "\tspeed: 0.1329s/iter; left time: 587.6187s\n",
      "\titers: 200, epoch: 1 | loss: 0.1925052\n",
      "\tspeed: 0.1106s/iter; left time: 477.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.2159439 Vali Loss: 0.1932427 Test Loss: 0.2050178\n",
      "Validation loss decreased (inf --> 0.193243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314638\n",
      "\tspeed: 0.1896s/iter; left time: 795.4534s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168003\n",
      "\tspeed: 0.1111s/iter; left time: 454.7854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 226 | Train Loss: 0.1347173 Vali Loss: 0.1344468 Test Loss: 0.1468320\n",
      "Validation loss decreased (0.193243 --> 0.134447).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1160294\n",
      "\tspeed: 0.1924s/iter; left time: 763.5237s\n",
      "\titers: 200, epoch: 3 | loss: 0.1084829\n",
      "\tspeed: 0.1120s/iter; left time: 433.2136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 226 | Train Loss: 0.1104945 Vali Loss: 0.1266848 Test Loss: 0.1359171\n",
      "Validation loss decreased (0.134447 --> 0.126685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1026648\n",
      "\tspeed: 0.1924s/iter; left time: 720.1922s\n",
      "\titers: 200, epoch: 4 | loss: 0.1025846\n",
      "\tspeed: 0.1125s/iter; left time: 409.7368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.1030868 Vali Loss: 0.1265405 Test Loss: 0.1362277\n",
      "Validation loss decreased (0.126685 --> 0.126540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0949977\n",
      "\tspeed: 0.1944s/iter; left time: 683.8708s\n",
      "\titers: 200, epoch: 5 | loss: 0.1002483\n",
      "\tspeed: 0.1127s/iter; left time: 385.1324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 226 | Train Loss: 0.0992358 Vali Loss: 0.1238016 Test Loss: 0.1330745\n",
      "Validation loss decreased (0.126540 --> 0.123802).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0978097\n",
      "\tspeed: 0.1949s/iter; left time: 641.5209s\n",
      "\titers: 200, epoch: 6 | loss: 0.1015601\n",
      "\tspeed: 0.1127s/iter; left time: 359.4686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 226 | Train Loss: 0.0974077 Vali Loss: 0.1212119 Test Loss: 0.1315436\n",
      "Validation loss decreased (0.123802 --> 0.121212).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0953034\n",
      "\tspeed: 0.1941s/iter; left time: 594.9769s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925589\n",
      "\tspeed: 0.1127s/iter; left time: 334.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 226 | Train Loss: 0.0955901 Vali Loss: 0.1219282 Test Loss: 0.1315164\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0931154\n",
      "\tspeed: 0.1906s/iter; left time: 541.0730s\n",
      "\titers: 200, epoch: 8 | loss: 0.0909662\n",
      "\tspeed: 0.1126s/iter; left time: 308.4447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.71s\n",
      "Steps: 226 | Train Loss: 0.0935574 Vali Loss: 0.1238804 Test Loss: 0.1346278\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0929445\n",
      "\tspeed: 0.1916s/iter; left time: 500.5761s\n",
      "\titers: 200, epoch: 9 | loss: 0.0922069\n",
      "\tspeed: 0.1126s/iter; left time: 282.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 226 | Train Loss: 0.0925014 Vali Loss: 0.1221920 Test Loss: 0.1338049\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0917716\n",
      "\tspeed: 0.1911s/iter; left time: 456.2730s\n",
      "\titers: 200, epoch: 10 | loss: 0.0917850\n",
      "\tspeed: 0.1125s/iter; left time: 257.3899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 226 | Train Loss: 0.0911621 Vali Loss: 0.1241075 Test Loss: 0.1356859\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0864981\n",
      "\tspeed: 0.1905s/iter; left time: 411.6115s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797761\n",
      "\tspeed: 0.1125s/iter; left time: 231.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0876384 Vali Loss: 0.1064428 Test Loss: 0.1148914\n",
      "Validation loss decreased (0.121212 --> 0.106443).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0703839\n",
      "\tspeed: 0.1930s/iter; left time: 373.4076s\n",
      "\titers: 200, epoch: 12 | loss: 0.0710526\n",
      "\tspeed: 0.1125s/iter; left time: 206.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0727683 Vali Loss: 0.1008933 Test Loss: 0.1059929\n",
      "Validation loss decreased (0.106443 --> 0.100893).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0693913\n",
      "\tspeed: 0.1923s/iter; left time: 328.6161s\n",
      "\titers: 200, epoch: 13 | loss: 0.0659728\n",
      "\tspeed: 0.1124s/iter; left time: 180.8075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0698396 Vali Loss: 0.0995669 Test Loss: 0.1047026\n",
      "Validation loss decreased (0.100893 --> 0.099567).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0712161\n",
      "\tspeed: 0.1933s/iter; left time: 286.6257s\n",
      "\titers: 200, epoch: 14 | loss: 0.0680469\n",
      "\tspeed: 0.1124s/iter; left time: 155.4409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 226 | Train Loss: 0.0685004 Vali Loss: 0.0970622 Test Loss: 0.1024812\n",
      "Validation loss decreased (0.099567 --> 0.097062).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0658465\n",
      "\tspeed: 0.1952s/iter; left time: 245.4027s\n",
      "\titers: 200, epoch: 15 | loss: 0.0686972\n",
      "\tspeed: 0.1124s/iter; left time: 130.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0672232 Vali Loss: 0.0986991 Test Loss: 0.1040994\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0672652\n",
      "\tspeed: 0.1900s/iter; left time: 195.8481s\n",
      "\titers: 200, epoch: 16 | loss: 0.0654867\n",
      "\tspeed: 0.1124s/iter; left time: 104.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0661957 Vali Loss: 0.0980600 Test Loss: 0.1028845\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0616860\n",
      "\tspeed: 0.1896s/iter; left time: 152.6511s\n",
      "\titers: 200, epoch: 17 | loss: 0.0646053\n",
      "\tspeed: 0.1124s/iter; left time: 79.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0652759 Vali Loss: 0.0986465 Test Loss: 0.1037694\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657193\n",
      "\tspeed: 0.1902s/iter; left time: 110.1415s\n",
      "\titers: 200, epoch: 18 | loss: 0.0649153\n",
      "\tspeed: 0.1124s/iter; left time: 53.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.72s\n",
      "Steps: 226 | Train Loss: 0.0646328 Vali Loss: 0.0990219 Test Loss: 0.1048393\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0642070\n",
      "\tspeed: 0.1901s/iter; left time: 67.1056s\n",
      "\titers: 200, epoch: 19 | loss: 0.0591548\n",
      "\tspeed: 0.1124s/iter; left time: 28.4331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0637807 Vali Loss: 0.0987908 Test Loss: 0.1046540\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02550637163221836, rmse:0.15970714390277863, mae:0.10258069634437561, rse:0.563628613948822\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2071513\n",
      "\tspeed: 0.1143s/iter; left time: 505.2550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1939065\n",
      "\tspeed: 0.1124s/iter; left time: 485.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.2192140 Vali Loss: 0.1865198 Test Loss: 0.1999819\n",
      "Validation loss decreased (inf --> 0.186520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1352927\n",
      "\tspeed: 0.1948s/iter; left time: 817.0433s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133211\n",
      "\tspeed: 0.1125s/iter; left time: 460.5926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 226 | Train Loss: 0.1359326 Vali Loss: 0.1325191 Test Loss: 0.1379216\n",
      "Validation loss decreased (0.186520 --> 0.132519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1034351\n",
      "\tspeed: 0.1937s/iter; left time: 768.7858s\n",
      "\titers: 200, epoch: 3 | loss: 0.0964917\n",
      "\tspeed: 0.1124s/iter; left time: 434.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.1024061 Vali Loss: 0.1121975 Test Loss: 0.1181073\n",
      "Validation loss decreased (0.132519 --> 0.112198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0932029\n",
      "\tspeed: 0.1927s/iter; left time: 721.1668s\n",
      "\titers: 200, epoch: 4 | loss: 0.0836130\n",
      "\tspeed: 0.1124s/iter; left time: 409.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0930664 Vali Loss: 0.1060084 Test Loss: 0.1078324\n",
      "Validation loss decreased (0.112198 --> 0.106008).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0869098\n",
      "\tspeed: 0.1923s/iter; left time: 676.2364s\n",
      "\titers: 200, epoch: 5 | loss: 0.0806634\n",
      "\tspeed: 0.1124s/iter; left time: 383.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0842085 Vali Loss: 0.0983439 Test Loss: 0.1008612\n",
      "Validation loss decreased (0.106008 --> 0.098344).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0742313\n",
      "\tspeed: 0.1921s/iter; left time: 632.1980s\n",
      "\titers: 200, epoch: 6 | loss: 0.0787062\n",
      "\tspeed: 0.1124s/iter; left time: 358.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0800830 Vali Loss: 0.1002331 Test Loss: 0.1021700\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776621\n",
      "\tspeed: 0.1895s/iter; left time: 580.6978s\n",
      "\titers: 200, epoch: 7 | loss: 0.0762639\n",
      "\tspeed: 0.1124s/iter; left time: 333.3197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0779277 Vali Loss: 0.0970966 Test Loss: 0.1002370\n",
      "Validation loss decreased (0.098344 --> 0.097097).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0771072\n",
      "\tspeed: 0.1937s/iter; left time: 549.8210s\n",
      "\titers: 200, epoch: 8 | loss: 0.0777450\n",
      "\tspeed: 0.1124s/iter; left time: 307.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.71s\n",
      "Steps: 226 | Train Loss: 0.0755896 Vali Loss: 0.0983142 Test Loss: 0.1022950\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749332\n",
      "\tspeed: 0.1895s/iter; left time: 495.2631s\n",
      "\titers: 200, epoch: 9 | loss: 0.0756877\n",
      "\tspeed: 0.1124s/iter; left time: 282.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0735994 Vali Loss: 0.0967036 Test Loss: 0.0992084\n",
      "Validation loss decreased (0.097097 --> 0.096704).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688027\n",
      "\tspeed: 0.1925s/iter; left time: 459.5080s\n",
      "\titers: 200, epoch: 10 | loss: 0.0702747\n",
      "\tspeed: 0.1124s/iter; left time: 257.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0719193 Vali Loss: 0.0948332 Test Loss: 0.0999299\n",
      "Validation loss decreased (0.096704 --> 0.094833).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0713559\n",
      "\tspeed: 0.1934s/iter; left time: 417.9545s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664703\n",
      "\tspeed: 0.1124s/iter; left time: 231.6709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 226 | Train Loss: 0.0704945 Vali Loss: 0.0948332 Test Loss: 0.1007622\n",
      "Validation loss decreased (0.094833 --> 0.094833).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0745672\n",
      "\tspeed: 0.1926s/iter; left time: 372.7408s\n",
      "\titers: 200, epoch: 12 | loss: 0.0670908\n",
      "\tspeed: 0.1124s/iter; left time: 206.3404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0691345 Vali Loss: 0.0961752 Test Loss: 0.0995369\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0661836\n",
      "\tspeed: 0.1905s/iter; left time: 325.5443s\n",
      "\titers: 200, epoch: 13 | loss: 0.0651209\n",
      "\tspeed: 0.1125s/iter; left time: 180.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0675983 Vali Loss: 0.0958593 Test Loss: 0.0998250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0632049\n",
      "\tspeed: 0.1898s/iter; left time: 281.5216s\n",
      "\titers: 200, epoch: 14 | loss: 0.0675911\n",
      "\tspeed: 0.1126s/iter; left time: 155.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0667691 Vali Loss: 0.0950352 Test Loss: 0.1003133\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0625391\n",
      "\tspeed: 0.1901s/iter; left time: 238.9521s\n",
      "\titers: 200, epoch: 15 | loss: 0.0638707\n",
      "\tspeed: 0.1124s/iter; left time: 130.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0657719 Vali Loss: 0.0956399 Test Loss: 0.0990897\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0630712\n",
      "\tspeed: 0.1894s/iter; left time: 195.3080s\n",
      "\titers: 200, epoch: 16 | loss: 0.0631331\n",
      "\tspeed: 0.1124s/iter; left time: 104.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0649568 Vali Loss: 0.0948139 Test Loss: 0.0993918\n",
      "Validation loss decreased (0.094833 --> 0.094814).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0651423\n",
      "\tspeed: 0.1933s/iter; left time: 155.6148s\n",
      "\titers: 200, epoch: 17 | loss: 0.0643190\n",
      "\tspeed: 0.1124s/iter; left time: 79.2713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 226 | Train Loss: 0.0641716 Vali Loss: 0.0957029 Test Loss: 0.0983704\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0657891\n",
      "\tspeed: 0.1899s/iter; left time: 109.9522s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641839\n",
      "\tspeed: 0.1125s/iter; left time: 53.8779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0631766 Vali Loss: 0.0949992 Test Loss: 0.0989038\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0607632\n",
      "\tspeed: 0.1898s/iter; left time: 66.9966s\n",
      "\titers: 200, epoch: 19 | loss: 0.0642785\n",
      "\tspeed: 0.1124s/iter; left time: 28.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0627735 Vali Loss: 0.0962504 Test Loss: 0.0995008\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0576813\n",
      "\tspeed: 0.1896s/iter; left time: 24.0732s\n",
      "\titers: 200, epoch: 20 | loss: 0.0619529\n",
      "\tspeed: 0.1125s/iter; left time: 3.0371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0621232 Vali Loss: 0.0952695 Test Loss: 0.0991549\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02397911250591278, rmse:0.15485189855098724, mae:0.09960474073886871, rse:0.5464938282966614\n",
      "Intermediate time for DE and pred_len 24: 00h:19m:57.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2200362\n",
      "\tspeed: 0.1667s/iter; left time: 736.9175s\n",
      "\titers: 200, epoch: 1 | loss: 0.2012604\n",
      "\tspeed: 0.1446s/iter; left time: 624.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.28s\n",
      "Steps: 226 | Train Loss: 0.2218854 Vali Loss: 0.2003790 Test Loss: 0.2206613\n",
      "Validation loss decreased (inf --> 0.200379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1535316\n",
      "\tspeed: 0.2486s/iter; left time: 1042.7408s\n",
      "\titers: 200, epoch: 2 | loss: 0.1436451\n",
      "\tspeed: 0.1446s/iter; left time: 592.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.1546836 Vali Loss: 0.1649555 Test Loss: 0.1807774\n",
      "Validation loss decreased (0.200379 --> 0.164956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1345716\n",
      "\tspeed: 0.2492s/iter; left time: 989.0355s\n",
      "\titers: 200, epoch: 3 | loss: 0.1324446\n",
      "\tspeed: 0.1449s/iter; left time: 560.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.02s\n",
      "Steps: 226 | Train Loss: 0.1349887 Vali Loss: 0.1560564 Test Loss: 0.1711857\n",
      "Validation loss decreased (0.164956 --> 0.156056).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1305542\n",
      "\tspeed: 0.2496s/iter; left time: 934.1388s\n",
      "\titers: 200, epoch: 4 | loss: 0.1230385\n",
      "\tspeed: 0.1447s/iter; left time: 527.1216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.99s\n",
      "Steps: 226 | Train Loss: 0.1241731 Vali Loss: 0.1535830 Test Loss: 0.1691201\n",
      "Validation loss decreased (0.156056 --> 0.153583).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1193244\n",
      "\tspeed: 0.2557s/iter; left time: 899.4665s\n",
      "\titers: 200, epoch: 5 | loss: 0.1132296\n",
      "\tspeed: 0.1445s/iter; left time: 493.6809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1175278 Vali Loss: 0.1436282 Test Loss: 0.1596925\n",
      "Validation loss decreased (0.153583 --> 0.143628).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1107184\n",
      "\tspeed: 0.2484s/iter; left time: 817.4045s\n",
      "\titers: 200, epoch: 6 | loss: 0.1072975\n",
      "\tspeed: 0.1445s/iter; left time: 461.2437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.03s\n",
      "Steps: 226 | Train Loss: 0.1090920 Vali Loss: 0.1375908 Test Loss: 0.1508135\n",
      "Validation loss decreased (0.143628 --> 0.137591).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1008609\n",
      "\tspeed: 0.2503s/iter; left time: 767.0864s\n",
      "\titers: 200, epoch: 7 | loss: 0.1042848\n",
      "\tspeed: 0.1447s/iter; left time: 429.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.01s\n",
      "Steps: 226 | Train Loss: 0.1034633 Vali Loss: 0.1341533 Test Loss: 0.1532133\n",
      "Validation loss decreased (0.137591 --> 0.134153).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0966008\n",
      "\tspeed: 0.2491s/iter; left time: 707.1162s\n",
      "\titers: 200, epoch: 8 | loss: 0.1004291\n",
      "\tspeed: 0.1447s/iter; left time: 396.2141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0994022 Vali Loss: 0.1356787 Test Loss: 0.1538816\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0905479\n",
      "\tspeed: 0.2459s/iter; left time: 642.4376s\n",
      "\titers: 200, epoch: 9 | loss: 0.0909362\n",
      "\tspeed: 0.1445s/iter; left time: 363.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.0938491 Vali Loss: 0.1295161 Test Loss: 0.1510132\n",
      "Validation loss decreased (0.134153 --> 0.129516).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0930162\n",
      "\tspeed: 0.2498s/iter; left time: 596.2002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0897120\n",
      "\tspeed: 0.1444s/iter; left time: 330.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0901773 Vali Loss: 0.1307912 Test Loss: 0.1480134\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844717\n",
      "\tspeed: 0.2456s/iter; left time: 530.6393s\n",
      "\titers: 200, epoch: 11 | loss: 0.0871740\n",
      "\tspeed: 0.1444s/iter; left time: 297.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.0874034 Vali Loss: 0.1306282 Test Loss: 0.1471153\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0907402\n",
      "\tspeed: 0.2463s/iter; left time: 476.6654s\n",
      "\titers: 200, epoch: 12 | loss: 0.0841027\n",
      "\tspeed: 0.1445s/iter; left time: 265.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.99s\n",
      "Steps: 226 | Train Loss: 0.0855618 Vali Loss: 0.1342329 Test Loss: 0.1491844\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0811777\n",
      "\tspeed: 0.2459s/iter; left time: 420.3098s\n",
      "\titers: 200, epoch: 13 | loss: 0.0845306\n",
      "\tspeed: 0.1446s/iter; left time: 232.5968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.98s\n",
      "Steps: 226 | Train Loss: 0.0838017 Vali Loss: 0.1326705 Test Loss: 0.1503428\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0839681\n",
      "\tspeed: 0.2463s/iter; left time: 365.2605s\n",
      "\titers: 200, epoch: 14 | loss: 0.0809291\n",
      "\tspeed: 0.1445s/iter; left time: 199.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0820114 Vali Loss: 0.1317957 Test Loss: 0.1501186\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051743797957897186, rmse:0.22747263312339783, mae:0.15091562271118164, rse:0.8055265545845032\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2302332\n",
      "\tspeed: 0.1462s/iter; left time: 646.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.2064224\n",
      "\tspeed: 0.1444s/iter; left time: 623.9417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.2307192 Vali Loss: 0.2159597 Test Loss: 0.2359195\n",
      "Validation loss decreased (inf --> 0.215960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1524357\n",
      "\tspeed: 0.2530s/iter; left time: 1061.2839s\n",
      "\titers: 200, epoch: 2 | loss: 0.1440340\n",
      "\tspeed: 0.1444s/iter; left time: 591.1693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.31s\n",
      "Steps: 226 | Train Loss: 0.1574332 Vali Loss: 0.1710052 Test Loss: 0.1851751\n",
      "Validation loss decreased (0.215960 --> 0.171005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1320199\n",
      "\tspeed: 0.2543s/iter; left time: 1009.4857s\n",
      "\titers: 200, epoch: 3 | loss: 0.1330540\n",
      "\tspeed: 0.1444s/iter; left time: 558.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.1369640 Vali Loss: 0.1605973 Test Loss: 0.1772115\n",
      "Validation loss decreased (0.171005 --> 0.160597).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1274869\n",
      "\tspeed: 0.2505s/iter; left time: 937.6220s\n",
      "\titers: 200, epoch: 4 | loss: 0.1305294\n",
      "\tspeed: 0.1444s/iter; left time: 525.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.1303049 Vali Loss: 0.1653224 Test Loss: 0.1796754\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1301885\n",
      "\tspeed: 0.2466s/iter; left time: 867.4273s\n",
      "\titers: 200, epoch: 5 | loss: 0.1247947\n",
      "\tspeed: 0.1446s/iter; left time: 494.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.98s\n",
      "Steps: 226 | Train Loss: 0.1258707 Vali Loss: 0.1569485 Test Loss: 0.1787132\n",
      "Validation loss decreased (0.160597 --> 0.156949).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1200539\n",
      "\tspeed: 0.2499s/iter; left time: 822.4938s\n",
      "\titers: 200, epoch: 6 | loss: 0.1239623\n",
      "\tspeed: 0.1445s/iter; left time: 460.9697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:33.00s\n",
      "Steps: 226 | Train Loss: 0.1223078 Vali Loss: 0.1542412 Test Loss: 0.1757769\n",
      "Validation loss decreased (0.156949 --> 0.154241).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1174654\n",
      "\tspeed: 0.2495s/iter; left time: 764.8515s\n",
      "\titers: 200, epoch: 7 | loss: 0.1125576\n",
      "\tspeed: 0.1445s/iter; left time: 428.3615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1179980 Vali Loss: 0.1519684 Test Loss: 0.1709698\n",
      "Validation loss decreased (0.154241 --> 0.151968).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1114029\n",
      "\tspeed: 0.2490s/iter; left time: 706.9992s\n",
      "\titers: 200, epoch: 8 | loss: 0.1079107\n",
      "\tspeed: 0.1445s/iter; left time: 395.6636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1106599 Vali Loss: 0.1478356 Test Loss: 0.1684052\n",
      "Validation loss decreased (0.151968 --> 0.147836).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1033346\n",
      "\tspeed: 0.2494s/iter; left time: 651.5780s\n",
      "\titers: 200, epoch: 9 | loss: 0.1040864\n",
      "\tspeed: 0.1445s/iter; left time: 363.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.1046413 Vali Loss: 0.1439615 Test Loss: 0.1658513\n",
      "Validation loss decreased (0.147836 --> 0.143962).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1017254\n",
      "\tspeed: 0.2484s/iter; left time: 592.9881s\n",
      "\titers: 200, epoch: 10 | loss: 0.0993685\n",
      "\tspeed: 0.1445s/iter; left time: 330.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1009847 Vali Loss: 0.1451816 Test Loss: 0.1662015\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0993654\n",
      "\tspeed: 0.2461s/iter; left time: 531.9206s\n",
      "\titers: 200, epoch: 11 | loss: 0.0943038\n",
      "\tspeed: 0.1445s/iter; left time: 297.7753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.0978804 Vali Loss: 0.1443404 Test Loss: 0.1641275\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0952126\n",
      "\tspeed: 0.2467s/iter; left time: 477.2905s\n",
      "\titers: 200, epoch: 12 | loss: 0.0878135\n",
      "\tspeed: 0.1447s/iter; left time: 265.5774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:33.00s\n",
      "Steps: 226 | Train Loss: 0.0927985 Vali Loss: 0.1373306 Test Loss: 0.1553303\n",
      "Validation loss decreased (0.143962 --> 0.137331).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0877777\n",
      "\tspeed: 0.2512s/iter; left time: 429.2441s\n",
      "\titers: 200, epoch: 13 | loss: 0.0866513\n",
      "\tspeed: 0.1444s/iter; left time: 232.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0867281 Vali Loss: 0.1313956 Test Loss: 0.1497746\n",
      "Validation loss decreased (0.137331 --> 0.131396).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0839621\n",
      "\tspeed: 0.2499s/iter; left time: 370.5598s\n",
      "\titers: 200, epoch: 14 | loss: 0.0853569\n",
      "\tspeed: 0.1445s/iter; left time: 199.8021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.0844398 Vali Loss: 0.1357617 Test Loss: 0.1517995\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0845734\n",
      "\tspeed: 0.2459s/iter; left time: 309.1536s\n",
      "\titers: 200, epoch: 15 | loss: 0.0851592\n",
      "\tspeed: 0.1445s/iter; left time: 167.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.0828165 Vali Loss: 0.1349822 Test Loss: 0.1511226\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0832207\n",
      "\tspeed: 0.2467s/iter; left time: 254.3833s\n",
      "\titers: 200, epoch: 16 | loss: 0.0803255\n",
      "\tspeed: 0.1448s/iter; left time: 134.7738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:33.06s\n",
      "Steps: 226 | Train Loss: 0.0816068 Vali Loss: 0.1368742 Test Loss: 0.1537199\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777356\n",
      "\tspeed: 0.2469s/iter; left time: 198.7739s\n",
      "\titers: 200, epoch: 17 | loss: 0.0767169\n",
      "\tspeed: 0.1446s/iter; left time: 101.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0800614 Vali Loss: 0.1358866 Test Loss: 0.1534883\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0825909\n",
      "\tspeed: 0.2459s/iter; left time: 142.3730s\n",
      "\titers: 200, epoch: 18 | loss: 0.0830482\n",
      "\tspeed: 0.1446s/iter; left time: 69.2573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.0791317 Vali Loss: 0.1325936 Test Loss: 0.1495270\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05006013065576553, rmse:0.22374121844768524, mae:0.1497931331396103, rse:0.7923128604888916\n",
      "Intermediate time for DE and pred_len 96: 00h:21m:13.08s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2169671\n",
      "\tspeed: 0.1993s/iter; left time: 877.1171s\n",
      "\titers: 200, epoch: 1 | loss: 0.2038472\n",
      "\tspeed: 0.1781s/iter; left time: 765.8961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.68s\n",
      "Steps: 225 | Train Loss: 0.2240388 Vali Loss: 0.2022819 Test Loss: 0.2242716\n",
      "Validation loss decreased (inf --> 0.202282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1512878\n",
      "\tspeed: 0.3049s/iter; left time: 1273.4541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1503087\n",
      "\tspeed: 0.1781s/iter; left time: 725.7355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1597763 Vali Loss: 0.1765698 Test Loss: 0.1921602\n",
      "Validation loss decreased (0.202282 --> 0.176570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1450239\n",
      "\tspeed: 0.3038s/iter; left time: 1200.2139s\n",
      "\titers: 200, epoch: 3 | loss: 0.1353425\n",
      "\tspeed: 0.1779s/iter; left time: 685.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.31s\n",
      "Steps: 225 | Train Loss: 0.1430676 Vali Loss: 0.1687627 Test Loss: 0.1876357\n",
      "Validation loss decreased (0.176570 --> 0.168763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1372974\n",
      "\tspeed: 0.3028s/iter; left time: 1128.0667s\n",
      "\titers: 200, epoch: 4 | loss: 0.1326260\n",
      "\tspeed: 0.1780s/iter; left time: 645.3172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.31s\n",
      "Steps: 225 | Train Loss: 0.1374954 Vali Loss: 0.1724461 Test Loss: 0.1906067\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1395691\n",
      "\tspeed: 0.2994s/iter; left time: 1048.2714s\n",
      "\titers: 200, epoch: 5 | loss: 0.1318163\n",
      "\tspeed: 0.1780s/iter; left time: 605.3936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.30s\n",
      "Steps: 225 | Train Loss: 0.1334877 Vali Loss: 0.1698701 Test Loss: 0.1872851\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1326521\n",
      "\tspeed: 0.3021s/iter; left time: 989.8176s\n",
      "\titers: 200, epoch: 6 | loss: 0.1277456\n",
      "\tspeed: 0.1787s/iter; left time: 567.5412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.55s\n",
      "Steps: 225 | Train Loss: 0.1287955 Vali Loss: 0.1730250 Test Loss: 0.1893142\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1241229\n",
      "\tspeed: 0.3007s/iter; left time: 917.2992s\n",
      "\titers: 200, epoch: 7 | loss: 0.1216235\n",
      "\tspeed: 0.1781s/iter; left time: 525.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.29s\n",
      "Steps: 225 | Train Loss: 0.1240600 Vali Loss: 0.1620095 Test Loss: 0.1842054\n",
      "Validation loss decreased (0.168763 --> 0.162009).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1160876\n",
      "\tspeed: 0.3034s/iter; left time: 857.3163s\n",
      "\titers: 200, epoch: 8 | loss: 0.1117514\n",
      "\tspeed: 0.1780s/iter; left time: 485.2473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.35s\n",
      "Steps: 225 | Train Loss: 0.1149717 Vali Loss: 0.1568870 Test Loss: 0.1778534\n",
      "Validation loss decreased (0.162009 --> 0.156887).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1065129\n",
      "\tspeed: 0.3023s/iter; left time: 786.2832s\n",
      "\titers: 200, epoch: 9 | loss: 0.1065176\n",
      "\tspeed: 0.1780s/iter; left time: 445.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.29s\n",
      "Steps: 225 | Train Loss: 0.1083615 Vali Loss: 0.1527688 Test Loss: 0.1704960\n",
      "Validation loss decreased (0.156887 --> 0.152769).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1002196\n",
      "\tspeed: 0.3044s/iter; left time: 723.2111s\n",
      "\titers: 200, epoch: 10 | loss: 0.0969234\n",
      "\tspeed: 0.1781s/iter; left time: 405.2917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0994018 Vali Loss: 0.1420476 Test Loss: 0.1551753\n",
      "Validation loss decreased (0.152769 --> 0.142048).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0924578\n",
      "\tspeed: 0.3028s/iter; left time: 651.3563s\n",
      "\titers: 200, epoch: 11 | loss: 0.0936776\n",
      "\tspeed: 0.1781s/iter; left time: 365.3366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0935255 Vali Loss: 0.1407854 Test Loss: 0.1584631\n",
      "Validation loss decreased (0.142048 --> 0.140785).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0903802\n",
      "\tspeed: 0.3051s/iter; left time: 587.7041s\n",
      "\titers: 200, epoch: 12 | loss: 0.0884845\n",
      "\tspeed: 0.1786s/iter; left time: 326.1715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.56s\n",
      "Steps: 225 | Train Loss: 0.0907624 Vali Loss: 0.1460839 Test Loss: 0.1601185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0880124\n",
      "\tspeed: 0.3020s/iter; left time: 513.6590s\n",
      "\titers: 200, epoch: 13 | loss: 0.0888366\n",
      "\tspeed: 0.1783s/iter; left time: 285.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0887032 Vali Loss: 0.1441631 Test Loss: 0.1611900\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0890861\n",
      "\tspeed: 0.3004s/iter; left time: 443.3870s\n",
      "\titers: 200, epoch: 14 | loss: 0.0878262\n",
      "\tspeed: 0.1782s/iter; left time: 245.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.35s\n",
      "Steps: 225 | Train Loss: 0.0870646 Vali Loss: 0.1433248 Test Loss: 0.1618975\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0829824\n",
      "\tspeed: 0.3010s/iter; left time: 376.5060s\n",
      "\titers: 200, epoch: 15 | loss: 0.0844335\n",
      "\tspeed: 0.1790s/iter; left time: 206.0799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.56s\n",
      "Steps: 225 | Train Loss: 0.0857711 Vali Loss: 0.1449560 Test Loss: 0.1632163\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0844385\n",
      "\tspeed: 0.3022s/iter; left time: 310.0344s\n",
      "\titers: 200, epoch: 16 | loss: 0.0813954\n",
      "\tspeed: 0.1783s/iter; left time: 165.1096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.0845858 Vali Loss: 0.1452336 Test Loss: 0.1627378\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05523236468434334, rmse:0.23501567542552948, mae:0.15854020416736603, rse:0.832444429397583\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2273217\n",
      "\tspeed: 0.1809s/iter; left time: 796.0532s\n",
      "\titers: 200, epoch: 1 | loss: 0.1998441\n",
      "\tspeed: 0.1784s/iter; left time: 767.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.52s\n",
      "Steps: 225 | Train Loss: 0.2249971 Vali Loss: 0.2031057 Test Loss: 0.2260262\n",
      "Validation loss decreased (inf --> 0.203106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1547653\n",
      "\tspeed: 0.3036s/iter; left time: 1267.7790s\n",
      "\titers: 200, epoch: 2 | loss: 0.1528366\n",
      "\tspeed: 0.1785s/iter; left time: 727.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.1601981 Vali Loss: 0.1738310 Test Loss: 0.1902849\n",
      "Validation loss decreased (0.203106 --> 0.173831).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1386869\n",
      "\tspeed: 0.3033s/iter; left time: 1198.2892s\n",
      "\titers: 200, epoch: 3 | loss: 0.1401473\n",
      "\tspeed: 0.1784s/iter; left time: 687.1165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.40s\n",
      "Steps: 225 | Train Loss: 0.1433476 Vali Loss: 0.1723074 Test Loss: 0.1877486\n",
      "Validation loss decreased (0.173831 --> 0.172307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1380620\n",
      "\tspeed: 0.3035s/iter; left time: 1130.7701s\n",
      "\titers: 200, epoch: 4 | loss: 0.1427474\n",
      "\tspeed: 0.1784s/iter; left time: 647.0413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.1374656 Vali Loss: 0.1651601 Test Loss: 0.1879196\n",
      "Validation loss decreased (0.172307 --> 0.165160).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1352166\n",
      "\tspeed: 0.3034s/iter; left time: 1062.2309s\n",
      "\titers: 200, epoch: 5 | loss: 0.1275465\n",
      "\tspeed: 0.1785s/iter; left time: 607.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.1332841 Vali Loss: 0.1696983 Test Loss: 0.1937665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1266169\n",
      "\tspeed: 0.2999s/iter; left time: 982.3693s\n",
      "\titers: 200, epoch: 6 | loss: 0.1289284\n",
      "\tspeed: 0.1786s/iter; left time: 567.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.1286696 Vali Loss: 0.1695248 Test Loss: 0.1910921\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1233527\n",
      "\tspeed: 0.2999s/iter; left time: 915.0733s\n",
      "\titers: 200, epoch: 7 | loss: 0.1236354\n",
      "\tspeed: 0.1786s/iter; left time: 526.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.1250824 Vali Loss: 0.1652050 Test Loss: 0.1894411\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1196133\n",
      "\tspeed: 0.3004s/iter; left time: 849.0007s\n",
      "\titers: 200, epoch: 8 | loss: 0.1245334\n",
      "\tspeed: 0.1786s/iter; left time: 486.7528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 225 | Train Loss: 0.1210158 Vali Loss: 0.1655154 Test Loss: 0.1900287\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1179073\n",
      "\tspeed: 0.3003s/iter; left time: 781.0972s\n",
      "\titers: 200, epoch: 9 | loss: 0.1160795\n",
      "\tspeed: 0.1785s/iter; left time: 446.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.1173404 Vali Loss: 0.1682258 Test Loss: 0.1940871\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07423169165849686, rmse:0.2724549472332001, mae:0.18800583481788635, rse:0.9650572538375854\n",
      "Intermediate time for DE and pred_len 168: 00h:20m:18.02s\n",
      "Intermediate time for DE: 01h:01m:28.35s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2196200\n",
      "\tspeed: 0.1341s/iter; left time: 592.6613s\n",
      "\titers: 200, epoch: 1 | loss: 0.1834605\n",
      "\tspeed: 0.1121s/iter; left time: 484.2710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.94s\n",
      "Steps: 226 | Train Loss: 0.2171512 Vali Loss: 0.1743793 Test Loss: 0.2067018\n",
      "Validation loss decreased (inf --> 0.174379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1203193\n",
      "\tspeed: 0.1946s/iter; left time: 816.5476s\n",
      "\titers: 200, epoch: 2 | loss: 0.1098573\n",
      "\tspeed: 0.1122s/iter; left time: 459.4554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.1268884 Vali Loss: 0.1250029 Test Loss: 0.1484916\n",
      "Validation loss decreased (0.174379 --> 0.125003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1054350\n",
      "\tspeed: 0.1928s/iter; left time: 765.1359s\n",
      "\titers: 200, epoch: 3 | loss: 0.1015375\n",
      "\tspeed: 0.1122s/iter; left time: 434.0780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.1057259 Vali Loss: 0.1183407 Test Loss: 0.1421247\n",
      "Validation loss decreased (0.125003 --> 0.118341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0986338\n",
      "\tspeed: 0.1964s/iter; left time: 734.9835s\n",
      "\titers: 200, epoch: 4 | loss: 0.0996652\n",
      "\tspeed: 0.1122s/iter; left time: 408.6762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.1007814 Vali Loss: 0.1183927 Test Loss: 0.1391361\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0967652\n",
      "\tspeed: 0.1900s/iter; left time: 668.2372s\n",
      "\titers: 200, epoch: 5 | loss: 0.0957951\n",
      "\tspeed: 0.1122s/iter; left time: 383.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0975690 Vali Loss: 0.1172663 Test Loss: 0.1379602\n",
      "Validation loss decreased (0.118341 --> 0.117266).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0947265\n",
      "\tspeed: 0.1920s/iter; left time: 632.0270s\n",
      "\titers: 200, epoch: 6 | loss: 0.0955972\n",
      "\tspeed: 0.1122s/iter; left time: 358.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0954980 Vali Loss: 0.1166693 Test Loss: 0.1396021\n",
      "Validation loss decreased (0.117266 --> 0.116669).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966900\n",
      "\tspeed: 0.1927s/iter; left time: 590.5005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0932572\n",
      "\tspeed: 0.1125s/iter; left time: 333.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0936765 Vali Loss: 0.1181856 Test Loss: 0.1423536\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0923663\n",
      "\tspeed: 0.1898s/iter; left time: 538.9228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0860889\n",
      "\tspeed: 0.1122s/iter; left time: 307.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0921640 Vali Loss: 0.1192541 Test Loss: 0.1414095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0914591\n",
      "\tspeed: 0.1898s/iter; left time: 496.0572s\n",
      "\titers: 200, epoch: 9 | loss: 0.0894317\n",
      "\tspeed: 0.1125s/iter; left time: 282.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0910502 Vali Loss: 0.1149442 Test Loss: 0.1395827\n",
      "Validation loss decreased (0.116669 --> 0.114944).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0855014\n",
      "\tspeed: 0.1937s/iter; left time: 462.2677s\n",
      "\titers: 200, epoch: 10 | loss: 0.0920765\n",
      "\tspeed: 0.1122s/iter; left time: 256.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0892353 Vali Loss: 0.1182807 Test Loss: 0.1431123\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0844710\n",
      "\tspeed: 0.1899s/iter; left time: 410.2719s\n",
      "\titers: 200, epoch: 11 | loss: 0.0845457\n",
      "\tspeed: 0.1122s/iter; left time: 231.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0877197 Vali Loss: 0.1172992 Test Loss: 0.1437677\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0806815\n",
      "\tspeed: 0.1901s/iter; left time: 367.9191s\n",
      "\titers: 200, epoch: 12 | loss: 0.0905944\n",
      "\tspeed: 0.1122s/iter; left time: 205.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0864403 Vali Loss: 0.1171539 Test Loss: 0.1444073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0890732\n",
      "\tspeed: 0.1901s/iter; left time: 324.7989s\n",
      "\titers: 200, epoch: 13 | loss: 0.0822399\n",
      "\tspeed: 0.1122s/iter; left time: 180.5942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0852028 Vali Loss: 0.1184415 Test Loss: 0.1457959\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0848403\n",
      "\tspeed: 0.1895s/iter; left time: 281.0292s\n",
      "\titers: 200, epoch: 14 | loss: 0.0855197\n",
      "\tspeed: 0.1123s/iter; left time: 155.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0840288 Vali Loss: 0.1159585 Test Loss: 0.1468279\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04600006341934204, rmse:0.21447625756263733, mae:0.139682337641716, rse:0.739882230758667\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2193896\n",
      "\tspeed: 0.1139s/iter; left time: 503.6482s\n",
      "\titers: 200, epoch: 1 | loss: 0.1934575\n",
      "\tspeed: 0.1123s/iter; left time: 485.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.2303826 Vali Loss: 0.1662929 Test Loss: 0.1968722\n",
      "Validation loss decreased (inf --> 0.166293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1254788\n",
      "\tspeed: 0.1930s/iter; left time: 809.6567s\n",
      "\titers: 200, epoch: 2 | loss: 0.1128153\n",
      "\tspeed: 0.1123s/iter; left time: 459.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.1309536 Vali Loss: 0.1240434 Test Loss: 0.1481091\n",
      "Validation loss decreased (0.166293 --> 0.124043).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012105\n",
      "\tspeed: 0.1940s/iter; left time: 769.9193s\n",
      "\titers: 200, epoch: 3 | loss: 0.1047275\n",
      "\tspeed: 0.1126s/iter; left time: 435.6499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.1076930 Vali Loss: 0.1184705 Test Loss: 0.1402729\n",
      "Validation loss decreased (0.124043 --> 0.118471).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1022754\n",
      "\tspeed: 0.1927s/iter; left time: 721.3442s\n",
      "\titers: 200, epoch: 4 | loss: 0.0966415\n",
      "\tspeed: 0.1124s/iter; left time: 409.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.1015029 Vali Loss: 0.1147485 Test Loss: 0.1377604\n",
      "Validation loss decreased (0.118471 --> 0.114749).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971767\n",
      "\tspeed: 0.1927s/iter; left time: 677.7603s\n",
      "\titers: 200, epoch: 5 | loss: 0.0957458\n",
      "\tspeed: 0.1123s/iter; left time: 383.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0967063 Vali Loss: 0.1100944 Test Loss: 0.1312794\n",
      "Validation loss decreased (0.114749 --> 0.110094).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0880673\n",
      "\tspeed: 0.1934s/iter; left time: 636.5775s\n",
      "\titers: 200, epoch: 6 | loss: 0.0919940\n",
      "\tspeed: 0.1123s/iter; left time: 358.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0918146 Vali Loss: 0.1073192 Test Loss: 0.1287939\n",
      "Validation loss decreased (0.110094 --> 0.107319).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0935238\n",
      "\tspeed: 0.1933s/iter; left time: 592.5308s\n",
      "\titers: 200, epoch: 7 | loss: 0.0926752\n",
      "\tspeed: 0.1123s/iter; left time: 333.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0892842 Vali Loss: 0.1086044 Test Loss: 0.1300751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0836295\n",
      "\tspeed: 0.1896s/iter; left time: 538.3139s\n",
      "\titers: 200, epoch: 8 | loss: 0.0859569\n",
      "\tspeed: 0.1124s/iter; left time: 307.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0873452 Vali Loss: 0.1079380 Test Loss: 0.1297187\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0874717\n",
      "\tspeed: 0.1893s/iter; left time: 494.5131s\n",
      "\titers: 200, epoch: 9 | loss: 0.0816180\n",
      "\tspeed: 0.1123s/iter; left time: 282.2214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0854494 Vali Loss: 0.1072342 Test Loss: 0.1301723\n",
      "Validation loss decreased (0.107319 --> 0.107234).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0876025\n",
      "\tspeed: 0.1924s/iter; left time: 459.2220s\n",
      "\titers: 200, epoch: 10 | loss: 0.0833782\n",
      "\tspeed: 0.1124s/iter; left time: 257.1030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0842593 Vali Loss: 0.1076692 Test Loss: 0.1324313\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0848169\n",
      "\tspeed: 0.1897s/iter; left time: 410.0018s\n",
      "\titers: 200, epoch: 11 | loss: 0.0806803\n",
      "\tspeed: 0.1124s/iter; left time: 231.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0832437 Vali Loss: 0.1080078 Test Loss: 0.1320938\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0856877\n",
      "\tspeed: 0.1897s/iter; left time: 367.0959s\n",
      "\titers: 200, epoch: 12 | loss: 0.0777491\n",
      "\tspeed: 0.1124s/iter; left time: 206.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0814242 Vali Loss: 0.1073724 Test Loss: 0.1309949\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0796043\n",
      "\tspeed: 0.1894s/iter; left time: 323.6234s\n",
      "\titers: 200, epoch: 13 | loss: 0.0793273\n",
      "\tspeed: 0.1124s/iter; left time: 180.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0807663 Vali Loss: 0.1072600 Test Loss: 0.1308198\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0802366\n",
      "\tspeed: 0.1903s/iter; left time: 282.2760s\n",
      "\titers: 200, epoch: 14 | loss: 0.0829431\n",
      "\tspeed: 0.1124s/iter; left time: 155.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0797064 Vali Loss: 0.1066210 Test Loss: 0.1333030\n",
      "Validation loss decreased (0.107234 --> 0.106621).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0795321\n",
      "\tspeed: 0.1935s/iter; left time: 243.2000s\n",
      "\titers: 200, epoch: 15 | loss: 0.0806201\n",
      "\tspeed: 0.1123s/iter; left time: 129.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0785649 Vali Loss: 0.1083740 Test Loss: 0.1358389\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0773239\n",
      "\tspeed: 0.1898s/iter; left time: 195.6959s\n",
      "\titers: 200, epoch: 16 | loss: 0.0766614\n",
      "\tspeed: 0.1124s/iter; left time: 104.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0778532 Vali Loss: 0.1097599 Test Loss: 0.1367004\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0780512\n",
      "\tspeed: 0.1898s/iter; left time: 152.8232s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752735\n",
      "\tspeed: 0.1124s/iter; left time: 79.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0772947 Vali Loss: 0.1090261 Test Loss: 0.1354926\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735924\n",
      "\tspeed: 0.1904s/iter; left time: 110.2161s\n",
      "\titers: 200, epoch: 18 | loss: 0.0749041\n",
      "\tspeed: 0.1124s/iter; left time: 53.8597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0763322 Vali Loss: 0.1073350 Test Loss: 0.1349700\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0725113\n",
      "\tspeed: 0.1895s/iter; left time: 66.8819s\n",
      "\titers: 200, epoch: 19 | loss: 0.0775750\n",
      "\tspeed: 0.1125s/iter; left time: 28.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0758853 Vali Loss: 0.1075677 Test Loss: 0.1360825\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04164503514766693, rmse:0.20407114923000336, mae:0.1331600844860077, rse:0.7039876580238342\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:55.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2238629\n",
      "\tspeed: 0.1661s/iter; left time: 734.2280s\n",
      "\titers: 200, epoch: 1 | loss: 0.1958504\n",
      "\tspeed: 0.1443s/iter; left time: 623.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.21s\n",
      "Steps: 226 | Train Loss: 0.2234482 Vali Loss: 0.1858243 Test Loss: 0.2255981\n",
      "Validation loss decreased (inf --> 0.185824).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1430684\n",
      "\tspeed: 0.2468s/iter; left time: 1035.2573s\n",
      "\titers: 200, epoch: 2 | loss: 0.1378014\n",
      "\tspeed: 0.1446s/iter; left time: 592.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.1466986 Vali Loss: 0.1602261 Test Loss: 0.1912270\n",
      "Validation loss decreased (0.185824 --> 0.160226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1341400\n",
      "\tspeed: 0.2482s/iter; left time: 985.1738s\n",
      "\titers: 200, epoch: 3 | loss: 0.1299844\n",
      "\tspeed: 0.1444s/iter; left time: 558.5110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.1307636 Vali Loss: 0.1612609 Test Loss: 0.1884030\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1312211\n",
      "\tspeed: 0.2442s/iter; left time: 913.8774s\n",
      "\titers: 200, epoch: 4 | loss: 0.1249839\n",
      "\tspeed: 0.1445s/iter; left time: 526.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.1261911 Vali Loss: 0.1500473 Test Loss: 0.1832484\n",
      "Validation loss decreased (0.160226 --> 0.150047).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1260967\n",
      "\tspeed: 0.2486s/iter; left time: 874.2392s\n",
      "\titers: 200, epoch: 5 | loss: 0.1199230\n",
      "\tspeed: 0.1444s/iter; left time: 493.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.1221617 Vali Loss: 0.1500470 Test Loss: 0.1858057\n",
      "Validation loss decreased (0.150047 --> 0.150047).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1181421\n",
      "\tspeed: 0.2480s/iter; left time: 816.0647s\n",
      "\titers: 200, epoch: 6 | loss: 0.1134150\n",
      "\tspeed: 0.1444s/iter; left time: 460.8200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.1164105 Vali Loss: 0.1485244 Test Loss: 0.1841266\n",
      "Validation loss decreased (0.150047 --> 0.148524).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1094390\n",
      "\tspeed: 0.2481s/iter; left time: 760.3354s\n",
      "\titers: 200, epoch: 7 | loss: 0.1108442\n",
      "\tspeed: 0.1444s/iter; left time: 428.2711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.1125637 Vali Loss: 0.1456345 Test Loss: 0.1840697\n",
      "Validation loss decreased (0.148524 --> 0.145635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1078290\n",
      "\tspeed: 0.2497s/iter; left time: 708.7903s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070016\n",
      "\tspeed: 0.1448s/iter; left time: 396.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.1083516 Vali Loss: 0.1455905 Test Loss: 0.1870466\n",
      "Validation loss decreased (0.145635 --> 0.145591).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036594\n",
      "\tspeed: 0.2504s/iter; left time: 654.3976s\n",
      "\titers: 200, epoch: 9 | loss: 0.1041176\n",
      "\tspeed: 0.1445s/iter; left time: 363.0664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1045232 Vali Loss: 0.1466166 Test Loss: 0.1896266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1046838\n",
      "\tspeed: 0.2467s/iter; left time: 588.7744s\n",
      "\titers: 200, epoch: 10 | loss: 0.1023012\n",
      "\tspeed: 0.1446s/iter; left time: 330.7975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:33.01s\n",
      "Steps: 226 | Train Loss: 0.1019777 Vali Loss: 0.1496410 Test Loss: 0.1921727\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1015530\n",
      "\tspeed: 0.2458s/iter; left time: 531.1624s\n",
      "\titers: 200, epoch: 11 | loss: 0.0958896\n",
      "\tspeed: 0.1445s/iter; left time: 297.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0990357 Vali Loss: 0.1459045 Test Loss: 0.1929539\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0999461\n",
      "\tspeed: 0.2459s/iter; left time: 475.7412s\n",
      "\titers: 200, epoch: 12 | loss: 0.0958294\n",
      "\tspeed: 0.1444s/iter; left time: 265.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.0966783 Vali Loss: 0.1468442 Test Loss: 0.1918766\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0948578\n",
      "\tspeed: 0.2454s/iter; left time: 419.4360s\n",
      "\titers: 200, epoch: 13 | loss: 0.0914848\n",
      "\tspeed: 0.1445s/iter; left time: 232.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0947767 Vali Loss: 0.1458371 Test Loss: 0.1945366\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07166936993598938, rmse:0.267711341381073, mae:0.18716973066329956, rse:0.9257831573486328\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2183826\n",
      "\tspeed: 0.1458s/iter; left time: 644.5953s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020140\n",
      "\tspeed: 0.1444s/iter; left time: 623.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.2277266 Vali Loss: 0.1892433 Test Loss: 0.2248690\n",
      "Validation loss decreased (inf --> 0.189243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1491035\n",
      "\tspeed: 0.2479s/iter; left time: 1039.9448s\n",
      "\titers: 200, epoch: 2 | loss: 0.1348036\n",
      "\tspeed: 0.1444s/iter; left time: 591.1808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.1484987 Vali Loss: 0.1535256 Test Loss: 0.1856820\n",
      "Validation loss decreased (0.189243 --> 0.153526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1371690\n",
      "\tspeed: 0.2478s/iter; left time: 983.6247s\n",
      "\titers: 200, epoch: 3 | loss: 0.1320887\n",
      "\tspeed: 0.1444s/iter; left time: 558.5359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.1309394 Vali Loss: 0.1547394 Test Loss: 0.1880667\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1271537\n",
      "\tspeed: 0.2464s/iter; left time: 922.1520s\n",
      "\titers: 200, epoch: 4 | loss: 0.1199556\n",
      "\tspeed: 0.1446s/iter; left time: 526.9149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1261665 Vali Loss: 0.1552638 Test Loss: 0.1872851\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1201052\n",
      "\tspeed: 0.2453s/iter; left time: 862.6743s\n",
      "\titers: 200, epoch: 5 | loss: 0.1219731\n",
      "\tspeed: 0.1443s/iter; left time: 493.1771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.1221180 Vali Loss: 0.1518034 Test Loss: 0.1844833\n",
      "Validation loss decreased (0.153526 --> 0.151803).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1240521\n",
      "\tspeed: 0.2485s/iter; left time: 817.6745s\n",
      "\titers: 200, epoch: 6 | loss: 0.1176639\n",
      "\tspeed: 0.1444s/iter; left time: 460.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.1188537 Vali Loss: 0.1531626 Test Loss: 0.1890292\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1175372\n",
      "\tspeed: 0.2454s/iter; left time: 752.0408s\n",
      "\titers: 200, epoch: 7 | loss: 0.1136834\n",
      "\tspeed: 0.1444s/iter; left time: 428.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.1149721 Vali Loss: 0.1498849 Test Loss: 0.1853527\n",
      "Validation loss decreased (0.151803 --> 0.149885).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1092652\n",
      "\tspeed: 0.2508s/iter; left time: 711.9815s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080554\n",
      "\tspeed: 0.1446s/iter; left time: 396.1458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1116165 Vali Loss: 0.1498581 Test Loss: 0.1834989\n",
      "Validation loss decreased (0.149885 --> 0.149858).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1113360\n",
      "\tspeed: 0.2485s/iter; left time: 649.3531s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069125\n",
      "\tspeed: 0.1443s/iter; left time: 362.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.1085205 Vali Loss: 0.1510564 Test Loss: 0.1860071\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1052752\n",
      "\tspeed: 0.2444s/iter; left time: 583.2712s\n",
      "\titers: 200, epoch: 10 | loss: 0.1015141\n",
      "\tspeed: 0.1444s/iter; left time: 330.1340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 226 | Train Loss: 0.1062149 Vali Loss: 0.1511716 Test Loss: 0.1872465\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1023754\n",
      "\tspeed: 0.2439s/iter; left time: 527.0142s\n",
      "\titers: 200, epoch: 11 | loss: 0.1045102\n",
      "\tspeed: 0.1444s/iter; left time: 297.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.1040619 Vali Loss: 0.1499207 Test Loss: 0.1856009\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1028014\n",
      "\tspeed: 0.2446s/iter; left time: 473.3889s\n",
      "\titers: 200, epoch: 12 | loss: 0.1036815\n",
      "\tspeed: 0.1444s/iter; left time: 264.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.1021957 Vali Loss: 0.1512486 Test Loss: 0.1861949\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0967871\n",
      "\tspeed: 0.2444s/iter; left time: 417.7295s\n",
      "\titers: 200, epoch: 13 | loss: 0.0996229\n",
      "\tspeed: 0.1445s/iter; left time: 232.4489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.1002278 Vali Loss: 0.1521056 Test Loss: 0.1871409\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07038446515798569, rmse:0.2653007209300995, mae:0.18352794647216797, rse:0.9174467921257019\n",
      "Intermediate time for GB and pred_len 96: 00h:17m:13.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2159002\n",
      "\tspeed: 0.1994s/iter; left time: 877.4377s\n",
      "\titers: 200, epoch: 1 | loss: 0.1986141\n",
      "\tspeed: 0.1785s/iter; left time: 767.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.72s\n",
      "Steps: 225 | Train Loss: 0.2247221 Vali Loss: 0.1882368 Test Loss: 0.2260828\n",
      "Validation loss decreased (inf --> 0.188237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1476269\n",
      "\tspeed: 0.3030s/iter; left time: 1265.1272s\n",
      "\titers: 200, epoch: 2 | loss: 0.1441675\n",
      "\tspeed: 0.1786s/iter; left time: 728.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.1514320 Vali Loss: 0.1622087 Test Loss: 0.1935603\n",
      "Validation loss decreased (0.188237 --> 0.162209).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1379481\n",
      "\tspeed: 0.3035s/iter; left time: 1199.1663s\n",
      "\titers: 200, epoch: 3 | loss: 0.1332985\n",
      "\tspeed: 0.1787s/iter; left time: 688.3323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.1361740 Vali Loss: 0.1637390 Test Loss: 0.1972875\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1347992\n",
      "\tspeed: 0.3006s/iter; left time: 1119.9190s\n",
      "\titers: 200, epoch: 4 | loss: 0.1270159\n",
      "\tspeed: 0.1787s/iter; left time: 647.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.1313482 Vali Loss: 0.1584908 Test Loss: 0.2005078\n",
      "Validation loss decreased (0.162209 --> 0.158491).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1304250\n",
      "\tspeed: 0.3063s/iter; left time: 1072.5224s\n",
      "\titers: 200, epoch: 5 | loss: 0.1243523\n",
      "\tspeed: 0.1787s/iter; left time: 607.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.1270421 Vali Loss: 0.1595552 Test Loss: 0.1984215\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1294963\n",
      "\tspeed: 0.3005s/iter; left time: 984.3471s\n",
      "\titers: 200, epoch: 6 | loss: 0.1209783\n",
      "\tspeed: 0.1788s/iter; left time: 567.7531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.1240842 Vali Loss: 0.1588282 Test Loss: 0.1974621\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1194447\n",
      "\tspeed: 0.3023s/iter; left time: 922.3516s\n",
      "\titers: 200, epoch: 7 | loss: 0.1214674\n",
      "\tspeed: 0.1787s/iter; left time: 527.4600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.57s\n",
      "Steps: 225 | Train Loss: 0.1208904 Vali Loss: 0.1568197 Test Loss: 0.1980545\n",
      "Validation loss decreased (0.158491 --> 0.156820).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1203558\n",
      "\tspeed: 0.3042s/iter; left time: 859.6830s\n",
      "\titers: 200, epoch: 8 | loss: 0.1145267\n",
      "\tspeed: 0.1788s/iter; left time: 487.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.1179926 Vali Loss: 0.1589442 Test Loss: 0.2032792\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1157924\n",
      "\tspeed: 0.3009s/iter; left time: 782.5150s\n",
      "\titers: 200, epoch: 9 | loss: 0.1133235\n",
      "\tspeed: 0.1787s/iter; left time: 447.0303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.1153288 Vali Loss: 0.1575831 Test Loss: 0.2010307\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1078079\n",
      "\tspeed: 0.3004s/iter; left time: 713.8058s\n",
      "\titers: 200, epoch: 10 | loss: 0.1103943\n",
      "\tspeed: 0.1789s/iter; left time: 407.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.1126977 Vali Loss: 0.1571033 Test Loss: 0.1988666\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1103964\n",
      "\tspeed: 0.3008s/iter; left time: 647.0698s\n",
      "\titers: 200, epoch: 11 | loss: 0.1117498\n",
      "\tspeed: 0.1788s/iter; left time: 366.7000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.1110473 Vali Loss: 0.1596651 Test Loss: 0.2035334\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1097977\n",
      "\tspeed: 0.3005s/iter; left time: 578.8344s\n",
      "\titers: 200, epoch: 12 | loss: 0.1095079\n",
      "\tspeed: 0.1789s/iter; left time: 326.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.1092791 Vali Loss: 0.1575170 Test Loss: 0.2006056\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07857304066419601, rmse:0.2803088426589966, mae:0.19801437854766846, rse:0.9718709588050842\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2155378\n",
      "\tspeed: 0.1819s/iter; left time: 800.7441s\n",
      "\titers: 200, epoch: 1 | loss: 0.2050767\n",
      "\tspeed: 0.1791s/iter; left time: 770.1467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 225 | Train Loss: 0.2233378 Vali Loss: 0.1949797 Test Loss: 0.2335735\n",
      "Validation loss decreased (inf --> 0.194980).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1479031\n",
      "\tspeed: 0.3068s/iter; left time: 1281.2460s\n",
      "\titers: 200, epoch: 2 | loss: 0.1419174\n",
      "\tspeed: 0.1790s/iter; left time: 729.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.1528341 Vali Loss: 0.1793903 Test Loss: 0.2105577\n",
      "Validation loss decreased (0.194980 --> 0.179390).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1362086\n",
      "\tspeed: 0.3039s/iter; left time: 1200.8060s\n",
      "\titers: 200, epoch: 3 | loss: 0.1374668\n",
      "\tspeed: 0.1791s/iter; left time: 689.8681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.1364735 Vali Loss: 0.1616995 Test Loss: 0.1990301\n",
      "Validation loss decreased (0.179390 --> 0.161699).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1337128\n",
      "\tspeed: 0.3037s/iter; left time: 1131.4870s\n",
      "\titers: 200, epoch: 4 | loss: 0.1286715\n",
      "\tspeed: 0.1791s/iter; left time: 649.5072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.55s\n",
      "Steps: 225 | Train Loss: 0.1317416 Vali Loss: 0.1600480 Test Loss: 0.1990461\n",
      "Validation loss decreased (0.161699 --> 0.160048).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1282063\n",
      "\tspeed: 0.3041s/iter; left time: 1064.7933s\n",
      "\titers: 200, epoch: 5 | loss: 0.1276506\n",
      "\tspeed: 0.1792s/iter; left time: 609.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.1272880 Vali Loss: 0.1574882 Test Loss: 0.1957782\n",
      "Validation loss decreased (0.160048 --> 0.157488).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1235778\n",
      "\tspeed: 0.3049s/iter; left time: 998.7282s\n",
      "\titers: 200, epoch: 6 | loss: 0.1220635\n",
      "\tspeed: 0.1792s/iter; left time: 568.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 225 | Train Loss: 0.1240694 Vali Loss: 0.1582096 Test Loss: 0.1963154\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1187624\n",
      "\tspeed: 0.3016s/iter; left time: 920.2016s\n",
      "\titers: 200, epoch: 7 | loss: 0.1208037\n",
      "\tspeed: 0.1792s/iter; left time: 528.7450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.57s\n",
      "Steps: 225 | Train Loss: 0.1205111 Vali Loss: 0.1583816 Test Loss: 0.1928487\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1123908\n",
      "\tspeed: 0.3019s/iter; left time: 853.2024s\n",
      "\titers: 200, epoch: 8 | loss: 0.1156810\n",
      "\tspeed: 0.1791s/iter; left time: 488.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.62s\n",
      "Steps: 225 | Train Loss: 0.1153876 Vali Loss: 0.1518709 Test Loss: 0.1895281\n",
      "Validation loss decreased (0.157488 --> 0.151871).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1090135\n",
      "\tspeed: 0.3051s/iter; left time: 793.5019s\n",
      "\titers: 200, epoch: 9 | loss: 0.1072715\n",
      "\tspeed: 0.1791s/iter; left time: 448.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.60s\n",
      "Steps: 225 | Train Loss: 0.1087301 Vali Loss: 0.1484658 Test Loss: 0.1876024\n",
      "Validation loss decreased (0.151871 --> 0.148466).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1040497\n",
      "\tspeed: 0.3045s/iter; left time: 723.3914s\n",
      "\titers: 200, epoch: 10 | loss: 0.1040761\n",
      "\tspeed: 0.1791s/iter; left time: 407.6893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.57s\n",
      "Steps: 225 | Train Loss: 0.1050111 Vali Loss: 0.1484712 Test Loss: 0.1888300\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1015193\n",
      "\tspeed: 0.3024s/iter; left time: 650.4653s\n",
      "\titers: 200, epoch: 11 | loss: 0.1022227\n",
      "\tspeed: 0.1791s/iter; left time: 367.3024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.60s\n",
      "Steps: 225 | Train Loss: 0.1020768 Vali Loss: 0.1478909 Test Loss: 0.1875359\n",
      "Validation loss decreased (0.148466 --> 0.147891).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0979403\n",
      "\tspeed: 0.3045s/iter; left time: 586.5459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0986980\n",
      "\tspeed: 0.1792s/iter; left time: 327.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.59s\n",
      "Steps: 225 | Train Loss: 0.0997274 Vali Loss: 0.1465068 Test Loss: 0.1861825\n",
      "Validation loss decreased (0.147891 --> 0.146507).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988221\n",
      "\tspeed: 0.3048s/iter; left time: 518.4256s\n",
      "\titers: 200, epoch: 13 | loss: 0.0978258\n",
      "\tspeed: 0.1792s/iter; left time: 286.9067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.0974631 Vali Loss: 0.1455918 Test Loss: 0.1851215\n",
      "Validation loss decreased (0.146507 --> 0.145592).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0945356\n",
      "\tspeed: 0.3048s/iter; left time: 449.8639s\n",
      "\titers: 200, epoch: 14 | loss: 0.0947730\n",
      "\tspeed: 0.1792s/iter; left time: 246.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.0947293 Vali Loss: 0.1439406 Test Loss: 0.1850051\n",
      "Validation loss decreased (0.145592 --> 0.143941).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0898347\n",
      "\tspeed: 0.3050s/iter; left time: 381.5056s\n",
      "\titers: 200, epoch: 15 | loss: 0.0902708\n",
      "\tspeed: 0.1792s/iter; left time: 206.2938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.61s\n",
      "Steps: 225 | Train Loss: 0.0916819 Vali Loss: 0.1419794 Test Loss: 0.1838967\n",
      "Validation loss decreased (0.143941 --> 0.141979).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0854881\n",
      "\tspeed: 0.3069s/iter; left time: 314.9196s\n",
      "\titers: 200, epoch: 16 | loss: 0.0888650\n",
      "\tspeed: 0.1793s/iter; left time: 166.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.65s\n",
      "Steps: 225 | Train Loss: 0.0886635 Vali Loss: 0.1387267 Test Loss: 0.1792703\n",
      "Validation loss decreased (0.141979 --> 0.138727).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0864816\n",
      "\tspeed: 0.3054s/iter; left time: 244.6484s\n",
      "\titers: 200, epoch: 17 | loss: 0.0863989\n",
      "\tspeed: 0.1794s/iter; left time: 125.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 225 | Train Loss: 0.0857787 Vali Loss: 0.1361548 Test Loss: 0.1761749\n",
      "Validation loss decreased (0.138727 --> 0.136155).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0820943\n",
      "\tspeed: 0.3053s/iter; left time: 175.8262s\n",
      "\titers: 200, epoch: 18 | loss: 0.0838346\n",
      "\tspeed: 0.1792s/iter; left time: 85.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.65s\n",
      "Steps: 225 | Train Loss: 0.0836893 Vali Loss: 0.1386315 Test Loss: 0.1789000\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0806458\n",
      "\tspeed: 0.3021s/iter; left time: 106.0258s\n",
      "\titers: 200, epoch: 19 | loss: 0.0829432\n",
      "\tspeed: 0.1793s/iter; left time: 44.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 225 | Train Loss: 0.0823610 Vali Loss: 0.1366859 Test Loss: 0.1768816\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0813951\n",
      "\tspeed: 0.3018s/iter; left time: 38.0265s\n",
      "\titers: 200, epoch: 20 | loss: 0.0820269\n",
      "\tspeed: 0.1793s/iter; left time: 4.6607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:40.57s\n",
      "Steps: 225 | Train Loss: 0.0814273 Vali Loss: 0.1371977 Test Loss: 0.1775841\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0663556382060051, rmse:0.25759586691856384, mae:0.17620733380317688, rse:0.8931218385696411\n",
      "Intermediate time for GB and pred_len 168: 00h:26m:00.29s\n",
      "Intermediate time for GB: 01h:00m:09.06s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2164556\n",
      "\tspeed: 0.1345s/iter; left time: 594.5452s\n",
      "\titers: 200, epoch: 1 | loss: 0.2010650\n",
      "\tspeed: 0.1118s/iter; left time: 482.9395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.87s\n",
      "Steps: 226 | Train Loss: 0.2254029 Vali Loss: 0.1688436 Test Loss: 0.2138903\n",
      "Validation loss decreased (inf --> 0.168844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1137506\n",
      "\tspeed: 0.1922s/iter; left time: 806.1573s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912588\n",
      "\tspeed: 0.1119s/iter; left time: 458.0268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.1158457 Vali Loss: 0.0860857 Test Loss: 0.1086149\n",
      "Validation loss decreased (0.168844 --> 0.086086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0858010\n",
      "\tspeed: 0.1957s/iter; left time: 776.6803s\n",
      "\titers: 200, epoch: 3 | loss: 0.0785745\n",
      "\tspeed: 0.1120s/iter; left time: 433.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0837454 Vali Loss: 0.0816503 Test Loss: 0.0973666\n",
      "Validation loss decreased (0.086086 --> 0.081650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0722165\n",
      "\tspeed: 0.1922s/iter; left time: 719.4892s\n",
      "\titers: 200, epoch: 4 | loss: 0.0708162\n",
      "\tspeed: 0.1119s/iter; left time: 407.5553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.53s\n",
      "Steps: 226 | Train Loss: 0.0748156 Vali Loss: 0.0735722 Test Loss: 0.0985650\n",
      "Validation loss decreased (0.081650 --> 0.073572).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0723310\n",
      "\tspeed: 0.1915s/iter; left time: 673.5876s\n",
      "\titers: 200, epoch: 5 | loss: 0.0725993\n",
      "\tspeed: 0.1120s/iter; left time: 382.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0701475 Vali Loss: 0.0694135 Test Loss: 0.0940425\n",
      "Validation loss decreased (0.073572 --> 0.069414).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0635539\n",
      "\tspeed: 0.1925s/iter; left time: 633.6230s\n",
      "\titers: 200, epoch: 6 | loss: 0.0681299\n",
      "\tspeed: 0.1120s/iter; left time: 357.2921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 226 | Train Loss: 0.0666852 Vali Loss: 0.0672942 Test Loss: 0.0895945\n",
      "Validation loss decreased (0.069414 --> 0.067294).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0663689\n",
      "\tspeed: 0.1949s/iter; left time: 597.4235s\n",
      "\titers: 200, epoch: 7 | loss: 0.0640718\n",
      "\tspeed: 0.1119s/iter; left time: 331.8362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 226 | Train Loss: 0.0646382 Vali Loss: 0.0656380 Test Loss: 0.0903824\n",
      "Validation loss decreased (0.067294 --> 0.065638).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0626805\n",
      "\tspeed: 0.1925s/iter; left time: 546.5416s\n",
      "\titers: 200, epoch: 8 | loss: 0.0619397\n",
      "\tspeed: 0.1119s/iter; left time: 306.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 226 | Train Loss: 0.0626823 Vali Loss: 0.0652926 Test Loss: 0.0915619\n",
      "Validation loss decreased (0.065638 --> 0.065293).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0643526\n",
      "\tspeed: 0.1957s/iter; left time: 511.3488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0606059\n",
      "\tspeed: 0.1122s/iter; left time: 282.0480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0615986 Vali Loss: 0.0633955 Test Loss: 0.0903748\n",
      "Validation loss decreased (0.065293 --> 0.063396).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0610415\n",
      "\tspeed: 0.1924s/iter; left time: 459.1694s\n",
      "\titers: 200, epoch: 10 | loss: 0.0610328\n",
      "\tspeed: 0.1120s/iter; left time: 256.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0605227 Vali Loss: 0.0614202 Test Loss: 0.0894707\n",
      "Validation loss decreased (0.063396 --> 0.061420).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0587717\n",
      "\tspeed: 0.1921s/iter; left time: 415.0826s\n",
      "\titers: 200, epoch: 11 | loss: 0.0598158\n",
      "\tspeed: 0.1122s/iter; left time: 231.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0593063 Vali Loss: 0.0618221 Test Loss: 0.0863012\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553136\n",
      "\tspeed: 0.1893s/iter; left time: 366.2622s\n",
      "\titers: 200, epoch: 12 | loss: 0.0580855\n",
      "\tspeed: 0.1123s/iter; left time: 205.9981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0586015 Vali Loss: 0.0614711 Test Loss: 0.0899177\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0597154\n",
      "\tspeed: 0.1903s/iter; left time: 325.2114s\n",
      "\titers: 200, epoch: 13 | loss: 0.0586086\n",
      "\tspeed: 0.1123s/iter; left time: 180.6845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0580896 Vali Loss: 0.0615674 Test Loss: 0.0915181\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0545680\n",
      "\tspeed: 0.1898s/iter; left time: 281.4923s\n",
      "\titers: 200, epoch: 14 | loss: 0.0548207\n",
      "\tspeed: 0.1122s/iter; left time: 155.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 226 | Train Loss: 0.0573289 Vali Loss: 0.0608425 Test Loss: 0.0862274\n",
      "Validation loss decreased (0.061420 --> 0.060842).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0554201\n",
      "\tspeed: 0.1928s/iter; left time: 242.2882s\n",
      "\titers: 200, epoch: 15 | loss: 0.0595716\n",
      "\tspeed: 0.1120s/iter; left time: 129.5900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 226 | Train Loss: 0.0566450 Vali Loss: 0.0604291 Test Loss: 0.0889126\n",
      "Validation loss decreased (0.060842 --> 0.060429).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0544598\n",
      "\tspeed: 0.1929s/iter; left time: 198.8881s\n",
      "\titers: 200, epoch: 16 | loss: 0.0557508\n",
      "\tspeed: 0.1122s/iter; left time: 104.4517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0560623 Vali Loss: 0.0591254 Test Loss: 0.0871587\n",
      "Validation loss decreased (0.060429 --> 0.059125).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0580888\n",
      "\tspeed: 0.1930s/iter; left time: 155.3383s\n",
      "\titers: 200, epoch: 17 | loss: 0.0535822\n",
      "\tspeed: 0.1121s/iter; left time: 79.0235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0554195 Vali Loss: 0.0591436 Test Loss: 0.0870469\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0539827\n",
      "\tspeed: 0.1893s/iter; left time: 109.6272s\n",
      "\titers: 200, epoch: 18 | loss: 0.0543762\n",
      "\tspeed: 0.1122s/iter; left time: 53.7319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0550340 Vali Loss: 0.0592445 Test Loss: 0.0874328\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0547189\n",
      "\tspeed: 0.1893s/iter; left time: 66.8320s\n",
      "\titers: 200, epoch: 19 | loss: 0.0505433\n",
      "\tspeed: 0.1123s/iter; left time: 28.3993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0545409 Vali Loss: 0.0585384 Test Loss: 0.0848401\n",
      "Validation loss decreased (0.059125 --> 0.058538).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0511566\n",
      "\tspeed: 0.1926s/iter; left time: 24.4655s\n",
      "\titers: 200, epoch: 20 | loss: 0.0539951\n",
      "\tspeed: 0.1123s/iter; left time: 3.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0542110 Vali Loss: 0.0591295 Test Loss: 0.0891810\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01995997130870819, rmse:0.14127975702285767, mae:0.0851166620850563, rse:0.4157692492008209\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2317054\n",
      "\tspeed: 0.1166s/iter; left time: 515.5740s\n",
      "\titers: 200, epoch: 1 | loss: 0.1997255\n",
      "\tspeed: 0.1121s/iter; left time: 484.2193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 226 | Train Loss: 0.2376139 Vali Loss: 0.1683591 Test Loss: 0.2090721\n",
      "Validation loss decreased (inf --> 0.168359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1022155\n",
      "\tspeed: 0.1936s/iter; left time: 812.0445s\n",
      "\titers: 200, epoch: 2 | loss: 0.0927430\n",
      "\tspeed: 0.1121s/iter; left time: 459.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.1144977 Vali Loss: 0.0829197 Test Loss: 0.1092220\n",
      "Validation loss decreased (0.168359 --> 0.082920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0826994\n",
      "\tspeed: 0.1943s/iter; left time: 771.2777s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896373\n",
      "\tspeed: 0.1122s/iter; left time: 434.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0829902 Vali Loss: 0.0751408 Test Loss: 0.1035900\n",
      "Validation loss decreased (0.082920 --> 0.075141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0739515\n",
      "\tspeed: 0.1931s/iter; left time: 722.9492s\n",
      "\titers: 200, epoch: 4 | loss: 0.0723798\n",
      "\tspeed: 0.1122s/iter; left time: 408.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0735294 Vali Loss: 0.0695670 Test Loss: 0.1005925\n",
      "Validation loss decreased (0.075141 --> 0.069567).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0727702\n",
      "\tspeed: 0.1925s/iter; left time: 677.1660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0673773\n",
      "\tspeed: 0.1121s/iter; left time: 383.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0694308 Vali Loss: 0.0670344 Test Loss: 0.0935458\n",
      "Validation loss decreased (0.069567 --> 0.067034).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0679884\n",
      "\tspeed: 0.1928s/iter; left time: 634.6565s\n",
      "\titers: 200, epoch: 6 | loss: 0.0660580\n",
      "\tspeed: 0.1122s/iter; left time: 357.9747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0672520 Vali Loss: 0.0667096 Test Loss: 0.0932762\n",
      "Validation loss decreased (0.067034 --> 0.066710).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0658965\n",
      "\tspeed: 0.1922s/iter; left time: 588.9700s\n",
      "\titers: 200, epoch: 7 | loss: 0.0643685\n",
      "\tspeed: 0.1121s/iter; left time: 332.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0653484 Vali Loss: 0.0659476 Test Loss: 0.0952963\n",
      "Validation loss decreased (0.066710 --> 0.065948).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0630611\n",
      "\tspeed: 0.1922s/iter; left time: 545.5195s\n",
      "\titers: 200, epoch: 8 | loss: 0.0667156\n",
      "\tspeed: 0.1121s/iter; left time: 307.1103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0634143 Vali Loss: 0.0655213 Test Loss: 0.0901632\n",
      "Validation loss decreased (0.065948 --> 0.065521).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0629159\n",
      "\tspeed: 0.1922s/iter; left time: 502.2862s\n",
      "\titers: 200, epoch: 9 | loss: 0.0650493\n",
      "\tspeed: 0.1121s/iter; left time: 281.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0620028 Vali Loss: 0.0639534 Test Loss: 0.0892703\n",
      "Validation loss decreased (0.065521 --> 0.063953).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0604586\n",
      "\tspeed: 0.1924s/iter; left time: 459.3764s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569845\n",
      "\tspeed: 0.1121s/iter; left time: 256.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0613309 Vali Loss: 0.0656653 Test Loss: 0.0925255\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0620295\n",
      "\tspeed: 0.1898s/iter; left time: 410.1422s\n",
      "\titers: 200, epoch: 11 | loss: 0.0617635\n",
      "\tspeed: 0.1121s/iter; left time: 231.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0603377 Vali Loss: 0.0620826 Test Loss: 0.0912801\n",
      "Validation loss decreased (0.063953 --> 0.062083).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0600221\n",
      "\tspeed: 0.1929s/iter; left time: 373.2506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0646833\n",
      "\tspeed: 0.1124s/iter; left time: 206.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0594560 Vali Loss: 0.0611782 Test Loss: 0.0897158\n",
      "Validation loss decreased (0.062083 --> 0.061178).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0591026\n",
      "\tspeed: 0.1929s/iter; left time: 329.6948s\n",
      "\titers: 200, epoch: 13 | loss: 0.0587049\n",
      "\tspeed: 0.1123s/iter; left time: 180.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0587314 Vali Loss: 0.0621077 Test Loss: 0.0922790\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0587336\n",
      "\tspeed: 0.1895s/iter; left time: 281.0622s\n",
      "\titers: 200, epoch: 14 | loss: 0.0593806\n",
      "\tspeed: 0.1122s/iter; left time: 155.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0581712 Vali Loss: 0.0599925 Test Loss: 0.0875275\n",
      "Validation loss decreased (0.061178 --> 0.059992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0571937\n",
      "\tspeed: 0.1929s/iter; left time: 242.4853s\n",
      "\titers: 200, epoch: 15 | loss: 0.0550991\n",
      "\tspeed: 0.1123s/iter; left time: 129.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0576492 Vali Loss: 0.0606094 Test Loss: 0.0852740\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0582823\n",
      "\tspeed: 0.1897s/iter; left time: 195.5836s\n",
      "\titers: 200, epoch: 16 | loss: 0.0552116\n",
      "\tspeed: 0.1123s/iter; left time: 104.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0567717 Vali Loss: 0.0598725 Test Loss: 0.0879443\n",
      "Validation loss decreased (0.059992 --> 0.059873).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0551515\n",
      "\tspeed: 0.1943s/iter; left time: 156.3775s\n",
      "\titers: 200, epoch: 17 | loss: 0.0560318\n",
      "\tspeed: 0.1123s/iter; left time: 79.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0564023 Vali Loss: 0.0590683 Test Loss: 0.0893493\n",
      "Validation loss decreased (0.059873 --> 0.059068).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0524824\n",
      "\tspeed: 0.1932s/iter; left time: 111.8612s\n",
      "\titers: 200, epoch: 18 | loss: 0.0548655\n",
      "\tspeed: 0.1121s/iter; left time: 53.7053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0564808 Vali Loss: 0.0593738 Test Loss: 0.0868338\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0557627\n",
      "\tspeed: 0.1890s/iter; left time: 66.7272s\n",
      "\titers: 200, epoch: 19 | loss: 0.0545528\n",
      "\tspeed: 0.1121s/iter; left time: 28.3590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 226 | Train Loss: 0.0554372 Vali Loss: 0.0586545 Test Loss: 0.0880507\n",
      "Validation loss decreased (0.059068 --> 0.058654).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0543051\n",
      "\tspeed: 0.1920s/iter; left time: 24.3839s\n",
      "\titers: 200, epoch: 20 | loss: 0.0534533\n",
      "\tspeed: 0.1121s/iter; left time: 3.0271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0550184 Vali Loss: 0.0583314 Test Loss: 0.0860947\n",
      "Validation loss decreased (0.058654 --> 0.058331).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0205184668302536, rmse:0.14324268698692322, mae:0.08598485589027405, rse:0.4215458929538727\n",
      "Intermediate time for ES and pred_len 24: 00h:20m:30.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2386744\n",
      "\tspeed: 0.1653s/iter; left time: 730.6284s\n",
      "\titers: 200, epoch: 1 | loss: 0.2154501\n",
      "\tspeed: 0.1441s/iter; left time: 622.6008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.14s\n",
      "Steps: 226 | Train Loss: 0.2388595 Vali Loss: 0.2051802 Test Loss: 0.2512444\n",
      "Validation loss decreased (inf --> 0.205180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1438882\n",
      "\tspeed: 0.2469s/iter; left time: 1035.8916s\n",
      "\titers: 200, epoch: 2 | loss: 0.1319930\n",
      "\tspeed: 0.1443s/iter; left time: 591.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.1508937 Vali Loss: 0.1337660 Test Loss: 0.1722258\n",
      "Validation loss decreased (0.205180 --> 0.133766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1185326\n",
      "\tspeed: 0.2466s/iter; left time: 978.9454s\n",
      "\titers: 200, epoch: 3 | loss: 0.1055847\n",
      "\tspeed: 0.1443s/iter; left time: 558.3098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.1140689 Vali Loss: 0.1034260 Test Loss: 0.1380991\n",
      "Validation loss decreased (0.133766 --> 0.103426).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1007278\n",
      "\tspeed: 0.2467s/iter; left time: 923.3018s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939828\n",
      "\tspeed: 0.1444s/iter; left time: 526.0400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0974034 Vali Loss: 0.0950149 Test Loss: 0.1345967\n",
      "Validation loss decreased (0.103426 --> 0.095015).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0928005\n",
      "\tspeed: 0.2480s/iter; left time: 872.2375s\n",
      "\titers: 200, epoch: 5 | loss: 0.0880634\n",
      "\tspeed: 0.1444s/iter; left time: 493.3206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0914755 Vali Loss: 0.0922461 Test Loss: 0.1396674\n",
      "Validation loss decreased (0.095015 --> 0.092246).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861439\n",
      "\tspeed: 0.2470s/iter; left time: 812.7774s\n",
      "\titers: 200, epoch: 6 | loss: 0.0839831\n",
      "\tspeed: 0.1444s/iter; left time: 460.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.86s\n",
      "Steps: 226 | Train Loss: 0.0882940 Vali Loss: 0.0910260 Test Loss: 0.1306770\n",
      "Validation loss decreased (0.092246 --> 0.091026).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0868780\n",
      "\tspeed: 0.2477s/iter; left time: 759.1894s\n",
      "\titers: 200, epoch: 7 | loss: 0.0867847\n",
      "\tspeed: 0.1445s/iter; left time: 428.3519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0858758 Vali Loss: 0.0893660 Test Loss: 0.1318837\n",
      "Validation loss decreased (0.091026 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0809824\n",
      "\tspeed: 0.2473s/iter; left time: 702.2155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0839557\n",
      "\tspeed: 0.1444s/iter; left time: 395.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0843138 Vali Loss: 0.0878613 Test Loss: 0.1283448\n",
      "Validation loss decreased (0.089366 --> 0.087861).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0838818\n",
      "\tspeed: 0.2468s/iter; left time: 644.8648s\n",
      "\titers: 200, epoch: 9 | loss: 0.0814285\n",
      "\tspeed: 0.1444s/iter; left time: 362.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0826800 Vali Loss: 0.0878250 Test Loss: 0.1300548\n",
      "Validation loss decreased (0.087861 --> 0.087825).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0796342\n",
      "\tspeed: 0.2466s/iter; left time: 588.6050s\n",
      "\titers: 200, epoch: 10 | loss: 0.0818929\n",
      "\tspeed: 0.1444s/iter; left time: 330.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0809772 Vali Loss: 0.0880182 Test Loss: 0.1364100\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784439\n",
      "\tspeed: 0.2431s/iter; left time: 525.2342s\n",
      "\titers: 200, epoch: 11 | loss: 0.0796802\n",
      "\tspeed: 0.1443s/iter; left time: 297.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0797382 Vali Loss: 0.0855931 Test Loss: 0.1320583\n",
      "Validation loss decreased (0.087825 --> 0.085593).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0827526\n",
      "\tspeed: 0.2466s/iter; left time: 477.0867s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768038\n",
      "\tspeed: 0.1444s/iter; left time: 264.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0782345 Vali Loss: 0.0860973 Test Loss: 0.1370279\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0771650\n",
      "\tspeed: 0.2440s/iter; left time: 416.9754s\n",
      "\titers: 200, epoch: 13 | loss: 0.0772022\n",
      "\tspeed: 0.1444s/iter; left time: 232.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.0771531 Vali Loss: 0.0849418 Test Loss: 0.1373489\n",
      "Validation loss decreased (0.085593 --> 0.084942).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0785024\n",
      "\tspeed: 0.2535s/iter; left time: 375.8683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0735263\n",
      "\tspeed: 0.1443s/iter; left time: 199.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 226 | Train Loss: 0.0760383 Vali Loss: 0.0863459 Test Loss: 0.1388245\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0724762\n",
      "\tspeed: 0.2443s/iter; left time: 307.0341s\n",
      "\titers: 200, epoch: 15 | loss: 0.0748147\n",
      "\tspeed: 0.1444s/iter; left time: 167.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0751881 Vali Loss: 0.0848379 Test Loss: 0.1390119\n",
      "Validation loss decreased (0.084942 --> 0.084838).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0758618\n",
      "\tspeed: 0.2483s/iter; left time: 256.0171s\n",
      "\titers: 200, epoch: 16 | loss: 0.0729252\n",
      "\tspeed: 0.1444s/iter; left time: 134.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0740159 Vali Loss: 0.0846680 Test Loss: 0.1345105\n",
      "Validation loss decreased (0.084838 --> 0.084668).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734877\n",
      "\tspeed: 0.2486s/iter; left time: 200.0914s\n",
      "\titers: 200, epoch: 17 | loss: 0.0752054\n",
      "\tspeed: 0.1443s/iter; left time: 101.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0733219 Vali Loss: 0.0866349 Test Loss: 0.1425368\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0722487\n",
      "\tspeed: 0.2449s/iter; left time: 141.8064s\n",
      "\titers: 200, epoch: 18 | loss: 0.0708653\n",
      "\tspeed: 0.1443s/iter; left time: 69.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0724095 Vali Loss: 0.0861923 Test Loss: 0.1419327\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0712917\n",
      "\tspeed: 0.2436s/iter; left time: 85.9782s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707777\n",
      "\tspeed: 0.1444s/iter; left time: 36.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0719406 Vali Loss: 0.0869982 Test Loss: 0.1440870\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0705315\n",
      "\tspeed: 0.2445s/iter; left time: 31.0462s\n",
      "\titers: 200, epoch: 20 | loss: 0.0707853\n",
      "\tspeed: 0.1444s/iter; left time: 3.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.0713165 Vali Loss: 0.0864051 Test Loss: 0.1417807\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0471978485584259, rmse:0.21725066006183624, mae:0.13446779549121857, rse:0.638217031955719\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2416694\n",
      "\tspeed: 0.1456s/iter; left time: 643.7800s\n",
      "\titers: 200, epoch: 1 | loss: 0.2235083\n",
      "\tspeed: 0.1446s/iter; left time: 624.9028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.2485852 Vali Loss: 0.2082335 Test Loss: 0.2530997\n",
      "Validation loss decreased (inf --> 0.208233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1452881\n",
      "\tspeed: 0.2478s/iter; left time: 1039.5431s\n",
      "\titers: 200, epoch: 2 | loss: 0.1338378\n",
      "\tspeed: 0.1444s/iter; left time: 591.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 226 | Train Loss: 0.1501067 Vali Loss: 0.1341378 Test Loss: 0.1727708\n",
      "Validation loss decreased (0.208233 --> 0.134138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1169905\n",
      "\tspeed: 0.2495s/iter; left time: 990.1630s\n",
      "\titers: 200, epoch: 3 | loss: 0.1044615\n",
      "\tspeed: 0.1445s/iter; left time: 559.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.1158815 Vali Loss: 0.1040401 Test Loss: 0.1359054\n",
      "Validation loss decreased (0.134138 --> 0.104040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0974751\n",
      "\tspeed: 0.2480s/iter; left time: 928.2289s\n",
      "\titers: 200, epoch: 4 | loss: 0.0930906\n",
      "\tspeed: 0.1445s/iter; left time: 526.3975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.96s\n",
      "Steps: 226 | Train Loss: 0.0973248 Vali Loss: 0.0939704 Test Loss: 0.1281625\n",
      "Validation loss decreased (0.104040 --> 0.093970).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0953981\n",
      "\tspeed: 0.2477s/iter; left time: 871.2355s\n",
      "\titers: 200, epoch: 5 | loss: 0.0944890\n",
      "\tspeed: 0.1444s/iter; left time: 493.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0912272 Vali Loss: 0.0903855 Test Loss: 0.1278766\n",
      "Validation loss decreased (0.093970 --> 0.090385).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0876466\n",
      "\tspeed: 0.2474s/iter; left time: 814.1564s\n",
      "\titers: 200, epoch: 6 | loss: 0.0872737\n",
      "\tspeed: 0.1445s/iter; left time: 461.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0880332 Vali Loss: 0.0924955 Test Loss: 0.1292344\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0877176\n",
      "\tspeed: 0.2441s/iter; left time: 748.1948s\n",
      "\titers: 200, epoch: 7 | loss: 0.0833706\n",
      "\tspeed: 0.1446s/iter; left time: 428.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0859677 Vali Loss: 0.0879819 Test Loss: 0.1300540\n",
      "Validation loss decreased (0.090385 --> 0.087982).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0828758\n",
      "\tspeed: 0.2476s/iter; left time: 702.8189s\n",
      "\titers: 200, epoch: 8 | loss: 0.0818401\n",
      "\tspeed: 0.1447s/iter; left time: 396.3792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.97s\n",
      "Steps: 226 | Train Loss: 0.0838352 Vali Loss: 0.0889232 Test Loss: 0.1313546\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805965\n",
      "\tspeed: 0.2442s/iter; left time: 638.1333s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817569\n",
      "\tspeed: 0.1445s/iter; left time: 363.2537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0825541 Vali Loss: 0.0867625 Test Loss: 0.1272793\n",
      "Validation loss decreased (0.087982 --> 0.086762).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0801238\n",
      "\tspeed: 0.2469s/iter; left time: 589.3273s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771179\n",
      "\tspeed: 0.1445s/iter; left time: 330.5116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0811834 Vali Loss: 0.0864701 Test Loss: 0.1333003\n",
      "Validation loss decreased (0.086762 --> 0.086470).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0829750\n",
      "\tspeed: 0.2465s/iter; left time: 532.7814s\n",
      "\titers: 200, epoch: 11 | loss: 0.0796693\n",
      "\tspeed: 0.1445s/iter; left time: 297.8459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0798831 Vali Loss: 0.0875054 Test Loss: 0.1353047\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0810323\n",
      "\tspeed: 0.2437s/iter; left time: 471.5625s\n",
      "\titers: 200, epoch: 12 | loss: 0.0789352\n",
      "\tspeed: 0.1445s/iter; left time: 265.1596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0789042 Vali Loss: 0.0877821 Test Loss: 0.1360080\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0768939\n",
      "\tspeed: 0.2450s/iter; left time: 418.7045s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759984\n",
      "\tspeed: 0.1447s/iter; left time: 232.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:33.01s\n",
      "Steps: 226 | Train Loss: 0.0777172 Vali Loss: 0.0853919 Test Loss: 0.1324732\n",
      "Validation loss decreased (0.086470 --> 0.085392).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0755458\n",
      "\tspeed: 0.2470s/iter; left time: 366.3121s\n",
      "\titers: 200, epoch: 14 | loss: 0.0773456\n",
      "\tspeed: 0.1446s/iter; left time: 199.9990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0768413 Vali Loss: 0.0860440 Test Loss: 0.1372458\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0749763\n",
      "\tspeed: 0.2437s/iter; left time: 306.3334s\n",
      "\titers: 200, epoch: 15 | loss: 0.0750006\n",
      "\tspeed: 0.1446s/iter; left time: 167.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0758367 Vali Loss: 0.0865098 Test Loss: 0.1383647\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741497\n",
      "\tspeed: 0.2437s/iter; left time: 251.2508s\n",
      "\titers: 200, epoch: 16 | loss: 0.0771714\n",
      "\tspeed: 0.1445s/iter; left time: 134.5338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0751124 Vali Loss: 0.0864923 Test Loss: 0.1423149\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0747525\n",
      "\tspeed: 0.2443s/iter; left time: 196.6785s\n",
      "\titers: 200, epoch: 17 | loss: 0.0736851\n",
      "\tspeed: 0.1445s/iter; left time: 101.8893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0742932 Vali Loss: 0.0863387 Test Loss: 0.1457452\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0756682\n",
      "\tspeed: 0.2448s/iter; left time: 141.7280s\n",
      "\titers: 200, epoch: 18 | loss: 0.0741084\n",
      "\tspeed: 0.1445s/iter; left time: 69.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0736669 Vali Loss: 0.0852755 Test Loss: 0.1419687\n",
      "Validation loss decreased (0.085392 --> 0.085276).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0731287\n",
      "\tspeed: 0.2464s/iter; left time: 86.9711s\n",
      "\titers: 200, epoch: 19 | loss: 0.0738496\n",
      "\tspeed: 0.1445s/iter; left time: 36.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0729906 Vali Loss: 0.0858004 Test Loss: 0.1426003\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747969\n",
      "\tspeed: 0.2435s/iter; left time: 30.9244s\n",
      "\titers: 200, epoch: 20 | loss: 0.0683809\n",
      "\tspeed: 0.1445s/iter; left time: 3.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0724597 Vali Loss: 0.0856602 Test Loss: 0.1421667\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.052399978041648865, rmse:0.2289104163646698, mae:0.14182890951633453, rse:0.672469973564148\n",
      "Intermediate time for ES and pred_len 96: 00h:26m:17.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2457610\n",
      "\tspeed: 0.2004s/iter; left time: 881.8083s\n",
      "\titers: 200, epoch: 1 | loss: 0.2115155\n",
      "\tspeed: 0.1781s/iter; left time: 766.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.67s\n",
      "Steps: 225 | Train Loss: 0.2409930 Vali Loss: 0.2062387 Test Loss: 0.2530334\n",
      "Validation loss decreased (inf --> 0.206239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626451\n",
      "\tspeed: 0.3031s/iter; left time: 1265.6568s\n",
      "\titers: 200, epoch: 2 | loss: 0.1532018\n",
      "\tspeed: 0.1782s/iter; left time: 726.4760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1653174 Vali Loss: 0.1691995 Test Loss: 0.2094212\n",
      "Validation loss decreased (0.206239 --> 0.169199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1442084\n",
      "\tspeed: 0.3067s/iter; left time: 1211.8936s\n",
      "\titers: 200, epoch: 3 | loss: 0.1256499\n",
      "\tspeed: 0.1782s/iter; left time: 686.2828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.1399329 Vali Loss: 0.1225743 Test Loss: 0.1697520\n",
      "Validation loss decreased (0.169199 --> 0.122574).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1041941\n",
      "\tspeed: 0.3034s/iter; left time: 1130.3619s\n",
      "\titers: 200, epoch: 4 | loss: 0.1016427\n",
      "\tspeed: 0.1782s/iter; left time: 646.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.1046915 Vali Loss: 0.1018029 Test Loss: 0.1392777\n",
      "Validation loss decreased (0.122574 --> 0.101803).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0994780\n",
      "\tspeed: 0.3024s/iter; left time: 1058.6614s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963222\n",
      "\tspeed: 0.1782s/iter; left time: 606.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.33s\n",
      "Steps: 225 | Train Loss: 0.0972197 Vali Loss: 0.1000510 Test Loss: 0.1350308\n",
      "Validation loss decreased (0.101803 --> 0.100051).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920110\n",
      "\tspeed: 0.3023s/iter; left time: 990.4279s\n",
      "\titers: 200, epoch: 6 | loss: 0.0913163\n",
      "\tspeed: 0.1783s/iter; left time: 566.2770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.0940366 Vali Loss: 0.0983448 Test Loss: 0.1345941\n",
      "Validation loss decreased (0.100051 --> 0.098345).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0920803\n",
      "\tspeed: 0.3048s/iter; left time: 930.0429s\n",
      "\titers: 200, epoch: 7 | loss: 0.0882216\n",
      "\tspeed: 0.1783s/iter; left time: 526.0396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.0914058 Vali Loss: 0.0958223 Test Loss: 0.1399717\n",
      "Validation loss decreased (0.098345 --> 0.095822).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0883072\n",
      "\tspeed: 0.3029s/iter; left time: 855.8820s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872633\n",
      "\tspeed: 0.1782s/iter; left time: 485.8934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0893757 Vali Loss: 0.0958934 Test Loss: 0.1425967\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0891180\n",
      "\tspeed: 0.2998s/iter; left time: 779.7484s\n",
      "\titers: 200, epoch: 9 | loss: 0.0870991\n",
      "\tspeed: 0.1784s/iter; left time: 446.2249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0872738 Vali Loss: 0.0939452 Test Loss: 0.1410699\n",
      "Validation loss decreased (0.095822 --> 0.093945).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0848214\n",
      "\tspeed: 0.3026s/iter; left time: 719.0185s\n",
      "\titers: 200, epoch: 10 | loss: 0.0838362\n",
      "\tspeed: 0.1785s/iter; left time: 406.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.0853143 Vali Loss: 0.0927593 Test Loss: 0.1403578\n",
      "Validation loss decreased (0.093945 --> 0.092759).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0853636\n",
      "\tspeed: 0.3036s/iter; left time: 653.0643s\n",
      "\titers: 200, epoch: 11 | loss: 0.0842072\n",
      "\tspeed: 0.1783s/iter; left time: 365.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0839645 Vali Loss: 0.0934072 Test Loss: 0.1427162\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0850797\n",
      "\tspeed: 0.3006s/iter; left time: 578.9387s\n",
      "\titers: 200, epoch: 12 | loss: 0.0817300\n",
      "\tspeed: 0.1782s/iter; left time: 325.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0825499 Vali Loss: 0.0938800 Test Loss: 0.1467399\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0810869\n",
      "\tspeed: 0.3002s/iter; left time: 510.6757s\n",
      "\titers: 200, epoch: 13 | loss: 0.0821653\n",
      "\tspeed: 0.1784s/iter; left time: 285.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.0813790 Vali Loss: 0.0950782 Test Loss: 0.1491613\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0798811\n",
      "\tspeed: 0.3002s/iter; left time: 443.1117s\n",
      "\titers: 200, epoch: 14 | loss: 0.0797997\n",
      "\tspeed: 0.1785s/iter; left time: 245.6256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0800231 Vali Loss: 0.0922713 Test Loss: 0.1474217\n",
      "Validation loss decreased (0.092759 --> 0.092271).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797766\n",
      "\tspeed: 0.3036s/iter; left time: 379.8558s\n",
      "\titers: 200, epoch: 15 | loss: 0.0787708\n",
      "\tspeed: 0.1783s/iter; left time: 205.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.0791962 Vali Loss: 0.0932344 Test Loss: 0.1425375\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0781200\n",
      "\tspeed: 0.3003s/iter; left time: 308.1158s\n",
      "\titers: 200, epoch: 16 | loss: 0.0753142\n",
      "\tspeed: 0.1783s/iter; left time: 165.1112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0782140 Vali Loss: 0.0940368 Test Loss: 0.1473053\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0767803\n",
      "\tspeed: 0.2985s/iter; left time: 239.1044s\n",
      "\titers: 200, epoch: 17 | loss: 0.0771697\n",
      "\tspeed: 0.1782s/iter; left time: 124.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.34s\n",
      "Steps: 225 | Train Loss: 0.0775748 Vali Loss: 0.0935200 Test Loss: 0.1491674\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0766747\n",
      "\tspeed: 0.2998s/iter; left time: 172.7030s\n",
      "\titers: 200, epoch: 18 | loss: 0.0737456\n",
      "\tspeed: 0.1783s/iter; left time: 84.8733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0767617 Vali Loss: 0.0931739 Test Loss: 0.1512034\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0759772\n",
      "\tspeed: 0.2997s/iter; left time: 105.2013s\n",
      "\titers: 200, epoch: 19 | loss: 0.0765092\n",
      "\tspeed: 0.1783s/iter; left time: 44.7500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.37s\n",
      "Steps: 225 | Train Loss: 0.0761163 Vali Loss: 0.0941681 Test Loss: 0.1492964\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05317690223455429, rmse:0.23060117661952972, mae:0.14745983481407166, rse:0.6774855256080627\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2379377\n",
      "\tspeed: 0.1796s/iter; left time: 790.6053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2189854\n",
      "\tspeed: 0.1785s/iter; left time: 767.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.2476095 Vali Loss: 0.2148700 Test Loss: 0.2648005\n",
      "Validation loss decreased (inf --> 0.214870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1615509\n",
      "\tspeed: 0.3049s/iter; left time: 1273.1476s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471982\n",
      "\tspeed: 0.1785s/iter; left time: 727.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.1621998 Vali Loss: 0.1592304 Test Loss: 0.1985315\n",
      "Validation loss decreased (0.214870 --> 0.159230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1364531\n",
      "\tspeed: 0.3052s/iter; left time: 1205.7915s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155609\n",
      "\tspeed: 0.1785s/iter; left time: 687.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.1318529 Vali Loss: 0.1148189 Test Loss: 0.1571652\n",
      "Validation loss decreased (0.159230 --> 0.114819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058262\n",
      "\tspeed: 0.3035s/iter; left time: 1130.7578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0981507\n",
      "\tspeed: 0.1788s/iter; left time: 648.2096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.52s\n",
      "Steps: 225 | Train Loss: 0.1047981 Vali Loss: 0.1015726 Test Loss: 0.1422848\n",
      "Validation loss decreased (0.114819 --> 0.101573).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0983844\n",
      "\tspeed: 0.3029s/iter; left time: 1060.3748s\n",
      "\titers: 200, epoch: 5 | loss: 0.0967631\n",
      "\tspeed: 0.1785s/iter; left time: 607.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0979664 Vali Loss: 0.0997661 Test Loss: 0.1398762\n",
      "Validation loss decreased (0.101573 --> 0.099766).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0931462\n",
      "\tspeed: 0.3049s/iter; left time: 998.7254s\n",
      "\titers: 200, epoch: 6 | loss: 0.0922666\n",
      "\tspeed: 0.1788s/iter; left time: 567.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.54s\n",
      "Steps: 225 | Train Loss: 0.0944642 Vali Loss: 0.0986249 Test Loss: 0.1433112\n",
      "Validation loss decreased (0.099766 --> 0.098625).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0912865\n",
      "\tspeed: 0.3043s/iter; left time: 928.5473s\n",
      "\titers: 200, epoch: 7 | loss: 0.0915872\n",
      "\tspeed: 0.1787s/iter; left time: 527.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.0921687 Vali Loss: 0.0960949 Test Loss: 0.1364723\n",
      "Validation loss decreased (0.098625 --> 0.096095).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0855803\n",
      "\tspeed: 0.3025s/iter; left time: 854.8869s\n",
      "\titers: 200, epoch: 8 | loss: 0.0893359\n",
      "\tspeed: 0.1785s/iter; left time: 486.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 225 | Train Loss: 0.0895876 Vali Loss: 0.0991692 Test Loss: 0.1479159\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0833680\n",
      "\tspeed: 0.2998s/iter; left time: 779.7769s\n",
      "\titers: 200, epoch: 9 | loss: 0.0864347\n",
      "\tspeed: 0.1785s/iter; left time: 446.4198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.0876332 Vali Loss: 0.0945758 Test Loss: 0.1446760\n",
      "Validation loss decreased (0.096095 --> 0.094576).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0866547\n",
      "\tspeed: 0.3024s/iter; left time: 718.4965s\n",
      "\titers: 200, epoch: 10 | loss: 0.0867972\n",
      "\tspeed: 0.1786s/iter; left time: 406.5067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0859398 Vali Loss: 0.0968789 Test Loss: 0.1424100\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0860226\n",
      "\tspeed: 0.3013s/iter; left time: 648.0263s\n",
      "\titers: 200, epoch: 11 | loss: 0.0857143\n",
      "\tspeed: 0.1789s/iter; left time: 366.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.58s\n",
      "Steps: 225 | Train Loss: 0.0842236 Vali Loss: 0.0938331 Test Loss: 0.1419861\n",
      "Validation loss decreased (0.094576 --> 0.093833).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0830095\n",
      "\tspeed: 0.3030s/iter; left time: 583.5574s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816654\n",
      "\tspeed: 0.1786s/iter; left time: 326.0975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0830147 Vali Loss: 0.0948405 Test Loss: 0.1475951\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0815789\n",
      "\tspeed: 0.3003s/iter; left time: 510.8778s\n",
      "\titers: 200, epoch: 13 | loss: 0.0824939\n",
      "\tspeed: 0.1789s/iter; left time: 286.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.0816337 Vali Loss: 0.0940156 Test Loss: 0.1508449\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0821354\n",
      "\tspeed: 0.3016s/iter; left time: 445.1509s\n",
      "\titers: 200, epoch: 14 | loss: 0.0808930\n",
      "\tspeed: 0.1788s/iter; left time: 246.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 225 | Train Loss: 0.0805720 Vali Loss: 0.0927225 Test Loss: 0.1534377\n",
      "Validation loss decreased (0.093833 --> 0.092722).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0826486\n",
      "\tspeed: 0.3065s/iter; left time: 383.4016s\n",
      "\titers: 200, epoch: 15 | loss: 0.0800845\n",
      "\tspeed: 0.1786s/iter; left time: 205.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0796697 Vali Loss: 0.0947670 Test Loss: 0.1539400\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0794830\n",
      "\tspeed: 0.2996s/iter; left time: 307.4167s\n",
      "\titers: 200, epoch: 16 | loss: 0.0787446\n",
      "\tspeed: 0.1787s/iter; left time: 165.4337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.0788107 Vali Loss: 0.0944432 Test Loss: 0.1544909\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0766730\n",
      "\tspeed: 0.3001s/iter; left time: 240.3613s\n",
      "\titers: 200, epoch: 17 | loss: 0.0782681\n",
      "\tspeed: 0.1787s/iter; left time: 125.2653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0778782 Vali Loss: 0.0945748 Test Loss: 0.1574771\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0743197\n",
      "\tspeed: 0.3004s/iter; left time: 173.0421s\n",
      "\titers: 200, epoch: 18 | loss: 0.0758227\n",
      "\tspeed: 0.1787s/iter; left time: 85.0400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 225 | Train Loss: 0.0772520 Vali Loss: 0.0936467 Test Loss: 0.1567090\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0769747\n",
      "\tspeed: 0.2998s/iter; left time: 105.2362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760629\n",
      "\tspeed: 0.1787s/iter; left time: 44.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0766288 Vali Loss: 0.0940152 Test Loss: 0.1570881\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06147249788045883, rmse:0.24793647229671478, mae:0.1534600555896759, rse:0.7284150719642639\n",
      "Intermediate time for ES and pred_len 168: 00h:30m:42.87s\n",
      "Intermediate time for ES: 01h:17m:30.59s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1702676\n",
      "\tspeed: 0.1342s/iter; left time: 593.1856s\n",
      "\titers: 200, epoch: 1 | loss: 0.1605760\n",
      "\tspeed: 0.1120s/iter; left time: 483.8208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.92s\n",
      "Steps: 226 | Train Loss: 0.1753477 Vali Loss: 0.1621627 Test Loss: 0.1865840\n",
      "Validation loss decreased (inf --> 0.162163).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1101868\n",
      "\tspeed: 0.1944s/iter; left time: 815.3433s\n",
      "\titers: 200, epoch: 2 | loss: 0.0926496\n",
      "\tspeed: 0.1120s/iter; left time: 458.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.57s\n",
      "Steps: 226 | Train Loss: 0.1106069 Vali Loss: 0.0943471 Test Loss: 0.1064690\n",
      "Validation loss decreased (0.162163 --> 0.094347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0704553\n",
      "\tspeed: 0.1928s/iter; left time: 765.0938s\n",
      "\titers: 200, epoch: 3 | loss: 0.0642383\n",
      "\tspeed: 0.1122s/iter; left time: 434.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0724409 Vali Loss: 0.0718213 Test Loss: 0.0793675\n",
      "Validation loss decreased (0.094347 --> 0.071821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0580635\n",
      "\tspeed: 0.1952s/iter; left time: 730.4964s\n",
      "\titers: 200, epoch: 4 | loss: 0.0609369\n",
      "\tspeed: 0.1123s/iter; left time: 409.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0592440 Vali Loss: 0.0708287 Test Loss: 0.0775396\n",
      "Validation loss decreased (0.071821 --> 0.070829).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0568340\n",
      "\tspeed: 0.1922s/iter; left time: 676.0241s\n",
      "\titers: 200, epoch: 5 | loss: 0.0537689\n",
      "\tspeed: 0.1123s/iter; left time: 383.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0553003 Vali Loss: 0.0631915 Test Loss: 0.0705554\n",
      "Validation loss decreased (0.070829 --> 0.063192).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0529045\n",
      "\tspeed: 0.1941s/iter; left time: 638.9159s\n",
      "\titers: 200, epoch: 6 | loss: 0.0550647\n",
      "\tspeed: 0.1123s/iter; left time: 358.3732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 226 | Train Loss: 0.0530094 Vali Loss: 0.0619395 Test Loss: 0.0688249\n",
      "Validation loss decreased (0.063192 --> 0.061939).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0500040\n",
      "\tspeed: 0.1937s/iter; left time: 593.6027s\n",
      "\titers: 200, epoch: 7 | loss: 0.0490464\n",
      "\tspeed: 0.1123s/iter; left time: 333.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0511564 Vali Loss: 0.0636291 Test Loss: 0.0699203\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0495845\n",
      "\tspeed: 0.1898s/iter; left time: 538.7675s\n",
      "\titers: 200, epoch: 8 | loss: 0.0498717\n",
      "\tspeed: 0.1121s/iter; left time: 307.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0498700 Vali Loss: 0.0616608 Test Loss: 0.0686316\n",
      "Validation loss decreased (0.061939 --> 0.061661).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0522856\n",
      "\tspeed: 0.1932s/iter; left time: 504.7403s\n",
      "\titers: 200, epoch: 9 | loss: 0.0453240\n",
      "\tspeed: 0.1123s/iter; left time: 282.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0489732 Vali Loss: 0.0601843 Test Loss: 0.0671085\n",
      "Validation loss decreased (0.061661 --> 0.060184).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0472582\n",
      "\tspeed: 0.1952s/iter; left time: 466.0324s\n",
      "\titers: 200, epoch: 10 | loss: 0.0488918\n",
      "\tspeed: 0.1123s/iter; left time: 256.9117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0479883 Vali Loss: 0.0615522 Test Loss: 0.0688199\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0504769\n",
      "\tspeed: 0.1893s/iter; left time: 409.1595s\n",
      "\titers: 200, epoch: 11 | loss: 0.0468239\n",
      "\tspeed: 0.1123s/iter; left time: 231.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0471026 Vali Loss: 0.0611574 Test Loss: 0.0691946\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0464070\n",
      "\tspeed: 0.1897s/iter; left time: 367.0463s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484488\n",
      "\tspeed: 0.1123s/iter; left time: 206.0737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0465368 Vali Loss: 0.0600034 Test Loss: 0.0673989\n",
      "Validation loss decreased (0.060184 --> 0.060003).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0452547\n",
      "\tspeed: 0.1932s/iter; left time: 330.1500s\n",
      "\titers: 200, epoch: 13 | loss: 0.0461572\n",
      "\tspeed: 0.1123s/iter; left time: 180.6561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0459066 Vali Loss: 0.0607861 Test Loss: 0.0668933\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0418420\n",
      "\tspeed: 0.1897s/iter; left time: 281.2752s\n",
      "\titers: 200, epoch: 14 | loss: 0.0441332\n",
      "\tspeed: 0.1124s/iter; left time: 155.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0452820 Vali Loss: 0.0606238 Test Loss: 0.0670919\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0447426\n",
      "\tspeed: 0.1891s/iter; left time: 237.7379s\n",
      "\titers: 200, epoch: 15 | loss: 0.0455186\n",
      "\tspeed: 0.1124s/iter; left time: 129.9952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0450349 Vali Loss: 0.0587545 Test Loss: 0.0665200\n",
      "Validation loss decreased (0.060003 --> 0.058754).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0443731\n",
      "\tspeed: 0.1935s/iter; left time: 199.5340s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434828\n",
      "\tspeed: 0.1123s/iter; left time: 104.5651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0444221 Vali Loss: 0.0600092 Test Loss: 0.0672657\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0457099\n",
      "\tspeed: 0.1900s/iter; left time: 152.9274s\n",
      "\titers: 200, epoch: 17 | loss: 0.0437652\n",
      "\tspeed: 0.1124s/iter; left time: 79.2483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0440317 Vali Loss: 0.0597580 Test Loss: 0.0664431\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0409786\n",
      "\tspeed: 0.1900s/iter; left time: 110.0140s\n",
      "\titers: 200, epoch: 18 | loss: 0.0409479\n",
      "\tspeed: 0.1123s/iter; left time: 53.8045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0437918 Vali Loss: 0.0587373 Test Loss: 0.0666219\n",
      "Validation loss decreased (0.058754 --> 0.058737).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0418082\n",
      "\tspeed: 0.1925s/iter; left time: 67.9501s\n",
      "\titers: 200, epoch: 19 | loss: 0.0441233\n",
      "\tspeed: 0.1124s/iter; left time: 28.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0433935 Vali Loss: 0.0601905 Test Loss: 0.0672240\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0426457\n",
      "\tspeed: 0.1896s/iter; left time: 24.0783s\n",
      "\titers: 200, epoch: 20 | loss: 0.0461567\n",
      "\tspeed: 0.1121s/iter; left time: 3.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.53s\n",
      "Steps: 226 | Train Loss: 0.0430825 Vali Loss: 0.0593030 Test Loss: 0.0675713\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013226393610239029, rmse:0.11500605940818787, mae:0.06676443666219711, rse:0.4436901807785034\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1774181\n",
      "\tspeed: 0.1169s/iter; left time: 516.9729s\n",
      "\titers: 200, epoch: 1 | loss: 0.1683326\n",
      "\tspeed: 0.1120s/iter; left time: 484.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.92s\n",
      "Steps: 226 | Train Loss: 0.1894309 Vali Loss: 0.1668799 Test Loss: 0.1919497\n",
      "Validation loss decreased (inf --> 0.166880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1045541\n",
      "\tspeed: 0.1930s/iter; left time: 809.7594s\n",
      "\titers: 200, epoch: 2 | loss: 0.0891130\n",
      "\tspeed: 0.1121s/iter; left time: 458.9595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 226 | Train Loss: 0.1096062 Vali Loss: 0.0911400 Test Loss: 0.1042495\n",
      "Validation loss decreased (0.166880 --> 0.091140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803955\n",
      "\tspeed: 0.2006s/iter; left time: 796.1569s\n",
      "\titers: 200, epoch: 3 | loss: 0.0845279\n",
      "\tspeed: 0.1123s/iter; left time: 434.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.65s\n",
      "Steps: 226 | Train Loss: 0.0787869 Vali Loss: 0.0909816 Test Loss: 0.1042863\n",
      "Validation loss decreased (0.091140 --> 0.090982).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0738682\n",
      "\tspeed: 0.1925s/iter; left time: 720.5630s\n",
      "\titers: 200, epoch: 4 | loss: 0.0727730\n",
      "\tspeed: 0.1120s/iter; left time: 408.1090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0735131 Vali Loss: 0.0844789 Test Loss: 0.0972447\n",
      "Validation loss decreased (0.090982 --> 0.084479).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0686450\n",
      "\tspeed: 0.1959s/iter; left time: 688.9859s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724654\n",
      "\tspeed: 0.1120s/iter; left time: 382.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.69s\n",
      "Steps: 226 | Train Loss: 0.0698030 Vali Loss: 0.0834839 Test Loss: 0.0955971\n",
      "Validation loss decreased (0.084479 --> 0.083484).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0682677\n",
      "\tspeed: 0.1932s/iter; left time: 635.9045s\n",
      "\titers: 200, epoch: 6 | loss: 0.0668375\n",
      "\tspeed: 0.1123s/iter; left time: 358.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0675269 Vali Loss: 0.0833980 Test Loss: 0.0958501\n",
      "Validation loss decreased (0.083484 --> 0.083398).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543846\n",
      "\tspeed: 0.1924s/iter; left time: 589.8353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0496124\n",
      "\tspeed: 0.1121s/iter; left time: 332.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0571364 Vali Loss: 0.0622076 Test Loss: 0.0691396\n",
      "Validation loss decreased (0.083398 --> 0.062208).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0498833\n",
      "\tspeed: 0.1969s/iter; left time: 558.9969s\n",
      "\titers: 200, epoch: 8 | loss: 0.0536817\n",
      "\tspeed: 0.1123s/iter; left time: 307.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0506898 Vali Loss: 0.0618427 Test Loss: 0.0679611\n",
      "Validation loss decreased (0.062208 --> 0.061843).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0533017\n",
      "\tspeed: 0.1938s/iter; left time: 506.3592s\n",
      "\titers: 200, epoch: 9 | loss: 0.0467102\n",
      "\tspeed: 0.1123s/iter; left time: 282.2288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0495207 Vali Loss: 0.0609268 Test Loss: 0.0685116\n",
      "Validation loss decreased (0.061843 --> 0.060927).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0510347\n",
      "\tspeed: 0.1954s/iter; left time: 466.4485s\n",
      "\titers: 200, epoch: 10 | loss: 0.0495945\n",
      "\tspeed: 0.1121s/iter; left time: 256.3832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.67s\n",
      "Steps: 226 | Train Loss: 0.0488307 Vali Loss: 0.0598835 Test Loss: 0.0663515\n",
      "Validation loss decreased (0.060927 --> 0.059884).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0474851\n",
      "\tspeed: 0.1947s/iter; left time: 420.7884s\n",
      "\titers: 200, epoch: 11 | loss: 0.0470781\n",
      "\tspeed: 0.1121s/iter; left time: 230.9536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0475201 Vali Loss: 0.0600977 Test Loss: 0.0673866\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0449984\n",
      "\tspeed: 0.1902s/iter; left time: 368.0760s\n",
      "\titers: 200, epoch: 12 | loss: 0.0495665\n",
      "\tspeed: 0.1123s/iter; left time: 206.1274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.73s\n",
      "Steps: 226 | Train Loss: 0.0472575 Vali Loss: 0.0593352 Test Loss: 0.0654847\n",
      "Validation loss decreased (0.059884 --> 0.059335).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0476521\n",
      "\tspeed: 0.1937s/iter; left time: 331.0841s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463802\n",
      "\tspeed: 0.1123s/iter; left time: 180.6550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0464462 Vali Loss: 0.0593088 Test Loss: 0.0662957\n",
      "Validation loss decreased (0.059335 --> 0.059309).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0481837\n",
      "\tspeed: 0.1924s/iter; left time: 285.3497s\n",
      "\titers: 200, epoch: 14 | loss: 0.0438529\n",
      "\tspeed: 0.1124s/iter; left time: 155.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 226 | Train Loss: 0.0459630 Vali Loss: 0.0596619 Test Loss: 0.0661467\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0424995\n",
      "\tspeed: 0.1893s/iter; left time: 237.8875s\n",
      "\titers: 200, epoch: 15 | loss: 0.0424456\n",
      "\tspeed: 0.1121s/iter; left time: 129.7369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0454099 Vali Loss: 0.0593900 Test Loss: 0.0669232\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0427241\n",
      "\tspeed: 0.1893s/iter; left time: 195.1641s\n",
      "\titers: 200, epoch: 16 | loss: 0.0424759\n",
      "\tspeed: 0.1121s/iter; left time: 104.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0448683 Vali Loss: 0.0590975 Test Loss: 0.0662373\n",
      "Validation loss decreased (0.059309 --> 0.059098).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0432423\n",
      "\tspeed: 0.1945s/iter; left time: 156.5605s\n",
      "\titers: 200, epoch: 17 | loss: 0.0446365\n",
      "\tspeed: 0.1123s/iter; left time: 79.1883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 226 | Train Loss: 0.0447376 Vali Loss: 0.0596180 Test Loss: 0.0669884\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0435086\n",
      "\tspeed: 0.1892s/iter; left time: 109.5484s\n",
      "\titers: 200, epoch: 18 | loss: 0.0446305\n",
      "\tspeed: 0.1121s/iter; left time: 53.6948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 226 | Train Loss: 0.0442583 Vali Loss: 0.0593134 Test Loss: 0.0659693\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0419267\n",
      "\tspeed: 0.1898s/iter; left time: 66.9853s\n",
      "\titers: 200, epoch: 19 | loss: 0.0427753\n",
      "\tspeed: 0.1124s/iter; left time: 28.4285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0437868 Vali Loss: 0.0587697 Test Loss: 0.0651773\n",
      "Validation loss decreased (0.059098 --> 0.058770).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0471612\n",
      "\tspeed: 0.1929s/iter; left time: 24.5044s\n",
      "\titers: 200, epoch: 20 | loss: 0.0442058\n",
      "\tspeed: 0.1123s/iter; left time: 3.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0435827 Vali Loss: 0.0590427 Test Loss: 0.0653145\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01269116997718811, rmse:0.11265509575605392, mae:0.0649927482008934, rse:0.4346202313899994\n",
      "Intermediate time for FR and pred_len 24: 00h:20m:32.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1804125\n",
      "\tspeed: 0.1666s/iter; left time: 736.4405s\n",
      "\titers: 200, epoch: 1 | loss: 0.1637505\n",
      "\tspeed: 0.1442s/iter; left time: 623.0740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.22s\n",
      "Steps: 226 | Train Loss: 0.1853619 Vali Loss: 0.1744819 Test Loss: 0.2000746\n",
      "Validation loss decreased (inf --> 0.174482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1264411\n",
      "\tspeed: 0.2504s/iter; left time: 1050.5061s\n",
      "\titers: 200, epoch: 2 | loss: 0.1201469\n",
      "\tspeed: 0.1440s/iter; left time: 589.7730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.1284326 Vali Loss: 0.1377183 Test Loss: 0.1631223\n",
      "Validation loss decreased (0.174482 --> 0.137718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1124429\n",
      "\tspeed: 0.2472s/iter; left time: 981.1037s\n",
      "\titers: 200, epoch: 3 | loss: 0.1052106\n",
      "\tspeed: 0.1441s/iter; left time: 557.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.86s\n",
      "Steps: 226 | Train Loss: 0.1088477 Vali Loss: 0.1247378 Test Loss: 0.1426578\n",
      "Validation loss decreased (0.137718 --> 0.124738).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045050\n",
      "\tspeed: 0.2476s/iter; left time: 926.8519s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997182\n",
      "\tspeed: 0.1441s/iter; left time: 524.9580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.1006509 Vali Loss: 0.1249578 Test Loss: 0.1457649\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0978278\n",
      "\tspeed: 0.2445s/iter; left time: 859.9027s\n",
      "\titers: 200, epoch: 5 | loss: 0.0955162\n",
      "\tspeed: 0.1441s/iter; left time: 492.4479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0973669 Vali Loss: 0.1229526 Test Loss: 0.1415190\n",
      "Validation loss decreased (0.124738 --> 0.122953).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0923122\n",
      "\tspeed: 0.2485s/iter; left time: 817.8105s\n",
      "\titers: 200, epoch: 6 | loss: 0.0934198\n",
      "\tspeed: 0.1440s/iter; left time: 459.6060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0958077 Vali Loss: 0.1217753 Test Loss: 0.1409844\n",
      "Validation loss decreased (0.122953 --> 0.121775).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0941031\n",
      "\tspeed: 0.2465s/iter; left time: 755.4859s\n",
      "\titers: 200, epoch: 7 | loss: 0.0908934\n",
      "\tspeed: 0.1441s/iter; left time: 427.3970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.0931171 Vali Loss: 0.1148960 Test Loss: 0.1308858\n",
      "Validation loss decreased (0.121775 --> 0.114896).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823491\n",
      "\tspeed: 0.2471s/iter; left time: 701.4698s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827234\n",
      "\tspeed: 0.1443s/iter; left time: 395.3608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0836458 Vali Loss: 0.1031146 Test Loss: 0.1165694\n",
      "Validation loss decreased (0.114896 --> 0.103115).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0772217\n",
      "\tspeed: 0.2472s/iter; left time: 645.8734s\n",
      "\titers: 200, epoch: 9 | loss: 0.0727659\n",
      "\tspeed: 0.1442s/iter; left time: 362.2555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.86s\n",
      "Steps: 226 | Train Loss: 0.0760373 Vali Loss: 0.0955309 Test Loss: 0.1063488\n",
      "Validation loss decreased (0.103115 --> 0.095531).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688425\n",
      "\tspeed: 0.2463s/iter; left time: 588.0141s\n",
      "\titers: 200, epoch: 10 | loss: 0.0668714\n",
      "\tspeed: 0.1441s/iter; left time: 329.5826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 226 | Train Loss: 0.0686590 Vali Loss: 0.0873834 Test Loss: 0.0985605\n",
      "Validation loss decreased (0.095531 --> 0.087383).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603418\n",
      "\tspeed: 0.2486s/iter; left time: 537.2981s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619900\n",
      "\tspeed: 0.1442s/iter; left time: 297.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0644037 Vali Loss: 0.0859030 Test Loss: 0.0954747\n",
      "Validation loss decreased (0.087383 --> 0.085903).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0645894\n",
      "\tspeed: 0.2482s/iter; left time: 480.2734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0609357\n",
      "\tspeed: 0.1442s/iter; left time: 264.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 226 | Train Loss: 0.0622402 Vali Loss: 0.0852123 Test Loss: 0.0949412\n",
      "Validation loss decreased (0.085903 --> 0.085212).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0624247\n",
      "\tspeed: 0.2482s/iter; left time: 424.0970s\n",
      "\titers: 200, epoch: 13 | loss: 0.0591796\n",
      "\tspeed: 0.1442s/iter; left time: 232.0108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0608492 Vali Loss: 0.0837068 Test Loss: 0.0951346\n",
      "Validation loss decreased (0.085212 --> 0.083707).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0608328\n",
      "\tspeed: 0.2478s/iter; left time: 367.5302s\n",
      "\titers: 200, epoch: 14 | loss: 0.0574922\n",
      "\tspeed: 0.1442s/iter; left time: 199.3845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0596374 Vali Loss: 0.0836324 Test Loss: 0.0939623\n",
      "Validation loss decreased (0.083707 --> 0.083632).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0578139\n",
      "\tspeed: 0.2478s/iter; left time: 311.5169s\n",
      "\titers: 200, epoch: 15 | loss: 0.0589272\n",
      "\tspeed: 0.1441s/iter; left time: 166.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0585211 Vali Loss: 0.0822262 Test Loss: 0.0920835\n",
      "Validation loss decreased (0.083632 --> 0.082226).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0565450\n",
      "\tspeed: 0.2479s/iter; left time: 255.5887s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553163\n",
      "\tspeed: 0.1441s/iter; left time: 134.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.86s\n",
      "Steps: 226 | Train Loss: 0.0576542 Vali Loss: 0.0825034 Test Loss: 0.0915923\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0574541\n",
      "\tspeed: 0.2444s/iter; left time: 196.7670s\n",
      "\titers: 200, epoch: 17 | loss: 0.0575930\n",
      "\tspeed: 0.1443s/iter; left time: 101.7085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0569295 Vali Loss: 0.0822981 Test Loss: 0.0914765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0565474\n",
      "\tspeed: 0.2438s/iter; left time: 141.1358s\n",
      "\titers: 200, epoch: 18 | loss: 0.0555179\n",
      "\tspeed: 0.1442s/iter; left time: 69.0650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0562815 Vali Loss: 0.0828314 Test Loss: 0.0919349\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0566064\n",
      "\tspeed: 0.2435s/iter; left time: 85.9548s\n",
      "\titers: 200, epoch: 19 | loss: 0.0573603\n",
      "\tspeed: 0.1441s/iter; left time: 36.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 226 | Train Loss: 0.0557360 Vali Loss: 0.0823333 Test Loss: 0.0927193\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0530574\n",
      "\tspeed: 0.2434s/iter; left time: 30.9108s\n",
      "\titers: 200, epoch: 20 | loss: 0.0534924\n",
      "\tspeed: 0.1442s/iter; left time: 3.8925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0553022 Vali Loss: 0.0816225 Test Loss: 0.0904835\n",
      "Validation loss decreased (0.082226 --> 0.081623).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02255314402282238, rmse:0.15017704665660858, mae:0.09045195579528809, rse:0.5809247493743896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1750419\n",
      "\tspeed: 0.1493s/iter; left time: 659.9502s\n",
      "\titers: 200, epoch: 1 | loss: 0.1680877\n",
      "\tspeed: 0.1442s/iter; left time: 623.0991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.22s\n",
      "Steps: 226 | Train Loss: 0.1850604 Vali Loss: 0.1790399 Test Loss: 0.2056045\n",
      "Validation loss decreased (inf --> 0.179040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1283423\n",
      "\tspeed: 0.2480s/iter; left time: 1040.5403s\n",
      "\titers: 200, epoch: 2 | loss: 0.1121598\n",
      "\tspeed: 0.1443s/iter; left time: 590.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.1268870 Vali Loss: 0.1196214 Test Loss: 0.1383074\n",
      "Validation loss decreased (0.179040 --> 0.119621).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0968452\n",
      "\tspeed: 0.2476s/iter; left time: 982.8314s\n",
      "\titers: 200, epoch: 3 | loss: 0.0916490\n",
      "\tspeed: 0.1444s/iter; left time: 558.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0986975 Vali Loss: 0.1077145 Test Loss: 0.1226915\n",
      "Validation loss decreased (0.119621 --> 0.107715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886018\n",
      "\tspeed: 0.2471s/iter; left time: 925.0625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0875412\n",
      "\tspeed: 0.1446s/iter; left time: 526.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0887748 Vali Loss: 0.1049691 Test Loss: 0.1196978\n",
      "Validation loss decreased (0.107715 --> 0.104969).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824814\n",
      "\tspeed: 0.2471s/iter; left time: 869.1713s\n",
      "\titers: 200, epoch: 5 | loss: 0.0795511\n",
      "\tspeed: 0.1444s/iter; left time: 493.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0823050 Vali Loss: 0.0951525 Test Loss: 0.1084487\n",
      "Validation loss decreased (0.104969 --> 0.095153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0760242\n",
      "\tspeed: 0.2473s/iter; left time: 813.8646s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736786\n",
      "\tspeed: 0.1443s/iter; left time: 460.5200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0748392 Vali Loss: 0.0881163 Test Loss: 0.0987454\n",
      "Validation loss decreased (0.095153 --> 0.088116).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0711157\n",
      "\tspeed: 0.2480s/iter; left time: 760.2436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0650525\n",
      "\tspeed: 0.1444s/iter; left time: 428.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.93s\n",
      "Steps: 226 | Train Loss: 0.0679581 Vali Loss: 0.0824147 Test Loss: 0.0918639\n",
      "Validation loss decreased (0.088116 --> 0.082415).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0635089\n",
      "\tspeed: 0.2469s/iter; left time: 701.0478s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633250\n",
      "\tspeed: 0.1444s/iter; left time: 395.6479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0648970 Vali Loss: 0.0815006 Test Loss: 0.0906714\n",
      "Validation loss decreased (0.082415 --> 0.081501).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0625918\n",
      "\tspeed: 0.2469s/iter; left time: 645.2257s\n",
      "\titers: 200, epoch: 9 | loss: 0.0624812\n",
      "\tspeed: 0.1444s/iter; left time: 362.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0633403 Vali Loss: 0.0791475 Test Loss: 0.0887284\n",
      "Validation loss decreased (0.081501 --> 0.079147).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0599761\n",
      "\tspeed: 0.2480s/iter; left time: 592.0905s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594312\n",
      "\tspeed: 0.1444s/iter; left time: 330.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0619550 Vali Loss: 0.0803877 Test Loss: 0.0883061\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0602800\n",
      "\tspeed: 0.2445s/iter; left time: 528.3404s\n",
      "\titers: 200, epoch: 11 | loss: 0.0590588\n",
      "\tspeed: 0.1444s/iter; left time: 297.6329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0605099 Vali Loss: 0.0787673 Test Loss: 0.0889606\n",
      "Validation loss decreased (0.079147 --> 0.078767).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0579331\n",
      "\tspeed: 0.2481s/iter; left time: 480.1696s\n",
      "\titers: 200, epoch: 12 | loss: 0.0593827\n",
      "\tspeed: 0.1446s/iter; left time: 265.4086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.98s\n",
      "Steps: 226 | Train Loss: 0.0594216 Vali Loss: 0.0809698 Test Loss: 0.0881967\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0564982\n",
      "\tspeed: 0.2451s/iter; left time: 418.9408s\n",
      "\titers: 200, epoch: 13 | loss: 0.0577423\n",
      "\tspeed: 0.1444s/iter; left time: 232.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0585269 Vali Loss: 0.0787135 Test Loss: 0.0875791\n",
      "Validation loss decreased (0.078767 --> 0.078713).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603714\n",
      "\tspeed: 0.2470s/iter; left time: 366.3446s\n",
      "\titers: 200, epoch: 14 | loss: 0.0594511\n",
      "\tspeed: 0.1444s/iter; left time: 199.7138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.94s\n",
      "Steps: 226 | Train Loss: 0.0579368 Vali Loss: 0.0787463 Test Loss: 0.0879428\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0570017\n",
      "\tspeed: 0.2447s/iter; left time: 307.6096s\n",
      "\titers: 200, epoch: 15 | loss: 0.0573758\n",
      "\tspeed: 0.1444s/iter; left time: 167.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0571231 Vali Loss: 0.0794490 Test Loss: 0.0880159\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0576153\n",
      "\tspeed: 0.2453s/iter; left time: 252.8879s\n",
      "\titers: 200, epoch: 16 | loss: 0.0556691\n",
      "\tspeed: 0.1445s/iter; left time: 134.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0565448 Vali Loss: 0.0798003 Test Loss: 0.0883752\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0560376\n",
      "\tspeed: 0.2442s/iter; left time: 196.5418s\n",
      "\titers: 200, epoch: 17 | loss: 0.0560716\n",
      "\tspeed: 0.1444s/iter; left time: 101.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.90s\n",
      "Steps: 226 | Train Loss: 0.0559770 Vali Loss: 0.0776801 Test Loss: 0.0864032\n",
      "Validation loss decreased (0.078713 --> 0.077680).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0583218\n",
      "\tspeed: 0.2482s/iter; left time: 143.6810s\n",
      "\titers: 200, epoch: 18 | loss: 0.0546397\n",
      "\tspeed: 0.1445s/iter; left time: 69.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0554923 Vali Loss: 0.0782344 Test Loss: 0.0858363\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0561487\n",
      "\tspeed: 0.2445s/iter; left time: 86.3110s\n",
      "\titers: 200, epoch: 19 | loss: 0.0528299\n",
      "\tspeed: 0.1444s/iter; left time: 36.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.0549633 Vali Loss: 0.0784145 Test Loss: 0.0863717\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0559790\n",
      "\tspeed: 0.2441s/iter; left time: 31.0015s\n",
      "\titers: 200, epoch: 20 | loss: 0.0538395\n",
      "\tspeed: 0.1445s/iter; left time: 3.9022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.92s\n",
      "Steps: 226 | Train Loss: 0.0545736 Vali Loss: 0.0781327 Test Loss: 0.0867220\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02064206637442112, rmse:0.14367346465587616, mae:0.0864601656794548, rse:0.5557671785354614\n",
      "Intermediate time for FR and pred_len 96: 00h:26m:20.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1913590\n",
      "\tspeed: 0.2005s/iter; left time: 882.2993s\n",
      "\titers: 200, epoch: 1 | loss: 0.1623564\n",
      "\tspeed: 0.1780s/iter; left time: 765.7740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.65s\n",
      "Steps: 225 | Train Loss: 0.1873580 Vali Loss: 0.1778540 Test Loss: 0.2029923\n",
      "Validation loss decreased (inf --> 0.177854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303728\n",
      "\tspeed: 0.3024s/iter; left time: 1262.8376s\n",
      "\titers: 200, epoch: 2 | loss: 0.1149181\n",
      "\tspeed: 0.1782s/iter; left time: 726.2657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.37s\n",
      "Steps: 225 | Train Loss: 0.1295825 Vali Loss: 0.1367869 Test Loss: 0.1577154\n",
      "Validation loss decreased (0.177854 --> 0.136787).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1117214\n",
      "\tspeed: 0.3043s/iter; left time: 1202.3175s\n",
      "\titers: 200, epoch: 3 | loss: 0.1096817\n",
      "\tspeed: 0.1782s/iter; left time: 686.1234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1116897 Vali Loss: 0.1347032 Test Loss: 0.1548624\n",
      "Validation loss decreased (0.136787 --> 0.134703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077711\n",
      "\tspeed: 0.3038s/iter; left time: 1132.0679s\n",
      "\titers: 200, epoch: 4 | loss: 0.1044297\n",
      "\tspeed: 0.1781s/iter; left time: 645.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.1063061 Vali Loss: 0.1311356 Test Loss: 0.1538997\n",
      "Validation loss decreased (0.134703 --> 0.131136).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043703\n",
      "\tspeed: 0.3043s/iter; left time: 1065.4717s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008380\n",
      "\tspeed: 0.1780s/iter; left time: 605.4309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.1016473 Vali Loss: 0.1226063 Test Loss: 0.1417499\n",
      "Validation loss decreased (0.131136 --> 0.122606).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0975962\n",
      "\tspeed: 0.3044s/iter; left time: 997.2660s\n",
      "\titers: 200, epoch: 6 | loss: 0.0973153\n",
      "\tspeed: 0.1780s/iter; left time: 565.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.34s\n",
      "Steps: 225 | Train Loss: 0.0982620 Vali Loss: 0.1189692 Test Loss: 0.1372047\n",
      "Validation loss decreased (0.122606 --> 0.118969).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0900705\n",
      "\tspeed: 0.3027s/iter; left time: 923.4215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0874040\n",
      "\tspeed: 0.1780s/iter; left time: 525.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.40s\n",
      "Steps: 225 | Train Loss: 0.0919960 Vali Loss: 0.1130720 Test Loss: 0.1292914\n",
      "Validation loss decreased (0.118969 --> 0.113072).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0842762\n",
      "\tspeed: 0.3033s/iter; left time: 857.0630s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819874\n",
      "\tspeed: 0.1779s/iter; left time: 484.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0854944 Vali Loss: 0.1028419 Test Loss: 0.1162690\n",
      "Validation loss decreased (0.113072 --> 0.102842).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0708436\n",
      "\tspeed: 0.3031s/iter; left time: 788.3963s\n",
      "\titers: 200, epoch: 9 | loss: 0.0684146\n",
      "\tspeed: 0.1779s/iter; left time: 444.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.37s\n",
      "Steps: 225 | Train Loss: 0.0734702 Vali Loss: 0.0889448 Test Loss: 0.0978799\n",
      "Validation loss decreased (0.102842 --> 0.088945).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676529\n",
      "\tspeed: 0.3049s/iter; left time: 724.5177s\n",
      "\titers: 200, epoch: 10 | loss: 0.0644393\n",
      "\tspeed: 0.1780s/iter; left time: 405.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.0677677 Vali Loss: 0.0896813 Test Loss: 0.0990897\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0687296\n",
      "\tspeed: 0.3010s/iter; left time: 647.4588s\n",
      "\titers: 200, epoch: 11 | loss: 0.0657889\n",
      "\tspeed: 0.1781s/iter; left time: 365.2429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 225 | Train Loss: 0.0660489 Vali Loss: 0.0889977 Test Loss: 0.0987190\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0635856\n",
      "\tspeed: 0.3007s/iter; left time: 579.1657s\n",
      "\titers: 200, epoch: 12 | loss: 0.0650013\n",
      "\tspeed: 0.1780s/iter; left time: 325.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0643508 Vali Loss: 0.0886139 Test Loss: 0.0967352\n",
      "Validation loss decreased (0.088945 --> 0.088614).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0616139\n",
      "\tspeed: 0.3055s/iter; left time: 519.6216s\n",
      "\titers: 200, epoch: 13 | loss: 0.0632821\n",
      "\tspeed: 0.1781s/iter; left time: 285.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.0633152 Vali Loss: 0.0887369 Test Loss: 0.0983146\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0604596\n",
      "\tspeed: 0.3017s/iter; left time: 445.2904s\n",
      "\titers: 200, epoch: 14 | loss: 0.0632588\n",
      "\tspeed: 0.1780s/iter; left time: 244.9709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0619917 Vali Loss: 0.0868922 Test Loss: 0.0943551\n",
      "Validation loss decreased (0.088614 --> 0.086892).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0591398\n",
      "\tspeed: 0.3050s/iter; left time: 381.4943s\n",
      "\titers: 200, epoch: 15 | loss: 0.0614784\n",
      "\tspeed: 0.1781s/iter; left time: 204.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.34s\n",
      "Steps: 225 | Train Loss: 0.0611488 Vali Loss: 0.0877538 Test Loss: 0.0960522\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0607934\n",
      "\tspeed: 0.2999s/iter; left time: 307.7194s\n",
      "\titers: 200, epoch: 16 | loss: 0.0604017\n",
      "\tspeed: 0.1781s/iter; left time: 164.8933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0605099 Vali Loss: 0.0873056 Test Loss: 0.0956175\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0605855\n",
      "\tspeed: 0.3006s/iter; left time: 240.7418s\n",
      "\titers: 200, epoch: 17 | loss: 0.0600160\n",
      "\tspeed: 0.1781s/iter; left time: 124.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0598944 Vali Loss: 0.0884959 Test Loss: 0.0974417\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0605417\n",
      "\tspeed: 0.3009s/iter; left time: 173.3152s\n",
      "\titers: 200, epoch: 18 | loss: 0.0590552\n",
      "\tspeed: 0.1781s/iter; left time: 84.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0591941 Vali Loss: 0.0876162 Test Loss: 0.0955591\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0599198\n",
      "\tspeed: 0.3010s/iter; left time: 105.6518s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604858\n",
      "\tspeed: 0.1781s/iter; left time: 44.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0587078 Vali Loss: 0.0873598 Test Loss: 0.0952867\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02322584018111229, rmse:0.15240027010440826, mae:0.0943157970905304, rse:0.5902606844902039\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1786887\n",
      "\tspeed: 0.1799s/iter; left time: 791.5780s\n",
      "\titers: 200, epoch: 1 | loss: 0.1659641\n",
      "\tspeed: 0.1784s/iter; left time: 767.1329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.1885286 Vali Loss: 0.1883090 Test Loss: 0.2146182\n",
      "Validation loss decreased (inf --> 0.188309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1278235\n",
      "\tspeed: 0.3063s/iter; left time: 1279.1160s\n",
      "\titers: 200, epoch: 2 | loss: 0.1219380\n",
      "\tspeed: 0.1783s/iter; left time: 726.6905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.42s\n",
      "Steps: 225 | Train Loss: 0.1332626 Vali Loss: 0.1441548 Test Loss: 0.1673547\n",
      "Validation loss decreased (0.188309 --> 0.144155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1154181\n",
      "\tspeed: 0.3059s/iter; left time: 1208.7177s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076544\n",
      "\tspeed: 0.1783s/iter; left time: 686.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.1143699 Vali Loss: 0.1317549 Test Loss: 0.1532418\n",
      "Validation loss decreased (0.144155 --> 0.131755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077171\n",
      "\tspeed: 0.3029s/iter; left time: 1128.7268s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020665\n",
      "\tspeed: 0.1784s/iter; left time: 646.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.1051277 Vali Loss: 0.1210883 Test Loss: 0.1397143\n",
      "Validation loss decreased (0.131755 --> 0.121088).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0963776\n",
      "\tspeed: 0.3043s/iter; left time: 1065.5047s\n",
      "\titers: 200, epoch: 5 | loss: 0.0943386\n",
      "\tspeed: 0.1785s/iter; left time: 606.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.0956694 Vali Loss: 0.1160552 Test Loss: 0.1326164\n",
      "Validation loss decreased (0.121088 --> 0.116055).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0894248\n",
      "\tspeed: 0.3047s/iter; left time: 998.3051s\n",
      "\titers: 200, epoch: 6 | loss: 0.0899418\n",
      "\tspeed: 0.1785s/iter; left time: 566.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.0908008 Vali Loss: 0.1101163 Test Loss: 0.1272966\n",
      "Validation loss decreased (0.116055 --> 0.110116).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0868920\n",
      "\tspeed: 0.3048s/iter; left time: 929.8539s\n",
      "\titers: 200, epoch: 7 | loss: 0.0839833\n",
      "\tspeed: 0.1784s/iter; left time: 526.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.0867552 Vali Loss: 0.1057664 Test Loss: 0.1205403\n",
      "Validation loss decreased (0.110116 --> 0.105766).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0783500\n",
      "\tspeed: 0.3049s/iter; left time: 861.6592s\n",
      "\titers: 200, epoch: 8 | loss: 0.0760808\n",
      "\tspeed: 0.1784s/iter; left time: 486.3257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.0807508 Vali Loss: 0.0919362 Test Loss: 0.1027537\n",
      "Validation loss decreased (0.105766 --> 0.091936).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0665380\n",
      "\tspeed: 0.3030s/iter; left time: 788.0242s\n",
      "\titers: 200, epoch: 9 | loss: 0.0698125\n",
      "\tspeed: 0.1784s/iter; left time: 446.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0700975 Vali Loss: 0.0878155 Test Loss: 0.0955047\n",
      "Validation loss decreased (0.091936 --> 0.087816).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670919\n",
      "\tspeed: 0.3048s/iter; left time: 724.1951s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675578\n",
      "\tspeed: 0.1784s/iter; left time: 406.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.0672358 Vali Loss: 0.0894065 Test Loss: 0.0978392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0689106\n",
      "\tspeed: 0.3020s/iter; left time: 649.6365s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630242\n",
      "\tspeed: 0.1785s/iter; left time: 366.0806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.0656688 Vali Loss: 0.0876338 Test Loss: 0.0959941\n",
      "Validation loss decreased (0.087816 --> 0.087634).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0630858\n",
      "\tspeed: 0.3049s/iter; left time: 587.1660s\n",
      "\titers: 200, epoch: 12 | loss: 0.0657755\n",
      "\tspeed: 0.1785s/iter; left time: 325.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.0643023 Vali Loss: 0.0885418 Test Loss: 0.0956982\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0628766\n",
      "\tspeed: 0.3016s/iter; left time: 513.0090s\n",
      "\titers: 200, epoch: 13 | loss: 0.0634975\n",
      "\tspeed: 0.1786s/iter; left time: 285.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.0632654 Vali Loss: 0.0875201 Test Loss: 0.0952696\n",
      "Validation loss decreased (0.087634 --> 0.087520).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0649705\n",
      "\tspeed: 0.3049s/iter; left time: 450.0969s\n",
      "\titers: 200, epoch: 14 | loss: 0.0635808\n",
      "\tspeed: 0.1785s/iter; left time: 245.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.49s\n",
      "Steps: 225 | Train Loss: 0.0623501 Vali Loss: 0.0872783 Test Loss: 0.0965485\n",
      "Validation loss decreased (0.087520 --> 0.087278).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0629174\n",
      "\tspeed: 0.3053s/iter; left time: 381.9175s\n",
      "\titers: 200, epoch: 15 | loss: 0.0599513\n",
      "\tspeed: 0.1786s/iter; left time: 205.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0613816 Vali Loss: 0.0866755 Test Loss: 0.0957817\n",
      "Validation loss decreased (0.087278 --> 0.086676).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0640663\n",
      "\tspeed: 0.3057s/iter; left time: 313.6020s\n",
      "\titers: 200, epoch: 16 | loss: 0.0613522\n",
      "\tspeed: 0.1786s/iter; left time: 165.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 225 | Train Loss: 0.0608552 Vali Loss: 0.0868790 Test Loss: 0.0959475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0608349\n",
      "\tspeed: 0.3019s/iter; left time: 241.8263s\n",
      "\titers: 200, epoch: 17 | loss: 0.0592060\n",
      "\tspeed: 0.1789s/iter; left time: 125.4023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.0602201 Vali Loss: 0.0876721 Test Loss: 0.0941693\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578084\n",
      "\tspeed: 0.3013s/iter; left time: 173.5406s\n",
      "\titers: 200, epoch: 18 | loss: 0.0597996\n",
      "\tspeed: 0.1789s/iter; left time: 85.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.53s\n",
      "Steps: 225 | Train Loss: 0.0595985 Vali Loss: 0.0871657 Test Loss: 0.0960042\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0593276\n",
      "\tspeed: 0.3015s/iter; left time: 105.8393s\n",
      "\titers: 200, epoch: 19 | loss: 0.0565709\n",
      "\tspeed: 0.1788s/iter; left time: 44.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.51s\n",
      "Steps: 225 | Train Loss: 0.0591850 Vali Loss: 0.0863916 Test Loss: 0.0946068\n",
      "Validation loss decreased (0.086676 --> 0.086392).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0591992\n",
      "\tspeed: 0.3047s/iter; left time: 38.3912s\n",
      "\titers: 200, epoch: 20 | loss: 0.0577732\n",
      "\tspeed: 0.1792s/iter; left time: 4.6591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:40.59s\n",
      "Steps: 225 | Train Loss: 0.0586399 Vali Loss: 0.0866206 Test Loss: 0.0938860\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023550577461719513, rmse:0.1534619778394699, mae:0.09461454302072525, rse:0.5943727493286133\n",
      "Intermediate time for FR and pred_len 168: 00h:31m:34.76s\n",
      "Intermediate time for FR: 01h:18m:27.28s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2158962\n",
      "\tspeed: 0.1329s/iter; left time: 587.7230s\n",
      "\titers: 200, epoch: 1 | loss: 0.2014618\n",
      "\tspeed: 0.1118s/iter; left time: 483.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 226 | Train Loss: 0.2193270 Vali Loss: 0.1686699 Test Loss: 0.1882067\n",
      "Validation loss decreased (inf --> 0.168670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1294789\n",
      "\tspeed: 0.1925s/iter; left time: 807.5281s\n",
      "\titers: 200, epoch: 2 | loss: 0.0934020\n",
      "\tspeed: 0.1121s/iter; left time: 458.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.1297351 Vali Loss: 0.0805872 Test Loss: 0.0845078\n",
      "Validation loss decreased (0.168670 --> 0.080587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0874310\n",
      "\tspeed: 0.1959s/iter; left time: 777.5462s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807498\n",
      "\tspeed: 0.1121s/iter; left time: 433.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0821347 Vali Loss: 0.0740358 Test Loss: 0.0766544\n",
      "Validation loss decreased (0.080587 --> 0.074036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727209\n",
      "\tspeed: 0.1918s/iter; left time: 717.7711s\n",
      "\titers: 200, epoch: 4 | loss: 0.0690835\n",
      "\tspeed: 0.1123s/iter; left time: 409.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0726238 Vali Loss: 0.0720660 Test Loss: 0.0755553\n",
      "Validation loss decreased (0.074036 --> 0.072066).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0660740\n",
      "\tspeed: 0.1924s/iter; left time: 676.8341s\n",
      "\titers: 200, epoch: 5 | loss: 0.0707603\n",
      "\tspeed: 0.1121s/iter; left time: 383.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.64s\n",
      "Steps: 226 | Train Loss: 0.0688518 Vali Loss: 0.0674862 Test Loss: 0.0708901\n",
      "Validation loss decreased (0.072066 --> 0.067486).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0669363\n",
      "\tspeed: 0.1917s/iter; left time: 630.7892s\n",
      "\titers: 200, epoch: 6 | loss: 0.0663729\n",
      "\tspeed: 0.1121s/iter; left time: 357.8602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0662081 Vali Loss: 0.0655262 Test Loss: 0.0693448\n",
      "Validation loss decreased (0.067486 --> 0.065526).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0612544\n",
      "\tspeed: 0.1921s/iter; left time: 588.7332s\n",
      "\titers: 200, epoch: 7 | loss: 0.0609293\n",
      "\tspeed: 0.1121s/iter; left time: 332.5044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0639419 Vali Loss: 0.0636586 Test Loss: 0.0673350\n",
      "Validation loss decreased (0.065526 --> 0.063659).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0633112\n",
      "\tspeed: 0.1982s/iter; left time: 562.6744s\n",
      "\titers: 200, epoch: 8 | loss: 0.0632541\n",
      "\tspeed: 0.1121s/iter; left time: 307.0351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 226 | Train Loss: 0.0621825 Vali Loss: 0.0622119 Test Loss: 0.0661639\n",
      "Validation loss decreased (0.063659 --> 0.062212).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0620070\n",
      "\tspeed: 0.1921s/iter; left time: 501.8917s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626221\n",
      "\tspeed: 0.1121s/iter; left time: 281.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0610204 Vali Loss: 0.0599876 Test Loss: 0.0646112\n",
      "Validation loss decreased (0.062212 --> 0.059988).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0558530\n",
      "\tspeed: 0.1925s/iter; left time: 459.4027s\n",
      "\titers: 200, epoch: 10 | loss: 0.0594004\n",
      "\tspeed: 0.1122s/iter; left time: 256.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0599391 Vali Loss: 0.0605487 Test Loss: 0.0642515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0603560\n",
      "\tspeed: 0.1893s/iter; left time: 408.9953s\n",
      "\titers: 200, epoch: 11 | loss: 0.0617503\n",
      "\tspeed: 0.1121s/iter; left time: 231.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.61s\n",
      "Steps: 226 | Train Loss: 0.0589503 Vali Loss: 0.0604623 Test Loss: 0.0651384\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0570332\n",
      "\tspeed: 0.1891s/iter; left time: 365.9523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565552\n",
      "\tspeed: 0.1121s/iter; left time: 205.7792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 226 | Train Loss: 0.0579543 Vali Loss: 0.0593254 Test Loss: 0.0640660\n",
      "Validation loss decreased (0.059988 --> 0.059325).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0561131\n",
      "\tspeed: 0.1929s/iter; left time: 329.6006s\n",
      "\titers: 200, epoch: 13 | loss: 0.0573386\n",
      "\tspeed: 0.1122s/iter; left time: 180.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0575232 Vali Loss: 0.0595935 Test Loss: 0.0649850\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0548251\n",
      "\tspeed: 0.1887s/iter; left time: 279.8633s\n",
      "\titers: 200, epoch: 14 | loss: 0.0594808\n",
      "\tspeed: 0.1122s/iter; left time: 155.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0567527 Vali Loss: 0.0598983 Test Loss: 0.0637449\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580511\n",
      "\tspeed: 0.1879s/iter; left time: 236.1539s\n",
      "\titers: 200, epoch: 15 | loss: 0.0602134\n",
      "\tspeed: 0.1122s/iter; left time: 129.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 226 | Train Loss: 0.0560795 Vali Loss: 0.0594213 Test Loss: 0.0650749\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0552960\n",
      "\tspeed: 0.1898s/iter; left time: 195.7310s\n",
      "\titers: 200, epoch: 16 | loss: 0.0527199\n",
      "\tspeed: 0.1121s/iter; left time: 104.4027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0554234 Vali Loss: 0.0581660 Test Loss: 0.0625007\n",
      "Validation loss decreased (0.059325 --> 0.058166).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0556958\n",
      "\tspeed: 0.1937s/iter; left time: 155.9194s\n",
      "\titers: 200, epoch: 17 | loss: 0.0547709\n",
      "\tspeed: 0.1121s/iter; left time: 79.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0548207 Vali Loss: 0.0581324 Test Loss: 0.0626005\n",
      "Validation loss decreased (0.058166 --> 0.058132).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0541565\n",
      "\tspeed: 0.1932s/iter; left time: 111.8741s\n",
      "\titers: 200, epoch: 18 | loss: 0.0518364\n",
      "\tspeed: 0.1121s/iter; left time: 53.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0541825 Vali Loss: 0.0581470 Test Loss: 0.0627852\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0542443\n",
      "\tspeed: 0.1889s/iter; left time: 66.6710s\n",
      "\titers: 200, epoch: 19 | loss: 0.0524704\n",
      "\tspeed: 0.1121s/iter; left time: 28.3536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.52s\n",
      "Steps: 226 | Train Loss: 0.0539303 Vali Loss: 0.0578140 Test Loss: 0.0622105\n",
      "Validation loss decreased (0.058132 --> 0.057814).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0536485\n",
      "\tspeed: 0.1925s/iter; left time: 24.4416s\n",
      "\titers: 200, epoch: 20 | loss: 0.0541695\n",
      "\tspeed: 0.1120s/iter; left time: 3.0238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0534070 Vali Loss: 0.0574905 Test Loss: 0.0620287\n",
      "Validation loss decreased (0.057814 --> 0.057491).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01098212692886591, rmse:0.10479564219713211, mae:0.062085431069135666, rse:0.3959711492061615\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2215547\n",
      "\tspeed: 0.1141s/iter; left time: 504.5282s\n",
      "\titers: 200, epoch: 1 | loss: 0.2034520\n",
      "\tspeed: 0.1121s/iter; left time: 484.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.2342423 Vali Loss: 0.1748281 Test Loss: 0.1949065\n",
      "Validation loss decreased (inf --> 0.174828).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1186385\n",
      "\tspeed: 0.1926s/iter; left time: 808.0692s\n",
      "\titers: 200, epoch: 2 | loss: 0.1126382\n",
      "\tspeed: 0.1121s/iter; left time: 458.9426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.1294026 Vali Loss: 0.1082211 Test Loss: 0.1134458\n",
      "Validation loss decreased (0.174828 --> 0.108221).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982751\n",
      "\tspeed: 0.1929s/iter; left time: 765.7593s\n",
      "\titers: 200, epoch: 3 | loss: 0.0974554\n",
      "\tspeed: 0.1120s/iter; left time: 433.3980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0973456 Vali Loss: 0.0968403 Test Loss: 0.1018887\n",
      "Validation loss decreased (0.108221 --> 0.096840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870180\n",
      "\tspeed: 0.1921s/iter; left time: 719.2153s\n",
      "\titers: 200, epoch: 4 | loss: 0.0846616\n",
      "\tspeed: 0.1121s/iter; left time: 408.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0893396 Vali Loss: 0.0758719 Test Loss: 0.0792018\n",
      "Validation loss decreased (0.096840 --> 0.075872).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0728553\n",
      "\tspeed: 0.1934s/iter; left time: 680.3198s\n",
      "\titers: 200, epoch: 5 | loss: 0.0627232\n",
      "\tspeed: 0.1121s/iter; left time: 382.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0692701 Vali Loss: 0.0657285 Test Loss: 0.0711243\n",
      "Validation loss decreased (0.075872 --> 0.065729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0665109\n",
      "\tspeed: 0.1922s/iter; left time: 632.4849s\n",
      "\titers: 200, epoch: 6 | loss: 0.0654273\n",
      "\tspeed: 0.1121s/iter; left time: 357.6537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0657332 Vali Loss: 0.0640563 Test Loss: 0.0695624\n",
      "Validation loss decreased (0.065729 --> 0.064056).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0662899\n",
      "\tspeed: 0.1918s/iter; left time: 587.9831s\n",
      "\titers: 200, epoch: 7 | loss: 0.0658168\n",
      "\tspeed: 0.1121s/iter; left time: 332.4955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0636875 Vali Loss: 0.0640475 Test Loss: 0.0693156\n",
      "Validation loss decreased (0.064056 --> 0.064047).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0628824\n",
      "\tspeed: 0.1929s/iter; left time: 547.7514s\n",
      "\titers: 200, epoch: 8 | loss: 0.0609230\n",
      "\tspeed: 0.1121s/iter; left time: 307.1406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0616141 Vali Loss: 0.0619949 Test Loss: 0.0667783\n",
      "Validation loss decreased (0.064047 --> 0.061995).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0594535\n",
      "\tspeed: 0.1933s/iter; left time: 505.0600s\n",
      "\titers: 200, epoch: 9 | loss: 0.0658226\n",
      "\tspeed: 0.1121s/iter; left time: 281.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0609654 Vali Loss: 0.0605858 Test Loss: 0.0650997\n",
      "Validation loss decreased (0.061995 --> 0.060586).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0605097\n",
      "\tspeed: 0.1917s/iter; left time: 457.6685s\n",
      "\titers: 200, epoch: 10 | loss: 0.0601452\n",
      "\tspeed: 0.1121s/iter; left time: 256.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0600130 Vali Loss: 0.0618902 Test Loss: 0.0669281\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0587782\n",
      "\tspeed: 0.1896s/iter; left time: 409.7495s\n",
      "\titers: 200, epoch: 11 | loss: 0.0622356\n",
      "\tspeed: 0.1122s/iter; left time: 231.2551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0588265 Vali Loss: 0.0600056 Test Loss: 0.0653594\n",
      "Validation loss decreased (0.060586 --> 0.060006).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0604267\n",
      "\tspeed: 0.1921s/iter; left time: 371.7245s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607929\n",
      "\tspeed: 0.1121s/iter; left time: 205.7335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0581484 Vali Loss: 0.0603053 Test Loss: 0.0660117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0563073\n",
      "\tspeed: 0.1889s/iter; left time: 322.8225s\n",
      "\titers: 200, epoch: 13 | loss: 0.0583395\n",
      "\tspeed: 0.1122s/iter; left time: 180.4749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.58s\n",
      "Steps: 226 | Train Loss: 0.0575529 Vali Loss: 0.0601538 Test Loss: 0.0667217\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0581742\n",
      "\tspeed: 0.1891s/iter; left time: 280.3784s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572734\n",
      "\tspeed: 0.1122s/iter; left time: 155.1436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0568210 Vali Loss: 0.0589701 Test Loss: 0.0648577\n",
      "Validation loss decreased (0.060006 --> 0.058970).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0564280\n",
      "\tspeed: 0.1929s/iter; left time: 242.4551s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540858\n",
      "\tspeed: 0.1120s/iter; left time: 129.5849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0563176 Vali Loss: 0.0591722 Test Loss: 0.0649063\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0538036\n",
      "\tspeed: 0.1899s/iter; left time: 195.7556s\n",
      "\titers: 200, epoch: 16 | loss: 0.0550404\n",
      "\tspeed: 0.1122s/iter; left time: 104.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 226 | Train Loss: 0.0555982 Vali Loss: 0.0599838 Test Loss: 0.0647830\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0552123\n",
      "\tspeed: 0.1900s/iter; left time: 152.9339s\n",
      "\titers: 200, epoch: 17 | loss: 0.0570497\n",
      "\tspeed: 0.1122s/iter; left time: 79.0951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.63s\n",
      "Steps: 226 | Train Loss: 0.0550800 Vali Loss: 0.0589017 Test Loss: 0.0647873\n",
      "Validation loss decreased (0.058970 --> 0.058902).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0527325\n",
      "\tspeed: 0.1927s/iter; left time: 111.5802s\n",
      "\titers: 200, epoch: 18 | loss: 0.0540833\n",
      "\tspeed: 0.1122s/iter; left time: 53.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0547428 Vali Loss: 0.0590622 Test Loss: 0.0643494\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0501505\n",
      "\tspeed: 0.1891s/iter; left time: 66.7616s\n",
      "\titers: 200, epoch: 19 | loss: 0.0516510\n",
      "\tspeed: 0.1122s/iter; left time: 28.3798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 226 | Train Loss: 0.0544069 Vali Loss: 0.0584722 Test Loss: 0.0640826\n",
      "Validation loss decreased (0.058902 --> 0.058472).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0513487\n",
      "\tspeed: 0.1923s/iter; left time: 24.4270s\n",
      "\titers: 200, epoch: 20 | loss: 0.0519610\n",
      "\tspeed: 0.1122s/iter; left time: 3.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 226 | Train Loss: 0.0536308 Vali Loss: 0.0578415 Test Loss: 0.0639235\n",
      "Validation loss decreased (0.058472 --> 0.057842).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011577458120882511, rmse:0.10759859532117844, mae:0.06382088363170624, rse:0.40656211972236633\n",
      "Intermediate time for IT and pred_len 24: 00h:20m:29.16s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2246442\n",
      "\tspeed: 0.1654s/iter; left time: 731.4332s\n",
      "\titers: 200, epoch: 1 | loss: 0.2049995\n",
      "\tspeed: 0.1440s/iter; left time: 622.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:33.13s\n",
      "Steps: 226 | Train Loss: 0.2309365 Vali Loss: 0.1839862 Test Loss: 0.2022747\n",
      "Validation loss decreased (inf --> 0.183986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1647844\n",
      "\tspeed: 0.2466s/iter; left time: 1034.4750s\n",
      "\titers: 200, epoch: 2 | loss: 0.1619165\n",
      "\tspeed: 0.1440s/iter; left time: 589.6101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.79s\n",
      "Steps: 226 | Train Loss: 0.1675207 Vali Loss: 0.1578966 Test Loss: 0.1757436\n",
      "Validation loss decreased (0.183986 --> 0.157897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1520205\n",
      "\tspeed: 0.2475s/iter; left time: 982.2254s\n",
      "\titers: 200, epoch: 3 | loss: 0.1488112\n",
      "\tspeed: 0.1440s/iter; left time: 557.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 226 | Train Loss: 0.1510937 Vali Loss: 0.1496918 Test Loss: 0.1704490\n",
      "Validation loss decreased (0.157897 --> 0.149692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1430230\n",
      "\tspeed: 0.2478s/iter; left time: 927.3672s\n",
      "\titers: 200, epoch: 4 | loss: 0.1403943\n",
      "\tspeed: 0.1440s/iter; left time: 524.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.1428045 Vali Loss: 0.1386756 Test Loss: 0.1577404\n",
      "Validation loss decreased (0.149692 --> 0.138676).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1301463\n",
      "\tspeed: 0.2465s/iter; left time: 866.9046s\n",
      "\titers: 200, epoch: 5 | loss: 0.1229217\n",
      "\tspeed: 0.1441s/iter; left time: 492.4469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 226 | Train Loss: 0.1287535 Vali Loss: 0.1137412 Test Loss: 0.1273983\n",
      "Validation loss decreased (0.138676 --> 0.113741).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0959451\n",
      "\tspeed: 0.2471s/iter; left time: 813.3659s\n",
      "\titers: 200, epoch: 6 | loss: 0.0902198\n",
      "\tspeed: 0.1441s/iter; left time: 459.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0970942 Vali Loss: 0.0885270 Test Loss: 0.0952029\n",
      "Validation loss decreased (0.113741 --> 0.088527).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0882168\n",
      "\tspeed: 0.2463s/iter; left time: 754.9322s\n",
      "\titers: 200, epoch: 7 | loss: 0.0877519\n",
      "\tspeed: 0.1440s/iter; left time: 426.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 226 | Train Loss: 0.0866679 Vali Loss: 0.0824636 Test Loss: 0.0914051\n",
      "Validation loss decreased (0.088527 --> 0.082464).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0787932\n",
      "\tspeed: 0.2485s/iter; left time: 705.3917s\n",
      "\titers: 200, epoch: 8 | loss: 0.0829289\n",
      "\tspeed: 0.1440s/iter; left time: 394.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0831293 Vali Loss: 0.0828278 Test Loss: 0.0924342\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0812588\n",
      "\tspeed: 0.2431s/iter; left time: 635.3206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788470\n",
      "\tspeed: 0.1441s/iter; left time: 362.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 226 | Train Loss: 0.0809045 Vali Loss: 0.0832215 Test Loss: 0.0914407\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0779214\n",
      "\tspeed: 0.2436s/iter; left time: 581.4103s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783227\n",
      "\tspeed: 0.1440s/iter; left time: 329.4158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 226 | Train Loss: 0.0791640 Vali Loss: 0.0817541 Test Loss: 0.0883936\n",
      "Validation loss decreased (0.082464 --> 0.081754).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0771855\n",
      "\tspeed: 0.2472s/iter; left time: 534.2326s\n",
      "\titers: 200, epoch: 11 | loss: 0.0780164\n",
      "\tspeed: 0.1441s/iter; left time: 297.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0775604 Vali Loss: 0.0810173 Test Loss: 0.0901638\n",
      "Validation loss decreased (0.081754 --> 0.081017).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0800336\n",
      "\tspeed: 0.2471s/iter; left time: 478.0715s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748878\n",
      "\tspeed: 0.1441s/iter; left time: 264.4347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 226 | Train Loss: 0.0763553 Vali Loss: 0.0814387 Test Loss: 0.0901754\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0763793\n",
      "\tspeed: 0.2428s/iter; left time: 414.8841s\n",
      "\titers: 200, epoch: 13 | loss: 0.0754554\n",
      "\tspeed: 0.1441s/iter; left time: 231.8971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.77s\n",
      "Steps: 226 | Train Loss: 0.0750127 Vali Loss: 0.0808521 Test Loss: 0.0891367\n",
      "Validation loss decreased (0.081017 --> 0.080852).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0748086\n",
      "\tspeed: 0.2468s/iter; left time: 366.0504s\n",
      "\titers: 200, epoch: 14 | loss: 0.0734751\n",
      "\tspeed: 0.1441s/iter; left time: 199.2980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0739143 Vali Loss: 0.0815611 Test Loss: 0.0910621\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718157\n",
      "\tspeed: 0.2434s/iter; left time: 305.9077s\n",
      "\titers: 200, epoch: 15 | loss: 0.0716654\n",
      "\tspeed: 0.1441s/iter; left time: 166.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 226 | Train Loss: 0.0730243 Vali Loss: 0.0813766 Test Loss: 0.0899374\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0714804\n",
      "\tspeed: 0.2435s/iter; left time: 251.0408s\n",
      "\titers: 200, epoch: 16 | loss: 0.0723217\n",
      "\tspeed: 0.1441s/iter; left time: 134.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0720355 Vali Loss: 0.0819538 Test Loss: 0.0894004\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0722782\n",
      "\tspeed: 0.2442s/iter; left time: 196.5865s\n",
      "\titers: 200, epoch: 17 | loss: 0.0748913\n",
      "\tspeed: 0.1442s/iter; left time: 101.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.0713547 Vali Loss: 0.0806062 Test Loss: 0.0894318\n",
      "Validation loss decreased (0.080852 --> 0.080606).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0708856\n",
      "\tspeed: 0.2501s/iter; left time: 144.8315s\n",
      "\titers: 200, epoch: 18 | loss: 0.0695220\n",
      "\tspeed: 0.1439s/iter; left time: 68.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.86s\n",
      "Steps: 226 | Train Loss: 0.0705818 Vali Loss: 0.0818083 Test Loss: 0.0908359\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0697629\n",
      "\tspeed: 0.2461s/iter; left time: 86.8661s\n",
      "\titers: 200, epoch: 19 | loss: 0.0672547\n",
      "\tspeed: 0.1439s/iter; left time: 36.3976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 226 | Train Loss: 0.0699381 Vali Loss: 0.0821205 Test Loss: 0.0915940\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0680374\n",
      "\tspeed: 0.2451s/iter; left time: 31.1230s\n",
      "\titers: 200, epoch: 20 | loss: 0.0705516\n",
      "\tspeed: 0.1439s/iter; left time: 3.8860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 226 | Train Loss: 0.0694544 Vali Loss: 0.0813834 Test Loss: 0.0918273\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021881617605686188, rmse:0.14792436361312866, mae:0.08946646004915237, rse:0.559317946434021\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2277873\n",
      "\tspeed: 0.1457s/iter; left time: 644.2666s\n",
      "\titers: 200, epoch: 1 | loss: 0.2203927\n",
      "\tspeed: 0.1440s/iter; left time: 622.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.2383801 Vali Loss: 0.1934624 Test Loss: 0.2120840\n",
      "Validation loss decreased (inf --> 0.193462).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1582543\n",
      "\tspeed: 0.2524s/iter; left time: 1058.7579s\n",
      "\titers: 200, epoch: 2 | loss: 0.1398623\n",
      "\tspeed: 0.1440s/iter; left time: 589.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.1594804 Vali Loss: 0.1313246 Test Loss: 0.1419366\n",
      "Validation loss decreased (0.193462 --> 0.131325).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1254365\n",
      "\tspeed: 0.2484s/iter; left time: 985.7886s\n",
      "\titers: 200, epoch: 3 | loss: 0.1138366\n",
      "\tspeed: 0.1440s/iter; left time: 556.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.88s\n",
      "Steps: 226 | Train Loss: 0.1229371 Vali Loss: 0.1052538 Test Loss: 0.1138988\n",
      "Validation loss decreased (0.131325 --> 0.105254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0995191\n",
      "\tspeed: 0.2479s/iter; left time: 927.9974s\n",
      "\titers: 200, epoch: 4 | loss: 0.0953588\n",
      "\tspeed: 0.1440s/iter; left time: 524.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.1000060 Vali Loss: 0.0909799 Test Loss: 0.0964797\n",
      "Validation loss decreased (0.105254 --> 0.090980).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0933703\n",
      "\tspeed: 0.2491s/iter; left time: 876.1347s\n",
      "\titers: 200, epoch: 5 | loss: 0.0891734\n",
      "\tspeed: 0.1442s/iter; left time: 492.6271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0909051 Vali Loss: 0.0868503 Test Loss: 0.0924507\n",
      "Validation loss decreased (0.090980 --> 0.086850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910866\n",
      "\tspeed: 0.2511s/iter; left time: 826.2919s\n",
      "\titers: 200, epoch: 6 | loss: 0.0864736\n",
      "\tspeed: 0.1440s/iter; left time: 459.6616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0869045 Vali Loss: 0.0840891 Test Loss: 0.0902262\n",
      "Validation loss decreased (0.086850 --> 0.084089).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0851538\n",
      "\tspeed: 0.2482s/iter; left time: 760.8383s\n",
      "\titers: 200, epoch: 7 | loss: 0.0829387\n",
      "\tspeed: 0.1439s/iter; left time: 426.6506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 226 | Train Loss: 0.0844295 Vali Loss: 0.0825475 Test Loss: 0.0889556\n",
      "Validation loss decreased (0.084089 --> 0.082547).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0854615\n",
      "\tspeed: 0.2478s/iter; left time: 703.6064s\n",
      "\titers: 200, epoch: 8 | loss: 0.0786878\n",
      "\tspeed: 0.1441s/iter; left time: 394.8064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:32.83s\n",
      "Steps: 226 | Train Loss: 0.0821710 Vali Loss: 0.0846162 Test Loss: 0.0900662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808633\n",
      "\tspeed: 0.2438s/iter; left time: 637.0164s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780968\n",
      "\tspeed: 0.1441s/iter; left time: 362.1822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:32.81s\n",
      "Steps: 226 | Train Loss: 0.0803319 Vali Loss: 0.0839024 Test Loss: 0.0895073\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0756726\n",
      "\tspeed: 0.2442s/iter; left time: 582.9963s\n",
      "\titers: 200, epoch: 10 | loss: 0.0770281\n",
      "\tspeed: 0.1438s/iter; left time: 328.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.80s\n",
      "Steps: 226 | Train Loss: 0.0789233 Vali Loss: 0.0804089 Test Loss: 0.0888253\n",
      "Validation loss decreased (0.082547 --> 0.080409).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0784808\n",
      "\tspeed: 0.2470s/iter; left time: 533.7607s\n",
      "\titers: 200, epoch: 11 | loss: 0.0798187\n",
      "\tspeed: 0.1438s/iter; left time: 296.4546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 226 | Train Loss: 0.0777530 Vali Loss: 0.0819407 Test Loss: 0.0872668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0771632\n",
      "\tspeed: 0.2449s/iter; left time: 473.9124s\n",
      "\titers: 200, epoch: 12 | loss: 0.0760317\n",
      "\tspeed: 0.1442s/iter; left time: 264.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0763829 Vali Loss: 0.0831375 Test Loss: 0.0891417\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0725327\n",
      "\tspeed: 0.2453s/iter; left time: 419.2609s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729984\n",
      "\tspeed: 0.1439s/iter; left time: 231.5849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:32.84s\n",
      "Steps: 226 | Train Loss: 0.0753297 Vali Loss: 0.0807508 Test Loss: 0.0885105\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0740705\n",
      "\tspeed: 0.2448s/iter; left time: 362.9863s\n",
      "\titers: 200, epoch: 14 | loss: 0.0758249\n",
      "\tspeed: 0.1439s/iter; left time: 199.0024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.82s\n",
      "Steps: 226 | Train Loss: 0.0746546 Vali Loss: 0.0828449 Test Loss: 0.0894869\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0755713\n",
      "\tspeed: 0.2444s/iter; left time: 307.1650s\n",
      "\titers: 200, epoch: 15 | loss: 0.0714910\n",
      "\tspeed: 0.1444s/iter; left time: 167.0472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 226 | Train Loss: 0.0737074 Vali Loss: 0.0827445 Test Loss: 0.0890662\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02054090052843094, rmse:0.1433209776878357, mae:0.08876102417707443, rse:0.5419120192527771\n",
      "Intermediate time for IT and pred_len 96: 00h:23m:01.50s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2338964\n",
      "\tspeed: 0.1981s/iter; left time: 871.8159s\n",
      "\titers: 200, epoch: 1 | loss: 0.2079264\n",
      "\tspeed: 0.1778s/iter; left time: 764.7890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.59s\n",
      "Steps: 225 | Train Loss: 0.2333866 Vali Loss: 0.1858445 Test Loss: 0.2047770\n",
      "Validation loss decreased (inf --> 0.185845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1719575\n",
      "\tspeed: 0.3017s/iter; left time: 1259.8670s\n",
      "\titers: 200, epoch: 2 | loss: 0.1632057\n",
      "\tspeed: 0.1780s/iter; left time: 725.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.32s\n",
      "Steps: 225 | Train Loss: 0.1721146 Vali Loss: 0.1563892 Test Loss: 0.1739976\n",
      "Validation loss decreased (0.185845 --> 0.156389).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1510016\n",
      "\tspeed: 0.3024s/iter; left time: 1194.7667s\n",
      "\titers: 200, epoch: 3 | loss: 0.1432512\n",
      "\tspeed: 0.1781s/iter; left time: 685.8773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.33s\n",
      "Steps: 225 | Train Loss: 0.1514503 Vali Loss: 0.1426643 Test Loss: 0.1594612\n",
      "Validation loss decreased (0.156389 --> 0.142664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1336239\n",
      "\tspeed: 0.3033s/iter; left time: 1129.9586s\n",
      "\titers: 200, epoch: 4 | loss: 0.1245449\n",
      "\tspeed: 0.1780s/iter; left time: 645.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1331892 Vali Loss: 0.1163105 Test Loss: 0.1295479\n",
      "Validation loss decreased (0.142664 --> 0.116310).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1048497\n",
      "\tspeed: 0.3033s/iter; left time: 1061.7086s\n",
      "\titers: 200, epoch: 5 | loss: 0.0966253\n",
      "\tspeed: 0.1779s/iter; left time: 605.1238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1039548 Vali Loss: 0.0954429 Test Loss: 0.1013167\n",
      "Validation loss decreased (0.116310 --> 0.095443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0935075\n",
      "\tspeed: 0.3064s/iter; left time: 1003.7066s\n",
      "\titers: 200, epoch: 6 | loss: 0.0938159\n",
      "\tspeed: 0.1781s/iter; left time: 565.7742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.35s\n",
      "Steps: 225 | Train Loss: 0.0936747 Vali Loss: 0.0907116 Test Loss: 0.0981740\n",
      "Validation loss decreased (0.095443 --> 0.090712).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0880344\n",
      "\tspeed: 0.3027s/iter; left time: 923.6483s\n",
      "\titers: 200, epoch: 7 | loss: 0.0858405\n",
      "\tspeed: 0.1781s/iter; left time: 525.5944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0902015 Vali Loss: 0.0894151 Test Loss: 0.0968230\n",
      "Validation loss decreased (0.090712 --> 0.089415).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0882045\n",
      "\tspeed: 0.3031s/iter; left time: 856.5160s\n",
      "\titers: 200, epoch: 8 | loss: 0.0861788\n",
      "\tspeed: 0.1781s/iter; left time: 485.5594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.0878540 Vali Loss: 0.0887283 Test Loss: 0.0973109\n",
      "Validation loss decreased (0.089415 --> 0.088728).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0884519\n",
      "\tspeed: 0.3033s/iter; left time: 788.8646s\n",
      "\titers: 200, epoch: 9 | loss: 0.0822723\n",
      "\tspeed: 0.1783s/iter; left time: 445.8421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0861343 Vali Loss: 0.0870594 Test Loss: 0.0959809\n",
      "Validation loss decreased (0.088728 --> 0.087059).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0847355\n",
      "\tspeed: 0.3049s/iter; left time: 724.3345s\n",
      "\titers: 200, epoch: 10 | loss: 0.0821157\n",
      "\tspeed: 0.1782s/iter; left time: 405.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.37s\n",
      "Steps: 225 | Train Loss: 0.0841045 Vali Loss: 0.0865132 Test Loss: 0.0948414\n",
      "Validation loss decreased (0.087059 --> 0.086513).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0830729\n",
      "\tspeed: 0.3030s/iter; left time: 651.7566s\n",
      "\titers: 200, epoch: 11 | loss: 0.0826609\n",
      "\tspeed: 0.1781s/iter; left time: 365.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.0827296 Vali Loss: 0.0861081 Test Loss: 0.0959922\n",
      "Validation loss decreased (0.086513 --> 0.086108).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0791569\n",
      "\tspeed: 0.3029s/iter; left time: 583.4172s\n",
      "\titers: 200, epoch: 12 | loss: 0.0803758\n",
      "\tspeed: 0.1782s/iter; left time: 325.4716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.40s\n",
      "Steps: 225 | Train Loss: 0.0814628 Vali Loss: 0.0856612 Test Loss: 0.0962376\n",
      "Validation loss decreased (0.086108 --> 0.085661).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0790256\n",
      "\tspeed: 0.3033s/iter; left time: 515.8812s\n",
      "\titers: 200, epoch: 13 | loss: 0.0796222\n",
      "\tspeed: 0.1782s/iter; left time: 285.3457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0800322 Vali Loss: 0.0864634 Test Loss: 0.0964006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0769767\n",
      "\tspeed: 0.2995s/iter; left time: 441.9959s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786419\n",
      "\tspeed: 0.1783s/iter; left time: 245.3485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0786416 Vali Loss: 0.0854087 Test Loss: 0.0944601\n",
      "Validation loss decreased (0.085661 --> 0.085409).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0762637\n",
      "\tspeed: 0.3021s/iter; left time: 377.9099s\n",
      "\titers: 200, epoch: 15 | loss: 0.0788395\n",
      "\tspeed: 0.1782s/iter; left time: 205.0538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.32s\n",
      "Steps: 225 | Train Loss: 0.0777699 Vali Loss: 0.0874865 Test Loss: 0.0945009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0787953\n",
      "\tspeed: 0.2989s/iter; left time: 306.6475s\n",
      "\titers: 200, epoch: 16 | loss: 0.0749671\n",
      "\tspeed: 0.1782s/iter; left time: 164.9706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0768129 Vali Loss: 0.0876965 Test Loss: 0.0966550\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0758925\n",
      "\tspeed: 0.2991s/iter; left time: 239.5609s\n",
      "\titers: 200, epoch: 17 | loss: 0.0749228\n",
      "\tspeed: 0.1782s/iter; left time: 124.9126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.35s\n",
      "Steps: 225 | Train Loss: 0.0758905 Vali Loss: 0.0864865 Test Loss: 0.0946389\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0783412\n",
      "\tspeed: 0.2996s/iter; left time: 172.5565s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710729\n",
      "\tspeed: 0.1782s/iter; left time: 84.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.35s\n",
      "Steps: 225 | Train Loss: 0.0751676 Vali Loss: 0.0893811 Test Loss: 0.0953542\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733849\n",
      "\tspeed: 0.2996s/iter; left time: 105.1525s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773089\n",
      "\tspeed: 0.1783s/iter; left time: 44.7430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.36s\n",
      "Steps: 225 | Train Loss: 0.0744290 Vali Loss: 0.0890521 Test Loss: 0.0956367\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022526469081640244, rmse:0.15008820593357086, mae:0.09451047331094742, rse:0.5680270195007324\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2330348\n",
      "\tspeed: 0.1803s/iter; left time: 793.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.2122743\n",
      "\tspeed: 0.1784s/iter; left time: 767.4326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.2385129 Vali Loss: 0.1919889 Test Loss: 0.2096702\n",
      "Validation loss decreased (inf --> 0.191989).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1726521\n",
      "\tspeed: 0.3100s/iter; left time: 1294.7685s\n",
      "\titers: 200, epoch: 2 | loss: 0.1665625\n",
      "\tspeed: 0.1784s/iter; left time: 727.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.39s\n",
      "Steps: 225 | Train Loss: 0.1739605 Vali Loss: 0.1636355 Test Loss: 0.1803874\n",
      "Validation loss decreased (0.191989 --> 0.163635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1561879\n",
      "\tspeed: 0.3058s/iter; left time: 1208.1765s\n",
      "\titers: 200, epoch: 3 | loss: 0.1497312\n",
      "\tspeed: 0.1784s/iter; left time: 686.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 225 | Train Loss: 0.1569071 Vali Loss: 0.1522886 Test Loss: 0.1680278\n",
      "Validation loss decreased (0.163635 --> 0.152289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1444519\n",
      "\tspeed: 0.3032s/iter; left time: 1129.6513s\n",
      "\titers: 200, epoch: 4 | loss: 0.1299959\n",
      "\tspeed: 0.1785s/iter; left time: 647.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 225 | Train Loss: 0.1412762 Vali Loss: 0.1270953 Test Loss: 0.1415460\n",
      "Validation loss decreased (0.152289 --> 0.127095).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1096720\n",
      "\tspeed: 0.3030s/iter; left time: 1060.7918s\n",
      "\titers: 200, epoch: 5 | loss: 0.0969964\n",
      "\tspeed: 0.1785s/iter; left time: 607.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.1092365 Vali Loss: 0.0947727 Test Loss: 0.1015152\n",
      "Validation loss decreased (0.127095 --> 0.094773).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0948417\n",
      "\tspeed: 0.3029s/iter; left time: 992.3895s\n",
      "\titers: 200, epoch: 6 | loss: 0.0940093\n",
      "\tspeed: 0.1786s/iter; left time: 567.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0947388 Vali Loss: 0.0933895 Test Loss: 0.1008049\n",
      "Validation loss decreased (0.094773 --> 0.093389).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0932618\n",
      "\tspeed: 0.3062s/iter; left time: 934.1032s\n",
      "\titers: 200, epoch: 7 | loss: 0.0918676\n",
      "\tspeed: 0.1786s/iter; left time: 526.9396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.44s\n",
      "Steps: 225 | Train Loss: 0.0912245 Vali Loss: 0.0890979 Test Loss: 0.0953182\n",
      "Validation loss decreased (0.093389 --> 0.089098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0898107\n",
      "\tspeed: 0.3042s/iter; left time: 859.5380s\n",
      "\titers: 200, epoch: 8 | loss: 0.0880873\n",
      "\tspeed: 0.1785s/iter; left time: 486.7087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.50s\n",
      "Steps: 225 | Train Loss: 0.0885436 Vali Loss: 0.0876671 Test Loss: 0.0987374\n",
      "Validation loss decreased (0.089098 --> 0.087667).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0840452\n",
      "\tspeed: 0.3033s/iter; left time: 788.8950s\n",
      "\titers: 200, epoch: 9 | loss: 0.0876284\n",
      "\tspeed: 0.1786s/iter; left time: 446.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0864377 Vali Loss: 0.0879360 Test Loss: 0.0972011\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0866080\n",
      "\tspeed: 0.3007s/iter; left time: 714.4423s\n",
      "\titers: 200, epoch: 10 | loss: 0.0880062\n",
      "\tspeed: 0.1787s/iter; left time: 406.6637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0848678 Vali Loss: 0.0865804 Test Loss: 0.0934231\n",
      "Validation loss decreased (0.087667 --> 0.086580).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0816392\n",
      "\tspeed: 0.3029s/iter; left time: 651.5347s\n",
      "\titers: 200, epoch: 11 | loss: 0.0819241\n",
      "\tspeed: 0.1787s/iter; left time: 366.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.0829336 Vali Loss: 0.0873211 Test Loss: 0.0948479\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781909\n",
      "\tspeed: 0.3001s/iter; left time: 577.9084s\n",
      "\titers: 200, epoch: 12 | loss: 0.0799698\n",
      "\tspeed: 0.1787s/iter; left time: 326.2489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.0815049 Vali Loss: 0.0887449 Test Loss: 0.0945286\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0814670\n",
      "\tspeed: 0.2998s/iter; left time: 509.9683s\n",
      "\titers: 200, epoch: 13 | loss: 0.0770817\n",
      "\tspeed: 0.1788s/iter; left time: 286.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.0802723 Vali Loss: 0.0882128 Test Loss: 0.0985386\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0806501\n",
      "\tspeed: 0.3002s/iter; left time: 443.1354s\n",
      "\titers: 200, epoch: 14 | loss: 0.0764818\n",
      "\tspeed: 0.1787s/iter; left time: 245.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 225 | Train Loss: 0.0793284 Vali Loss: 0.0865217 Test Loss: 0.0932432\n",
      "Validation loss decreased (0.086580 --> 0.086522).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0794715\n",
      "\tspeed: 0.3037s/iter; left time: 379.8833s\n",
      "\titers: 200, epoch: 15 | loss: 0.0790207\n",
      "\tspeed: 0.1786s/iter; left time: 205.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 225 | Train Loss: 0.0781115 Vali Loss: 0.0871812 Test Loss: 0.0940575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0785409\n",
      "\tspeed: 0.2995s/iter; left time: 307.3357s\n",
      "\titers: 200, epoch: 16 | loss: 0.0766718\n",
      "\tspeed: 0.1787s/iter; left time: 165.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 225 | Train Loss: 0.0774712 Vali Loss: 0.0871164 Test Loss: 0.0937650\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0773272\n",
      "\tspeed: 0.3008s/iter; left time: 240.9523s\n",
      "\titers: 200, epoch: 17 | loss: 0.0739188\n",
      "\tspeed: 0.1787s/iter; left time: 125.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0764310 Vali Loss: 0.0876537 Test Loss: 0.0938412\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0744740\n",
      "\tspeed: 0.3003s/iter; left time: 172.9768s\n",
      "\titers: 200, epoch: 18 | loss: 0.0745468\n",
      "\tspeed: 0.1787s/iter; left time: 85.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.48s\n",
      "Steps: 225 | Train Loss: 0.0757741 Vali Loss: 0.0881527 Test Loss: 0.0944940\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0760728\n",
      "\tspeed: 0.3003s/iter; left time: 105.4011s\n",
      "\titers: 200, epoch: 19 | loss: 0.0732792\n",
      "\tspeed: 0.1786s/iter; left time: 44.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 225 | Train Loss: 0.0751790 Vali Loss: 0.0885867 Test Loss: 0.0928513\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023039165884256363, rmse:0.15178658068180084, mae:0.0932452604174614, rse:0.5744547247886658\n",
      "Intermediate time for IT and pred_len 168: 00h:30m:43.22s\n",
      "Intermediate time for IT: 01h:14m:13.87s\n",
      "Total time: 05h:51m:49.16s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 128 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "informer_df_itrs = pd.DataFrame(informer_results)\n",
    "\n",
    "# Set multi-index \n",
    "informer_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df_itrs.to_csv(os.path.join(path, 'informer_df_itrs_128.csv'))\n",
    "informer_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.1382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>0.1505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.0659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>0.1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.0938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0248  0.1573  0.1011\n",
       "        96         0.0509  0.2256  0.1503\n",
       "        168        0.0647  0.2538  0.1733\n",
       "ES      24         0.0202  0.1422  0.0855\n",
       "        96         0.0498  0.2231  0.1382\n",
       "        168        0.0574  0.2392  0.1505\n",
       "FR      24         0.0130  0.1138  0.0659\n",
       "        96         0.0216  0.1470  0.0885\n",
       "        168        0.0234  0.1530  0.0945\n",
       "GB      24         0.0438  0.2093  0.1365\n",
       "        96         0.0710  0.2665  0.1854\n",
       "        168        0.0725  0.2690  0.1871\n",
       "IT      24         0.0113  0.1062  0.0630\n",
       "        96         0.0212  0.1456  0.0892\n",
       "        168        0.0228  0.1510  0.0938"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final DF\n",
    "informer_df = informer_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer_128.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1552846\n",
      "\tspeed: 0.0386s/iter; left time: 169.1497s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349387\n",
      "\tspeed: 0.0171s/iter; left time: 73.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.33s\n",
      "Steps: 224 | Train Loss: 0.1540624 Vali Loss: 0.1402043 Test Loss: 0.1497415\n",
      "Validation loss decreased (inf --> 0.140204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870196\n",
      "\tspeed: 0.0377s/iter; left time: 156.6963s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852675\n",
      "\tspeed: 0.0172s/iter; left time: 69.6029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0921912 Vali Loss: 0.0948991 Test Loss: 0.0956263\n",
      "Validation loss decreased (0.140204 --> 0.094899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0780745\n",
      "\tspeed: 0.0375s/iter; left time: 147.3494s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829521\n",
      "\tspeed: 0.0172s/iter; left time: 65.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0813875 Vali Loss: 0.0914835 Test Loss: 0.0926128\n",
      "Validation loss decreased (0.094899 --> 0.091483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0763411\n",
      "\tspeed: 0.0370s/iter; left time: 137.0593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788606\n",
      "\tspeed: 0.0172s/iter; left time: 61.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0785792 Vali Loss: 0.0897479 Test Loss: 0.0915311\n",
      "Validation loss decreased (0.091483 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786201\n",
      "\tspeed: 0.0372s/iter; left time: 129.8125s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775603\n",
      "\tspeed: 0.0171s/iter; left time: 58.0130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0770201 Vali Loss: 0.0888097 Test Loss: 0.0907630\n",
      "Validation loss decreased (0.089748 --> 0.088810).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797430\n",
      "\tspeed: 0.0367s/iter; left time: 119.8188s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739905\n",
      "\tspeed: 0.0171s/iter; left time: 54.0657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0759351 Vali Loss: 0.0882563 Test Loss: 0.0899552\n",
      "Validation loss decreased (0.088810 --> 0.088256).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744912\n",
      "\tspeed: 0.0361s/iter; left time: 109.4976s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771100\n",
      "\tspeed: 0.0171s/iter; left time: 50.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0752218 Vali Loss: 0.0878177 Test Loss: 0.0892529\n",
      "Validation loss decreased (0.088256 --> 0.087818).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781358\n",
      "\tspeed: 0.0364s/iter; left time: 102.5174s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730628\n",
      "\tspeed: 0.0171s/iter; left time: 46.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0746178 Vali Loss: 0.0877714 Test Loss: 0.0892701\n",
      "Validation loss decreased (0.087818 --> 0.087771).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749489\n",
      "\tspeed: 0.0378s/iter; left time: 97.9551s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725721\n",
      "\tspeed: 0.0171s/iter; left time: 42.5431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0740126 Vali Loss: 0.0871786 Test Loss: 0.0891943\n",
      "Validation loss decreased (0.087771 --> 0.087179).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726015\n",
      "\tspeed: 0.0367s/iter; left time: 86.8023s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741761\n",
      "\tspeed: 0.0171s/iter; left time: 38.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0736832 Vali Loss: 0.0868305 Test Loss: 0.0889153\n",
      "Validation loss decreased (0.087179 --> 0.086830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685348\n",
      "\tspeed: 0.0372s/iter; left time: 79.6720s\n",
      "\titers: 200, epoch: 11 | loss: 0.0705283\n",
      "\tspeed: 0.0172s/iter; left time: 35.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0734142 Vali Loss: 0.0868541 Test Loss: 0.0888376\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0706811\n",
      "\tspeed: 0.0366s/iter; left time: 70.2452s\n",
      "\titers: 200, epoch: 12 | loss: 0.0724820\n",
      "\tspeed: 0.0171s/iter; left time: 31.0776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0730704 Vali Loss: 0.0866896 Test Loss: 0.0885880\n",
      "Validation loss decreased (0.086830 --> 0.086690).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729633\n",
      "\tspeed: 0.0369s/iter; left time: 62.4995s\n",
      "\titers: 200, epoch: 13 | loss: 0.0778621\n",
      "\tspeed: 0.0171s/iter; left time: 27.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0727560 Vali Loss: 0.0865001 Test Loss: 0.0886636\n",
      "Validation loss decreased (0.086690 --> 0.086500).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709714\n",
      "\tspeed: 0.0387s/iter; left time: 56.8315s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751399\n",
      "\tspeed: 0.0176s/iter; left time: 24.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0725595 Vali Loss: 0.0860851 Test Loss: 0.0884585\n",
      "Validation loss decreased (0.086500 --> 0.086085).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0737076\n",
      "\tspeed: 0.0386s/iter; left time: 48.0530s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740580\n",
      "\tspeed: 0.0176s/iter; left time: 20.1028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0723475 Vali Loss: 0.0862519 Test Loss: 0.0885224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741089\n",
      "\tspeed: 0.0376s/iter; left time: 38.4246s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679487\n",
      "\tspeed: 0.0176s/iter; left time: 16.1754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0722050 Vali Loss: 0.0863559 Test Loss: 0.0885100\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0714612\n",
      "\tspeed: 0.0381s/iter; left time: 30.3517s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703044\n",
      "\tspeed: 0.0178s/iter; left time: 12.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0720605 Vali Loss: 0.0860859 Test Loss: 0.0882050\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692411\n",
      "\tspeed: 0.0377s/iter; left time: 21.6031s\n",
      "\titers: 200, epoch: 18 | loss: 0.0696555\n",
      "\tspeed: 0.0175s/iter; left time: 8.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0719251 Vali Loss: 0.0860834 Test Loss: 0.0883264\n",
      "Validation loss decreased (0.086085 --> 0.086083).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0666350\n",
      "\tspeed: 0.0387s/iter; left time: 13.4968s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690289\n",
      "\tspeed: 0.0176s/iter; left time: 4.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0718146 Vali Loss: 0.0862328 Test Loss: 0.0883009\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727314\n",
      "\tspeed: 0.0387s/iter; left time: 4.8361s\n",
      "\titers: 200, epoch: 20 | loss: 0.0679560\n",
      "\tspeed: 0.0176s/iter; left time: 0.4397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0717518 Vali Loss: 0.0859731 Test Loss: 0.0882746\n",
      "Validation loss decreased (0.086083 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0210769884288311, rmse:0.1451791524887085, mae:0.08827455341815948, rse:0.5123573541641235\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1570233\n",
      "\tspeed: 0.0199s/iter; left time: 86.9701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1280985\n",
      "\tspeed: 0.0176s/iter; left time: 75.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1548676 Vali Loss: 0.1411604 Test Loss: 0.1500474\n",
      "Validation loss decreased (inf --> 0.141160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0882181\n",
      "\tspeed: 0.0378s/iter; left time: 157.1319s\n",
      "\titers: 200, epoch: 2 | loss: 0.0908060\n",
      "\tspeed: 0.0177s/iter; left time: 71.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0924610 Vali Loss: 0.0944853 Test Loss: 0.0955149\n",
      "Validation loss decreased (0.141160 --> 0.094485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0820593\n",
      "\tspeed: 0.0370s/iter; left time: 145.3278s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806413\n",
      "\tspeed: 0.0175s/iter; left time: 67.2454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0812146 Vali Loss: 0.0912485 Test Loss: 0.0926978\n",
      "Validation loss decreased (0.094485 --> 0.091248).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0721176\n",
      "\tspeed: 0.0372s/iter; left time: 138.0003s\n",
      "\titers: 200, epoch: 4 | loss: 0.0759243\n",
      "\tspeed: 0.0176s/iter; left time: 63.5519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0786283 Vali Loss: 0.0901646 Test Loss: 0.0913521\n",
      "Validation loss decreased (0.091248 --> 0.090165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0774314\n",
      "\tspeed: 0.0371s/iter; left time: 129.3976s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733740\n",
      "\tspeed: 0.0176s/iter; left time: 59.6445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0771180 Vali Loss: 0.0891310 Test Loss: 0.0905645\n",
      "Validation loss decreased (0.090165 --> 0.089131).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777217\n",
      "\tspeed: 0.0381s/iter; left time: 124.1840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0788934\n",
      "\tspeed: 0.0174s/iter; left time: 55.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0760264 Vali Loss: 0.0887408 Test Loss: 0.0903082\n",
      "Validation loss decreased (0.089131 --> 0.088741).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0783334\n",
      "\tspeed: 0.0375s/iter; left time: 113.9005s\n",
      "\titers: 200, epoch: 7 | loss: 0.0725325\n",
      "\tspeed: 0.0176s/iter; left time: 51.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0752755 Vali Loss: 0.0877701 Test Loss: 0.0896570\n",
      "Validation loss decreased (0.088741 --> 0.087770).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0791230\n",
      "\tspeed: 0.0374s/iter; left time: 105.2542s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748657\n",
      "\tspeed: 0.0176s/iter; left time: 47.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0746919 Vali Loss: 0.0874901 Test Loss: 0.0895536\n",
      "Validation loss decreased (0.087770 --> 0.087490).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736110\n",
      "\tspeed: 0.0377s/iter; left time: 97.5055s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704603\n",
      "\tspeed: 0.0176s/iter; left time: 43.7559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0741805 Vali Loss: 0.0873955 Test Loss: 0.0892691\n",
      "Validation loss decreased (0.087490 --> 0.087395).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0782311\n",
      "\tspeed: 0.0382s/iter; left time: 90.4315s\n",
      "\titers: 200, epoch: 10 | loss: 0.0763321\n",
      "\tspeed: 0.0177s/iter; left time: 40.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0737265 Vali Loss: 0.0872063 Test Loss: 0.0889933\n",
      "Validation loss decreased (0.087395 --> 0.087206).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0760693\n",
      "\tspeed: 0.0371s/iter; left time: 79.4071s\n",
      "\titers: 200, epoch: 11 | loss: 0.0712096\n",
      "\tspeed: 0.0177s/iter; left time: 36.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0734939 Vali Loss: 0.0869958 Test Loss: 0.0890277\n",
      "Validation loss decreased (0.087206 --> 0.086996).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767276\n",
      "\tspeed: 0.0374s/iter; left time: 71.7213s\n",
      "\titers: 200, epoch: 12 | loss: 0.0735241\n",
      "\tspeed: 0.0173s/iter; left time: 31.3880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0731428 Vali Loss: 0.0867699 Test Loss: 0.0890896\n",
      "Validation loss decreased (0.086996 --> 0.086770).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764216\n",
      "\tspeed: 0.0366s/iter; left time: 61.9050s\n",
      "\titers: 200, epoch: 13 | loss: 0.0709676\n",
      "\tspeed: 0.0172s/iter; left time: 27.3394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0728482 Vali Loss: 0.0863059 Test Loss: 0.0886948\n",
      "Validation loss decreased (0.086770 --> 0.086306).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0664139\n",
      "\tspeed: 0.0371s/iter; left time: 54.4901s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747447\n",
      "\tspeed: 0.0176s/iter; left time: 24.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0727029 Vali Loss: 0.0865522 Test Loss: 0.0888920\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720799\n",
      "\tspeed: 0.0370s/iter; left time: 46.0796s\n",
      "\titers: 200, epoch: 15 | loss: 0.0687887\n",
      "\tspeed: 0.0176s/iter; left time: 20.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0724657 Vali Loss: 0.0861464 Test Loss: 0.0884602\n",
      "Validation loss decreased (0.086306 --> 0.086146).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0697779\n",
      "\tspeed: 0.0374s/iter; left time: 38.1614s\n",
      "\titers: 200, epoch: 16 | loss: 0.0776083\n",
      "\tspeed: 0.0176s/iter; left time: 16.1703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0722829 Vali Loss: 0.0861370 Test Loss: 0.0884659\n",
      "Validation loss decreased (0.086146 --> 0.086137).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0755604\n",
      "\tspeed: 0.0385s/iter; left time: 30.6520s\n",
      "\titers: 200, epoch: 17 | loss: 0.0652553\n",
      "\tspeed: 0.0176s/iter; left time: 12.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0720857 Vali Loss: 0.0861050 Test Loss: 0.0884551\n",
      "Validation loss decreased (0.086137 --> 0.086105).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0759788\n",
      "\tspeed: 0.0374s/iter; left time: 21.4187s\n",
      "\titers: 200, epoch: 18 | loss: 0.0702495\n",
      "\tspeed: 0.0173s/iter; left time: 8.1992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0719627 Vali Loss: 0.0861501 Test Loss: 0.0885607\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0757058\n",
      "\tspeed: 0.0367s/iter; left time: 12.8078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721789\n",
      "\tspeed: 0.0175s/iter; left time: 4.3465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0718498 Vali Loss: 0.0861521 Test Loss: 0.0884756\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0717254\n",
      "\tspeed: 0.0365s/iter; left time: 4.5626s\n",
      "\titers: 200, epoch: 20 | loss: 0.0702315\n",
      "\tspeed: 0.0178s/iter; left time: 0.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0717969 Vali Loss: 0.0858329 Test Loss: 0.0882293\n",
      "Validation loss decreased (0.086105 --> 0.085833).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02107721008360386, rmse:0.14517992734909058, mae:0.08822928369045258, rse:0.5123600363731384\n",
      "Intermediate time for DE and pred_len 24: 00h:03m:49.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1619344\n",
      "\tspeed: 0.0377s/iter; left time: 164.9479s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504099\n",
      "\tspeed: 0.0174s/iter; left time: 74.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 224 | Train Loss: 0.1589250 Vali Loss: 0.1489491 Test Loss: 0.1608326\n",
      "Validation loss decreased (inf --> 0.148949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089703\n",
      "\tspeed: 0.0377s/iter; left time: 156.8415s\n",
      "\titers: 200, epoch: 2 | loss: 0.1149744\n",
      "\tspeed: 0.0174s/iter; left time: 70.5402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1169351 Vali Loss: 0.1223615 Test Loss: 0.1302950\n",
      "Validation loss decreased (0.148949 --> 0.122361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056557\n",
      "\tspeed: 0.0387s/iter; left time: 152.0560s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986517\n",
      "\tspeed: 0.0174s/iter; left time: 66.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1074685 Vali Loss: 0.1198070 Test Loss: 0.1282619\n",
      "Validation loss decreased (0.122361 --> 0.119807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025510\n",
      "\tspeed: 0.0376s/iter; left time: 139.5475s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046377\n",
      "\tspeed: 0.0174s/iter; left time: 62.9657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1054033 Vali Loss: 0.1191063 Test Loss: 0.1278673\n",
      "Validation loss decreased (0.119807 --> 0.119106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1038417\n",
      "\tspeed: 0.0376s/iter; left time: 131.0251s\n",
      "\titers: 200, epoch: 5 | loss: 0.1063736\n",
      "\tspeed: 0.0174s/iter; left time: 59.0648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1040633 Vali Loss: 0.1187290 Test Loss: 0.1275928\n",
      "Validation loss decreased (0.119106 --> 0.118729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1033758\n",
      "\tspeed: 0.0385s/iter; left time: 125.6103s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998508\n",
      "\tspeed: 0.0175s/iter; left time: 55.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1030631 Vali Loss: 0.1175519 Test Loss: 0.1267884\n",
      "Validation loss decreased (0.118729 --> 0.117552).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0990547\n",
      "\tspeed: 0.0379s/iter; left time: 115.2469s\n",
      "\titers: 200, epoch: 7 | loss: 0.1022646\n",
      "\tspeed: 0.0175s/iter; left time: 51.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1023639 Vali Loss: 0.1179993 Test Loss: 0.1276480\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988650\n",
      "\tspeed: 0.0375s/iter; left time: 105.5605s\n",
      "\titers: 200, epoch: 8 | loss: 0.1039498\n",
      "\tspeed: 0.0174s/iter; left time: 47.2465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1016782 Vali Loss: 0.1179397 Test Loss: 0.1280137\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008036\n",
      "\tspeed: 0.0376s/iter; left time: 97.4247s\n",
      "\titers: 200, epoch: 9 | loss: 0.1005208\n",
      "\tspeed: 0.0174s/iter; left time: 43.3190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1010756 Vali Loss: 0.1179529 Test Loss: 0.1277854\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0970302\n",
      "\tspeed: 0.0376s/iter; left time: 88.9268s\n",
      "\titers: 200, epoch: 10 | loss: 0.0986957\n",
      "\tspeed: 0.0174s/iter; left time: 39.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1004807 Vali Loss: 0.1180902 Test Loss: 0.1278614\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994967\n",
      "\tspeed: 0.0380s/iter; left time: 81.2950s\n",
      "\titers: 200, epoch: 11 | loss: 0.1038442\n",
      "\tspeed: 0.0174s/iter; left time: 35.5522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1000124 Vali Loss: 0.1173964 Test Loss: 0.1274240\n",
      "Validation loss decreased (0.117552 --> 0.117396).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996821\n",
      "\tspeed: 0.0376s/iter; left time: 72.1304s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990979\n",
      "\tspeed: 0.0174s/iter; left time: 31.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0994957 Vali Loss: 0.1176490 Test Loss: 0.1276904\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1023465\n",
      "\tspeed: 0.0376s/iter; left time: 63.5964s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957390\n",
      "\tspeed: 0.0175s/iter; left time: 27.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0990532 Vali Loss: 0.1175529 Test Loss: 0.1279353\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013488\n",
      "\tspeed: 0.0372s/iter; left time: 54.6649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959193\n",
      "\tspeed: 0.0175s/iter; left time: 23.9002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0987154 Vali Loss: 0.1176766 Test Loss: 0.1277661\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0998006\n",
      "\tspeed: 0.0372s/iter; left time: 46.2830s\n",
      "\titers: 200, epoch: 15 | loss: 0.1027932\n",
      "\tspeed: 0.0176s/iter; left time: 20.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0982760 Vali Loss: 0.1177681 Test Loss: 0.1287941\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000815\n",
      "\tspeed: 0.0381s/iter; left time: 38.8788s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991594\n",
      "\tspeed: 0.0174s/iter; left time: 15.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0979667 Vali Loss: 0.1176327 Test Loss: 0.1287536\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03713487833738327, rmse:0.19270412623882294, mae:0.12742400169372559, rse:0.6824042201042175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1629421\n",
      "\tspeed: 0.0194s/iter; left time: 85.0090s\n",
      "\titers: 200, epoch: 1 | loss: 0.1449223\n",
      "\tspeed: 0.0174s/iter; left time: 74.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1604962 Vali Loss: 0.1499582 Test Loss: 0.1620217\n",
      "Validation loss decreased (inf --> 0.149958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091688\n",
      "\tspeed: 0.0389s/iter; left time: 161.5524s\n",
      "\titers: 200, epoch: 2 | loss: 0.1061413\n",
      "\tspeed: 0.0174s/iter; left time: 70.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1169925 Vali Loss: 0.1220629 Test Loss: 0.1303540\n",
      "Validation loss decreased (0.149958 --> 0.122063).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1125579\n",
      "\tspeed: 0.0388s/iter; left time: 152.6543s\n",
      "\titers: 200, epoch: 3 | loss: 0.1056803\n",
      "\tspeed: 0.0174s/iter; left time: 66.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1075579 Vali Loss: 0.1201527 Test Loss: 0.1298505\n",
      "Validation loss decreased (0.122063 --> 0.120153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1016130\n",
      "\tspeed: 0.0382s/iter; left time: 141.8455s\n",
      "\titers: 200, epoch: 4 | loss: 0.1063603\n",
      "\tspeed: 0.0174s/iter; left time: 62.6955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1053327 Vali Loss: 0.1193292 Test Loss: 0.1300284\n",
      "Validation loss decreased (0.120153 --> 0.119329).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1039883\n",
      "\tspeed: 0.0384s/iter; left time: 133.8520s\n",
      "\titers: 200, epoch: 5 | loss: 0.1141819\n",
      "\tspeed: 0.0174s/iter; left time: 59.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1039553 Vali Loss: 0.1187222 Test Loss: 0.1288536\n",
      "Validation loss decreased (0.119329 --> 0.118722).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1036907\n",
      "\tspeed: 0.0381s/iter; left time: 124.2237s\n",
      "\titers: 200, epoch: 6 | loss: 0.0987412\n",
      "\tspeed: 0.0174s/iter; left time: 55.0298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1029148 Vali Loss: 0.1181296 Test Loss: 0.1285886\n",
      "Validation loss decreased (0.118722 --> 0.118130).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0984505\n",
      "\tspeed: 0.0382s/iter; left time: 115.9160s\n",
      "\titers: 200, epoch: 7 | loss: 0.1076829\n",
      "\tspeed: 0.0175s/iter; left time: 51.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1020770 Vali Loss: 0.1182825 Test Loss: 0.1284680\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1005999\n",
      "\tspeed: 0.0377s/iter; left time: 105.9937s\n",
      "\titers: 200, epoch: 8 | loss: 0.1040235\n",
      "\tspeed: 0.0174s/iter; left time: 47.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.1012994 Vali Loss: 0.1186805 Test Loss: 0.1291316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027327\n",
      "\tspeed: 0.0383s/iter; left time: 99.1656s\n",
      "\titers: 200, epoch: 9 | loss: 0.1049346\n",
      "\tspeed: 0.0174s/iter; left time: 43.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1006749 Vali Loss: 0.1181007 Test Loss: 0.1283150\n",
      "Validation loss decreased (0.118130 --> 0.118101).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0991371\n",
      "\tspeed: 0.0401s/iter; left time: 94.9165s\n",
      "\titers: 200, epoch: 10 | loss: 0.0956333\n",
      "\tspeed: 0.0174s/iter; left time: 39.4178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0999219 Vali Loss: 0.1180787 Test Loss: 0.1285358\n",
      "Validation loss decreased (0.118101 --> 0.118079).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0958790\n",
      "\tspeed: 0.0379s/iter; left time: 81.1053s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004438\n",
      "\tspeed: 0.0176s/iter; left time: 35.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0994439 Vali Loss: 0.1180479 Test Loss: 0.1286640\n",
      "Validation loss decreased (0.118079 --> 0.118048).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1038648\n",
      "\tspeed: 0.0378s/iter; left time: 72.3786s\n",
      "\titers: 200, epoch: 12 | loss: 0.0940785\n",
      "\tspeed: 0.0174s/iter; left time: 31.6883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0988478 Vali Loss: 0.1186219 Test Loss: 0.1295672\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0929158\n",
      "\tspeed: 0.0373s/iter; left time: 63.1928s\n",
      "\titers: 200, epoch: 13 | loss: 0.1013541\n",
      "\tspeed: 0.0174s/iter; left time: 27.7130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0983381 Vali Loss: 0.1181220 Test Loss: 0.1292001\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0962316\n",
      "\tspeed: 0.0384s/iter; left time: 56.4344s\n",
      "\titers: 200, epoch: 14 | loss: 0.0996268\n",
      "\tspeed: 0.0176s/iter; left time: 24.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0979179 Vali Loss: 0.1186127 Test Loss: 0.1297009\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0958015\n",
      "\tspeed: 0.0395s/iter; left time: 49.1659s\n",
      "\titers: 200, epoch: 15 | loss: 0.0987199\n",
      "\tspeed: 0.0175s/iter; left time: 20.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0975216 Vali Loss: 0.1186228 Test Loss: 0.1295691\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0936652\n",
      "\tspeed: 0.0388s/iter; left time: 39.6273s\n",
      "\titers: 200, epoch: 16 | loss: 0.0967917\n",
      "\tspeed: 0.0176s/iter; left time: 16.2138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0971746 Vali Loss: 0.1185344 Test Loss: 0.1296407\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03818440064787865, rmse:0.19540829956531525, mae:0.1286640465259552, rse:0.6919803023338318\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:08.50s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1628355\n",
      "\tspeed: 0.0386s/iter; left time: 168.5114s\n",
      "\titers: 200, epoch: 1 | loss: 0.1461226\n",
      "\tspeed: 0.0176s/iter; left time: 75.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.41s\n",
      "Steps: 223 | Train Loss: 0.1605776 Vali Loss: 0.1508951 Test Loss: 0.1630175\n",
      "Validation loss decreased (inf --> 0.150895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295495\n",
      "\tspeed: 0.0384s/iter; left time: 158.9452s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168577\n",
      "\tspeed: 0.0176s/iter; left time: 71.2665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1227509 Vali Loss: 0.1269903 Test Loss: 0.1363985\n",
      "Validation loss decreased (0.150895 --> 0.126990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139878\n",
      "\tspeed: 0.0411s/iter; left time: 160.8091s\n",
      "\titers: 200, epoch: 3 | loss: 0.1160950\n",
      "\tspeed: 0.0177s/iter; left time: 67.4128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1136342 Vali Loss: 0.1248411 Test Loss: 0.1347367\n",
      "Validation loss decreased (0.126990 --> 0.124841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1093246\n",
      "\tspeed: 0.0387s/iter; left time: 142.7660s\n",
      "\titers: 200, epoch: 4 | loss: 0.1123354\n",
      "\tspeed: 0.0176s/iter; left time: 63.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1113418 Vali Loss: 0.1242843 Test Loss: 0.1348724\n",
      "Validation loss decreased (0.124841 --> 0.124284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121740\n",
      "\tspeed: 0.0382s/iter; left time: 132.6832s\n",
      "\titers: 200, epoch: 5 | loss: 0.1110278\n",
      "\tspeed: 0.0176s/iter; left time: 59.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1099283 Vali Loss: 0.1237305 Test Loss: 0.1349811\n",
      "Validation loss decreased (0.124284 --> 0.123731).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062920\n",
      "\tspeed: 0.0392s/iter; left time: 127.2175s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049748\n",
      "\tspeed: 0.0177s/iter; left time: 55.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1088134 Vali Loss: 0.1234774 Test Loss: 0.1352224\n",
      "Validation loss decreased (0.123731 --> 0.123477).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020317\n",
      "\tspeed: 0.0391s/iter; left time: 118.2618s\n",
      "\titers: 200, epoch: 7 | loss: 0.1096161\n",
      "\tspeed: 0.0176s/iter; left time: 51.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1079568 Vali Loss: 0.1236840 Test Loss: 0.1353464\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1095021\n",
      "\tspeed: 0.0380s/iter; left time: 106.4613s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080197\n",
      "\tspeed: 0.0177s/iter; left time: 47.7045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1071359 Vali Loss: 0.1236301 Test Loss: 0.1354977\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036291\n",
      "\tspeed: 0.0381s/iter; left time: 98.2305s\n",
      "\titers: 200, epoch: 9 | loss: 0.1095203\n",
      "\tspeed: 0.0176s/iter; left time: 43.6362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1063827 Vali Loss: 0.1240077 Test Loss: 0.1362663\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034006\n",
      "\tspeed: 0.0383s/iter; left time: 90.2585s\n",
      "\titers: 200, epoch: 10 | loss: 0.1180468\n",
      "\tspeed: 0.0176s/iter; left time: 39.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1057231 Vali Loss: 0.1239120 Test Loss: 0.1363678\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1066202\n",
      "\tspeed: 0.0376s/iter; left time: 80.0861s\n",
      "\titers: 200, epoch: 11 | loss: 0.1106018\n",
      "\tspeed: 0.0177s/iter; left time: 35.9707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1050407 Vali Loss: 0.1239418 Test Loss: 0.1362969\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039771974086761475, rmse:0.19942912459373474, mae:0.13522249460220337, rse:0.7063939571380615\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1551516\n",
      "\tspeed: 0.0200s/iter; left time: 87.1928s\n",
      "\titers: 200, epoch: 1 | loss: 0.1452319\n",
      "\tspeed: 0.0176s/iter; left time: 74.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1597897 Vali Loss: 0.1508700 Test Loss: 0.1624745\n",
      "Validation loss decreased (inf --> 0.150870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1205210\n",
      "\tspeed: 0.0424s/iter; left time: 175.3020s\n",
      "\titers: 200, epoch: 2 | loss: 0.1155377\n",
      "\tspeed: 0.0176s/iter; left time: 71.1829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1224981 Vali Loss: 0.1261784 Test Loss: 0.1358866\n",
      "Validation loss decreased (0.150870 --> 0.126178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1154976\n",
      "\tspeed: 0.0392s/iter; left time: 153.5256s\n",
      "\titers: 200, epoch: 3 | loss: 0.1205826\n",
      "\tspeed: 0.0176s/iter; left time: 67.0342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1134431 Vali Loss: 0.1243780 Test Loss: 0.1350724\n",
      "Validation loss decreased (0.126178 --> 0.124378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1084444\n",
      "\tspeed: 0.0389s/iter; left time: 143.5099s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114469\n",
      "\tspeed: 0.0175s/iter; left time: 62.9946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1111445 Vali Loss: 0.1237809 Test Loss: 0.1348892\n",
      "Validation loss decreased (0.124378 --> 0.123781).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1089066\n",
      "\tspeed: 0.0398s/iter; left time: 138.0498s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137042\n",
      "\tspeed: 0.0176s/iter; left time: 59.1504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1096994 Vali Loss: 0.1238349 Test Loss: 0.1351202\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1059890\n",
      "\tspeed: 0.0380s/iter; left time: 123.4960s\n",
      "\titers: 200, epoch: 6 | loss: 0.1077313\n",
      "\tspeed: 0.0176s/iter; left time: 55.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1085598 Vali Loss: 0.1238074 Test Loss: 0.1351869\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1061355\n",
      "\tspeed: 0.0381s/iter; left time: 115.0556s\n",
      "\titers: 200, epoch: 7 | loss: 0.1075903\n",
      "\tspeed: 0.0176s/iter; left time: 51.3990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1075068 Vali Loss: 0.1243649 Test Loss: 0.1356606\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1056887\n",
      "\tspeed: 0.0385s/iter; left time: 107.8338s\n",
      "\titers: 200, epoch: 8 | loss: 0.1032582\n",
      "\tspeed: 0.0176s/iter; left time: 47.5355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1067399 Vali Loss: 0.1240940 Test Loss: 0.1352382\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1021452\n",
      "\tspeed: 0.0384s/iter; left time: 98.8739s\n",
      "\titers: 200, epoch: 9 | loss: 0.1055389\n",
      "\tspeed: 0.0176s/iter; left time: 43.5374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1058441 Vali Loss: 0.1242146 Test Loss: 0.1354213\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03952934965491295, rmse:0.19881989061832428, mae:0.13488918542861938, rse:0.7042360901832581\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:05.79s\n",
      "Intermediate time for DE: 00h:09m:03.76s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1414340\n",
      "\tspeed: 0.0376s/iter; left time: 164.6216s\n",
      "\titers: 200, epoch: 1 | loss: 0.1221013\n",
      "\tspeed: 0.0173s/iter; left time: 73.8638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 224 | Train Loss: 0.1394487 Vali Loss: 0.1303349 Test Loss: 0.1521696\n",
      "Validation loss decreased (inf --> 0.130335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0840514\n",
      "\tspeed: 0.0370s/iter; left time: 153.7809s\n",
      "\titers: 200, epoch: 2 | loss: 0.0808714\n",
      "\tspeed: 0.0172s/iter; left time: 69.5860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0883156 Vali Loss: 0.0921759 Test Loss: 0.1036873\n",
      "Validation loss decreased (0.130335 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803500\n",
      "\tspeed: 0.0367s/iter; left time: 144.4488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805062\n",
      "\tspeed: 0.0171s/iter; left time: 65.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0800184 Vali Loss: 0.0905325 Test Loss: 0.1025728\n",
      "Validation loss decreased (0.092176 --> 0.090532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798231\n",
      "\tspeed: 0.0370s/iter; left time: 137.3117s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777466\n",
      "\tspeed: 0.0172s/iter; left time: 61.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0784797 Vali Loss: 0.0899157 Test Loss: 0.1023136\n",
      "Validation loss decreased (0.090532 --> 0.089916).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795304\n",
      "\tspeed: 0.0367s/iter; left time: 127.8021s\n",
      "\titers: 200, epoch: 5 | loss: 0.0756811\n",
      "\tspeed: 0.0172s/iter; left time: 58.2482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0774861 Vali Loss: 0.0895856 Test Loss: 0.1022673\n",
      "Validation loss decreased (0.089916 --> 0.089586).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0745707\n",
      "\tspeed: 0.0361s/iter; left time: 117.8830s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718807\n",
      "\tspeed: 0.0172s/iter; left time: 54.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0767927 Vali Loss: 0.0892474 Test Loss: 0.1016225\n",
      "Validation loss decreased (0.089586 --> 0.089247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763125\n",
      "\tspeed: 0.0362s/iter; left time: 109.9274s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761305\n",
      "\tspeed: 0.0171s/iter; left time: 50.3377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0762174 Vali Loss: 0.0889595 Test Loss: 0.1021078\n",
      "Validation loss decreased (0.089247 --> 0.088960).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740032\n",
      "\tspeed: 0.0380s/iter; left time: 106.7556s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748307\n",
      "\tspeed: 0.0172s/iter; left time: 46.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0758005 Vali Loss: 0.0888929 Test Loss: 0.1011652\n",
      "Validation loss decreased (0.088960 --> 0.088893).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0772215\n",
      "\tspeed: 0.0359s/iter; left time: 93.0665s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779016\n",
      "\tspeed: 0.0172s/iter; left time: 42.6890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0754587 Vali Loss: 0.0887787 Test Loss: 0.1017626\n",
      "Validation loss decreased (0.088893 --> 0.088779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781136\n",
      "\tspeed: 0.0369s/iter; left time: 87.1581s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792562\n",
      "\tspeed: 0.0172s/iter; left time: 38.9402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0750786 Vali Loss: 0.0883456 Test Loss: 0.1013593\n",
      "Validation loss decreased (0.088779 --> 0.088346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0763240\n",
      "\tspeed: 0.0362s/iter; left time: 77.4065s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766105\n",
      "\tspeed: 0.0172s/iter; left time: 35.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0748253 Vali Loss: 0.0884376 Test Loss: 0.1009040\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720343\n",
      "\tspeed: 0.0368s/iter; left time: 70.5606s\n",
      "\titers: 200, epoch: 12 | loss: 0.0749820\n",
      "\tspeed: 0.0171s/iter; left time: 31.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0745866 Vali Loss: 0.0884318 Test Loss: 0.1014207\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764522\n",
      "\tspeed: 0.0362s/iter; left time: 61.2742s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720733\n",
      "\tspeed: 0.0171s/iter; left time: 27.2795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0743763 Vali Loss: 0.0881860 Test Loss: 0.1007518\n",
      "Validation loss decreased (0.088346 --> 0.088186).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0781043\n",
      "\tspeed: 0.0375s/iter; left time: 55.1082s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749587\n",
      "\tspeed: 0.0172s/iter; left time: 23.4889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0742807 Vali Loss: 0.0881734 Test Loss: 0.1011914\n",
      "Validation loss decreased (0.088186 --> 0.088173).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0691805\n",
      "\tspeed: 0.0368s/iter; left time: 45.8291s\n",
      "\titers: 200, epoch: 15 | loss: 0.0790325\n",
      "\tspeed: 0.0172s/iter; left time: 19.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0741194 Vali Loss: 0.0882669 Test Loss: 0.1008864\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723666\n",
      "\tspeed: 0.0362s/iter; left time: 36.9924s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744868\n",
      "\tspeed: 0.0172s/iter; left time: 15.8018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0739220 Vali Loss: 0.0880005 Test Loss: 0.1011248\n",
      "Validation loss decreased (0.088173 --> 0.088000).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0806842\n",
      "\tspeed: 0.0366s/iter; left time: 29.1805s\n",
      "\titers: 200, epoch: 17 | loss: 0.0699300\n",
      "\tspeed: 0.0172s/iter; left time: 11.9636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0737822 Vali Loss: 0.0880966 Test Loss: 0.1010500\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789800\n",
      "\tspeed: 0.0358s/iter; left time: 20.5026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703603\n",
      "\tspeed: 0.0171s/iter; left time: 8.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0736363 Vali Loss: 0.0880285 Test Loss: 0.1005919\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718165\n",
      "\tspeed: 0.0362s/iter; left time: 12.6340s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751730\n",
      "\tspeed: 0.0172s/iter; left time: 4.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0735602 Vali Loss: 0.0878067 Test Loss: 0.1006212\n",
      "Validation loss decreased (0.088000 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748918\n",
      "\tspeed: 0.0368s/iter; left time: 4.6028s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692953\n",
      "\tspeed: 0.0171s/iter; left time: 0.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734651 Vali Loss: 0.0879854 Test Loss: 0.1006300\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025700200349092484, rmse:0.16031281650066376, mae:0.10062122344970703, rse:0.5530337691307068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1422009\n",
      "\tspeed: 0.0191s/iter; left time: 83.5473s\n",
      "\titers: 200, epoch: 1 | loss: 0.1200285\n",
      "\tspeed: 0.0171s/iter; left time: 73.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.1414123 Vali Loss: 0.1313294 Test Loss: 0.1529285\n",
      "Validation loss decreased (inf --> 0.131329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922377\n",
      "\tspeed: 0.0372s/iter; left time: 154.4811s\n",
      "\titers: 200, epoch: 2 | loss: 0.0919798\n",
      "\tspeed: 0.0173s/iter; left time: 70.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0886869 Vali Loss: 0.0919450 Test Loss: 0.1033028\n",
      "Validation loss decreased (0.131329 --> 0.091945).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0748871\n",
      "\tspeed: 0.0362s/iter; left time: 142.5595s\n",
      "\titers: 200, epoch: 3 | loss: 0.0777108\n",
      "\tspeed: 0.0171s/iter; left time: 65.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0799962 Vali Loss: 0.0908523 Test Loss: 0.1022962\n",
      "Validation loss decreased (0.091945 --> 0.090852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786184\n",
      "\tspeed: 0.0363s/iter; left time: 134.6324s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803857\n",
      "\tspeed: 0.0172s/iter; left time: 61.9744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0784213 Vali Loss: 0.0900642 Test Loss: 0.1022148\n",
      "Validation loss decreased (0.090852 --> 0.090064).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0738037\n",
      "\tspeed: 0.0362s/iter; left time: 126.0584s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784855\n",
      "\tspeed: 0.0171s/iter; left time: 58.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0774722 Vali Loss: 0.0897736 Test Loss: 0.1024334\n",
      "Validation loss decreased (0.090064 --> 0.089774).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0762075\n",
      "\tspeed: 0.0361s/iter; left time: 117.7522s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760078\n",
      "\tspeed: 0.0172s/iter; left time: 54.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0767708 Vali Loss: 0.0894914 Test Loss: 0.1016460\n",
      "Validation loss decreased (0.089774 --> 0.089491).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0769813\n",
      "\tspeed: 0.0367s/iter; left time: 111.4068s\n",
      "\titers: 200, epoch: 7 | loss: 0.0738989\n",
      "\tspeed: 0.0172s/iter; left time: 50.4375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0761804 Vali Loss: 0.0888315 Test Loss: 0.1016231\n",
      "Validation loss decreased (0.089491 --> 0.088831).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770518\n",
      "\tspeed: 0.0362s/iter; left time: 101.9397s\n",
      "\titers: 200, epoch: 8 | loss: 0.0699307\n",
      "\tspeed: 0.0172s/iter; left time: 46.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0757875 Vali Loss: 0.0889037 Test Loss: 0.1016399\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742829\n",
      "\tspeed: 0.0357s/iter; left time: 92.4262s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798777\n",
      "\tspeed: 0.0171s/iter; left time: 42.5765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0754156 Vali Loss: 0.0887733 Test Loss: 0.1010946\n",
      "Validation loss decreased (0.088831 --> 0.088773).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0693498\n",
      "\tspeed: 0.0359s/iter; left time: 84.9851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0747973\n",
      "\tspeed: 0.0172s/iter; left time: 38.9137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0751455 Vali Loss: 0.0890305 Test Loss: 0.1011741\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0776062\n",
      "\tspeed: 0.0356s/iter; left time: 76.2751s\n",
      "\titers: 200, epoch: 11 | loss: 0.0710389\n",
      "\tspeed: 0.0172s/iter; left time: 35.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0748430 Vali Loss: 0.0885079 Test Loss: 0.1005311\n",
      "Validation loss decreased (0.088773 --> 0.088508).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774497\n",
      "\tspeed: 0.0362s/iter; left time: 69.4721s\n",
      "\titers: 200, epoch: 12 | loss: 0.0763883\n",
      "\tspeed: 0.0172s/iter; left time: 31.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0746614 Vali Loss: 0.0886720 Test Loss: 0.1007122\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738585\n",
      "\tspeed: 0.0357s/iter; left time: 60.4062s\n",
      "\titers: 200, epoch: 13 | loss: 0.0666320\n",
      "\tspeed: 0.0172s/iter; left time: 27.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0743507 Vali Loss: 0.0881569 Test Loss: 0.1011065\n",
      "Validation loss decreased (0.088508 --> 0.088157).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715535\n",
      "\tspeed: 0.0370s/iter; left time: 54.4190s\n",
      "\titers: 200, epoch: 14 | loss: 0.0718102\n",
      "\tspeed: 0.0171s/iter; left time: 23.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0742120 Vali Loss: 0.0883131 Test Loss: 0.1009890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0764904\n",
      "\tspeed: 0.0359s/iter; left time: 44.6822s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760919\n",
      "\tspeed: 0.0171s/iter; left time: 19.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0740144 Vali Loss: 0.0880940 Test Loss: 0.1007358\n",
      "Validation loss decreased (0.088157 --> 0.088094).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715841\n",
      "\tspeed: 0.0363s/iter; left time: 37.0853s\n",
      "\titers: 200, epoch: 16 | loss: 0.0754959\n",
      "\tspeed: 0.0171s/iter; left time: 15.7798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0738687 Vali Loss: 0.0881185 Test Loss: 0.1006489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0757043\n",
      "\tspeed: 0.0360s/iter; left time: 28.6693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0710046\n",
      "\tspeed: 0.0172s/iter; left time: 11.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0737722 Vali Loss: 0.0879211 Test Loss: 0.1009671\n",
      "Validation loss decreased (0.088094 --> 0.087921).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0715606\n",
      "\tspeed: 0.0361s/iter; left time: 20.6916s\n",
      "\titers: 200, epoch: 18 | loss: 0.0714183\n",
      "\tspeed: 0.0171s/iter; left time: 8.1036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0736600 Vali Loss: 0.0879440 Test Loss: 0.1007076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0691574\n",
      "\tspeed: 0.0358s/iter; left time: 12.4911s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773228\n",
      "\tspeed: 0.0172s/iter; left time: 4.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0735008 Vali Loss: 0.0879841 Test Loss: 0.1003970\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747810\n",
      "\tspeed: 0.0360s/iter; left time: 4.5033s\n",
      "\titers: 200, epoch: 20 | loss: 0.0733762\n",
      "\tspeed: 0.0172s/iter; left time: 0.4293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0734122 Vali Loss: 0.0880092 Test Loss: 0.1003906\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02568984590470791, rmse:0.1602805256843567, mae:0.10096710920333862, rse:0.5529223680496216\n",
      "Intermediate time for GB and pred_len 24: 00h:03m:44.17s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1466275\n",
      "\tspeed: 0.0390s/iter; left time: 170.6765s\n",
      "\titers: 200, epoch: 1 | loss: 0.1337850\n",
      "\tspeed: 0.0177s/iter; left time: 75.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 224 | Train Loss: 0.1435828 Vali Loss: 0.1385492 Test Loss: 0.1633576\n",
      "Validation loss decreased (inf --> 0.138549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1104258\n",
      "\tspeed: 0.0380s/iter; left time: 157.9074s\n",
      "\titers: 200, epoch: 2 | loss: 0.1112381\n",
      "\tspeed: 0.0175s/iter; left time: 71.0256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1108078 Vali Loss: 0.1185432 Test Loss: 0.1400204\n",
      "Validation loss decreased (0.138549 --> 0.118543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055267\n",
      "\tspeed: 0.0388s/iter; left time: 152.7872s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024510\n",
      "\tspeed: 0.0175s/iter; left time: 67.1051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1047173 Vali Loss: 0.1173792 Test Loss: 0.1411833\n",
      "Validation loss decreased (0.118543 --> 0.117379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1010584\n",
      "\tspeed: 0.0386s/iter; left time: 143.2510s\n",
      "\titers: 200, epoch: 4 | loss: 0.1023916\n",
      "\tspeed: 0.0176s/iter; left time: 63.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1031035 Vali Loss: 0.1173137 Test Loss: 0.1412240\n",
      "Validation loss decreased (0.117379 --> 0.117314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018159\n",
      "\tspeed: 0.0397s/iter; left time: 138.2124s\n",
      "\titers: 200, epoch: 5 | loss: 0.1006902\n",
      "\tspeed: 0.0175s/iter; left time: 59.3728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.1020479 Vali Loss: 0.1172939 Test Loss: 0.1422832\n",
      "Validation loss decreased (0.117314 --> 0.117294).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1007758\n",
      "\tspeed: 0.0389s/iter; left time: 126.8225s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994306\n",
      "\tspeed: 0.0174s/iter; left time: 55.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1009951 Vali Loss: 0.1164035 Test Loss: 0.1401911\n",
      "Validation loss decreased (0.117294 --> 0.116403).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036470\n",
      "\tspeed: 0.0379s/iter; left time: 115.1075s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978406\n",
      "\tspeed: 0.0176s/iter; left time: 51.5931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1001050 Vali Loss: 0.1163152 Test Loss: 0.1423407\n",
      "Validation loss decreased (0.116403 --> 0.116315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0974191\n",
      "\tspeed: 0.0380s/iter; left time: 106.9084s\n",
      "\titers: 200, epoch: 8 | loss: 0.1014476\n",
      "\tspeed: 0.0175s/iter; left time: 47.5436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0992137 Vali Loss: 0.1164122 Test Loss: 0.1430775\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0985387\n",
      "\tspeed: 0.0375s/iter; left time: 97.0764s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965922\n",
      "\tspeed: 0.0172s/iter; left time: 42.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0984681 Vali Loss: 0.1171481 Test Loss: 0.1426953\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0963279\n",
      "\tspeed: 0.0383s/iter; left time: 90.5825s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998888\n",
      "\tspeed: 0.0175s/iter; left time: 39.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0978281 Vali Loss: 0.1175429 Test Loss: 0.1437618\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0968340\n",
      "\tspeed: 0.0386s/iter; left time: 82.7142s\n",
      "\titers: 200, epoch: 11 | loss: 0.1017763\n",
      "\tspeed: 0.0176s/iter; left time: 36.0105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0972433 Vali Loss: 0.1171132 Test Loss: 0.1428917\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0951716\n",
      "\tspeed: 0.0381s/iter; left time: 73.0416s\n",
      "\titers: 200, epoch: 12 | loss: 0.0948278\n",
      "\tspeed: 0.0177s/iter; left time: 32.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0967977 Vali Loss: 0.1174284 Test Loss: 0.1440489\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043783560395240784, rmse:0.2092452198266983, mae:0.14234068989753723, rse:0.7235991358757019\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1440759\n",
      "\tspeed: 0.0204s/iter; left time: 89.3097s\n",
      "\titers: 200, epoch: 1 | loss: 0.1328751\n",
      "\tspeed: 0.0175s/iter; left time: 75.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1449540 Vali Loss: 0.1393136 Test Loss: 0.1642298\n",
      "Validation loss decreased (inf --> 0.139314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1102223\n",
      "\tspeed: 0.0397s/iter; left time: 165.1439s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079791\n",
      "\tspeed: 0.0176s/iter; left time: 71.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.1110439 Vali Loss: 0.1183170 Test Loss: 0.1403053\n",
      "Validation loss decreased (0.139314 --> 0.118317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1059737\n",
      "\tspeed: 0.0393s/iter; left time: 154.4078s\n",
      "\titers: 200, epoch: 3 | loss: 0.1034809\n",
      "\tspeed: 0.0176s/iter; left time: 67.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.1046243 Vali Loss: 0.1172979 Test Loss: 0.1405665\n",
      "Validation loss decreased (0.118317 --> 0.117298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1017363\n",
      "\tspeed: 0.0398s/iter; left time: 147.7825s\n",
      "\titers: 200, epoch: 4 | loss: 0.1028161\n",
      "\tspeed: 0.0176s/iter; left time: 63.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1028885 Vali Loss: 0.1164917 Test Loss: 0.1403750\n",
      "Validation loss decreased (0.117298 --> 0.116492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0997417\n",
      "\tspeed: 0.0474s/iter; left time: 165.2830s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999667\n",
      "\tspeed: 0.0175s/iter; left time: 59.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.1016265 Vali Loss: 0.1166197 Test Loss: 0.1419718\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1000853\n",
      "\tspeed: 0.0401s/iter; left time: 130.7600s\n",
      "\titers: 200, epoch: 6 | loss: 0.1028287\n",
      "\tspeed: 0.0175s/iter; left time: 55.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1004530 Vali Loss: 0.1165940 Test Loss: 0.1414203\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1026894\n",
      "\tspeed: 0.0394s/iter; left time: 119.5488s\n",
      "\titers: 200, epoch: 7 | loss: 0.0959040\n",
      "\tspeed: 0.0176s/iter; left time: 51.6095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0994967 Vali Loss: 0.1165230 Test Loss: 0.1413475\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995387\n",
      "\tspeed: 0.0387s/iter; left time: 108.9935s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041096\n",
      "\tspeed: 0.0176s/iter; left time: 47.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0985223 Vali Loss: 0.1168115 Test Loss: 0.1421495\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1005742\n",
      "\tspeed: 0.0387s/iter; left time: 100.1714s\n",
      "\titers: 200, epoch: 9 | loss: 0.1009817\n",
      "\tspeed: 0.0176s/iter; left time: 43.7209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0977647 Vali Loss: 0.1178261 Test Loss: 0.1428408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04229957237839699, rmse:0.2056685984134674, mae:0.14037492871284485, rse:0.7112306952476501\n",
      "Intermediate time for GB and pred_len 96: 00h:02m:09.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1476450\n",
      "\tspeed: 0.0394s/iter; left time: 172.0233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1322379\n",
      "\tspeed: 0.0176s/iter; left time: 74.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1446634 Vali Loss: 0.1403988 Test Loss: 0.1657538\n",
      "Validation loss decreased (inf --> 0.140399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1181542\n",
      "\tspeed: 0.0387s/iter; left time: 160.1993s\n",
      "\titers: 200, epoch: 2 | loss: 0.1103590\n",
      "\tspeed: 0.0176s/iter; left time: 70.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1153974 Vali Loss: 0.1230213 Test Loss: 0.1469014\n",
      "Validation loss decreased (0.140399 --> 0.123021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1078933\n",
      "\tspeed: 0.0390s/iter; left time: 152.8634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1094684\n",
      "\tspeed: 0.0173s/iter; left time: 66.0707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1095194 Vali Loss: 0.1215952 Test Loss: 0.1471972\n",
      "Validation loss decreased (0.123021 --> 0.121595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068714\n",
      "\tspeed: 0.0400s/iter; left time: 147.6835s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091786\n",
      "\tspeed: 0.0175s/iter; left time: 62.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1077170 Vali Loss: 0.1219872 Test Loss: 0.1488043\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074749\n",
      "\tspeed: 0.0391s/iter; left time: 135.4877s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072562\n",
      "\tspeed: 0.0175s/iter; left time: 58.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1063439 Vali Loss: 0.1214106 Test Loss: 0.1474847\n",
      "Validation loss decreased (0.121595 --> 0.121411).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1031363\n",
      "\tspeed: 0.0404s/iter; left time: 131.2125s\n",
      "\titers: 200, epoch: 6 | loss: 0.1033070\n",
      "\tspeed: 0.0175s/iter; left time: 55.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1048237 Vali Loss: 0.1214159 Test Loss: 0.1477327\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015336\n",
      "\tspeed: 0.0395s/iter; left time: 119.3526s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040114\n",
      "\tspeed: 0.0180s/iter; left time: 52.5328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1036718 Vali Loss: 0.1211991 Test Loss: 0.1474411\n",
      "Validation loss decreased (0.121411 --> 0.121199).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045649\n",
      "\tspeed: 0.0402s/iter; left time: 112.6007s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997393\n",
      "\tspeed: 0.0180s/iter; left time: 48.4673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.28s\n",
      "Steps: 223 | Train Loss: 0.1027916 Vali Loss: 0.1215216 Test Loss: 0.1471704\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1015813\n",
      "\tspeed: 0.0397s/iter; left time: 102.4155s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016080\n",
      "\tspeed: 0.0176s/iter; left time: 43.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1020035 Vali Loss: 0.1216637 Test Loss: 0.1498252\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1022068\n",
      "\tspeed: 0.0382s/iter; left time: 90.0211s\n",
      "\titers: 200, epoch: 10 | loss: 0.1057559\n",
      "\tspeed: 0.0175s/iter; left time: 39.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1014043 Vali Loss: 0.1225466 Test Loss: 0.1508662\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1012574\n",
      "\tspeed: 0.0382s/iter; left time: 81.3747s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064127\n",
      "\tspeed: 0.0174s/iter; left time: 35.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1008412 Vali Loss: 0.1222213 Test Loss: 0.1478938\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0995592\n",
      "\tspeed: 0.0382s/iter; left time: 72.9362s\n",
      "\titers: 200, epoch: 12 | loss: 0.1017008\n",
      "\tspeed: 0.0177s/iter; left time: 31.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1004033 Vali Loss: 0.1223581 Test Loss: 0.1499430\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04548247531056404, rmse:0.21326620876789093, mae:0.14744102954864502, rse:0.7394245862960815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1443954\n",
      "\tspeed: 0.0199s/iter; left time: 86.6705s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329396\n",
      "\tspeed: 0.0174s/iter; left time: 74.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1444746 Vali Loss: 0.1397851 Test Loss: 0.1651123\n",
      "Validation loss decreased (inf --> 0.139785).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1152997\n",
      "\tspeed: 0.0404s/iter; left time: 167.3385s\n",
      "\titers: 200, epoch: 2 | loss: 0.1154610\n",
      "\tspeed: 0.0180s/iter; left time: 72.5843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1152647 Vali Loss: 0.1229733 Test Loss: 0.1469299\n",
      "Validation loss decreased (0.139785 --> 0.122973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091522\n",
      "\tspeed: 0.0411s/iter; left time: 160.9824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1074008\n",
      "\tspeed: 0.0180s/iter; left time: 68.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.29s\n",
      "Steps: 223 | Train Loss: 0.1093979 Vali Loss: 0.1222026 Test Loss: 0.1474644\n",
      "Validation loss decreased (0.122973 --> 0.122203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1105969\n",
      "\tspeed: 0.0395s/iter; left time: 145.6556s\n",
      "\titers: 200, epoch: 4 | loss: 0.1092896\n",
      "\tspeed: 0.0174s/iter; left time: 62.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 223 | Train Loss: 0.1075571 Vali Loss: 0.1213144 Test Loss: 0.1466673\n",
      "Validation loss decreased (0.122203 --> 0.121314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1026646\n",
      "\tspeed: 0.0415s/iter; left time: 144.0521s\n",
      "\titers: 200, epoch: 5 | loss: 0.1054192\n",
      "\tspeed: 0.0174s/iter; left time: 58.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.44s\n",
      "Steps: 223 | Train Loss: 0.1060407 Vali Loss: 0.1211272 Test Loss: 0.1483335\n",
      "Validation loss decreased (0.121314 --> 0.121127).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1051621\n",
      "\tspeed: 0.0392s/iter; left time: 127.3985s\n",
      "\titers: 200, epoch: 6 | loss: 0.1033786\n",
      "\tspeed: 0.0177s/iter; left time: 55.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1045825 Vali Loss: 0.1220101 Test Loss: 0.1496769\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1046920\n",
      "\tspeed: 0.0399s/iter; left time: 120.5473s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026492\n",
      "\tspeed: 0.0179s/iter; left time: 52.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1035206 Vali Loss: 0.1215435 Test Loss: 0.1485344\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1016812\n",
      "\tspeed: 0.0404s/iter; left time: 113.1318s\n",
      "\titers: 200, epoch: 8 | loss: 0.1051641\n",
      "\tspeed: 0.0180s/iter; left time: 48.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.1025836 Vali Loss: 0.1214356 Test Loss: 0.1485675\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1025469\n",
      "\tspeed: 0.0402s/iter; left time: 103.7101s\n",
      "\titers: 200, epoch: 9 | loss: 0.0990375\n",
      "\tspeed: 0.0179s/iter; left time: 44.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1018556 Vali Loss: 0.1213479 Test Loss: 0.1500267\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0973733\n",
      "\tspeed: 0.0400s/iter; left time: 94.2096s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971824\n",
      "\tspeed: 0.0176s/iter; left time: 39.6195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1011464 Vali Loss: 0.1214701 Test Loss: 0.1500645\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0455465130507946, rmse:0.21341629326343536, mae:0.14833343029022217, rse:0.7399449348449707\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:19.33s\n",
      "Intermediate time for GB: 00h:08m:13.48s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1494770\n",
      "\tspeed: 0.0317s/iter; left time: 139.0300s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274537\n",
      "\tspeed: 0.0114s/iter; left time: 48.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.1528605 Vali Loss: 0.1144877 Test Loss: 0.1285769\n",
      "Validation loss decreased (inf --> 0.114488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765437\n",
      "\tspeed: 0.0273s/iter; left time: 113.4174s\n",
      "\titers: 200, epoch: 2 | loss: 0.0665579\n",
      "\tspeed: 0.0114s/iter; left time: 46.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0811992 Vali Loss: 0.0652718 Test Loss: 0.0723863\n",
      "Validation loss decreased (0.114488 --> 0.065272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697450\n",
      "\tspeed: 0.0267s/iter; left time: 104.9098s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660162\n",
      "\tspeed: 0.0113s/iter; left time: 43.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0678131 Vali Loss: 0.0617073 Test Loss: 0.0685091\n",
      "Validation loss decreased (0.065272 --> 0.061707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611825\n",
      "\tspeed: 0.0267s/iter; left time: 99.2155s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663184\n",
      "\tspeed: 0.0113s/iter; left time: 40.8007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0643569 Vali Loss: 0.0592894 Test Loss: 0.0658884\n",
      "Validation loss decreased (0.061707 --> 0.059289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620450\n",
      "\tspeed: 0.0275s/iter; left time: 95.6716s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624085\n",
      "\tspeed: 0.0113s/iter; left time: 38.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0622190 Vali Loss: 0.0580893 Test Loss: 0.0645561\n",
      "Validation loss decreased (0.059289 --> 0.058089).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605343\n",
      "\tspeed: 0.0262s/iter; left time: 85.4232s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587551\n",
      "\tspeed: 0.0113s/iter; left time: 35.7225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0572285 Test Loss: 0.0637012\n",
      "Validation loss decreased (0.058089 --> 0.057228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607917\n",
      "\tspeed: 0.0276s/iter; left time: 83.8662s\n",
      "\titers: 200, epoch: 7 | loss: 0.0628559\n",
      "\tspeed: 0.0114s/iter; left time: 33.4093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0597911 Vali Loss: 0.0568611 Test Loss: 0.0632574\n",
      "Validation loss decreased (0.057228 --> 0.056861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585717\n",
      "\tspeed: 0.0273s/iter; left time: 76.7984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590016\n",
      "\tspeed: 0.0113s/iter; left time: 30.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0589440 Vali Loss: 0.0562228 Test Loss: 0.0624446\n",
      "Validation loss decreased (0.056861 --> 0.056223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570429\n",
      "\tspeed: 0.0273s/iter; left time: 70.6142s\n",
      "\titers: 200, epoch: 9 | loss: 0.0550695\n",
      "\tspeed: 0.0113s/iter; left time: 28.1637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0582554 Vali Loss: 0.0558884 Test Loss: 0.0622871\n",
      "Validation loss decreased (0.056223 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585720\n",
      "\tspeed: 0.0269s/iter; left time: 63.6232s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569206\n",
      "\tspeed: 0.0113s/iter; left time: 25.5959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0577634 Vali Loss: 0.0553971 Test Loss: 0.0617752\n",
      "Validation loss decreased (0.055888 --> 0.055397).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0591369\n",
      "\tspeed: 0.0270s/iter; left time: 57.7607s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592699\n",
      "\tspeed: 0.0112s/iter; left time: 22.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0572746 Vali Loss: 0.0550906 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.055397 --> 0.055091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0612531\n",
      "\tspeed: 0.0269s/iter; left time: 51.4909s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553235\n",
      "\tspeed: 0.0113s/iter; left time: 20.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0567800 Vali Loss: 0.0550882 Test Loss: 0.0614859\n",
      "Validation loss decreased (0.055091 --> 0.055088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0574471\n",
      "\tspeed: 0.0269s/iter; left time: 45.5146s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576361\n",
      "\tspeed: 0.0113s/iter; left time: 18.0090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0565321 Vali Loss: 0.0548449 Test Loss: 0.0614008\n",
      "Validation loss decreased (0.055088 --> 0.054845).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0557640\n",
      "\tspeed: 0.0269s/iter; left time: 39.4663s\n",
      "\titers: 200, epoch: 14 | loss: 0.0564044\n",
      "\tspeed: 0.0114s/iter; left time: 15.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0562479 Vali Loss: 0.0548242 Test Loss: 0.0611537\n",
      "Validation loss decreased (0.054845 --> 0.054824).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533020\n",
      "\tspeed: 0.0279s/iter; left time: 34.6767s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543857\n",
      "\tspeed: 0.0113s/iter; left time: 12.9096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0559401 Vali Loss: 0.0545402 Test Loss: 0.0610489\n",
      "Validation loss decreased (0.054824 --> 0.054540).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609088\n",
      "\tspeed: 0.0265s/iter; left time: 27.0094s\n",
      "\titers: 200, epoch: 16 | loss: 0.0545612\n",
      "\tspeed: 0.0113s/iter; left time: 10.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0558091 Vali Loss: 0.0543885 Test Loss: 0.0608586\n",
      "Validation loss decreased (0.054540 --> 0.054389).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537297\n",
      "\tspeed: 0.0274s/iter; left time: 21.8437s\n",
      "\titers: 200, epoch: 17 | loss: 0.0562503\n",
      "\tspeed: 0.0113s/iter; left time: 7.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0556262 Vali Loss: 0.0542731 Test Loss: 0.0607741\n",
      "Validation loss decreased (0.054389 --> 0.054273).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572393\n",
      "\tspeed: 0.0264s/iter; left time: 15.0990s\n",
      "\titers: 200, epoch: 18 | loss: 0.0538083\n",
      "\tspeed: 0.0113s/iter; left time: 5.3247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0553770 Vali Loss: 0.0542938 Test Loss: 0.0607562\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543686\n",
      "\tspeed: 0.0273s/iter; left time: 9.5140s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553563\n",
      "\tspeed: 0.0113s/iter; left time: 2.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0552918 Vali Loss: 0.0541263 Test Loss: 0.0606835\n",
      "Validation loss decreased (0.054273 --> 0.054126).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0580385\n",
      "\tspeed: 0.0267s/iter; left time: 3.3388s\n",
      "\titers: 200, epoch: 20 | loss: 0.0506126\n",
      "\tspeed: 0.0113s/iter; left time: 0.2823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0551724 Vali Loss: 0.0539999 Test Loss: 0.0603945\n",
      "Validation loss decreased (0.054126 --> 0.054000).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009931187145411968, rmse:0.09965534508228302, mae:0.06039450317621231, rse:0.2932736277580261\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1556551\n",
      "\tspeed: 0.0137s/iter; left time: 60.0390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1238871\n",
      "\tspeed: 0.0117s/iter; left time: 49.8921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.1551209 Vali Loss: 0.1149658 Test Loss: 0.1298747\n",
      "Validation loss decreased (inf --> 0.114966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784185\n",
      "\tspeed: 0.0280s/iter; left time: 116.3490s\n",
      "\titers: 200, epoch: 2 | loss: 0.0682577\n",
      "\tspeed: 0.0113s/iter; left time: 45.9172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0810422 Vali Loss: 0.0650935 Test Loss: 0.0717688\n",
      "Validation loss decreased (0.114966 --> 0.065094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0690213\n",
      "\tspeed: 0.0269s/iter; left time: 105.8000s\n",
      "\titers: 200, epoch: 3 | loss: 0.0668357\n",
      "\tspeed: 0.0113s/iter; left time: 43.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0675884 Vali Loss: 0.0610957 Test Loss: 0.0677405\n",
      "Validation loss decreased (0.065094 --> 0.061096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637767\n",
      "\tspeed: 0.0262s/iter; left time: 97.1458s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622976\n",
      "\tspeed: 0.0113s/iter; left time: 40.8076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0641213 Vali Loss: 0.0590871 Test Loss: 0.0657832\n",
      "Validation loss decreased (0.061096 --> 0.059087).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0605592\n",
      "\tspeed: 0.0276s/iter; left time: 96.0129s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578117\n",
      "\tspeed: 0.0113s/iter; left time: 38.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0620087 Vali Loss: 0.0577362 Test Loss: 0.0641884\n",
      "Validation loss decreased (0.059087 --> 0.057736).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597171\n",
      "\tspeed: 0.0275s/iter; left time: 89.6045s\n",
      "\titers: 200, epoch: 6 | loss: 0.0631097\n",
      "\tspeed: 0.0114s/iter; left time: 35.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0605131 Vali Loss: 0.0567674 Test Loss: 0.0632716\n",
      "Validation loss decreased (0.057736 --> 0.056767).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0600709\n",
      "\tspeed: 0.0267s/iter; left time: 80.9579s\n",
      "\titers: 200, epoch: 7 | loss: 0.0558400\n",
      "\tspeed: 0.0113s/iter; left time: 33.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0593662 Vali Loss: 0.0560938 Test Loss: 0.0625260\n",
      "Validation loss decreased (0.056767 --> 0.056094).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0591932\n",
      "\tspeed: 0.0267s/iter; left time: 75.0977s\n",
      "\titers: 200, epoch: 8 | loss: 0.0566134\n",
      "\tspeed: 0.0113s/iter; left time: 30.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0586497 Vali Loss: 0.0559053 Test Loss: 0.0623956\n",
      "Validation loss decreased (0.056094 --> 0.055905).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0578017\n",
      "\tspeed: 0.0268s/iter; left time: 69.2913s\n",
      "\titers: 200, epoch: 9 | loss: 0.0608524\n",
      "\tspeed: 0.0113s/iter; left time: 28.1070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0579206 Vali Loss: 0.0554532 Test Loss: 0.0619622\n",
      "Validation loss decreased (0.055905 --> 0.055453).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0557183\n",
      "\tspeed: 0.0262s/iter; left time: 61.9002s\n",
      "\titers: 200, epoch: 10 | loss: 0.0574988\n",
      "\tspeed: 0.0113s/iter; left time: 25.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0574463 Vali Loss: 0.0551643 Test Loss: 0.0615977\n",
      "Validation loss decreased (0.055453 --> 0.055164).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0562042\n",
      "\tspeed: 0.0261s/iter; left time: 55.8944s\n",
      "\titers: 200, epoch: 11 | loss: 0.0547854\n",
      "\tspeed: 0.0113s/iter; left time: 23.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0570041 Vali Loss: 0.0548636 Test Loss: 0.0612392\n",
      "Validation loss decreased (0.055164 --> 0.054864).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0536011\n",
      "\tspeed: 0.0262s/iter; left time: 50.2201s\n",
      "\titers: 200, epoch: 12 | loss: 0.0547583\n",
      "\tspeed: 0.0113s/iter; left time: 20.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0565564 Vali Loss: 0.0548057 Test Loss: 0.0613708\n",
      "Validation loss decreased (0.054864 --> 0.054806).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0538747\n",
      "\tspeed: 0.0261s/iter; left time: 44.2553s\n",
      "\titers: 200, epoch: 13 | loss: 0.0558614\n",
      "\tspeed: 0.0113s/iter; left time: 17.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0563296 Vali Loss: 0.0545942 Test Loss: 0.0609953\n",
      "Validation loss decreased (0.054806 --> 0.054594).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0570528\n",
      "\tspeed: 0.0271s/iter; left time: 39.8674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0539998\n",
      "\tspeed: 0.0113s/iter; left time: 15.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0560721 Vali Loss: 0.0545014 Test Loss: 0.0608965\n",
      "Validation loss decreased (0.054594 --> 0.054501).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0558659\n",
      "\tspeed: 0.0264s/iter; left time: 32.8463s\n",
      "\titers: 200, epoch: 15 | loss: 0.0555724\n",
      "\tspeed: 0.0113s/iter; left time: 12.9102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0558337 Vali Loss: 0.0543190 Test Loss: 0.0608781\n",
      "Validation loss decreased (0.054501 --> 0.054319).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0502567\n",
      "\tspeed: 0.0260s/iter; left time: 26.5949s\n",
      "\titers: 200, epoch: 16 | loss: 0.0585473\n",
      "\tspeed: 0.0113s/iter; left time: 10.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0555682 Vali Loss: 0.0541908 Test Loss: 0.0607273\n",
      "Validation loss decreased (0.054319 --> 0.054191).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571907\n",
      "\tspeed: 0.0260s/iter; left time: 20.7251s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549186\n",
      "\tspeed: 0.0113s/iter; left time: 7.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0554409 Vali Loss: 0.0539711 Test Loss: 0.0604676\n",
      "Validation loss decreased (0.054191 --> 0.053971).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0570545\n",
      "\tspeed: 0.0277s/iter; left time: 15.8615s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563004\n",
      "\tspeed: 0.0113s/iter; left time: 5.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0552863 Vali Loss: 0.0539168 Test Loss: 0.0604286\n",
      "Validation loss decreased (0.053971 --> 0.053917).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0544547\n",
      "\tspeed: 0.0262s/iter; left time: 9.1362s\n",
      "\titers: 200, epoch: 19 | loss: 0.0538205\n",
      "\tspeed: 0.0113s/iter; left time: 2.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0550870 Vali Loss: 0.0540152 Test Loss: 0.0605182\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0500700\n",
      "\tspeed: 0.0262s/iter; left time: 3.2755s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550875\n",
      "\tspeed: 0.0113s/iter; left time: 0.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0549684 Vali Loss: 0.0539093 Test Loss: 0.0603909\n",
      "Validation loss decreased (0.053917 --> 0.053909).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009954366832971573, rmse:0.09977157413959503, mae:0.060390934348106384, rse:0.2936156690120697\n",
      "Intermediate time for ES and pred_len 24: 00h:02m:42.55s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600715\n",
      "\tspeed: 0.0319s/iter; left time: 139.9661s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329738\n",
      "\tspeed: 0.0115s/iter; left time: 49.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.1563259 Vali Loss: 0.1220047 Test Loss: 0.1377991\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986281\n",
      "\tspeed: 0.0278s/iter; left time: 115.5698s\n",
      "\titers: 200, epoch: 2 | loss: 0.0916502\n",
      "\tspeed: 0.0114s/iter; left time: 46.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0987325 Vali Loss: 0.0868770 Test Loss: 0.0978651\n",
      "Validation loss decreased (0.122005 --> 0.086877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870886\n",
      "\tspeed: 0.0284s/iter; left time: 111.5707s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855636\n",
      "\tspeed: 0.0115s/iter; left time: 43.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0874873 Vali Loss: 0.0815230 Test Loss: 0.0928167\n",
      "Validation loss decreased (0.086877 --> 0.081523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859502\n",
      "\tspeed: 0.0285s/iter; left time: 105.7301s\n",
      "\titers: 200, epoch: 4 | loss: 0.0796197\n",
      "\tspeed: 0.0115s/iter; left time: 41.5071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0837237 Vali Loss: 0.0794888 Test Loss: 0.0907266\n",
      "Validation loss decreased (0.081523 --> 0.079489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817280\n",
      "\tspeed: 0.0282s/iter; left time: 98.1448s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827391\n",
      "\tspeed: 0.0114s/iter; left time: 38.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0817404 Vali Loss: 0.0787186 Test Loss: 0.0896066\n",
      "Validation loss decreased (0.079489 --> 0.078719).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0804231\n",
      "\tspeed: 0.0281s/iter; left time: 91.4792s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756826\n",
      "\tspeed: 0.0115s/iter; left time: 36.4475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0802827 Vali Loss: 0.0777990 Test Loss: 0.0888387\n",
      "Validation loss decreased (0.078719 --> 0.077799).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785264\n",
      "\tspeed: 0.0282s/iter; left time: 85.7239s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755876\n",
      "\tspeed: 0.0115s/iter; left time: 33.8616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0792729 Vali Loss: 0.0773480 Test Loss: 0.0884110\n",
      "Validation loss decreased (0.077799 --> 0.077348).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815148\n",
      "\tspeed: 0.0280s/iter; left time: 78.6349s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805861\n",
      "\tspeed: 0.0115s/iter; left time: 31.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0784637 Vali Loss: 0.0769119 Test Loss: 0.0878655\n",
      "Validation loss decreased (0.077348 --> 0.076912).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779870\n",
      "\tspeed: 0.0291s/iter; left time: 75.2372s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807751\n",
      "\tspeed: 0.0115s/iter; left time: 28.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0777863 Vali Loss: 0.0771217 Test Loss: 0.0875601\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772136\n",
      "\tspeed: 0.0279s/iter; left time: 65.9296s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758945\n",
      "\tspeed: 0.0115s/iter; left time: 26.0033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0772079 Vali Loss: 0.0772257 Test Loss: 0.0879205\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747496\n",
      "\tspeed: 0.0280s/iter; left time: 59.9301s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791871\n",
      "\tspeed: 0.0116s/iter; left time: 23.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0767879 Vali Loss: 0.0771484 Test Loss: 0.0879905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0762381\n",
      "\tspeed: 0.0280s/iter; left time: 53.7355s\n",
      "\titers: 200, epoch: 12 | loss: 0.0765716\n",
      "\tspeed: 0.0116s/iter; left time: 21.0194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0764095 Vali Loss: 0.0771252 Test Loss: 0.0876286\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0747886\n",
      "\tspeed: 0.0276s/iter; left time: 46.6801s\n",
      "\titers: 200, epoch: 13 | loss: 0.0747912\n",
      "\tspeed: 0.0116s/iter; left time: 18.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0760711 Vali Loss: 0.0773463 Test Loss: 0.0876072\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018780911341309547, rmse:0.13704346120357513, mae:0.08786552399396896, rse:0.4025924503803253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1609155\n",
      "\tspeed: 0.0136s/iter; left time: 59.3758s\n",
      "\titers: 200, epoch: 1 | loss: 0.1392553\n",
      "\tspeed: 0.0115s/iter; left time: 49.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.1606353 Vali Loss: 0.1255435 Test Loss: 0.1420600\n",
      "Validation loss decreased (inf --> 0.125544).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0989368\n",
      "\tspeed: 0.0272s/iter; left time: 113.0269s\n",
      "\titers: 200, epoch: 2 | loss: 0.0917517\n",
      "\tspeed: 0.0115s/iter; left time: 46.5570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0989939 Vali Loss: 0.0866069 Test Loss: 0.0975074\n",
      "Validation loss decreased (0.125544 --> 0.086607).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881878\n",
      "\tspeed: 0.0280s/iter; left time: 110.2228s\n",
      "\titers: 200, epoch: 3 | loss: 0.0868338\n",
      "\tspeed: 0.0115s/iter; left time: 44.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0873806 Vali Loss: 0.0815672 Test Loss: 0.0929901\n",
      "Validation loss decreased (0.086607 --> 0.081567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868333\n",
      "\tspeed: 0.0283s/iter; left time: 104.9011s\n",
      "\titers: 200, epoch: 4 | loss: 0.0832773\n",
      "\tspeed: 0.0115s/iter; left time: 41.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0838568 Vali Loss: 0.0793864 Test Loss: 0.0907652\n",
      "Validation loss decreased (0.081567 --> 0.079386).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0838556\n",
      "\tspeed: 0.0323s/iter; left time: 112.6370s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836494\n",
      "\tspeed: 0.0115s/iter; left time: 38.7684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0818360 Vali Loss: 0.0784956 Test Loss: 0.0893709\n",
      "Validation loss decreased (0.079386 --> 0.078496).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0806378\n",
      "\tspeed: 0.0286s/iter; left time: 93.1447s\n",
      "\titers: 200, epoch: 6 | loss: 0.0794055\n",
      "\tspeed: 0.0115s/iter; left time: 36.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0803881 Vali Loss: 0.0777162 Test Loss: 0.0886234\n",
      "Validation loss decreased (0.078496 --> 0.077716).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0788840\n",
      "\tspeed: 0.0279s/iter; left time: 84.8396s\n",
      "\titers: 200, epoch: 7 | loss: 0.0766921\n",
      "\tspeed: 0.0114s/iter; left time: 33.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0793882 Vali Loss: 0.0770763 Test Loss: 0.0880639\n",
      "Validation loss decreased (0.077716 --> 0.077076).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0799958\n",
      "\tspeed: 0.0273s/iter; left time: 76.8830s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752629\n",
      "\tspeed: 0.0114s/iter; left time: 31.0630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0785344 Vali Loss: 0.0771097 Test Loss: 0.0877821\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0798732\n",
      "\tspeed: 0.0273s/iter; left time: 70.6047s\n",
      "\titers: 200, epoch: 9 | loss: 0.0763348\n",
      "\tspeed: 0.0115s/iter; left time: 28.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0778461 Vali Loss: 0.0769220 Test Loss: 0.0876128\n",
      "Validation loss decreased (0.077076 --> 0.076922).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0743215\n",
      "\tspeed: 0.0274s/iter; left time: 64.7420s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804870\n",
      "\tspeed: 0.0114s/iter; left time: 25.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0772132 Vali Loss: 0.0769246 Test Loss: 0.0874467\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0826044\n",
      "\tspeed: 0.0272s/iter; left time: 58.2747s\n",
      "\titers: 200, epoch: 11 | loss: 0.0788673\n",
      "\tspeed: 0.0115s/iter; left time: 23.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0766971 Vali Loss: 0.0773208 Test Loss: 0.0875554\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0752086\n",
      "\tspeed: 0.0269s/iter; left time: 51.6387s\n",
      "\titers: 200, epoch: 12 | loss: 0.0771490\n",
      "\tspeed: 0.0115s/iter; left time: 20.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0763049 Vali Loss: 0.0769417 Test Loss: 0.0873715\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728450\n",
      "\tspeed: 0.0272s/iter; left time: 46.0181s\n",
      "\titers: 200, epoch: 13 | loss: 0.0766766\n",
      "\tspeed: 0.0115s/iter; left time: 18.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0759119 Vali Loss: 0.0769993 Test Loss: 0.0874939\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771995\n",
      "\tspeed: 0.0274s/iter; left time: 40.2334s\n",
      "\titers: 200, epoch: 14 | loss: 0.0776248\n",
      "\tspeed: 0.0115s/iter; left time: 15.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0755728 Vali Loss: 0.0772427 Test Loss: 0.0875207\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018756497651338577, rmse:0.13695436716079712, mae:0.0876128226518631, rse:0.4023307263851166\n",
      "Intermediate time for ES and pred_len 96: 00h:01m:55.94s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1587022\n",
      "\tspeed: 0.0277s/iter; left time: 120.7666s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341747\n",
      "\tspeed: 0.0118s/iter; left time: 50.2674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 223 | Train Loss: 0.1577783 Vali Loss: 0.1251705 Test Loss: 0.1401281\n",
      "Validation loss decreased (inf --> 0.125171).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031412\n",
      "\tspeed: 0.0284s/iter; left time: 117.4405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0959672\n",
      "\tspeed: 0.0117s/iter; left time: 47.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.1027157 Vali Loss: 0.0919966 Test Loss: 0.1034162\n",
      "Validation loss decreased (0.125171 --> 0.091997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0920534\n",
      "\tspeed: 0.0294s/iter; left time: 115.1407s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888611\n",
      "\tspeed: 0.0117s/iter; left time: 44.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0920359 Vali Loss: 0.0870327 Test Loss: 0.0976905\n",
      "Validation loss decreased (0.091997 --> 0.087033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0895105\n",
      "\tspeed: 0.0294s/iter; left time: 108.4737s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878107\n",
      "\tspeed: 0.0120s/iter; left time: 43.0213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0884706 Vali Loss: 0.0853649 Test Loss: 0.0954801\n",
      "Validation loss decreased (0.087033 --> 0.085365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862070\n",
      "\tspeed: 0.0295s/iter; left time: 102.3714s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893748\n",
      "\tspeed: 0.0118s/iter; left time: 39.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0865734 Vali Loss: 0.0847053 Test Loss: 0.0949914\n",
      "Validation loss decreased (0.085365 --> 0.084705).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864203\n",
      "\tspeed: 0.0300s/iter; left time: 97.5177s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820089\n",
      "\tspeed: 0.0119s/iter; left time: 37.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0852276 Vali Loss: 0.0837621 Test Loss: 0.0942142\n",
      "Validation loss decreased (0.084705 --> 0.083762).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0851779\n",
      "\tspeed: 0.0297s/iter; left time: 89.8212s\n",
      "\titers: 200, epoch: 7 | loss: 0.0864495\n",
      "\tspeed: 0.0119s/iter; left time: 34.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 223 | Train Loss: 0.0841670 Vali Loss: 0.0831766 Test Loss: 0.0941424\n",
      "Validation loss decreased (0.083762 --> 0.083177).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873072\n",
      "\tspeed: 0.0299s/iter; left time: 83.6507s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819371\n",
      "\tspeed: 0.0116s/iter; left time: 31.4446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0833336 Vali Loss: 0.0830012 Test Loss: 0.0937584\n",
      "Validation loss decreased (0.083177 --> 0.083001).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824002\n",
      "\tspeed: 0.0290s/iter; left time: 74.6439s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809036\n",
      "\tspeed: 0.0118s/iter; left time: 29.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0827256 Vali Loss: 0.0830959 Test Loss: 0.0934695\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832733\n",
      "\tspeed: 0.0290s/iter; left time: 68.3761s\n",
      "\titers: 200, epoch: 10 | loss: 0.0845594\n",
      "\tspeed: 0.0120s/iter; left time: 27.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0820771 Vali Loss: 0.0831661 Test Loss: 0.0935841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0840108\n",
      "\tspeed: 0.0294s/iter; left time: 62.6391s\n",
      "\titers: 200, epoch: 11 | loss: 0.0846826\n",
      "\tspeed: 0.0119s/iter; left time: 24.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0816523 Vali Loss: 0.0829173 Test Loss: 0.0937325\n",
      "Validation loss decreased (0.083001 --> 0.082917).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819534\n",
      "\tspeed: 0.0294s/iter; left time: 56.0105s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778076\n",
      "\tspeed: 0.0114s/iter; left time: 20.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0812295 Vali Loss: 0.0828364 Test Loss: 0.0937928\n",
      "Validation loss decreased (0.082917 --> 0.082836).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0812906\n",
      "\tspeed: 0.0291s/iter; left time: 49.0698s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818937\n",
      "\tspeed: 0.0116s/iter; left time: 18.3131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0807780 Vali Loss: 0.0831400 Test Loss: 0.0939310\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822786\n",
      "\tspeed: 0.0284s/iter; left time: 41.4949s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779815\n",
      "\tspeed: 0.0115s/iter; left time: 15.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0805288 Vali Loss: 0.0833648 Test Loss: 0.0938287\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780915\n",
      "\tspeed: 0.0283s/iter; left time: 35.0180s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791826\n",
      "\tspeed: 0.0115s/iter; left time: 13.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0801763 Vali Loss: 0.0833790 Test Loss: 0.0936142\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0781371\n",
      "\tspeed: 0.0291s/iter; left time: 29.5890s\n",
      "\titers: 200, epoch: 16 | loss: 0.0776101\n",
      "\tspeed: 0.0121s/iter; left time: 11.0529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 223 | Train Loss: 0.0799538 Vali Loss: 0.0833786 Test Loss: 0.0939362\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800811\n",
      "\tspeed: 0.0281s/iter; left time: 22.3130s\n",
      "\titers: 200, epoch: 17 | loss: 0.0839744\n",
      "\tspeed: 0.0118s/iter; left time: 8.1921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0796631 Vali Loss: 0.0837506 Test Loss: 0.0939819\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021249037235975266, rmse:0.14577049016952515, mae:0.09379277378320694, rse:0.42826059460639954\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1613253\n",
      "\tspeed: 0.0143s/iter; left time: 62.1798s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379661\n",
      "\tspeed: 0.0116s/iter; left time: 49.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.1605699 Vali Loss: 0.1269564 Test Loss: 0.1422651\n",
      "Validation loss decreased (inf --> 0.126956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1011166\n",
      "\tspeed: 0.0288s/iter; left time: 119.3730s\n",
      "\titers: 200, epoch: 2 | loss: 0.0964100\n",
      "\tspeed: 0.0117s/iter; left time: 47.1714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.1028684 Vali Loss: 0.0919216 Test Loss: 0.1033256\n",
      "Validation loss decreased (0.126956 --> 0.091922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0919904\n",
      "\tspeed: 0.0289s/iter; left time: 113.3043s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932997\n",
      "\tspeed: 0.0117s/iter; left time: 44.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0919826 Vali Loss: 0.0869391 Test Loss: 0.0977627\n",
      "Validation loss decreased (0.091922 --> 0.086939).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853900\n",
      "\tspeed: 0.0317s/iter; left time: 117.1775s\n",
      "\titers: 200, epoch: 4 | loss: 0.0877520\n",
      "\tspeed: 0.0121s/iter; left time: 43.5891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.21s\n",
      "Steps: 223 | Train Loss: 0.0882947 Vali Loss: 0.0853301 Test Loss: 0.0954336\n",
      "Validation loss decreased (0.086939 --> 0.085330).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0842153\n",
      "\tspeed: 0.0301s/iter; left time: 104.2579s\n",
      "\titers: 200, epoch: 5 | loss: 0.0884012\n",
      "\tspeed: 0.0119s/iter; left time: 40.1872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0863264 Vali Loss: 0.0842051 Test Loss: 0.0947297\n",
      "Validation loss decreased (0.085330 --> 0.084205).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863844\n",
      "\tspeed: 0.0291s/iter; left time: 94.3492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844114\n",
      "\tspeed: 0.0117s/iter; left time: 36.7241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0849223 Vali Loss: 0.0838633 Test Loss: 0.0939944\n",
      "Validation loss decreased (0.084205 --> 0.083863).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0817755\n",
      "\tspeed: 0.0285s/iter; left time: 86.1333s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835092\n",
      "\tspeed: 0.0117s/iter; left time: 34.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0839199 Vali Loss: 0.0835818 Test Loss: 0.0939294\n",
      "Validation loss decreased (0.083863 --> 0.083582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0832944\n",
      "\tspeed: 0.0286s/iter; left time: 80.0193s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838037\n",
      "\tspeed: 0.0116s/iter; left time: 31.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0830767 Vali Loss: 0.0830342 Test Loss: 0.0935405\n",
      "Validation loss decreased (0.083582 --> 0.083034).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0783223\n",
      "\tspeed: 0.0287s/iter; left time: 74.0256s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815742\n",
      "\tspeed: 0.0117s/iter; left time: 29.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0824175 Vali Loss: 0.0832622 Test Loss: 0.0935256\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825320\n",
      "\tspeed: 0.0290s/iter; left time: 68.2133s\n",
      "\titers: 200, epoch: 10 | loss: 0.0812171\n",
      "\tspeed: 0.0119s/iter; left time: 26.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0818186 Vali Loss: 0.0831434 Test Loss: 0.0934408\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0828382\n",
      "\tspeed: 0.0299s/iter; left time: 63.6815s\n",
      "\titers: 200, epoch: 11 | loss: 0.0794838\n",
      "\tspeed: 0.0116s/iter; left time: 23.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0813276 Vali Loss: 0.0833540 Test Loss: 0.0934451\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0841984\n",
      "\tspeed: 0.0292s/iter; left time: 55.6406s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807900\n",
      "\tspeed: 0.0116s/iter; left time: 21.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0808180 Vali Loss: 0.0831364 Test Loss: 0.0931335\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0804507\n",
      "\tspeed: 0.0288s/iter; left time: 48.4642s\n",
      "\titers: 200, epoch: 13 | loss: 0.0830584\n",
      "\tspeed: 0.0119s/iter; left time: 18.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0804731 Vali Loss: 0.0834696 Test Loss: 0.0930707\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02081207185983658, rmse:0.14426389336585999, mae:0.09354054182767868, rse:0.42383435368537903\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:12.80s\n",
      "Intermediate time for ES: 00h:06m:51.29s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1109400\n",
      "\tspeed: 0.0328s/iter; left time: 143.8481s\n",
      "\titers: 200, epoch: 1 | loss: 0.0880111\n",
      "\tspeed: 0.0117s/iter; left time: 50.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.1121065 Vali Loss: 0.0946012 Test Loss: 0.1039492\n",
      "Validation loss decreased (inf --> 0.094601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0538929\n",
      "\tspeed: 0.0273s/iter; left time: 113.5271s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533425\n",
      "\tspeed: 0.0116s/iter; left time: 46.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0594639 Vali Loss: 0.0593115 Test Loss: 0.0626804\n",
      "Validation loss decreased (0.094601 --> 0.059311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0489332\n",
      "\tspeed: 0.0274s/iter; left time: 107.7529s\n",
      "\titers: 200, epoch: 3 | loss: 0.0485343\n",
      "\tspeed: 0.0113s/iter; left time: 43.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0507693 Vali Loss: 0.0568483 Test Loss: 0.0600760\n",
      "Validation loss decreased (0.059311 --> 0.056848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0487404\n",
      "\tspeed: 0.0285s/iter; left time: 105.8727s\n",
      "\titers: 200, epoch: 4 | loss: 0.0477995\n",
      "\tspeed: 0.0116s/iter; left time: 41.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0485856 Vali Loss: 0.0556100 Test Loss: 0.0589949\n",
      "Validation loss decreased (0.056848 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0472121\n",
      "\tspeed: 0.0273s/iter; left time: 94.9841s\n",
      "\titers: 200, epoch: 5 | loss: 0.0472476\n",
      "\tspeed: 0.0113s/iter; left time: 38.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0472403 Vali Loss: 0.0546619 Test Loss: 0.0584079\n",
      "Validation loss decreased (0.055610 --> 0.054662).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473987\n",
      "\tspeed: 0.0275s/iter; left time: 89.5337s\n",
      "\titers: 200, epoch: 6 | loss: 0.0465832\n",
      "\tspeed: 0.0113s/iter; left time: 35.8277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0462808 Vali Loss: 0.0536563 Test Loss: 0.0576321\n",
      "Validation loss decreased (0.054662 --> 0.053656).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0467726\n",
      "\tspeed: 0.0271s/iter; left time: 82.1835s\n",
      "\titers: 200, epoch: 7 | loss: 0.0450430\n",
      "\tspeed: 0.0113s/iter; left time: 33.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0456065 Vali Loss: 0.0533683 Test Loss: 0.0574062\n",
      "Validation loss decreased (0.053656 --> 0.053368).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0468291\n",
      "\tspeed: 0.0276s/iter; left time: 77.6114s\n",
      "\titers: 200, epoch: 8 | loss: 0.0441214\n",
      "\tspeed: 0.0116s/iter; left time: 31.3656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0450418 Vali Loss: 0.0531526 Test Loss: 0.0570093\n",
      "Validation loss decreased (0.053368 --> 0.053153).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0461029\n",
      "\tspeed: 0.0272s/iter; left time: 70.4458s\n",
      "\titers: 200, epoch: 9 | loss: 0.0408064\n",
      "\tspeed: 0.0114s/iter; left time: 28.4553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0445590 Vali Loss: 0.0528589 Test Loss: 0.0570480\n",
      "Validation loss decreased (0.053153 --> 0.052859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465658\n",
      "\tspeed: 0.0278s/iter; left time: 65.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442628\n",
      "\tspeed: 0.0113s/iter; left time: 25.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0441614 Vali Loss: 0.0525321 Test Loss: 0.0567075\n",
      "Validation loss decreased (0.052859 --> 0.052532).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0423924\n",
      "\tspeed: 0.0273s/iter; left time: 58.3718s\n",
      "\titers: 200, epoch: 11 | loss: 0.0421286\n",
      "\tspeed: 0.0115s/iter; left time: 23.5343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0438235 Vali Loss: 0.0523531 Test Loss: 0.0565543\n",
      "Validation loss decreased (0.052532 --> 0.052353).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0432395\n",
      "\tspeed: 0.0270s/iter; left time: 51.8299s\n",
      "\titers: 200, epoch: 12 | loss: 0.0427727\n",
      "\tspeed: 0.0114s/iter; left time: 20.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0435605 Vali Loss: 0.0522622 Test Loss: 0.0562977\n",
      "Validation loss decreased (0.052353 --> 0.052262).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0425658\n",
      "\tspeed: 0.0272s/iter; left time: 46.0590s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426574\n",
      "\tspeed: 0.0114s/iter; left time: 18.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0433638 Vali Loss: 0.0520600 Test Loss: 0.0562625\n",
      "Validation loss decreased (0.052262 --> 0.052060).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0430053\n",
      "\tspeed: 0.0283s/iter; left time: 41.6454s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461629\n",
      "\tspeed: 0.0117s/iter; left time: 16.0345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0431846 Vali Loss: 0.0523483 Test Loss: 0.0562605\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0421305\n",
      "\tspeed: 0.0297s/iter; left time: 36.9925s\n",
      "\titers: 200, epoch: 15 | loss: 0.0412395\n",
      "\tspeed: 0.0116s/iter; left time: 13.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0429814 Vali Loss: 0.0519295 Test Loss: 0.0562118\n",
      "Validation loss decreased (0.052060 --> 0.051930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0420358\n",
      "\tspeed: 0.0293s/iter; left time: 29.9298s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441732\n",
      "\tspeed: 0.0117s/iter; left time: 10.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0428641 Vali Loss: 0.0518976 Test Loss: 0.0560167\n",
      "Validation loss decreased (0.051930 --> 0.051898).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0419349\n",
      "\tspeed: 0.0288s/iter; left time: 22.9721s\n",
      "\titers: 200, epoch: 17 | loss: 0.0407056\n",
      "\tspeed: 0.0117s/iter; left time: 8.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0426269 Vali Loss: 0.0517025 Test Loss: 0.0560059\n",
      "Validation loss decreased (0.051898 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0445126\n",
      "\tspeed: 0.0304s/iter; left time: 17.4073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0424769\n",
      "\tspeed: 0.0118s/iter; left time: 5.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0425544 Vali Loss: 0.0517746 Test Loss: 0.0559971\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0395071\n",
      "\tspeed: 0.0287s/iter; left time: 10.0244s\n",
      "\titers: 200, epoch: 19 | loss: 0.0431924\n",
      "\tspeed: 0.0117s/iter; left time: 2.9122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0424392 Vali Loss: 0.0516417 Test Loss: 0.0558206\n",
      "Validation loss decreased (0.051702 --> 0.051642).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0415440\n",
      "\tspeed: 0.0288s/iter; left time: 3.6025s\n",
      "\titers: 200, epoch: 20 | loss: 0.0394489\n",
      "\tspeed: 0.0116s/iter; left time: 0.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0423368 Vali Loss: 0.0516620 Test Loss: 0.0558139\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010159791447222233, rmse:0.10079579055309296, mae:0.05582056939601898, rse:0.3888673782348633\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1158036\n",
      "\tspeed: 0.0143s/iter; left time: 62.6084s\n",
      "\titers: 200, epoch: 1 | loss: 0.0897452\n",
      "\tspeed: 0.0116s/iter; left time: 49.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.1133295 Vali Loss: 0.0949919 Test Loss: 0.1035445\n",
      "Validation loss decreased (inf --> 0.094992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0569122\n",
      "\tspeed: 0.0280s/iter; left time: 116.2907s\n",
      "\titers: 200, epoch: 2 | loss: 0.0541146\n",
      "\tspeed: 0.0116s/iter; left time: 47.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0595537 Vali Loss: 0.0592307 Test Loss: 0.0624938\n",
      "Validation loss decreased (0.094992 --> 0.059231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0535804\n",
      "\tspeed: 0.0283s/iter; left time: 111.4540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0482767\n",
      "\tspeed: 0.0116s/iter; left time: 44.4312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0507777 Vali Loss: 0.0568637 Test Loss: 0.0602203\n",
      "Validation loss decreased (0.059231 --> 0.056864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0489563\n",
      "\tspeed: 0.0281s/iter; left time: 104.1438s\n",
      "\titers: 200, epoch: 4 | loss: 0.0472311\n",
      "\tspeed: 0.0116s/iter; left time: 41.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0485894 Vali Loss: 0.0553823 Test Loss: 0.0590451\n",
      "Validation loss decreased (0.056864 --> 0.055382).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0476006\n",
      "\tspeed: 0.0290s/iter; left time: 101.1218s\n",
      "\titers: 200, epoch: 5 | loss: 0.0451604\n",
      "\tspeed: 0.0116s/iter; left time: 39.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0472259 Vali Loss: 0.0547291 Test Loss: 0.0585976\n",
      "Validation loss decreased (0.055382 --> 0.054729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0460030\n",
      "\tspeed: 0.0285s/iter; left time: 93.0952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0442784\n",
      "\tspeed: 0.0116s/iter; left time: 36.6254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0462648 Vali Loss: 0.0540650 Test Loss: 0.0579539\n",
      "Validation loss decreased (0.054729 --> 0.054065).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0454986\n",
      "\tspeed: 0.0280s/iter; left time: 85.1777s\n",
      "\titers: 200, epoch: 7 | loss: 0.0469666\n",
      "\tspeed: 0.0116s/iter; left time: 34.0770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0455293 Vali Loss: 0.0532679 Test Loss: 0.0573423\n",
      "Validation loss decreased (0.054065 --> 0.053268).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0447970\n",
      "\tspeed: 0.0277s/iter; left time: 78.0220s\n",
      "\titers: 200, epoch: 8 | loss: 0.0483812\n",
      "\tspeed: 0.0116s/iter; left time: 31.4530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0449567 Vali Loss: 0.0530940 Test Loss: 0.0571498\n",
      "Validation loss decreased (0.053268 --> 0.053094).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0444100\n",
      "\tspeed: 0.0279s/iter; left time: 72.2106s\n",
      "\titers: 200, epoch: 9 | loss: 0.0438467\n",
      "\tspeed: 0.0115s/iter; left time: 28.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0444837 Vali Loss: 0.0528195 Test Loss: 0.0569643\n",
      "Validation loss decreased (0.053094 --> 0.052819).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0440547\n",
      "\tspeed: 0.0278s/iter; left time: 65.8084s\n",
      "\titers: 200, epoch: 10 | loss: 0.0428151\n",
      "\tspeed: 0.0116s/iter; left time: 26.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0440762 Vali Loss: 0.0526214 Test Loss: 0.0568737\n",
      "Validation loss decreased (0.052819 --> 0.052621).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0445571\n",
      "\tspeed: 0.0283s/iter; left time: 60.5750s\n",
      "\titers: 200, epoch: 11 | loss: 0.0471088\n",
      "\tspeed: 0.0117s/iter; left time: 23.8888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0437659 Vali Loss: 0.0523438 Test Loss: 0.0564469\n",
      "Validation loss decreased (0.052621 --> 0.052344).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0434962\n",
      "\tspeed: 0.0280s/iter; left time: 53.6655s\n",
      "\titers: 200, epoch: 12 | loss: 0.0420639\n",
      "\tspeed: 0.0117s/iter; left time: 21.1720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0435228 Vali Loss: 0.0522977 Test Loss: 0.0564896\n",
      "Validation loss decreased (0.052344 --> 0.052298).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465735\n",
      "\tspeed: 0.0276s/iter; left time: 46.7459s\n",
      "\titers: 200, epoch: 13 | loss: 0.0405169\n",
      "\tspeed: 0.0117s/iter; left time: 18.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0432881 Vali Loss: 0.0522314 Test Loss: 0.0563967\n",
      "Validation loss decreased (0.052298 --> 0.052231).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0418454\n",
      "\tspeed: 0.0280s/iter; left time: 41.1613s\n",
      "\titers: 200, epoch: 14 | loss: 0.0447588\n",
      "\tspeed: 0.0116s/iter; left time: 15.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0430877 Vali Loss: 0.0519799 Test Loss: 0.0562589\n",
      "Validation loss decreased (0.052231 --> 0.051980).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0423968\n",
      "\tspeed: 0.0275s/iter; left time: 34.2506s\n",
      "\titers: 200, epoch: 15 | loss: 0.0383774\n",
      "\tspeed: 0.0112s/iter; left time: 12.8781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0428894 Vali Loss: 0.0519243 Test Loss: 0.0561372\n",
      "Validation loss decreased (0.051980 --> 0.051924).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0407413\n",
      "\tspeed: 0.0278s/iter; left time: 28.3533s\n",
      "\titers: 200, epoch: 16 | loss: 0.0405852\n",
      "\tspeed: 0.0122s/iter; left time: 11.2720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0427432 Vali Loss: 0.0518589 Test Loss: 0.0561070\n",
      "Validation loss decreased (0.051924 --> 0.051859).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0430592\n",
      "\tspeed: 0.0283s/iter; left time: 22.5159s\n",
      "\titers: 200, epoch: 17 | loss: 0.0412801\n",
      "\tspeed: 0.0123s/iter; left time: 8.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 224 | Train Loss: 0.0426225 Vali Loss: 0.0518812 Test Loss: 0.0561238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0411777\n",
      "\tspeed: 0.0276s/iter; left time: 15.8272s\n",
      "\titers: 200, epoch: 18 | loss: 0.0410426\n",
      "\tspeed: 0.0122s/iter; left time: 5.7567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0425417 Vali Loss: 0.0517370 Test Loss: 0.0560527\n",
      "Validation loss decreased (0.051859 --> 0.051737).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0427175\n",
      "\tspeed: 0.0282s/iter; left time: 9.8363s\n",
      "\titers: 200, epoch: 19 | loss: 0.0448190\n",
      "\tspeed: 0.0123s/iter; left time: 3.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 224 | Train Loss: 0.0423826 Vali Loss: 0.0516347 Test Loss: 0.0559927\n",
      "Validation loss decreased (0.051737 --> 0.051635).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0438801\n",
      "\tspeed: 0.0287s/iter; left time: 3.5837s\n",
      "\titers: 200, epoch: 20 | loss: 0.0390797\n",
      "\tspeed: 0.0124s/iter; left time: 0.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0423430 Vali Loss: 0.0516649 Test Loss: 0.0558768\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010225766338407993, rmse:0.10112252831459045, mae:0.055992696434259415, rse:0.39012792706489563\n",
      "Intermediate time for FR and pred_len 24: 00h:02m:48.75s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1147146\n",
      "\tspeed: 0.0335s/iter; left time: 146.7454s\n",
      "\titers: 200, epoch: 1 | loss: 0.1000472\n",
      "\tspeed: 0.0117s/iter; left time: 50.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 224 | Train Loss: 0.1151350 Vali Loss: 0.1004755 Test Loss: 0.1112628\n",
      "Validation loss decreased (inf --> 0.100475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692950\n",
      "\tspeed: 0.0286s/iter; left time: 118.8001s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726237\n",
      "\tspeed: 0.0116s/iter; left time: 46.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0735507 Vali Loss: 0.0766084 Test Loss: 0.0845824\n",
      "Validation loss decreased (0.100475 --> 0.076608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0612146\n",
      "\tspeed: 0.0291s/iter; left time: 114.5152s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639182\n",
      "\tspeed: 0.0115s/iter; left time: 44.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0659023 Vali Loss: 0.0733167 Test Loss: 0.0827081\n",
      "Validation loss decreased (0.076608 --> 0.073317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0624377\n",
      "\tspeed: 0.0291s/iter; left time: 107.9314s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632359\n",
      "\tspeed: 0.0118s/iter; left time: 42.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 224 | Train Loss: 0.0634114 Vali Loss: 0.0719024 Test Loss: 0.0820890\n",
      "Validation loss decreased (0.073317 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0613682\n",
      "\tspeed: 0.0287s/iter; left time: 100.1649s\n",
      "\titers: 200, epoch: 5 | loss: 0.0603765\n",
      "\tspeed: 0.0115s/iter; left time: 39.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0622096 Vali Loss: 0.0716747 Test Loss: 0.0817658\n",
      "Validation loss decreased (0.071902 --> 0.071675).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0613188\n",
      "\tspeed: 0.0289s/iter; left time: 94.2221s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585596\n",
      "\tspeed: 0.0116s/iter; left time: 36.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0613992 Vali Loss: 0.0709265 Test Loss: 0.0814199\n",
      "Validation loss decreased (0.071675 --> 0.070926).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581186\n",
      "\tspeed: 0.0294s/iter; left time: 89.3218s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601980\n",
      "\tspeed: 0.0118s/iter; left time: 34.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0607734 Vali Loss: 0.0705771 Test Loss: 0.0811658\n",
      "Validation loss decreased (0.070926 --> 0.070577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599504\n",
      "\tspeed: 0.0289s/iter; left time: 81.1635s\n",
      "\titers: 200, epoch: 8 | loss: 0.0627330\n",
      "\tspeed: 0.0117s/iter; left time: 31.6516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0602172 Vali Loss: 0.0707170 Test Loss: 0.0811702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0582917\n",
      "\tspeed: 0.0291s/iter; left time: 75.2427s\n",
      "\titers: 200, epoch: 9 | loss: 0.0607997\n",
      "\tspeed: 0.0117s/iter; left time: 29.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0597521 Vali Loss: 0.0708032 Test Loss: 0.0809484\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596805\n",
      "\tspeed: 0.0281s/iter; left time: 66.3860s\n",
      "\titers: 200, epoch: 10 | loss: 0.0599481\n",
      "\tspeed: 0.0117s/iter; left time: 26.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0594114 Vali Loss: 0.0709393 Test Loss: 0.0808087\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559060\n",
      "\tspeed: 0.0284s/iter; left time: 60.8353s\n",
      "\titers: 200, epoch: 11 | loss: 0.0589835\n",
      "\tspeed: 0.0117s/iter; left time: 23.8450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0590685 Vali Loss: 0.0707514 Test Loss: 0.0809203\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0602128\n",
      "\tspeed: 0.0290s/iter; left time: 55.6871s\n",
      "\titers: 200, epoch: 12 | loss: 0.0592024\n",
      "\tspeed: 0.0117s/iter; left time: 21.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0587862 Vali Loss: 0.0708335 Test Loss: 0.0807095\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019104918465018272, rmse:0.13822054862976074, mae:0.08116577565670013, rse:0.534673810005188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1143000\n",
      "\tspeed: 0.0145s/iter; left time: 63.5347s\n",
      "\titers: 200, epoch: 1 | loss: 0.0998920\n",
      "\tspeed: 0.0118s/iter; left time: 50.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.1165416 Vali Loss: 0.1021830 Test Loss: 0.1129842\n",
      "Validation loss decreased (inf --> 0.102183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0689287\n",
      "\tspeed: 0.0291s/iter; left time: 120.9753s\n",
      "\titers: 200, epoch: 2 | loss: 0.0708336\n",
      "\tspeed: 0.0117s/iter; left time: 47.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0736541 Vali Loss: 0.0765947 Test Loss: 0.0845144\n",
      "Validation loss decreased (0.102183 --> 0.076595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0688908\n",
      "\tspeed: 0.0293s/iter; left time: 115.3649s\n",
      "\titers: 200, epoch: 3 | loss: 0.0633019\n",
      "\tspeed: 0.0118s/iter; left time: 45.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0657550 Vali Loss: 0.0734985 Test Loss: 0.0830433\n",
      "Validation loss decreased (0.076595 --> 0.073499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691519\n",
      "\tspeed: 0.0300s/iter; left time: 111.1389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618158\n",
      "\tspeed: 0.0118s/iter; left time: 42.5991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0632717 Vali Loss: 0.0722616 Test Loss: 0.0826190\n",
      "Validation loss decreased (0.073499 --> 0.072262).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0622582\n",
      "\tspeed: 0.0353s/iter; left time: 123.0562s\n",
      "\titers: 200, epoch: 5 | loss: 0.0615297\n",
      "\tspeed: 0.0133s/iter; left time: 45.1396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.62s\n",
      "Steps: 224 | Train Loss: 0.0619997 Vali Loss: 0.0715764 Test Loss: 0.0818878\n",
      "Validation loss decreased (0.072262 --> 0.071576).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0590784\n",
      "\tspeed: 0.0289s/iter; left time: 94.3597s\n",
      "\titers: 200, epoch: 6 | loss: 0.0622722\n",
      "\tspeed: 0.0117s/iter; left time: 37.1052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0611935 Vali Loss: 0.0714514 Test Loss: 0.0817338\n",
      "Validation loss decreased (0.071576 --> 0.071451).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0604725\n",
      "\tspeed: 0.0294s/iter; left time: 89.2865s\n",
      "\titers: 200, epoch: 7 | loss: 0.0604548\n",
      "\tspeed: 0.0118s/iter; left time: 34.5435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0605358 Vali Loss: 0.0712921 Test Loss: 0.0815184\n",
      "Validation loss decreased (0.071451 --> 0.071292).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0592130\n",
      "\tspeed: 0.0291s/iter; left time: 81.7847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590778\n",
      "\tspeed: 0.0116s/iter; left time: 31.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0599328 Vali Loss: 0.0709609 Test Loss: 0.0816006\n",
      "Validation loss decreased (0.071292 --> 0.070961).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0577401\n",
      "\tspeed: 0.0278s/iter; left time: 71.8713s\n",
      "\titers: 200, epoch: 9 | loss: 0.0619090\n",
      "\tspeed: 0.0114s/iter; left time: 28.4931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0595059 Vali Loss: 0.0710032 Test Loss: 0.0812286\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0633323\n",
      "\tspeed: 0.0285s/iter; left time: 67.3003s\n",
      "\titers: 200, epoch: 10 | loss: 0.0548593\n",
      "\tspeed: 0.0118s/iter; left time: 26.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0591519 Vali Loss: 0.0709546 Test Loss: 0.0809395\n",
      "Validation loss decreased (0.070961 --> 0.070955).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0578921\n",
      "\tspeed: 0.0302s/iter; left time: 64.7035s\n",
      "\titers: 200, epoch: 11 | loss: 0.0616430\n",
      "\tspeed: 0.0117s/iter; left time: 23.9195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0587993 Vali Loss: 0.0710152 Test Loss: 0.0811566\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0562681\n",
      "\tspeed: 0.0287s/iter; left time: 54.9371s\n",
      "\titers: 200, epoch: 12 | loss: 0.0630862\n",
      "\tspeed: 0.0114s/iter; left time: 20.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0585476 Vali Loss: 0.0710435 Test Loss: 0.0810608\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0615604\n",
      "\tspeed: 0.0283s/iter; left time: 47.9113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0607418\n",
      "\tspeed: 0.0115s/iter; left time: 18.2982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0582608 Vali Loss: 0.0711067 Test Loss: 0.0807557\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0583864\n",
      "\tspeed: 0.0282s/iter; left time: 41.4720s\n",
      "\titers: 200, epoch: 14 | loss: 0.0560069\n",
      "\tspeed: 0.0117s/iter; left time: 16.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0579940 Vali Loss: 0.0712457 Test Loss: 0.0812506\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0537845\n",
      "\tspeed: 0.0285s/iter; left time: 35.4472s\n",
      "\titers: 200, epoch: 15 | loss: 0.0620155\n",
      "\tspeed: 0.0118s/iter; left time: 13.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0578380 Vali Loss: 0.0711892 Test Loss: 0.0811719\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019235698506236076, rmse:0.13869282603263855, mae:0.08093950152397156, rse:0.5365006923675537\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:00.24s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1183062\n",
      "\tspeed: 0.0328s/iter; left time: 142.9406s\n",
      "\titers: 200, epoch: 1 | loss: 0.0972488\n",
      "\tspeed: 0.0118s/iter; left time: 50.3992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 223 | Train Loss: 0.1167069 Vali Loss: 0.1032240 Test Loss: 0.1129787\n",
      "Validation loss decreased (inf --> 0.103224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0826022\n",
      "\tspeed: 0.0281s/iter; left time: 116.1534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746639\n",
      "\tspeed: 0.0116s/iter; left time: 46.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0773228 Vali Loss: 0.0803081 Test Loss: 0.0886298\n",
      "Validation loss decreased (0.103224 --> 0.080308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714847\n",
      "\tspeed: 0.0288s/iter; left time: 112.7304s\n",
      "\titers: 200, epoch: 3 | loss: 0.0688747\n",
      "\tspeed: 0.0116s/iter; left time: 44.3167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0697671 Vali Loss: 0.0767658 Test Loss: 0.0878571\n",
      "Validation loss decreased (0.080308 --> 0.076766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0678537\n",
      "\tspeed: 0.0317s/iter; left time: 116.8599s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696913\n",
      "\tspeed: 0.0116s/iter; left time: 41.8282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0672740 Vali Loss: 0.0758421 Test Loss: 0.0871055\n",
      "Validation loss decreased (0.076766 --> 0.075842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679309\n",
      "\tspeed: 0.0289s/iter; left time: 100.1727s\n",
      "\titers: 200, epoch: 5 | loss: 0.0694386\n",
      "\tspeed: 0.0116s/iter; left time: 39.1876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0661240 Vali Loss: 0.0754434 Test Loss: 0.0868867\n",
      "Validation loss decreased (0.075842 --> 0.075443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640229\n",
      "\tspeed: 0.0287s/iter; left time: 93.2148s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638434\n",
      "\tspeed: 0.0116s/iter; left time: 36.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0653081 Vali Loss: 0.0750301 Test Loss: 0.0866583\n",
      "Validation loss decreased (0.075443 --> 0.075030).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656921\n",
      "\tspeed: 0.0290s/iter; left time: 87.6558s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664725\n",
      "\tspeed: 0.0116s/iter; left time: 34.0039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0647015 Vali Loss: 0.0748772 Test Loss: 0.0860748\n",
      "Validation loss decreased (0.075030 --> 0.074877).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0677239\n",
      "\tspeed: 0.0293s/iter; left time: 82.1328s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618351\n",
      "\tspeed: 0.0117s/iter; left time: 31.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0641984 Vali Loss: 0.0750208 Test Loss: 0.0871818\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654734\n",
      "\tspeed: 0.0285s/iter; left time: 73.3489s\n",
      "\titers: 200, epoch: 9 | loss: 0.0638321\n",
      "\tspeed: 0.0117s/iter; left time: 28.8734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0637861 Vali Loss: 0.0750694 Test Loss: 0.0867115\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0613091\n",
      "\tspeed: 0.0279s/iter; left time: 65.7059s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665837\n",
      "\tspeed: 0.0116s/iter; left time: 26.1477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0634266 Vali Loss: 0.0752134 Test Loss: 0.0868901\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667932\n",
      "\tspeed: 0.0286s/iter; left time: 60.9111s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656480\n",
      "\tspeed: 0.0119s/iter; left time: 24.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0631315 Vali Loss: 0.0750217 Test Loss: 0.0868845\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0645292\n",
      "\tspeed: 0.0282s/iter; left time: 53.8033s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635025\n",
      "\tspeed: 0.0116s/iter; left time: 20.9435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0628285 Vali Loss: 0.0754389 Test Loss: 0.0868052\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02051929198205471, rmse:0.14324556291103363, mae:0.08607485145330429, rse:0.5548036694526672\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163215\n",
      "\tspeed: 0.0138s/iter; left time: 59.9905s\n",
      "\titers: 200, epoch: 1 | loss: 0.1008288\n",
      "\tspeed: 0.0118s/iter; left time: 50.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.1164158 Vali Loss: 0.1032304 Test Loss: 0.1131373\n",
      "Validation loss decreased (inf --> 0.103230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0742068\n",
      "\tspeed: 0.0287s/iter; left time: 118.6475s\n",
      "\titers: 200, epoch: 2 | loss: 0.0729584\n",
      "\tspeed: 0.0116s/iter; left time: 46.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0772881 Vali Loss: 0.0804655 Test Loss: 0.0887936\n",
      "Validation loss decreased (0.103230 --> 0.080465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0693759\n",
      "\tspeed: 0.0283s/iter; left time: 110.7495s\n",
      "\titers: 200, epoch: 3 | loss: 0.0663430\n",
      "\tspeed: 0.0116s/iter; left time: 44.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0697295 Vali Loss: 0.0766993 Test Loss: 0.0879378\n",
      "Validation loss decreased (0.080465 --> 0.076699).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0690095\n",
      "\tspeed: 0.0287s/iter; left time: 105.9435s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655570\n",
      "\tspeed: 0.0117s/iter; left time: 41.8768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0672098 Vali Loss: 0.0757153 Test Loss: 0.0876326\n",
      "Validation loss decreased (0.076699 --> 0.075715).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0648292\n",
      "\tspeed: 0.0365s/iter; left time: 126.7079s\n",
      "\titers: 200, epoch: 5 | loss: 0.0636270\n",
      "\tspeed: 0.0118s/iter; left time: 39.8869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.61s\n",
      "Steps: 223 | Train Loss: 0.0660205 Vali Loss: 0.0755744 Test Loss: 0.0876081\n",
      "Validation loss decreased (0.075715 --> 0.075574).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0668137\n",
      "\tspeed: 0.0298s/iter; left time: 96.6959s\n",
      "\titers: 200, epoch: 6 | loss: 0.0653384\n",
      "\tspeed: 0.0119s/iter; left time: 37.2950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0652508 Vali Loss: 0.0750264 Test Loss: 0.0864856\n",
      "Validation loss decreased (0.075574 --> 0.075026).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0650892\n",
      "\tspeed: 0.0288s/iter; left time: 87.1309s\n",
      "\titers: 200, epoch: 7 | loss: 0.0644793\n",
      "\tspeed: 0.0117s/iter; left time: 34.1308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0645868 Vali Loss: 0.0750114 Test Loss: 0.0868331\n",
      "Validation loss decreased (0.075026 --> 0.075011).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0653592\n",
      "\tspeed: 0.0298s/iter; left time: 83.3679s\n",
      "\titers: 200, epoch: 8 | loss: 0.0653282\n",
      "\tspeed: 0.0118s/iter; left time: 31.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0641446 Vali Loss: 0.0748277 Test Loss: 0.0862671\n",
      "Validation loss decreased (0.075011 --> 0.074828).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0644312\n",
      "\tspeed: 0.0289s/iter; left time: 74.4920s\n",
      "\titers: 200, epoch: 9 | loss: 0.0615943\n",
      "\tspeed: 0.0116s/iter; left time: 28.7163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0637232 Vali Loss: 0.0751069 Test Loss: 0.0860124\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0620447\n",
      "\tspeed: 0.0285s/iter; left time: 66.9874s\n",
      "\titers: 200, epoch: 10 | loss: 0.0633003\n",
      "\tspeed: 0.0117s/iter; left time: 26.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0633491 Vali Loss: 0.0752738 Test Loss: 0.0857870\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0609704\n",
      "\tspeed: 0.0286s/iter; left time: 60.8659s\n",
      "\titers: 200, epoch: 11 | loss: 0.0661358\n",
      "\tspeed: 0.0117s/iter; left time: 23.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0630023 Vali Loss: 0.0749894 Test Loss: 0.0863085\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0640791\n",
      "\tspeed: 0.0289s/iter; left time: 55.0650s\n",
      "\titers: 200, epoch: 12 | loss: 0.0625561\n",
      "\tspeed: 0.0117s/iter; left time: 21.0709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0627204 Vali Loss: 0.0749291 Test Loss: 0.0859225\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0646269\n",
      "\tspeed: 0.0284s/iter; left time: 47.8859s\n",
      "\titers: 200, epoch: 13 | loss: 0.0641280\n",
      "\tspeed: 0.0117s/iter; left time: 18.5167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0624306 Vali Loss: 0.0750348 Test Loss: 0.0861682\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020482137799263, rmse:0.1431158185005188, mae:0.08626711368560791, rse:0.5543011426925659\n",
      "Intermediate time for FR and pred_len 168: 00h:01m:52.57s\n",
      "Intermediate time for FR: 00h:06m:41.56s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1628962\n",
      "\tspeed: 0.0321s/iter; left time: 140.8314s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291237\n",
      "\tspeed: 0.0115s/iter; left time: 49.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.03s\n",
      "Steps: 224 | Train Loss: 0.1621927 Vali Loss: 0.1139153 Test Loss: 0.1173210\n",
      "Validation loss decreased (inf --> 0.113915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784920\n",
      "\tspeed: 0.0274s/iter; left time: 113.9878s\n",
      "\titers: 200, epoch: 2 | loss: 0.0711628\n",
      "\tspeed: 0.0114s/iter; left time: 46.4289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0831000 Vali Loss: 0.0642116 Test Loss: 0.0672076\n",
      "Validation loss decreased (0.113915 --> 0.064212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0703022\n",
      "\tspeed: 0.0270s/iter; left time: 106.1965s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671893\n",
      "\tspeed: 0.0113s/iter; left time: 43.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0678163 Vali Loss: 0.0607519 Test Loss: 0.0635062\n",
      "Validation loss decreased (0.064212 --> 0.060752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609002\n",
      "\tspeed: 0.0281s/iter; left time: 104.3447s\n",
      "\titers: 200, epoch: 4 | loss: 0.0623605\n",
      "\tspeed: 0.0114s/iter; left time: 41.0350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0644234 Vali Loss: 0.0591367 Test Loss: 0.0617633\n",
      "Validation loss decreased (0.060752 --> 0.059137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633016\n",
      "\tspeed: 0.0279s/iter; left time: 97.3548s\n",
      "\titers: 200, epoch: 5 | loss: 0.0651986\n",
      "\tspeed: 0.0113s/iter; left time: 38.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0625412 Vali Loss: 0.0581853 Test Loss: 0.0606249\n",
      "Validation loss decreased (0.059137 --> 0.058185).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0649286\n",
      "\tspeed: 0.0270s/iter; left time: 88.0467s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616859\n",
      "\tspeed: 0.0115s/iter; left time: 36.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0611915 Vali Loss: 0.0574970 Test Loss: 0.0600334\n",
      "Validation loss decreased (0.058185 --> 0.057497).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590814\n",
      "\tspeed: 0.0272s/iter; left time: 82.7353s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585640\n",
      "\tspeed: 0.0113s/iter; left time: 33.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0602745 Vali Loss: 0.0569347 Test Loss: 0.0594827\n",
      "Validation loss decreased (0.057497 --> 0.056935).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0607947\n",
      "\tspeed: 0.0274s/iter; left time: 77.0214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0553050\n",
      "\tspeed: 0.0113s/iter; left time: 30.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0595292 Vali Loss: 0.0563626 Test Loss: 0.0592692\n",
      "Validation loss decreased (0.056935 --> 0.056363).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550640\n",
      "\tspeed: 0.0270s/iter; left time: 69.8897s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581901\n",
      "\tspeed: 0.0113s/iter; left time: 28.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0589363 Vali Loss: 0.0561472 Test Loss: 0.0590204\n",
      "Validation loss decreased (0.056363 --> 0.056147).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586622\n",
      "\tspeed: 0.0264s/iter; left time: 62.4701s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589459\n",
      "\tspeed: 0.0114s/iter; left time: 25.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0584518 Vali Loss: 0.0559549 Test Loss: 0.0588039\n",
      "Validation loss decreased (0.056147 --> 0.055955).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0604423\n",
      "\tspeed: 0.0271s/iter; left time: 58.0682s\n",
      "\titers: 200, epoch: 11 | loss: 0.0600132\n",
      "\tspeed: 0.0113s/iter; left time: 23.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0579917 Vali Loss: 0.0557425 Test Loss: 0.0584588\n",
      "Validation loss decreased (0.055955 --> 0.055742).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0585862\n",
      "\tspeed: 0.0272s/iter; left time: 52.2296s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565248\n",
      "\tspeed: 0.0113s/iter; left time: 20.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0575839 Vali Loss: 0.0553778 Test Loss: 0.0581512\n",
      "Validation loss decreased (0.055742 --> 0.055378).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0592767\n",
      "\tspeed: 0.0276s/iter; left time: 46.6804s\n",
      "\titers: 200, epoch: 13 | loss: 0.0601190\n",
      "\tspeed: 0.0113s/iter; left time: 18.0660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0572631 Vali Loss: 0.0554036 Test Loss: 0.0582940\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0584438\n",
      "\tspeed: 0.0269s/iter; left time: 39.5251s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597098\n",
      "\tspeed: 0.0114s/iter; left time: 15.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0570509 Vali Loss: 0.0552208 Test Loss: 0.0581448\n",
      "Validation loss decreased (0.055378 --> 0.055221).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0570238\n",
      "\tspeed: 0.0279s/iter; left time: 34.7792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0546779\n",
      "\tspeed: 0.0113s/iter; left time: 12.9547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0568364 Vali Loss: 0.0549905 Test Loss: 0.0578448\n",
      "Validation loss decreased (0.055221 --> 0.054990).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0585651\n",
      "\tspeed: 0.0272s/iter; left time: 27.7257s\n",
      "\titers: 200, epoch: 16 | loss: 0.0602605\n",
      "\tspeed: 0.0113s/iter; left time: 10.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0566376 Vali Loss: 0.0548767 Test Loss: 0.0577145\n",
      "Validation loss decreased (0.054990 --> 0.054877).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632500\n",
      "\tspeed: 0.0267s/iter; left time: 21.2693s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582883\n",
      "\tspeed: 0.0114s/iter; left time: 7.9652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0564069 Vali Loss: 0.0548520 Test Loss: 0.0575403\n",
      "Validation loss decreased (0.054877 --> 0.054852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549437\n",
      "\tspeed: 0.0271s/iter; left time: 15.5545s\n",
      "\titers: 200, epoch: 18 | loss: 0.0606063\n",
      "\tspeed: 0.0113s/iter; left time: 5.3661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0563488 Vali Loss: 0.0549136 Test Loss: 0.0575645\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0539349\n",
      "\tspeed: 0.0264s/iter; left time: 9.2265s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541664\n",
      "\tspeed: 0.0113s/iter; left time: 2.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0561536 Vali Loss: 0.0546398 Test Loss: 0.0574950\n",
      "Validation loss decreased (0.054852 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0571351\n",
      "\tspeed: 0.0274s/iter; left time: 3.4275s\n",
      "\titers: 200, epoch: 20 | loss: 0.0553324\n",
      "\tspeed: 0.0114s/iter; left time: 0.2846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0560287 Vali Loss: 0.0546072 Test Loss: 0.0573911\n",
      "Validation loss decreased (0.054640 --> 0.054607).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010179038159549236, rmse:0.10089121758937836, mae:0.05739111453294754, rse:0.3812182545661926\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1643064\n",
      "\tspeed: 0.0135s/iter; left time: 59.0639s\n",
      "\titers: 200, epoch: 1 | loss: 0.1332380\n",
      "\tspeed: 0.0113s/iter; left time: 48.2756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.1647739 Vali Loss: 0.1140934 Test Loss: 0.1179993\n",
      "Validation loss decreased (inf --> 0.114093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0783891\n",
      "\tspeed: 0.0273s/iter; left time: 113.2803s\n",
      "\titers: 200, epoch: 2 | loss: 0.0731892\n",
      "\tspeed: 0.0113s/iter; left time: 45.9796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0831498 Vali Loss: 0.0640458 Test Loss: 0.0669815\n",
      "Validation loss decreased (0.114093 --> 0.064046).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0668713\n",
      "\tspeed: 0.0262s/iter; left time: 103.0121s\n",
      "\titers: 200, epoch: 3 | loss: 0.0657760\n",
      "\tspeed: 0.0113s/iter; left time: 43.2574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0676153 Vali Loss: 0.0606492 Test Loss: 0.0632237\n",
      "Validation loss decreased (0.064046 --> 0.060649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0620542\n",
      "\tspeed: 0.0265s/iter; left time: 98.4674s\n",
      "\titers: 200, epoch: 4 | loss: 0.0630409\n",
      "\tspeed: 0.0113s/iter; left time: 40.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0642292 Vali Loss: 0.0588349 Test Loss: 0.0615947\n",
      "Validation loss decreased (0.060649 --> 0.058835).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629932\n",
      "\tspeed: 0.0265s/iter; left time: 92.2697s\n",
      "\titers: 200, epoch: 5 | loss: 0.0583962\n",
      "\tspeed: 0.0113s/iter; left time: 38.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0622446 Vali Loss: 0.0577234 Test Loss: 0.0604983\n",
      "Validation loss decreased (0.058835 --> 0.057723).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631058\n",
      "\tspeed: 0.0268s/iter; left time: 87.2526s\n",
      "\titers: 200, epoch: 6 | loss: 0.0636711\n",
      "\tspeed: 0.0115s/iter; left time: 36.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0609994 Vali Loss: 0.0572215 Test Loss: 0.0600380\n",
      "Validation loss decreased (0.057723 --> 0.057222).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0620245\n",
      "\tspeed: 0.0272s/iter; left time: 82.5019s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590188\n",
      "\tspeed: 0.0114s/iter; left time: 33.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0601276 Vali Loss: 0.0566568 Test Loss: 0.0594509\n",
      "Validation loss decreased (0.057222 --> 0.056657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0584333\n",
      "\tspeed: 0.0263s/iter; left time: 74.0808s\n",
      "\titers: 200, epoch: 8 | loss: 0.0558407\n",
      "\tspeed: 0.0113s/iter; left time: 30.5627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0593526 Vali Loss: 0.0562219 Test Loss: 0.0585741\n",
      "Validation loss decreased (0.056657 --> 0.056222).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0546636\n",
      "\tspeed: 0.0271s/iter; left time: 70.2266s\n",
      "\titers: 200, epoch: 9 | loss: 0.0594059\n",
      "\tspeed: 0.0113s/iter; left time: 28.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0587434 Vali Loss: 0.0561855 Test Loss: 0.0587512\n",
      "Validation loss decreased (0.056222 --> 0.056185).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0599125\n",
      "\tspeed: 0.0264s/iter; left time: 62.5541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551820\n",
      "\tspeed: 0.0113s/iter; left time: 25.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0582120 Vali Loss: 0.0557990 Test Loss: 0.0583509\n",
      "Validation loss decreased (0.056185 --> 0.055799).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0542246\n",
      "\tspeed: 0.0275s/iter; left time: 58.8962s\n",
      "\titers: 200, epoch: 11 | loss: 0.0568748\n",
      "\tspeed: 0.0117s/iter; left time: 23.9817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0578913 Vali Loss: 0.0554993 Test Loss: 0.0581651\n",
      "Validation loss decreased (0.055799 --> 0.055499).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0534663\n",
      "\tspeed: 0.0282s/iter; left time: 54.1318s\n",
      "\titers: 200, epoch: 12 | loss: 0.0535820\n",
      "\tspeed: 0.0115s/iter; left time: 20.9491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0575138 Vali Loss: 0.0551920 Test Loss: 0.0578730\n",
      "Validation loss decreased (0.055499 --> 0.055192).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0578202\n",
      "\tspeed: 0.0268s/iter; left time: 45.3700s\n",
      "\titers: 200, epoch: 13 | loss: 0.0523866\n",
      "\tspeed: 0.0113s/iter; left time: 18.0362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0571534 Vali Loss: 0.0551626 Test Loss: 0.0578474\n",
      "Validation loss decreased (0.055192 --> 0.055163).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0552824\n",
      "\tspeed: 0.0259s/iter; left time: 38.0826s\n",
      "\titers: 200, epoch: 14 | loss: 0.0516682\n",
      "\tspeed: 0.0113s/iter; left time: 15.4515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0569531 Vali Loss: 0.0551356 Test Loss: 0.0576503\n",
      "Validation loss decreased (0.055163 --> 0.055136).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0594676\n",
      "\tspeed: 0.0261s/iter; left time: 32.4792s\n",
      "\titers: 200, epoch: 15 | loss: 0.0545479\n",
      "\tspeed: 0.0113s/iter; left time: 12.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0566778 Vali Loss: 0.0548414 Test Loss: 0.0575935\n",
      "Validation loss decreased (0.055136 --> 0.054841).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0543843\n",
      "\tspeed: 0.0263s/iter; left time: 26.8968s\n",
      "\titers: 200, epoch: 16 | loss: 0.0565425\n",
      "\tspeed: 0.0113s/iter; left time: 10.4313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0565070 Vali Loss: 0.0548034 Test Loss: 0.0574594\n",
      "Validation loss decreased (0.054841 --> 0.054803).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0619975\n",
      "\tspeed: 0.0268s/iter; left time: 21.3236s\n",
      "\titers: 200, epoch: 17 | loss: 0.0535555\n",
      "\tspeed: 0.0113s/iter; left time: 7.8661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0563112 Vali Loss: 0.0548327 Test Loss: 0.0573983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0553390\n",
      "\tspeed: 0.0261s/iter; left time: 14.9370s\n",
      "\titers: 200, epoch: 18 | loss: 0.0519897\n",
      "\tspeed: 0.0113s/iter; left time: 5.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0561897 Vali Loss: 0.0547850 Test Loss: 0.0573173\n",
      "Validation loss decreased (0.054803 --> 0.054785).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0521124\n",
      "\tspeed: 0.0263s/iter; left time: 9.1845s\n",
      "\titers: 200, epoch: 19 | loss: 0.0521864\n",
      "\tspeed: 0.0113s/iter; left time: 2.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0559832 Vali Loss: 0.0548023 Test Loss: 0.0572995\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0512948\n",
      "\tspeed: 0.0260s/iter; left time: 3.2522s\n",
      "\titers: 200, epoch: 20 | loss: 0.0542285\n",
      "\tspeed: 0.0114s/iter; left time: 0.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0559045 Vali Loss: 0.0546398 Test Loss: 0.0573421\n",
      "Validation loss decreased (0.054785 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010212065652012825, rmse:0.10105476528406143, mae:0.057342130690813065, rse:0.3818362355232239\n",
      "Intermediate time for IT and pred_len 24: 00h:02m:42.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1694137\n",
      "\tspeed: 0.0322s/iter; left time: 140.9059s\n",
      "\titers: 200, epoch: 1 | loss: 0.1422566\n",
      "\tspeed: 0.0115s/iter; left time: 49.0680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.1661313 Vali Loss: 0.1205659 Test Loss: 0.1253998\n",
      "Validation loss decreased (inf --> 0.120566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982611\n",
      "\tspeed: 0.0290s/iter; left time: 120.7142s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932958\n",
      "\tspeed: 0.0115s/iter; left time: 46.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.1010618 Vali Loss: 0.0828836 Test Loss: 0.0877833\n",
      "Validation loss decreased (0.120566 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0864613\n",
      "\tspeed: 0.0281s/iter; left time: 110.5085s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823260\n",
      "\tspeed: 0.0115s/iter; left time: 44.1704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0868094 Vali Loss: 0.0794397 Test Loss: 0.0843617\n",
      "Validation loss decreased (0.082884 --> 0.079440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839486\n",
      "\tspeed: 0.0287s/iter; left time: 106.3726s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801206\n",
      "\tspeed: 0.0115s/iter; left time: 41.5647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0835503 Vali Loss: 0.0782552 Test Loss: 0.0835699\n",
      "Validation loss decreased (0.079440 --> 0.078255).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815459\n",
      "\tspeed: 0.0302s/iter; left time: 105.3279s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828756\n",
      "\tspeed: 0.0116s/iter; left time: 39.1408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0818222 Vali Loss: 0.0776317 Test Loss: 0.0827362\n",
      "Validation loss decreased (0.078255 --> 0.077632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834187\n",
      "\tspeed: 0.0317s/iter; left time: 103.4027s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795873\n",
      "\tspeed: 0.0115s/iter; left time: 36.3559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0805658 Vali Loss: 0.0772948 Test Loss: 0.0826314\n",
      "Validation loss decreased (0.077632 --> 0.077295).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0768925\n",
      "\tspeed: 0.0284s/iter; left time: 86.2397s\n",
      "\titers: 200, epoch: 7 | loss: 0.0789800\n",
      "\tspeed: 0.0116s/iter; left time: 33.9809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0796422 Vali Loss: 0.0770975 Test Loss: 0.0823685\n",
      "Validation loss decreased (0.077295 --> 0.077098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801099\n",
      "\tspeed: 0.0291s/iter; left time: 81.9227s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806852\n",
      "\tspeed: 0.0115s/iter; left time: 31.3275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0789244 Vali Loss: 0.0767069 Test Loss: 0.0817630\n",
      "Validation loss decreased (0.077098 --> 0.076707).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0756710\n",
      "\tspeed: 0.0288s/iter; left time: 74.6022s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760978\n",
      "\tspeed: 0.0115s/iter; left time: 28.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0782492 Vali Loss: 0.0765156 Test Loss: 0.0816814\n",
      "Validation loss decreased (0.076707 --> 0.076516).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783817\n",
      "\tspeed: 0.0280s/iter; left time: 66.1651s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794710\n",
      "\tspeed: 0.0115s/iter; left time: 26.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0776505 Vali Loss: 0.0763667 Test Loss: 0.0815143\n",
      "Validation loss decreased (0.076516 --> 0.076367).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764569\n",
      "\tspeed: 0.0292s/iter; left time: 62.4961s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764720\n",
      "\tspeed: 0.0115s/iter; left time: 23.5634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0772299 Vali Loss: 0.0762668 Test Loss: 0.0814972\n",
      "Validation loss decreased (0.076367 --> 0.076267).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0755686\n",
      "\tspeed: 0.0285s/iter; left time: 54.5823s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748391\n",
      "\tspeed: 0.0116s/iter; left time: 21.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0767714 Vali Loss: 0.0761280 Test Loss: 0.0812074\n",
      "Validation loss decreased (0.076267 --> 0.076128).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782008\n",
      "\tspeed: 0.0295s/iter; left time: 49.9895s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751148\n",
      "\tspeed: 0.0115s/iter; left time: 18.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0763727 Vali Loss: 0.0763362 Test Loss: 0.0812979\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707611\n",
      "\tspeed: 0.0284s/iter; left time: 41.7819s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763229\n",
      "\tspeed: 0.0115s/iter; left time: 15.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0760496 Vali Loss: 0.0761597 Test Loss: 0.0812481\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798078\n",
      "\tspeed: 0.0284s/iter; left time: 35.3032s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711448\n",
      "\tspeed: 0.0115s/iter; left time: 13.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0757627 Vali Loss: 0.0761455 Test Loss: 0.0810610\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709446\n",
      "\tspeed: 0.0284s/iter; left time: 29.0244s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774027\n",
      "\tspeed: 0.0115s/iter; left time: 10.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0754142 Vali Loss: 0.0760802 Test Loss: 0.0811172\n",
      "Validation loss decreased (0.076128 --> 0.076080).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734147\n",
      "\tspeed: 0.0290s/iter; left time: 23.0817s\n",
      "\titers: 200, epoch: 17 | loss: 0.0760152\n",
      "\tspeed: 0.0115s/iter; left time: 8.0491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0751861 Vali Loss: 0.0760274 Test Loss: 0.0810721\n",
      "Validation loss decreased (0.076080 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773675\n",
      "\tspeed: 0.0284s/iter; left time: 16.2618s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752099\n",
      "\tspeed: 0.0116s/iter; left time: 5.4758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0749369 Vali Loss: 0.0759469 Test Loss: 0.0809807\n",
      "Validation loss decreased (0.076027 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726778\n",
      "\tspeed: 0.0287s/iter; left time: 10.0274s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723060\n",
      "\tspeed: 0.0115s/iter; left time: 2.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0747569 Vali Loss: 0.0760007 Test Loss: 0.0810970\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0714997\n",
      "\tspeed: 0.0285s/iter; left time: 3.5624s\n",
      "\titers: 200, epoch: 20 | loss: 0.0753793\n",
      "\tspeed: 0.0115s/iter; left time: 0.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0746135 Vali Loss: 0.0759967 Test Loss: 0.0809578\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018395546823740005, rmse:0.13563019037246704, mae:0.08098065108060837, rse:0.5128323435783386\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1659828\n",
      "\tspeed: 0.0185s/iter; left time: 80.9585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1377545\n",
      "\tspeed: 0.0115s/iter; left time: 49.2370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.32s\n",
      "Steps: 224 | Train Loss: 0.1651078 Vali Loss: 0.1197496 Test Loss: 0.1245617\n",
      "Validation loss decreased (inf --> 0.119750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1041728\n",
      "\tspeed: 0.0281s/iter; left time: 116.7155s\n",
      "\titers: 200, epoch: 2 | loss: 0.0899635\n",
      "\tspeed: 0.0115s/iter; left time: 46.8451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.1007306 Vali Loss: 0.0832745 Test Loss: 0.0876749\n",
      "Validation loss decreased (0.119750 --> 0.083274).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0899828\n",
      "\tspeed: 0.0281s/iter; left time: 110.6926s\n",
      "\titers: 200, epoch: 3 | loss: 0.0884937\n",
      "\tspeed: 0.0115s/iter; left time: 44.2508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0869526 Vali Loss: 0.0797011 Test Loss: 0.0844012\n",
      "Validation loss decreased (0.083274 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0844673\n",
      "\tspeed: 0.0284s/iter; left time: 105.4245s\n",
      "\titers: 200, epoch: 4 | loss: 0.0826469\n",
      "\tspeed: 0.0115s/iter; left time: 41.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0837113 Vali Loss: 0.0787353 Test Loss: 0.0831461\n",
      "Validation loss decreased (0.079701 --> 0.078735).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0856277\n",
      "\tspeed: 0.0282s/iter; left time: 98.2904s\n",
      "\titers: 200, epoch: 5 | loss: 0.0847376\n",
      "\tspeed: 0.0116s/iter; left time: 39.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0817940 Vali Loss: 0.0780197 Test Loss: 0.0824059\n",
      "Validation loss decreased (0.078735 --> 0.078020).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0799199\n",
      "\tspeed: 0.0281s/iter; left time: 91.4724s\n",
      "\titers: 200, epoch: 6 | loss: 0.0797415\n",
      "\tspeed: 0.0116s/iter; left time: 36.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0804718 Vali Loss: 0.0775971 Test Loss: 0.0818354\n",
      "Validation loss decreased (0.078020 --> 0.077597).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792248\n",
      "\tspeed: 0.0280s/iter; left time: 84.9436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814994\n",
      "\tspeed: 0.0115s/iter; left time: 33.7767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0795296 Vali Loss: 0.0773038 Test Loss: 0.0817166\n",
      "Validation loss decreased (0.077597 --> 0.077304).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807771\n",
      "\tspeed: 0.0280s/iter; left time: 78.7140s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778802\n",
      "\tspeed: 0.0116s/iter; left time: 31.4060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0788082 Vali Loss: 0.0770593 Test Loss: 0.0815343\n",
      "Validation loss decreased (0.077304 --> 0.077059).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779113\n",
      "\tspeed: 0.0276s/iter; left time: 71.5707s\n",
      "\titers: 200, epoch: 9 | loss: 0.0765582\n",
      "\tspeed: 0.0115s/iter; left time: 28.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0782034 Vali Loss: 0.0769300 Test Loss: 0.0815683\n",
      "Validation loss decreased (0.077059 --> 0.076930).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0745629\n",
      "\tspeed: 0.0278s/iter; left time: 65.7567s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756760\n",
      "\tspeed: 0.0115s/iter; left time: 26.1083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0776538 Vali Loss: 0.0768092 Test Loss: 0.0813674\n",
      "Validation loss decreased (0.076930 --> 0.076809).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764665\n",
      "\tspeed: 0.0278s/iter; left time: 59.5152s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809056\n",
      "\tspeed: 0.0116s/iter; left time: 23.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0772223 Vali Loss: 0.0768539 Test Loss: 0.0814002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0786310\n",
      "\tspeed: 0.0274s/iter; left time: 52.4824s\n",
      "\titers: 200, epoch: 12 | loss: 0.0731935\n",
      "\tspeed: 0.0116s/iter; left time: 21.0102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0768144 Vali Loss: 0.0769477 Test Loss: 0.0813958\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0762809\n",
      "\tspeed: 0.0272s/iter; left time: 45.9776s\n",
      "\titers: 200, epoch: 13 | loss: 0.0762783\n",
      "\tspeed: 0.0116s/iter; left time: 18.4040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0764390 Vali Loss: 0.0768751 Test Loss: 0.0811918\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0726768\n",
      "\tspeed: 0.0274s/iter; left time: 40.2532s\n",
      "\titers: 200, epoch: 14 | loss: 0.0798649\n",
      "\tspeed: 0.0115s/iter; left time: 15.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0761796 Vali Loss: 0.0765816 Test Loss: 0.0812422\n",
      "Validation loss decreased (0.076809 --> 0.076582).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0803482\n",
      "\tspeed: 0.0278s/iter; left time: 34.5811s\n",
      "\titers: 200, epoch: 15 | loss: 0.0738454\n",
      "\tspeed: 0.0116s/iter; left time: 13.2487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0758314 Vali Loss: 0.0767500 Test Loss: 0.0811962\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0800447\n",
      "\tspeed: 0.0276s/iter; left time: 28.1365s\n",
      "\titers: 200, epoch: 16 | loss: 0.0752598\n",
      "\tspeed: 0.0115s/iter; left time: 10.5840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0756317 Vali Loss: 0.0765777 Test Loss: 0.0811239\n",
      "Validation loss decreased (0.076582 --> 0.076578).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782356\n",
      "\tspeed: 0.0276s/iter; left time: 21.9743s\n",
      "\titers: 200, epoch: 17 | loss: 0.0716928\n",
      "\tspeed: 0.0115s/iter; left time: 8.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0753781 Vali Loss: 0.0766676 Test Loss: 0.0810611\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713939\n",
      "\tspeed: 0.0273s/iter; left time: 15.6425s\n",
      "\titers: 200, epoch: 18 | loss: 0.0712077\n",
      "\tspeed: 0.0115s/iter; left time: 5.4360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0751830 Vali Loss: 0.0766489 Test Loss: 0.0810038\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0750694\n",
      "\tspeed: 0.0273s/iter; left time: 9.5345s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721135\n",
      "\tspeed: 0.0116s/iter; left time: 2.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0750273 Vali Loss: 0.0766039 Test Loss: 0.0810596\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0684590\n",
      "\tspeed: 0.0278s/iter; left time: 3.4764s\n",
      "\titers: 200, epoch: 20 | loss: 0.0789137\n",
      "\tspeed: 0.0117s/iter; left time: 0.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0748275 Vali Loss: 0.0766555 Test Loss: 0.0809131\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018500106409192085, rmse:0.13601510226726532, mae:0.08112388104200363, rse:0.5142877101898193\n",
      "Intermediate time for IT and pred_len 96: 00h:02m:49.36s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1690010\n",
      "\tspeed: 0.0333s/iter; left time: 145.3071s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379525\n",
      "\tspeed: 0.0118s/iter; left time: 50.1914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 223 | Train Loss: 0.1674818 Vali Loss: 0.1228408 Test Loss: 0.1272520\n",
      "Validation loss decreased (inf --> 0.122841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1055019\n",
      "\tspeed: 0.0284s/iter; left time: 117.4111s\n",
      "\titers: 200, epoch: 2 | loss: 0.0947789\n",
      "\tspeed: 0.0116s/iter; left time: 46.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.1046888 Vali Loss: 0.0870983 Test Loss: 0.0914740\n",
      "Validation loss decreased (0.122841 --> 0.087098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945887\n",
      "\tspeed: 0.0290s/iter; left time: 113.5805s\n",
      "\titers: 200, epoch: 3 | loss: 0.0912248\n",
      "\tspeed: 0.0116s/iter; left time: 44.1977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0910463 Vali Loss: 0.0845167 Test Loss: 0.0886465\n",
      "Validation loss decreased (0.087098 --> 0.084517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0890638\n",
      "\tspeed: 0.0283s/iter; left time: 104.3749s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876659\n",
      "\tspeed: 0.0116s/iter; left time: 41.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0876957 Vali Loss: 0.0838203 Test Loss: 0.0880159\n",
      "Validation loss decreased (0.084517 --> 0.083820).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888273\n",
      "\tspeed: 0.0292s/iter; left time: 101.4495s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901279\n",
      "\tspeed: 0.0118s/iter; left time: 39.9192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0858796 Vali Loss: 0.0827751 Test Loss: 0.0877248\n",
      "Validation loss decreased (0.083820 --> 0.082775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843554\n",
      "\tspeed: 0.0294s/iter; left time: 95.4344s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846031\n",
      "\tspeed: 0.0117s/iter; left time: 36.6958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0846602 Vali Loss: 0.0825831 Test Loss: 0.0875698\n",
      "Validation loss decreased (0.082775 --> 0.082583).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839404\n",
      "\tspeed: 0.0290s/iter; left time: 87.5380s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820961\n",
      "\tspeed: 0.0116s/iter; left time: 33.8688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0836598 Vali Loss: 0.0826961 Test Loss: 0.0873808\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0833263\n",
      "\tspeed: 0.0287s/iter; left time: 80.2427s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827962\n",
      "\tspeed: 0.0117s/iter; left time: 31.5688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0828944 Vali Loss: 0.0821371 Test Loss: 0.0873078\n",
      "Validation loss decreased (0.082583 --> 0.082137).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822694\n",
      "\tspeed: 0.0287s/iter; left time: 74.0251s\n",
      "\titers: 200, epoch: 9 | loss: 0.0826395\n",
      "\tspeed: 0.0119s/iter; left time: 29.4516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0822426 Vali Loss: 0.0819558 Test Loss: 0.0873221\n",
      "Validation loss decreased (0.082137 --> 0.081956).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777007\n",
      "\tspeed: 0.0292s/iter; left time: 68.7713s\n",
      "\titers: 200, epoch: 10 | loss: 0.0856002\n",
      "\tspeed: 0.0117s/iter; left time: 26.2940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0817157 Vali Loss: 0.0821818 Test Loss: 0.0874224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795958\n",
      "\tspeed: 0.0279s/iter; left time: 59.4082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828160\n",
      "\tspeed: 0.0116s/iter; left time: 23.6572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0812583 Vali Loss: 0.0822034 Test Loss: 0.0871338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838655\n",
      "\tspeed: 0.0291s/iter; left time: 55.4707s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794579\n",
      "\tspeed: 0.0118s/iter; left time: 21.4006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0807852 Vali Loss: 0.0821391 Test Loss: 0.0870446\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816532\n",
      "\tspeed: 0.0277s/iter; left time: 46.7095s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783536\n",
      "\tspeed: 0.0116s/iter; left time: 18.3963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0804130 Vali Loss: 0.0822525 Test Loss: 0.0869995\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825000\n",
      "\tspeed: 0.0288s/iter; left time: 42.0523s\n",
      "\titers: 200, epoch: 14 | loss: 0.0804190\n",
      "\tspeed: 0.0119s/iter; left time: 16.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0800701 Vali Loss: 0.0822010 Test Loss: 0.0872152\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020744217559695244, rmse:0.14402852952480316, mae:0.08732207864522934, rse:0.5450934767723083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1728229\n",
      "\tspeed: 0.0146s/iter; left time: 63.7496s\n",
      "\titers: 200, epoch: 1 | loss: 0.1374964\n",
      "\tspeed: 0.0119s/iter; left time: 50.6436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 223 | Train Loss: 0.1687018 Vali Loss: 0.1234342 Test Loss: 0.1279982\n",
      "Validation loss decreased (inf --> 0.123434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1038418\n",
      "\tspeed: 0.0292s/iter; left time: 120.7189s\n",
      "\titers: 200, epoch: 2 | loss: 0.0941175\n",
      "\tspeed: 0.0117s/iter; left time: 47.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.1045210 Vali Loss: 0.0871740 Test Loss: 0.0917077\n",
      "Validation loss decreased (0.123434 --> 0.087174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0930343\n",
      "\tspeed: 0.0318s/iter; left time: 124.3571s\n",
      "\titers: 200, epoch: 3 | loss: 0.0850276\n",
      "\tspeed: 0.0116s/iter; left time: 44.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0911007 Vali Loss: 0.0846023 Test Loss: 0.0887443\n",
      "Validation loss decreased (0.087174 --> 0.084602).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857418\n",
      "\tspeed: 0.0292s/iter; left time: 107.7636s\n",
      "\titers: 200, epoch: 4 | loss: 0.0871077\n",
      "\tspeed: 0.0116s/iter; left time: 41.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0878101 Vali Loss: 0.0834646 Test Loss: 0.0878316\n",
      "Validation loss decreased (0.084602 --> 0.083465).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859645\n",
      "\tspeed: 0.0285s/iter; left time: 98.7949s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848323\n",
      "\tspeed: 0.0116s/iter; left time: 38.9909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0858897 Vali Loss: 0.0828111 Test Loss: 0.0874313\n",
      "Validation loss decreased (0.083465 --> 0.082811).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0838870\n",
      "\tspeed: 0.0296s/iter; left time: 96.1081s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844055\n",
      "\tspeed: 0.0116s/iter; left time: 36.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0845650 Vali Loss: 0.0827209 Test Loss: 0.0872308\n",
      "Validation loss decreased (0.082811 --> 0.082721).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0821112\n",
      "\tspeed: 0.0284s/iter; left time: 85.8596s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814037\n",
      "\tspeed: 0.0117s/iter; left time: 34.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0835194 Vali Loss: 0.0824771 Test Loss: 0.0871494\n",
      "Validation loss decreased (0.082721 --> 0.082477).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815682\n",
      "\tspeed: 0.0284s/iter; left time: 79.4926s\n",
      "\titers: 200, epoch: 8 | loss: 0.0851163\n",
      "\tspeed: 0.0116s/iter; left time: 31.3429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0827619 Vali Loss: 0.0826948 Test Loss: 0.0870347\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843730\n",
      "\tspeed: 0.0274s/iter; left time: 70.6490s\n",
      "\titers: 200, epoch: 9 | loss: 0.0853319\n",
      "\tspeed: 0.0116s/iter; left time: 28.8162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0821315 Vali Loss: 0.0826753 Test Loss: 0.0870150\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0810438\n",
      "\tspeed: 0.0278s/iter; left time: 65.4689s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787690\n",
      "\tspeed: 0.0116s/iter; left time: 26.2422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0815343 Vali Loss: 0.0824560 Test Loss: 0.0871205\n",
      "Validation loss decreased (0.082477 --> 0.082456).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0786969\n",
      "\tspeed: 0.0285s/iter; left time: 60.6654s\n",
      "\titers: 200, epoch: 11 | loss: 0.0804603\n",
      "\tspeed: 0.0119s/iter; left time: 24.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0810415 Vali Loss: 0.0826562 Test Loss: 0.0870654\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0778386\n",
      "\tspeed: 0.0277s/iter; left time: 52.7735s\n",
      "\titers: 200, epoch: 12 | loss: 0.0787151\n",
      "\tspeed: 0.0117s/iter; left time: 21.0780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0806434 Vali Loss: 0.0829397 Test Loss: 0.0868908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0840895\n",
      "\tspeed: 0.0284s/iter; left time: 47.8581s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783719\n",
      "\tspeed: 0.0119s/iter; left time: 18.8772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0802445 Vali Loss: 0.0827911 Test Loss: 0.0864662\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0831609\n",
      "\tspeed: 0.0281s/iter; left time: 41.0208s\n",
      "\titers: 200, epoch: 14 | loss: 0.0801993\n",
      "\tspeed: 0.0119s/iter; left time: 16.2479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0799630 Vali Loss: 0.0827387 Test Loss: 0.0868728\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797336\n",
      "\tspeed: 0.0281s/iter; left time: 34.8661s\n",
      "\titers: 200, epoch: 15 | loss: 0.0788411\n",
      "\tspeed: 0.0118s/iter; left time: 13.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0796749 Vali Loss: 0.0828900 Test Loss: 0.0868879\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02060188353061676, rmse:0.14353355765342712, mae:0.08712054044008255, rse:0.5432202219963074\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:07.05s\n",
      "Intermediate time for IT: 00h:07m:39.07s\n",
      "Total time: 00h:38m:29.16s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "patchtst_df_itrs = pd.DataFrame(patchtst_results)\n",
    "\n",
    "# Set multi-index \n",
    "patchtst_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df_itrs.to_csv(os.path.join(path, 'patchtst_df_itrs_128.csv'))\n",
    "patchtst_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>0.0811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0211  0.1452  0.0882\n",
       "        96         0.0377  0.1940  0.1280\n",
       "        168        0.0397  0.1991  0.1350\n",
       "ES      24         0.0100  0.0998  0.0604\n",
       "        96         0.0188  0.1370  0.0878\n",
       "        168        0.0210  0.1451  0.0936\n",
       "FR      24         0.0102  0.1010  0.0559\n",
       "        96         0.0192  0.1384  0.0810\n",
       "        168        0.0205  0.1432  0.0862\n",
       "GB      24         0.0257  0.1603  0.1008\n",
       "        96         0.0430  0.2074  0.1414\n",
       "        168        0.0455  0.2134  0.1478\n",
       "IT      24         0.0102  0.1010  0.0574\n",
       "        96         0.0184  0.1358  0.0811\n",
       "        168        0.0207  0.1438  0.0872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final DF\n",
    "patchtst_df = patchtst_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 512\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1373355\n",
      "\tspeed: 0.0457s/iter; left time: 199.3868s\n",
      "\titers: 200, epoch: 1 | loss: 0.1334118\n",
      "\tspeed: 0.0249s/iter; left time: 106.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.1453993 Vali Loss: 0.1329783 Test Loss: 0.1404441\n",
      "Validation loss decreased (inf --> 0.132978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888796\n",
      "\tspeed: 0.0490s/iter; left time: 202.8774s\n",
      "\titers: 200, epoch: 2 | loss: 0.0831336\n",
      "\tspeed: 0.0249s/iter; left time: 100.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0907415 Vali Loss: 0.0933192 Test Loss: 0.0952993\n",
      "Validation loss decreased (0.132978 --> 0.093319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792083\n",
      "\tspeed: 0.0500s/iter; left time: 195.7325s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782485\n",
      "\tspeed: 0.0250s/iter; left time: 95.4262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0800919 Vali Loss: 0.0906347 Test Loss: 0.0927831\n",
      "Validation loss decreased (0.093319 --> 0.090635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760983\n",
      "\tspeed: 0.0495s/iter; left time: 182.8128s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804803\n",
      "\tspeed: 0.0250s/iter; left time: 89.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0776514 Vali Loss: 0.0891426 Test Loss: 0.0911534\n",
      "Validation loss decreased (0.090635 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0731426\n",
      "\tspeed: 0.0497s/iter; left time: 172.4770s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730842\n",
      "\tspeed: 0.0250s/iter; left time: 84.1632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0762323 Vali Loss: 0.0887006 Test Loss: 0.0911575\n",
      "Validation loss decreased (0.089143 --> 0.088701).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770437\n",
      "\tspeed: 0.0499s/iter; left time: 161.9939s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688699\n",
      "\tspeed: 0.0250s/iter; left time: 78.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0752050 Vali Loss: 0.0875822 Test Loss: 0.0899144\n",
      "Validation loss decreased (0.088701 --> 0.087582).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776841\n",
      "\tspeed: 0.0497s/iter; left time: 150.2287s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760563\n",
      "\tspeed: 0.0250s/iter; left time: 73.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0744924 Vali Loss: 0.0878255 Test Loss: 0.0900309\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724099\n",
      "\tspeed: 0.0491s/iter; left time: 137.3829s\n",
      "\titers: 200, epoch: 8 | loss: 0.0770502\n",
      "\tspeed: 0.0251s/iter; left time: 67.6885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0739047 Vali Loss: 0.0875601 Test Loss: 0.0895829\n",
      "Validation loss decreased (0.087582 --> 0.087560).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0735691\n",
      "\tspeed: 0.0490s/iter; left time: 126.1622s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746017\n",
      "\tspeed: 0.0250s/iter; left time: 61.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0733632 Vali Loss: 0.0873396 Test Loss: 0.0894276\n",
      "Validation loss decreased (0.087560 --> 0.087340).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712517\n",
      "\tspeed: 0.0490s/iter; left time: 115.4570s\n",
      "\titers: 200, epoch: 10 | loss: 0.0719973\n",
      "\tspeed: 0.0250s/iter; left time: 56.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0730056 Vali Loss: 0.0871200 Test Loss: 0.0890380\n",
      "Validation loss decreased (0.087340 --> 0.087120).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736760\n",
      "\tspeed: 0.0492s/iter; left time: 104.7781s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749013\n",
      "\tspeed: 0.0250s/iter; left time: 50.7884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0726510 Vali Loss: 0.0867601 Test Loss: 0.0890658\n",
      "Validation loss decreased (0.087120 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733816\n",
      "\tspeed: 0.0490s/iter; left time: 93.5557s\n",
      "\titers: 200, epoch: 12 | loss: 0.0710724\n",
      "\tspeed: 0.0250s/iter; left time: 45.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0723448 Vali Loss: 0.0869641 Test Loss: 0.0890288\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775656\n",
      "\tspeed: 0.0488s/iter; left time: 82.2093s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687345\n",
      "\tspeed: 0.0251s/iter; left time: 39.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0720741 Vali Loss: 0.0867219 Test Loss: 0.0888413\n",
      "Validation loss decreased (0.086760 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752403\n",
      "\tspeed: 0.0490s/iter; left time: 71.6950s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746249\n",
      "\tspeed: 0.0250s/iter; left time: 34.0516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0718593 Vali Loss: 0.0864101 Test Loss: 0.0884662\n",
      "Validation loss decreased (0.086722 --> 0.086410).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0715580\n",
      "\tspeed: 0.0493s/iter; left time: 61.0501s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659076\n",
      "\tspeed: 0.0250s/iter; left time: 28.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0717240 Vali Loss: 0.0864764 Test Loss: 0.0888205\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0784111\n",
      "\tspeed: 0.0491s/iter; left time: 49.9073s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652250\n",
      "\tspeed: 0.0250s/iter; left time: 22.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0714541 Vali Loss: 0.0865088 Test Loss: 0.0888026\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695369\n",
      "\tspeed: 0.0496s/iter; left time: 39.3088s\n",
      "\titers: 200, epoch: 17 | loss: 0.0679761\n",
      "\tspeed: 0.0250s/iter; left time: 17.3283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0713016 Vali Loss: 0.0866600 Test Loss: 0.0888405\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0707704\n",
      "\tspeed: 0.0490s/iter; left time: 27.9288s\n",
      "\titers: 200, epoch: 18 | loss: 0.0674867\n",
      "\tspeed: 0.0250s/iter; left time: 11.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0711602 Vali Loss: 0.0860936 Test Loss: 0.0882517\n",
      "Validation loss decreased (0.086410 --> 0.086094).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734340\n",
      "\tspeed: 0.0497s/iter; left time: 17.2329s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713441\n",
      "\tspeed: 0.0249s/iter; left time: 6.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0710292 Vali Loss: 0.0862774 Test Loss: 0.0884907\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0644633\n",
      "\tspeed: 0.0489s/iter; left time: 6.0581s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701132\n",
      "\tspeed: 0.0250s/iter; left time: 0.5993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0709714 Vali Loss: 0.0861165 Test Loss: 0.0884363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02113972045481205, rmse:0.14539505541324615, mae:0.08825169503688812, rse:0.5131192803382874\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1387260\n",
      "\tspeed: 0.0268s/iter; left time: 116.8880s\n",
      "\titers: 200, epoch: 1 | loss: 0.1324830\n",
      "\tspeed: 0.0249s/iter; left time: 106.2605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.1422265 Vali Loss: 0.1323882 Test Loss: 0.1402231\n",
      "Validation loss decreased (inf --> 0.132388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0881633\n",
      "\tspeed: 0.0490s/iter; left time: 202.8462s\n",
      "\titers: 200, epoch: 2 | loss: 0.0869370\n",
      "\tspeed: 0.0251s/iter; left time: 101.2003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0903240 Vali Loss: 0.0937527 Test Loss: 0.0951589\n",
      "Validation loss decreased (0.132388 --> 0.093753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0821824\n",
      "\tspeed: 0.0491s/iter; left time: 192.3118s\n",
      "\titers: 200, epoch: 3 | loss: 0.0797993\n",
      "\tspeed: 0.0251s/iter; left time: 95.6078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0801487 Vali Loss: 0.0902874 Test Loss: 0.0924725\n",
      "Validation loss decreased (0.093753 --> 0.090287).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0778300\n",
      "\tspeed: 0.0487s/iter; left time: 179.8589s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749223\n",
      "\tspeed: 0.0249s/iter; left time: 89.5862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0775661 Vali Loss: 0.0892974 Test Loss: 0.0914376\n",
      "Validation loss decreased (0.090287 --> 0.089297).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0769507\n",
      "\tspeed: 0.0489s/iter; left time: 169.6334s\n",
      "\titers: 200, epoch: 5 | loss: 0.0768380\n",
      "\tspeed: 0.0249s/iter; left time: 84.0407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0760782 Vali Loss: 0.0889501 Test Loss: 0.0910797\n",
      "Validation loss decreased (0.089297 --> 0.088950).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768618\n",
      "\tspeed: 0.0494s/iter; left time: 160.4455s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756993\n",
      "\tspeed: 0.0250s/iter; left time: 78.6890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0750654 Vali Loss: 0.0880747 Test Loss: 0.0902579\n",
      "Validation loss decreased (0.088950 --> 0.088075).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731461\n",
      "\tspeed: 0.0501s/iter; left time: 151.4604s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774921\n",
      "\tspeed: 0.0250s/iter; left time: 73.0115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0742952 Vali Loss: 0.0876327 Test Loss: 0.0900111\n",
      "Validation loss decreased (0.088075 --> 0.087633).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776454\n",
      "\tspeed: 0.0518s/iter; left time: 144.9353s\n",
      "\titers: 200, epoch: 8 | loss: 0.0741013\n",
      "\tspeed: 0.0250s/iter; left time: 67.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0737748 Vali Loss: 0.0873966 Test Loss: 0.0896094\n",
      "Validation loss decreased (0.087633 --> 0.087397).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758426\n",
      "\tspeed: 0.0503s/iter; left time: 129.5705s\n",
      "\titers: 200, epoch: 9 | loss: 0.0721907\n",
      "\tspeed: 0.0252s/iter; left time: 62.3020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0733159 Vali Loss: 0.0870264 Test Loss: 0.0894529\n",
      "Validation loss decreased (0.087397 --> 0.087026).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0737975\n",
      "\tspeed: 0.0514s/iter; left time: 120.9728s\n",
      "\titers: 200, epoch: 10 | loss: 0.0756847\n",
      "\tspeed: 0.0250s/iter; left time: 56.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0729094 Vali Loss: 0.0873865 Test Loss: 0.0895283\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0738934\n",
      "\tspeed: 0.0485s/iter; left time: 103.3111s\n",
      "\titers: 200, epoch: 11 | loss: 0.0704107\n",
      "\tspeed: 0.0250s/iter; left time: 50.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0726011 Vali Loss: 0.0867967 Test Loss: 0.0889862\n",
      "Validation loss decreased (0.087026 --> 0.086797).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0739036\n",
      "\tspeed: 0.0503s/iter; left time: 96.0113s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699825\n",
      "\tspeed: 0.0253s/iter; left time: 45.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0722698 Vali Loss: 0.0866896 Test Loss: 0.0890082\n",
      "Validation loss decreased (0.086797 --> 0.086690).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0681471\n",
      "\tspeed: 0.0503s/iter; left time: 84.6751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0717300\n",
      "\tspeed: 0.0250s/iter; left time: 39.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0720004 Vali Loss: 0.0864829 Test Loss: 0.0886948\n",
      "Validation loss decreased (0.086690 --> 0.086483).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0715130\n",
      "\tspeed: 0.0492s/iter; left time: 71.8976s\n",
      "\titers: 200, epoch: 14 | loss: 0.0686836\n",
      "\tspeed: 0.0251s/iter; left time: 34.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0717527 Vali Loss: 0.0866668 Test Loss: 0.0888871\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0708634\n",
      "\tspeed: 0.0487s/iter; left time: 60.2789s\n",
      "\titers: 200, epoch: 15 | loss: 0.0683472\n",
      "\tspeed: 0.0250s/iter; left time: 28.4288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0716079 Vali Loss: 0.0864506 Test Loss: 0.0887673\n",
      "Validation loss decreased (0.086483 --> 0.086451).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0710361\n",
      "\tspeed: 0.0494s/iter; left time: 50.2099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0785230\n",
      "\tspeed: 0.0249s/iter; left time: 22.8512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0714277 Vali Loss: 0.0864223 Test Loss: 0.0885017\n",
      "Validation loss decreased (0.086451 --> 0.086422).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0653563\n",
      "\tspeed: 0.0491s/iter; left time: 38.9623s\n",
      "\titers: 200, epoch: 17 | loss: 0.0704447\n",
      "\tspeed: 0.0250s/iter; left time: 17.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0712278 Vali Loss: 0.0865197 Test Loss: 0.0885296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0662463\n",
      "\tspeed: 0.0486s/iter; left time: 27.7158s\n",
      "\titers: 200, epoch: 18 | loss: 0.0720317\n",
      "\tspeed: 0.0249s/iter; left time: 11.7161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0711606 Vali Loss: 0.0865448 Test Loss: 0.0887078\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0693354\n",
      "\tspeed: 0.0493s/iter; left time: 17.0970s\n",
      "\titers: 200, epoch: 19 | loss: 0.0727959\n",
      "\tspeed: 0.0250s/iter; left time: 6.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0710075 Vali Loss: 0.0861939 Test Loss: 0.0884476\n",
      "Validation loss decreased (0.086422 --> 0.086194).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0703969\n",
      "\tspeed: 0.0490s/iter; left time: 6.0740s\n",
      "\titers: 200, epoch: 20 | loss: 0.0697241\n",
      "\tspeed: 0.0250s/iter; left time: 0.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0709244 Vali Loss: 0.0862467 Test Loss: 0.0884698\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021096836775541306, rmse:0.14524750411510468, mae:0.08844760060310364, rse:0.5125985145568848\n",
      "Intermediate time for DE and pred_len 24: 00h:05m:07.57s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1524197\n",
      "\tspeed: 0.0463s/iter; left time: 200.8558s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375952\n",
      "\tspeed: 0.0253s/iter; left time: 107.1877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 222 | Train Loss: 0.1509252 Vali Loss: 0.1419280 Test Loss: 0.1509789\n",
      "Validation loss decreased (inf --> 0.141928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138061\n",
      "\tspeed: 0.0503s/iter; left time: 207.1054s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108992\n",
      "\tspeed: 0.0252s/iter; left time: 101.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1142543 Vali Loss: 0.1206686 Test Loss: 0.1282206\n",
      "Validation loss decreased (0.141928 --> 0.120669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041095\n",
      "\tspeed: 0.0496s/iter; left time: 193.4045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048442\n",
      "\tspeed: 0.0251s/iter; left time: 95.4201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1059201 Vali Loss: 0.1185557 Test Loss: 0.1270821\n",
      "Validation loss decreased (0.120669 --> 0.118556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1051723\n",
      "\tspeed: 0.0495s/iter; left time: 181.8689s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051609\n",
      "\tspeed: 0.0252s/iter; left time: 89.9781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1039714 Vali Loss: 0.1180957 Test Loss: 0.1273423\n",
      "Validation loss decreased (0.118556 --> 0.118096).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1021679\n",
      "\tspeed: 0.0497s/iter; left time: 171.6917s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999732\n",
      "\tspeed: 0.0252s/iter; left time: 84.3653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1025546 Vali Loss: 0.1181811 Test Loss: 0.1268808\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1011426\n",
      "\tspeed: 0.0488s/iter; left time: 157.7509s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999946\n",
      "\tspeed: 0.0252s/iter; left time: 78.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.1014402 Vali Loss: 0.1177357 Test Loss: 0.1269181\n",
      "Validation loss decreased (0.118096 --> 0.117736).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005419\n",
      "\tspeed: 0.0500s/iter; left time: 150.3295s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978059\n",
      "\tspeed: 0.0253s/iter; left time: 73.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1004559 Vali Loss: 0.1176819 Test Loss: 0.1281645\n",
      "Validation loss decreased (0.117736 --> 0.117682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985050\n",
      "\tspeed: 0.0494s/iter; left time: 137.7020s\n",
      "\titers: 200, epoch: 8 | loss: 0.1038893\n",
      "\tspeed: 0.0251s/iter; left time: 67.4332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.0995783 Vali Loss: 0.1171959 Test Loss: 0.1264225\n",
      "Validation loss decreased (0.117682 --> 0.117196).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951688\n",
      "\tspeed: 0.0518s/iter; left time: 132.9921s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956111\n",
      "\tspeed: 0.0251s/iter; left time: 61.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0988268 Vali Loss: 0.1174052 Test Loss: 0.1277224\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954819\n",
      "\tspeed: 0.0488s/iter; left time: 114.3995s\n",
      "\titers: 200, epoch: 10 | loss: 0.1034079\n",
      "\tspeed: 0.0251s/iter; left time: 56.3444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.0981092 Vali Loss: 0.1172850 Test Loss: 0.1271868\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022108\n",
      "\tspeed: 0.0490s/iter; left time: 103.9260s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883767\n",
      "\tspeed: 0.0251s/iter; left time: 50.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 222 | Train Loss: 0.0974056 Vali Loss: 0.1178961 Test Loss: 0.1278977\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1006592\n",
      "\tspeed: 0.0498s/iter; left time: 94.6347s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967516\n",
      "\tspeed: 0.0251s/iter; left time: 45.2311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0967342 Vali Loss: 0.1180168 Test Loss: 0.1285491\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893896\n",
      "\tspeed: 0.0501s/iter; left time: 83.9550s\n",
      "\titers: 200, epoch: 13 | loss: 0.1023085\n",
      "\tspeed: 0.0253s/iter; left time: 39.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.0962980 Vali Loss: 0.1178484 Test Loss: 0.1280199\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03628804534673691, rmse:0.19049420952796936, mae:0.12642250955104828, rse:0.6745785474777222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1509143\n",
      "\tspeed: 0.0274s/iter; left time: 118.8341s\n",
      "\titers: 200, epoch: 1 | loss: 0.1396052\n",
      "\tspeed: 0.0254s/iter; left time: 107.6230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1545742 Vali Loss: 0.1438320 Test Loss: 0.1527672\n",
      "Validation loss decreased (inf --> 0.143832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1096659\n",
      "\tspeed: 0.0518s/iter; left time: 213.1952s\n",
      "\titers: 200, epoch: 2 | loss: 0.1083580\n",
      "\tspeed: 0.0252s/iter; left time: 101.4405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1146843 Vali Loss: 0.1206286 Test Loss: 0.1288152\n",
      "Validation loss decreased (0.143832 --> 0.120629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055950\n",
      "\tspeed: 0.0504s/iter; left time: 196.4441s\n",
      "\titers: 200, epoch: 3 | loss: 0.1063335\n",
      "\tspeed: 0.0252s/iter; left time: 95.5909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.1061741 Vali Loss: 0.1190469 Test Loss: 0.1273288\n",
      "Validation loss decreased (0.120629 --> 0.119047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1054941\n",
      "\tspeed: 0.0561s/iter; left time: 206.0017s\n",
      "\titers: 200, epoch: 4 | loss: 0.1054156\n",
      "\tspeed: 0.0254s/iter; left time: 90.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1037878 Vali Loss: 0.1172908 Test Loss: 0.1273427\n",
      "Validation loss decreased (0.119047 --> 0.117291).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1014776\n",
      "\tspeed: 0.0519s/iter; left time: 179.1725s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076194\n",
      "\tspeed: 0.0252s/iter; left time: 84.4003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1022845 Vali Loss: 0.1175373 Test Loss: 0.1275375\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0997480\n",
      "\tspeed: 0.0503s/iter; left time: 162.4067s\n",
      "\titers: 200, epoch: 6 | loss: 0.1095149\n",
      "\tspeed: 0.0252s/iter; left time: 79.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 222 | Train Loss: 0.1011955 Vali Loss: 0.1171618 Test Loss: 0.1267175\n",
      "Validation loss decreased (0.117291 --> 0.117162).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0976854\n",
      "\tspeed: 0.0517s/iter; left time: 155.5617s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983340\n",
      "\tspeed: 0.0253s/iter; left time: 73.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1003771 Vali Loss: 0.1167987 Test Loss: 0.1267028\n",
      "Validation loss decreased (0.117162 --> 0.116799).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997622\n",
      "\tspeed: 0.0506s/iter; left time: 141.0098s\n",
      "\titers: 200, epoch: 8 | loss: 0.0992231\n",
      "\tspeed: 0.0253s/iter; left time: 68.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 222 | Train Loss: 0.0996266 Vali Loss: 0.1171689 Test Loss: 0.1272052\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1002065\n",
      "\tspeed: 0.0502s/iter; left time: 128.6977s\n",
      "\titers: 200, epoch: 9 | loss: 0.0960183\n",
      "\tspeed: 0.0253s/iter; left time: 62.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.0989336 Vali Loss: 0.1171821 Test Loss: 0.1277008\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0958978\n",
      "\tspeed: 0.0498s/iter; left time: 116.7292s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998627\n",
      "\tspeed: 0.0253s/iter; left time: 56.6364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0983088 Vali Loss: 0.1171546 Test Loss: 0.1274462\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0966632\n",
      "\tspeed: 0.0504s/iter; left time: 106.9843s\n",
      "\titers: 200, epoch: 11 | loss: 0.0963016\n",
      "\tspeed: 0.0253s/iter; left time: 51.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0978272 Vali Loss: 0.1172742 Test Loss: 0.1275713\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0967989\n",
      "\tspeed: 0.0511s/iter; left time: 97.0387s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002217\n",
      "\tspeed: 0.0253s/iter; left time: 45.4362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0971994 Vali Loss: 0.1176822 Test Loss: 0.1279267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03638647496700287, rmse:0.19075238704681396, mae:0.12670288980007172, rse:0.6754928231239319\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:20.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1490380\n",
      "\tspeed: 0.0470s/iter; left time: 203.9462s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348439\n",
      "\tspeed: 0.0256s/iter; left time: 108.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 222 | Train Loss: 0.1536819 Vali Loss: 0.1435488 Test Loss: 0.1536387\n",
      "Validation loss decreased (inf --> 0.143549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156273\n",
      "\tspeed: 0.0513s/iter; left time: 211.1736s\n",
      "\titers: 200, epoch: 2 | loss: 0.1153742\n",
      "\tspeed: 0.0255s/iter; left time: 102.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1194604 Vali Loss: 0.1243052 Test Loss: 0.1335621\n",
      "Validation loss decreased (0.143549 --> 0.124305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091914\n",
      "\tspeed: 0.0512s/iter; left time: 199.5210s\n",
      "\titers: 200, epoch: 3 | loss: 0.1107274\n",
      "\tspeed: 0.0254s/iter; left time: 96.2763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1114915 Vali Loss: 0.1228457 Test Loss: 0.1317932\n",
      "Validation loss decreased (0.124305 --> 0.122846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125002\n",
      "\tspeed: 0.0513s/iter; left time: 188.5952s\n",
      "\titers: 200, epoch: 4 | loss: 0.1050300\n",
      "\tspeed: 0.0255s/iter; left time: 90.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1093076 Vali Loss: 0.1216234 Test Loss: 0.1328400\n",
      "Validation loss decreased (0.122846 --> 0.121623).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088410\n",
      "\tspeed: 0.0512s/iter; left time: 176.8172s\n",
      "\titers: 200, epoch: 5 | loss: 0.1082159\n",
      "\tspeed: 0.0254s/iter; left time: 85.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1076152 Vali Loss: 0.1219271 Test Loss: 0.1323917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080438\n",
      "\tspeed: 0.0508s/iter; left time: 164.0521s\n",
      "\titers: 200, epoch: 6 | loss: 0.1060845\n",
      "\tspeed: 0.0255s/iter; left time: 79.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1063124 Vali Loss: 0.1223658 Test Loss: 0.1331617\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041891\n",
      "\tspeed: 0.0511s/iter; left time: 153.7708s\n",
      "\titers: 200, epoch: 7 | loss: 0.1084695\n",
      "\tspeed: 0.0256s/iter; left time: 74.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1050821 Vali Loss: 0.1230205 Test Loss: 0.1332460\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057436\n",
      "\tspeed: 0.0510s/iter; left time: 142.0456s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041152\n",
      "\tspeed: 0.0255s/iter; left time: 68.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.1038863 Vali Loss: 0.1226599 Test Loss: 0.1340252\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044045\n",
      "\tspeed: 0.0508s/iter; left time: 130.3976s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016497\n",
      "\tspeed: 0.0255s/iter; left time: 62.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1028623 Vali Loss: 0.1233028 Test Loss: 0.1341052\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03833557665348053, rmse:0.1957947313785553, mae:0.13283993303775787, rse:0.6935206651687622\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1512634\n",
      "\tspeed: 0.0277s/iter; left time: 120.3187s\n",
      "\titers: 200, epoch: 1 | loss: 0.1386232\n",
      "\tspeed: 0.0256s/iter; left time: 108.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1542056 Vali Loss: 0.1439728 Test Loss: 0.1536107\n",
      "Validation loss decreased (inf --> 0.143973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1199878\n",
      "\tspeed: 0.0519s/iter; left time: 213.8710s\n",
      "\titers: 200, epoch: 2 | loss: 0.1082336\n",
      "\tspeed: 0.0255s/iter; left time: 102.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1194501 Vali Loss: 0.1245349 Test Loss: 0.1338168\n",
      "Validation loss decreased (0.143973 --> 0.124535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146913\n",
      "\tspeed: 0.0517s/iter; left time: 201.5605s\n",
      "\titers: 200, epoch: 3 | loss: 0.1125843\n",
      "\tspeed: 0.0254s/iter; left time: 96.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1114812 Vali Loss: 0.1228653 Test Loss: 0.1336787\n",
      "Validation loss decreased (0.124535 --> 0.122865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1086331\n",
      "\tspeed: 0.0554s/iter; left time: 203.6868s\n",
      "\titers: 200, epoch: 4 | loss: 0.1056447\n",
      "\tspeed: 0.0256s/iter; left time: 91.4854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1090843 Vali Loss: 0.1226171 Test Loss: 0.1336725\n",
      "Validation loss decreased (0.122865 --> 0.122617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1079249\n",
      "\tspeed: 0.0526s/iter; left time: 181.7254s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057752\n",
      "\tspeed: 0.0255s/iter; left time: 85.4730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1075889 Vali Loss: 0.1217376 Test Loss: 0.1339359\n",
      "Validation loss decreased (0.122617 --> 0.121738).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1065142\n",
      "\tspeed: 0.0538s/iter; left time: 173.7805s\n",
      "\titers: 200, epoch: 6 | loss: 0.1090356\n",
      "\tspeed: 0.0256s/iter; left time: 80.2195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1062648 Vali Loss: 0.1221878 Test Loss: 0.1343143\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1081868\n",
      "\tspeed: 0.0520s/iter; left time: 156.4754s\n",
      "\titers: 200, epoch: 7 | loss: 0.1031092\n",
      "\tspeed: 0.0257s/iter; left time: 74.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1050724 Vali Loss: 0.1228293 Test Loss: 0.1336516\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039568\n",
      "\tspeed: 0.0517s/iter; left time: 144.1828s\n",
      "\titers: 200, epoch: 8 | loss: 0.1012034\n",
      "\tspeed: 0.0256s/iter; left time: 68.7318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1039466 Vali Loss: 0.1221145 Test Loss: 0.1339977\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1027512\n",
      "\tspeed: 0.0520s/iter; left time: 133.3644s\n",
      "\titers: 200, epoch: 9 | loss: 0.1043352\n",
      "\tspeed: 0.0256s/iter; left time: 63.2072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.1029358 Vali Loss: 0.1227088 Test Loss: 0.1333162\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1035414\n",
      "\tspeed: 0.0516s/iter; left time: 120.9529s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019643\n",
      "\tspeed: 0.0255s/iter; left time: 57.1356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1019297 Vali Loss: 0.1230178 Test Loss: 0.1333210\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03888119384646416, rmse:0.19718314707279205, mae:0.13393597304821014, rse:0.6984385848045349\n",
      "Intermediate time for DE and pred_len 168: 00h:02m:39.41s\n",
      "Intermediate time for DE: 00h:11m:06.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248104\n",
      "\tspeed: 0.0477s/iter; left time: 207.8651s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189683\n",
      "\tspeed: 0.0249s/iter; left time: 106.1931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 223 | Train Loss: 0.1320080 Vali Loss: 0.1245858 Test Loss: 0.1461386\n",
      "Validation loss decreased (inf --> 0.124586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871835\n",
      "\tspeed: 0.0502s/iter; left time: 207.8396s\n",
      "\titers: 200, epoch: 2 | loss: 0.0825444\n",
      "\tspeed: 0.0249s/iter; left time: 100.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0873957 Vali Loss: 0.0911867 Test Loss: 0.1036528\n",
      "Validation loss decreased (0.124586 --> 0.091187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829440\n",
      "\tspeed: 0.0492s/iter; left time: 192.6282s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811696\n",
      "\tspeed: 0.0249s/iter; left time: 94.9380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0794493 Vali Loss: 0.0906464 Test Loss: 0.1034824\n",
      "Validation loss decreased (0.091187 --> 0.090646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736907\n",
      "\tspeed: 0.0496s/iter; left time: 183.1612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760392\n",
      "\tspeed: 0.0249s/iter; left time: 89.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0779166 Vali Loss: 0.0895404 Test Loss: 0.1021740\n",
      "Validation loss decreased (0.090646 --> 0.089540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748423\n",
      "\tspeed: 0.0495s/iter; left time: 171.6201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785504\n",
      "\tspeed: 0.0249s/iter; left time: 83.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0768613 Vali Loss: 0.0893269 Test Loss: 0.1015313\n",
      "Validation loss decreased (0.089540 --> 0.089327).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773457\n",
      "\tspeed: 0.0493s/iter; left time: 159.9414s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689240\n",
      "\tspeed: 0.0249s/iter; left time: 78.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0760901 Vali Loss: 0.0886091 Test Loss: 0.1013818\n",
      "Validation loss decreased (0.089327 --> 0.088609).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797589\n",
      "\tspeed: 0.0497s/iter; left time: 150.3662s\n",
      "\titers: 200, epoch: 7 | loss: 0.0784155\n",
      "\tspeed: 0.0250s/iter; left time: 73.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0755444 Vali Loss: 0.0884675 Test Loss: 0.1010676\n",
      "Validation loss decreased (0.088609 --> 0.088467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801681\n",
      "\tspeed: 0.0492s/iter; left time: 137.7477s\n",
      "\titers: 200, epoch: 8 | loss: 0.0736745\n",
      "\tspeed: 0.0250s/iter; left time: 67.3720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0749900 Vali Loss: 0.0884748 Test Loss: 0.1007913\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.0493s/iter; left time: 127.0295s\n",
      "\titers: 200, epoch: 9 | loss: 0.0762836\n",
      "\tspeed: 0.0251s/iter; left time: 62.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0746327 Vali Loss: 0.0882159 Test Loss: 0.1009664\n",
      "Validation loss decreased (0.088467 --> 0.088216).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769711\n",
      "\tspeed: 0.0504s/iter; left time: 118.5537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704211\n",
      "\tspeed: 0.0252s/iter; left time: 56.7280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0743007 Vali Loss: 0.0878040 Test Loss: 0.1006743\n",
      "Validation loss decreased (0.088216 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712703\n",
      "\tspeed: 0.0499s/iter; left time: 106.3984s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745102\n",
      "\tspeed: 0.0250s/iter; left time: 50.8021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0739317 Vali Loss: 0.0876703 Test Loss: 0.1006999\n",
      "Validation loss decreased (0.087804 --> 0.087670).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710412\n",
      "\tspeed: 0.0497s/iter; left time: 94.7622s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782618\n",
      "\tspeed: 0.0250s/iter; left time: 45.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0736354 Vali Loss: 0.0876544 Test Loss: 0.1004437\n",
      "Validation loss decreased (0.087670 --> 0.087654).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783196\n",
      "\tspeed: 0.0497s/iter; left time: 83.7753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716469\n",
      "\tspeed: 0.0252s/iter; left time: 39.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0734116 Vali Loss: 0.0879656 Test Loss: 0.1002505\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0729655\n",
      "\tspeed: 0.0486s/iter; left time: 71.0545s\n",
      "\titers: 200, epoch: 14 | loss: 0.0741272\n",
      "\tspeed: 0.0250s/iter; left time: 34.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0731876 Vali Loss: 0.0877671 Test Loss: 0.1007679\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0784120\n",
      "\tspeed: 0.0492s/iter; left time: 60.9394s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713894\n",
      "\tspeed: 0.0250s/iter; left time: 28.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0730301 Vali Loss: 0.0874009 Test Loss: 0.1004193\n",
      "Validation loss decreased (0.087654 --> 0.087401).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0752648\n",
      "\tspeed: 0.0504s/iter; left time: 51.2257s\n",
      "\titers: 200, epoch: 16 | loss: 0.0692569\n",
      "\tspeed: 0.0251s/iter; left time: 22.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0728606 Vali Loss: 0.0875206 Test Loss: 0.0998576\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0696480\n",
      "\tspeed: 0.0496s/iter; left time: 39.3573s\n",
      "\titers: 200, epoch: 17 | loss: 0.0696990\n",
      "\tspeed: 0.0251s/iter; left time: 17.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0727070 Vali Loss: 0.0874191 Test Loss: 0.1002236\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680822\n",
      "\tspeed: 0.0489s/iter; left time: 27.8962s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788060\n",
      "\tspeed: 0.0250s/iter; left time: 11.7648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0725290 Vali Loss: 0.0875011 Test Loss: 0.1004622\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758588\n",
      "\tspeed: 0.0493s/iter; left time: 17.1204s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707837\n",
      "\tspeed: 0.0250s/iter; left time: 6.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0724507 Vali Loss: 0.0874077 Test Loss: 0.1003668\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709867\n",
      "\tspeed: 0.0490s/iter; left time: 6.0732s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729043\n",
      "\tspeed: 0.0251s/iter; left time: 0.6014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0723412 Vali Loss: 0.0872065 Test Loss: 0.0999682\n",
      "Validation loss decreased (0.087401 --> 0.087207).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02504582144320011, rmse:0.15825872123241425, mae:0.09996816515922546, rse:0.5459477305412292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1294611\n",
      "\tspeed: 0.0271s/iter; left time: 118.1447s\n",
      "\titers: 200, epoch: 1 | loss: 0.1205135\n",
      "\tspeed: 0.0250s/iter; left time: 106.4608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.1303674 Vali Loss: 0.1248064 Test Loss: 0.1454734\n",
      "Validation loss decreased (inf --> 0.124806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0866117\n",
      "\tspeed: 0.0500s/iter; left time: 207.1024s\n",
      "\titers: 200, epoch: 2 | loss: 0.0824038\n",
      "\tspeed: 0.0252s/iter; left time: 101.5620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0872526 Vali Loss: 0.0912432 Test Loss: 0.1033538\n",
      "Validation loss decreased (0.124806 --> 0.091243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0770556\n",
      "\tspeed: 0.0501s/iter; left time: 196.0652s\n",
      "\titers: 200, epoch: 3 | loss: 0.0759367\n",
      "\tspeed: 0.0251s/iter; left time: 95.9299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0795269 Vali Loss: 0.0903121 Test Loss: 0.1026443\n",
      "Validation loss decreased (0.091243 --> 0.090312).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0794817\n",
      "\tspeed: 0.0503s/iter; left time: 185.8143s\n",
      "\titers: 200, epoch: 4 | loss: 0.0725037\n",
      "\tspeed: 0.0250s/iter; left time: 89.7171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0779244 Vali Loss: 0.0894066 Test Loss: 0.1028099\n",
      "Validation loss decreased (0.090312 --> 0.089407).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0751133\n",
      "\tspeed: 0.0501s/iter; left time: 173.9664s\n",
      "\titers: 200, epoch: 5 | loss: 0.0759372\n",
      "\tspeed: 0.0252s/iter; left time: 84.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0767845 Vali Loss: 0.0892266 Test Loss: 0.1017113\n",
      "Validation loss decreased (0.089407 --> 0.089227).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793913\n",
      "\tspeed: 0.0499s/iter; left time: 161.8157s\n",
      "\titers: 200, epoch: 6 | loss: 0.0791184\n",
      "\tspeed: 0.0250s/iter; left time: 78.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0760865 Vali Loss: 0.0890232 Test Loss: 0.1013097\n",
      "Validation loss decreased (0.089227 --> 0.089023).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0772553\n",
      "\tspeed: 0.0491s/iter; left time: 148.4508s\n",
      "\titers: 200, epoch: 7 | loss: 0.0757662\n",
      "\tspeed: 0.0249s/iter; left time: 72.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0754369 Vali Loss: 0.0883436 Test Loss: 0.1013570\n",
      "Validation loss decreased (0.089023 --> 0.088344).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0808531\n",
      "\tspeed: 0.0492s/iter; left time: 137.6462s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733330\n",
      "\tspeed: 0.0251s/iter; left time: 67.6588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0749820 Vali Loss: 0.0884141 Test Loss: 0.1013714\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805251\n",
      "\tspeed: 0.0490s/iter; left time: 126.3493s\n",
      "\titers: 200, epoch: 9 | loss: 0.0774776\n",
      "\tspeed: 0.0250s/iter; left time: 61.8244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0745466 Vali Loss: 0.0880825 Test Loss: 0.1015604\n",
      "Validation loss decreased (0.088344 --> 0.088082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0799305\n",
      "\tspeed: 0.0504s/iter; left time: 118.6181s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753193\n",
      "\tspeed: 0.0252s/iter; left time: 56.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0742156 Vali Loss: 0.0882399 Test Loss: 0.1005099\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0748022\n",
      "\tspeed: 0.0501s/iter; left time: 106.7275s\n",
      "\titers: 200, epoch: 11 | loss: 0.0708263\n",
      "\tspeed: 0.0250s/iter; left time: 50.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0738708 Vali Loss: 0.0879598 Test Loss: 0.1008806\n",
      "Validation loss decreased (0.088082 --> 0.087960).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710602\n",
      "\tspeed: 0.0488s/iter; left time: 93.0726s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746384\n",
      "\tspeed: 0.0249s/iter; left time: 45.0254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0736211 Vali Loss: 0.0879124 Test Loss: 0.1001388\n",
      "Validation loss decreased (0.087960 --> 0.087912).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0735792\n",
      "\tspeed: 0.0508s/iter; left time: 85.6758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0734467\n",
      "\tspeed: 0.0249s/iter; left time: 39.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0733581 Vali Loss: 0.0879119 Test Loss: 0.1007672\n",
      "Validation loss decreased (0.087912 --> 0.087912).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709326\n",
      "\tspeed: 0.0494s/iter; left time: 72.2768s\n",
      "\titers: 200, epoch: 14 | loss: 0.0794831\n",
      "\tspeed: 0.0250s/iter; left time: 34.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0731631 Vali Loss: 0.0879339 Test Loss: 0.1001540\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0708378\n",
      "\tspeed: 0.0497s/iter; left time: 61.5561s\n",
      "\titers: 200, epoch: 15 | loss: 0.0727752\n",
      "\tspeed: 0.0249s/iter; left time: 28.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0729571 Vali Loss: 0.0874541 Test Loss: 0.1003712\n",
      "Validation loss decreased (0.087912 --> 0.087454).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0687091\n",
      "\tspeed: 0.0491s/iter; left time: 49.9321s\n",
      "\titers: 200, epoch: 16 | loss: 0.0780086\n",
      "\tspeed: 0.0249s/iter; left time: 22.8299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0727654 Vali Loss: 0.0874904 Test Loss: 0.1000285\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0719278\n",
      "\tspeed: 0.0487s/iter; left time: 38.6552s\n",
      "\titers: 200, epoch: 17 | loss: 0.0681665\n",
      "\tspeed: 0.0249s/iter; left time: 17.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0726065 Vali Loss: 0.0876727 Test Loss: 0.1004601\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0678561\n",
      "\tspeed: 0.0491s/iter; left time: 27.9724s\n",
      "\titers: 200, epoch: 18 | loss: 0.0691214\n",
      "\tspeed: 0.0250s/iter; left time: 11.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0724923 Vali Loss: 0.0875289 Test Loss: 0.0999042\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711187\n",
      "\tspeed: 0.0496s/iter; left time: 17.2100s\n",
      "\titers: 200, epoch: 19 | loss: 0.0721421\n",
      "\tspeed: 0.0249s/iter; left time: 6.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0723260 Vali Loss: 0.0874994 Test Loss: 0.1004439\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0697939\n",
      "\tspeed: 0.0496s/iter; left time: 6.1453s\n",
      "\titers: 200, epoch: 20 | loss: 0.0699597\n",
      "\tspeed: 0.0249s/iter; left time: 0.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0722401 Vali Loss: 0.0876277 Test Loss: 0.1000945\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025304274633526802, rmse:0.15907317399978638, mae:0.10037115961313248, rse:0.5487573742866516\n",
      "Intermediate time for GB and pred_len 24: 00h:05m:08.95s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1394340\n",
      "\tspeed: 0.0473s/iter; left time: 205.3154s\n",
      "\titers: 200, epoch: 1 | loss: 0.1290265\n",
      "\tspeed: 0.0251s/iter; left time: 106.4031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.1366888 Vali Loss: 0.1331916 Test Loss: 0.1571194\n",
      "Validation loss decreased (inf --> 0.133192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1068254\n",
      "\tspeed: 0.0511s/iter; left time: 210.3761s\n",
      "\titers: 200, epoch: 2 | loss: 0.1038789\n",
      "\tspeed: 0.0250s/iter; left time: 100.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 222 | Train Loss: 0.1089743 Vali Loss: 0.1170851 Test Loss: 0.1377481\n",
      "Validation loss decreased (0.133192 --> 0.117085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039727\n",
      "\tspeed: 0.0498s/iter; left time: 193.8929s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007207\n",
      "\tspeed: 0.0250s/iter; left time: 94.9688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1035166 Vali Loss: 0.1159595 Test Loss: 0.1386739\n",
      "Validation loss decreased (0.117085 --> 0.115960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032024\n",
      "\tspeed: 0.0502s/iter; left time: 184.3200s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009170\n",
      "\tspeed: 0.0250s/iter; left time: 89.4153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 222 | Train Loss: 0.1019685 Vali Loss: 0.1150414 Test Loss: 0.1387783\n",
      "Validation loss decreased (0.115960 --> 0.115041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023183\n",
      "\tspeed: 0.0491s/iter; left time: 169.4553s\n",
      "\titers: 200, epoch: 5 | loss: 0.0971835\n",
      "\tspeed: 0.0251s/iter; left time: 84.0776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 222 | Train Loss: 0.1006222 Vali Loss: 0.1144552 Test Loss: 0.1380308\n",
      "Validation loss decreased (0.115041 --> 0.114455).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0979462\n",
      "\tspeed: 0.0506s/iter; left time: 163.4448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0962899\n",
      "\tspeed: 0.0250s/iter; left time: 78.3981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 222 | Train Loss: 0.0993785 Vali Loss: 0.1143939 Test Loss: 0.1384692\n",
      "Validation loss decreased (0.114455 --> 0.114394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0957437\n",
      "\tspeed: 0.0511s/iter; left time: 153.9008s\n",
      "\titers: 200, epoch: 7 | loss: 0.0956334\n",
      "\tspeed: 0.0250s/iter; left time: 72.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0984068 Vali Loss: 0.1152558 Test Loss: 0.1409329\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985388\n",
      "\tspeed: 0.0491s/iter; left time: 136.7956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979370\n",
      "\tspeed: 0.0250s/iter; left time: 67.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 222 | Train Loss: 0.0974339 Vali Loss: 0.1146337 Test Loss: 0.1407919\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0960061\n",
      "\tspeed: 0.0505s/iter; left time: 129.6123s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977183\n",
      "\tspeed: 0.0254s/iter; left time: 62.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0965533 Vali Loss: 0.1147367 Test Loss: 0.1410791\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983268\n",
      "\tspeed: 0.0517s/iter; left time: 121.0222s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971290\n",
      "\tspeed: 0.0254s/iter; left time: 57.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0957947 Vali Loss: 0.1152980 Test Loss: 0.1419808\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0965237\n",
      "\tspeed: 0.0513s/iter; left time: 108.7725s\n",
      "\titers: 200, epoch: 11 | loss: 0.0888941\n",
      "\tspeed: 0.0255s/iter; left time: 51.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0951090 Vali Loss: 0.1158843 Test Loss: 0.1428171\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04119270667433739, rmse:0.20295986533164978, mae:0.13846930861473083, rse:0.7018635272979736\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1365912\n",
      "\tspeed: 0.0279s/iter; left time: 121.2763s\n",
      "\titers: 200, epoch: 1 | loss: 0.1290740\n",
      "\tspeed: 0.0254s/iter; left time: 107.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1389132 Vali Loss: 0.1345307 Test Loss: 0.1591601\n",
      "Validation loss decreased (inf --> 0.134531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1076054\n",
      "\tspeed: 0.0587s/iter; left time: 241.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1062119\n",
      "\tspeed: 0.0253s/iter; left time: 101.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1092445 Vali Loss: 0.1172763 Test Loss: 0.1378209\n",
      "Validation loss decreased (0.134531 --> 0.117276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020365\n",
      "\tspeed: 0.0521s/iter; left time: 203.0195s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043519\n",
      "\tspeed: 0.0254s/iter; left time: 96.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1036230 Vali Loss: 0.1157246 Test Loss: 0.1374671\n",
      "Validation loss decreased (0.117276 --> 0.115725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982133\n",
      "\tspeed: 0.0523s/iter; left time: 192.0524s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026201\n",
      "\tspeed: 0.0255s/iter; left time: 91.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1017590 Vali Loss: 0.1151671 Test Loss: 0.1382986\n",
      "Validation loss decreased (0.115725 --> 0.115167).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018179\n",
      "\tspeed: 0.0522s/iter; left time: 180.2671s\n",
      "\titers: 200, epoch: 5 | loss: 0.1009365\n",
      "\tspeed: 0.0255s/iter; left time: 85.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1003516 Vali Loss: 0.1149728 Test Loss: 0.1380189\n",
      "Validation loss decreased (0.115167 --> 0.114973).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1041179\n",
      "\tspeed: 0.0520s/iter; left time: 168.1364s\n",
      "\titers: 200, epoch: 6 | loss: 0.1016819\n",
      "\tspeed: 0.0254s/iter; left time: 79.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0991088 Vali Loss: 0.1147444 Test Loss: 0.1384884\n",
      "Validation loss decreased (0.114973 --> 0.114744).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1039703\n",
      "\tspeed: 0.0527s/iter; left time: 158.4277s\n",
      "\titers: 200, epoch: 7 | loss: 0.1030468\n",
      "\tspeed: 0.0255s/iter; left time: 74.3117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0980691 Vali Loss: 0.1146851 Test Loss: 0.1393597\n",
      "Validation loss decreased (0.114744 --> 0.114685).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0925659\n",
      "\tspeed: 0.0517s/iter; left time: 144.1034s\n",
      "\titers: 200, epoch: 8 | loss: 0.1030127\n",
      "\tspeed: 0.0255s/iter; left time: 68.5461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0971579 Vali Loss: 0.1146965 Test Loss: 0.1400719\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991212\n",
      "\tspeed: 0.0508s/iter; left time: 130.1917s\n",
      "\titers: 200, epoch: 9 | loss: 0.0950394\n",
      "\tspeed: 0.0256s/iter; left time: 63.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0964368 Vali Loss: 0.1152398 Test Loss: 0.1415877\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0937270\n",
      "\tspeed: 0.0513s/iter; left time: 120.2759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0928974\n",
      "\tspeed: 0.0255s/iter; left time: 57.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0956364 Vali Loss: 0.1152773 Test Loss: 0.1406660\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0969222\n",
      "\tspeed: 0.0518s/iter; left time: 109.8593s\n",
      "\titers: 200, epoch: 11 | loss: 0.0946718\n",
      "\tspeed: 0.0255s/iter; left time: 51.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0949587 Vali Loss: 0.1158046 Test Loss: 0.1421930\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0901898\n",
      "\tspeed: 0.0512s/iter; left time: 97.2574s\n",
      "\titers: 200, epoch: 12 | loss: 0.0933780\n",
      "\tspeed: 0.0255s/iter; left time: 45.8958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0943317 Vali Loss: 0.1156237 Test Loss: 0.1397123\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041973523795604706, rmse:0.2048744112253189, mae:0.13935968279838562, rse:0.7084842920303345\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:07.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1374336\n",
      "\tspeed: 0.0462s/iter; left time: 200.3797s\n",
      "\titers: 200, epoch: 1 | loss: 0.1251440\n",
      "\tspeed: 0.0253s/iter; left time: 107.4812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 222 | Train Loss: 0.1389109 Vali Loss: 0.1349851 Test Loss: 0.1598008\n",
      "Validation loss decreased (inf --> 0.134985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122300\n",
      "\tspeed: 0.0498s/iter; left time: 205.2928s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079164\n",
      "\tspeed: 0.0253s/iter; left time: 101.5836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.1132026 Vali Loss: 0.1214197 Test Loss: 0.1451650\n",
      "Validation loss decreased (0.134985 --> 0.121420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036352\n",
      "\tspeed: 0.0500s/iter; left time: 194.7553s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043559\n",
      "\tspeed: 0.0254s/iter; left time: 96.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1080314 Vali Loss: 0.1201407 Test Loss: 0.1442623\n",
      "Validation loss decreased (0.121420 --> 0.120141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083568\n",
      "\tspeed: 0.0508s/iter; left time: 186.6568s\n",
      "\titers: 200, epoch: 4 | loss: 0.1068884\n",
      "\tspeed: 0.0254s/iter; left time: 90.9284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.1063734 Vali Loss: 0.1194321 Test Loss: 0.1463639\n",
      "Validation loss decreased (0.120141 --> 0.119432).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059435\n",
      "\tspeed: 0.0512s/iter; left time: 176.9128s\n",
      "\titers: 200, epoch: 5 | loss: 0.1046826\n",
      "\tspeed: 0.0254s/iter; left time: 85.2936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1048385 Vali Loss: 0.1198237 Test Loss: 0.1464768\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1037265\n",
      "\tspeed: 0.0500s/iter; left time: 161.5218s\n",
      "\titers: 200, epoch: 6 | loss: 0.1038950\n",
      "\tspeed: 0.0254s/iter; left time: 79.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1033754 Vali Loss: 0.1201003 Test Loss: 0.1470414\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1040469\n",
      "\tspeed: 0.0497s/iter; left time: 149.4529s\n",
      "\titers: 200, epoch: 7 | loss: 0.1053304\n",
      "\tspeed: 0.0255s/iter; left time: 74.1017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 222 | Train Loss: 0.1021183 Vali Loss: 0.1202404 Test Loss: 0.1469195\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039958\n",
      "\tspeed: 0.0508s/iter; left time: 141.6486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013930\n",
      "\tspeed: 0.0254s/iter; left time: 68.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.1009759 Vali Loss: 0.1207501 Test Loss: 0.1468556\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0994803\n",
      "\tspeed: 0.0501s/iter; left time: 128.5502s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979783\n",
      "\tspeed: 0.0253s/iter; left time: 62.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0998242 Vali Loss: 0.1210882 Test Loss: 0.1469089\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04480735957622528, rmse:0.21167749166488647, mae:0.14636394381523132, rse:0.7339162826538086\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1355522\n",
      "\tspeed: 0.0273s/iter; left time: 118.4042s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274015\n",
      "\tspeed: 0.0254s/iter; left time: 107.8174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1394984 Vali Loss: 0.1352586 Test Loss: 0.1598129\n",
      "Validation loss decreased (inf --> 0.135259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1091381\n",
      "\tspeed: 0.0512s/iter; left time: 210.9057s\n",
      "\titers: 200, epoch: 2 | loss: 0.1071792\n",
      "\tspeed: 0.0255s/iter; left time: 102.3677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1131621 Vali Loss: 0.1214741 Test Loss: 0.1446611\n",
      "Validation loss decreased (0.135259 --> 0.121474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1094883\n",
      "\tspeed: 0.0506s/iter; left time: 197.1634s\n",
      "\titers: 200, epoch: 3 | loss: 0.1045896\n",
      "\tspeed: 0.0254s/iter; left time: 96.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1081718 Vali Loss: 0.1202765 Test Loss: 0.1443724\n",
      "Validation loss decreased (0.121474 --> 0.120276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1076571\n",
      "\tspeed: 0.0562s/iter; left time: 206.6492s\n",
      "\titers: 200, epoch: 4 | loss: 0.1014475\n",
      "\tspeed: 0.0255s/iter; left time: 91.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1063156 Vali Loss: 0.1197968 Test Loss: 0.1463517\n",
      "Validation loss decreased (0.120276 --> 0.119797).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1025544\n",
      "\tspeed: 0.0516s/iter; left time: 178.3187s\n",
      "\titers: 200, epoch: 5 | loss: 0.1026519\n",
      "\tspeed: 0.0255s/iter; left time: 85.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1047799 Vali Loss: 0.1200861 Test Loss: 0.1472630\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1064387\n",
      "\tspeed: 0.0515s/iter; left time: 166.4209s\n",
      "\titers: 200, epoch: 6 | loss: 0.1037773\n",
      "\tspeed: 0.0256s/iter; left time: 80.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1034544 Vali Loss: 0.1205088 Test Loss: 0.1483668\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036646\n",
      "\tspeed: 0.0507s/iter; left time: 152.6592s\n",
      "\titers: 200, epoch: 7 | loss: 0.0979128\n",
      "\tspeed: 0.0255s/iter; left time: 74.0826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1022100 Vali Loss: 0.1204105 Test Loss: 0.1481286\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0995876\n",
      "\tspeed: 0.0513s/iter; left time: 143.1053s\n",
      "\titers: 200, epoch: 8 | loss: 0.0977129\n",
      "\tspeed: 0.0254s/iter; left time: 68.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1009682 Vali Loss: 0.1205941 Test Loss: 0.1476202\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0968032\n",
      "\tspeed: 0.0516s/iter; left time: 132.2275s\n",
      "\titers: 200, epoch: 9 | loss: 0.0991139\n",
      "\tspeed: 0.0255s/iter; left time: 62.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0997093 Vali Loss: 0.1207828 Test Loss: 0.1471774\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04440097510814667, rmse:0.2107153832912445, mae:0.14635175466537476, rse:0.7305805087089539\n",
      "Intermediate time for GB and pred_len 168: 00h:02m:29.28s\n",
      "Intermediate time for GB: 00h:10m:46.06s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1329129\n",
      "\tspeed: 0.0379s/iter; left time: 165.4441s\n",
      "\titers: 200, epoch: 1 | loss: 0.1140730\n",
      "\tspeed: 0.0158s/iter; left time: 67.2718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 223 | Train Loss: 0.1388291 Vali Loss: 0.1031739 Test Loss: 0.1167768\n",
      "Validation loss decreased (inf --> 0.103174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0760406\n",
      "\tspeed: 0.0345s/iter; left time: 142.7941s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709279\n",
      "\tspeed: 0.0157s/iter; left time: 63.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0782182 Vali Loss: 0.0637507 Test Loss: 0.0713524\n",
      "Validation loss decreased (0.103174 --> 0.063751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656441\n",
      "\tspeed: 0.0345s/iter; left time: 135.1514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637093\n",
      "\tspeed: 0.0159s/iter; left time: 60.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0659534 Vali Loss: 0.0600094 Test Loss: 0.0667960\n",
      "Validation loss decreased (0.063751 --> 0.060009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627606\n",
      "\tspeed: 0.0345s/iter; left time: 127.2860s\n",
      "\titers: 200, epoch: 4 | loss: 0.0611268\n",
      "\tspeed: 0.0159s/iter; left time: 57.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0627434 Vali Loss: 0.0586569 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.060009 --> 0.058657).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597999\n",
      "\tspeed: 0.0361s/iter; left time: 125.3710s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628164\n",
      "\tspeed: 0.0162s/iter; left time: 54.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0608250 Vali Loss: 0.0571451 Test Loss: 0.0638910\n",
      "Validation loss decreased (0.058657 --> 0.057145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588184\n",
      "\tspeed: 0.0361s/iter; left time: 117.3406s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603673\n",
      "\tspeed: 0.0162s/iter; left time: 50.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0595142 Vali Loss: 0.0563593 Test Loss: 0.0631915\n",
      "Validation loss decreased (0.057145 --> 0.056359).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571423\n",
      "\tspeed: 0.0366s/iter; left time: 110.5641s\n",
      "\titers: 200, epoch: 7 | loss: 0.0634167\n",
      "\tspeed: 0.0162s/iter; left time: 47.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0586404 Vali Loss: 0.0558892 Test Loss: 0.0628020\n",
      "Validation loss decreased (0.056359 --> 0.055889).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0587911\n",
      "\tspeed: 0.0360s/iter; left time: 100.9207s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589734\n",
      "\tspeed: 0.0162s/iter; left time: 43.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0579511 Vali Loss: 0.0554596 Test Loss: 0.0625661\n",
      "Validation loss decreased (0.055889 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562014\n",
      "\tspeed: 0.0361s/iter; left time: 92.9534s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573063\n",
      "\tspeed: 0.0162s/iter; left time: 40.2268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 223 | Train Loss: 0.0573422 Vali Loss: 0.0551464 Test Loss: 0.0621672\n",
      "Validation loss decreased (0.055460 --> 0.055146).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563526\n",
      "\tspeed: 0.0360s/iter; left time: 84.6992s\n",
      "\titers: 200, epoch: 10 | loss: 0.0558840\n",
      "\tspeed: 0.0163s/iter; left time: 36.7570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0568031 Vali Loss: 0.0549321 Test Loss: 0.0619139\n",
      "Validation loss decreased (0.055146 --> 0.054932).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561171\n",
      "\tspeed: 0.0359s/iter; left time: 76.4112s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546085\n",
      "\tspeed: 0.0163s/iter; left time: 33.0925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0563940 Vali Loss: 0.0546079 Test Loss: 0.0616910\n",
      "Validation loss decreased (0.054932 --> 0.054608).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553174\n",
      "\tspeed: 0.0374s/iter; left time: 71.2823s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555087\n",
      "\tspeed: 0.0162s/iter; left time: 29.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0560539 Vali Loss: 0.0541861 Test Loss: 0.0612447\n",
      "Validation loss decreased (0.054608 --> 0.054186).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536061\n",
      "\tspeed: 0.0362s/iter; left time: 60.9948s\n",
      "\titers: 200, epoch: 13 | loss: 0.0512201\n",
      "\tspeed: 0.0162s/iter; left time: 25.6852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0556423 Vali Loss: 0.0539564 Test Loss: 0.0611355\n",
      "Validation loss decreased (0.054186 --> 0.053956).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0582338\n",
      "\tspeed: 0.0362s/iter; left time: 52.9429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572633\n",
      "\tspeed: 0.0162s/iter; left time: 22.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0554266 Vali Loss: 0.0539151 Test Loss: 0.0609410\n",
      "Validation loss decreased (0.053956 --> 0.053915).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0551506\n",
      "\tspeed: 0.0357s/iter; left time: 44.2579s\n",
      "\titers: 200, epoch: 15 | loss: 0.0490729\n",
      "\tspeed: 0.0161s/iter; left time: 18.3930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0551881 Vali Loss: 0.0538702 Test Loss: 0.0607723\n",
      "Validation loss decreased (0.053915 --> 0.053870).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550896\n",
      "\tspeed: 0.0360s/iter; left time: 36.5572s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553330\n",
      "\tspeed: 0.0157s/iter; left time: 14.3835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0549647 Vali Loss: 0.0537893 Test Loss: 0.0606530\n",
      "Validation loss decreased (0.053870 --> 0.053789).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518273\n",
      "\tspeed: 0.0362s/iter; left time: 28.7407s\n",
      "\titers: 200, epoch: 17 | loss: 0.0541851\n",
      "\tspeed: 0.0157s/iter; left time: 10.8802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0548265 Vali Loss: 0.0535404 Test Loss: 0.0606558\n",
      "Validation loss decreased (0.053789 --> 0.053540).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0561151\n",
      "\tspeed: 0.0350s/iter; left time: 19.9765s\n",
      "\titers: 200, epoch: 18 | loss: 0.0536424\n",
      "\tspeed: 0.0158s/iter; left time: 7.4134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0545902 Vali Loss: 0.0535757 Test Loss: 0.0607545\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0576345\n",
      "\tspeed: 0.0363s/iter; left time: 12.5915s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547254\n",
      "\tspeed: 0.0163s/iter; left time: 4.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0545236 Vali Loss: 0.0534763 Test Loss: 0.0604636\n",
      "Validation loss decreased (0.053540 --> 0.053476).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522795\n",
      "\tspeed: 0.0360s/iter; left time: 4.4700s\n",
      "\titers: 200, epoch: 20 | loss: 0.0537029\n",
      "\tspeed: 0.0163s/iter; left time: 0.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 223 | Train Loss: 0.0544254 Vali Loss: 0.0533704 Test Loss: 0.0604521\n",
      "Validation loss decreased (0.053476 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009890918619930744, rmse:0.09945309907197952, mae:0.06045207753777504, rse:0.29267844557762146\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1279595\n",
      "\tspeed: 0.0230s/iter; left time: 100.1254s\n",
      "\titers: 200, epoch: 1 | loss: 0.1086019\n",
      "\tspeed: 0.0161s/iter; left time: 68.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.32s\n",
      "Steps: 223 | Train Loss: 0.1344859 Vali Loss: 0.1017183 Test Loss: 0.1152673\n",
      "Validation loss decreased (inf --> 0.101718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0735457\n",
      "\tspeed: 0.0357s/iter; left time: 147.7778s\n",
      "\titers: 200, epoch: 2 | loss: 0.0693448\n",
      "\tspeed: 0.0162s/iter; left time: 65.3538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0775861 Vali Loss: 0.0633993 Test Loss: 0.0710598\n",
      "Validation loss decreased (0.101718 --> 0.063399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0666565\n",
      "\tspeed: 0.0359s/iter; left time: 140.6370s\n",
      "\titers: 200, epoch: 3 | loss: 0.0644751\n",
      "\tspeed: 0.0162s/iter; left time: 61.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0657430 Vali Loss: 0.0598359 Test Loss: 0.0666923\n",
      "Validation loss decreased (0.063399 --> 0.059836).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0654695\n",
      "\tspeed: 0.0347s/iter; left time: 128.2464s\n",
      "\titers: 200, epoch: 4 | loss: 0.0609133\n",
      "\tspeed: 0.0156s/iter; left time: 56.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0624257 Vali Loss: 0.0581786 Test Loss: 0.0650473\n",
      "Validation loss decreased (0.059836 --> 0.058179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0629714\n",
      "\tspeed: 0.0358s/iter; left time: 124.3160s\n",
      "\titers: 200, epoch: 5 | loss: 0.0566989\n",
      "\tspeed: 0.0160s/iter; left time: 53.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0605862 Vali Loss: 0.0572167 Test Loss: 0.0640629\n",
      "Validation loss decreased (0.058179 --> 0.057217).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0580013\n",
      "\tspeed: 0.0360s/iter; left time: 116.7343s\n",
      "\titers: 200, epoch: 6 | loss: 0.0592974\n",
      "\tspeed: 0.0164s/iter; left time: 51.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 223 | Train Loss: 0.0592775 Vali Loss: 0.0563820 Test Loss: 0.0630901\n",
      "Validation loss decreased (0.057217 --> 0.056382).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606943\n",
      "\tspeed: 0.0359s/iter; left time: 108.6003s\n",
      "\titers: 200, epoch: 7 | loss: 0.0561517\n",
      "\tspeed: 0.0161s/iter; left time: 47.1975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0583424 Vali Loss: 0.0557012 Test Loss: 0.0625994\n",
      "Validation loss decreased (0.056382 --> 0.055701).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603218\n",
      "\tspeed: 0.0350s/iter; left time: 98.0653s\n",
      "\titers: 200, epoch: 8 | loss: 0.0588647\n",
      "\tspeed: 0.0163s/iter; left time: 43.8880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0576146 Vali Loss: 0.0552016 Test Loss: 0.0622390\n",
      "Validation loss decreased (0.055701 --> 0.055202).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0566144\n",
      "\tspeed: 0.0354s/iter; left time: 91.2476s\n",
      "\titers: 200, epoch: 9 | loss: 0.0567635\n",
      "\tspeed: 0.0162s/iter; left time: 40.0181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0570295 Vali Loss: 0.0550724 Test Loss: 0.0619212\n",
      "Validation loss decreased (0.055202 --> 0.055072).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563664\n",
      "\tspeed: 0.0358s/iter; left time: 84.3294s\n",
      "\titers: 200, epoch: 10 | loss: 0.0591527\n",
      "\tspeed: 0.0162s/iter; left time: 36.4380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0565442 Vali Loss: 0.0546937 Test Loss: 0.0616718\n",
      "Validation loss decreased (0.055072 --> 0.054694).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0577397\n",
      "\tspeed: 0.0355s/iter; left time: 75.6932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553575\n",
      "\tspeed: 0.0162s/iter; left time: 32.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0561088 Vali Loss: 0.0544968 Test Loss: 0.0613600\n",
      "Validation loss decreased (0.054694 --> 0.054497).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0573475\n",
      "\tspeed: 0.0359s/iter; left time: 68.5430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0556808\n",
      "\tspeed: 0.0162s/iter; left time: 29.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0557425 Vali Loss: 0.0542554 Test Loss: 0.0610903\n",
      "Validation loss decreased (0.054497 --> 0.054255).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580835\n",
      "\tspeed: 0.0353s/iter; left time: 59.4894s\n",
      "\titers: 200, epoch: 13 | loss: 0.0562407\n",
      "\tspeed: 0.0161s/iter; left time: 25.5769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0554549 Vali Loss: 0.0541976 Test Loss: 0.0609923\n",
      "Validation loss decreased (0.054255 --> 0.054198).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577417\n",
      "\tspeed: 0.0350s/iter; left time: 51.2410s\n",
      "\titers: 200, epoch: 14 | loss: 0.0546249\n",
      "\tspeed: 0.0162s/iter; left time: 22.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0551867 Vali Loss: 0.0538669 Test Loss: 0.0609006\n",
      "Validation loss decreased (0.054198 --> 0.053867).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0580590\n",
      "\tspeed: 0.0357s/iter; left time: 44.2141s\n",
      "\titers: 200, epoch: 15 | loss: 0.0533785\n",
      "\tspeed: 0.0160s/iter; left time: 18.1711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0549592 Vali Loss: 0.0537050 Test Loss: 0.0606348\n",
      "Validation loss decreased (0.053867 --> 0.053705).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0584997\n",
      "\tspeed: 0.0361s/iter; left time: 36.7068s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622431\n",
      "\tspeed: 0.0158s/iter; left time: 14.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0547352 Vali Loss: 0.0537173 Test Loss: 0.0607005\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0567969\n",
      "\tspeed: 0.0352s/iter; left time: 27.9276s\n",
      "\titers: 200, epoch: 17 | loss: 0.0530954\n",
      "\tspeed: 0.0159s/iter; left time: 10.9918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0546198 Vali Loss: 0.0534973 Test Loss: 0.0604868\n",
      "Validation loss decreased (0.053705 --> 0.053497).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0558345\n",
      "\tspeed: 0.0356s/iter; left time: 20.3038s\n",
      "\titers: 200, epoch: 18 | loss: 0.0515417\n",
      "\tspeed: 0.0158s/iter; left time: 7.4256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0543856 Vali Loss: 0.0535284 Test Loss: 0.0605108\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0532008\n",
      "\tspeed: 0.0357s/iter; left time: 12.3987s\n",
      "\titers: 200, epoch: 19 | loss: 0.0540956\n",
      "\tspeed: 0.0161s/iter; left time: 3.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0542990 Vali Loss: 0.0535540 Test Loss: 0.0603973\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522034\n",
      "\tspeed: 0.0347s/iter; left time: 4.3084s\n",
      "\titers: 200, epoch: 20 | loss: 0.0543188\n",
      "\tspeed: 0.0156s/iter; left time: 0.3748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0542121 Vali Loss: 0.0533839 Test Loss: 0.0602595\n",
      "Validation loss decreased (0.053497 --> 0.053384).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009858346544206142, rmse:0.09928920865058899, mae:0.06025950610637665, rse:0.292196124792099\n",
      "Intermediate time for ES and pred_len 24: 00h:03m:37.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1382145\n",
      "\tspeed: 0.0379s/iter; left time: 164.7397s\n",
      "\titers: 200, epoch: 1 | loss: 0.1181780\n",
      "\tspeed: 0.0160s/iter; left time: 67.8674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.1422870 Vali Loss: 0.1110726 Test Loss: 0.1262145\n",
      "Validation loss decreased (inf --> 0.111073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934740\n",
      "\tspeed: 0.0365s/iter; left time: 150.3850s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868728\n",
      "\tspeed: 0.0161s/iter; left time: 64.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0946656 Vali Loss: 0.0840059 Test Loss: 0.0971048\n",
      "Validation loss decreased (0.111073 --> 0.084006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818275\n",
      "\tspeed: 0.0364s/iter; left time: 141.9095s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815208\n",
      "\tspeed: 0.0158s/iter; left time: 60.1087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0849752 Vali Loss: 0.0803390 Test Loss: 0.0920883\n",
      "Validation loss decreased (0.084006 --> 0.080339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0843434\n",
      "\tspeed: 0.0367s/iter; left time: 135.0444s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803908\n",
      "\tspeed: 0.0164s/iter; left time: 58.7824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0819896 Vali Loss: 0.0789692 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.080339 --> 0.078969).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0778120\n",
      "\tspeed: 0.0369s/iter; left time: 127.4601s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792906\n",
      "\tspeed: 0.0162s/iter; left time: 54.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0802503 Vali Loss: 0.0777747 Test Loss: 0.0894107\n",
      "Validation loss decreased (0.078969 --> 0.077775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807522\n",
      "\tspeed: 0.0380s/iter; left time: 122.8049s\n",
      "\titers: 200, epoch: 6 | loss: 0.0769921\n",
      "\tspeed: 0.0161s/iter; left time: 50.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0790549 Vali Loss: 0.0774048 Test Loss: 0.0887209\n",
      "Validation loss decreased (0.077775 --> 0.077405).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823921\n",
      "\tspeed: 0.0368s/iter; left time: 110.7950s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769773\n",
      "\tspeed: 0.0165s/iter; left time: 48.1353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0780271 Vali Loss: 0.0765681 Test Loss: 0.0888416\n",
      "Validation loss decreased (0.077405 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805103\n",
      "\tspeed: 0.0372s/iter; left time: 103.5773s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825891\n",
      "\tspeed: 0.0166s/iter; left time: 44.6667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0772853 Vali Loss: 0.0766558 Test Loss: 0.0883564\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758953\n",
      "\tspeed: 0.0376s/iter; left time: 96.3159s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758411\n",
      "\tspeed: 0.0165s/iter; left time: 40.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0766971 Vali Loss: 0.0760411 Test Loss: 0.0879879\n",
      "Validation loss decreased (0.076568 --> 0.076041).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772159\n",
      "\tspeed: 0.0370s/iter; left time: 86.5931s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762513\n",
      "\tspeed: 0.0166s/iter; left time: 37.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0761602 Vali Loss: 0.0759706 Test Loss: 0.0880720\n",
      "Validation loss decreased (0.076041 --> 0.075971).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0755076\n",
      "\tspeed: 0.0362s/iter; left time: 76.8158s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763734\n",
      "\tspeed: 0.0165s/iter; left time: 33.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0756422 Vali Loss: 0.0762044 Test Loss: 0.0878475\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0748532\n",
      "\tspeed: 0.0359s/iter; left time: 68.0922s\n",
      "\titers: 200, epoch: 12 | loss: 0.0741075\n",
      "\tspeed: 0.0165s/iter; left time: 29.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0751778 Vali Loss: 0.0761833 Test Loss: 0.0877756\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0756494\n",
      "\tspeed: 0.0362s/iter; left time: 60.7856s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696331\n",
      "\tspeed: 0.0165s/iter; left time: 26.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0747903 Vali Loss: 0.0759777 Test Loss: 0.0875898\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709691\n",
      "\tspeed: 0.0360s/iter; left time: 52.4383s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781972\n",
      "\tspeed: 0.0165s/iter; left time: 22.4250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0744701 Vali Loss: 0.0760754 Test Loss: 0.0878949\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766354\n",
      "\tspeed: 0.0373s/iter; left time: 45.9441s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760197\n",
      "\tspeed: 0.0165s/iter; left time: 18.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 222 | Train Loss: 0.0741755 Vali Loss: 0.0762521 Test Loss: 0.0875846\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01861393451690674, rmse:0.13643290102481842, mae:0.08807197213172913, rse:0.4007987976074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1401673\n",
      "\tspeed: 0.0193s/iter; left time: 83.7271s\n",
      "\titers: 200, epoch: 1 | loss: 0.1195182\n",
      "\tspeed: 0.0165s/iter; left time: 70.0892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.1430732 Vali Loss: 0.1126027 Test Loss: 0.1276715\n",
      "Validation loss decreased (inf --> 0.112603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0918490\n",
      "\tspeed: 0.0411s/iter; left time: 169.2667s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912421\n",
      "\tspeed: 0.0166s/iter; left time: 66.8071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0946936 Vali Loss: 0.0846617 Test Loss: 0.0975314\n",
      "Validation loss decreased (0.112603 --> 0.084662).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851025\n",
      "\tspeed: 0.0366s/iter; left time: 142.7199s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807028\n",
      "\tspeed: 0.0166s/iter; left time: 62.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0852020 Vali Loss: 0.0806539 Test Loss: 0.0927236\n",
      "Validation loss decreased (0.084662 --> 0.080654).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0821001\n",
      "\tspeed: 0.0367s/iter; left time: 134.7763s\n",
      "\titers: 200, epoch: 4 | loss: 0.0830633\n",
      "\tspeed: 0.0166s/iter; left time: 59.1893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0822834 Vali Loss: 0.0789649 Test Loss: 0.0910162\n",
      "Validation loss decreased (0.080654 --> 0.078965).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0768529\n",
      "\tspeed: 0.0362s/iter; left time: 125.0620s\n",
      "\titers: 200, epoch: 5 | loss: 0.0789720\n",
      "\tspeed: 0.0165s/iter; left time: 55.3816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0804274 Vali Loss: 0.0782210 Test Loss: 0.0894947\n",
      "Validation loss decreased (0.078965 --> 0.078221).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749856\n",
      "\tspeed: 0.0363s/iter; left time: 117.2226s\n",
      "\titers: 200, epoch: 6 | loss: 0.0800525\n",
      "\tspeed: 0.0166s/iter; left time: 51.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0790466 Vali Loss: 0.0770681 Test Loss: 0.0889147\n",
      "Validation loss decreased (0.078221 --> 0.077068).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0778470\n",
      "\tspeed: 0.0367s/iter; left time: 110.3294s\n",
      "\titers: 200, epoch: 7 | loss: 0.0764591\n",
      "\tspeed: 0.0166s/iter; left time: 48.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0780620 Vali Loss: 0.0770800 Test Loss: 0.0882575\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0761395\n",
      "\tspeed: 0.0359s/iter; left time: 100.0392s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761275\n",
      "\tspeed: 0.0165s/iter; left time: 44.4483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0773584 Vali Loss: 0.0764647 Test Loss: 0.0884067\n",
      "Validation loss decreased (0.077068 --> 0.076465).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758509\n",
      "\tspeed: 0.0367s/iter; left time: 94.1422s\n",
      "\titers: 200, epoch: 9 | loss: 0.0754697\n",
      "\tspeed: 0.0166s/iter; left time: 40.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0766769 Vali Loss: 0.0765209 Test Loss: 0.0880247\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777909\n",
      "\tspeed: 0.0355s/iter; left time: 83.2139s\n",
      "\titers: 200, epoch: 10 | loss: 0.0743774\n",
      "\tspeed: 0.0160s/iter; left time: 35.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0761345 Vali Loss: 0.0761065 Test Loss: 0.0884370\n",
      "Validation loss decreased (0.076465 --> 0.076106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781779\n",
      "\tspeed: 0.0366s/iter; left time: 77.5590s\n",
      "\titers: 200, epoch: 11 | loss: 0.0781140\n",
      "\tspeed: 0.0166s/iter; left time: 33.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0756517 Vali Loss: 0.0762509 Test Loss: 0.0878481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0758330\n",
      "\tspeed: 0.0360s/iter; left time: 68.3632s\n",
      "\titers: 200, epoch: 12 | loss: 0.0747232\n",
      "\tspeed: 0.0165s/iter; left time: 29.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0751902 Vali Loss: 0.0762376 Test Loss: 0.0878943\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0750675\n",
      "\tspeed: 0.0357s/iter; left time: 59.8132s\n",
      "\titers: 200, epoch: 13 | loss: 0.0719781\n",
      "\tspeed: 0.0165s/iter; left time: 26.0753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0748755 Vali Loss: 0.0764348 Test Loss: 0.0878604\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734775\n",
      "\tspeed: 0.0361s/iter; left time: 52.4920s\n",
      "\titers: 200, epoch: 14 | loss: 0.0739771\n",
      "\tspeed: 0.0166s/iter; left time: 22.4688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0744408 Vali Loss: 0.0763637 Test Loss: 0.0873832\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0743827\n",
      "\tspeed: 0.0372s/iter; left time: 45.8946s\n",
      "\titers: 200, epoch: 15 | loss: 0.0768726\n",
      "\tspeed: 0.0165s/iter; left time: 18.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0741297 Vali Loss: 0.0766998 Test Loss: 0.0875579\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018726512789726257, rmse:0.13684484362602234, mae:0.0884370505809784, rse:0.402008980512619\n",
      "Intermediate time for ES and pred_len 96: 00h:02m:49.81s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1420207\n",
      "\tspeed: 0.0367s/iter; left time: 159.1286s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220062\n",
      "\tspeed: 0.0164s/iter; left time: 69.5255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 222 | Train Loss: 0.1459882 Vali Loss: 0.1142418 Test Loss: 0.1288368\n",
      "Validation loss decreased (inf --> 0.114242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938779\n",
      "\tspeed: 0.0367s/iter; left time: 151.1914s\n",
      "\titers: 200, epoch: 2 | loss: 0.0906986\n",
      "\tspeed: 0.0163s/iter; left time: 65.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0986648 Vali Loss: 0.0893049 Test Loss: 0.1028076\n",
      "Validation loss decreased (0.114242 --> 0.089305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886885\n",
      "\tspeed: 0.0380s/iter; left time: 148.0387s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865253\n",
      "\tspeed: 0.0164s/iter; left time: 62.3000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0898190 Vali Loss: 0.0859340 Test Loss: 0.0980160\n",
      "Validation loss decreased (0.089305 --> 0.085934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0852806\n",
      "\tspeed: 0.0366s/iter; left time: 134.6612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859492\n",
      "\tspeed: 0.0164s/iter; left time: 58.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0869044 Vali Loss: 0.0841650 Test Loss: 0.0958709\n",
      "Validation loss decreased (0.085934 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888405\n",
      "\tspeed: 0.0361s/iter; left time: 124.5844s\n",
      "\titers: 200, epoch: 5 | loss: 0.0867904\n",
      "\tspeed: 0.0162s/iter; left time: 54.3151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0850048 Vali Loss: 0.0835832 Test Loss: 0.0956103\n",
      "Validation loss decreased (0.084165 --> 0.083583).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844916\n",
      "\tspeed: 0.0383s/iter; left time: 123.7300s\n",
      "\titers: 200, epoch: 6 | loss: 0.0805309\n",
      "\tspeed: 0.0162s/iter; left time: 50.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0836529 Vali Loss: 0.0832231 Test Loss: 0.0952673\n",
      "Validation loss decreased (0.083583 --> 0.083223).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847475\n",
      "\tspeed: 0.0368s/iter; left time: 110.8086s\n",
      "\titers: 200, epoch: 7 | loss: 0.0842363\n",
      "\tspeed: 0.0162s/iter; left time: 47.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0825565 Vali Loss: 0.0831752 Test Loss: 0.0948034\n",
      "Validation loss decreased (0.083223 --> 0.083175).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815429\n",
      "\tspeed: 0.0372s/iter; left time: 103.7756s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795956\n",
      "\tspeed: 0.0162s/iter; left time: 43.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0816194 Vali Loss: 0.0834158 Test Loss: 0.0945200\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805828\n",
      "\tspeed: 0.0356s/iter; left time: 91.3756s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785723\n",
      "\tspeed: 0.0164s/iter; left time: 40.4454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0808371 Vali Loss: 0.0834359 Test Loss: 0.0951119\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788970\n",
      "\tspeed: 0.0364s/iter; left time: 85.1798s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791808\n",
      "\tspeed: 0.0162s/iter; left time: 36.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0801603 Vali Loss: 0.0837579 Test Loss: 0.0949604\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781882\n",
      "\tspeed: 0.0365s/iter; left time: 77.5082s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749253\n",
      "\tspeed: 0.0162s/iter; left time: 32.6774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0795041 Vali Loss: 0.0836973 Test Loss: 0.0950555\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0820172\n",
      "\tspeed: 0.0355s/iter; left time: 67.4894s\n",
      "\titers: 200, epoch: 12 | loss: 0.0827949\n",
      "\tspeed: 0.0162s/iter; left time: 29.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0790387 Vali Loss: 0.0843834 Test Loss: 0.0948036\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02094191126525402, rmse:0.14471320807933807, mae:0.09480340778827667, rse:0.4251543879508972\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1496143\n",
      "\tspeed: 0.0188s/iter; left time: 81.7257s\n",
      "\titers: 200, epoch: 1 | loss: 0.1239623\n",
      "\tspeed: 0.0164s/iter; left time: 69.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.1494615 Vali Loss: 0.1163782 Test Loss: 0.1309904\n",
      "Validation loss decreased (inf --> 0.116378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0963073\n",
      "\tspeed: 0.0363s/iter; left time: 149.6607s\n",
      "\titers: 200, epoch: 2 | loss: 0.0907201\n",
      "\tspeed: 0.0164s/iter; left time: 65.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0985604 Vali Loss: 0.0897975 Test Loss: 0.1030184\n",
      "Validation loss decreased (0.116378 --> 0.089797).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0908636\n",
      "\tspeed: 0.0383s/iter; left time: 149.2550s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888883\n",
      "\tspeed: 0.0164s/iter; left time: 62.0848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0900136 Vali Loss: 0.0864137 Test Loss: 0.0986794\n",
      "Validation loss decreased (0.089797 --> 0.086414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853538\n",
      "\tspeed: 0.0365s/iter; left time: 134.1591s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859582\n",
      "\tspeed: 0.0162s/iter; left time: 57.7471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0870681 Vali Loss: 0.0853866 Test Loss: 0.0963003\n",
      "Validation loss decreased (0.086414 --> 0.085387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0824069\n",
      "\tspeed: 0.0382s/iter; left time: 131.9430s\n",
      "\titers: 200, epoch: 5 | loss: 0.0809987\n",
      "\tspeed: 0.0164s/iter; left time: 54.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0851098 Vali Loss: 0.0841634 Test Loss: 0.0957687\n",
      "Validation loss decreased (0.085387 --> 0.084163).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0813394\n",
      "\tspeed: 0.0371s/iter; left time: 119.8784s\n",
      "\titers: 200, epoch: 6 | loss: 0.0816348\n",
      "\tspeed: 0.0162s/iter; left time: 50.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0836742 Vali Loss: 0.0833399 Test Loss: 0.0949330\n",
      "Validation loss decreased (0.084163 --> 0.083340).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0828306\n",
      "\tspeed: 0.0357s/iter; left time: 107.2841s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830407\n",
      "\tspeed: 0.0162s/iter; left time: 47.2246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0824505 Vali Loss: 0.0835392 Test Loss: 0.0949280\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0814650\n",
      "\tspeed: 0.0359s/iter; left time: 100.0302s\n",
      "\titers: 200, epoch: 8 | loss: 0.0808381\n",
      "\tspeed: 0.0163s/iter; left time: 43.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0814993 Vali Loss: 0.0834557 Test Loss: 0.0947734\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0787199\n",
      "\tspeed: 0.0355s/iter; left time: 91.1109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0799115\n",
      "\tspeed: 0.0163s/iter; left time: 40.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0805486 Vali Loss: 0.0833337 Test Loss: 0.0949287\n",
      "Validation loss decreased (0.083340 --> 0.083334).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0836201\n",
      "\tspeed: 0.0371s/iter; left time: 86.8456s\n",
      "\titers: 200, epoch: 10 | loss: 0.0804693\n",
      "\tspeed: 0.0162s/iter; left time: 36.3958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0798706 Vali Loss: 0.0834730 Test Loss: 0.0946220\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0760122\n",
      "\tspeed: 0.0356s/iter; left time: 75.4284s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766698\n",
      "\tspeed: 0.0162s/iter; left time: 32.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0791417 Vali Loss: 0.0835872 Test Loss: 0.0949908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0815300\n",
      "\tspeed: 0.0353s/iter; left time: 66.9741s\n",
      "\titers: 200, epoch: 12 | loss: 0.0771889\n",
      "\tspeed: 0.0162s/iter; left time: 29.0898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0786277 Vali Loss: 0.0843396 Test Loss: 0.0952377\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0792111\n",
      "\tspeed: 0.0361s/iter; left time: 60.5570s\n",
      "\titers: 200, epoch: 13 | loss: 0.0796132\n",
      "\tspeed: 0.0162s/iter; left time: 25.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0781316 Vali Loss: 0.0841842 Test Loss: 0.0952322\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0786563\n",
      "\tspeed: 0.0361s/iter; left time: 52.5267s\n",
      "\titers: 200, epoch: 14 | loss: 0.0782091\n",
      "\tspeed: 0.0163s/iter; left time: 22.0380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0776963 Vali Loss: 0.0846619 Test Loss: 0.0959198\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021230584010481834, rmse:0.14570719003677368, mae:0.09492865204811096, rse:0.42807459831237793\n",
      "Intermediate time for ES and pred_len 168: 00h:02m:27.45s\n",
      "Intermediate time for ES: 00h:08m:54.49s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975797\n",
      "\tspeed: 0.0378s/iter; left time: 164.7804s\n",
      "\titers: 200, epoch: 1 | loss: 0.0836335\n",
      "\tspeed: 0.0160s/iter; left time: 68.1311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 223 | Train Loss: 0.1024391 Vali Loss: 0.0872047 Test Loss: 0.0960801\n",
      "Validation loss decreased (inf --> 0.087205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0558590\n",
      "\tspeed: 0.0341s/iter; left time: 141.2197s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529639\n",
      "\tspeed: 0.0159s/iter; left time: 64.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0578774 Vali Loss: 0.0587300 Test Loss: 0.0621037\n",
      "Validation loss decreased (0.087205 --> 0.058730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0464267\n",
      "\tspeed: 0.0342s/iter; left time: 133.9868s\n",
      "\titers: 200, epoch: 3 | loss: 0.0519227\n",
      "\tspeed: 0.0159s/iter; left time: 60.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0499244 Vali Loss: 0.0564306 Test Loss: 0.0598956\n",
      "Validation loss decreased (0.058730 --> 0.056431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0491055\n",
      "\tspeed: 0.0350s/iter; left time: 129.3276s\n",
      "\titers: 200, epoch: 4 | loss: 0.0485278\n",
      "\tspeed: 0.0158s/iter; left time: 56.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0479141 Vali Loss: 0.0552515 Test Loss: 0.0584848\n",
      "Validation loss decreased (0.056431 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461720\n",
      "\tspeed: 0.0344s/iter; left time: 119.3583s\n",
      "\titers: 200, epoch: 5 | loss: 0.0457155\n",
      "\tspeed: 0.0158s/iter; left time: 53.3060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0465824 Vali Loss: 0.0546872 Test Loss: 0.0577522\n",
      "Validation loss decreased (0.055251 --> 0.054687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473171\n",
      "\tspeed: 0.0342s/iter; left time: 111.0197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0413529\n",
      "\tspeed: 0.0159s/iter; left time: 49.8851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0456244 Vali Loss: 0.0540799 Test Loss: 0.0576998\n",
      "Validation loss decreased (0.054687 --> 0.054080).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445942\n",
      "\tspeed: 0.0346s/iter; left time: 104.4969s\n",
      "\titers: 200, epoch: 7 | loss: 0.0474015\n",
      "\tspeed: 0.0158s/iter; left time: 46.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0449627 Vali Loss: 0.0533268 Test Loss: 0.0570868\n",
      "Validation loss decreased (0.054080 --> 0.053327).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0458883\n",
      "\tspeed: 0.0343s/iter; left time: 96.1273s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440469\n",
      "\tspeed: 0.0159s/iter; left time: 42.8445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0443844 Vali Loss: 0.0530725 Test Loss: 0.0570844\n",
      "Validation loss decreased (0.053327 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0468748\n",
      "\tspeed: 0.0348s/iter; left time: 89.6174s\n",
      "\titers: 200, epoch: 9 | loss: 0.0448973\n",
      "\tspeed: 0.0160s/iter; left time: 39.7061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0439861 Vali Loss: 0.0528239 Test Loss: 0.0568019\n",
      "Validation loss decreased (0.053073 --> 0.052824).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0420790\n",
      "\tspeed: 0.0349s/iter; left time: 82.0910s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407695\n",
      "\tspeed: 0.0160s/iter; left time: 36.1590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0435386 Vali Loss: 0.0526597 Test Loss: 0.0562937\n",
      "Validation loss decreased (0.052824 --> 0.052660).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0412320\n",
      "\tspeed: 0.0343s/iter; left time: 73.1397s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465333\n",
      "\tspeed: 0.0158s/iter; left time: 32.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0433083 Vali Loss: 0.0523613 Test Loss: 0.0560849\n",
      "Validation loss decreased (0.052660 --> 0.052361).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0417468\n",
      "\tspeed: 0.0346s/iter; left time: 66.1049s\n",
      "\titers: 200, epoch: 12 | loss: 0.0436344\n",
      "\tspeed: 0.0159s/iter; left time: 28.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0430509 Vali Loss: 0.0523960 Test Loss: 0.0563496\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463760\n",
      "\tspeed: 0.0343s/iter; left time: 57.8467s\n",
      "\titers: 200, epoch: 13 | loss: 0.0398072\n",
      "\tspeed: 0.0158s/iter; left time: 25.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0427942 Vali Loss: 0.0523807 Test Loss: 0.0562546\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0441464\n",
      "\tspeed: 0.0340s/iter; left time: 49.6417s\n",
      "\titers: 200, epoch: 14 | loss: 0.0437662\n",
      "\tspeed: 0.0158s/iter; left time: 21.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0426049 Vali Loss: 0.0519577 Test Loss: 0.0558820\n",
      "Validation loss decreased (0.052361 --> 0.051958).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0397336\n",
      "\tspeed: 0.0349s/iter; left time: 43.2493s\n",
      "\titers: 200, epoch: 15 | loss: 0.0388149\n",
      "\tspeed: 0.0158s/iter; left time: 18.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0424205 Vali Loss: 0.0520772 Test Loss: 0.0560981\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0439926\n",
      "\tspeed: 0.0338s/iter; left time: 34.3309s\n",
      "\titers: 200, epoch: 16 | loss: 0.0399195\n",
      "\tspeed: 0.0159s/iter; left time: 14.5235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0422887 Vali Loss: 0.0519859 Test Loss: 0.0558941\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0427168\n",
      "\tspeed: 0.0339s/iter; left time: 26.8546s\n",
      "\titers: 200, epoch: 17 | loss: 0.0386291\n",
      "\tspeed: 0.0158s/iter; left time: 10.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0421217 Vali Loss: 0.0517315 Test Loss: 0.0557642\n",
      "Validation loss decreased (0.051958 --> 0.051731).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0424594\n",
      "\tspeed: 0.0348s/iter; left time: 19.8479s\n",
      "\titers: 200, epoch: 18 | loss: 0.0416625\n",
      "\tspeed: 0.0160s/iter; left time: 7.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0419993 Vali Loss: 0.0518133 Test Loss: 0.0558669\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458638\n",
      "\tspeed: 0.0345s/iter; left time: 11.9865s\n",
      "\titers: 200, epoch: 19 | loss: 0.0417649\n",
      "\tspeed: 0.0159s/iter; left time: 3.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0419249 Vali Loss: 0.0517524 Test Loss: 0.0559174\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0395100\n",
      "\tspeed: 0.0346s/iter; left time: 4.2845s\n",
      "\titers: 200, epoch: 20 | loss: 0.0389466\n",
      "\tspeed: 0.0158s/iter; left time: 0.3803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0418182 Vali Loss: 0.0516136 Test Loss: 0.0558284\n",
      "Validation loss decreased (0.051731 --> 0.051614).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010105066001415253, rmse:0.10052395612001419, mae:0.05582839623093605, rse:0.3878186345100403\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0966236\n",
      "\tspeed: 0.0182s/iter; left time: 79.5105s\n",
      "\titers: 200, epoch: 1 | loss: 0.0831524\n",
      "\tspeed: 0.0159s/iter; left time: 67.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0996807 Vali Loss: 0.0866263 Test Loss: 0.0948209\n",
      "Validation loss decreased (inf --> 0.086626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0560986\n",
      "\tspeed: 0.0339s/iter; left time: 140.0796s\n",
      "\titers: 200, epoch: 2 | loss: 0.0508434\n",
      "\tspeed: 0.0161s/iter; left time: 64.8636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0576257 Vali Loss: 0.0589958 Test Loss: 0.0621614\n",
      "Validation loss decreased (0.086626 --> 0.058996).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0485006\n",
      "\tspeed: 0.0342s/iter; left time: 133.7562s\n",
      "\titers: 200, epoch: 3 | loss: 0.0468709\n",
      "\tspeed: 0.0158s/iter; left time: 60.4264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0497620 Vali Loss: 0.0565754 Test Loss: 0.0597500\n",
      "Validation loss decreased (0.058996 --> 0.056575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0507864\n",
      "\tspeed: 0.0342s/iter; left time: 126.2259s\n",
      "\titers: 200, epoch: 4 | loss: 0.0469318\n",
      "\tspeed: 0.0160s/iter; left time: 57.4876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0478137 Vali Loss: 0.0554897 Test Loss: 0.0588700\n",
      "Validation loss decreased (0.056575 --> 0.055490).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0535418\n",
      "\tspeed: 0.0342s/iter; left time: 118.6495s\n",
      "\titers: 200, epoch: 5 | loss: 0.0447104\n",
      "\tspeed: 0.0159s/iter; left time: 53.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0465286 Vali Loss: 0.0546580 Test Loss: 0.0579263\n",
      "Validation loss decreased (0.055490 --> 0.054658).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0462863\n",
      "\tspeed: 0.0337s/iter; left time: 109.3456s\n",
      "\titers: 200, epoch: 6 | loss: 0.0456071\n",
      "\tspeed: 0.0158s/iter; left time: 49.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0455566 Vali Loss: 0.0539158 Test Loss: 0.0573759\n",
      "Validation loss decreased (0.054658 --> 0.053916).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0444433\n",
      "\tspeed: 0.0336s/iter; left time: 101.7017s\n",
      "\titers: 200, epoch: 7 | loss: 0.0428787\n",
      "\tspeed: 0.0159s/iter; left time: 46.3601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0448679 Vali Loss: 0.0532714 Test Loss: 0.0572128\n",
      "Validation loss decreased (0.053916 --> 0.053271).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0460071\n",
      "\tspeed: 0.0338s/iter; left time: 94.7605s\n",
      "\titers: 200, epoch: 8 | loss: 0.0459002\n",
      "\tspeed: 0.0160s/iter; left time: 43.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0443385 Vali Loss: 0.0529571 Test Loss: 0.0568479\n",
      "Validation loss decreased (0.053271 --> 0.052957).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0424217\n",
      "\tspeed: 0.0337s/iter; left time: 86.8745s\n",
      "\titers: 200, epoch: 9 | loss: 0.0430727\n",
      "\tspeed: 0.0159s/iter; left time: 39.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0438715 Vali Loss: 0.0525021 Test Loss: 0.0568678\n",
      "Validation loss decreased (0.052957 --> 0.052502).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0457912\n",
      "\tspeed: 0.0340s/iter; left time: 80.0129s\n",
      "\titers: 200, epoch: 10 | loss: 0.0435112\n",
      "\tspeed: 0.0158s/iter; left time: 35.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0434994 Vali Loss: 0.0523804 Test Loss: 0.0565236\n",
      "Validation loss decreased (0.052502 --> 0.052380).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0424530\n",
      "\tspeed: 0.0348s/iter; left time: 74.2307s\n",
      "\titers: 200, epoch: 11 | loss: 0.0401238\n",
      "\tspeed: 0.0159s/iter; left time: 32.2261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0431947 Vali Loss: 0.0520191 Test Loss: 0.0563543\n",
      "Validation loss decreased (0.052380 --> 0.052019).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0404953\n",
      "\tspeed: 0.0337s/iter; left time: 64.2675s\n",
      "\titers: 200, epoch: 12 | loss: 0.0433915\n",
      "\tspeed: 0.0158s/iter; left time: 28.5523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0429699 Vali Loss: 0.0522495 Test Loss: 0.0565029\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0419378\n",
      "\tspeed: 0.0333s/iter; left time: 56.1313s\n",
      "\titers: 200, epoch: 13 | loss: 0.0411598\n",
      "\tspeed: 0.0158s/iter; left time: 25.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0426828 Vali Loss: 0.0520837 Test Loss: 0.0565030\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0409010\n",
      "\tspeed: 0.0334s/iter; left time: 48.8928s\n",
      "\titers: 200, epoch: 14 | loss: 0.0416713\n",
      "\tspeed: 0.0160s/iter; left time: 21.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0425600 Vali Loss: 0.0519739 Test Loss: 0.0559947\n",
      "Validation loss decreased (0.052019 --> 0.051974).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0412968\n",
      "\tspeed: 0.0344s/iter; left time: 42.6796s\n",
      "\titers: 200, epoch: 15 | loss: 0.0421452\n",
      "\tspeed: 0.0159s/iter; left time: 18.0987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0423573 Vali Loss: 0.0517680 Test Loss: 0.0560328\n",
      "Validation loss decreased (0.051974 --> 0.051768).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0413271\n",
      "\tspeed: 0.0337s/iter; left time: 34.2554s\n",
      "\titers: 200, epoch: 16 | loss: 0.0467588\n",
      "\tspeed: 0.0158s/iter; left time: 14.4765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0421538 Vali Loss: 0.0516503 Test Loss: 0.0558049\n",
      "Validation loss decreased (0.051768 --> 0.051650).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423275\n",
      "\tspeed: 0.0339s/iter; left time: 26.9066s\n",
      "\titers: 200, epoch: 17 | loss: 0.0465122\n",
      "\tspeed: 0.0158s/iter; left time: 10.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0421002 Vali Loss: 0.0517575 Test Loss: 0.0560114\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0405653\n",
      "\tspeed: 0.0336s/iter; left time: 19.1664s\n",
      "\titers: 200, epoch: 18 | loss: 0.0397078\n",
      "\tspeed: 0.0159s/iter; left time: 7.4614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0419517 Vali Loss: 0.0514324 Test Loss: 0.0559192\n",
      "Validation loss decreased (0.051650 --> 0.051432).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0389818\n",
      "\tspeed: 0.0344s/iter; left time: 11.9218s\n",
      "\titers: 200, epoch: 19 | loss: 0.0445144\n",
      "\tspeed: 0.0159s/iter; left time: 3.9245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0418684 Vali Loss: 0.0514152 Test Loss: 0.0559219\n",
      "Validation loss decreased (0.051432 --> 0.051415).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0429346\n",
      "\tspeed: 0.0340s/iter; left time: 4.2139s\n",
      "\titers: 200, epoch: 20 | loss: 0.0440913\n",
      "\tspeed: 0.0158s/iter; left time: 0.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0417579 Vali Loss: 0.0515154 Test Loss: 0.0558122\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010080426931381226, rmse:0.10040132701396942, mae:0.055921897292137146, rse:0.387345552444458\n",
      "Intermediate time for FR and pred_len 24: 00h:03m:30.31s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1062729\n",
      "\tspeed: 0.0359s/iter; left time: 155.6992s\n",
      "\titers: 200, epoch: 1 | loss: 0.0912535\n",
      "\tspeed: 0.0161s/iter; left time: 68.0696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.1059553 Vali Loss: 0.0940188 Test Loss: 0.1034623\n",
      "Validation loss decreased (inf --> 0.094019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692657\n",
      "\tspeed: 0.0354s/iter; left time: 145.9809s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679127\n",
      "\tspeed: 0.0160s/iter; left time: 64.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0712136 Vali Loss: 0.0755337 Test Loss: 0.0831639\n",
      "Validation loss decreased (0.094019 --> 0.075534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0644198\n",
      "\tspeed: 0.0351s/iter; left time: 136.8146s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641778\n",
      "\tspeed: 0.0160s/iter; left time: 60.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0641186 Vali Loss: 0.0729066 Test Loss: 0.0819365\n",
      "Validation loss decreased (0.075534 --> 0.072907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0631415\n",
      "\tspeed: 0.0350s/iter; left time: 128.7882s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631826\n",
      "\tspeed: 0.0160s/iter; left time: 57.1395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0622656 Vali Loss: 0.0719733 Test Loss: 0.0818505\n",
      "Validation loss decreased (0.072907 --> 0.071973).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571297\n",
      "\tspeed: 0.0348s/iter; left time: 120.1803s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588143\n",
      "\tspeed: 0.0159s/iter; left time: 53.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0612333 Vali Loss: 0.0714952 Test Loss: 0.0811877\n",
      "Validation loss decreased (0.071973 --> 0.071495).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595467\n",
      "\tspeed: 0.0357s/iter; left time: 115.2153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0609350\n",
      "\tspeed: 0.0160s/iter; left time: 50.1219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0604214 Vali Loss: 0.0708795 Test Loss: 0.0811347\n",
      "Validation loss decreased (0.071495 --> 0.070879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608792\n",
      "\tspeed: 0.0347s/iter; left time: 104.5403s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585211\n",
      "\tspeed: 0.0159s/iter; left time: 46.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0597737 Vali Loss: 0.0705817 Test Loss: 0.0810214\n",
      "Validation loss decreased (0.070879 --> 0.070582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0610314\n",
      "\tspeed: 0.0355s/iter; left time: 98.9216s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618555\n",
      "\tspeed: 0.0160s/iter; left time: 42.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0592500 Vali Loss: 0.0704232 Test Loss: 0.0813442\n",
      "Validation loss decreased (0.070582 --> 0.070423).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571530\n",
      "\tspeed: 0.0362s/iter; left time: 92.7466s\n",
      "\titers: 200, epoch: 9 | loss: 0.0578120\n",
      "\tspeed: 0.0160s/iter; left time: 39.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0587209 Vali Loss: 0.0699692 Test Loss: 0.0809877\n",
      "Validation loss decreased (0.070423 --> 0.069969).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548690\n",
      "\tspeed: 0.0349s/iter; left time: 81.8591s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623343\n",
      "\tspeed: 0.0160s/iter; left time: 35.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0583109 Vali Loss: 0.0701566 Test Loss: 0.0808541\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622497\n",
      "\tspeed: 0.0352s/iter; left time: 74.7248s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519874\n",
      "\tspeed: 0.0159s/iter; left time: 32.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0579716 Vali Loss: 0.0699671 Test Loss: 0.0806739\n",
      "Validation loss decreased (0.069969 --> 0.069967).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0575550\n",
      "\tspeed: 0.0355s/iter; left time: 67.4563s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585573\n",
      "\tspeed: 0.0160s/iter; left time: 28.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0576525 Vali Loss: 0.0699727 Test Loss: 0.0805810\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0560351\n",
      "\tspeed: 0.0343s/iter; left time: 57.6002s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602073\n",
      "\tspeed: 0.0160s/iter; left time: 25.2778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0573944 Vali Loss: 0.0700975 Test Loss: 0.0805544\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0595173\n",
      "\tspeed: 0.0351s/iter; left time: 51.0643s\n",
      "\titers: 200, epoch: 14 | loss: 0.0593522\n",
      "\tspeed: 0.0160s/iter; left time: 21.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0570652 Vali Loss: 0.0699457 Test Loss: 0.0812258\n",
      "Validation loss decreased (0.069967 --> 0.069946).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574924\n",
      "\tspeed: 0.0348s/iter; left time: 42.9645s\n",
      "\titers: 200, epoch: 15 | loss: 0.0550430\n",
      "\tspeed: 0.0160s/iter; left time: 18.1093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0568423 Vali Loss: 0.0700274 Test Loss: 0.0809713\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0535070\n",
      "\tspeed: 0.0350s/iter; left time: 35.4056s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542754\n",
      "\tspeed: 0.0160s/iter; left time: 14.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0566337 Vali Loss: 0.0701664 Test Loss: 0.0816400\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0580005\n",
      "\tspeed: 0.0345s/iter; left time: 27.2490s\n",
      "\titers: 200, epoch: 17 | loss: 0.0568877\n",
      "\tspeed: 0.0159s/iter; left time: 10.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0564597 Vali Loss: 0.0703682 Test Loss: 0.0816390\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549882\n",
      "\tspeed: 0.0348s/iter; left time: 19.7149s\n",
      "\titers: 200, epoch: 18 | loss: 0.0590507\n",
      "\tspeed: 0.0160s/iter; left time: 7.4582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0562345 Vali Loss: 0.0703658 Test Loss: 0.0810546\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550113\n",
      "\tspeed: 0.0342s/iter; left time: 11.8030s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547352\n",
      "\tspeed: 0.0160s/iter; left time: 3.9229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0560780 Vali Loss: 0.0702507 Test Loss: 0.0813001\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01962335966527462, rmse:0.1400834023952484, mae:0.08122573792934418, rse:0.5418798327445984\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1078227\n",
      "\tspeed: 0.0180s/iter; left time: 78.0620s\n",
      "\titers: 200, epoch: 1 | loss: 0.0919140\n",
      "\tspeed: 0.0160s/iter; left time: 67.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.1105704 Vali Loss: 0.0957569 Test Loss: 0.1053015\n",
      "Validation loss decreased (inf --> 0.095757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0682901\n",
      "\tspeed: 0.0397s/iter; left time: 163.5504s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670406\n",
      "\tspeed: 0.0160s/iter; left time: 64.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0716458 Vali Loss: 0.0761554 Test Loss: 0.0831043\n",
      "Validation loss decreased (0.095757 --> 0.076155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646815\n",
      "\tspeed: 0.0358s/iter; left time: 139.5242s\n",
      "\titers: 200, epoch: 3 | loss: 0.0648520\n",
      "\tspeed: 0.0160s/iter; left time: 60.8137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0644725 Vali Loss: 0.0730400 Test Loss: 0.0815544\n",
      "Validation loss decreased (0.076155 --> 0.073040).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611014\n",
      "\tspeed: 0.0355s/iter; left time: 130.4014s\n",
      "\titers: 200, epoch: 4 | loss: 0.0635274\n",
      "\tspeed: 0.0160s/iter; left time: 57.0322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0622755 Vali Loss: 0.0722037 Test Loss: 0.0812116\n",
      "Validation loss decreased (0.073040 --> 0.072204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0589142\n",
      "\tspeed: 0.0351s/iter; left time: 121.1258s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596506\n",
      "\tspeed: 0.0159s/iter; left time: 53.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0610804 Vali Loss: 0.0714846 Test Loss: 0.0806093\n",
      "Validation loss decreased (0.072204 --> 0.071485).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605698\n",
      "\tspeed: 0.0351s/iter; left time: 113.3552s\n",
      "\titers: 200, epoch: 6 | loss: 0.0608675\n",
      "\tspeed: 0.0160s/iter; left time: 50.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0601794 Vali Loss: 0.0713318 Test Loss: 0.0810132\n",
      "Validation loss decreased (0.071485 --> 0.071332).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621530\n",
      "\tspeed: 0.0357s/iter; left time: 107.4047s\n",
      "\titers: 200, epoch: 7 | loss: 0.0595966\n",
      "\tspeed: 0.0159s/iter; left time: 46.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0595918 Vali Loss: 0.0705500 Test Loss: 0.0805443\n",
      "Validation loss decreased (0.071332 --> 0.070550).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0580288\n",
      "\tspeed: 0.0350s/iter; left time: 97.6625s\n",
      "\titers: 200, epoch: 8 | loss: 0.0600862\n",
      "\tspeed: 0.0160s/iter; left time: 42.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0590850 Vali Loss: 0.0703057 Test Loss: 0.0803361\n",
      "Validation loss decreased (0.070550 --> 0.070306).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0597476\n",
      "\tspeed: 0.0351s/iter; left time: 90.1559s\n",
      "\titers: 200, epoch: 9 | loss: 0.0554207\n",
      "\tspeed: 0.0160s/iter; left time: 39.3566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0585846 Vali Loss: 0.0704701 Test Loss: 0.0806231\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590830\n",
      "\tspeed: 0.0346s/iter; left time: 81.1780s\n",
      "\titers: 200, epoch: 10 | loss: 0.0564615\n",
      "\tspeed: 0.0160s/iter; left time: 35.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0582434 Vali Loss: 0.0699931 Test Loss: 0.0800337\n",
      "Validation loss decreased (0.070306 --> 0.069993).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0569817\n",
      "\tspeed: 0.0353s/iter; left time: 74.8217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0594220\n",
      "\tspeed: 0.0159s/iter; left time: 32.2050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0578705 Vali Loss: 0.0699769 Test Loss: 0.0801870\n",
      "Validation loss decreased (0.069993 --> 0.069977).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0588046\n",
      "\tspeed: 0.0350s/iter; left time: 66.4214s\n",
      "\titers: 200, epoch: 12 | loss: 0.0607358\n",
      "\tspeed: 0.0160s/iter; left time: 28.7534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0575100 Vali Loss: 0.0699266 Test Loss: 0.0803907\n",
      "Validation loss decreased (0.069977 --> 0.069927).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0585321\n",
      "\tspeed: 0.0355s/iter; left time: 59.4517s\n",
      "\titers: 200, epoch: 13 | loss: 0.0579361\n",
      "\tspeed: 0.0160s/iter; left time: 25.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0572901 Vali Loss: 0.0701751 Test Loss: 0.0807457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0538667\n",
      "\tspeed: 0.0352s/iter; left time: 51.1925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0604858\n",
      "\tspeed: 0.0160s/iter; left time: 21.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0569633 Vali Loss: 0.0702045 Test Loss: 0.0805202\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0575523\n",
      "\tspeed: 0.0347s/iter; left time: 42.8014s\n",
      "\titers: 200, epoch: 15 | loss: 0.0541610\n",
      "\tspeed: 0.0160s/iter; left time: 18.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0567761 Vali Loss: 0.0700288 Test Loss: 0.0802097\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0554736\n",
      "\tspeed: 0.0350s/iter; left time: 35.3416s\n",
      "\titers: 200, epoch: 16 | loss: 0.0513818\n",
      "\tspeed: 0.0160s/iter; left time: 14.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0565431 Vali Loss: 0.0701111 Test Loss: 0.0806726\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0571790\n",
      "\tspeed: 0.0352s/iter; left time: 27.7666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0549147\n",
      "\tspeed: 0.0160s/iter; left time: 10.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0564075 Vali Loss: 0.0702400 Test Loss: 0.0804368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01921806111931801, rmse:0.1386292278766632, mae:0.08039069920778275, rse:0.5362547039985657\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:13.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1038085\n",
      "\tspeed: 0.0377s/iter; left time: 163.5113s\n",
      "\titers: 200, epoch: 1 | loss: 0.0886158\n",
      "\tspeed: 0.0163s/iter; left time: 68.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 222 | Train Loss: 0.1091605 Vali Loss: 0.0966437 Test Loss: 0.1046350\n",
      "Validation loss decreased (inf --> 0.096644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0697438\n",
      "\tspeed: 0.0360s/iter; left time: 148.2359s\n",
      "\titers: 200, epoch: 2 | loss: 0.0691064\n",
      "\tspeed: 0.0163s/iter; left time: 65.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0750519 Vali Loss: 0.0789187 Test Loss: 0.0872487\n",
      "Validation loss decreased (0.096644 --> 0.078919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0678330\n",
      "\tspeed: 0.0364s/iter; left time: 141.7553s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678092\n",
      "\tspeed: 0.0163s/iter; left time: 62.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0678947 Vali Loss: 0.0768626 Test Loss: 0.0861012\n",
      "Validation loss decreased (0.078919 --> 0.076863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657281\n",
      "\tspeed: 0.0368s/iter; left time: 135.1291s\n",
      "\titers: 200, epoch: 4 | loss: 0.0660678\n",
      "\tspeed: 0.0164s/iter; left time: 58.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0660797 Vali Loss: 0.0759090 Test Loss: 0.0861572\n",
      "Validation loss decreased (0.076863 --> 0.075909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0692789\n",
      "\tspeed: 0.0368s/iter; left time: 127.1159s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646435\n",
      "\tspeed: 0.0164s/iter; left time: 54.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0650898 Vali Loss: 0.0755803 Test Loss: 0.0858476\n",
      "Validation loss decreased (0.075909 --> 0.075580).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0632229\n",
      "\tspeed: 0.0370s/iter; left time: 119.4200s\n",
      "\titers: 200, epoch: 6 | loss: 0.0647839\n",
      "\tspeed: 0.0163s/iter; left time: 51.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0642895 Vali Loss: 0.0752362 Test Loss: 0.0858734\n",
      "Validation loss decreased (0.075580 --> 0.075236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630247\n",
      "\tspeed: 0.0367s/iter; left time: 110.3919s\n",
      "\titers: 200, epoch: 7 | loss: 0.0642375\n",
      "\tspeed: 0.0164s/iter; left time: 47.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0636251 Vali Loss: 0.0747174 Test Loss: 0.0859729\n",
      "Validation loss decreased (0.075236 --> 0.074717).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0634076\n",
      "\tspeed: 0.0369s/iter; left time: 102.9495s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629932\n",
      "\tspeed: 0.0164s/iter; left time: 43.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0630702 Vali Loss: 0.0744353 Test Loss: 0.0859410\n",
      "Validation loss decreased (0.074717 --> 0.074435).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623881\n",
      "\tspeed: 0.0369s/iter; left time: 94.6838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627867\n",
      "\tspeed: 0.0164s/iter; left time: 40.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0625488 Vali Loss: 0.0742188 Test Loss: 0.0858460\n",
      "Validation loss decreased (0.074435 --> 0.074219).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612790\n",
      "\tspeed: 0.0368s/iter; left time: 86.3386s\n",
      "\titers: 200, epoch: 10 | loss: 0.0607237\n",
      "\tspeed: 0.0162s/iter; left time: 36.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0621399 Vali Loss: 0.0741986 Test Loss: 0.0865132\n",
      "Validation loss decreased (0.074219 --> 0.074199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0644236\n",
      "\tspeed: 0.0367s/iter; left time: 77.8404s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592703\n",
      "\tspeed: 0.0162s/iter; left time: 32.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0617343 Vali Loss: 0.0741677 Test Loss: 0.0863853\n",
      "Validation loss decreased (0.074199 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644370\n",
      "\tspeed: 0.0354s/iter; left time: 67.1966s\n",
      "\titers: 200, epoch: 12 | loss: 0.0639723\n",
      "\tspeed: 0.0164s/iter; left time: 29.4923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0613191 Vali Loss: 0.0743162 Test Loss: 0.0861957\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559229\n",
      "\tspeed: 0.0355s/iter; left time: 59.4999s\n",
      "\titers: 200, epoch: 13 | loss: 0.0556470\n",
      "\tspeed: 0.0164s/iter; left time: 25.8044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0609983 Vali Loss: 0.0742826 Test Loss: 0.0860600\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603098\n",
      "\tspeed: 0.0372s/iter; left time: 54.0824s\n",
      "\titers: 200, epoch: 14 | loss: 0.0619693\n",
      "\tspeed: 0.0163s/iter; left time: 22.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0607090 Vali Loss: 0.0742746 Test Loss: 0.0869348\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0594293\n",
      "\tspeed: 0.0365s/iter; left time: 45.0203s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618856\n",
      "\tspeed: 0.0163s/iter; left time: 18.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0604436 Vali Loss: 0.0745566 Test Loss: 0.0866983\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0625551\n",
      "\tspeed: 0.0363s/iter; left time: 36.7402s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558443\n",
      "\tspeed: 0.0162s/iter; left time: 14.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0601866 Vali Loss: 0.0745793 Test Loss: 0.0866429\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021192140877246857, rmse:0.14557521045207977, mae:0.08638525754213333, rse:0.5638265609741211\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1135118\n",
      "\tspeed: 0.0188s/iter; left time: 81.6290s\n",
      "\titers: 200, epoch: 1 | loss: 0.0940110\n",
      "\tspeed: 0.0163s/iter; left time: 69.2225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.1127467 Vali Loss: 0.0989019 Test Loss: 0.1072703\n",
      "Validation loss decreased (inf --> 0.098902).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0719645\n",
      "\tspeed: 0.0365s/iter; left time: 150.4048s\n",
      "\titers: 200, epoch: 2 | loss: 0.0684651\n",
      "\tspeed: 0.0162s/iter; left time: 65.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0751835 Vali Loss: 0.0800323 Test Loss: 0.0873625\n",
      "Validation loss decreased (0.098902 --> 0.080032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689290\n",
      "\tspeed: 0.0359s/iter; left time: 139.7419s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709937\n",
      "\tspeed: 0.0163s/iter; left time: 61.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0680559 Vali Loss: 0.0771532 Test Loss: 0.0864900\n",
      "Validation loss decreased (0.080032 --> 0.077153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0659223\n",
      "\tspeed: 0.0357s/iter; left time: 131.1153s\n",
      "\titers: 200, epoch: 4 | loss: 0.0657936\n",
      "\tspeed: 0.0162s/iter; left time: 57.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0660471 Vali Loss: 0.0762054 Test Loss: 0.0858534\n",
      "Validation loss decreased (0.077153 --> 0.076205).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0649723\n",
      "\tspeed: 0.0361s/iter; left time: 124.6838s\n",
      "\titers: 200, epoch: 5 | loss: 0.0645800\n",
      "\tspeed: 0.0162s/iter; left time: 54.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0649682 Vali Loss: 0.0755172 Test Loss: 0.0858298\n",
      "Validation loss decreased (0.076205 --> 0.075517).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638525\n",
      "\tspeed: 0.0361s/iter; left time: 116.6168s\n",
      "\titers: 200, epoch: 6 | loss: 0.0692233\n",
      "\tspeed: 0.0162s/iter; left time: 50.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0641383 Vali Loss: 0.0747725 Test Loss: 0.0852236\n",
      "Validation loss decreased (0.075517 --> 0.074772).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0632401\n",
      "\tspeed: 0.0362s/iter; left time: 108.8773s\n",
      "\titers: 200, epoch: 7 | loss: 0.0642724\n",
      "\tspeed: 0.0161s/iter; left time: 46.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0635255 Vali Loss: 0.0748693 Test Loss: 0.0857978\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0645528\n",
      "\tspeed: 0.0352s/iter; left time: 98.0240s\n",
      "\titers: 200, epoch: 8 | loss: 0.0622234\n",
      "\tspeed: 0.0162s/iter; left time: 43.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0629626 Vali Loss: 0.0748626 Test Loss: 0.0853991\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0617922\n",
      "\tspeed: 0.0354s/iter; left time: 90.7450s\n",
      "\titers: 200, epoch: 9 | loss: 0.0606463\n",
      "\tspeed: 0.0163s/iter; left time: 40.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0624070 Vali Loss: 0.0747745 Test Loss: 0.0854686\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0615385\n",
      "\tspeed: 0.0355s/iter; left time: 83.2530s\n",
      "\titers: 200, epoch: 10 | loss: 0.0650223\n",
      "\tspeed: 0.0162s/iter; left time: 36.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0618398 Vali Loss: 0.0752747 Test Loss: 0.0857516\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0613751\n",
      "\tspeed: 0.0354s/iter; left time: 74.9882s\n",
      "\titers: 200, epoch: 11 | loss: 0.0621263\n",
      "\tspeed: 0.0162s/iter; left time: 32.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0614129 Vali Loss: 0.0749968 Test Loss: 0.0854146\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020490793511271477, rmse:0.14314605295658112, mae:0.08522367477416992, rse:0.5544182062149048\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:32.45s\n",
      "Intermediate time for FR: 00h:09m:16.54s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1427019\n",
      "\tspeed: 0.0363s/iter; left time: 158.1655s\n",
      "\titers: 200, epoch: 1 | loss: 0.1210744\n",
      "\tspeed: 0.0159s/iter; left time: 67.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1474612 Vali Loss: 0.1040003 Test Loss: 0.1061004\n",
      "Validation loss decreased (inf --> 0.104000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786053\n",
      "\tspeed: 0.0344s/iter; left time: 142.4891s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688016\n",
      "\tspeed: 0.0158s/iter; left time: 63.8782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0795060 Vali Loss: 0.0627535 Test Loss: 0.0660522\n",
      "Validation loss decreased (0.104000 --> 0.062754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0712326\n",
      "\tspeed: 0.0339s/iter; left time: 132.5366s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645262\n",
      "\tspeed: 0.0158s/iter; left time: 60.2859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0662299 Vali Loss: 0.0600951 Test Loss: 0.0631527\n",
      "Validation loss decreased (0.062754 --> 0.060095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637566\n",
      "\tspeed: 0.0338s/iter; left time: 124.6487s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638368\n",
      "\tspeed: 0.0158s/iter; left time: 56.7971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0632282 Vali Loss: 0.0587887 Test Loss: 0.0614277\n",
      "Validation loss decreased (0.060095 --> 0.058789).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0593576\n",
      "\tspeed: 0.0356s/iter; left time: 123.3242s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606443\n",
      "\tspeed: 0.0159s/iter; left time: 53.4894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0614621 Vali Loss: 0.0578707 Test Loss: 0.0606217\n",
      "Validation loss decreased (0.058789 --> 0.057871).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630265\n",
      "\tspeed: 0.0348s/iter; left time: 112.8025s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619991\n",
      "\tspeed: 0.0159s/iter; left time: 49.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0602812 Vali Loss: 0.0573779 Test Loss: 0.0601057\n",
      "Validation loss decreased (0.057871 --> 0.057378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639013\n",
      "\tspeed: 0.0345s/iter; left time: 104.4238s\n",
      "\titers: 200, epoch: 7 | loss: 0.0623509\n",
      "\tspeed: 0.0159s/iter; left time: 46.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0593809 Vali Loss: 0.0566655 Test Loss: 0.0593408\n",
      "Validation loss decreased (0.057378 --> 0.056665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575579\n",
      "\tspeed: 0.0344s/iter; left time: 96.3420s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638874\n",
      "\tspeed: 0.0159s/iter; left time: 42.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0586741 Vali Loss: 0.0564011 Test Loss: 0.0590913\n",
      "Validation loss decreased (0.056665 --> 0.056401).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0573168\n",
      "\tspeed: 0.0343s/iter; left time: 88.4229s\n",
      "\titers: 200, epoch: 9 | loss: 0.0594589\n",
      "\tspeed: 0.0158s/iter; left time: 39.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0580785 Vali Loss: 0.0563285 Test Loss: 0.0593507\n",
      "Validation loss decreased (0.056401 --> 0.056329).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577093\n",
      "\tspeed: 0.0345s/iter; left time: 81.3092s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602368\n",
      "\tspeed: 0.0159s/iter; left time: 35.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0576331 Vali Loss: 0.0557669 Test Loss: 0.0586965\n",
      "Validation loss decreased (0.056329 --> 0.055767).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583503\n",
      "\tspeed: 0.0347s/iter; left time: 74.0092s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567511\n",
      "\tspeed: 0.0159s/iter; left time: 32.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0572207 Vali Loss: 0.0557464 Test Loss: 0.0586863\n",
      "Validation loss decreased (0.055767 --> 0.055746).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0557410\n",
      "\tspeed: 0.0341s/iter; left time: 65.1030s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559181\n",
      "\tspeed: 0.0158s/iter; left time: 28.6517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0568358 Vali Loss: 0.0554589 Test Loss: 0.0583942\n",
      "Validation loss decreased (0.055746 --> 0.055459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571601\n",
      "\tspeed: 0.0350s/iter; left time: 58.9732s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576887\n",
      "\tspeed: 0.0159s/iter; left time: 25.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0564875 Vali Loss: 0.0554860 Test Loss: 0.0581893\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0531539\n",
      "\tspeed: 0.0346s/iter; left time: 50.5925s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590748\n",
      "\tspeed: 0.0159s/iter; left time: 21.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0563151 Vali Loss: 0.0553224 Test Loss: 0.0581858\n",
      "Validation loss decreased (0.055459 --> 0.055322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506413\n",
      "\tspeed: 0.0344s/iter; left time: 42.6145s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539879\n",
      "\tspeed: 0.0159s/iter; left time: 18.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0560368 Vali Loss: 0.0551295 Test Loss: 0.0582475\n",
      "Validation loss decreased (0.055322 --> 0.055130).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0581412\n",
      "\tspeed: 0.0344s/iter; left time: 34.9065s\n",
      "\titers: 200, epoch: 16 | loss: 0.0519915\n",
      "\tspeed: 0.0159s/iter; left time: 14.5507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0557948 Vali Loss: 0.0549986 Test Loss: 0.0579295\n",
      "Validation loss decreased (0.055130 --> 0.054999).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0555389\n",
      "\tspeed: 0.0344s/iter; left time: 27.2697s\n",
      "\titers: 200, epoch: 17 | loss: 0.0499771\n",
      "\tspeed: 0.0158s/iter; left time: 10.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0556709 Vali Loss: 0.0548981 Test Loss: 0.0580050\n",
      "Validation loss decreased (0.054999 --> 0.054898).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0559821\n",
      "\tspeed: 0.0343s/iter; left time: 19.5616s\n",
      "\titers: 200, epoch: 18 | loss: 0.0539320\n",
      "\tspeed: 0.0159s/iter; left time: 7.4639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0554450 Vali Loss: 0.0548618 Test Loss: 0.0578751\n",
      "Validation loss decreased (0.054898 --> 0.054862).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0516250\n",
      "\tspeed: 0.0358s/iter; left time: 12.4264s\n",
      "\titers: 200, epoch: 19 | loss: 0.0590425\n",
      "\tspeed: 0.0159s/iter; left time: 3.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0553374 Vali Loss: 0.0548607 Test Loss: 0.0577288\n",
      "Validation loss decreased (0.054862 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0521452\n",
      "\tspeed: 0.0343s/iter; left time: 4.2583s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546899\n",
      "\tspeed: 0.0158s/iter; left time: 0.3804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0552047 Vali Loss: 0.0547884 Test Loss: 0.0577962\n",
      "Validation loss decreased (0.054861 --> 0.054788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010150963440537453, rmse:0.10075198858976364, mae:0.05779622495174408, rse:0.38069215416908264\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1419829\n",
      "\tspeed: 0.0176s/iter; left time: 76.7770s\n",
      "\titers: 200, epoch: 1 | loss: 0.1163189\n",
      "\tspeed: 0.0158s/iter; left time: 67.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1425949 Vali Loss: 0.1023602 Test Loss: 0.1041683\n",
      "Validation loss decreased (inf --> 0.102360).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0783880\n",
      "\tspeed: 0.0339s/iter; left time: 140.2696s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679684\n",
      "\tspeed: 0.0159s/iter; left time: 64.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0789644 Vali Loss: 0.0629243 Test Loss: 0.0656664\n",
      "Validation loss decreased (0.102360 --> 0.062924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0616162\n",
      "\tspeed: 0.0341s/iter; left time: 133.5815s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671688\n",
      "\tspeed: 0.0159s/iter; left time: 60.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0660889 Vali Loss: 0.0599624 Test Loss: 0.0629551\n",
      "Validation loss decreased (0.062924 --> 0.059962).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0610458\n",
      "\tspeed: 0.0337s/iter; left time: 124.3400s\n",
      "\titers: 200, epoch: 4 | loss: 0.0610312\n",
      "\tspeed: 0.0159s/iter; left time: 57.0153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0630342 Vali Loss: 0.0586474 Test Loss: 0.0616444\n",
      "Validation loss decreased (0.059962 --> 0.058647).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571282\n",
      "\tspeed: 0.0336s/iter; left time: 116.7024s\n",
      "\titers: 200, epoch: 5 | loss: 0.0562831\n",
      "\tspeed: 0.0159s/iter; left time: 53.4386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0612929 Vali Loss: 0.0577459 Test Loss: 0.0603331\n",
      "Validation loss decreased (0.058647 --> 0.057746).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0608607\n",
      "\tspeed: 0.0341s/iter; left time: 110.5712s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626487\n",
      "\tspeed: 0.0159s/iter; left time: 49.9362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0600615 Vali Loss: 0.0573048 Test Loss: 0.0600555\n",
      "Validation loss decreased (0.057746 --> 0.057305).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581606\n",
      "\tspeed: 0.0343s/iter; left time: 103.6463s\n",
      "\titers: 200, epoch: 7 | loss: 0.0609005\n",
      "\tspeed: 0.0158s/iter; left time: 46.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0591594 Vali Loss: 0.0566136 Test Loss: 0.0596915\n",
      "Validation loss decreased (0.057305 --> 0.056614).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0592040\n",
      "\tspeed: 0.0344s/iter; left time: 96.1815s\n",
      "\titers: 200, epoch: 8 | loss: 0.0604212\n",
      "\tspeed: 0.0159s/iter; left time: 42.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0584775 Vali Loss: 0.0565187 Test Loss: 0.0593163\n",
      "Validation loss decreased (0.056614 --> 0.056519).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0590639\n",
      "\tspeed: 0.0340s/iter; left time: 87.6995s\n",
      "\titers: 200, epoch: 9 | loss: 0.0605114\n",
      "\tspeed: 0.0159s/iter; left time: 39.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0579033 Vali Loss: 0.0563604 Test Loss: 0.0590891\n",
      "Validation loss decreased (0.056519 --> 0.056360).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0603953\n",
      "\tspeed: 0.0340s/iter; left time: 80.0911s\n",
      "\titers: 200, epoch: 10 | loss: 0.0575978\n",
      "\tspeed: 0.0158s/iter; left time: 35.6807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0574486 Vali Loss: 0.0557433 Test Loss: 0.0589160\n",
      "Validation loss decreased (0.056360 --> 0.055743).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0571903\n",
      "\tspeed: 0.0343s/iter; left time: 73.1867s\n",
      "\titers: 200, epoch: 11 | loss: 0.0529450\n",
      "\tspeed: 0.0158s/iter; left time: 32.1684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0570072 Vali Loss: 0.0554434 Test Loss: 0.0585258\n",
      "Validation loss decreased (0.055743 --> 0.055443).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0591192\n",
      "\tspeed: 0.0337s/iter; left time: 64.3015s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585950\n",
      "\tspeed: 0.0159s/iter; left time: 28.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0567224 Vali Loss: 0.0554773 Test Loss: 0.0584189\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559475\n",
      "\tspeed: 0.0334s/iter; left time: 56.2506s\n",
      "\titers: 200, epoch: 13 | loss: 0.0567616\n",
      "\tspeed: 0.0158s/iter; left time: 25.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0563565 Vali Loss: 0.0550969 Test Loss: 0.0582760\n",
      "Validation loss decreased (0.055443 --> 0.055097).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0556220\n",
      "\tspeed: 0.0338s/iter; left time: 49.4329s\n",
      "\titers: 200, epoch: 14 | loss: 0.0526725\n",
      "\tspeed: 0.0158s/iter; left time: 21.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0560953 Vali Loss: 0.0550480 Test Loss: 0.0581160\n",
      "Validation loss decreased (0.055097 --> 0.055048).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0577325\n",
      "\tspeed: 0.0343s/iter; left time: 42.4834s\n",
      "\titers: 200, epoch: 15 | loss: 0.0528219\n",
      "\tspeed: 0.0159s/iter; left time: 18.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0559282 Vali Loss: 0.0551110 Test Loss: 0.0581104\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0570617\n",
      "\tspeed: 0.0338s/iter; left time: 34.3473s\n",
      "\titers: 200, epoch: 16 | loss: 0.0573260\n",
      "\tspeed: 0.0158s/iter; left time: 14.5047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0556951 Vali Loss: 0.0549273 Test Loss: 0.0579408\n",
      "Validation loss decreased (0.055048 --> 0.054927).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0549826\n",
      "\tspeed: 0.0343s/iter; left time: 27.2352s\n",
      "\titers: 200, epoch: 17 | loss: 0.0620541\n",
      "\tspeed: 0.0159s/iter; left time: 11.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0555529 Vali Loss: 0.0548897 Test Loss: 0.0581434\n",
      "Validation loss decreased (0.054927 --> 0.054890).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0578782\n",
      "\tspeed: 0.0343s/iter; left time: 19.5326s\n",
      "\titers: 200, epoch: 18 | loss: 0.0545308\n",
      "\tspeed: 0.0158s/iter; left time: 7.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0553632 Vali Loss: 0.0548129 Test Loss: 0.0578101\n",
      "Validation loss decreased (0.054890 --> 0.054813).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0525388\n",
      "\tspeed: 0.0341s/iter; left time: 11.8205s\n",
      "\titers: 200, epoch: 19 | loss: 0.0566175\n",
      "\tspeed: 0.0158s/iter; left time: 3.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0552520 Vali Loss: 0.0546502 Test Loss: 0.0578146\n",
      "Validation loss decreased (0.054813 --> 0.054650).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0588491\n",
      "\tspeed: 0.0341s/iter; left time: 4.2281s\n",
      "\titers: 200, epoch: 20 | loss: 0.0545695\n",
      "\tspeed: 0.0159s/iter; left time: 0.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0551397 Vali Loss: 0.0546082 Test Loss: 0.0578759\n",
      "Validation loss decreased (0.054650 --> 0.054608).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010188685730099678, rmse:0.10093902051448822, mae:0.05787594988942146, rse:0.38139885663986206\n",
      "Intermediate time for IT and pred_len 24: 00h:03m:29.97s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1480092\n",
      "\tspeed: 0.0370s/iter; left time: 160.4701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1285040\n",
      "\tspeed: 0.0162s/iter; left time: 68.7154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.1509507 Vali Loss: 0.1113291 Test Loss: 0.1137491\n",
      "Validation loss decreased (inf --> 0.111329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0946910\n",
      "\tspeed: 0.0357s/iter; left time: 146.8925s\n",
      "\titers: 200, epoch: 2 | loss: 0.0880413\n",
      "\tspeed: 0.0160s/iter; left time: 64.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0966951 Vali Loss: 0.0821402 Test Loss: 0.0859240\n",
      "Validation loss decreased (0.111329 --> 0.082140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0857038\n",
      "\tspeed: 0.0361s/iter; left time: 140.5135s\n",
      "\titers: 200, epoch: 3 | loss: 0.0834037\n",
      "\tspeed: 0.0162s/iter; left time: 61.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0849271 Vali Loss: 0.0798710 Test Loss: 0.0837083\n",
      "Validation loss decreased (0.082140 --> 0.079871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806999\n",
      "\tspeed: 0.0355s/iter; left time: 130.3716s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802332\n",
      "\tspeed: 0.0161s/iter; left time: 57.3839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0820312 Vali Loss: 0.0793059 Test Loss: 0.0828319\n",
      "Validation loss decreased (0.079871 --> 0.079306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0756191\n",
      "\tspeed: 0.0364s/iter; left time: 125.6975s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793900\n",
      "\tspeed: 0.0162s/iter; left time: 54.3952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0802160 Vali Loss: 0.0782365 Test Loss: 0.0818849\n",
      "Validation loss decreased (0.079306 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778672\n",
      "\tspeed: 0.0356s/iter; left time: 114.9772s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811385\n",
      "\tspeed: 0.0160s/iter; left time: 50.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0789857 Vali Loss: 0.0778599 Test Loss: 0.0823483\n",
      "Validation loss decreased (0.078237 --> 0.077860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0805226\n",
      "\tspeed: 0.0352s/iter; left time: 105.8812s\n",
      "\titers: 200, epoch: 7 | loss: 0.0763721\n",
      "\tspeed: 0.0159s/iter; left time: 46.3895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0780315 Vali Loss: 0.0776080 Test Loss: 0.0814997\n",
      "Validation loss decreased (0.077860 --> 0.077608).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774337\n",
      "\tspeed: 0.0362s/iter; left time: 100.8269s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790309\n",
      "\tspeed: 0.0160s/iter; left time: 43.0655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0772947 Vali Loss: 0.0778682 Test Loss: 0.0816363\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766557\n",
      "\tspeed: 0.0353s/iter; left time: 90.5842s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757727\n",
      "\tspeed: 0.0159s/iter; left time: 39.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0766040 Vali Loss: 0.0773319 Test Loss: 0.0813767\n",
      "Validation loss decreased (0.077608 --> 0.077332).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735397\n",
      "\tspeed: 0.0357s/iter; left time: 83.7234s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794665\n",
      "\tspeed: 0.0161s/iter; left time: 36.1430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0760296 Vali Loss: 0.0770209 Test Loss: 0.0814560\n",
      "Validation loss decreased (0.077332 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747499\n",
      "\tspeed: 0.0362s/iter; left time: 76.8261s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756375\n",
      "\tspeed: 0.0160s/iter; left time: 32.3999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0754948 Vali Loss: 0.0773987 Test Loss: 0.0817112\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0736938\n",
      "\tspeed: 0.0354s/iter; left time: 67.1702s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756246\n",
      "\tspeed: 0.0161s/iter; left time: 29.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0751052 Vali Loss: 0.0768902 Test Loss: 0.0815840\n",
      "Validation loss decreased (0.077021 --> 0.076890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766086\n",
      "\tspeed: 0.0360s/iter; left time: 60.4472s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705611\n",
      "\tspeed: 0.0160s/iter; left time: 25.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0746385 Vali Loss: 0.0769166 Test Loss: 0.0817023\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752744\n",
      "\tspeed: 0.0350s/iter; left time: 50.8896s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727744\n",
      "\tspeed: 0.0161s/iter; left time: 21.8780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0742598 Vali Loss: 0.0771264 Test Loss: 0.0818628\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718330\n",
      "\tspeed: 0.0355s/iter; left time: 43.8115s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762048\n",
      "\tspeed: 0.0160s/iter; left time: 18.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0739807 Vali Loss: 0.0771396 Test Loss: 0.0821665\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717527\n",
      "\tspeed: 0.0350s/iter; left time: 35.3380s\n",
      "\titers: 200, epoch: 16 | loss: 0.0717268\n",
      "\tspeed: 0.0160s/iter; left time: 14.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0736803 Vali Loss: 0.0769131 Test Loss: 0.0820079\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754391\n",
      "\tspeed: 0.0350s/iter; left time: 27.6282s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759702\n",
      "\tspeed: 0.0161s/iter; left time: 11.0623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0734304 Vali Loss: 0.0771116 Test Loss: 0.0819217\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01853265054523945, rmse:0.13613468408584595, mae:0.08158402144908905, rse:0.5147398710250854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1507262\n",
      "\tspeed: 0.0182s/iter; left time: 78.9177s\n",
      "\titers: 200, epoch: 1 | loss: 0.1296732\n",
      "\tspeed: 0.0161s/iter; left time: 68.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.1529816 Vali Loss: 0.1123396 Test Loss: 0.1146337\n",
      "Validation loss decreased (inf --> 0.112340).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0957740\n",
      "\tspeed: 0.0353s/iter; left time: 145.3642s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912199\n",
      "\tspeed: 0.0161s/iter; left time: 64.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0967408 Vali Loss: 0.0821385 Test Loss: 0.0859979\n",
      "Validation loss decreased (0.112340 --> 0.082139).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0844245\n",
      "\tspeed: 0.0355s/iter; left time: 138.3264s\n",
      "\titers: 200, epoch: 3 | loss: 0.0819175\n",
      "\tspeed: 0.0160s/iter; left time: 60.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0851410 Vali Loss: 0.0801685 Test Loss: 0.0838451\n",
      "Validation loss decreased (0.082139 --> 0.080168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814081\n",
      "\tspeed: 0.0409s/iter; left time: 150.4567s\n",
      "\titers: 200, epoch: 4 | loss: 0.0809551\n",
      "\tspeed: 0.0160s/iter; left time: 57.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0821676 Vali Loss: 0.0793425 Test Loss: 0.0831998\n",
      "Validation loss decreased (0.080168 --> 0.079343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0829052\n",
      "\tspeed: 0.0353s/iter; left time: 121.7924s\n",
      "\titers: 200, epoch: 5 | loss: 0.0803125\n",
      "\tspeed: 0.0160s/iter; left time: 53.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0804876 Vali Loss: 0.0786416 Test Loss: 0.0830506\n",
      "Validation loss decreased (0.079343 --> 0.078642).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778762\n",
      "\tspeed: 0.0353s/iter; left time: 114.0085s\n",
      "\titers: 200, epoch: 6 | loss: 0.0792146\n",
      "\tspeed: 0.0160s/iter; left time: 50.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0793187 Vali Loss: 0.0780971 Test Loss: 0.0822130\n",
      "Validation loss decreased (0.078642 --> 0.078097).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764227\n",
      "\tspeed: 0.0364s/iter; left time: 109.6671s\n",
      "\titers: 200, epoch: 7 | loss: 0.0742595\n",
      "\tspeed: 0.0160s/iter; left time: 46.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0782462 Vali Loss: 0.0779555 Test Loss: 0.0821601\n",
      "Validation loss decreased (0.078097 --> 0.077956).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778910\n",
      "\tspeed: 0.0352s/iter; left time: 97.9670s\n",
      "\titers: 200, epoch: 8 | loss: 0.0733860\n",
      "\tspeed: 0.0159s/iter; left time: 42.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0773523 Vali Loss: 0.0774524 Test Loss: 0.0818950\n",
      "Validation loss decreased (0.077956 --> 0.077452).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808572\n",
      "\tspeed: 0.0351s/iter; left time: 90.1073s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805296\n",
      "\tspeed: 0.0159s/iter; left time: 39.2541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0766624 Vali Loss: 0.0771591 Test Loss: 0.0819085\n",
      "Validation loss decreased (0.077452 --> 0.077159).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751476\n",
      "\tspeed: 0.0354s/iter; left time: 82.9250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0752530\n",
      "\tspeed: 0.0160s/iter; left time: 35.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0759507 Vali Loss: 0.0773464 Test Loss: 0.0817901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720942\n",
      "\tspeed: 0.0352s/iter; left time: 74.6418s\n",
      "\titers: 200, epoch: 11 | loss: 0.0721641\n",
      "\tspeed: 0.0160s/iter; left time: 32.3252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0754021 Vali Loss: 0.0770691 Test Loss: 0.0819440\n",
      "Validation loss decreased (0.077159 --> 0.077069).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0719355\n",
      "\tspeed: 0.0350s/iter; left time: 66.4300s\n",
      "\titers: 200, epoch: 12 | loss: 0.0729342\n",
      "\tspeed: 0.0159s/iter; left time: 28.6710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0748713 Vali Loss: 0.0770017 Test Loss: 0.0820037\n",
      "Validation loss decreased (0.077069 --> 0.077002).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0721806\n",
      "\tspeed: 0.0349s/iter; left time: 58.6059s\n",
      "\titers: 200, epoch: 13 | loss: 0.0732604\n",
      "\tspeed: 0.0160s/iter; left time: 25.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0744331 Vali Loss: 0.0770994 Test Loss: 0.0822397\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719807\n",
      "\tspeed: 0.0345s/iter; left time: 50.2128s\n",
      "\titers: 200, epoch: 14 | loss: 0.0775819\n",
      "\tspeed: 0.0160s/iter; left time: 21.6768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0740726 Vali Loss: 0.0769238 Test Loss: 0.0821027\n",
      "Validation loss decreased (0.077002 --> 0.076924).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0717604\n",
      "\tspeed: 0.0353s/iter; left time: 43.5640s\n",
      "\titers: 200, epoch: 15 | loss: 0.0755598\n",
      "\tspeed: 0.0159s/iter; left time: 18.0514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0737268 Vali Loss: 0.0769512 Test Loss: 0.0821619\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746530\n",
      "\tspeed: 0.0345s/iter; left time: 34.8773s\n",
      "\titers: 200, epoch: 16 | loss: 0.0711408\n",
      "\tspeed: 0.0160s/iter; left time: 14.5329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0733967 Vali Loss: 0.0770700 Test Loss: 0.0824194\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0733515\n",
      "\tspeed: 0.0344s/iter; left time: 27.1721s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706123\n",
      "\tspeed: 0.0160s/iter; left time: 11.0030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0732017 Vali Loss: 0.0769774 Test Loss: 0.0821647\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706411\n",
      "\tspeed: 0.0345s/iter; left time: 19.5486s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706335\n",
      "\tspeed: 0.0160s/iter; left time: 7.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0728884 Vali Loss: 0.0773300 Test Loss: 0.0823716\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0711207\n",
      "\tspeed: 0.0349s/iter; left time: 12.0295s\n",
      "\titers: 200, epoch: 19 | loss: 0.0657455\n",
      "\tspeed: 0.0160s/iter; left time: 3.9181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0727352 Vali Loss: 0.0772174 Test Loss: 0.0821281\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01893829181790352, rmse:0.13761647045612335, mae:0.0821027159690857, rse:0.5203427076339722\n",
      "Intermediate time for IT and pred_len 96: 00h:03m:15.59s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1507905\n",
      "\tspeed: 0.0382s/iter; left time: 165.8940s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282871\n",
      "\tspeed: 0.0162s/iter; left time: 68.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 222 | Train Loss: 0.1545451 Vali Loss: 0.1136977 Test Loss: 0.1152371\n",
      "Validation loss decreased (inf --> 0.113698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0970599\n",
      "\tspeed: 0.0389s/iter; left time: 160.2516s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932366\n",
      "\tspeed: 0.0159s/iter; left time: 64.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.1000816 Vali Loss: 0.0867449 Test Loss: 0.0896152\n",
      "Validation loss decreased (0.113698 --> 0.086745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0901877\n",
      "\tspeed: 0.0371s/iter; left time: 144.4261s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865992\n",
      "\tspeed: 0.0160s/iter; left time: 60.8075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0889035 Vali Loss: 0.0849238 Test Loss: 0.0875093\n",
      "Validation loss decreased (0.086745 --> 0.084924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845438\n",
      "\tspeed: 0.0367s/iter; left time: 134.9906s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829936\n",
      "\tspeed: 0.0162s/iter; left time: 58.0186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0859813 Vali Loss: 0.0839607 Test Loss: 0.0871231\n",
      "Validation loss decreased (0.084924 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0876910\n",
      "\tspeed: 0.0380s/iter; left time: 131.1932s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828706\n",
      "\tspeed: 0.0160s/iter; left time: 53.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0842898 Vali Loss: 0.0835059 Test Loss: 0.0865171\n",
      "Validation loss decreased (0.083961 --> 0.083506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0829766\n",
      "\tspeed: 0.0365s/iter; left time: 117.8530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0801894\n",
      "\tspeed: 0.0162s/iter; left time: 50.7390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0830918 Vali Loss: 0.0831982 Test Loss: 0.0865383\n",
      "Validation loss decreased (0.083506 --> 0.083198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0817649\n",
      "\tspeed: 0.0367s/iter; left time: 110.5703s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810547\n",
      "\tspeed: 0.0162s/iter; left time: 47.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0820679 Vali Loss: 0.0825729 Test Loss: 0.0865927\n",
      "Validation loss decreased (0.083198 --> 0.082573).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778579\n",
      "\tspeed: 0.0364s/iter; left time: 101.5478s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810552\n",
      "\tspeed: 0.0159s/iter; left time: 42.7802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0811687 Vali Loss: 0.0825304 Test Loss: 0.0868129\n",
      "Validation loss decreased (0.082573 --> 0.082530).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791721\n",
      "\tspeed: 0.0356s/iter; left time: 91.2990s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805860\n",
      "\tspeed: 0.0160s/iter; left time: 39.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0804634 Vali Loss: 0.0822290 Test Loss: 0.0871206\n",
      "Validation loss decreased (0.082530 --> 0.082229).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794385\n",
      "\tspeed: 0.0358s/iter; left time: 83.8616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797314\n",
      "\tspeed: 0.0160s/iter; left time: 35.8592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0798415 Vali Loss: 0.0824751 Test Loss: 0.0871971\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0778659\n",
      "\tspeed: 0.0364s/iter; left time: 77.2216s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769867\n",
      "\tspeed: 0.0160s/iter; left time: 32.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0792664 Vali Loss: 0.0825735 Test Loss: 0.0874378\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774243\n",
      "\tspeed: 0.0362s/iter; left time: 68.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788503\n",
      "\tspeed: 0.0161s/iter; left time: 28.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0787563 Vali Loss: 0.0823296 Test Loss: 0.0874938\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766882\n",
      "\tspeed: 0.0354s/iter; left time: 59.3662s\n",
      "\titers: 200, epoch: 13 | loss: 0.0737316\n",
      "\tspeed: 0.0159s/iter; left time: 25.1108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0782796 Vali Loss: 0.0822701 Test Loss: 0.0875234\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0788106\n",
      "\tspeed: 0.0364s/iter; left time: 52.9319s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772315\n",
      "\tspeed: 0.0159s/iter; left time: 21.6037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0779511 Vali Loss: 0.0826971 Test Loss: 0.0877752\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020352747291326523, rmse:0.14266306161880493, mae:0.08712056279182434, rse:0.5399256944656372\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1526684\n",
      "\tspeed: 0.0183s/iter; left time: 79.3003s\n",
      "\titers: 200, epoch: 1 | loss: 0.1311747\n",
      "\tspeed: 0.0161s/iter; left time: 68.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.1564753 Vali Loss: 0.1150082 Test Loss: 0.1166594\n",
      "Validation loss decreased (inf --> 0.115008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0977032\n",
      "\tspeed: 0.0395s/iter; left time: 162.7381s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905012\n",
      "\tspeed: 0.0160s/iter; left time: 64.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 222 | Train Loss: 0.1002000 Vali Loss: 0.0867223 Test Loss: 0.0897312\n",
      "Validation loss decreased (0.115008 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0890371\n",
      "\tspeed: 0.0389s/iter; left time: 151.6035s\n",
      "\titers: 200, epoch: 3 | loss: 0.0867550\n",
      "\tspeed: 0.0162s/iter; left time: 61.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0889192 Vali Loss: 0.0850469 Test Loss: 0.0879137\n",
      "Validation loss decreased (0.086722 --> 0.085047).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0891485\n",
      "\tspeed: 0.0370s/iter; left time: 135.9238s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815158\n",
      "\tspeed: 0.0160s/iter; left time: 57.3464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0859408 Vali Loss: 0.0841075 Test Loss: 0.0872612\n",
      "Validation loss decreased (0.085047 --> 0.084107).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0826774\n",
      "\tspeed: 0.0356s/iter; left time: 122.9527s\n",
      "\titers: 200, epoch: 5 | loss: 0.0841416\n",
      "\tspeed: 0.0160s/iter; left time: 53.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0842623 Vali Loss: 0.0834419 Test Loss: 0.0871409\n",
      "Validation loss decreased (0.084107 --> 0.083442).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0808090\n",
      "\tspeed: 0.0362s/iter; left time: 116.9152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0833669\n",
      "\tspeed: 0.0159s/iter; left time: 49.9205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0829583 Vali Loss: 0.0833017 Test Loss: 0.0873386\n",
      "Validation loss decreased (0.083442 --> 0.083302).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0808285\n",
      "\tspeed: 0.0360s/iter; left time: 108.1758s\n",
      "\titers: 200, epoch: 7 | loss: 0.0819444\n",
      "\tspeed: 0.0159s/iter; left time: 46.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0818957 Vali Loss: 0.0827835 Test Loss: 0.0874482\n",
      "Validation loss decreased (0.083302 --> 0.082784).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798510\n",
      "\tspeed: 0.0363s/iter; left time: 101.1142s\n",
      "\titers: 200, epoch: 8 | loss: 0.0841702\n",
      "\tspeed: 0.0160s/iter; left time: 42.8762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0810556 Vali Loss: 0.0825696 Test Loss: 0.0878618\n",
      "Validation loss decreased (0.082784 --> 0.082570).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0796948\n",
      "\tspeed: 0.0367s/iter; left time: 94.2567s\n",
      "\titers: 200, epoch: 9 | loss: 0.0822921\n",
      "\tspeed: 0.0160s/iter; left time: 39.3262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0803224 Vali Loss: 0.0825211 Test Loss: 0.0879151\n",
      "Validation loss decreased (0.082570 --> 0.082521).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0815537\n",
      "\tspeed: 0.0368s/iter; left time: 86.3298s\n",
      "\titers: 200, epoch: 10 | loss: 0.0789126\n",
      "\tspeed: 0.0159s/iter; left time: 35.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0796628 Vali Loss: 0.0826349 Test Loss: 0.0882702\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774733\n",
      "\tspeed: 0.0353s/iter; left time: 74.8843s\n",
      "\titers: 200, epoch: 11 | loss: 0.0789419\n",
      "\tspeed: 0.0160s/iter; left time: 32.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0791495 Vali Loss: 0.0825843 Test Loss: 0.0884511\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0768253\n",
      "\tspeed: 0.0367s/iter; left time: 69.7540s\n",
      "\titers: 200, epoch: 12 | loss: 0.0767774\n",
      "\tspeed: 0.0166s/iter; left time: 29.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0786895 Vali Loss: 0.0824840 Test Loss: 0.0886010\n",
      "Validation loss decreased (0.082521 --> 0.082484).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0760532\n",
      "\tspeed: 0.0395s/iter; left time: 66.2393s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761733\n",
      "\tspeed: 0.0166s/iter; left time: 26.1433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0782589 Vali Loss: 0.0823821 Test Loss: 0.0887045\n",
      "Validation loss decreased (0.082484 --> 0.082382).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792271\n",
      "\tspeed: 0.0368s/iter; left time: 53.4763s\n",
      "\titers: 200, epoch: 14 | loss: 0.0803011\n",
      "\tspeed: 0.0163s/iter; left time: 22.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0778286 Vali Loss: 0.0829973 Test Loss: 0.0891749\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0775219\n",
      "\tspeed: 0.0361s/iter; left time: 44.4502s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753181\n",
      "\tspeed: 0.0163s/iter; left time: 18.4870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0774740 Vali Loss: 0.0826449 Test Loss: 0.0890899\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0795973\n",
      "\tspeed: 0.0359s/iter; left time: 36.2615s\n",
      "\titers: 200, epoch: 16 | loss: 0.0796113\n",
      "\tspeed: 0.0161s/iter; left time: 14.6412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0771568 Vali Loss: 0.0827013 Test Loss: 0.0891609\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0772035\n",
      "\tspeed: 0.0371s/iter; left time: 29.2922s\n",
      "\titers: 200, epoch: 17 | loss: 0.0795510\n",
      "\tspeed: 0.0161s/iter; left time: 11.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0768850 Vali Loss: 0.0824970 Test Loss: 0.0890725\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726247\n",
      "\tspeed: 0.0363s/iter; left time: 20.5576s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752741\n",
      "\tspeed: 0.0160s/iter; left time: 7.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0766348 Vali Loss: 0.0827873 Test Loss: 0.0893452\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021211443468928337, rmse:0.14564149081707, mae:0.08870448172092438, rse:0.55119788646698\n",
      "Intermediate time for IT and pred_len 168: 00h:02m:59.61s\n",
      "Intermediate time for IT: 00h:09m:45.16s\n",
      "Total time: 00h:49m:49.23s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "patchtst_df_itrs = pd.DataFrame(patchtst_results)\n",
    "\n",
    "# Set multi-index \n",
    "patchtst_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df_itrs.to_csv(os.path.join(path, 'patchtst_df_itrs_bs128_pl512.csv'))\n",
    "patchtst_df_itrs = patchtst_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.0884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.0808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0211  0.1453  0.0884\n",
       "        96         0.0364  0.1906  0.1266\n",
       "        168        0.0386  0.1965  0.1334\n",
       "ES      24         0.0099  0.0994  0.0604\n",
       "        96         0.0186  0.1366  0.0882\n",
       "        168        0.0210  0.1452  0.0948\n",
       "FR      24         0.0101  0.1005  0.0558\n",
       "        96         0.0194  0.1394  0.0808\n",
       "        168        0.0208  0.1444  0.0858\n",
       "GB      24         0.0252  0.1587  0.1002\n",
       "        96         0.0416  0.2040  0.1390\n",
       "        168        0.0446  0.2112  0.1464\n",
       "IT      24         0.0102  0.1008  0.0578\n",
       "        96         0.0187  0.1368  0.0819\n",
       "        168        0.0208  0.1442  0.0879"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final DF\n",
    "patchtst_df = patchtst_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer with PatchTST parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "dropout = 0.2\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2850503\n",
      "\tspeed: 0.0554s/iter; left time: 244.8827s\n",
      "\titers: 200, epoch: 1 | loss: 0.2612018\n",
      "\tspeed: 0.0316s/iter; left time: 136.5766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 226 | Train Loss: 0.2906705 Vali Loss: 0.2817744 Test Loss: 0.2966405\n",
      "Validation loss decreased (inf --> 0.281774).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1934383\n",
      "\tspeed: 0.0623s/iter; left time: 261.4688s\n",
      "\titers: 200, epoch: 2 | loss: 0.1564202\n",
      "\tspeed: 0.0317s/iter; left time: 129.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1888598 Vali Loss: 0.1706345 Test Loss: 0.1783528\n",
      "Validation loss decreased (0.281774 --> 0.170634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1387977\n",
      "\tspeed: 0.0644s/iter; left time: 255.5614s\n",
      "\titers: 200, epoch: 3 | loss: 0.1272498\n",
      "\tspeed: 0.0317s/iter; left time: 122.5700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 226 | Train Loss: 0.1397255 Vali Loss: 0.1439519 Test Loss: 0.1536844\n",
      "Validation loss decreased (0.170634 --> 0.143952).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1274136\n",
      "\tspeed: 0.0641s/iter; left time: 240.0682s\n",
      "\titers: 200, epoch: 4 | loss: 0.1231341\n",
      "\tspeed: 0.0322s/iter; left time: 117.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 226 | Train Loss: 0.1243664 Vali Loss: 0.1410188 Test Loss: 0.1515171\n",
      "Validation loss decreased (0.143952 --> 0.141019).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1204393\n",
      "\tspeed: 0.0633s/iter; left time: 222.5747s\n",
      "\titers: 200, epoch: 5 | loss: 0.1106840\n",
      "\tspeed: 0.0316s/iter; left time: 108.1154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1179926 Vali Loss: 0.1367391 Test Loss: 0.1478636\n",
      "Validation loss decreased (0.141019 --> 0.136739).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1125143\n",
      "\tspeed: 0.0632s/iter; left time: 207.9677s\n",
      "\titers: 200, epoch: 6 | loss: 0.1170508\n",
      "\tspeed: 0.0320s/iter; left time: 102.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 226 | Train Loss: 0.1143434 Vali Loss: 0.1329015 Test Loss: 0.1429864\n",
      "Validation loss decreased (0.136739 --> 0.132902).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1131883\n",
      "\tspeed: 0.0632s/iter; left time: 193.7270s\n",
      "\titers: 200, epoch: 7 | loss: 0.1152762\n",
      "\tspeed: 0.0316s/iter; left time: 93.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 226 | Train Loss: 0.1117556 Vali Loss: 0.1321808 Test Loss: 0.1417100\n",
      "Validation loss decreased (0.132902 --> 0.132181).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1158779\n",
      "\tspeed: 0.0634s/iter; left time: 179.9844s\n",
      "\titers: 200, epoch: 8 | loss: 0.1060115\n",
      "\tspeed: 0.0321s/iter; left time: 87.8852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 226 | Train Loss: 0.1099080 Vali Loss: 0.1333316 Test Loss: 0.1443281\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1054403\n",
      "\tspeed: 0.0621s/iter; left time: 162.2803s\n",
      "\titers: 200, epoch: 9 | loss: 0.1124984\n",
      "\tspeed: 0.0320s/iter; left time: 80.4652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1083780 Vali Loss: 0.1310073 Test Loss: 0.1408871\n",
      "Validation loss decreased (0.132181 --> 0.131007).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027638\n",
      "\tspeed: 0.0629s/iter; left time: 150.2222s\n",
      "\titers: 200, epoch: 10 | loss: 0.1063621\n",
      "\tspeed: 0.0317s/iter; left time: 72.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 226 | Train Loss: 0.1069883 Vali Loss: 0.1287040 Test Loss: 0.1372402\n",
      "Validation loss decreased (0.131007 --> 0.128704).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1037626\n",
      "\tspeed: 0.0631s/iter; left time: 136.3594s\n",
      "\titers: 200, epoch: 11 | loss: 0.1089735\n",
      "\tspeed: 0.0315s/iter; left time: 64.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1061052 Vali Loss: 0.1297567 Test Loss: 0.1387323\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1074404\n",
      "\tspeed: 0.0628s/iter; left time: 121.5485s\n",
      "\titers: 200, epoch: 12 | loss: 0.1051195\n",
      "\tspeed: 0.0317s/iter; left time: 58.1362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 226 | Train Loss: 0.1051432 Vali Loss: 0.1279996 Test Loss: 0.1369499\n",
      "Validation loss decreased (0.128704 --> 0.128000).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1052189\n",
      "\tspeed: 0.0633s/iter; left time: 108.1417s\n",
      "\titers: 200, epoch: 13 | loss: 0.1022407\n",
      "\tspeed: 0.0318s/iter; left time: 51.1588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 226 | Train Loss: 0.1045274 Vali Loss: 0.1275280 Test Loss: 0.1371105\n",
      "Validation loss decreased (0.128000 --> 0.127528).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013967\n",
      "\tspeed: 0.0643s/iter; left time: 95.3859s\n",
      "\titers: 200, epoch: 14 | loss: 0.1026991\n",
      "\tspeed: 0.0320s/iter; left time: 44.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 226 | Train Loss: 0.1039891 Vali Loss: 0.1275021 Test Loss: 0.1362386\n",
      "Validation loss decreased (0.127528 --> 0.127502).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1050184\n",
      "\tspeed: 0.0645s/iter; left time: 81.0686s\n",
      "\titers: 200, epoch: 15 | loss: 0.1105934\n",
      "\tspeed: 0.0314s/iter; left time: 36.2737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1035171 Vali Loss: 0.1277422 Test Loss: 0.1359466\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1032707\n",
      "\tspeed: 0.0630s/iter; left time: 64.9825s\n",
      "\titers: 200, epoch: 16 | loss: 0.1036074\n",
      "\tspeed: 0.0315s/iter; left time: 29.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1031446 Vali Loss: 0.1278536 Test Loss: 0.1361217\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1083631\n",
      "\tspeed: 0.0624s/iter; left time: 50.2410s\n",
      "\titers: 200, epoch: 17 | loss: 0.1037800\n",
      "\tspeed: 0.0315s/iter; left time: 22.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1027177 Vali Loss: 0.1274887 Test Loss: 0.1363003\n",
      "Validation loss decreased (0.127502 --> 0.127489).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1058973\n",
      "\tspeed: 0.0642s/iter; left time: 37.1650s\n",
      "\titers: 200, epoch: 18 | loss: 0.1020541\n",
      "\tspeed: 0.0315s/iter; left time: 15.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.1025720 Vali Loss: 0.1263499 Test Loss: 0.1354789\n",
      "Validation loss decreased (0.127489 --> 0.126350).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1018997\n",
      "\tspeed: 0.0630s/iter; left time: 22.2518s\n",
      "\titers: 200, epoch: 19 | loss: 0.1021739\n",
      "\tspeed: 0.0309s/iter; left time: 7.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.1023228 Vali Loss: 0.1273092 Test Loss: 0.1358986\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1063406\n",
      "\tspeed: 0.0628s/iter; left time: 7.9731s\n",
      "\titers: 200, epoch: 20 | loss: 0.0997600\n",
      "\tspeed: 0.0319s/iter; left time: 0.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.1018642 Vali Loss: 0.1274453 Test Loss: 0.1357896\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04946218430995941, rmse:0.2224009484052658, mae:0.13575194776058197, rse:0.7848837375640869\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2728128\n",
      "\tspeed: 0.0378s/iter; left time: 166.9727s\n",
      "\titers: 200, epoch: 1 | loss: 0.2574384\n",
      "\tspeed: 0.0316s/iter; left time: 136.4251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.81s\n",
      "Steps: 226 | Train Loss: 0.2658733 Vali Loss: 0.2563838 Test Loss: 0.2775598\n",
      "Validation loss decreased (inf --> 0.256384).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1860605\n",
      "\tspeed: 0.0637s/iter; left time: 267.2219s\n",
      "\titers: 200, epoch: 2 | loss: 0.1539983\n",
      "\tspeed: 0.0318s/iter; left time: 130.3353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1827592 Vali Loss: 0.1651841 Test Loss: 0.1729205\n",
      "Validation loss decreased (0.256384 --> 0.165184).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1347750\n",
      "\tspeed: 0.0658s/iter; left time: 261.2183s\n",
      "\titers: 200, epoch: 3 | loss: 0.1280466\n",
      "\tspeed: 0.0319s/iter; left time: 123.5565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 226 | Train Loss: 0.1341157 Vali Loss: 0.1388161 Test Loss: 0.1477263\n",
      "Validation loss decreased (0.165184 --> 0.138816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1219972\n",
      "\tspeed: 0.0623s/iter; left time: 233.2206s\n",
      "\titers: 200, epoch: 4 | loss: 0.1204184\n",
      "\tspeed: 0.0315s/iter; left time: 114.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 226 | Train Loss: 0.1207241 Vali Loss: 0.1354136 Test Loss: 0.1443395\n",
      "Validation loss decreased (0.138816 --> 0.135414).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1179611\n",
      "\tspeed: 0.0627s/iter; left time: 220.6183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183034\n",
      "\tspeed: 0.0323s/iter; left time: 110.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 226 | Train Loss: 0.1149856 Vali Loss: 0.1326392 Test Loss: 0.1413131\n",
      "Validation loss decreased (0.135414 --> 0.132639).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1051551\n",
      "\tspeed: 0.0630s/iter; left time: 207.4768s\n",
      "\titers: 200, epoch: 6 | loss: 0.1161256\n",
      "\tspeed: 0.0319s/iter; left time: 101.6626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.1120273 Vali Loss: 0.1297812 Test Loss: 0.1401427\n",
      "Validation loss decreased (0.132639 --> 0.129781).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1157999\n",
      "\tspeed: 0.0634s/iter; left time: 194.2703s\n",
      "\titers: 200, epoch: 7 | loss: 0.1100689\n",
      "\tspeed: 0.0320s/iter; left time: 94.8206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 226 | Train Loss: 0.1095757 Vali Loss: 0.1278569 Test Loss: 0.1370655\n",
      "Validation loss decreased (0.129781 --> 0.127857).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1056532\n",
      "\tspeed: 0.0622s/iter; left time: 176.6142s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080955\n",
      "\tspeed: 0.0319s/iter; left time: 87.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1079058 Vali Loss: 0.1281975 Test Loss: 0.1381371\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1061016\n",
      "\tspeed: 0.0618s/iter; left time: 161.5470s\n",
      "\titers: 200, epoch: 9 | loss: 0.1062078\n",
      "\tspeed: 0.0315s/iter; left time: 79.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1066224 Vali Loss: 0.1267837 Test Loss: 0.1359993\n",
      "Validation loss decreased (0.127857 --> 0.126784).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1063747\n",
      "\tspeed: 0.0630s/iter; left time: 150.3111s\n",
      "\titers: 200, epoch: 10 | loss: 0.1048075\n",
      "\tspeed: 0.0321s/iter; left time: 73.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 226 | Train Loss: 0.1055578 Vali Loss: 0.1257976 Test Loss: 0.1356338\n",
      "Validation loss decreased (0.126784 --> 0.125798).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1064174\n",
      "\tspeed: 0.0634s/iter; left time: 137.0089s\n",
      "\titers: 200, epoch: 11 | loss: 0.1025514\n",
      "\tspeed: 0.0318s/iter; left time: 65.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1048472 Vali Loss: 0.1263237 Test Loss: 0.1360471\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1001200\n",
      "\tspeed: 0.0624s/iter; left time: 120.6864s\n",
      "\titers: 200, epoch: 12 | loss: 0.1030935\n",
      "\tspeed: 0.0317s/iter; left time: 58.2178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.1040024 Vali Loss: 0.1265480 Test Loss: 0.1359738\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009692\n",
      "\tspeed: 0.0617s/iter; left time: 105.3929s\n",
      "\titers: 200, epoch: 13 | loss: 0.1017462\n",
      "\tspeed: 0.0313s/iter; left time: 50.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.1035184 Vali Loss: 0.1256561 Test Loss: 0.1360085\n",
      "Validation loss decreased (0.125798 --> 0.125656).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1069177\n",
      "\tspeed: 0.0624s/iter; left time: 92.5095s\n",
      "\titers: 200, epoch: 14 | loss: 0.0970065\n",
      "\tspeed: 0.0313s/iter; left time: 43.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1029663 Vali Loss: 0.1239390 Test Loss: 0.1341811\n",
      "Validation loss decreased (0.125656 --> 0.123939).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1051210\n",
      "\tspeed: 0.0626s/iter; left time: 78.7493s\n",
      "\titers: 200, epoch: 15 | loss: 0.1031163\n",
      "\tspeed: 0.0319s/iter; left time: 36.8846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1025541 Vali Loss: 0.1251539 Test Loss: 0.1356147\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1056002\n",
      "\tspeed: 0.0625s/iter; left time: 64.4049s\n",
      "\titers: 200, epoch: 16 | loss: 0.1071445\n",
      "\tspeed: 0.0314s/iter; left time: 29.2755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1022742 Vali Loss: 0.1245193 Test Loss: 0.1354005\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1052293\n",
      "\tspeed: 0.0623s/iter; left time: 50.1199s\n",
      "\titers: 200, epoch: 17 | loss: 0.0984780\n",
      "\tspeed: 0.0317s/iter; left time: 22.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1019409 Vali Loss: 0.1247217 Test Loss: 0.1354259\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1006598\n",
      "\tspeed: 0.0612s/iter; left time: 35.4235s\n",
      "\titers: 200, epoch: 18 | loss: 0.1009130\n",
      "\tspeed: 0.0318s/iter; left time: 15.2116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 226 | Train Loss: 0.1016525 Vali Loss: 0.1253500 Test Loss: 0.1359744\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1070131\n",
      "\tspeed: 0.0614s/iter; left time: 21.6892s\n",
      "\titers: 200, epoch: 19 | loss: 0.1071964\n",
      "\tspeed: 0.0331s/iter; left time: 8.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 226 | Train Loss: 0.1014513 Vali Loss: 0.1251441 Test Loss: 0.1353453\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04927999526262283, rmse:0.22199097275733948, mae:0.13416282832622528, rse:0.7834368944168091\n",
      "Intermediate time for DE and pred_len 24: 00h:06m:20.45s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2979645\n",
      "\tspeed: 0.0617s/iter; left time: 272.7541s\n",
      "\titers: 200, epoch: 1 | loss: 0.2619733\n",
      "\tspeed: 0.0362s/iter; left time: 156.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.01s\n",
      "Steps: 226 | Train Loss: 0.2914338 Vali Loss: 0.2684927 Test Loss: 0.2827348\n",
      "Validation loss decreased (inf --> 0.268493).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1977010\n",
      "\tspeed: 0.0719s/iter; left time: 301.5710s\n",
      "\titers: 200, epoch: 2 | loss: 0.1739215\n",
      "\tspeed: 0.0360s/iter; left time: 147.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 226 | Train Loss: 0.1977282 Vali Loss: 0.1982702 Test Loss: 0.2149053\n",
      "Validation loss decreased (0.268493 --> 0.198270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1548668\n",
      "\tspeed: 0.0722s/iter; left time: 286.5162s\n",
      "\titers: 200, epoch: 3 | loss: 0.1507715\n",
      "\tspeed: 0.0366s/iter; left time: 141.6709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 226 | Train Loss: 0.1564301 Vali Loss: 0.1716589 Test Loss: 0.1874831\n",
      "Validation loss decreased (0.198270 --> 0.171659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1440857\n",
      "\tspeed: 0.0723s/iter; left time: 270.7886s\n",
      "\titers: 200, epoch: 4 | loss: 0.1417214\n",
      "\tspeed: 0.0359s/iter; left time: 130.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 226 | Train Loss: 0.1422754 Vali Loss: 0.1675953 Test Loss: 0.1814237\n",
      "Validation loss decreased (0.171659 --> 0.167595).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1337245\n",
      "\tspeed: 0.0721s/iter; left time: 253.4344s\n",
      "\titers: 200, epoch: 5 | loss: 0.1442872\n",
      "\tspeed: 0.0362s/iter; left time: 123.5779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1374706 Vali Loss: 0.1646219 Test Loss: 0.1802012\n",
      "Validation loss decreased (0.167595 --> 0.164622).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1352070\n",
      "\tspeed: 0.0718s/iter; left time: 236.4352s\n",
      "\titers: 200, epoch: 6 | loss: 0.1274201\n",
      "\tspeed: 0.0363s/iter; left time: 115.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 226 | Train Loss: 0.1345845 Vali Loss: 0.1658308 Test Loss: 0.1810201\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1315774\n",
      "\tspeed: 0.0707s/iter; left time: 216.6212s\n",
      "\titers: 200, epoch: 7 | loss: 0.1288470\n",
      "\tspeed: 0.0361s/iter; left time: 107.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.1326511 Vali Loss: 0.1669347 Test Loss: 0.1823275\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1291343\n",
      "\tspeed: 0.0704s/iter; left time: 199.9523s\n",
      "\titers: 200, epoch: 8 | loss: 0.1326089\n",
      "\tspeed: 0.0362s/iter; left time: 99.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 226 | Train Loss: 0.1308896 Vali Loss: 0.1650998 Test Loss: 0.1794838\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1322043\n",
      "\tspeed: 0.0704s/iter; left time: 183.9402s\n",
      "\titers: 200, epoch: 9 | loss: 0.1275609\n",
      "\tspeed: 0.0359s/iter; left time: 90.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 226 | Train Loss: 0.1297559 Vali Loss: 0.1635853 Test Loss: 0.1800581\n",
      "Validation loss decreased (0.164622 --> 0.163585).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1233979\n",
      "\tspeed: 0.0732s/iter; left time: 174.7564s\n",
      "\titers: 200, epoch: 10 | loss: 0.1253335\n",
      "\tspeed: 0.0360s/iter; left time: 82.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 226 | Train Loss: 0.1285692 Vali Loss: 0.1610944 Test Loss: 0.1762842\n",
      "Validation loss decreased (0.163585 --> 0.161094).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1295469\n",
      "\tspeed: 0.0708s/iter; left time: 152.9372s\n",
      "\titers: 200, epoch: 11 | loss: 0.1293149\n",
      "\tspeed: 0.0357s/iter; left time: 73.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 226 | Train Loss: 0.1277169 Vali Loss: 0.1622647 Test Loss: 0.1778124\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1249967\n",
      "\tspeed: 0.0710s/iter; left time: 137.4099s\n",
      "\titers: 200, epoch: 12 | loss: 0.1252993\n",
      "\tspeed: 0.0360s/iter; left time: 66.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 226 | Train Loss: 0.1270804 Vali Loss: 0.1595611 Test Loss: 0.1761746\n",
      "Validation loss decreased (0.161094 --> 0.159561).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1225362\n",
      "\tspeed: 0.0714s/iter; left time: 122.0454s\n",
      "\titers: 200, epoch: 13 | loss: 0.1273994\n",
      "\tspeed: 0.0362s/iter; left time: 58.2296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1264884 Vali Loss: 0.1588797 Test Loss: 0.1769712\n",
      "Validation loss decreased (0.159561 --> 0.158880).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1270441\n",
      "\tspeed: 0.0718s/iter; left time: 106.4387s\n",
      "\titers: 200, epoch: 14 | loss: 0.1294229\n",
      "\tspeed: 0.0359s/iter; left time: 49.6903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 226 | Train Loss: 0.1260048 Vali Loss: 0.1594193 Test Loss: 0.1766631\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1260617\n",
      "\tspeed: 0.0714s/iter; left time: 89.7931s\n",
      "\titers: 200, epoch: 15 | loss: 0.1248775\n",
      "\tspeed: 0.0362s/iter; left time: 41.8707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 226 | Train Loss: 0.1255412 Vali Loss: 0.1609990 Test Loss: 0.1767546\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1236156\n",
      "\tspeed: 0.0716s/iter; left time: 73.8508s\n",
      "\titers: 200, epoch: 16 | loss: 0.1253932\n",
      "\tspeed: 0.0364s/iter; left time: 33.8814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 226 | Train Loss: 0.1251852 Vali Loss: 0.1604992 Test Loss: 0.1775108\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1206236\n",
      "\tspeed: 0.0734s/iter; left time: 59.0541s\n",
      "\titers: 200, epoch: 17 | loss: 0.1218079\n",
      "\tspeed: 0.0365s/iter; left time: 25.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 226 | Train Loss: 0.1247797 Vali Loss: 0.1591909 Test Loss: 0.1760949\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1226507\n",
      "\tspeed: 0.0732s/iter; left time: 42.3879s\n",
      "\titers: 200, epoch: 18 | loss: 0.1233687\n",
      "\tspeed: 0.0365s/iter; left time: 17.4766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1245271 Vali Loss: 0.1584761 Test Loss: 0.1758068\n",
      "Validation loss decreased (0.158880 --> 0.158476).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1246649\n",
      "\tspeed: 0.0739s/iter; left time: 26.0899s\n",
      "\titers: 200, epoch: 19 | loss: 0.1234806\n",
      "\tspeed: 0.0378s/iter; left time: 9.5518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 226 | Train Loss: 0.1242745 Vali Loss: 0.1586096 Test Loss: 0.1758148\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1294393\n",
      "\tspeed: 0.0755s/iter; left time: 9.5824s\n",
      "\titers: 200, epoch: 20 | loss: 0.1247283\n",
      "\tspeed: 0.0378s/iter; left time: 1.0219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 226 | Train Loss: 0.1240553 Vali Loss: 0.1575107 Test Loss: 0.1753406\n",
      "Validation loss decreased (0.158476 --> 0.157511).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07067342847585678, rmse:0.2658447325229645, mae:0.17543339729309082, rse:0.9414100050926208\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2892258\n",
      "\tspeed: 0.0413s/iter; left time: 182.3801s\n",
      "\titers: 200, epoch: 1 | loss: 0.2823797\n",
      "\tspeed: 0.0360s/iter; left time: 155.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 226 | Train Loss: 0.2957056 Vali Loss: 0.2864288 Test Loss: 0.3030032\n",
      "Validation loss decreased (inf --> 0.286429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1952162\n",
      "\tspeed: 0.0719s/iter; left time: 301.7285s\n",
      "\titers: 200, epoch: 2 | loss: 0.1728611\n",
      "\tspeed: 0.0365s/iter; left time: 149.3828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 226 | Train Loss: 0.1999605 Vali Loss: 0.1867504 Test Loss: 0.2046412\n",
      "Validation loss decreased (0.286429 --> 0.186750).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1608036\n",
      "\tspeed: 0.0737s/iter; left time: 292.7033s\n",
      "\titers: 200, epoch: 3 | loss: 0.1483013\n",
      "\tspeed: 0.0362s/iter; left time: 139.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 226 | Train Loss: 0.1565994 Vali Loss: 0.1687212 Test Loss: 0.1847945\n",
      "Validation loss decreased (0.186750 --> 0.168721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1433462\n",
      "\tspeed: 0.0732s/iter; left time: 274.0388s\n",
      "\titers: 200, epoch: 4 | loss: 0.1416965\n",
      "\tspeed: 0.0365s/iter; left time: 132.8936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 226 | Train Loss: 0.1428119 Vali Loss: 0.1667426 Test Loss: 0.1821162\n",
      "Validation loss decreased (0.168721 --> 0.166743).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1372226\n",
      "\tspeed: 0.0733s/iter; left time: 257.6779s\n",
      "\titers: 200, epoch: 5 | loss: 0.1392089\n",
      "\tspeed: 0.0360s/iter; left time: 123.1667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 226 | Train Loss: 0.1378375 Vali Loss: 0.1622989 Test Loss: 0.1787353\n",
      "Validation loss decreased (0.166743 --> 0.162299).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1326062\n",
      "\tspeed: 0.0723s/iter; left time: 238.0070s\n",
      "\titers: 200, epoch: 6 | loss: 0.1355096\n",
      "\tspeed: 0.0361s/iter; left time: 115.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 226 | Train Loss: 0.1353385 Vali Loss: 0.1622166 Test Loss: 0.1778958\n",
      "Validation loss decreased (0.162299 --> 0.162217).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1307443\n",
      "\tspeed: 0.0720s/iter; left time: 220.7566s\n",
      "\titers: 200, epoch: 7 | loss: 0.1340565\n",
      "\tspeed: 0.0359s/iter; left time: 106.5901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 226 | Train Loss: 0.1335675 Vali Loss: 0.1595157 Test Loss: 0.1768666\n",
      "Validation loss decreased (0.162217 --> 0.159516).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1387691\n",
      "\tspeed: 0.0713s/iter; left time: 202.5053s\n",
      "\titers: 200, epoch: 8 | loss: 0.1274465\n",
      "\tspeed: 0.0364s/iter; left time: 99.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 226 | Train Loss: 0.1320045 Vali Loss: 0.1599833 Test Loss: 0.1772093\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1300732\n",
      "\tspeed: 0.0720s/iter; left time: 188.0270s\n",
      "\titers: 200, epoch: 9 | loss: 0.1267448\n",
      "\tspeed: 0.0358s/iter; left time: 89.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 226 | Train Loss: 0.1308156 Vali Loss: 0.1576020 Test Loss: 0.1752514\n",
      "Validation loss decreased (0.159516 --> 0.157602).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1298917\n",
      "\tspeed: 0.0721s/iter; left time: 172.1357s\n",
      "\titers: 200, epoch: 10 | loss: 0.1261545\n",
      "\tspeed: 0.0361s/iter; left time: 82.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 226 | Train Loss: 0.1298419 Vali Loss: 0.1577523 Test Loss: 0.1759117\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1267491\n",
      "\tspeed: 0.0707s/iter; left time: 152.7113s\n",
      "\titers: 200, epoch: 11 | loss: 0.1260180\n",
      "\tspeed: 0.0365s/iter; left time: 75.1473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 226 | Train Loss: 0.1288979 Vali Loss: 0.1584217 Test Loss: 0.1752839\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1270341\n",
      "\tspeed: 0.0702s/iter; left time: 135.7732s\n",
      "\titers: 200, epoch: 12 | loss: 0.1344062\n",
      "\tspeed: 0.0359s/iter; left time: 65.9255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 226 | Train Loss: 0.1282725 Vali Loss: 0.1598915 Test Loss: 0.1763627\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1281147\n",
      "\tspeed: 0.0711s/iter; left time: 121.5282s\n",
      "\titers: 200, epoch: 13 | loss: 0.1255214\n",
      "\tspeed: 0.0360s/iter; left time: 57.9764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.1275593 Vali Loss: 0.1572132 Test Loss: 0.1747072\n",
      "Validation loss decreased (0.157602 --> 0.157213).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1337810\n",
      "\tspeed: 0.0726s/iter; left time: 107.7220s\n",
      "\titers: 200, epoch: 14 | loss: 0.1270272\n",
      "\tspeed: 0.0356s/iter; left time: 49.2241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 226 | Train Loss: 0.1270426 Vali Loss: 0.1583595 Test Loss: 0.1752665\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1243285\n",
      "\tspeed: 0.0723s/iter; left time: 90.9207s\n",
      "\titers: 200, epoch: 15 | loss: 0.1282022\n",
      "\tspeed: 0.0359s/iter; left time: 41.5918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1265204 Vali Loss: 0.1573266 Test Loss: 0.1751382\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1215820\n",
      "\tspeed: 0.0709s/iter; left time: 73.1074s\n",
      "\titers: 200, epoch: 16 | loss: 0.1268001\n",
      "\tspeed: 0.0361s/iter; left time: 33.6352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 226 | Train Loss: 0.1260765 Vali Loss: 0.1585348 Test Loss: 0.1762070\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1246858\n",
      "\tspeed: 0.0714s/iter; left time: 57.5002s\n",
      "\titers: 200, epoch: 17 | loss: 0.1246869\n",
      "\tspeed: 0.0358s/iter; left time: 25.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.1256544 Vali Loss: 0.1565353 Test Loss: 0.1745306\n",
      "Validation loss decreased (0.157213 --> 0.156535).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1237686\n",
      "\tspeed: 0.0736s/iter; left time: 42.6202s\n",
      "\titers: 200, epoch: 18 | loss: 0.1284661\n",
      "\tspeed: 0.0360s/iter; left time: 17.2216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1254405 Vali Loss: 0.1582126 Test Loss: 0.1759271\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1218617\n",
      "\tspeed: 0.0713s/iter; left time: 25.1552s\n",
      "\titers: 200, epoch: 19 | loss: 0.1255798\n",
      "\tspeed: 0.0361s/iter; left time: 9.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.47s\n",
      "Steps: 226 | Train Loss: 0.1250939 Vali Loss: 0.1560351 Test Loss: 0.1744043\n",
      "Validation loss decreased (0.156535 --> 0.156035).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1223989\n",
      "\tspeed: 0.0713s/iter; left time: 9.0589s\n",
      "\titers: 200, epoch: 20 | loss: 0.1212357\n",
      "\tspeed: 0.0358s/iter; left time: 0.9675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 226 | Train Loss: 0.1248573 Vali Loss: 0.1561580 Test Loss: 0.1748199\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06830287724733353, rmse:0.2613481879234314, mae:0.1743878871202469, rse:0.9254867434501648\n",
      "Intermediate time for DE and pred_len 96: 00h:07m:26.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2919331\n",
      "\tspeed: 0.0682s/iter; left time: 300.2013s\n",
      "\titers: 200, epoch: 1 | loss: 0.2642790\n",
      "\tspeed: 0.0446s/iter; left time: 191.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.71s\n",
      "Steps: 225 | Train Loss: 0.2941204 Vali Loss: 0.2689626 Test Loss: 0.2850314\n",
      "Validation loss decreased (inf --> 0.268963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1985889\n",
      "\tspeed: 0.0860s/iter; left time: 359.2154s\n",
      "\titers: 200, epoch: 2 | loss: 0.1771698\n",
      "\tspeed: 0.0441s/iter; left time: 179.8969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1994737 Vali Loss: 0.1962889 Test Loss: 0.2183952\n",
      "Validation loss decreased (0.268963 --> 0.196289).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1649157\n",
      "\tspeed: 0.0874s/iter; left time: 345.1843s\n",
      "\titers: 200, epoch: 3 | loss: 0.1546169\n",
      "\tspeed: 0.0450s/iter; left time: 173.3017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1611003 Vali Loss: 0.1762528 Test Loss: 0.1956673\n",
      "Validation loss decreased (0.196289 --> 0.176253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1486856\n",
      "\tspeed: 0.0861s/iter; left time: 320.6496s\n",
      "\titers: 200, epoch: 4 | loss: 0.1458529\n",
      "\tspeed: 0.0438s/iter; left time: 158.9330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 225 | Train Loss: 0.1489662 Vali Loss: 0.1716475 Test Loss: 0.1898381\n",
      "Validation loss decreased (0.176253 --> 0.171648).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1465091\n",
      "\tspeed: 0.0850s/iter; left time: 297.4615s\n",
      "\titers: 200, epoch: 5 | loss: 0.1423890\n",
      "\tspeed: 0.0440s/iter; left time: 149.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 225 | Train Loss: 0.1443562 Vali Loss: 0.1722554 Test Loss: 0.1911591\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1388884\n",
      "\tspeed: 0.0840s/iter; left time: 275.1621s\n",
      "\titers: 200, epoch: 6 | loss: 0.1425143\n",
      "\tspeed: 0.0438s/iter; left time: 139.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 225 | Train Loss: 0.1418804 Vali Loss: 0.1717993 Test Loss: 0.1903979\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1396698\n",
      "\tspeed: 0.0839s/iter; left time: 255.9964s\n",
      "\titers: 200, epoch: 7 | loss: 0.1408022\n",
      "\tspeed: 0.0437s/iter; left time: 129.0602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.1400012 Vali Loss: 0.1746895 Test Loss: 0.1920909\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1336985\n",
      "\tspeed: 0.0848s/iter; left time: 239.6446s\n",
      "\titers: 200, epoch: 8 | loss: 0.1383983\n",
      "\tspeed: 0.0445s/iter; left time: 121.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 225 | Train Loss: 0.1381297 Vali Loss: 0.1706948 Test Loss: 0.1885493\n",
      "Validation loss decreased (0.171648 --> 0.170695).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1428962\n",
      "\tspeed: 0.0846s/iter; left time: 220.1486s\n",
      "\titers: 200, epoch: 9 | loss: 0.1364201\n",
      "\tspeed: 0.0446s/iter; left time: 111.4911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1366390 Vali Loss: 0.1710807 Test Loss: 0.1891458\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1366548\n",
      "\tspeed: 0.0853s/iter; left time: 202.6915s\n",
      "\titers: 200, epoch: 10 | loss: 0.1386766\n",
      "\tspeed: 0.0441s/iter; left time: 100.4775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 225 | Train Loss: 0.1356768 Vali Loss: 0.1716755 Test Loss: 0.1897395\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1419389\n",
      "\tspeed: 0.0858s/iter; left time: 184.5391s\n",
      "\titers: 200, epoch: 11 | loss: 0.1336157\n",
      "\tspeed: 0.0442s/iter; left time: 90.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1350545 Vali Loss: 0.1685001 Test Loss: 0.1865522\n",
      "Validation loss decreased (0.170695 --> 0.168500).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1340209\n",
      "\tspeed: 0.0858s/iter; left time: 165.2303s\n",
      "\titers: 200, epoch: 12 | loss: 0.1359094\n",
      "\tspeed: 0.0439s/iter; left time: 80.2275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 225 | Train Loss: 0.1344187 Vali Loss: 0.1708566 Test Loss: 0.1889640\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1385711\n",
      "\tspeed: 0.0841s/iter; left time: 143.0276s\n",
      "\titers: 200, epoch: 13 | loss: 0.1291365\n",
      "\tspeed: 0.0442s/iter; left time: 70.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.1338271 Vali Loss: 0.1673108 Test Loss: 0.1863236\n",
      "Validation loss decreased (0.168500 --> 0.167311).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1254369\n",
      "\tspeed: 0.0865s/iter; left time: 127.6878s\n",
      "\titers: 200, epoch: 14 | loss: 0.1369539\n",
      "\tspeed: 0.0438s/iter; left time: 60.2525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.28s\n",
      "Steps: 225 | Train Loss: 0.1332201 Vali Loss: 0.1689980 Test Loss: 0.1872682\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1314582\n",
      "\tspeed: 0.0835s/iter; left time: 104.5043s\n",
      "\titers: 200, epoch: 15 | loss: 0.1343843\n",
      "\tspeed: 0.0437s/iter; left time: 50.2562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 225 | Train Loss: 0.1327212 Vali Loss: 0.1693960 Test Loss: 0.1882440\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1330234\n",
      "\tspeed: 0.0850s/iter; left time: 87.1923s\n",
      "\titers: 200, epoch: 16 | loss: 0.1369203\n",
      "\tspeed: 0.0438s/iter; left time: 40.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.21s\n",
      "Steps: 225 | Train Loss: 0.1323288 Vali Loss: 0.1681006 Test Loss: 0.1868023\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1303445\n",
      "\tspeed: 0.0841s/iter; left time: 67.3371s\n",
      "\titers: 200, epoch: 17 | loss: 0.1338227\n",
      "\tspeed: 0.0437s/iter; left time: 30.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.1320997 Vali Loss: 0.1694497 Test Loss: 0.1875496\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1338287\n",
      "\tspeed: 0.0841s/iter; left time: 48.4295s\n",
      "\titers: 200, epoch: 18 | loss: 0.1335781\n",
      "\tspeed: 0.0438s/iter; left time: 20.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 225 | Train Loss: 0.1317381 Vali Loss: 0.1681325 Test Loss: 0.1876133\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07505414634943008, rmse:0.2739601135253906, mae:0.18623866140842438, rse:0.9703887701034546\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3081711\n",
      "\tspeed: 0.0471s/iter; left time: 207.3286s\n",
      "\titers: 200, epoch: 1 | loss: 0.2942008\n",
      "\tspeed: 0.0440s/iter; left time: 189.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 225 | Train Loss: 0.3118462 Vali Loss: 0.2948962 Test Loss: 0.3105799\n",
      "Validation loss decreased (inf --> 0.294896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1997809\n",
      "\tspeed: 0.0855s/iter; left time: 357.1920s\n",
      "\titers: 200, epoch: 2 | loss: 0.1737257\n",
      "\tspeed: 0.0440s/iter; left time: 179.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.2024637 Vali Loss: 0.1983361 Test Loss: 0.2197344\n",
      "Validation loss decreased (0.294896 --> 0.198336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1612923\n",
      "\tspeed: 0.0886s/iter; left time: 350.1151s\n",
      "\titers: 200, epoch: 3 | loss: 0.1531096\n",
      "\tspeed: 0.0437s/iter; left time: 168.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.20s\n",
      "Steps: 225 | Train Loss: 0.1623603 Vali Loss: 0.1822303 Test Loss: 0.2001883\n",
      "Validation loss decreased (0.198336 --> 0.182230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1463610\n",
      "\tspeed: 0.0846s/iter; left time: 315.1700s\n",
      "\titers: 200, epoch: 4 | loss: 0.1494908\n",
      "\tspeed: 0.0437s/iter; left time: 158.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 225 | Train Loss: 0.1500319 Vali Loss: 0.1781607 Test Loss: 0.1958503\n",
      "Validation loss decreased (0.182230 --> 0.178161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1446582\n",
      "\tspeed: 0.0844s/iter; left time: 295.5561s\n",
      "\titers: 200, epoch: 5 | loss: 0.1438083\n",
      "\tspeed: 0.0438s/iter; left time: 149.0828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 225 | Train Loss: 0.1452040 Vali Loss: 0.1768737 Test Loss: 0.1931681\n",
      "Validation loss decreased (0.178161 --> 0.176874).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1444094\n",
      "\tspeed: 0.0852s/iter; left time: 279.2074s\n",
      "\titers: 200, epoch: 6 | loss: 0.1456790\n",
      "\tspeed: 0.0437s/iter; left time: 138.7622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 225 | Train Loss: 0.1425854 Vali Loss: 0.1752990 Test Loss: 0.1907977\n",
      "Validation loss decreased (0.176874 --> 0.175299).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1381940\n",
      "\tspeed: 0.0842s/iter; left time: 256.7653s\n",
      "\titers: 200, epoch: 7 | loss: 0.1455479\n",
      "\tspeed: 0.0439s/iter; left time: 129.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.1407955 Vali Loss: 0.1753981 Test Loss: 0.1914905\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1380732\n",
      "\tspeed: 0.0848s/iter; left time: 239.7486s\n",
      "\titers: 200, epoch: 8 | loss: 0.1386576\n",
      "\tspeed: 0.0438s/iter; left time: 119.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.25s\n",
      "Steps: 225 | Train Loss: 0.1393394 Vali Loss: 0.1742232 Test Loss: 0.1901426\n",
      "Validation loss decreased (0.175299 --> 0.174223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1402609\n",
      "\tspeed: 0.0856s/iter; left time: 222.6658s\n",
      "\titers: 200, epoch: 9 | loss: 0.1368972\n",
      "\tspeed: 0.0437s/iter; left time: 109.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 225 | Train Loss: 0.1381093 Vali Loss: 0.1753162 Test Loss: 0.1918945\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1387629\n",
      "\tspeed: 0.0848s/iter; left time: 201.5923s\n",
      "\titers: 200, epoch: 10 | loss: 0.1357187\n",
      "\tspeed: 0.0436s/iter; left time: 99.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.12s\n",
      "Steps: 225 | Train Loss: 0.1371946 Vali Loss: 0.1737086 Test Loss: 0.1894672\n",
      "Validation loss decreased (0.174223 --> 0.173709).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1407201\n",
      "\tspeed: 0.0849s/iter; left time: 182.5894s\n",
      "\titers: 200, epoch: 11 | loss: 0.1372386\n",
      "\tspeed: 0.0435s/iter; left time: 89.2629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 225 | Train Loss: 0.1364299 Vali Loss: 0.1728351 Test Loss: 0.1883840\n",
      "Validation loss decreased (0.173709 --> 0.172835).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1350793\n",
      "\tspeed: 0.0846s/iter; left time: 162.9420s\n",
      "\titers: 200, epoch: 12 | loss: 0.1347212\n",
      "\tspeed: 0.0438s/iter; left time: 80.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.1356881 Vali Loss: 0.1704149 Test Loss: 0.1869885\n",
      "Validation loss decreased (0.172835 --> 0.170415).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1296153\n",
      "\tspeed: 0.0844s/iter; left time: 143.6059s\n",
      "\titers: 200, epoch: 13 | loss: 0.1363776\n",
      "\tspeed: 0.0440s/iter; left time: 70.4228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.18s\n",
      "Steps: 225 | Train Loss: 0.1351111 Vali Loss: 0.1708766 Test Loss: 0.1873853\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1343696\n",
      "\tspeed: 0.0839s/iter; left time: 123.8017s\n",
      "\titers: 200, epoch: 14 | loss: 0.1337396\n",
      "\tspeed: 0.0438s/iter; left time: 60.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 225 | Train Loss: 0.1344777 Vali Loss: 0.1719516 Test Loss: 0.1874791\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1325170\n",
      "\tspeed: 0.0851s/iter; left time: 106.4908s\n",
      "\titers: 200, epoch: 15 | loss: 0.1335983\n",
      "\tspeed: 0.0438s/iter; left time: 50.4554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 225 | Train Loss: 0.1341017 Vali Loss: 0.1710320 Test Loss: 0.1880632\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1322413\n",
      "\tspeed: 0.0837s/iter; left time: 85.8290s\n",
      "\titers: 200, epoch: 16 | loss: 0.1338864\n",
      "\tspeed: 0.0438s/iter; left time: 40.5175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.14s\n",
      "Steps: 225 | Train Loss: 0.1336613 Vali Loss: 0.1702702 Test Loss: 0.1865164\n",
      "Validation loss decreased (0.170415 --> 0.170270).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1289469\n",
      "\tspeed: 0.0845s/iter; left time: 67.7179s\n",
      "\titers: 200, epoch: 17 | loss: 0.1293781\n",
      "\tspeed: 0.0435s/iter; left time: 30.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.15s\n",
      "Steps: 225 | Train Loss: 0.1332948 Vali Loss: 0.1710327 Test Loss: 0.1860210\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1298641\n",
      "\tspeed: 0.0842s/iter; left time: 48.5265s\n",
      "\titers: 200, epoch: 18 | loss: 0.1333946\n",
      "\tspeed: 0.0437s/iter; left time: 20.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.22s\n",
      "Steps: 225 | Train Loss: 0.1329872 Vali Loss: 0.1686317 Test Loss: 0.1856928\n",
      "Validation loss decreased (0.170270 --> 0.168632).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1298685\n",
      "\tspeed: 0.0854s/iter; left time: 29.9611s\n",
      "\titers: 200, epoch: 19 | loss: 0.1308499\n",
      "\tspeed: 0.0443s/iter; left time: 11.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1327008 Vali Loss: 0.1677450 Test Loss: 0.1855041\n",
      "Validation loss decreased (0.168632 --> 0.167745).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1359190\n",
      "\tspeed: 0.0865s/iter; left time: 10.8936s\n",
      "\titers: 200, epoch: 20 | loss: 0.1336842\n",
      "\tspeed: 0.0440s/iter; left time: 1.1450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1324725 Vali Loss: 0.1683688 Test Loss: 0.1855145\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07601576298475266, rmse:0.2757095694541931, mae:0.18542586266994476, rse:0.9765855073928833\n",
      "Intermediate time for DE and pred_len 168: 00h:08m:23.24s\n",
      "Intermediate time for DE: 00h:22m:10.10s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3052470\n",
      "\tspeed: 0.0544s/iter; left time: 240.4930s\n",
      "\titers: 200, epoch: 1 | loss: 0.2786257\n",
      "\tspeed: 0.0317s/iter; left time: 137.0536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.84s\n",
      "Steps: 226 | Train Loss: 0.3082365 Vali Loss: 0.2932253 Test Loss: 0.3235795\n",
      "Validation loss decreased (inf --> 0.293225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1818769\n",
      "\tspeed: 0.0633s/iter; left time: 265.5665s\n",
      "\titers: 200, epoch: 2 | loss: 0.1436093\n",
      "\tspeed: 0.0317s/iter; left time: 129.6999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 226 | Train Loss: 0.1806575 Vali Loss: 0.1492309 Test Loss: 0.1730072\n",
      "Validation loss decreased (0.293225 --> 0.149231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1303000\n",
      "\tspeed: 0.0634s/iter; left time: 251.5127s\n",
      "\titers: 200, epoch: 3 | loss: 0.1203991\n",
      "\tspeed: 0.0316s/iter; left time: 122.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1303042 Vali Loss: 0.1346049 Test Loss: 0.1573525\n",
      "Validation loss decreased (0.149231 --> 0.134605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1195447\n",
      "\tspeed: 0.0626s/iter; left time: 234.4936s\n",
      "\titers: 200, epoch: 4 | loss: 0.1117187\n",
      "\tspeed: 0.0320s/iter; left time: 116.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.1173304 Vali Loss: 0.1293561 Test Loss: 0.1517283\n",
      "Validation loss decreased (0.134605 --> 0.129356).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1143004\n",
      "\tspeed: 0.0625s/iter; left time: 219.7903s\n",
      "\titers: 200, epoch: 5 | loss: 0.1098080\n",
      "\tspeed: 0.0319s/iter; left time: 109.0075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.1118763 Vali Loss: 0.1260642 Test Loss: 0.1485213\n",
      "Validation loss decreased (0.129356 --> 0.126064).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1071764\n",
      "\tspeed: 0.0633s/iter; left time: 208.3032s\n",
      "\titers: 200, epoch: 6 | loss: 0.1082449\n",
      "\tspeed: 0.0312s/iter; left time: 99.6882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.1088055 Vali Loss: 0.1224470 Test Loss: 0.1460177\n",
      "Validation loss decreased (0.126064 --> 0.122447).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1056527\n",
      "\tspeed: 0.0624s/iter; left time: 191.3864s\n",
      "\titers: 200, epoch: 7 | loss: 0.1081177\n",
      "\tspeed: 0.0318s/iter; left time: 94.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 226 | Train Loss: 0.1065549 Vali Loss: 0.1201922 Test Loss: 0.1424849\n",
      "Validation loss decreased (0.122447 --> 0.120192).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1060951\n",
      "\tspeed: 0.0616s/iter; left time: 174.9956s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055608\n",
      "\tspeed: 0.0316s/iter; left time: 86.5523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 226 | Train Loss: 0.1053487 Vali Loss: 0.1202515 Test Loss: 0.1437510\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1118730\n",
      "\tspeed: 0.0613s/iter; left time: 160.2312s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085973\n",
      "\tspeed: 0.0316s/iter; left time: 79.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1043763 Vali Loss: 0.1190622 Test Loss: 0.1434785\n",
      "Validation loss decreased (0.120192 --> 0.119062).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0998025\n",
      "\tspeed: 0.0630s/iter; left time: 150.3241s\n",
      "\titers: 200, epoch: 10 | loss: 0.1024703\n",
      "\tspeed: 0.0323s/iter; left time: 73.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 226 | Train Loss: 0.1035024 Vali Loss: 0.1189299 Test Loss: 0.1420532\n",
      "Validation loss decreased (0.119062 --> 0.118930).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1011903\n",
      "\tspeed: 0.0616s/iter; left time: 133.1499s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058386\n",
      "\tspeed: 0.0316s/iter; left time: 65.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.1026822 Vali Loss: 0.1191851 Test Loss: 0.1420890\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1054835\n",
      "\tspeed: 0.0618s/iter; left time: 119.6665s\n",
      "\titers: 200, epoch: 12 | loss: 0.1047837\n",
      "\tspeed: 0.0318s/iter; left time: 58.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1020057 Vali Loss: 0.1187144 Test Loss: 0.1415418\n",
      "Validation loss decreased (0.118930 --> 0.118714).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1015236\n",
      "\tspeed: 0.0623s/iter; left time: 106.5003s\n",
      "\titers: 200, epoch: 13 | loss: 0.1070624\n",
      "\tspeed: 0.0320s/iter; left time: 51.4479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.1015182 Vali Loss: 0.1184762 Test Loss: 0.1421930\n",
      "Validation loss decreased (0.118714 --> 0.118476).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007310\n",
      "\tspeed: 0.0616s/iter; left time: 91.3613s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017445\n",
      "\tspeed: 0.0317s/iter; left time: 43.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1011540 Vali Loss: 0.1174799 Test Loss: 0.1408812\n",
      "Validation loss decreased (0.118476 --> 0.117480).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0967436\n",
      "\tspeed: 0.0639s/iter; left time: 80.2650s\n",
      "\titers: 200, epoch: 15 | loss: 0.1004322\n",
      "\tspeed: 0.0314s/iter; left time: 36.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.55s\n",
      "Steps: 226 | Train Loss: 0.1007919 Vali Loss: 0.1199909 Test Loss: 0.1417450\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1001772\n",
      "\tspeed: 0.0630s/iter; left time: 64.9671s\n",
      "\titers: 200, epoch: 16 | loss: 0.1039093\n",
      "\tspeed: 0.0334s/iter; left time: 31.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 226 | Train Loss: 0.1004126 Vali Loss: 0.1175528 Test Loss: 0.1404042\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1055303\n",
      "\tspeed: 0.0631s/iter; left time: 50.7844s\n",
      "\titers: 200, epoch: 17 | loss: 0.1005780\n",
      "\tspeed: 0.0321s/iter; left time: 22.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 226 | Train Loss: 0.1002009 Vali Loss: 0.1178656 Test Loss: 0.1406719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1021403\n",
      "\tspeed: 0.0612s/iter; left time: 35.4144s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003237\n",
      "\tspeed: 0.0313s/iter; left time: 15.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0998990 Vali Loss: 0.1176011 Test Loss: 0.1396772\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1011629\n",
      "\tspeed: 0.0608s/iter; left time: 21.4738s\n",
      "\titers: 200, epoch: 19 | loss: 0.1001325\n",
      "\tspeed: 0.0311s/iter; left time: 7.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0998035 Vali Loss: 0.1194680 Test Loss: 0.1420907\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04666012525558472, rmse:0.21600954234600067, mae:0.14098356664180756, rse:0.7451717257499695\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2743395\n",
      "\tspeed: 0.0339s/iter; left time: 149.7658s\n",
      "\titers: 200, epoch: 1 | loss: 0.2511843\n",
      "\tspeed: 0.0314s/iter; left time: 135.8432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.2746824 Vali Loss: 0.2620354 Test Loss: 0.2982498\n",
      "Validation loss decreased (inf --> 0.262035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1670466\n",
      "\tspeed: 0.0649s/iter; left time: 272.2305s\n",
      "\titers: 200, epoch: 2 | loss: 0.1424812\n",
      "\tspeed: 0.0313s/iter; left time: 128.0746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1725194 Vali Loss: 0.1417937 Test Loss: 0.1693854\n",
      "Validation loss decreased (0.262035 --> 0.141794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1252635\n",
      "\tspeed: 0.0608s/iter; left time: 241.3566s\n",
      "\titers: 200, epoch: 3 | loss: 0.1165617\n",
      "\tspeed: 0.0310s/iter; left time: 119.9599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.1240350 Vali Loss: 0.1331099 Test Loss: 0.1558182\n",
      "Validation loss decreased (0.141794 --> 0.133110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1108342\n",
      "\tspeed: 0.0611s/iter; left time: 228.6501s\n",
      "\titers: 200, epoch: 4 | loss: 0.1109259\n",
      "\tspeed: 0.0316s/iter; left time: 115.2301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 226 | Train Loss: 0.1139601 Vali Loss: 0.1245188 Test Loss: 0.1488642\n",
      "Validation loss decreased (0.133110 --> 0.124519).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1070710\n",
      "\tspeed: 0.0606s/iter; left time: 213.1148s\n",
      "\titers: 200, epoch: 5 | loss: 0.1117656\n",
      "\tspeed: 0.0310s/iter; left time: 106.0935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.1099577 Vali Loss: 0.1216694 Test Loss: 0.1455768\n",
      "Validation loss decreased (0.124519 --> 0.121669).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1173352\n",
      "\tspeed: 0.0605s/iter; left time: 199.2133s\n",
      "\titers: 200, epoch: 6 | loss: 0.1099106\n",
      "\tspeed: 0.0314s/iter; left time: 100.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.1069922 Vali Loss: 0.1226822 Test Loss: 0.1464075\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1067865\n",
      "\tspeed: 0.0597s/iter; left time: 183.0371s\n",
      "\titers: 200, epoch: 7 | loss: 0.1036342\n",
      "\tspeed: 0.0310s/iter; left time: 91.9236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 226 | Train Loss: 0.1058079 Vali Loss: 0.1249714 Test Loss: 0.1484469\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1115267\n",
      "\tspeed: 0.0608s/iter; left time: 172.6453s\n",
      "\titers: 200, epoch: 8 | loss: 0.1070663\n",
      "\tspeed: 0.0313s/iter; left time: 85.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1041932 Vali Loss: 0.1189855 Test Loss: 0.1423825\n",
      "Validation loss decreased (0.121669 --> 0.118985).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0992777\n",
      "\tspeed: 0.0636s/iter; left time: 166.2778s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018656\n",
      "\tspeed: 0.0310s/iter; left time: 77.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.1033564 Vali Loss: 0.1199200 Test Loss: 0.1432356\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1024193\n",
      "\tspeed: 0.0605s/iter; left time: 144.3388s\n",
      "\titers: 200, epoch: 10 | loss: 0.0985420\n",
      "\tspeed: 0.0313s/iter; left time: 71.6913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.1025634 Vali Loss: 0.1195223 Test Loss: 0.1424470\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1021113\n",
      "\tspeed: 0.0608s/iter; left time: 131.4436s\n",
      "\titers: 200, epoch: 11 | loss: 0.0990841\n",
      "\tspeed: 0.0313s/iter; left time: 64.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.1017614 Vali Loss: 0.1187477 Test Loss: 0.1419844\n",
      "Validation loss decreased (0.118985 --> 0.118748).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1004894\n",
      "\tspeed: 0.0621s/iter; left time: 120.2551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0991781\n",
      "\tspeed: 0.0311s/iter; left time: 57.0634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1013021 Vali Loss: 0.1173334 Test Loss: 0.1401358\n",
      "Validation loss decreased (0.118748 --> 0.117333).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1001117\n",
      "\tspeed: 0.0618s/iter; left time: 105.6860s\n",
      "\titers: 200, epoch: 13 | loss: 0.1046949\n",
      "\tspeed: 0.0312s/iter; left time: 50.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.1008259 Vali Loss: 0.1204027 Test Loss: 0.1424965\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1042575\n",
      "\tspeed: 0.0602s/iter; left time: 89.3154s\n",
      "\titers: 200, epoch: 14 | loss: 0.0992214\n",
      "\tspeed: 0.0313s/iter; left time: 43.2892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1005984 Vali Loss: 0.1190909 Test Loss: 0.1414720\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1016203\n",
      "\tspeed: 0.0616s/iter; left time: 77.4178s\n",
      "\titers: 200, epoch: 15 | loss: 0.1008491\n",
      "\tspeed: 0.0314s/iter; left time: 36.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.1002266 Vali Loss: 0.1194321 Test Loss: 0.1417282\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1030203\n",
      "\tspeed: 0.0607s/iter; left time: 62.6246s\n",
      "\titers: 200, epoch: 16 | loss: 0.1013915\n",
      "\tspeed: 0.0310s/iter; left time: 28.8746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0999705 Vali Loss: 0.1175912 Test Loss: 0.1402146\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0974214\n",
      "\tspeed: 0.0603s/iter; left time: 48.5484s\n",
      "\titers: 200, epoch: 17 | loss: 0.1019093\n",
      "\tspeed: 0.0315s/iter; left time: 22.2190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0995845 Vali Loss: 0.1173045 Test Loss: 0.1409251\n",
      "Validation loss decreased (0.117333 --> 0.117305).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0992472\n",
      "\tspeed: 0.0612s/iter; left time: 35.4347s\n",
      "\titers: 200, epoch: 18 | loss: 0.1003656\n",
      "\tspeed: 0.0311s/iter; left time: 14.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.36s\n",
      "Steps: 226 | Train Loss: 0.0994861 Vali Loss: 0.1159897 Test Loss: 0.1391787\n",
      "Validation loss decreased (0.117305 --> 0.115990).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0981983\n",
      "\tspeed: 0.0609s/iter; left time: 21.5052s\n",
      "\titers: 200, epoch: 19 | loss: 0.0973605\n",
      "\tspeed: 0.0314s/iter; left time: 7.9316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.0993182 Vali Loss: 0.1179150 Test Loss: 0.1404083\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1004087\n",
      "\tspeed: 0.0601s/iter; left time: 7.6362s\n",
      "\titers: 200, epoch: 20 | loss: 0.0979343\n",
      "\tspeed: 0.0313s/iter; left time: 0.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0991517 Vali Loss: 0.1169054 Test Loss: 0.1391831\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.046183161437511444, rmse:0.21490268409252167, mae:0.13910767436027527, rse:0.7413533329963684\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:13.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3122503\n",
      "\tspeed: 0.0612s/iter; left time: 270.6772s\n",
      "\titers: 200, epoch: 1 | loss: 0.2786227\n",
      "\tspeed: 0.0379s/iter; left time: 163.9432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.21s\n",
      "Steps: 226 | Train Loss: 0.3028378 Vali Loss: 0.2722572 Test Loss: 0.3054372\n",
      "Validation loss decreased (inf --> 0.272257).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1878467\n",
      "\tspeed: 0.0745s/iter; left time: 312.5051s\n",
      "\titers: 200, epoch: 2 | loss: 0.1624926\n",
      "\tspeed: 0.0378s/iter; left time: 154.7583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.87s\n",
      "Steps: 226 | Train Loss: 0.1890555 Vali Loss: 0.1743498 Test Loss: 0.2127410\n",
      "Validation loss decreased (0.272257 --> 0.174350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1489910\n",
      "\tspeed: 0.0741s/iter; left time: 294.1894s\n",
      "\titers: 200, epoch: 3 | loss: 0.1444040\n",
      "\tspeed: 0.0378s/iter; left time: 146.3783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 226 | Train Loss: 0.1478007 Vali Loss: 0.1658378 Test Loss: 0.2007975\n",
      "Validation loss decreased (0.174350 --> 0.165838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1397662\n",
      "\tspeed: 0.0757s/iter; left time: 283.3947s\n",
      "\titers: 200, epoch: 4 | loss: 0.1425046\n",
      "\tspeed: 0.0376s/iter; left time: 136.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 226 | Train Loss: 0.1402265 Vali Loss: 0.1572729 Test Loss: 0.1911708\n",
      "Validation loss decreased (0.165838 --> 0.157273).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1323869\n",
      "\tspeed: 0.0748s/iter; left time: 262.9039s\n",
      "\titers: 200, epoch: 5 | loss: 0.1327451\n",
      "\tspeed: 0.0379s/iter; left time: 129.3985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.96s\n",
      "Steps: 226 | Train Loss: 0.1339098 Vali Loss: 0.1553418 Test Loss: 0.1904022\n",
      "Validation loss decreased (0.157273 --> 0.155342).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1279119\n",
      "\tspeed: 0.0753s/iter; left time: 247.8807s\n",
      "\titers: 200, epoch: 6 | loss: 0.1284798\n",
      "\tspeed: 0.0378s/iter; left time: 120.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 226 | Train Loss: 0.1308580 Vali Loss: 0.1556955 Test Loss: 0.1899207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1261943\n",
      "\tspeed: 0.0732s/iter; left time: 224.4927s\n",
      "\titers: 200, epoch: 7 | loss: 0.1254131\n",
      "\tspeed: 0.0378s/iter; left time: 111.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 226 | Train Loss: 0.1293241 Vali Loss: 0.1573925 Test Loss: 0.1924611\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1277766\n",
      "\tspeed: 0.0737s/iter; left time: 209.0981s\n",
      "\titers: 200, epoch: 8 | loss: 0.1280790\n",
      "\tspeed: 0.0376s/iter; left time: 103.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.86s\n",
      "Steps: 226 | Train Loss: 0.1280730 Vali Loss: 0.1603580 Test Loss: 0.1923739\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1260670\n",
      "\tspeed: 0.0733s/iter; left time: 191.4267s\n",
      "\titers: 200, epoch: 9 | loss: 0.1276200\n",
      "\tspeed: 0.0376s/iter; left time: 94.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 226 | Train Loss: 0.1271885 Vali Loss: 0.1605011 Test Loss: 0.1934098\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1224042\n",
      "\tspeed: 0.0724s/iter; left time: 172.9110s\n",
      "\titers: 200, epoch: 10 | loss: 0.1248131\n",
      "\tspeed: 0.0382s/iter; left time: 87.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.86s\n",
      "Steps: 226 | Train Loss: 0.1263181 Vali Loss: 0.1569900 Test Loss: 0.1890523\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07604854553937912, rmse:0.2757689952850342, mae:0.19032683968544006, rse:0.9536476135253906\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2967875\n",
      "\tspeed: 0.0403s/iter; left time: 178.2375s\n",
      "\titers: 200, epoch: 1 | loss: 0.2793468\n",
      "\tspeed: 0.0383s/iter; left time: 165.3491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 226 | Train Loss: 0.2941906 Vali Loss: 0.2847565 Test Loss: 0.3206187\n",
      "Validation loss decreased (inf --> 0.284756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1790935\n",
      "\tspeed: 0.0737s/iter; left time: 309.2111s\n",
      "\titers: 200, epoch: 2 | loss: 0.1566150\n",
      "\tspeed: 0.0374s/iter; left time: 153.0788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 226 | Train Loss: 0.1835298 Vali Loss: 0.1627146 Test Loss: 0.1994986\n",
      "Validation loss decreased (0.284756 --> 0.162715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1442558\n",
      "\tspeed: 0.0779s/iter; left time: 309.3184s\n",
      "\titers: 200, epoch: 3 | loss: 0.1420343\n",
      "\tspeed: 0.0372s/iter; left time: 144.1202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 226 | Train Loss: 0.1451078 Vali Loss: 0.1559297 Test Loss: 0.1919716\n",
      "Validation loss decreased (0.162715 --> 0.155930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1386904\n",
      "\tspeed: 0.0735s/iter; left time: 275.2921s\n",
      "\titers: 200, epoch: 4 | loss: 0.1331836\n",
      "\tspeed: 0.0372s/iter; left time: 135.4067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.1369379 Vali Loss: 0.1558688 Test Loss: 0.1912343\n",
      "Validation loss decreased (0.155930 --> 0.155869).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1345949\n",
      "\tspeed: 0.0748s/iter; left time: 263.1682s\n",
      "\titers: 200, epoch: 5 | loss: 0.1336392\n",
      "\tspeed: 0.0378s/iter; left time: 129.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 226 | Train Loss: 0.1321562 Vali Loss: 0.1584540 Test Loss: 0.1939325\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1324664\n",
      "\tspeed: 0.0724s/iter; left time: 238.2605s\n",
      "\titers: 200, epoch: 6 | loss: 0.1273343\n",
      "\tspeed: 0.0371s/iter; left time: 118.2545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.1298376 Vali Loss: 0.1568653 Test Loss: 0.1902459\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1278613\n",
      "\tspeed: 0.0729s/iter; left time: 223.4033s\n",
      "\titers: 200, epoch: 7 | loss: 0.1228618\n",
      "\tspeed: 0.0374s/iter; left time: 110.7938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 226 | Train Loss: 0.1282284 Vali Loss: 0.1590777 Test Loss: 0.1912397\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1273279\n",
      "\tspeed: 0.0722s/iter; left time: 204.8619s\n",
      "\titers: 200, epoch: 8 | loss: 0.1278992\n",
      "\tspeed: 0.0372s/iter; left time: 101.7950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 226 | Train Loss: 0.1271898 Vali Loss: 0.1546943 Test Loss: 0.1864519\n",
      "Validation loss decreased (0.155869 --> 0.154694).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1252222\n",
      "\tspeed: 0.0747s/iter; left time: 195.2686s\n",
      "\titers: 200, epoch: 9 | loss: 0.1238933\n",
      "\tspeed: 0.0370s/iter; left time: 93.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.1261476 Vali Loss: 0.1555540 Test Loss: 0.1858137\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1250102\n",
      "\tspeed: 0.0746s/iter; left time: 178.1798s\n",
      "\titers: 200, epoch: 10 | loss: 0.1255189\n",
      "\tspeed: 0.0372s/iter; left time: 85.0446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 226 | Train Loss: 0.1254240 Vali Loss: 0.1554132 Test Loss: 0.1855863\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1222246\n",
      "\tspeed: 0.0737s/iter; left time: 159.2406s\n",
      "\titers: 200, epoch: 11 | loss: 0.1282935\n",
      "\tspeed: 0.0371s/iter; left time: 76.4179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.1247227 Vali Loss: 0.1583612 Test Loss: 0.1877843\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1229611\n",
      "\tspeed: 0.0752s/iter; left time: 145.5106s\n",
      "\titers: 200, epoch: 12 | loss: 0.1233430\n",
      "\tspeed: 0.0369s/iter; left time: 67.7959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 226 | Train Loss: 0.1241673 Vali Loss: 0.1541651 Test Loss: 0.1835623\n",
      "Validation loss decreased (0.154694 --> 0.154165).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1238462\n",
      "\tspeed: 0.0763s/iter; left time: 130.3231s\n",
      "\titers: 200, epoch: 13 | loss: 0.1241414\n",
      "\tspeed: 0.0368s/iter; left time: 59.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 226 | Train Loss: 0.1236021 Vali Loss: 0.1555400 Test Loss: 0.1854006\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1269714\n",
      "\tspeed: 0.0746s/iter; left time: 110.5692s\n",
      "\titers: 200, epoch: 14 | loss: 0.1243913\n",
      "\tspeed: 0.0375s/iter; left time: 51.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 226 | Train Loss: 0.1233211 Vali Loss: 0.1510371 Test Loss: 0.1801276\n",
      "Validation loss decreased (0.154165 --> 0.151037).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1192059\n",
      "\tspeed: 0.0765s/iter; left time: 96.2221s\n",
      "\titers: 200, epoch: 15 | loss: 0.1222001\n",
      "\tspeed: 0.0373s/iter; left time: 43.1667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.83s\n",
      "Steps: 226 | Train Loss: 0.1228849 Vali Loss: 0.1543644 Test Loss: 0.1824075\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1208979\n",
      "\tspeed: 0.0739s/iter; left time: 76.2087s\n",
      "\titers: 200, epoch: 16 | loss: 0.1215230\n",
      "\tspeed: 0.0373s/iter; left time: 34.7435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 226 | Train Loss: 0.1224982 Vali Loss: 0.1542555 Test Loss: 0.1822228\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1189411\n",
      "\tspeed: 0.0750s/iter; left time: 60.3765s\n",
      "\titers: 200, epoch: 17 | loss: 0.1189278\n",
      "\tspeed: 0.0372s/iter; left time: 26.2298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 226 | Train Loss: 0.1223383 Vali Loss: 0.1547809 Test Loss: 0.1831286\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1215858\n",
      "\tspeed: 0.0748s/iter; left time: 43.2892s\n",
      "\titers: 200, epoch: 18 | loss: 0.1225885\n",
      "\tspeed: 0.0374s/iter; left time: 17.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 226 | Train Loss: 0.1220316 Vali Loss: 0.1531128 Test Loss: 0.1813350\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1249099\n",
      "\tspeed: 0.0751s/iter; left time: 26.5198s\n",
      "\titers: 200, epoch: 19 | loss: 0.1186845\n",
      "\tspeed: 0.0371s/iter; left time: 9.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 226 | Train Loss: 0.1218169 Vali Loss: 0.1515624 Test Loss: 0.1810340\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06876428425312042, rmse:0.26222944259643555, mae:0.17995072901248932, rse:0.9068259596824646\n",
      "Intermediate time for GB and pred_len 96: 00h:05m:37.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3045457\n",
      "\tspeed: 0.0685s/iter; left time: 301.4568s\n",
      "\titers: 200, epoch: 1 | loss: 0.2772324\n",
      "\tspeed: 0.0460s/iter; left time: 197.9467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.96s\n",
      "Steps: 225 | Train Loss: 0.3049603 Vali Loss: 0.2762563 Test Loss: 0.3078917\n",
      "Validation loss decreased (inf --> 0.276256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1895686\n",
      "\tspeed: 0.0879s/iter; left time: 367.2436s\n",
      "\titers: 200, epoch: 2 | loss: 0.1591524\n",
      "\tspeed: 0.0457s/iter; left time: 186.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 225 | Train Loss: 0.1913395 Vali Loss: 0.1821304 Test Loss: 0.2236919\n",
      "Validation loss decreased (0.276256 --> 0.182130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1524724\n",
      "\tspeed: 0.0890s/iter; left time: 351.5122s\n",
      "\titers: 200, epoch: 3 | loss: 0.1478010\n",
      "\tspeed: 0.0456s/iter; left time: 175.7696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 225 | Train Loss: 0.1508172 Vali Loss: 0.1728749 Test Loss: 0.2083533\n",
      "Validation loss decreased (0.182130 --> 0.172875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1433894\n",
      "\tspeed: 0.0873s/iter; left time: 325.2573s\n",
      "\titers: 200, epoch: 4 | loss: 0.1467440\n",
      "\tspeed: 0.0455s/iter; left time: 165.0404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1443794 Vali Loss: 0.1681560 Test Loss: 0.2038760\n",
      "Validation loss decreased (0.172875 --> 0.168156).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1415890\n",
      "\tspeed: 0.0872s/iter; left time: 305.3634s\n",
      "\titers: 200, epoch: 5 | loss: 0.1422882\n",
      "\tspeed: 0.0455s/iter; left time: 154.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 225 | Train Loss: 0.1407754 Vali Loss: 0.1684659 Test Loss: 0.2055315\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1312543\n",
      "\tspeed: 0.0874s/iter; left time: 286.3550s\n",
      "\titers: 200, epoch: 6 | loss: 0.1364732\n",
      "\tspeed: 0.0456s/iter; left time: 144.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.63s\n",
      "Steps: 225 | Train Loss: 0.1378935 Vali Loss: 0.1719940 Test Loss: 0.2084472\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1365812\n",
      "\tspeed: 0.0874s/iter; left time: 266.6733s\n",
      "\titers: 200, epoch: 7 | loss: 0.1334323\n",
      "\tspeed: 0.0452s/iter; left time: 133.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 225 | Train Loss: 0.1359734 Vali Loss: 0.1708600 Test Loss: 0.2086513\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1346727\n",
      "\tspeed: 0.0864s/iter; left time: 244.1489s\n",
      "\titers: 200, epoch: 8 | loss: 0.1345412\n",
      "\tspeed: 0.0452s/iter; left time: 123.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1346326 Vali Loss: 0.1710923 Test Loss: 0.2078574\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1353575\n",
      "\tspeed: 0.0872s/iter; left time: 226.7979s\n",
      "\titers: 200, epoch: 9 | loss: 0.1356600\n",
      "\tspeed: 0.0451s/iter; left time: 112.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.44s\n",
      "Steps: 225 | Train Loss: 0.1334810 Vali Loss: 0.1714829 Test Loss: 0.2032231\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.08658408373594284, rmse:0.2942517399787903, mae:0.20382244884967804, rse:1.020213007926941\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3057109\n",
      "\tspeed: 0.0485s/iter; left time: 213.6178s\n",
      "\titers: 200, epoch: 1 | loss: 0.2809233\n",
      "\tspeed: 0.0452s/iter; left time: 194.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.3009017 Vali Loss: 0.2841057 Test Loss: 0.3148355\n",
      "Validation loss decreased (inf --> 0.284106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1767915\n",
      "\tspeed: 0.0875s/iter; left time: 365.2664s\n",
      "\titers: 200, epoch: 2 | loss: 0.1587376\n",
      "\tspeed: 0.0454s/iter; left time: 185.2433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1855510 Vali Loss: 0.1808179 Test Loss: 0.2228326\n",
      "Validation loss decreased (0.284106 --> 0.180818).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1555925\n",
      "\tspeed: 0.0875s/iter; left time: 345.6878s\n",
      "\titers: 200, epoch: 3 | loss: 0.1498047\n",
      "\tspeed: 0.0452s/iter; left time: 173.9632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 225 | Train Loss: 0.1499404 Vali Loss: 0.1729935 Test Loss: 0.2104565\n",
      "Validation loss decreased (0.180818 --> 0.172993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1447900\n",
      "\tspeed: 0.0903s/iter; left time: 336.3636s\n",
      "\titers: 200, epoch: 4 | loss: 0.1371687\n",
      "\tspeed: 0.0455s/iter; left time: 165.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.81s\n",
      "Steps: 225 | Train Loss: 0.1434755 Vali Loss: 0.1667024 Test Loss: 0.2044952\n",
      "Validation loss decreased (0.172993 --> 0.166702).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1413133\n",
      "\tspeed: 0.0881s/iter; left time: 308.4787s\n",
      "\titers: 200, epoch: 5 | loss: 0.1373095\n",
      "\tspeed: 0.0447s/iter; left time: 152.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.46s\n",
      "Steps: 225 | Train Loss: 0.1388973 Vali Loss: 0.1745550 Test Loss: 0.2114939\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1334917\n",
      "\tspeed: 0.0868s/iter; left time: 284.3043s\n",
      "\titers: 200, epoch: 6 | loss: 0.1393016\n",
      "\tspeed: 0.0454s/iter; left time: 144.0606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1360940 Vali Loss: 0.1668453 Test Loss: 0.2038103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1315885\n",
      "\tspeed: 0.0875s/iter; left time: 266.9714s\n",
      "\titers: 200, epoch: 7 | loss: 0.1353391\n",
      "\tspeed: 0.0452s/iter; left time: 133.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 225 | Train Loss: 0.1341556 Vali Loss: 0.1670887 Test Loss: 0.2068098\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1328250\n",
      "\tspeed: 0.0862s/iter; left time: 243.6403s\n",
      "\titers: 200, epoch: 8 | loss: 0.1325110\n",
      "\tspeed: 0.0453s/iter; left time: 123.5809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1328915 Vali Loss: 0.1681926 Test Loss: 0.2034640\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1330549\n",
      "\tspeed: 0.0862s/iter; left time: 224.2499s\n",
      "\titers: 200, epoch: 9 | loss: 0.1319667\n",
      "\tspeed: 0.0454s/iter; left time: 113.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1317044 Vali Loss: 0.1644522 Test Loss: 0.1996256\n",
      "Validation loss decreased (0.166702 --> 0.164452).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1290483\n",
      "\tspeed: 0.0879s/iter; left time: 208.9269s\n",
      "\titers: 200, epoch: 10 | loss: 0.1314699\n",
      "\tspeed: 0.0453s/iter; left time: 103.1097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.59s\n",
      "Steps: 225 | Train Loss: 0.1307263 Vali Loss: 0.1622051 Test Loss: 0.1994760\n",
      "Validation loss decreased (0.164452 --> 0.162205).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1288148\n",
      "\tspeed: 0.0876s/iter; left time: 188.3305s\n",
      "\titers: 200, epoch: 11 | loss: 0.1299076\n",
      "\tspeed: 0.0456s/iter; left time: 93.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1300119 Vali Loss: 0.1644092 Test Loss: 0.1961632\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1296844\n",
      "\tspeed: 0.0866s/iter; left time: 166.7818s\n",
      "\titers: 200, epoch: 12 | loss: 0.1264157\n",
      "\tspeed: 0.0453s/iter; left time: 82.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 225 | Train Loss: 0.1293405 Vali Loss: 0.1614091 Test Loss: 0.1961861\n",
      "Validation loss decreased (0.162205 --> 0.161409).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1288653\n",
      "\tspeed: 0.0882s/iter; left time: 150.0470s\n",
      "\titers: 200, epoch: 13 | loss: 0.1252534\n",
      "\tspeed: 0.0455s/iter; left time: 72.8396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 225 | Train Loss: 0.1289139 Vali Loss: 0.1603012 Test Loss: 0.1952427\n",
      "Validation loss decreased (0.161409 --> 0.160301).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1279578\n",
      "\tspeed: 0.0876s/iter; left time: 129.3087s\n",
      "\titers: 200, epoch: 14 | loss: 0.1259118\n",
      "\tspeed: 0.0457s/iter; left time: 62.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.1284974 Vali Loss: 0.1588617 Test Loss: 0.1937819\n",
      "Validation loss decreased (0.160301 --> 0.158862).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1278425\n",
      "\tspeed: 0.0880s/iter; left time: 110.0832s\n",
      "\titers: 200, epoch: 15 | loss: 0.1309463\n",
      "\tspeed: 0.0455s/iter; left time: 52.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1281162 Vali Loss: 0.1571324 Test Loss: 0.1927726\n",
      "Validation loss decreased (0.158862 --> 0.157132).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1290028\n",
      "\tspeed: 0.0875s/iter; left time: 89.7752s\n",
      "\titers: 200, epoch: 16 | loss: 0.1273433\n",
      "\tspeed: 0.0451s/iter; left time: 41.7675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1278387 Vali Loss: 0.1588683 Test Loss: 0.1939960\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1284463\n",
      "\tspeed: 0.0870s/iter; left time: 69.6964s\n",
      "\titers: 200, epoch: 17 | loss: 0.1249081\n",
      "\tspeed: 0.0451s/iter; left time: 31.6484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 225 | Train Loss: 0.1275161 Vali Loss: 0.1560205 Test Loss: 0.1930194\n",
      "Validation loss decreased (0.157132 --> 0.156021).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1312951\n",
      "\tspeed: 0.0882s/iter; left time: 50.8056s\n",
      "\titers: 200, epoch: 18 | loss: 0.1292962\n",
      "\tspeed: 0.0454s/iter; left time: 21.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 225 | Train Loss: 0.1272280 Vali Loss: 0.1577847 Test Loss: 0.1935252\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1284195\n",
      "\tspeed: 0.0868s/iter; left time: 30.4629s\n",
      "\titers: 200, epoch: 19 | loss: 0.1300386\n",
      "\tspeed: 0.0458s/iter; left time: 11.4943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 225 | Train Loss: 0.1269443 Vali Loss: 0.1564681 Test Loss: 0.1928374\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1284035\n",
      "\tspeed: 0.0868s/iter; left time: 10.9421s\n",
      "\titers: 200, epoch: 20 | loss: 0.1274438\n",
      "\tspeed: 0.0460s/iter; left time: 1.1947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1268262 Vali Loss: 0.1561070 Test Loss: 0.1927140\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07559245824813843, rmse:0.2749408185482025, mae:0.19306747615337372, rse:0.953259289264679\n",
      "Intermediate time for GB and pred_len 168: 00h:06m:39.35s\n",
      "Intermediate time for GB: 00h:18m:30.32s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3288556\n",
      "\tspeed: 0.0553s/iter; left time: 244.4174s\n",
      "\titers: 200, epoch: 1 | loss: 0.3065537\n",
      "\tspeed: 0.0319s/iter; left time: 137.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 226 | Train Loss: 0.3337293 Vali Loss: 0.3080382 Test Loss: 0.3452307\n",
      "Validation loss decreased (inf --> 0.308038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2068300\n",
      "\tspeed: 0.0617s/iter; left time: 258.9613s\n",
      "\titers: 200, epoch: 2 | loss: 0.1334518\n",
      "\tspeed: 0.0305s/iter; left time: 124.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.19s\n",
      "Steps: 226 | Train Loss: 0.1962749 Vali Loss: 0.1087909 Test Loss: 0.1324519\n",
      "Validation loss decreased (0.308038 --> 0.108791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1099497\n",
      "\tspeed: 0.0621s/iter; left time: 246.5181s\n",
      "\titers: 200, epoch: 3 | loss: 0.1061416\n",
      "\tspeed: 0.0310s/iter; left time: 119.9416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.1127756 Vali Loss: 0.0913226 Test Loss: 0.1122550\n",
      "Validation loss decreased (0.108791 --> 0.091323).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1001455\n",
      "\tspeed: 0.0611s/iter; left time: 228.8455s\n",
      "\titers: 200, epoch: 4 | loss: 0.0904689\n",
      "\tspeed: 0.0312s/iter; left time: 113.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.0968682 Vali Loss: 0.0867076 Test Loss: 0.1055801\n",
      "Validation loss decreased (0.091323 --> 0.086708).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0905827\n",
      "\tspeed: 0.0618s/iter; left time: 217.3173s\n",
      "\titers: 200, epoch: 5 | loss: 0.0895412\n",
      "\tspeed: 0.0316s/iter; left time: 107.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.0895420 Vali Loss: 0.0814439 Test Loss: 0.1022313\n",
      "Validation loss decreased (0.086708 --> 0.081444).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0883251\n",
      "\tspeed: 0.0612s/iter; left time: 201.4762s\n",
      "\titers: 200, epoch: 6 | loss: 0.0833686\n",
      "\tspeed: 0.0303s/iter; left time: 96.7474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0850954 Vali Loss: 0.0817694 Test Loss: 0.1018593\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812765\n",
      "\tspeed: 0.0603s/iter; left time: 184.7519s\n",
      "\titers: 200, epoch: 7 | loss: 0.0823280\n",
      "\tspeed: 0.0309s/iter; left time: 91.7099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.0818563 Vali Loss: 0.0792530 Test Loss: 0.0987220\n",
      "Validation loss decreased (0.081444 --> 0.079253).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0798216\n",
      "\tspeed: 0.0620s/iter; left time: 175.8814s\n",
      "\titers: 200, epoch: 8 | loss: 0.0767640\n",
      "\tspeed: 0.0307s/iter; left time: 83.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.0796005 Vali Loss: 0.0763351 Test Loss: 0.0981332\n",
      "Validation loss decreased (0.079253 --> 0.076335).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0777429\n",
      "\tspeed: 0.0617s/iter; left time: 161.2201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0769622\n",
      "\tspeed: 0.0314s/iter; left time: 78.9311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.0779616 Vali Loss: 0.0763961 Test Loss: 0.0988198\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0797415\n",
      "\tspeed: 0.0610s/iter; left time: 145.6110s\n",
      "\titers: 200, epoch: 10 | loss: 0.0737450\n",
      "\tspeed: 0.0310s/iter; left time: 71.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0765696 Vali Loss: 0.0744575 Test Loss: 0.0969600\n",
      "Validation loss decreased (0.076335 --> 0.074458).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0740012\n",
      "\tspeed: 0.0603s/iter; left time: 130.3719s\n",
      "\titers: 200, epoch: 11 | loss: 0.0709251\n",
      "\tspeed: 0.0302s/iter; left time: 62.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.13s\n",
      "Steps: 226 | Train Loss: 0.0754526 Vali Loss: 0.0741963 Test Loss: 0.0961700\n",
      "Validation loss decreased (0.074458 --> 0.074196).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0703878\n",
      "\tspeed: 0.0609s/iter; left time: 117.8276s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739954\n",
      "\tspeed: 0.0306s/iter; left time: 56.2222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0746230 Vali Loss: 0.0728036 Test Loss: 0.0957944\n",
      "Validation loss decreased (0.074196 --> 0.072804).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0727053\n",
      "\tspeed: 0.0612s/iter; left time: 104.6025s\n",
      "\titers: 200, epoch: 13 | loss: 0.0733850\n",
      "\tspeed: 0.0302s/iter; left time: 48.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 226 | Train Loss: 0.0736386 Vali Loss: 0.0719627 Test Loss: 0.0937227\n",
      "Validation loss decreased (0.072804 --> 0.071963).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0754165\n",
      "\tspeed: 0.0624s/iter; left time: 92.5175s\n",
      "\titers: 200, epoch: 14 | loss: 0.0714374\n",
      "\tspeed: 0.0314s/iter; left time: 43.4014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.0730871 Vali Loss: 0.0718282 Test Loss: 0.0956412\n",
      "Validation loss decreased (0.071963 --> 0.071828).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0748117\n",
      "\tspeed: 0.0641s/iter; left time: 80.5180s\n",
      "\titers: 200, epoch: 15 | loss: 0.0722148\n",
      "\tspeed: 0.0320s/iter; left time: 37.0346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 226 | Train Loss: 0.0724779 Vali Loss: 0.0703104 Test Loss: 0.0933110\n",
      "Validation loss decreased (0.071828 --> 0.070310).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723853\n",
      "\tspeed: 0.0621s/iter; left time: 64.0742s\n",
      "\titers: 200, epoch: 16 | loss: 0.0750340\n",
      "\tspeed: 0.0316s/iter; left time: 29.4192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.0718899 Vali Loss: 0.0692794 Test Loss: 0.0935927\n",
      "Validation loss decreased (0.070310 --> 0.069279).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0691597\n",
      "\tspeed: 0.0620s/iter; left time: 49.9483s\n",
      "\titers: 200, epoch: 17 | loss: 0.0706336\n",
      "\tspeed: 0.0304s/iter; left time: 21.4640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0714493 Vali Loss: 0.0695147 Test Loss: 0.0935906\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0741498\n",
      "\tspeed: 0.0605s/iter; left time: 35.0475s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706890\n",
      "\tspeed: 0.0312s/iter; left time: 14.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0710591 Vali Loss: 0.0688513 Test Loss: 0.0921055\n",
      "Validation loss decreased (0.069279 --> 0.068851).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694923\n",
      "\tspeed: 0.0622s/iter; left time: 21.9665s\n",
      "\titers: 200, epoch: 19 | loss: 0.0706423\n",
      "\tspeed: 0.0311s/iter; left time: 7.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.0708529 Vali Loss: 0.0679829 Test Loss: 0.0924609\n",
      "Validation loss decreased (0.068851 --> 0.067983).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0700418\n",
      "\tspeed: 0.0617s/iter; left time: 7.8298s\n",
      "\titers: 200, epoch: 20 | loss: 0.0719122\n",
      "\tspeed: 0.0306s/iter; left time: 0.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.0704128 Vali Loss: 0.0694726 Test Loss: 0.0928017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020894184708595276, rmse:0.1445482075214386, mae:0.09258250892162323, rse:0.4253878891468048\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3461825\n",
      "\tspeed: 0.0352s/iter; left time: 155.8309s\n",
      "\titers: 200, epoch: 1 | loss: 0.3224756\n",
      "\tspeed: 0.0306s/iter; left time: 132.2082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.3402421 Vali Loss: 0.3193687 Test Loss: 0.3562776\n",
      "Validation loss decreased (inf --> 0.319369).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2093117\n",
      "\tspeed: 0.0624s/iter; left time: 261.9015s\n",
      "\titers: 200, epoch: 2 | loss: 0.1696655\n",
      "\tspeed: 0.0316s/iter; left time: 129.4562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.2117658 Vali Loss: 0.1727204 Test Loss: 0.2150232\n",
      "Validation loss decreased (0.319369 --> 0.172720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1503206\n",
      "\tspeed: 0.0613s/iter; left time: 243.1505s\n",
      "\titers: 200, epoch: 3 | loss: 0.1405625\n",
      "\tspeed: 0.0312s/iter; left time: 120.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.1509956 Vali Loss: 0.1514986 Test Loss: 0.1907867\n",
      "Validation loss decreased (0.172720 --> 0.151499).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1305767\n",
      "\tspeed: 0.0596s/iter; left time: 223.1862s\n",
      "\titers: 200, epoch: 4 | loss: 0.1210615\n",
      "\tspeed: 0.0302s/iter; left time: 109.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 226 | Train Loss: 0.1346913 Vali Loss: 0.1356237 Test Loss: 0.1662314\n",
      "Validation loss decreased (0.151499 --> 0.135624).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1218939\n",
      "\tspeed: 0.0608s/iter; left time: 213.8164s\n",
      "\titers: 200, epoch: 5 | loss: 0.1197917\n",
      "\tspeed: 0.0301s/iter; left time: 102.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.1213222 Vali Loss: 0.1259287 Test Loss: 0.1584914\n",
      "Validation loss decreased (0.135624 --> 0.125929).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0911965\n",
      "\tspeed: 0.0622s/iter; left time: 204.7147s\n",
      "\titers: 200, epoch: 6 | loss: 0.0893026\n",
      "\tspeed: 0.0317s/iter; left time: 101.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.0961181 Vali Loss: 0.0811345 Test Loss: 0.0970692\n",
      "Validation loss decreased (0.125929 --> 0.081134).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0836223\n",
      "\tspeed: 0.0601s/iter; left time: 184.3566s\n",
      "\titers: 200, epoch: 7 | loss: 0.0808177\n",
      "\tspeed: 0.0302s/iter; left time: 89.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 226 | Train Loss: 0.0832876 Vali Loss: 0.0791732 Test Loss: 0.0963151\n",
      "Validation loss decreased (0.081134 --> 0.079173).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0824990\n",
      "\tspeed: 0.0602s/iter; left time: 170.9316s\n",
      "\titers: 200, epoch: 8 | loss: 0.0817892\n",
      "\tspeed: 0.0303s/iter; left time: 83.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 226 | Train Loss: 0.0801158 Vali Loss: 0.0756623 Test Loss: 0.0955786\n",
      "Validation loss decreased (0.079173 --> 0.075662).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0789208\n",
      "\tspeed: 0.0609s/iter; left time: 159.0872s\n",
      "\titers: 200, epoch: 9 | loss: 0.0781618\n",
      "\tspeed: 0.0309s/iter; left time: 77.5415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0778129 Vali Loss: 0.0750450 Test Loss: 0.0944479\n",
      "Validation loss decreased (0.075662 --> 0.075045).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0789673\n",
      "\tspeed: 0.0611s/iter; left time: 145.7514s\n",
      "\titers: 200, epoch: 10 | loss: 0.0779048\n",
      "\tspeed: 0.0302s/iter; left time: 69.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 226 | Train Loss: 0.0761912 Vali Loss: 0.0734790 Test Loss: 0.0971480\n",
      "Validation loss decreased (0.075045 --> 0.073479).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0750645\n",
      "\tspeed: 0.0616s/iter; left time: 133.2051s\n",
      "\titers: 200, epoch: 11 | loss: 0.0754665\n",
      "\tspeed: 0.0302s/iter; left time: 62.2300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.22s\n",
      "Steps: 226 | Train Loss: 0.0748842 Vali Loss: 0.0725388 Test Loss: 0.0938657\n",
      "Validation loss decreased (0.073479 --> 0.072539).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726297\n",
      "\tspeed: 0.0607s/iter; left time: 117.4325s\n",
      "\titers: 200, epoch: 12 | loss: 0.0736833\n",
      "\tspeed: 0.0309s/iter; left time: 56.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.0736199 Vali Loss: 0.0717365 Test Loss: 0.0933248\n",
      "Validation loss decreased (0.072539 --> 0.071736).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0728721\n",
      "\tspeed: 0.0612s/iter; left time: 104.5875s\n",
      "\titers: 200, epoch: 13 | loss: 0.0734444\n",
      "\tspeed: 0.0303s/iter; left time: 48.7603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 226 | Train Loss: 0.0728005 Vali Loss: 0.0706397 Test Loss: 0.0932539\n",
      "Validation loss decreased (0.071736 --> 0.070640).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0706382\n",
      "\tspeed: 0.0613s/iter; left time: 90.9738s\n",
      "\titers: 200, epoch: 14 | loss: 0.0701969\n",
      "\tspeed: 0.0309s/iter; left time: 42.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 226 | Train Loss: 0.0721958 Vali Loss: 0.0695447 Test Loss: 0.0928179\n",
      "Validation loss decreased (0.070640 --> 0.069545).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0711061\n",
      "\tspeed: 0.0601s/iter; left time: 75.5266s\n",
      "\titers: 200, epoch: 15 | loss: 0.0678796\n",
      "\tspeed: 0.0301s/iter; left time: 34.8193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 226 | Train Loss: 0.0714494 Vali Loss: 0.0694795 Test Loss: 0.0916939\n",
      "Validation loss decreased (0.069545 --> 0.069479).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0715937\n",
      "\tspeed: 0.0603s/iter; left time: 62.1518s\n",
      "\titers: 200, epoch: 16 | loss: 0.0731710\n",
      "\tspeed: 0.0312s/iter; left time: 29.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0709263 Vali Loss: 0.0686449 Test Loss: 0.0922895\n",
      "Validation loss decreased (0.069479 --> 0.068645).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0713256\n",
      "\tspeed: 0.0600s/iter; left time: 48.2682s\n",
      "\titers: 200, epoch: 17 | loss: 0.0699320\n",
      "\tspeed: 0.0303s/iter; left time: 21.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0704890 Vali Loss: 0.0686117 Test Loss: 0.0904800\n",
      "Validation loss decreased (0.068645 --> 0.068612).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0712545\n",
      "\tspeed: 0.0606s/iter; left time: 35.0966s\n",
      "\titers: 200, epoch: 18 | loss: 0.0690277\n",
      "\tspeed: 0.0303s/iter; left time: 14.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.14s\n",
      "Steps: 226 | Train Loss: 0.0700652 Vali Loss: 0.0676136 Test Loss: 0.0911129\n",
      "Validation loss decreased (0.068612 --> 0.067614).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0682778\n",
      "\tspeed: 0.0605s/iter; left time: 21.3400s\n",
      "\titers: 200, epoch: 19 | loss: 0.0698642\n",
      "\tspeed: 0.0301s/iter; left time: 7.6103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 226 | Train Loss: 0.0696991 Vali Loss: 0.0685625 Test Loss: 0.0896494\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0714715\n",
      "\tspeed: 0.0597s/iter; left time: 7.5765s\n",
      "\titers: 200, epoch: 20 | loss: 0.0723322\n",
      "\tspeed: 0.0302s/iter; left time: 0.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 226 | Train Loss: 0.0694726 Vali Loss: 0.0674063 Test Loss: 0.0901096\n",
      "Validation loss decreased (0.067614 --> 0.067406).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.018777692690491676, rmse:0.13703171908855438, mae:0.09015980362892151, rse:0.4032678008079529\n",
      "Intermediate time for ES and pred_len 24: 00h:06m:18.33s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3181987\n",
      "\tspeed: 0.0601s/iter; left time: 265.9089s\n",
      "\titers: 200, epoch: 1 | loss: 0.2911023\n",
      "\tspeed: 0.0372s/iter; left time: 160.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.12s\n",
      "Steps: 226 | Train Loss: 0.3182425 Vali Loss: 0.2821525 Test Loss: 0.3260046\n",
      "Validation loss decreased (inf --> 0.282153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2072557\n",
      "\tspeed: 0.0720s/iter; left time: 301.9723s\n",
      "\titers: 200, epoch: 2 | loss: 0.1472228\n",
      "\tspeed: 0.0373s/iter; left time: 152.8985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.2000621 Vali Loss: 0.1337541 Test Loss: 0.1575626\n",
      "Validation loss decreased (0.282153 --> 0.133754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1313876\n",
      "\tspeed: 0.0729s/iter; left time: 289.1468s\n",
      "\titers: 200, epoch: 3 | loss: 0.1214886\n",
      "\tspeed: 0.0370s/iter; left time: 142.9970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 226 | Train Loss: 0.1305957 Vali Loss: 0.1207391 Test Loss: 0.1452142\n",
      "Validation loss decreased (0.133754 --> 0.120739).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1169813\n",
      "\tspeed: 0.0728s/iter; left time: 272.4973s\n",
      "\titers: 200, epoch: 4 | loss: 0.1120115\n",
      "\tspeed: 0.0370s/iter; left time: 134.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1178858 Vali Loss: 0.1127241 Test Loss: 0.1406444\n",
      "Validation loss decreased (0.120739 --> 0.112724).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1091234\n",
      "\tspeed: 0.0723s/iter; left time: 254.4436s\n",
      "\titers: 200, epoch: 5 | loss: 0.1106293\n",
      "\tspeed: 0.0370s/iter; left time: 126.4618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1118682 Vali Loss: 0.1106397 Test Loss: 0.1398559\n",
      "Validation loss decreased (0.112724 --> 0.110640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080357\n",
      "\tspeed: 0.0722s/iter; left time: 237.6497s\n",
      "\titers: 200, epoch: 6 | loss: 0.1092359\n",
      "\tspeed: 0.0371s/iter; left time: 118.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 226 | Train Loss: 0.1081495 Vali Loss: 0.1107806 Test Loss: 0.1359452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1054622\n",
      "\tspeed: 0.0716s/iter; left time: 219.5560s\n",
      "\titers: 200, epoch: 7 | loss: 0.1051330\n",
      "\tspeed: 0.0370s/iter; left time: 109.6472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 226 | Train Loss: 0.1057178 Vali Loss: 0.1071104 Test Loss: 0.1352263\n",
      "Validation loss decreased (0.110640 --> 0.107110).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1022570\n",
      "\tspeed: 0.0730s/iter; left time: 207.1642s\n",
      "\titers: 200, epoch: 8 | loss: 0.1007675\n",
      "\tspeed: 0.0373s/iter; left time: 102.2739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 226 | Train Loss: 0.1036130 Vali Loss: 0.1062366 Test Loss: 0.1327628\n",
      "Validation loss decreased (0.107110 --> 0.106237).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1016834\n",
      "\tspeed: 0.0731s/iter; left time: 190.9569s\n",
      "\titers: 200, epoch: 9 | loss: 0.0998323\n",
      "\tspeed: 0.0370s/iter; left time: 92.9681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.1019221 Vali Loss: 0.1058611 Test Loss: 0.1311111\n",
      "Validation loss decreased (0.106237 --> 0.105861).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995335\n",
      "\tspeed: 0.0727s/iter; left time: 173.5006s\n",
      "\titers: 200, epoch: 10 | loss: 0.1012429\n",
      "\tspeed: 0.0371s/iter; left time: 84.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 226 | Train Loss: 0.1006769 Vali Loss: 0.1048012 Test Loss: 0.1322803\n",
      "Validation loss decreased (0.105861 --> 0.104801).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1010450\n",
      "\tspeed: 0.0715s/iter; left time: 154.5105s\n",
      "\titers: 200, epoch: 11 | loss: 0.1005874\n",
      "\tspeed: 0.0369s/iter; left time: 76.1244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 226 | Train Loss: 0.0997166 Vali Loss: 0.1026917 Test Loss: 0.1326899\n",
      "Validation loss decreased (0.104801 --> 0.102692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0995894\n",
      "\tspeed: 0.0725s/iter; left time: 140.2931s\n",
      "\titers: 200, epoch: 12 | loss: 0.0983595\n",
      "\tspeed: 0.0372s/iter; left time: 68.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.0988607 Vali Loss: 0.1039873 Test Loss: 0.1290248\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0985976\n",
      "\tspeed: 0.0720s/iter; left time: 123.0080s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981167\n",
      "\tspeed: 0.0372s/iter; left time: 59.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.0980740 Vali Loss: 0.1038736 Test Loss: 0.1291824\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0968871\n",
      "\tspeed: 0.0722s/iter; left time: 107.1193s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959438\n",
      "\tspeed: 0.0374s/iter; left time: 51.7316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 226 | Train Loss: 0.0975098 Vali Loss: 0.1021845 Test Loss: 0.1313410\n",
      "Validation loss decreased (0.102692 --> 0.102185).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0940208\n",
      "\tspeed: 0.0728s/iter; left time: 91.5061s\n",
      "\titers: 200, epoch: 15 | loss: 0.0961943\n",
      "\tspeed: 0.0375s/iter; left time: 43.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 226 | Train Loss: 0.0969515 Vali Loss: 0.1029793 Test Loss: 0.1290878\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0953849\n",
      "\tspeed: 0.0714s/iter; left time: 73.6125s\n",
      "\titers: 200, epoch: 16 | loss: 0.0959623\n",
      "\tspeed: 0.0369s/iter; left time: 34.3642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 226 | Train Loss: 0.0965079 Vali Loss: 0.1024040 Test Loss: 0.1291218\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0979599\n",
      "\tspeed: 0.0712s/iter; left time: 57.3088s\n",
      "\titers: 200, epoch: 17 | loss: 0.1001847\n",
      "\tspeed: 0.0370s/iter; left time: 26.1163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.0960618 Vali Loss: 0.1017888 Test Loss: 0.1292525\n",
      "Validation loss decreased (0.102185 --> 0.101789).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0957646\n",
      "\tspeed: 0.0728s/iter; left time: 42.1309s\n",
      "\titers: 200, epoch: 18 | loss: 0.0941166\n",
      "\tspeed: 0.0370s/iter; left time: 17.7433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.0957389 Vali Loss: 0.1009046 Test Loss: 0.1292533\n",
      "Validation loss decreased (0.101789 --> 0.100905).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0958459\n",
      "\tspeed: 0.0738s/iter; left time: 26.0411s\n",
      "\titers: 200, epoch: 19 | loss: 0.0951555\n",
      "\tspeed: 0.0374s/iter; left time: 9.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 226 | Train Loss: 0.0954592 Vali Loss: 0.1010287 Test Loss: 0.1295010\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0951066\n",
      "\tspeed: 0.0721s/iter; left time: 9.1561s\n",
      "\titers: 200, epoch: 20 | loss: 0.0922241\n",
      "\tspeed: 0.0367s/iter; left time: 0.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.0952011 Vali Loss: 0.1010638 Test Loss: 0.1288552\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03873514384031296, rmse:0.1968124657869339, mae:0.12926803529262543, rse:0.5781757831573486\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3131732\n",
      "\tspeed: 0.0397s/iter; left time: 175.3786s\n",
      "\titers: 200, epoch: 1 | loss: 0.2904586\n",
      "\tspeed: 0.0369s/iter; left time: 159.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 226 | Train Loss: 0.3096360 Vali Loss: 0.2849613 Test Loss: 0.3231701\n",
      "Validation loss decreased (inf --> 0.284961).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2023485\n",
      "\tspeed: 0.0715s/iter; left time: 299.7703s\n",
      "\titers: 200, epoch: 2 | loss: 0.1637651\n",
      "\tspeed: 0.0370s/iter; left time: 151.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 226 | Train Loss: 0.2023733 Vali Loss: 0.1647402 Test Loss: 0.1964008\n",
      "Validation loss decreased (0.284961 --> 0.164740).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1358592\n",
      "\tspeed: 0.0710s/iter; left time: 281.8743s\n",
      "\titers: 200, epoch: 3 | loss: 0.1241393\n",
      "\tspeed: 0.0368s/iter; left time: 142.3365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 226 | Train Loss: 0.1349114 Vali Loss: 0.1225857 Test Loss: 0.1434304\n",
      "Validation loss decreased (0.164740 --> 0.122586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1176909\n",
      "\tspeed: 0.0714s/iter; left time: 267.1344s\n",
      "\titers: 200, epoch: 4 | loss: 0.1125154\n",
      "\tspeed: 0.0374s/iter; left time: 136.1861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.1163111 Vali Loss: 0.1123185 Test Loss: 0.1398821\n",
      "Validation loss decreased (0.122586 --> 0.112318).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1076546\n",
      "\tspeed: 0.0720s/iter; left time: 253.1605s\n",
      "\titers: 200, epoch: 5 | loss: 0.1051853\n",
      "\tspeed: 0.0368s/iter; left time: 125.7589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 226 | Train Loss: 0.1099926 Vali Loss: 0.1134091 Test Loss: 0.1353403\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1055953\n",
      "\tspeed: 0.0726s/iter; left time: 238.8389s\n",
      "\titers: 200, epoch: 6 | loss: 0.1061031\n",
      "\tspeed: 0.0374s/iter; left time: 119.2729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 226 | Train Loss: 0.1063956 Vali Loss: 0.1071142 Test Loss: 0.1360243\n",
      "Validation loss decreased (0.112318 --> 0.107114).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1075654\n",
      "\tspeed: 0.0715s/iter; left time: 219.1271s\n",
      "\titers: 200, epoch: 7 | loss: 0.1035936\n",
      "\tspeed: 0.0368s/iter; left time: 109.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 226 | Train Loss: 0.1038351 Vali Loss: 0.1058298 Test Loss: 0.1353654\n",
      "Validation loss decreased (0.107114 --> 0.105830).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1026323\n",
      "\tspeed: 0.0728s/iter; left time: 206.7131s\n",
      "\titers: 200, epoch: 8 | loss: 0.0988119\n",
      "\tspeed: 0.0371s/iter; left time: 101.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1019649 Vali Loss: 0.1050941 Test Loss: 0.1336456\n",
      "Validation loss decreased (0.105830 --> 0.105094).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1004151\n",
      "\tspeed: 0.0717s/iter; left time: 187.3004s\n",
      "\titers: 200, epoch: 9 | loss: 0.0975337\n",
      "\tspeed: 0.0370s/iter; left time: 92.9871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1002821 Vali Loss: 0.1035146 Test Loss: 0.1337508\n",
      "Validation loss decreased (0.105094 --> 0.103515).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1008646\n",
      "\tspeed: 0.0728s/iter; left time: 173.8642s\n",
      "\titers: 200, epoch: 10 | loss: 0.0973887\n",
      "\tspeed: 0.0375s/iter; left time: 85.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 226 | Train Loss: 0.0987568 Vali Loss: 0.1019707 Test Loss: 0.1347670\n",
      "Validation loss decreased (0.103515 --> 0.101971).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0916815\n",
      "\tspeed: 0.0723s/iter; left time: 156.1568s\n",
      "\titers: 200, epoch: 11 | loss: 0.0930822\n",
      "\tspeed: 0.0370s/iter; left time: 76.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.0975361 Vali Loss: 0.1017843 Test Loss: 0.1309182\n",
      "Validation loss decreased (0.101971 --> 0.101784).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0938661\n",
      "\tspeed: 0.0709s/iter; left time: 137.2594s\n",
      "\titers: 200, epoch: 12 | loss: 0.0960683\n",
      "\tspeed: 0.0369s/iter; left time: 67.7293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 226 | Train Loss: 0.0966443 Vali Loss: 0.1007553 Test Loss: 0.1320661\n",
      "Validation loss decreased (0.101784 --> 0.100755).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0946868\n",
      "\tspeed: 0.0713s/iter; left time: 121.9180s\n",
      "\titers: 200, epoch: 13 | loss: 0.0943354\n",
      "\tspeed: 0.0368s/iter; left time: 59.1942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.0959620 Vali Loss: 0.1001427 Test Loss: 0.1310394\n",
      "Validation loss decreased (0.100755 --> 0.100143).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0943800\n",
      "\tspeed: 0.0712s/iter; left time: 105.6605s\n",
      "\titers: 200, epoch: 14 | loss: 0.0943177\n",
      "\tspeed: 0.0368s/iter; left time: 50.9593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 226 | Train Loss: 0.0953237 Vali Loss: 0.1002084 Test Loss: 0.1309389\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0938426\n",
      "\tspeed: 0.0706s/iter; left time: 88.7323s\n",
      "\titers: 200, epoch: 15 | loss: 0.0986734\n",
      "\tspeed: 0.0369s/iter; left time: 42.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.0948665 Vali Loss: 0.0998338 Test Loss: 0.1312348\n",
      "Validation loss decreased (0.100143 --> 0.099834).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0925328\n",
      "\tspeed: 0.0720s/iter; left time: 74.1911s\n",
      "\titers: 200, epoch: 16 | loss: 0.0928332\n",
      "\tspeed: 0.0369s/iter; left time: 34.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 226 | Train Loss: 0.0944162 Vali Loss: 0.0998834 Test Loss: 0.1326436\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0944256\n",
      "\tspeed: 0.0716s/iter; left time: 57.6158s\n",
      "\titers: 200, epoch: 17 | loss: 0.0922941\n",
      "\tspeed: 0.0369s/iter; left time: 25.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.0940538 Vali Loss: 0.0987952 Test Loss: 0.1313607\n",
      "Validation loss decreased (0.099834 --> 0.098795).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0923443\n",
      "\tspeed: 0.0715s/iter; left time: 41.4135s\n",
      "\titers: 200, epoch: 18 | loss: 0.0923352\n",
      "\tspeed: 0.0369s/iter; left time: 17.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 226 | Train Loss: 0.0937521 Vali Loss: 0.0973663 Test Loss: 0.1337302\n",
      "Validation loss decreased (0.098795 --> 0.097366).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0951022\n",
      "\tspeed: 0.0713s/iter; left time: 25.1694s\n",
      "\titers: 200, epoch: 19 | loss: 0.0914813\n",
      "\tspeed: 0.0369s/iter; left time: 9.3430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 226 | Train Loss: 0.0933269 Vali Loss: 0.0976783 Test Loss: 0.1336437\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0950709\n",
      "\tspeed: 0.0705s/iter; left time: 8.9489s\n",
      "\titers: 200, epoch: 20 | loss: 0.0928871\n",
      "\tspeed: 0.0372s/iter; left time: 1.0040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 226 | Train Loss: 0.0930625 Vali Loss: 0.0968792 Test Loss: 0.1331241\n",
      "Validation loss decreased (0.097366 --> 0.096879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04150637984275818, rmse:0.20373114943504333, mae:0.13310353457927704, rse:0.5985007882118225\n",
      "Intermediate time for ES and pred_len 96: 00h:07m:26.93s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3199352\n",
      "\tspeed: 0.0688s/iter; left time: 302.7586s\n",
      "\titers: 200, epoch: 1 | loss: 0.2904662\n",
      "\tspeed: 0.0452s/iter; left time: 194.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.80s\n",
      "Steps: 225 | Train Loss: 0.3184391 Vali Loss: 0.2829991 Test Loss: 0.3253019\n",
      "Validation loss decreased (inf --> 0.282999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2048859\n",
      "\tspeed: 0.0872s/iter; left time: 364.1127s\n",
      "\titers: 200, epoch: 2 | loss: 0.1652155\n",
      "\tspeed: 0.0449s/iter; left time: 182.9393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 225 | Train Loss: 0.2066925 Vali Loss: 0.1556762 Test Loss: 0.1868700\n",
      "Validation loss decreased (0.282999 --> 0.155676).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1447721\n",
      "\tspeed: 0.0873s/iter; left time: 344.9138s\n",
      "\titers: 200, epoch: 3 | loss: 0.1389940\n",
      "\tspeed: 0.0449s/iter; left time: 172.9465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1474363 Vali Loss: 0.1455533 Test Loss: 0.1711761\n",
      "Validation loss decreased (0.155676 --> 0.145553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1348276\n",
      "\tspeed: 0.0862s/iter; left time: 321.0021s\n",
      "\titers: 200, epoch: 4 | loss: 0.1300863\n",
      "\tspeed: 0.0450s/iter; left time: 163.0119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 225 | Train Loss: 0.1342954 Vali Loss: 0.1374051 Test Loss: 0.1682328\n",
      "Validation loss decreased (0.145553 --> 0.137405).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1286117\n",
      "\tspeed: 0.0917s/iter; left time: 321.0711s\n",
      "\titers: 200, epoch: 5 | loss: 0.1254431\n",
      "\tspeed: 0.0447s/iter; left time: 152.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.43s\n",
      "Steps: 225 | Train Loss: 0.1275059 Vali Loss: 0.1339340 Test Loss: 0.1623902\n",
      "Validation loss decreased (0.137405 --> 0.133934).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1223909\n",
      "\tspeed: 0.0864s/iter; left time: 282.8959s\n",
      "\titers: 200, epoch: 6 | loss: 0.1243197\n",
      "\tspeed: 0.0443s/iter; left time: 140.7021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.32s\n",
      "Steps: 225 | Train Loss: 0.1233692 Vali Loss: 0.1321844 Test Loss: 0.1622740\n",
      "Validation loss decreased (0.133934 --> 0.132184).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1203946\n",
      "\tspeed: 0.0854s/iter; left time: 260.4927s\n",
      "\titers: 200, epoch: 7 | loss: 0.1197341\n",
      "\tspeed: 0.0444s/iter; left time: 131.0379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1203030 Vali Loss: 0.1307014 Test Loss: 0.1579680\n",
      "Validation loss decreased (0.132184 --> 0.130701).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1159319\n",
      "\tspeed: 0.0852s/iter; left time: 240.7943s\n",
      "\titers: 200, epoch: 8 | loss: 0.1195130\n",
      "\tspeed: 0.0442s/iter; left time: 120.4164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1178349 Vali Loss: 0.1280387 Test Loss: 0.1573496\n",
      "Validation loss decreased (0.130701 --> 0.128039).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1168301\n",
      "\tspeed: 0.0851s/iter; left time: 221.4114s\n",
      "\titers: 200, epoch: 9 | loss: 0.1150357\n",
      "\tspeed: 0.0439s/iter; left time: 109.8507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 225 | Train Loss: 0.1159325 Vali Loss: 0.1280957 Test Loss: 0.1550342\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1141510\n",
      "\tspeed: 0.0842s/iter; left time: 200.0181s\n",
      "\titers: 200, epoch: 10 | loss: 0.1144394\n",
      "\tspeed: 0.0432s/iter; left time: 98.4112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 225 | Train Loss: 0.1143615 Vali Loss: 0.1243402 Test Loss: 0.1556973\n",
      "Validation loss decreased (0.128039 --> 0.124340).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1148760\n",
      "\tspeed: 0.0865s/iter; left time: 186.1109s\n",
      "\titers: 200, epoch: 11 | loss: 0.1126754\n",
      "\tspeed: 0.0448s/iter; left time: 91.9755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.40s\n",
      "Steps: 225 | Train Loss: 0.1132257 Vali Loss: 0.1228697 Test Loss: 0.1547955\n",
      "Validation loss decreased (0.124340 --> 0.122870).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1136385\n",
      "\tspeed: 0.0862s/iter; left time: 166.0503s\n",
      "\titers: 200, epoch: 12 | loss: 0.1145175\n",
      "\tspeed: 0.0443s/iter; left time: 80.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 225 | Train Loss: 0.1120891 Vali Loss: 0.1235217 Test Loss: 0.1510904\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1128238\n",
      "\tspeed: 0.0845s/iter; left time: 143.7951s\n",
      "\titers: 200, epoch: 13 | loss: 0.1126715\n",
      "\tspeed: 0.0442s/iter; left time: 70.7223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1110694 Vali Loss: 0.1217232 Test Loss: 0.1516053\n",
      "Validation loss decreased (0.122870 --> 0.121723).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1104986\n",
      "\tspeed: 0.0854s/iter; left time: 126.1239s\n",
      "\titers: 200, epoch: 14 | loss: 0.1084247\n",
      "\tspeed: 0.0449s/iter; left time: 61.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.36s\n",
      "Steps: 225 | Train Loss: 0.1103297 Vali Loss: 0.1217503 Test Loss: 0.1500141\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1094985\n",
      "\tspeed: 0.0854s/iter; left time: 106.7888s\n",
      "\titers: 200, epoch: 15 | loss: 0.1095536\n",
      "\tspeed: 0.0440s/iter; left time: 50.6855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 225 | Train Loss: 0.1096375 Vali Loss: 0.1192090 Test Loss: 0.1500523\n",
      "Validation loss decreased (0.121723 --> 0.119209).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1105389\n",
      "\tspeed: 0.0854s/iter; left time: 87.5924s\n",
      "\titers: 200, epoch: 16 | loss: 0.1062419\n",
      "\tspeed: 0.0440s/iter; left time: 40.7289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.28s\n",
      "Steps: 225 | Train Loss: 0.1090809 Vali Loss: 0.1177936 Test Loss: 0.1477227\n",
      "Validation loss decreased (0.119209 --> 0.117794).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1086016\n",
      "\tspeed: 0.0856s/iter; left time: 68.5370s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086584\n",
      "\tspeed: 0.0442s/iter; left time: 31.0049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1086072 Vali Loss: 0.1185556 Test Loss: 0.1476339\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1096675\n",
      "\tspeed: 0.0844s/iter; left time: 48.6136s\n",
      "\titers: 200, epoch: 18 | loss: 0.1074494\n",
      "\tspeed: 0.0443s/iter; left time: 21.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 225 | Train Loss: 0.1081263 Vali Loss: 0.1193977 Test Loss: 0.1481341\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1084842\n",
      "\tspeed: 0.0842s/iter; left time: 29.5696s\n",
      "\titers: 200, epoch: 19 | loss: 0.1069015\n",
      "\tspeed: 0.0442s/iter; left time: 11.0871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.26s\n",
      "Steps: 225 | Train Loss: 0.1077479 Vali Loss: 0.1177147 Test Loss: 0.1468834\n",
      "Validation loss decreased (0.117794 --> 0.117715).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1058651\n",
      "\tspeed: 0.0854s/iter; left time: 10.7618s\n",
      "\titers: 200, epoch: 20 | loss: 0.1084858\n",
      "\tspeed: 0.0447s/iter; left time: 1.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.42s\n",
      "Steps: 225 | Train Loss: 0.1074109 Vali Loss: 0.1178427 Test Loss: 0.1460664\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.050476811826229095, rmse:0.22467045485973358, mae:0.1469610035419464, rse:0.6600615382194519\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2998949\n",
      "\tspeed: 0.0474s/iter; left time: 208.7929s\n",
      "\titers: 200, epoch: 1 | loss: 0.2835027\n",
      "\tspeed: 0.0444s/iter; left time: 190.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.34s\n",
      "Steps: 225 | Train Loss: 0.3027075 Vali Loss: 0.2825024 Test Loss: 0.3212502\n",
      "Validation loss decreased (inf --> 0.282502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2011438\n",
      "\tspeed: 0.0858s/iter; left time: 358.3834s\n",
      "\titers: 200, epoch: 2 | loss: 0.1681751\n",
      "\tspeed: 0.0443s/iter; left time: 180.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 225 | Train Loss: 0.2026726 Vali Loss: 0.1633612 Test Loss: 0.1956033\n",
      "Validation loss decreased (0.282502 --> 0.163361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1470439\n",
      "\tspeed: 0.0867s/iter; left time: 342.4892s\n",
      "\titers: 200, epoch: 3 | loss: 0.1396960\n",
      "\tspeed: 0.0446s/iter; left time: 171.8607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.35s\n",
      "Steps: 225 | Train Loss: 0.1469399 Vali Loss: 0.1431353 Test Loss: 0.1731739\n",
      "Validation loss decreased (0.163361 --> 0.143135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1316857\n",
      "\tspeed: 0.0872s/iter; left time: 324.8761s\n",
      "\titers: 200, epoch: 4 | loss: 0.1285651\n",
      "\tspeed: 0.0445s/iter; left time: 161.4311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 225 | Train Loss: 0.1332156 Vali Loss: 0.1373095 Test Loss: 0.1671022\n",
      "Validation loss decreased (0.143135 --> 0.137310).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1242311\n",
      "\tspeed: 0.0861s/iter; left time: 301.5349s\n",
      "\titers: 200, epoch: 5 | loss: 0.1224897\n",
      "\tspeed: 0.0443s/iter; left time: 150.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.31s\n",
      "Steps: 225 | Train Loss: 0.1254424 Vali Loss: 0.1330290 Test Loss: 0.1603833\n",
      "Validation loss decreased (0.137310 --> 0.133029).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1211893\n",
      "\tspeed: 0.0861s/iter; left time: 282.0354s\n",
      "\titers: 200, epoch: 6 | loss: 0.1220798\n",
      "\tspeed: 0.0445s/iter; left time: 141.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.35s\n",
      "Steps: 225 | Train Loss: 0.1205391 Vali Loss: 0.1303184 Test Loss: 0.1581637\n",
      "Validation loss decreased (0.133029 --> 0.130318).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1161071\n",
      "\tspeed: 0.0855s/iter; left time: 260.8200s\n",
      "\titers: 200, epoch: 7 | loss: 0.1179884\n",
      "\tspeed: 0.0442s/iter; left time: 130.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 225 | Train Loss: 0.1174249 Vali Loss: 0.1259282 Test Loss: 0.1571292\n",
      "Validation loss decreased (0.130318 --> 0.125928).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1149470\n",
      "\tspeed: 0.0860s/iter; left time: 243.0226s\n",
      "\titers: 200, epoch: 8 | loss: 0.1151317\n",
      "\tspeed: 0.0445s/iter; left time: 121.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.35s\n",
      "Steps: 225 | Train Loss: 0.1150192 Vali Loss: 0.1228629 Test Loss: 0.1558346\n",
      "Validation loss decreased (0.125928 --> 0.122863).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1126134\n",
      "\tspeed: 0.0865s/iter; left time: 225.0396s\n",
      "\titers: 200, epoch: 9 | loss: 0.1126166\n",
      "\tspeed: 0.0441s/iter; left time: 110.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1132529 Vali Loss: 0.1221997 Test Loss: 0.1534827\n",
      "Validation loss decreased (0.122863 --> 0.122200).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1116059\n",
      "\tspeed: 0.0857s/iter; left time: 203.5505s\n",
      "\titers: 200, epoch: 10 | loss: 0.1104976\n",
      "\tspeed: 0.0444s/iter; left time: 100.9605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.29s\n",
      "Steps: 225 | Train Loss: 0.1116333 Vali Loss: 0.1206286 Test Loss: 0.1519579\n",
      "Validation loss decreased (0.122200 --> 0.120629).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1098525\n",
      "\tspeed: 0.0856s/iter; left time: 184.0622s\n",
      "\titers: 200, epoch: 11 | loss: 0.1107253\n",
      "\tspeed: 0.0435s/iter; left time: 89.1524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 225 | Train Loss: 0.1103354 Vali Loss: 0.1216338 Test Loss: 0.1510612\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1109264\n",
      "\tspeed: 0.0832s/iter; left time: 160.2001s\n",
      "\titers: 200, epoch: 12 | loss: 0.1086039\n",
      "\tspeed: 0.0447s/iter; left time: 81.7012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.30s\n",
      "Steps: 225 | Train Loss: 0.1093596 Vali Loss: 0.1201979 Test Loss: 0.1495531\n",
      "Validation loss decreased (0.120629 --> 0.120198).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1073115\n",
      "\tspeed: 0.0877s/iter; left time: 149.1634s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071517\n",
      "\tspeed: 0.0441s/iter; left time: 70.5524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.27s\n",
      "Steps: 225 | Train Loss: 0.1085571 Vali Loss: 0.1174131 Test Loss: 0.1504400\n",
      "Validation loss decreased (0.120198 --> 0.117413).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1084891\n",
      "\tspeed: 0.0858s/iter; left time: 126.6736s\n",
      "\titers: 200, epoch: 14 | loss: 0.1086841\n",
      "\tspeed: 0.0441s/iter; left time: 60.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.33s\n",
      "Steps: 225 | Train Loss: 0.1076751 Vali Loss: 0.1166780 Test Loss: 0.1487234\n",
      "Validation loss decreased (0.117413 --> 0.116678).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1055986\n",
      "\tspeed: 0.0866s/iter; left time: 108.3789s\n",
      "\titers: 200, epoch: 15 | loss: 0.1081964\n",
      "\tspeed: 0.0443s/iter; left time: 50.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.34s\n",
      "Steps: 225 | Train Loss: 0.1068682 Vali Loss: 0.1146955 Test Loss: 0.1492259\n",
      "Validation loss decreased (0.116678 --> 0.114696).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1056143\n",
      "\tspeed: 0.0862s/iter; left time: 88.4575s\n",
      "\titers: 200, epoch: 16 | loss: 0.1073665\n",
      "\tspeed: 0.0436s/iter; left time: 40.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 225 | Train Loss: 0.1062787 Vali Loss: 0.1153379 Test Loss: 0.1479984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1042104\n",
      "\tspeed: 0.0833s/iter; left time: 66.7133s\n",
      "\titers: 200, epoch: 17 | loss: 0.1058270\n",
      "\tspeed: 0.0439s/iter; left time: 30.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.16s\n",
      "Steps: 225 | Train Loss: 0.1055653 Vali Loss: 0.1129677 Test Loss: 0.1502614\n",
      "Validation loss decreased (0.114696 --> 0.112968).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1032693\n",
      "\tspeed: 0.0838s/iter; left time: 48.2647s\n",
      "\titers: 200, epoch: 18 | loss: 0.1066784\n",
      "\tspeed: 0.0435s/iter; left time: 20.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 225 | Train Loss: 0.1050625 Vali Loss: 0.1138389 Test Loss: 0.1476472\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1049190\n",
      "\tspeed: 0.0829s/iter; left time: 29.1125s\n",
      "\titers: 200, epoch: 19 | loss: 0.1063340\n",
      "\tspeed: 0.0432s/iter; left time: 10.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.08s\n",
      "Steps: 225 | Train Loss: 0.1046291 Vali Loss: 0.1137638 Test Loss: 0.1473266\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1075083\n",
      "\tspeed: 0.0829s/iter; left time: 10.4405s\n",
      "\titers: 200, epoch: 20 | loss: 0.1019675\n",
      "\tspeed: 0.0436s/iter; left time: 1.1325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.11s\n",
      "Steps: 225 | Train Loss: 0.1041133 Vali Loss: 0.1117626 Test Loss: 0.1479889\n",
      "Validation loss decreased (0.112968 --> 0.111763).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0526326559484005, rmse:0.229418084025383, mae:0.14801563322544098, rse:0.6740096807479858\n",
      "Intermediate time for ES and pred_len 168: 00h:08m:51.90s\n",
      "Intermediate time for ES: 00h:22m:37.16s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2774773\n",
      "\tspeed: 0.0544s/iter; left time: 240.6463s\n",
      "\titers: 200, epoch: 1 | loss: 0.2401486\n",
      "\tspeed: 0.0313s/iter; left time: 135.1636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 226 | Train Loss: 0.2760921 Vali Loss: 0.2476363 Test Loss: 0.2630727\n",
      "Validation loss decreased (inf --> 0.247636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1690976\n",
      "\tspeed: 0.0613s/iter; left time: 257.0711s\n",
      "\titers: 200, epoch: 2 | loss: 0.1430351\n",
      "\tspeed: 0.0314s/iter; left time: 128.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.1672327 Vali Loss: 0.1791551 Test Loss: 0.2009583\n",
      "Validation loss decreased (0.247636 --> 0.179155).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1259109\n",
      "\tspeed: 0.0621s/iter; left time: 246.6424s\n",
      "\titers: 200, epoch: 3 | loss: 0.1174905\n",
      "\tspeed: 0.0318s/iter; left time: 123.1028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1271803 Vali Loss: 0.1441013 Test Loss: 0.1623127\n",
      "Validation loss decreased (0.179155 --> 0.144101).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1147889\n",
      "\tspeed: 0.0609s/iter; left time: 227.8039s\n",
      "\titers: 200, epoch: 4 | loss: 0.1113406\n",
      "\tspeed: 0.0311s/iter; left time: 113.1944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.1141474 Vali Loss: 0.1339134 Test Loss: 0.1523813\n",
      "Validation loss decreased (0.144101 --> 0.133913).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1087572\n",
      "\tspeed: 0.0617s/iter; left time: 216.9881s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047679\n",
      "\tspeed: 0.0309s/iter; left time: 105.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.1087034 Vali Loss: 0.1323892 Test Loss: 0.1507402\n",
      "Validation loss decreased (0.133913 --> 0.132389).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1042225\n",
      "\tspeed: 0.0622s/iter; left time: 204.6775s\n",
      "\titers: 200, epoch: 6 | loss: 0.1043228\n",
      "\tspeed: 0.0310s/iter; left time: 99.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 226 | Train Loss: 0.1054517 Vali Loss: 0.1291991 Test Loss: 0.1482220\n",
      "Validation loss decreased (0.132389 --> 0.129199).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1035275\n",
      "\tspeed: 0.0615s/iter; left time: 188.4606s\n",
      "\titers: 200, epoch: 7 | loss: 0.1030435\n",
      "\tspeed: 0.0313s/iter; left time: 92.7741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1035596 Vali Loss: 0.1286843 Test Loss: 0.1465822\n",
      "Validation loss decreased (0.129199 --> 0.128684).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1034210\n",
      "\tspeed: 0.0615s/iter; left time: 174.5707s\n",
      "\titers: 200, epoch: 8 | loss: 0.1006546\n",
      "\tspeed: 0.0312s/iter; left time: 85.5718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.1021520 Vali Loss: 0.1248840 Test Loss: 0.1440544\n",
      "Validation loss decreased (0.128684 --> 0.124884).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0973498\n",
      "\tspeed: 0.0603s/iter; left time: 157.5517s\n",
      "\titers: 200, epoch: 9 | loss: 0.1008990\n",
      "\tspeed: 0.0312s/iter; left time: 78.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.1012670 Vali Loss: 0.1264536 Test Loss: 0.1450374\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0986338\n",
      "\tspeed: 0.0601s/iter; left time: 143.4349s\n",
      "\titers: 200, epoch: 10 | loss: 0.1026012\n",
      "\tspeed: 0.0313s/iter; left time: 71.6884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.1001684 Vali Loss: 0.1235728 Test Loss: 0.1426126\n",
      "Validation loss decreased (0.124884 --> 0.123573).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0979927\n",
      "\tspeed: 0.0616s/iter; left time: 133.0948s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006420\n",
      "\tspeed: 0.0311s/iter; left time: 64.1024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0995861 Vali Loss: 0.1267229 Test Loss: 0.1451528\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0982709\n",
      "\tspeed: 0.0604s/iter; left time: 116.8944s\n",
      "\titers: 200, epoch: 12 | loss: 0.0924103\n",
      "\tspeed: 0.0311s/iter; left time: 57.0483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.0991176 Vali Loss: 0.1237954 Test Loss: 0.1428015\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1001440\n",
      "\tspeed: 0.0602s/iter; left time: 102.8738s\n",
      "\titers: 200, epoch: 13 | loss: 0.0929783\n",
      "\tspeed: 0.0314s/iter; left time: 50.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.0984569 Vali Loss: 0.1220799 Test Loss: 0.1411827\n",
      "Validation loss decreased (0.123573 --> 0.122080).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0958833\n",
      "\tspeed: 0.0610s/iter; left time: 90.4614s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959060\n",
      "\tspeed: 0.0320s/iter; left time: 44.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 226 | Train Loss: 0.0980839 Vali Loss: 0.1221063 Test Loss: 0.1412002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0976994\n",
      "\tspeed: 0.0597s/iter; left time: 75.0952s\n",
      "\titers: 200, epoch: 15 | loss: 0.1023093\n",
      "\tspeed: 0.0315s/iter; left time: 36.5004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0976189 Vali Loss: 0.1215886 Test Loss: 0.1408549\n",
      "Validation loss decreased (0.122080 --> 0.121589).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0952234\n",
      "\tspeed: 0.0612s/iter; left time: 63.1199s\n",
      "\titers: 200, epoch: 16 | loss: 0.0975711\n",
      "\tspeed: 0.0309s/iter; left time: 28.8134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 226 | Train Loss: 0.0972638 Vali Loss: 0.1212842 Test Loss: 0.1406887\n",
      "Validation loss decreased (0.121589 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0928463\n",
      "\tspeed: 0.0611s/iter; left time: 49.1938s\n",
      "\titers: 200, epoch: 17 | loss: 0.0935921\n",
      "\tspeed: 0.0308s/iter; left time: 21.6850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0970739 Vali Loss: 0.1213920 Test Loss: 0.1408462\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0941568\n",
      "\tspeed: 0.0621s/iter; left time: 35.9504s\n",
      "\titers: 200, epoch: 18 | loss: 0.0958078\n",
      "\tspeed: 0.0315s/iter; left time: 15.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.0967176 Vali Loss: 0.1210236 Test Loss: 0.1402074\n",
      "Validation loss decreased (0.121284 --> 0.121024).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0940376\n",
      "\tspeed: 0.0607s/iter; left time: 21.4322s\n",
      "\titers: 200, epoch: 19 | loss: 0.0959429\n",
      "\tspeed: 0.0312s/iter; left time: 7.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.0965026 Vali Loss: 0.1203753 Test Loss: 0.1401139\n",
      "Validation loss decreased (0.121024 --> 0.120375).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0931378\n",
      "\tspeed: 0.0632s/iter; left time: 8.0245s\n",
      "\titers: 200, epoch: 20 | loss: 0.0989985\n",
      "\tspeed: 0.0323s/iter; left time: 0.8708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 226 | Train Loss: 0.0963576 Vali Loss: 0.1205760 Test Loss: 0.1401417\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.07151491940021515, rmse:0.26742273569107056, mae:0.14010414481163025, rse:1.0317094326019287\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2850727\n",
      "\tspeed: 0.0358s/iter; left time: 158.1634s\n",
      "\titers: 200, epoch: 1 | loss: 0.2502438\n",
      "\tspeed: 0.0313s/iter; left time: 135.3727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.57s\n",
      "Steps: 226 | Train Loss: 0.2812806 Vali Loss: 0.2542199 Test Loss: 0.2746691\n",
      "Validation loss decreased (inf --> 0.254220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1644331\n",
      "\tspeed: 0.0627s/iter; left time: 263.2009s\n",
      "\titers: 200, epoch: 2 | loss: 0.1371755\n",
      "\tspeed: 0.0323s/iter; left time: 132.4195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 226 | Train Loss: 0.1666156 Vali Loss: 0.1771178 Test Loss: 0.1992712\n",
      "Validation loss decreased (0.254220 --> 0.177118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1277044\n",
      "\tspeed: 0.0612s/iter; left time: 243.0757s\n",
      "\titers: 200, epoch: 3 | loss: 0.1152053\n",
      "\tspeed: 0.0313s/iter; left time: 121.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.1249608 Vali Loss: 0.1412632 Test Loss: 0.1589661\n",
      "Validation loss decreased (0.177118 --> 0.141263).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1136213\n",
      "\tspeed: 0.0611s/iter; left time: 228.5995s\n",
      "\titers: 200, epoch: 4 | loss: 0.1077765\n",
      "\tspeed: 0.0317s/iter; left time: 115.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1124800 Vali Loss: 0.1314722 Test Loss: 0.1515270\n",
      "Validation loss decreased (0.141263 --> 0.131472).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1080868\n",
      "\tspeed: 0.0610s/iter; left time: 214.6687s\n",
      "\titers: 200, epoch: 5 | loss: 0.1062482\n",
      "\tspeed: 0.0315s/iter; left time: 107.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1074346 Vali Loss: 0.1334902 Test Loss: 0.1522190\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1072952\n",
      "\tspeed: 0.0600s/iter; left time: 197.3717s\n",
      "\titers: 200, epoch: 6 | loss: 0.1059341\n",
      "\tspeed: 0.0318s/iter; left time: 101.4152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.1048053 Vali Loss: 0.1268020 Test Loss: 0.1466498\n",
      "Validation loss decreased (0.131472 --> 0.126802).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1044225\n",
      "\tspeed: 0.0617s/iter; left time: 189.2593s\n",
      "\titers: 200, epoch: 7 | loss: 0.1000516\n",
      "\tspeed: 0.0316s/iter; left time: 93.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.48s\n",
      "Steps: 226 | Train Loss: 0.1024742 Vali Loss: 0.1269501 Test Loss: 0.1465268\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1018230\n",
      "\tspeed: 0.0610s/iter; left time: 173.0483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0954693\n",
      "\tspeed: 0.0311s/iter; left time: 85.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 226 | Train Loss: 0.1010931 Vali Loss: 0.1254323 Test Loss: 0.1451608\n",
      "Validation loss decreased (0.126802 --> 0.125432).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991919\n",
      "\tspeed: 0.0606s/iter; left time: 158.4066s\n",
      "\titers: 200, epoch: 9 | loss: 0.0959110\n",
      "\tspeed: 0.0314s/iter; left time: 79.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.1000547 Vali Loss: 0.1243511 Test Loss: 0.1435928\n",
      "Validation loss decreased (0.125432 --> 0.124351).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995059\n",
      "\tspeed: 0.0612s/iter; left time: 146.1120s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971065\n",
      "\tspeed: 0.0313s/iter; left time: 71.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.0992146 Vali Loss: 0.1237055 Test Loss: 0.1436944\n",
      "Validation loss decreased (0.124351 --> 0.123705).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0982912\n",
      "\tspeed: 0.0610s/iter; left time: 131.7719s\n",
      "\titers: 200, epoch: 11 | loss: 0.0978427\n",
      "\tspeed: 0.0306s/iter; left time: 63.0038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.0984856 Vali Loss: 0.1234227 Test Loss: 0.1427391\n",
      "Validation loss decreased (0.123705 --> 0.123423).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0965957\n",
      "\tspeed: 0.0600s/iter; left time: 116.0430s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971051\n",
      "\tspeed: 0.0313s/iter; left time: 57.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.0979071 Vali Loss: 0.1225829 Test Loss: 0.1421178\n",
      "Validation loss decreased (0.123423 --> 0.122583).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0982637\n",
      "\tspeed: 0.0629s/iter; left time: 107.5161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1006163\n",
      "\tspeed: 0.0311s/iter; left time: 49.9948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.43s\n",
      "Steps: 226 | Train Loss: 0.0974120 Vali Loss: 0.1227344 Test Loss: 0.1418243\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0957779\n",
      "\tspeed: 0.0620s/iter; left time: 91.9340s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960315\n",
      "\tspeed: 0.0319s/iter; left time: 44.1418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 226 | Train Loss: 0.0970200 Vali Loss: 0.1216480 Test Loss: 0.1405213\n",
      "Validation loss decreased (0.122583 --> 0.121648).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0952985\n",
      "\tspeed: 0.0626s/iter; left time: 78.7179s\n",
      "\titers: 200, epoch: 15 | loss: 0.0987367\n",
      "\tspeed: 0.0309s/iter; left time: 35.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.45s\n",
      "Steps: 226 | Train Loss: 0.0967089 Vali Loss: 0.1235154 Test Loss: 0.1421530\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0967367\n",
      "\tspeed: 0.0610s/iter; left time: 62.8964s\n",
      "\titers: 200, epoch: 16 | loss: 0.1008220\n",
      "\tspeed: 0.0311s/iter; left time: 28.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 226 | Train Loss: 0.0963443 Vali Loss: 0.1223538 Test Loss: 0.1415895\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0948430\n",
      "\tspeed: 0.0604s/iter; left time: 48.6000s\n",
      "\titers: 200, epoch: 17 | loss: 0.0987077\n",
      "\tspeed: 0.0313s/iter; left time: 22.0794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.0961581 Vali Loss: 0.1226156 Test Loss: 0.1408909\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0974751\n",
      "\tspeed: 0.0617s/iter; left time: 35.7413s\n",
      "\titers: 200, epoch: 18 | loss: 0.0972838\n",
      "\tspeed: 0.0316s/iter; left time: 15.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 226 | Train Loss: 0.0960059 Vali Loss: 0.1216611 Test Loss: 0.1406583\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0938235\n",
      "\tspeed: 0.0613s/iter; left time: 21.6217s\n",
      "\titers: 200, epoch: 19 | loss: 0.0955338\n",
      "\tspeed: 0.0315s/iter; left time: 7.9736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.0958315 Vali Loss: 0.1241700 Test Loss: 0.1423301\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.07121231406927109, rmse:0.2668563425540924, mae:0.1404910534620285, rse:1.029524326324463\n",
      "Intermediate time for FR and pred_len 24: 00h:06m:11.63s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2668277\n",
      "\tspeed: 0.0608s/iter; left time: 268.9926s\n",
      "\titers: 200, epoch: 1 | loss: 0.2365881\n",
      "\tspeed: 0.0359s/iter; left time: 155.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.91s\n",
      "Steps: 226 | Train Loss: 0.2711771 Vali Loss: 0.2333678 Test Loss: 0.2537911\n",
      "Validation loss decreased (inf --> 0.233368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1642069\n",
      "\tspeed: 0.0711s/iter; left time: 298.1240s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435912\n",
      "\tspeed: 0.0364s/iter; left time: 149.0899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 226 | Train Loss: 0.1682515 Vali Loss: 0.1735060 Test Loss: 0.2008051\n",
      "Validation loss decreased (0.233368 --> 0.173506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1351066\n",
      "\tspeed: 0.0725s/iter; left time: 287.6563s\n",
      "\titers: 200, epoch: 3 | loss: 0.1291091\n",
      "\tspeed: 0.0371s/iter; left time: 143.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.1350502 Vali Loss: 0.1512001 Test Loss: 0.1742555\n",
      "Validation loss decreased (0.173506 --> 0.151200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1241704\n",
      "\tspeed: 0.0736s/iter; left time: 275.6048s\n",
      "\titers: 200, epoch: 4 | loss: 0.1220577\n",
      "\tspeed: 0.0366s/iter; left time: 133.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 226 | Train Loss: 0.1230206 Vali Loss: 0.1440067 Test Loss: 0.1672465\n",
      "Validation loss decreased (0.151200 --> 0.144007).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1162365\n",
      "\tspeed: 0.0734s/iter; left time: 258.1165s\n",
      "\titers: 200, epoch: 5 | loss: 0.1184664\n",
      "\tspeed: 0.0377s/iter; left time: 128.9127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 226 | Train Loss: 0.1184197 Vali Loss: 0.1405973 Test Loss: 0.1639409\n",
      "Validation loss decreased (0.144007 --> 0.140597).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1138581\n",
      "\tspeed: 0.0739s/iter; left time: 243.0587s\n",
      "\titers: 200, epoch: 6 | loss: 0.1174790\n",
      "\tspeed: 0.0362s/iter; left time: 115.5475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 226 | Train Loss: 0.1160509 Vali Loss: 0.1390713 Test Loss: 0.1621730\n",
      "Validation loss decreased (0.140597 --> 0.139071).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1142476\n",
      "\tspeed: 0.0726s/iter; left time: 222.4605s\n",
      "\titers: 200, epoch: 7 | loss: 0.1143280\n",
      "\tspeed: 0.0367s/iter; left time: 108.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 226 | Train Loss: 0.1146812 Vali Loss: 0.1381505 Test Loss: 0.1618189\n",
      "Validation loss decreased (0.139071 --> 0.138151).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1125740\n",
      "\tspeed: 0.0740s/iter; left time: 210.0232s\n",
      "\titers: 200, epoch: 8 | loss: 0.1154047\n",
      "\tspeed: 0.0366s/iter; left time: 100.3498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1136695 Vali Loss: 0.1378118 Test Loss: 0.1613069\n",
      "Validation loss decreased (0.138151 --> 0.137812).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1133467\n",
      "\tspeed: 0.0728s/iter; left time: 190.1656s\n",
      "\titers: 200, epoch: 9 | loss: 0.1114003\n",
      "\tspeed: 0.0370s/iter; left time: 92.9839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1127972 Vali Loss: 0.1373884 Test Loss: 0.1613626\n",
      "Validation loss decreased (0.137812 --> 0.137388).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1145886\n",
      "\tspeed: 0.0724s/iter; left time: 172.7824s\n",
      "\titers: 200, epoch: 10 | loss: 0.1121639\n",
      "\tspeed: 0.0361s/iter; left time: 82.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1121749 Vali Loss: 0.1377129 Test Loss: 0.1607609\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1112239\n",
      "\tspeed: 0.0718s/iter; left time: 155.2311s\n",
      "\titers: 200, epoch: 11 | loss: 0.1097993\n",
      "\tspeed: 0.0365s/iter; left time: 75.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 226 | Train Loss: 0.1115658 Vali Loss: 0.1380044 Test Loss: 0.1608877\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1110479\n",
      "\tspeed: 0.0718s/iter; left time: 138.8804s\n",
      "\titers: 200, epoch: 12 | loss: 0.1080394\n",
      "\tspeed: 0.0364s/iter; left time: 66.8440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 226 | Train Loss: 0.1112398 Vali Loss: 0.1371231 Test Loss: 0.1593787\n",
      "Validation loss decreased (0.137388 --> 0.137123).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1099469\n",
      "\tspeed: 0.0725s/iter; left time: 123.9167s\n",
      "\titers: 200, epoch: 13 | loss: 0.1096227\n",
      "\tspeed: 0.0360s/iter; left time: 58.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 226 | Train Loss: 0.1108269 Vali Loss: 0.1365433 Test Loss: 0.1597832\n",
      "Validation loss decreased (0.137123 --> 0.136543).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1104019\n",
      "\tspeed: 0.0721s/iter; left time: 106.8892s\n",
      "\titers: 200, epoch: 14 | loss: 0.1130025\n",
      "\tspeed: 0.0363s/iter; left time: 50.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 226 | Train Loss: 0.1103357 Vali Loss: 0.1366921 Test Loss: 0.1602311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1088844\n",
      "\tspeed: 0.0716s/iter; left time: 90.0124s\n",
      "\titers: 200, epoch: 15 | loss: 0.1068849\n",
      "\tspeed: 0.0360s/iter; left time: 41.6017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 226 | Train Loss: 0.1100378 Vali Loss: 0.1363607 Test Loss: 0.1593052\n",
      "Validation loss decreased (0.136543 --> 0.136361).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1097190\n",
      "\tspeed: 0.0727s/iter; left time: 74.9868s\n",
      "\titers: 200, epoch: 16 | loss: 0.1123788\n",
      "\tspeed: 0.0362s/iter; left time: 33.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 226 | Train Loss: 0.1098495 Vali Loss: 0.1361489 Test Loss: 0.1594585\n",
      "Validation loss decreased (0.136361 --> 0.136149).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1118869\n",
      "\tspeed: 0.0724s/iter; left time: 58.3090s\n",
      "\titers: 200, epoch: 17 | loss: 0.1112123\n",
      "\tspeed: 0.0359s/iter; left time: 25.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 226 | Train Loss: 0.1095969 Vali Loss: 0.1364258 Test Loss: 0.1598473\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1131335\n",
      "\tspeed: 0.0716s/iter; left time: 41.4714s\n",
      "\titers: 200, epoch: 18 | loss: 0.1099465\n",
      "\tspeed: 0.0367s/iter; left time: 17.5643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.1093875 Vali Loss: 0.1358813 Test Loss: 0.1589869\n",
      "Validation loss decreased (0.136149 --> 0.135881).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1049459\n",
      "\tspeed: 0.0727s/iter; left time: 25.6496s\n",
      "\titers: 200, epoch: 19 | loss: 0.1083981\n",
      "\tspeed: 0.0360s/iter; left time: 9.1182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 226 | Train Loss: 0.1091260 Vali Loss: 0.1359261 Test Loss: 0.1589147\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1113433\n",
      "\tspeed: 0.0700s/iter; left time: 8.8947s\n",
      "\titers: 200, epoch: 20 | loss: 0.1055827\n",
      "\tspeed: 0.0358s/iter; left time: 0.9664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 226 | Train Loss: 0.1089990 Vali Loss: 0.1356704 Test Loss: 0.1584348\n",
      "Validation loss decreased (0.135881 --> 0.135670).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07960689812898636, rmse:0.2821469306945801, mae:0.15844303369522095, rse:1.0914193391799927\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2544356\n",
      "\tspeed: 0.0401s/iter; left time: 177.2053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2335267\n",
      "\tspeed: 0.0371s/iter; left time: 160.2725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.72s\n",
      "Steps: 226 | Train Loss: 0.2576508 Vali Loss: 0.2351593 Test Loss: 0.2528761\n",
      "Validation loss decreased (inf --> 0.235159).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1573309\n",
      "\tspeed: 0.0725s/iter; left time: 304.0111s\n",
      "\titers: 200, epoch: 2 | loss: 0.1359254\n",
      "\tspeed: 0.0363s/iter; left time: 148.5202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 226 | Train Loss: 0.1618749 Vali Loss: 0.1559907 Test Loss: 0.1807799\n",
      "Validation loss decreased (0.235159 --> 0.155991).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1278612\n",
      "\tspeed: 0.0717s/iter; left time: 284.5957s\n",
      "\titers: 200, epoch: 3 | loss: 0.1205113\n",
      "\tspeed: 0.0356s/iter; left time: 137.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 226 | Train Loss: 0.1265906 Vali Loss: 0.1456780 Test Loss: 0.1688919\n",
      "Validation loss decreased (0.155991 --> 0.145678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1226149\n",
      "\tspeed: 0.0712s/iter; left time: 266.6316s\n",
      "\titers: 200, epoch: 4 | loss: 0.1185307\n",
      "\tspeed: 0.0356s/iter; left time: 129.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 226 | Train Loss: 0.1185696 Vali Loss: 0.1394389 Test Loss: 0.1625482\n",
      "Validation loss decreased (0.145678 --> 0.139439).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1137969\n",
      "\tspeed: 0.0713s/iter; left time: 250.6576s\n",
      "\titers: 200, epoch: 5 | loss: 0.1178054\n",
      "\tspeed: 0.0355s/iter; left time: 121.3063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 226 | Train Loss: 0.1154920 Vali Loss: 0.1387098 Test Loss: 0.1614897\n",
      "Validation loss decreased (0.139439 --> 0.138710).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1133963\n",
      "\tspeed: 0.0708s/iter; left time: 232.9943s\n",
      "\titers: 200, epoch: 6 | loss: 0.1129407\n",
      "\tspeed: 0.0358s/iter; left time: 114.3888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 226 | Train Loss: 0.1138122 Vali Loss: 0.1374213 Test Loss: 0.1600241\n",
      "Validation loss decreased (0.138710 --> 0.137421).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1151640\n",
      "\tspeed: 0.0707s/iter; left time: 216.7867s\n",
      "\titers: 200, epoch: 7 | loss: 0.1141736\n",
      "\tspeed: 0.0359s/iter; left time: 106.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 226 | Train Loss: 0.1127349 Vali Loss: 0.1366322 Test Loss: 0.1602296\n",
      "Validation loss decreased (0.137421 --> 0.136632).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1163634\n",
      "\tspeed: 0.0705s/iter; left time: 200.1659s\n",
      "\titers: 200, epoch: 8 | loss: 0.1095980\n",
      "\tspeed: 0.0356s/iter; left time: 97.5432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.36s\n",
      "Steps: 226 | Train Loss: 0.1119138 Vali Loss: 0.1362890 Test Loss: 0.1597734\n",
      "Validation loss decreased (0.136632 --> 0.136289).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1113533\n",
      "\tspeed: 0.0711s/iter; left time: 185.7126s\n",
      "\titers: 200, epoch: 9 | loss: 0.1124547\n",
      "\tspeed: 0.0358s/iter; left time: 89.9630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 226 | Train Loss: 0.1111716 Vali Loss: 0.1358793 Test Loss: 0.1584020\n",
      "Validation loss decreased (0.136289 --> 0.135879).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1075953\n",
      "\tspeed: 0.0704s/iter; left time: 168.0087s\n",
      "\titers: 200, epoch: 10 | loss: 0.1064761\n",
      "\tspeed: 0.0358s/iter; left time: 81.8381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 226 | Train Loss: 0.1107207 Vali Loss: 0.1363144 Test Loss: 0.1600352\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1067812\n",
      "\tspeed: 0.0706s/iter; left time: 152.6506s\n",
      "\titers: 200, epoch: 11 | loss: 0.1107539\n",
      "\tspeed: 0.0357s/iter; left time: 73.5600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 226 | Train Loss: 0.1103092 Vali Loss: 0.1351533 Test Loss: 0.1581494\n",
      "Validation loss decreased (0.135879 --> 0.135153).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1102595\n",
      "\tspeed: 0.0712s/iter; left time: 137.8187s\n",
      "\titers: 200, epoch: 12 | loss: 0.1109269\n",
      "\tspeed: 0.0357s/iter; left time: 65.5813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 226 | Train Loss: 0.1098104 Vali Loss: 0.1353113 Test Loss: 0.1584510\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1086923\n",
      "\tspeed: 0.0731s/iter; left time: 124.9867s\n",
      "\titers: 200, epoch: 13 | loss: 0.1104603\n",
      "\tspeed: 0.0360s/iter; left time: 57.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 226 | Train Loss: 0.1095439 Vali Loss: 0.1352118 Test Loss: 0.1578940\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1063033\n",
      "\tspeed: 0.0698s/iter; left time: 103.5428s\n",
      "\titers: 200, epoch: 14 | loss: 0.1081202\n",
      "\tspeed: 0.0353s/iter; left time: 48.8542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 226 | Train Loss: 0.1092570 Vali Loss: 0.1359249 Test Loss: 0.1577429\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1049073\n",
      "\tspeed: 0.0704s/iter; left time: 88.4986s\n",
      "\titers: 200, epoch: 15 | loss: 0.1103418\n",
      "\tspeed: 0.0356s/iter; left time: 41.1864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 226 | Train Loss: 0.1089439 Vali Loss: 0.1352208 Test Loss: 0.1576614\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1073186\n",
      "\tspeed: 0.0709s/iter; left time: 73.0632s\n",
      "\titers: 200, epoch: 16 | loss: 0.1100885\n",
      "\tspeed: 0.0357s/iter; left time: 33.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 226 | Train Loss: 0.1086839 Vali Loss: 0.1352955 Test Loss: 0.1577068\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07914045453071594, rmse:0.28131914138793945, mae:0.15817812085151672, rse:1.0882171392440796\n",
      "Intermediate time for FR and pred_len 96: 00h:06m:40.22s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2710388\n",
      "\tspeed: 0.0688s/iter; left time: 302.9577s\n",
      "\titers: 200, epoch: 1 | loss: 0.2377171\n",
      "\tspeed: 0.0454s/iter; left time: 195.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.92s\n",
      "Steps: 225 | Train Loss: 0.2698364 Vali Loss: 0.2345628 Test Loss: 0.2541006\n",
      "Validation loss decreased (inf --> 0.234563).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1664434\n",
      "\tspeed: 0.0882s/iter; left time: 368.2300s\n",
      "\titers: 200, epoch: 2 | loss: 0.1472564\n",
      "\tspeed: 0.0462s/iter; left time: 188.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.66s\n",
      "Steps: 225 | Train Loss: 0.1683006 Vali Loss: 0.1751234 Test Loss: 0.2011595\n",
      "Validation loss decreased (0.234563 --> 0.175123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1335751\n",
      "\tspeed: 0.0873s/iter; left time: 344.7370s\n",
      "\titers: 200, epoch: 3 | loss: 0.1286593\n",
      "\tspeed: 0.0465s/iter; left time: 178.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.77s\n",
      "Steps: 225 | Train Loss: 0.1350909 Vali Loss: 0.1585200 Test Loss: 0.1822521\n",
      "Validation loss decreased (0.175123 --> 0.158520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1240638\n",
      "\tspeed: 0.0894s/iter; left time: 333.1145s\n",
      "\titers: 200, epoch: 4 | loss: 0.1234467\n",
      "\tspeed: 0.0456s/iter; left time: 165.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.62s\n",
      "Steps: 225 | Train Loss: 0.1250637 Vali Loss: 0.1491440 Test Loss: 0.1723177\n",
      "Validation loss decreased (0.158520 --> 0.149144).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1217355\n",
      "\tspeed: 0.0854s/iter; left time: 298.9431s\n",
      "\titers: 200, epoch: 5 | loss: 0.1192519\n",
      "\tspeed: 0.0460s/iter; left time: 156.3110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 225 | Train Loss: 0.1212141 Vali Loss: 0.1457728 Test Loss: 0.1687603\n",
      "Validation loss decreased (0.149144 --> 0.145773).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1198286\n",
      "\tspeed: 0.0870s/iter; left time: 285.1223s\n",
      "\titers: 200, epoch: 6 | loss: 0.1230412\n",
      "\tspeed: 0.0456s/iter; left time: 144.8123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.59s\n",
      "Steps: 225 | Train Loss: 0.1194899 Vali Loss: 0.1441735 Test Loss: 0.1675639\n",
      "Validation loss decreased (0.145773 --> 0.144173).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1160137\n",
      "\tspeed: 0.0887s/iter; left time: 270.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.1162511\n",
      "\tspeed: 0.0454s/iter; left time: 134.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1183961 Vali Loss: 0.1439017 Test Loss: 0.1675642\n",
      "Validation loss decreased (0.144173 --> 0.143902).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1175593\n",
      "\tspeed: 0.0875s/iter; left time: 247.3787s\n",
      "\titers: 200, epoch: 8 | loss: 0.1186083\n",
      "\tspeed: 0.0458s/iter; left time: 124.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.63s\n",
      "Steps: 225 | Train Loss: 0.1175156 Vali Loss: 0.1434067 Test Loss: 0.1670507\n",
      "Validation loss decreased (0.143902 --> 0.143407).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1217218\n",
      "\tspeed: 0.0878s/iter; left time: 228.4005s\n",
      "\titers: 200, epoch: 9 | loss: 0.1158845\n",
      "\tspeed: 0.0456s/iter; left time: 114.0401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.1167780 Vali Loss: 0.1429874 Test Loss: 0.1661395\n",
      "Validation loss decreased (0.143407 --> 0.142987).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1164055\n",
      "\tspeed: 0.0865s/iter; left time: 205.4507s\n",
      "\titers: 200, epoch: 10 | loss: 0.1165589\n",
      "\tspeed: 0.0453s/iter; left time: 103.1393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.1162201 Vali Loss: 0.1438408 Test Loss: 0.1676510\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1177056\n",
      "\tspeed: 0.0859s/iter; left time: 184.7374s\n",
      "\titers: 200, epoch: 11 | loss: 0.1142041\n",
      "\tspeed: 0.0457s/iter; left time: 93.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1157783 Vali Loss: 0.1432416 Test Loss: 0.1671983\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1158498\n",
      "\tspeed: 0.0860s/iter; left time: 165.6598s\n",
      "\titers: 200, epoch: 12 | loss: 0.1191326\n",
      "\tspeed: 0.0453s/iter; left time: 82.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 225 | Train Loss: 0.1153289 Vali Loss: 0.1422886 Test Loss: 0.1663659\n",
      "Validation loss decreased (0.142987 --> 0.142289).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1169306\n",
      "\tspeed: 0.0871s/iter; left time: 148.0964s\n",
      "\titers: 200, epoch: 13 | loss: 0.1146642\n",
      "\tspeed: 0.0455s/iter; left time: 72.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1150017 Vali Loss: 0.1422134 Test Loss: 0.1662599\n",
      "Validation loss decreased (0.142289 --> 0.142213).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1181377\n",
      "\tspeed: 0.0873s/iter; left time: 128.8519s\n",
      "\titers: 200, epoch: 14 | loss: 0.1160175\n",
      "\tspeed: 0.0455s/iter; left time: 62.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1147521 Vali Loss: 0.1427258 Test Loss: 0.1666992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1108920\n",
      "\tspeed: 0.0856s/iter; left time: 107.1404s\n",
      "\titers: 200, epoch: 15 | loss: 0.1121829\n",
      "\tspeed: 0.0456s/iter; left time: 52.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1144061 Vali Loss: 0.1430697 Test Loss: 0.1680770\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1130244\n",
      "\tspeed: 0.0854s/iter; left time: 87.6109s\n",
      "\titers: 200, epoch: 16 | loss: 0.1110011\n",
      "\tspeed: 0.0456s/iter; left time: 42.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 225 | Train Loss: 0.1142441 Vali Loss: 0.1418580 Test Loss: 0.1660047\n",
      "Validation loss decreased (0.142213 --> 0.141858).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1101674\n",
      "\tspeed: 0.0873s/iter; left time: 69.9011s\n",
      "\titers: 200, epoch: 17 | loss: 0.1150975\n",
      "\tspeed: 0.0456s/iter; left time: 31.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1138548 Vali Loss: 0.1408361 Test Loss: 0.1642556\n",
      "Validation loss decreased (0.141858 --> 0.140836).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1132001\n",
      "\tspeed: 0.0868s/iter; left time: 49.9735s\n",
      "\titers: 200, epoch: 18 | loss: 0.1107622\n",
      "\tspeed: 0.0458s/iter; left time: 21.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.63s\n",
      "Steps: 225 | Train Loss: 0.1134841 Vali Loss: 0.1405897 Test Loss: 0.1641935\n",
      "Validation loss decreased (0.140836 --> 0.140590).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1117647\n",
      "\tspeed: 0.0878s/iter; left time: 30.8143s\n",
      "\titers: 200, epoch: 19 | loss: 0.1125062\n",
      "\tspeed: 0.0453s/iter; left time: 11.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.50s\n",
      "Steps: 225 | Train Loss: 0.1129933 Vali Loss: 0.1396613 Test Loss: 0.1633240\n",
      "Validation loss decreased (0.140590 --> 0.139661).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1133916\n",
      "\tspeed: 0.0867s/iter; left time: 10.9199s\n",
      "\titers: 200, epoch: 20 | loss: 0.1073655\n",
      "\tspeed: 0.0459s/iter; left time: 1.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.62s\n",
      "Steps: 225 | Train Loss: 0.1084388 Vali Loss: 0.1239390 Test Loss: 0.1456682\n",
      "Validation loss decreased (0.139661 --> 0.123939).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.058162953704595566, rmse:0.2411699742078781, mae:0.1457083821296692, rse:0.9340741634368896\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2368117\n",
      "\tspeed: 0.0473s/iter; left time: 208.2604s\n",
      "\titers: 200, epoch: 1 | loss: 0.2169962\n",
      "\tspeed: 0.0452s/iter; left time: 194.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.44s\n",
      "Steps: 225 | Train Loss: 0.2382082 Vali Loss: 0.2287292 Test Loss: 0.2509134\n",
      "Validation loss decreased (inf --> 0.228729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1504753\n",
      "\tspeed: 0.0905s/iter; left time: 378.1252s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390685\n",
      "\tspeed: 0.0449s/iter; left time: 183.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.44s\n",
      "Steps: 225 | Train Loss: 0.1564642 Vali Loss: 0.1648384 Test Loss: 0.1893210\n",
      "Validation loss decreased (0.228729 --> 0.164838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1340137\n",
      "\tspeed: 0.0857s/iter; left time: 338.4808s\n",
      "\titers: 200, epoch: 3 | loss: 0.1244672\n",
      "\tspeed: 0.0450s/iter; left time: 173.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.44s\n",
      "Steps: 225 | Train Loss: 0.1272247 Vali Loss: 0.1507960 Test Loss: 0.1737160\n",
      "Validation loss decreased (0.164838 --> 0.150796).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190886\n",
      "\tspeed: 0.0872s/iter; left time: 324.8396s\n",
      "\titers: 200, epoch: 4 | loss: 0.1199658\n",
      "\tspeed: 0.0454s/iter; left time: 164.4860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 225 | Train Loss: 0.1210976 Vali Loss: 0.1478613 Test Loss: 0.1705744\n",
      "Validation loss decreased (0.150796 --> 0.147861).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1180765\n",
      "\tspeed: 0.0868s/iter; left time: 303.8182s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183109\n",
      "\tspeed: 0.0454s/iter; left time: 154.4985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 225 | Train Loss: 0.1190224 Vali Loss: 0.1461831 Test Loss: 0.1690830\n",
      "Validation loss decreased (0.147861 --> 0.146183).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1203409\n",
      "\tspeed: 0.0876s/iter; left time: 286.9237s\n",
      "\titers: 200, epoch: 6 | loss: 0.1169616\n",
      "\tspeed: 0.0461s/iter; left time: 146.3674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.67s\n",
      "Steps: 225 | Train Loss: 0.1175615 Vali Loss: 0.1437948 Test Loss: 0.1666466\n",
      "Validation loss decreased (0.146183 --> 0.143795).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1164420\n",
      "\tspeed: 0.0888s/iter; left time: 270.8997s\n",
      "\titers: 200, epoch: 7 | loss: 0.1216807\n",
      "\tspeed: 0.0458s/iter; left time: 135.2793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.70s\n",
      "Steps: 225 | Train Loss: 0.1165494 Vali Loss: 0.1442808 Test Loss: 0.1676705\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1149203\n",
      "\tspeed: 0.0853s/iter; left time: 241.1961s\n",
      "\titers: 200, epoch: 8 | loss: 0.1148235\n",
      "\tspeed: 0.0457s/iter; left time: 124.5134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1157640 Vali Loss: 0.1430776 Test Loss: 0.1671387\n",
      "Validation loss decreased (0.143795 --> 0.143078).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1126568\n",
      "\tspeed: 0.0866s/iter; left time: 225.1423s\n",
      "\titers: 200, epoch: 9 | loss: 0.1158942\n",
      "\tspeed: 0.0453s/iter; left time: 113.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.1152046 Vali Loss: 0.1426099 Test Loss: 0.1676257\n",
      "Validation loss decreased (0.143078 --> 0.142610).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1138073\n",
      "\tspeed: 0.0876s/iter; left time: 208.0764s\n",
      "\titers: 200, epoch: 10 | loss: 0.1154144\n",
      "\tspeed: 0.0454s/iter; left time: 103.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 225 | Train Loss: 0.1147775 Vali Loss: 0.1423470 Test Loss: 0.1669241\n",
      "Validation loss decreased (0.142610 --> 0.142347).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1145327\n",
      "\tspeed: 0.0874s/iter; left time: 187.9225s\n",
      "\titers: 200, epoch: 11 | loss: 0.1128664\n",
      "\tspeed: 0.0450s/iter; left time: 92.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.1143358 Vali Loss: 0.1419589 Test Loss: 0.1659772\n",
      "Validation loss decreased (0.142347 --> 0.141959).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1130639\n",
      "\tspeed: 0.0878s/iter; left time: 169.0214s\n",
      "\titers: 200, epoch: 12 | loss: 0.1123998\n",
      "\tspeed: 0.0456s/iter; left time: 83.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 225 | Train Loss: 0.1140116 Vali Loss: 0.1421637 Test Loss: 0.1657816\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1148280\n",
      "\tspeed: 0.0854s/iter; left time: 145.2744s\n",
      "\titers: 200, epoch: 13 | loss: 0.1128614\n",
      "\tspeed: 0.0455s/iter; left time: 72.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1136253 Vali Loss: 0.1422620 Test Loss: 0.1672119\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1132743\n",
      "\tspeed: 0.0847s/iter; left time: 124.9633s\n",
      "\titers: 200, epoch: 14 | loss: 0.1132438\n",
      "\tspeed: 0.0452s/iter; left time: 62.1944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.42s\n",
      "Steps: 225 | Train Loss: 0.1133908 Vali Loss: 0.1416748 Test Loss: 0.1667121\n",
      "Validation loss decreased (0.141959 --> 0.141675).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1095861\n",
      "\tspeed: 0.0856s/iter; left time: 107.0563s\n",
      "\titers: 200, epoch: 15 | loss: 0.1124988\n",
      "\tspeed: 0.0454s/iter; left time: 52.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1131024 Vali Loss: 0.1413144 Test Loss: 0.1662286\n",
      "Validation loss decreased (0.141675 --> 0.141314).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1117279\n",
      "\tspeed: 0.0865s/iter; left time: 88.7551s\n",
      "\titers: 200, epoch: 16 | loss: 0.1168421\n",
      "\tspeed: 0.0457s/iter; left time: 42.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.59s\n",
      "Steps: 225 | Train Loss: 0.1130128 Vali Loss: 0.1419405 Test Loss: 0.1662359\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1142082\n",
      "\tspeed: 0.0863s/iter; left time: 69.1315s\n",
      "\titers: 200, epoch: 17 | loss: 0.1114332\n",
      "\tspeed: 0.0454s/iter; left time: 31.8069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 225 | Train Loss: 0.1127405 Vali Loss: 0.1414985 Test Loss: 0.1665936\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1135014\n",
      "\tspeed: 0.0863s/iter; left time: 49.7119s\n",
      "\titers: 200, epoch: 18 | loss: 0.1137701\n",
      "\tspeed: 0.0455s/iter; left time: 21.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.1126839 Vali Loss: 0.1414437 Test Loss: 0.1665137\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1134195\n",
      "\tspeed: 0.0863s/iter; left time: 30.2901s\n",
      "\titers: 200, epoch: 19 | loss: 0.1145658\n",
      "\tspeed: 0.0454s/iter; left time: 11.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.56s\n",
      "Steps: 225 | Train Loss: 0.1124830 Vali Loss: 0.1416815 Test Loss: 0.1663119\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1151375\n",
      "\tspeed: 0.0861s/iter; left time: 10.8495s\n",
      "\titers: 200, epoch: 20 | loss: 0.1111932\n",
      "\tspeed: 0.0462s/iter; left time: 1.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.64s\n",
      "Steps: 225 | Train Loss: 0.1123512 Vali Loss: 0.1414074 Test Loss: 0.1665253\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.08351708948612213, rmse:0.288993239402771, mae:0.16628709435462952, rse:1.1192981004714966\n",
      "Intermediate time for FR and pred_len 168: 00h:09m:01.82s\n",
      "Intermediate time for FR: 00h:21m:53.68s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3235262\n",
      "\tspeed: 0.0543s/iter; left time: 239.9878s\n",
      "\titers: 200, epoch: 1 | loss: 0.2947414\n",
      "\tspeed: 0.0316s/iter; left time: 136.7274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.82s\n",
      "Steps: 226 | Train Loss: 0.3245132 Vali Loss: 0.2867514 Test Loss: 0.2913297\n",
      "Validation loss decreased (inf --> 0.286751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2129966\n",
      "\tspeed: 0.0622s/iter; left time: 261.1360s\n",
      "\titers: 200, epoch: 2 | loss: 0.1733197\n",
      "\tspeed: 0.0317s/iter; left time: 129.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.50s\n",
      "Steps: 226 | Train Loss: 0.2077673 Vali Loss: 0.1610002 Test Loss: 0.1801899\n",
      "Validation loss decreased (0.286751 --> 0.161000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1536565\n",
      "\tspeed: 0.0624s/iter; left time: 247.4786s\n",
      "\titers: 200, epoch: 3 | loss: 0.1435415\n",
      "\tspeed: 0.0315s/iter; left time: 122.0140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.49s\n",
      "Steps: 226 | Train Loss: 0.1545577 Vali Loss: 0.1466698 Test Loss: 0.1630588\n",
      "Validation loss decreased (0.161000 --> 0.146670).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1462462\n",
      "\tspeed: 0.0633s/iter; left time: 236.9244s\n",
      "\titers: 200, epoch: 4 | loss: 0.1377596\n",
      "\tspeed: 0.0319s/iter; left time: 116.3696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1415325 Vali Loss: 0.1396169 Test Loss: 0.1564471\n",
      "Validation loss decreased (0.146670 --> 0.139617).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1359064\n",
      "\tspeed: 0.0625s/iter; left time: 219.6786s\n",
      "\titers: 200, epoch: 5 | loss: 0.1346487\n",
      "\tspeed: 0.0318s/iter; left time: 108.5793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 226 | Train Loss: 0.1354367 Vali Loss: 0.1375286 Test Loss: 0.1539654\n",
      "Validation loss decreased (0.139617 --> 0.137529).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1311775\n",
      "\tspeed: 0.0637s/iter; left time: 209.5327s\n",
      "\titers: 200, epoch: 6 | loss: 0.1310913\n",
      "\tspeed: 0.0314s/iter; left time: 100.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.53s\n",
      "Steps: 226 | Train Loss: 0.1316315 Vali Loss: 0.1353711 Test Loss: 0.1517100\n",
      "Validation loss decreased (0.137529 --> 0.135371).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1262639\n",
      "\tspeed: 0.0613s/iter; left time: 187.7426s\n",
      "\titers: 200, epoch: 7 | loss: 0.1308507\n",
      "\tspeed: 0.0312s/iter; left time: 92.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1291618 Vali Loss: 0.1334088 Test Loss: 0.1493991\n",
      "Validation loss decreased (0.135371 --> 0.133409).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1350082\n",
      "\tspeed: 0.0612s/iter; left time: 173.7453s\n",
      "\titers: 200, epoch: 8 | loss: 0.1265897\n",
      "\tspeed: 0.0324s/iter; left time: 88.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 226 | Train Loss: 0.1273229 Vali Loss: 0.1300535 Test Loss: 0.1468810\n",
      "Validation loss decreased (0.133409 --> 0.130053).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1265648\n",
      "\tspeed: 0.0618s/iter; left time: 161.5625s\n",
      "\titers: 200, epoch: 9 | loss: 0.1282344\n",
      "\tspeed: 0.0311s/iter; left time: 78.2389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.1257730 Vali Loss: 0.1304904 Test Loss: 0.1470915\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1212332\n",
      "\tspeed: 0.0598s/iter; left time: 142.8496s\n",
      "\titers: 200, epoch: 10 | loss: 0.1228779\n",
      "\tspeed: 0.0309s/iter; left time: 70.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.25s\n",
      "Steps: 226 | Train Loss: 0.1244145 Vali Loss: 0.1305181 Test Loss: 0.1464777\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1214684\n",
      "\tspeed: 0.0613s/iter; left time: 132.4912s\n",
      "\titers: 200, epoch: 11 | loss: 0.1256010\n",
      "\tspeed: 0.0308s/iter; left time: 63.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1234222 Vali Loss: 0.1294077 Test Loss: 0.1453450\n",
      "Validation loss decreased (0.130053 --> 0.129408).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1201006\n",
      "\tspeed: 0.0603s/iter; left time: 116.7456s\n",
      "\titers: 200, epoch: 12 | loss: 0.1167392\n",
      "\tspeed: 0.0309s/iter; left time: 56.7464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.1228648 Vali Loss: 0.1275276 Test Loss: 0.1441311\n",
      "Validation loss decreased (0.129408 --> 0.127528).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1247723\n",
      "\tspeed: 0.0613s/iter; left time: 104.7881s\n",
      "\titers: 200, epoch: 13 | loss: 0.1185699\n",
      "\tspeed: 0.0310s/iter; left time: 49.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.33s\n",
      "Steps: 226 | Train Loss: 0.1222027 Vali Loss: 0.1265191 Test Loss: 0.1433391\n",
      "Validation loss decreased (0.127528 --> 0.126519).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1203067\n",
      "\tspeed: 0.0612s/iter; left time: 90.8172s\n",
      "\titers: 200, epoch: 14 | loss: 0.1195131\n",
      "\tspeed: 0.0311s/iter; left time: 42.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.1216872 Vali Loss: 0.1262472 Test Loss: 0.1431967\n",
      "Validation loss decreased (0.126519 --> 0.126247).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1216466\n",
      "\tspeed: 0.0613s/iter; left time: 76.9947s\n",
      "\titers: 200, epoch: 15 | loss: 0.1240479\n",
      "\tspeed: 0.0310s/iter; left time: 35.8783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.1212961 Vali Loss: 0.1262104 Test Loss: 0.1428905\n",
      "Validation loss decreased (0.126247 --> 0.126210).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1222371\n",
      "\tspeed: 0.0605s/iter; left time: 62.4102s\n",
      "\titers: 200, epoch: 16 | loss: 0.1283023\n",
      "\tspeed: 0.0311s/iter; left time: 28.9602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.1209204 Vali Loss: 0.1254271 Test Loss: 0.1426470\n",
      "Validation loss decreased (0.126210 --> 0.125427).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1209252\n",
      "\tspeed: 0.0606s/iter; left time: 48.7603s\n",
      "\titers: 200, epoch: 17 | loss: 0.1254366\n",
      "\tspeed: 0.0315s/iter; left time: 22.2204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1206108 Vali Loss: 0.1250828 Test Loss: 0.1421264\n",
      "Validation loss decreased (0.125427 --> 0.125083).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1156558\n",
      "\tspeed: 0.0610s/iter; left time: 35.2943s\n",
      "\titers: 200, epoch: 18 | loss: 0.1216989\n",
      "\tspeed: 0.0316s/iter; left time: 15.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 226 | Train Loss: 0.1203502 Vali Loss: 0.1255819 Test Loss: 0.1424930\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1221352\n",
      "\tspeed: 0.0604s/iter; left time: 21.3292s\n",
      "\titers: 200, epoch: 19 | loss: 0.1218341\n",
      "\tspeed: 0.0309s/iter; left time: 7.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.1200704 Vali Loss: 0.1249272 Test Loss: 0.1420950\n",
      "Validation loss decreased (0.125083 --> 0.124927).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1154615\n",
      "\tspeed: 0.0619s/iter; left time: 7.8655s\n",
      "\titers: 200, epoch: 20 | loss: 0.1189166\n",
      "\tspeed: 0.0310s/iter; left time: 0.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.34s\n",
      "Steps: 226 | Train Loss: 0.1199144 Vali Loss: 0.1242100 Test Loss: 0.1413907\n",
      "Validation loss decreased (0.124927 --> 0.124210).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.06774772703647614, rmse:0.2602839469909668, mae:0.14135020971298218, rse:0.9834848642349243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3350616\n",
      "\tspeed: 0.0338s/iter; left time: 149.5598s\n",
      "\titers: 200, epoch: 1 | loss: 0.3130561\n",
      "\tspeed: 0.0317s/iter; left time: 136.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 226 | Train Loss: 0.3324660 Vali Loss: 0.2966985 Test Loss: 0.3007135\n",
      "Validation loss decreased (inf --> 0.296698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2035012\n",
      "\tspeed: 0.0603s/iter; left time: 252.8402s\n",
      "\titers: 200, epoch: 2 | loss: 0.1741216\n",
      "\tspeed: 0.0309s/iter; left time: 126.7353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.2080762 Vali Loss: 0.1636146 Test Loss: 0.1806969\n",
      "Validation loss decreased (0.296698 --> 0.163615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1548401\n",
      "\tspeed: 0.0597s/iter; left time: 236.8435s\n",
      "\titers: 200, epoch: 3 | loss: 0.1431384\n",
      "\tspeed: 0.0309s/iter; left time: 119.4186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 226 | Train Loss: 0.1545287 Vali Loss: 0.1497114 Test Loss: 0.1650219\n",
      "Validation loss decreased (0.163615 --> 0.149711).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1385174\n",
      "\tspeed: 0.0612s/iter; left time: 229.1188s\n",
      "\titers: 200, epoch: 4 | loss: 0.1382230\n",
      "\tspeed: 0.0309s/iter; left time: 112.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.1406126 Vali Loss: 0.1459548 Test Loss: 0.1606917\n",
      "Validation loss decreased (0.149711 --> 0.145955).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1336613\n",
      "\tspeed: 0.0598s/iter; left time: 210.3201s\n",
      "\titers: 200, epoch: 5 | loss: 0.1303143\n",
      "\tspeed: 0.0309s/iter; left time: 105.7416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.26s\n",
      "Steps: 226 | Train Loss: 0.1344137 Vali Loss: 0.1402734 Test Loss: 0.1552464\n",
      "Validation loss decreased (0.145955 --> 0.140273).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1337976\n",
      "\tspeed: 0.0602s/iter; left time: 198.1861s\n",
      "\titers: 200, epoch: 6 | loss: 0.1315307\n",
      "\tspeed: 0.0314s/iter; left time: 100.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.39s\n",
      "Steps: 226 | Train Loss: 0.1304393 Vali Loss: 0.1345640 Test Loss: 0.1515583\n",
      "Validation loss decreased (0.140273 --> 0.134564).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1250639\n",
      "\tspeed: 0.0603s/iter; left time: 184.7910s\n",
      "\titers: 200, epoch: 7 | loss: 0.1294717\n",
      "\tspeed: 0.0308s/iter; left time: 91.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 226 | Train Loss: 0.1279640 Vali Loss: 0.1316012 Test Loss: 0.1483842\n",
      "Validation loss decreased (0.134564 --> 0.131601).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1297368\n",
      "\tspeed: 0.0605s/iter; left time: 171.6917s\n",
      "\titers: 200, epoch: 8 | loss: 0.1236270\n",
      "\tspeed: 0.0311s/iter; left time: 85.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.37s\n",
      "Steps: 226 | Train Loss: 0.1261469 Vali Loss: 0.1295742 Test Loss: 0.1459938\n",
      "Validation loss decreased (0.131601 --> 0.129574).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1237106\n",
      "\tspeed: 0.0610s/iter; left time: 159.3989s\n",
      "\titers: 200, epoch: 9 | loss: 0.1137382\n",
      "\tspeed: 0.0312s/iter; left time: 78.5088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1245366 Vali Loss: 0.1292264 Test Loss: 0.1452724\n",
      "Validation loss decreased (0.129574 --> 0.129226).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1217264\n",
      "\tspeed: 0.0603s/iter; left time: 143.8873s\n",
      "\titers: 200, epoch: 10 | loss: 0.1229733\n",
      "\tspeed: 0.0310s/iter; left time: 70.9509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1235262 Vali Loss: 0.1288969 Test Loss: 0.1446041\n",
      "Validation loss decreased (0.129226 --> 0.128897).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1238100\n",
      "\tspeed: 0.0603s/iter; left time: 130.3780s\n",
      "\titers: 200, epoch: 11 | loss: 0.1247750\n",
      "\tspeed: 0.0312s/iter; left time: 64.2021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.31s\n",
      "Steps: 226 | Train Loss: 0.1226984 Vali Loss: 0.1267816 Test Loss: 0.1432519\n",
      "Validation loss decreased (0.128897 --> 0.126782).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1216834\n",
      "\tspeed: 0.0608s/iter; left time: 117.6152s\n",
      "\titers: 200, epoch: 12 | loss: 0.1204883\n",
      "\tspeed: 0.0309s/iter; left time: 56.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.30s\n",
      "Steps: 226 | Train Loss: 0.1219182 Vali Loss: 0.1273459 Test Loss: 0.1437076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1193808\n",
      "\tspeed: 0.0601s/iter; left time: 102.7171s\n",
      "\titers: 200, epoch: 13 | loss: 0.1265379\n",
      "\tspeed: 0.0311s/iter; left time: 50.0418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1213543 Vali Loss: 0.1268097 Test Loss: 0.1431511\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1216426\n",
      "\tspeed: 0.0595s/iter; left time: 88.1728s\n",
      "\titers: 200, epoch: 14 | loss: 0.1186039\n",
      "\tspeed: 0.0311s/iter; left time: 43.0452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 226 | Train Loss: 0.1208968 Vali Loss: 0.1264507 Test Loss: 0.1425885\n",
      "Validation loss decreased (0.126782 --> 0.126451).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1194646\n",
      "\tspeed: 0.0606s/iter; left time: 76.1235s\n",
      "\titers: 200, epoch: 15 | loss: 0.1183997\n",
      "\tspeed: 0.0311s/iter; left time: 35.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 226 | Train Loss: 0.1203546 Vali Loss: 0.1259366 Test Loss: 0.1423282\n",
      "Validation loss decreased (0.126451 --> 0.125937).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1231746\n",
      "\tspeed: 0.0604s/iter; left time: 62.2482s\n",
      "\titers: 200, epoch: 16 | loss: 0.1225275\n",
      "\tspeed: 0.0310s/iter; left time: 28.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.1201675 Vali Loss: 0.1259299 Test Loss: 0.1423547\n",
      "Validation loss decreased (0.125937 --> 0.125930).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1184430\n",
      "\tspeed: 0.0607s/iter; left time: 48.8669s\n",
      "\titers: 200, epoch: 17 | loss: 0.1242824\n",
      "\tspeed: 0.0317s/iter; left time: 22.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.38s\n",
      "Steps: 226 | Train Loss: 0.1197769 Vali Loss: 0.1245584 Test Loss: 0.1414025\n",
      "Validation loss decreased (0.125930 --> 0.124558).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1197780\n",
      "\tspeed: 0.0607s/iter; left time: 35.1482s\n",
      "\titers: 200, epoch: 18 | loss: 0.1258870\n",
      "\tspeed: 0.0312s/iter; left time: 14.9227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.35s\n",
      "Steps: 226 | Train Loss: 0.1196915 Vali Loss: 0.1250923 Test Loss: 0.1415668\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1188456\n",
      "\tspeed: 0.0598s/iter; left time: 21.1011s\n",
      "\titers: 200, epoch: 19 | loss: 0.1200979\n",
      "\tspeed: 0.0307s/iter; left time: 7.7724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.23s\n",
      "Steps: 226 | Train Loss: 0.1194041 Vali Loss: 0.1247021 Test Loss: 0.1410296\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1172074\n",
      "\tspeed: 0.0596s/iter; left time: 7.5716s\n",
      "\titers: 200, epoch: 20 | loss: 0.1186848\n",
      "\tspeed: 0.0310s/iter; left time: 0.8367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.29s\n",
      "Steps: 226 | Train Loss: 0.1191771 Vali Loss: 0.1242416 Test Loss: 0.1410991\n",
      "Validation loss decreased (0.124558 --> 0.124242).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.06736654788255692, rmse:0.25955066084861755, mae:0.14106279611587524, rse:0.9807142019271851\n",
      "Intermediate time for IT and pred_len 24: 00h:06m:18.80s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3117923\n",
      "\tspeed: 0.0613s/iter; left time: 270.8823s\n",
      "\titers: 200, epoch: 1 | loss: 0.2826721\n",
      "\tspeed: 0.0380s/iter; left time: 164.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.26s\n",
      "Steps: 226 | Train Loss: 0.3111652 Vali Loss: 0.2594322 Test Loss: 0.2724586\n",
      "Validation loss decreased (inf --> 0.259432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2042455\n",
      "\tspeed: 0.0736s/iter; left time: 308.6879s\n",
      "\titers: 200, epoch: 2 | loss: 0.1808358\n",
      "\tspeed: 0.0377s/iter; left time: 154.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 226 | Train Loss: 0.2093268 Vali Loss: 0.1653722 Test Loss: 0.1859858\n",
      "Validation loss decreased (0.259432 --> 0.165372).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1657456\n",
      "\tspeed: 0.0747s/iter; left time: 296.4726s\n",
      "\titers: 200, epoch: 3 | loss: 0.1542021\n",
      "\tspeed: 0.0373s/iter; left time: 144.2379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.82s\n",
      "Steps: 226 | Train Loss: 0.1655606 Vali Loss: 0.1401888 Test Loss: 0.1590467\n",
      "Validation loss decreased (0.165372 --> 0.140189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1306985\n",
      "\tspeed: 0.0742s/iter; left time: 277.8663s\n",
      "\titers: 200, epoch: 4 | loss: 0.1187444\n",
      "\tspeed: 0.0376s/iter; left time: 136.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.79s\n",
      "Steps: 226 | Train Loss: 0.1315708 Vali Loss: 0.1130955 Test Loss: 0.1207407\n",
      "Validation loss decreased (0.140189 --> 0.113096).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1167008\n",
      "\tspeed: 0.0737s/iter; left time: 259.3241s\n",
      "\titers: 200, epoch: 5 | loss: 0.1148278\n",
      "\tspeed: 0.0373s/iter; left time: 127.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 226 | Train Loss: 0.1166099 Vali Loss: 0.1069165 Test Loss: 0.1145172\n",
      "Validation loss decreased (0.113096 --> 0.106917).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1069865\n",
      "\tspeed: 0.0735s/iter; left time: 241.9270s\n",
      "\titers: 200, epoch: 6 | loss: 0.1115355\n",
      "\tspeed: 0.0373s/iter; left time: 118.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 226 | Train Loss: 0.1112258 Vali Loss: 0.1052597 Test Loss: 0.1114581\n",
      "Validation loss decreased (0.106917 --> 0.105260).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1076516\n",
      "\tspeed: 0.0739s/iter; left time: 226.4815s\n",
      "\titers: 200, epoch: 7 | loss: 0.1063606\n",
      "\tspeed: 0.0372s/iter; left time: 110.4417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.81s\n",
      "Steps: 226 | Train Loss: 0.1074602 Vali Loss: 0.1021268 Test Loss: 0.1077086\n",
      "Validation loss decreased (0.105260 --> 0.102127).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1036559\n",
      "\tspeed: 0.0729s/iter; left time: 206.8721s\n",
      "\titers: 200, epoch: 8 | loss: 0.1023701\n",
      "\tspeed: 0.0371s/iter; left time: 101.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.1045033 Vali Loss: 0.1003420 Test Loss: 0.1064199\n",
      "Validation loss decreased (0.102127 --> 0.100342).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1048426\n",
      "\tspeed: 0.0726s/iter; left time: 189.7445s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016122\n",
      "\tspeed: 0.0371s/iter; left time: 93.1783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1023478 Vali Loss: 0.0984003 Test Loss: 0.1047876\n",
      "Validation loss decreased (0.100342 --> 0.098400).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1009512\n",
      "\tspeed: 0.0728s/iter; left time: 173.8023s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003316\n",
      "\tspeed: 0.0371s/iter; left time: 84.9599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.1008727 Vali Loss: 0.0974910 Test Loss: 0.1035310\n",
      "Validation loss decreased (0.098400 --> 0.097491).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0990624\n",
      "\tspeed: 0.0739s/iter; left time: 159.6519s\n",
      "\titers: 200, epoch: 11 | loss: 0.0990606\n",
      "\tspeed: 0.0373s/iter; left time: 76.9341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 226 | Train Loss: 0.0996618 Vali Loss: 0.0977767 Test Loss: 0.1036989\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008467\n",
      "\tspeed: 0.0721s/iter; left time: 139.5478s\n",
      "\titers: 200, epoch: 12 | loss: 0.0987339\n",
      "\tspeed: 0.0371s/iter; left time: 68.0871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.0986973 Vali Loss: 0.0976713 Test Loss: 0.1035435\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0967789\n",
      "\tspeed: 0.0725s/iter; left time: 123.8276s\n",
      "\titers: 200, epoch: 13 | loss: 0.0973528\n",
      "\tspeed: 0.0369s/iter; left time: 59.4272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 226 | Train Loss: 0.0979368 Vali Loss: 0.0946207 Test Loss: 0.1010440\n",
      "Validation loss decreased (0.097491 --> 0.094621).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0958451\n",
      "\tspeed: 0.0726s/iter; left time: 107.7043s\n",
      "\titers: 200, epoch: 14 | loss: 0.0973529\n",
      "\tspeed: 0.0375s/iter; left time: 51.8496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.0973005 Vali Loss: 0.0952649 Test Loss: 0.1014898\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0961106\n",
      "\tspeed: 0.0725s/iter; left time: 91.1400s\n",
      "\titers: 200, epoch: 15 | loss: 0.0975293\n",
      "\tspeed: 0.0375s/iter; left time: 43.3978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 226 | Train Loss: 0.0967003 Vali Loss: 0.0953703 Test Loss: 0.1016553\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0948593\n",
      "\tspeed: 0.0732s/iter; left time: 75.5039s\n",
      "\titers: 200, epoch: 16 | loss: 0.0963626\n",
      "\tspeed: 0.0377s/iter; left time: 35.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.84s\n",
      "Steps: 226 | Train Loss: 0.0962189 Vali Loss: 0.0951829 Test Loss: 0.1010747\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0941575\n",
      "\tspeed: 0.0724s/iter; left time: 58.2773s\n",
      "\titers: 200, epoch: 17 | loss: 0.0969908\n",
      "\tspeed: 0.0373s/iter; left time: 26.2971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 226 | Train Loss: 0.0956716 Vali Loss: 0.0932936 Test Loss: 0.0998498\n",
      "Validation loss decreased (0.094621 --> 0.093294).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0928172\n",
      "\tspeed: 0.0731s/iter; left time: 42.3392s\n",
      "\titers: 200, epoch: 18 | loss: 0.0945846\n",
      "\tspeed: 0.0373s/iter; left time: 17.8603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.0952493 Vali Loss: 0.0933342 Test Loss: 0.0998776\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0955199\n",
      "\tspeed: 0.0720s/iter; left time: 25.4155s\n",
      "\titers: 200, epoch: 19 | loss: 0.0922768\n",
      "\tspeed: 0.0372s/iter; left time: 9.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.0948650 Vali Loss: 0.0937985 Test Loss: 0.1000346\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0962785\n",
      "\tspeed: 0.0722s/iter; left time: 9.1745s\n",
      "\titers: 200, epoch: 20 | loss: 0.0948163\n",
      "\tspeed: 0.0371s/iter; left time: 1.0022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.0946407 Vali Loss: 0.0931589 Test Loss: 0.0993505\n",
      "Validation loss decreased (0.093294 --> 0.093159).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022916091606020927, rmse:0.15138061344623566, mae:0.09937920421361923, rse:0.5723864436149597\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3048002\n",
      "\tspeed: 0.0401s/iter; left time: 177.1355s\n",
      "\titers: 200, epoch: 1 | loss: 0.2805236\n",
      "\tspeed: 0.0370s/iter; left time: 160.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 226 | Train Loss: 0.3006993 Vali Loss: 0.2648580 Test Loss: 0.2716488\n",
      "Validation loss decreased (inf --> 0.264858).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1960660\n",
      "\tspeed: 0.0740s/iter; left time: 310.3970s\n",
      "\titers: 200, epoch: 2 | loss: 0.1685132\n",
      "\tspeed: 0.0365s/iter; left time: 149.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 226 | Train Loss: 0.2015916 Vali Loss: 0.1663945 Test Loss: 0.1849986\n",
      "Validation loss decreased (0.264858 --> 0.166395).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1640876\n",
      "\tspeed: 0.0728s/iter; left time: 289.1144s\n",
      "\titers: 200, epoch: 3 | loss: 0.1573836\n",
      "\tspeed: 0.0375s/iter; left time: 145.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 226 | Train Loss: 0.1629480 Vali Loss: 0.1537360 Test Loss: 0.1733284\n",
      "Validation loss decreased (0.166395 --> 0.153736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1567562\n",
      "\tspeed: 0.0723s/iter; left time: 270.7856s\n",
      "\titers: 200, epoch: 4 | loss: 0.1521877\n",
      "\tspeed: 0.0371s/iter; left time: 135.0259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.1533201 Vali Loss: 0.1506243 Test Loss: 0.1708769\n",
      "Validation loss decreased (0.153736 --> 0.150624).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1473833\n",
      "\tspeed: 0.0720s/iter; left time: 253.0552s\n",
      "\titers: 200, epoch: 5 | loss: 0.1502476\n",
      "\tspeed: 0.0368s/iter; left time: 125.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 226 | Train Loss: 0.1492065 Vali Loss: 0.1473931 Test Loss: 0.1665449\n",
      "Validation loss decreased (0.150624 --> 0.147393).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1459737\n",
      "\tspeed: 0.0722s/iter; left time: 237.5166s\n",
      "\titers: 200, epoch: 6 | loss: 0.1466015\n",
      "\tspeed: 0.0369s/iter; left time: 117.8816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1469750 Vali Loss: 0.1455483 Test Loss: 0.1657653\n",
      "Validation loss decreased (0.147393 --> 0.145548).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1471837\n",
      "\tspeed: 0.0724s/iter; left time: 221.7853s\n",
      "\titers: 200, epoch: 7 | loss: 0.1434889\n",
      "\tspeed: 0.0377s/iter; left time: 111.7314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.76s\n",
      "Steps: 226 | Train Loss: 0.1453456 Vali Loss: 0.1455843 Test Loss: 0.1670961\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1521415\n",
      "\tspeed: 0.0721s/iter; left time: 204.6164s\n",
      "\titers: 200, epoch: 8 | loss: 0.1413356\n",
      "\tspeed: 0.0373s/iter; left time: 102.2147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 226 | Train Loss: 0.1439215 Vali Loss: 0.1439296 Test Loss: 0.1641677\n",
      "Validation loss decreased (0.145548 --> 0.143930).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1432353\n",
      "\tspeed: 0.0736s/iter; left time: 192.4014s\n",
      "\titers: 200, epoch: 9 | loss: 0.1421352\n",
      "\tspeed: 0.0371s/iter; left time: 93.2645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 226 | Train Loss: 0.1429051 Vali Loss: 0.1434445 Test Loss: 0.1633750\n",
      "Validation loss decreased (0.143930 --> 0.143444).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1424229\n",
      "\tspeed: 0.0730s/iter; left time: 174.3072s\n",
      "\titers: 200, epoch: 10 | loss: 0.1402130\n",
      "\tspeed: 0.0372s/iter; left time: 85.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.1421269 Vali Loss: 0.1429241 Test Loss: 0.1638133\n",
      "Validation loss decreased (0.143444 --> 0.142924).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1380753\n",
      "\tspeed: 0.0730s/iter; left time: 157.7462s\n",
      "\titers: 200, epoch: 11 | loss: 0.1417805\n",
      "\tspeed: 0.0378s/iter; left time: 77.8369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 226 | Train Loss: 0.1414703 Vali Loss: 0.1421832 Test Loss: 0.1633087\n",
      "Validation loss decreased (0.142924 --> 0.142183).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1409536\n",
      "\tspeed: 0.0736s/iter; left time: 142.4663s\n",
      "\titers: 200, epoch: 12 | loss: 0.1414926\n",
      "\tspeed: 0.0371s/iter; left time: 68.1298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 226 | Train Loss: 0.1408790 Vali Loss: 0.1425147 Test Loss: 0.1638915\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1381426\n",
      "\tspeed: 0.0725s/iter; left time: 123.8351s\n",
      "\titers: 200, epoch: 13 | loss: 0.1429288\n",
      "\tspeed: 0.0373s/iter; left time: 60.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 226 | Train Loss: 0.1403976 Vali Loss: 0.1417581 Test Loss: 0.1623155\n",
      "Validation loss decreased (0.142183 --> 0.141758).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1387962\n",
      "\tspeed: 0.0721s/iter; left time: 106.9753s\n",
      "\titers: 200, epoch: 14 | loss: 0.1414717\n",
      "\tspeed: 0.0374s/iter; left time: 51.6551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1400058 Vali Loss: 0.1411327 Test Loss: 0.1628660\n",
      "Validation loss decreased (0.141758 --> 0.141133).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1364574\n",
      "\tspeed: 0.0729s/iter; left time: 91.5823s\n",
      "\titers: 200, epoch: 15 | loss: 0.1425574\n",
      "\tspeed: 0.0370s/iter; left time: 42.8560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1397703 Vali Loss: 0.1413148 Test Loss: 0.1623359\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1383148\n",
      "\tspeed: 0.0714s/iter; left time: 73.5626s\n",
      "\titers: 200, epoch: 16 | loss: 0.1390328\n",
      "\tspeed: 0.0374s/iter; left time: 34.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 226 | Train Loss: 0.1393477 Vali Loss: 0.1415988 Test Loss: 0.1625231\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1398590\n",
      "\tspeed: 0.0716s/iter; left time: 57.6687s\n",
      "\titers: 200, epoch: 17 | loss: 0.1373641\n",
      "\tspeed: 0.0376s/iter; left time: 26.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 226 | Train Loss: 0.1391973 Vali Loss: 0.1411650 Test Loss: 0.1617826\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1360651\n",
      "\tspeed: 0.0723s/iter; left time: 41.8864s\n",
      "\titers: 200, epoch: 18 | loss: 0.1406906\n",
      "\tspeed: 0.0371s/iter; left time: 17.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.73s\n",
      "Steps: 226 | Train Loss: 0.1390311 Vali Loss: 0.1410970 Test Loss: 0.1623264\n",
      "Validation loss decreased (0.141133 --> 0.141097).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1445395\n",
      "\tspeed: 0.0725s/iter; left time: 25.5949s\n",
      "\titers: 200, epoch: 19 | loss: 0.1377317\n",
      "\tspeed: 0.0371s/iter; left time: 9.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 226 | Train Loss: 0.1388068 Vali Loss: 0.1410492 Test Loss: 0.1618427\n",
      "Validation loss decreased (0.141097 --> 0.141049).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1333902\n",
      "\tspeed: 0.0726s/iter; left time: 9.2213s\n",
      "\titers: 200, epoch: 20 | loss: 0.1377930\n",
      "\tspeed: 0.0372s/iter; left time: 1.0056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 226 | Train Loss: 0.1385366 Vali Loss: 0.1407390 Test Loss: 0.1614996\n",
      "Validation loss decreased (0.141049 --> 0.140739).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07520537078380585, rmse:0.27423596382141113, mae:0.16149014234542847, rse:1.0369157791137695\n",
      "Intermediate time for IT and pred_len 96: 00h:07m:31.72s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=128, n_heads=16, e_layers=2, d_layers=1, d_ff=256, moving_avg=25, factor=5, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3114176\n",
      "\tspeed: 0.0689s/iter; left time: 303.1467s\n",
      "\titers: 200, epoch: 1 | loss: 0.2829991\n",
      "\tspeed: 0.0452s/iter; left time: 194.4114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.94s\n",
      "Steps: 225 | Train Loss: 0.3110994 Vali Loss: 0.2604344 Test Loss: 0.2718581\n",
      "Validation loss decreased (inf --> 0.260434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2029363\n",
      "\tspeed: 0.0884s/iter; left time: 369.0917s\n",
      "\titers: 200, epoch: 2 | loss: 0.1866091\n",
      "\tspeed: 0.0457s/iter; left time: 186.2163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.62s\n",
      "Steps: 225 | Train Loss: 0.2104378 Vali Loss: 0.1701028 Test Loss: 0.1900666\n",
      "Validation loss decreased (0.260434 --> 0.170103).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1717800\n",
      "\tspeed: 0.0878s/iter; left time: 346.7250s\n",
      "\titers: 200, epoch: 3 | loss: 0.1689198\n",
      "\tspeed: 0.0457s/iter; left time: 175.8099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.65s\n",
      "Steps: 225 | Train Loss: 0.1729796 Vali Loss: 0.1656217 Test Loss: 0.1843113\n",
      "Validation loss decreased (0.170103 --> 0.165622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1639925\n",
      "\tspeed: 0.0871s/iter; left time: 324.5245s\n",
      "\titers: 200, epoch: 4 | loss: 0.1644154\n",
      "\tspeed: 0.0457s/iter; left time: 165.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.57s\n",
      "Steps: 225 | Train Loss: 0.1648469 Vali Loss: 0.1622676 Test Loss: 0.1805400\n",
      "Validation loss decreased (0.165622 --> 0.162268).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1620847\n",
      "\tspeed: 0.0867s/iter; left time: 303.6119s\n",
      "\titers: 200, epoch: 5 | loss: 0.1578263\n",
      "\tspeed: 0.0455s/iter; left time: 154.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.1606122 Vali Loss: 0.1564144 Test Loss: 0.1753415\n",
      "Validation loss decreased (0.162268 --> 0.156414).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1485261\n",
      "\tspeed: 0.0873s/iter; left time: 285.9839s\n",
      "\titers: 200, epoch: 6 | loss: 0.1361068\n",
      "\tspeed: 0.0457s/iter; left time: 145.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.60s\n",
      "Steps: 225 | Train Loss: 0.1469751 Vali Loss: 0.1302860 Test Loss: 0.1410772\n",
      "Validation loss decreased (0.156414 --> 0.130286).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1301002\n",
      "\tspeed: 0.0875s/iter; left time: 267.1086s\n",
      "\titers: 200, epoch: 7 | loss: 0.1226806\n",
      "\tspeed: 0.0456s/iter; left time: 134.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.64s\n",
      "Steps: 225 | Train Loss: 0.1287564 Vali Loss: 0.1234703 Test Loss: 0.1317603\n",
      "Validation loss decreased (0.130286 --> 0.123470).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1213538\n",
      "\tspeed: 0.0869s/iter; left time: 245.5218s\n",
      "\titers: 200, epoch: 8 | loss: 0.1240535\n",
      "\tspeed: 0.0457s/iter; left time: 124.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.62s\n",
      "Steps: 225 | Train Loss: 0.1228943 Vali Loss: 0.1188263 Test Loss: 0.1275405\n",
      "Validation loss decreased (0.123470 --> 0.118826).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1194697\n",
      "\tspeed: 0.0883s/iter; left time: 229.6323s\n",
      "\titers: 200, epoch: 9 | loss: 0.1178362\n",
      "\tspeed: 0.0458s/iter; left time: 114.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.63s\n",
      "Steps: 225 | Train Loss: 0.1198182 Vali Loss: 0.1194107 Test Loss: 0.1271132\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1189127\n",
      "\tspeed: 0.0866s/iter; left time: 205.6923s\n",
      "\titers: 200, epoch: 10 | loss: 0.1148641\n",
      "\tspeed: 0.0456s/iter; left time: 103.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 225 | Train Loss: 0.1175846 Vali Loss: 0.1162259 Test Loss: 0.1240256\n",
      "Validation loss decreased (0.118826 --> 0.116226).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1198008\n",
      "\tspeed: 0.0872s/iter; left time: 187.5631s\n",
      "\titers: 200, epoch: 11 | loss: 0.1140130\n",
      "\tspeed: 0.0462s/iter; left time: 94.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.1158401 Vali Loss: 0.1147040 Test Loss: 0.1222283\n",
      "Validation loss decreased (0.116226 --> 0.114704).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1155379\n",
      "\tspeed: 0.0874s/iter; left time: 168.2670s\n",
      "\titers: 200, epoch: 12 | loss: 0.1144194\n",
      "\tspeed: 0.0456s/iter; left time: 83.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.61s\n",
      "Steps: 225 | Train Loss: 0.1143384 Vali Loss: 0.1148974 Test Loss: 0.1225209\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1165169\n",
      "\tspeed: 0.0863s/iter; left time: 146.8530s\n",
      "\titers: 200, epoch: 13 | loss: 0.1153544\n",
      "\tspeed: 0.0457s/iter; left time: 73.0958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.51s\n",
      "Steps: 225 | Train Loss: 0.1131959 Vali Loss: 0.1127982 Test Loss: 0.1212409\n",
      "Validation loss decreased (0.114704 --> 0.112798).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1087733\n",
      "\tspeed: 0.0870s/iter; left time: 128.4212s\n",
      "\titers: 200, epoch: 14 | loss: 0.1108484\n",
      "\tspeed: 0.0454s/iter; left time: 62.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1121983 Vali Loss: 0.1132872 Test Loss: 0.1208662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1069586\n",
      "\tspeed: 0.0854s/iter; left time: 106.7764s\n",
      "\titers: 200, epoch: 15 | loss: 0.1126451\n",
      "\tspeed: 0.0454s/iter; left time: 52.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.48s\n",
      "Steps: 225 | Train Loss: 0.1114284 Vali Loss: 0.1113758 Test Loss: 0.1193138\n",
      "Validation loss decreased (0.112798 --> 0.111376).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1104863\n",
      "\tspeed: 0.0873s/iter; left time: 89.6198s\n",
      "\titers: 200, epoch: 16 | loss: 0.1083707\n",
      "\tspeed: 0.0457s/iter; left time: 42.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1107360 Vali Loss: 0.1103696 Test Loss: 0.1184127\n",
      "Validation loss decreased (0.111376 --> 0.110370).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1107242\n",
      "\tspeed: 0.0868s/iter; left time: 69.5400s\n",
      "\titers: 200, epoch: 17 | loss: 0.1115420\n",
      "\tspeed: 0.0450s/iter; left time: 31.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1102039 Vali Loss: 0.1105506 Test Loss: 0.1186264\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1105439\n",
      "\tspeed: 0.0861s/iter; left time: 49.5811s\n",
      "\titers: 200, epoch: 18 | loss: 0.1078856\n",
      "\tspeed: 0.0449s/iter; left time: 21.3652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.42s\n",
      "Steps: 225 | Train Loss: 0.1096842 Vali Loss: 0.1108085 Test Loss: 0.1187204\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1104525\n",
      "\tspeed: 0.0852s/iter; left time: 29.9143s\n",
      "\titers: 200, epoch: 19 | loss: 0.1053065\n",
      "\tspeed: 0.0449s/iter; left time: 11.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1093174 Vali Loss: 0.1114274 Test Loss: 0.1185483\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1113438\n",
      "\tspeed: 0.0870s/iter; left time: 10.9652s\n",
      "\titers: 200, epoch: 20 | loss: 0.1098847\n",
      "\tspeed: 0.0454s/iter; left time: 1.1799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.54s\n",
      "Steps: 225 | Train Loss: 0.1089683 Vali Loss: 0.1106552 Test Loss: 0.1181125\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.030604103580117226, rmse:0.174940288066864, mae:0.11823233962059021, rse:0.6620827317237854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2941262\n",
      "\tspeed: 0.0512s/iter; left time: 225.3344s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666424\n",
      "\tspeed: 0.0452s/iter; left time: 194.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.86s\n",
      "Steps: 225 | Train Loss: 0.2923229 Vali Loss: 0.2580853 Test Loss: 0.2686902\n",
      "Validation loss decreased (inf --> 0.258085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1958332\n",
      "\tspeed: 0.0866s/iter; left time: 361.7945s\n",
      "\titers: 200, epoch: 2 | loss: 0.1826746\n",
      "\tspeed: 0.0452s/iter; left time: 184.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 225 | Train Loss: 0.2016098 Vali Loss: 0.1753762 Test Loss: 0.1916100\n",
      "Validation loss decreased (0.258085 --> 0.175376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1751656\n",
      "\tspeed: 0.0877s/iter; left time: 346.6317s\n",
      "\titers: 200, epoch: 3 | loss: 0.1679857\n",
      "\tspeed: 0.0446s/iter; left time: 171.8089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1702062 Vali Loss: 0.1644219 Test Loss: 0.1824915\n",
      "Validation loss decreased (0.175376 --> 0.164422).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1606461\n",
      "\tspeed: 0.0857s/iter; left time: 319.4966s\n",
      "\titers: 200, epoch: 4 | loss: 0.1608806\n",
      "\tspeed: 0.0450s/iter; left time: 163.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 225 | Train Loss: 0.1622097 Vali Loss: 0.1595956 Test Loss: 0.1777068\n",
      "Validation loss decreased (0.164422 --> 0.159596).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1607111\n",
      "\tspeed: 0.0864s/iter; left time: 302.4129s\n",
      "\titers: 200, epoch: 5 | loss: 0.1585512\n",
      "\tspeed: 0.0448s/iter; left time: 152.3489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.42s\n",
      "Steps: 225 | Train Loss: 0.1580723 Vali Loss: 0.1571702 Test Loss: 0.1759370\n",
      "Validation loss decreased (0.159596 --> 0.157170).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1566879\n",
      "\tspeed: 0.0859s/iter; left time: 281.4610s\n",
      "\titers: 200, epoch: 6 | loss: 0.1571992\n",
      "\tspeed: 0.0450s/iter; left time: 143.0454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:10.49s\n",
      "Steps: 225 | Train Loss: 0.1556842 Vali Loss: 0.1542075 Test Loss: 0.1740605\n",
      "Validation loss decreased (0.157170 --> 0.154208).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1576083\n",
      "\tspeed: 0.0873s/iter; left time: 266.4219s\n",
      "\titers: 200, epoch: 7 | loss: 0.1604516\n",
      "\tspeed: 0.0455s/iter; left time: 134.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:10.58s\n",
      "Steps: 225 | Train Loss: 0.1540891 Vali Loss: 0.1544410 Test Loss: 0.1739365\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1508415\n",
      "\tspeed: 0.0870s/iter; left time: 245.8990s\n",
      "\titers: 200, epoch: 8 | loss: 0.1524826\n",
      "\tspeed: 0.0454s/iter; left time: 123.8569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1526721 Vali Loss: 0.1532004 Test Loss: 0.1730593\n",
      "Validation loss decreased (0.154208 --> 0.153200).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1510241\n",
      "\tspeed: 0.0855s/iter; left time: 222.3190s\n",
      "\titers: 200, epoch: 9 | loss: 0.1497750\n",
      "\tspeed: 0.0453s/iter; left time: 113.1900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:10.45s\n",
      "Steps: 225 | Train Loss: 0.1515892 Vali Loss: 0.1523653 Test Loss: 0.1732817\n",
      "Validation loss decreased (0.153200 --> 0.152365).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1465482\n",
      "\tspeed: 0.0862s/iter; left time: 204.8699s\n",
      "\titers: 200, epoch: 10 | loss: 0.1479229\n",
      "\tspeed: 0.0452s/iter; left time: 102.9118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:10.51s\n",
      "Steps: 225 | Train Loss: 0.1505481 Vali Loss: 0.1516478 Test Loss: 0.1729443\n",
      "Validation loss decreased (0.152365 --> 0.151648).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1517297\n",
      "\tspeed: 0.0876s/iter; left time: 188.3689s\n",
      "\titers: 200, epoch: 11 | loss: 0.1486346\n",
      "\tspeed: 0.0451s/iter; left time: 92.4836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:10.51s\n",
      "Steps: 225 | Train Loss: 0.1497302 Vali Loss: 0.1518015 Test Loss: 0.1729726\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1482868\n",
      "\tspeed: 0.0852s/iter; left time: 164.1030s\n",
      "\titers: 200, epoch: 12 | loss: 0.1521935\n",
      "\tspeed: 0.0451s/iter; left time: 82.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:10.42s\n",
      "Steps: 225 | Train Loss: 0.1491188 Vali Loss: 0.1510230 Test Loss: 0.1721103\n",
      "Validation loss decreased (0.151648 --> 0.151023).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1491129\n",
      "\tspeed: 0.0873s/iter; left time: 148.5759s\n",
      "\titers: 200, epoch: 13 | loss: 0.1475995\n",
      "\tspeed: 0.0458s/iter; left time: 73.2651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:10.64s\n",
      "Steps: 225 | Train Loss: 0.1484512 Vali Loss: 0.1506003 Test Loss: 0.1717075\n",
      "Validation loss decreased (0.151023 --> 0.150600).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1469474\n",
      "\tspeed: 0.0869s/iter; left time: 128.3337s\n",
      "\titers: 200, epoch: 14 | loss: 0.1504213\n",
      "\tspeed: 0.0453s/iter; left time: 62.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.52s\n",
      "Steps: 225 | Train Loss: 0.1479466 Vali Loss: 0.1504255 Test Loss: 0.1719507\n",
      "Validation loss decreased (0.150600 --> 0.150426).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1429042\n",
      "\tspeed: 0.0860s/iter; left time: 107.5617s\n",
      "\titers: 200, epoch: 15 | loss: 0.1466358\n",
      "\tspeed: 0.0446s/iter; left time: 51.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:10.39s\n",
      "Steps: 225 | Train Loss: 0.1475435 Vali Loss: 0.1497347 Test Loss: 0.1710558\n",
      "Validation loss decreased (0.150426 --> 0.149735).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1430475\n",
      "\tspeed: 0.0884s/iter; left time: 90.6794s\n",
      "\titers: 200, epoch: 16 | loss: 0.1462035\n",
      "\tspeed: 0.0452s/iter; left time: 41.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:10.53s\n",
      "Steps: 225 | Train Loss: 0.1472111 Vali Loss: 0.1506217 Test Loss: 0.1721246\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1502348\n",
      "\tspeed: 0.0861s/iter; left time: 68.9936s\n",
      "\titers: 200, epoch: 17 | loss: 0.1475698\n",
      "\tspeed: 0.0450s/iter; left time: 31.5470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:10.43s\n",
      "Steps: 225 | Train Loss: 0.1468807 Vali Loss: 0.1492906 Test Loss: 0.1715464\n",
      "Validation loss decreased (0.149735 --> 0.149291).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1508883\n",
      "\tspeed: 0.0868s/iter; left time: 49.9684s\n",
      "\titers: 200, epoch: 18 | loss: 0.1462397\n",
      "\tspeed: 0.0452s/iter; left time: 21.4958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1466258 Vali Loss: 0.1494294 Test Loss: 0.1708290\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1440767\n",
      "\tspeed: 0.0861s/iter; left time: 30.2193s\n",
      "\titers: 200, epoch: 19 | loss: 0.1489349\n",
      "\tspeed: 0.0451s/iter; left time: 11.3217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:10.47s\n",
      "Steps: 225 | Train Loss: 0.1464077 Vali Loss: 0.1497333 Test Loss: 0.1717865\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1493555\n",
      "\tspeed: 0.0847s/iter; left time: 10.6739s\n",
      "\titers: 200, epoch: 20 | loss: 0.1474688\n",
      "\tspeed: 0.0451s/iter; left time: 1.1715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:10.41s\n",
      "Steps: 225 | Train Loss: 0.1462136 Vali Loss: 0.1492373 Test Loss: 0.1705220\n",
      "Validation loss decreased (0.149291 --> 0.149237).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm128_nh16_el2_dl1_df256_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.07909660786390305, rmse:0.28124117851257324, mae:0.17056691646575928, rse:1.0643914937973022\n",
      "Intermediate time for IT and pred_len 168: 00h:09m:00.99s\n",
      "Intermediate time for IT: 00h:22m:51.50s\n",
      "Total time: 01h:48m:02.76s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.2 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --itr {itr} --batch_size 128 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "informer_df_itrs = pd.DataFrame(informer_results)\n",
    "\n",
    "# Set multi-index \n",
    "informer_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df_itrs.to_csv(os.path.join(path, 'informer_df_itrs_128_with_patchtst.csv'))\n",
    "informer_df_itrs = informer_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>0.1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.2817</td>\n",
       "      <td>0.1583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.2651</td>\n",
       "      <td>0.1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.1304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.1444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0494  0.2222  0.1350\n",
       "        96         0.0695  0.2635  0.1749\n",
       "        168        0.0756  0.2749  0.1858\n",
       "ES      24         0.0198  0.1407  0.0914\n",
       "        96         0.0401  0.2002  0.1312\n",
       "        168        0.0516  0.2270  0.1475\n",
       "FR      24         0.0714  0.2672  0.1403\n",
       "        96         0.0794  0.2817  0.1583\n",
       "        168        0.0708  0.2651  0.1560\n",
       "GB      24         0.0464  0.2154  0.1400\n",
       "        96         0.0724  0.2690  0.1851\n",
       "        168        0.0811  0.2846  0.1985\n",
       "IT      24         0.0676  0.2600  0.1412\n",
       "        96         0.0491  0.2128  0.1304\n",
       "        168        0.0548  0.2280  0.1444"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final DF\n",
    "informer_df = informer_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer_128_with_patchtst.csv'))\n",
    "informer_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
