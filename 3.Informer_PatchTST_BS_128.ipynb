{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST](#3-patchtst)\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2157750\n",
      "\tspeed: 0.0573s/iter; left time: 1032.1750s\n",
      "\titers: 200, epoch: 1 | loss: 0.1963026\n",
      "\tspeed: 0.0345s/iter; left time: 618.3465s\n",
      "\titers: 300, epoch: 1 | loss: 0.1900428\n",
      "\tspeed: 0.0346s/iter; left time: 616.3469s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759242\n",
      "\tspeed: 0.0346s/iter; left time: 612.6584s\n",
      "\titers: 500, epoch: 1 | loss: 0.1711153\n",
      "\tspeed: 0.0346s/iter; left time: 609.0709s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630517\n",
      "\tspeed: 0.0346s/iter; left time: 605.7895s\n",
      "\titers: 700, epoch: 1 | loss: 0.1811213\n",
      "\tspeed: 0.0346s/iter; left time: 602.2036s\n",
      "\titers: 800, epoch: 1 | loss: 0.1556394\n",
      "\tspeed: 0.0346s/iter; left time: 598.6039s\n",
      "\titers: 900, epoch: 1 | loss: 0.1458707\n",
      "\tspeed: 0.0346s/iter; left time: 595.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.96s\n",
      "Steps: 906 | Train Loss: 0.1844934 Vali Loss: 0.1649067 Test Loss: 0.1739943\n",
      "Validation loss decreased (inf --> 0.164907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1358088\n",
      "\tspeed: 0.1027s/iter; left time: 1757.8565s\n",
      "\titers: 200, epoch: 2 | loss: 0.1412189\n",
      "\tspeed: 0.0345s/iter; left time: 586.6060s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239359\n",
      "\tspeed: 0.0345s/iter; left time: 582.8982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1101899\n",
      "\tspeed: 0.0345s/iter; left time: 579.3501s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120785\n",
      "\tspeed: 0.0344s/iter; left time: 575.1125s\n",
      "\titers: 600, epoch: 2 | loss: 0.1019989\n",
      "\tspeed: 0.0344s/iter; left time: 571.9308s\n",
      "\titers: 700, epoch: 2 | loss: 0.1072432\n",
      "\tspeed: 0.0339s/iter; left time: 559.6339s\n",
      "\titers: 800, epoch: 2 | loss: 0.1118224\n",
      "\tspeed: 0.0338s/iter; left time: 555.2880s\n",
      "\titers: 900, epoch: 2 | loss: 0.1012448\n",
      "\tspeed: 0.0338s/iter; left time: 551.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.1192783 Vali Loss: 0.1259812 Test Loss: 0.1363558\n",
      "Validation loss decreased (0.164907 --> 0.125981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092039\n",
      "\tspeed: 0.0994s/iter; left time: 1611.1556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914676\n",
      "\tspeed: 0.0344s/iter; left time: 554.0304s\n",
      "\titers: 300, epoch: 3 | loss: 0.0905245\n",
      "\tspeed: 0.0344s/iter; left time: 550.6343s\n",
      "\titers: 400, epoch: 3 | loss: 0.0860451\n",
      "\tspeed: 0.0344s/iter; left time: 547.1417s\n",
      "\titers: 500, epoch: 3 | loss: 0.0840570\n",
      "\tspeed: 0.0344s/iter; left time: 544.1619s\n",
      "\titers: 600, epoch: 3 | loss: 0.0864475\n",
      "\tspeed: 0.0345s/iter; left time: 541.2266s\n",
      "\titers: 700, epoch: 3 | loss: 0.0776535\n",
      "\tspeed: 0.0344s/iter; left time: 537.5386s\n",
      "\titers: 800, epoch: 3 | loss: 0.0880026\n",
      "\tspeed: 0.0339s/iter; left time: 525.2373s\n",
      "\titers: 900, epoch: 3 | loss: 0.0833839\n",
      "\tspeed: 0.0339s/iter; left time: 522.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.37s\n",
      "Steps: 906 | Train Loss: 0.0881952 Vali Loss: 0.1017724 Test Loss: 0.1044518\n",
      "Validation loss decreased (0.125981 --> 0.101772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744945\n",
      "\tspeed: 0.0997s/iter; left time: 1525.1724s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867104\n",
      "\tspeed: 0.0346s/iter; left time: 526.1904s\n",
      "\titers: 300, epoch: 4 | loss: 0.0777602\n",
      "\tspeed: 0.0346s/iter; left time: 522.0265s\n",
      "\titers: 400, epoch: 4 | loss: 0.0799538\n",
      "\tspeed: 0.0345s/iter; left time: 518.2007s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863173\n",
      "\tspeed: 0.0345s/iter; left time: 514.7978s\n",
      "\titers: 600, epoch: 4 | loss: 0.0789659\n",
      "\tspeed: 0.0345s/iter; left time: 510.7476s\n",
      "\titers: 700, epoch: 4 | loss: 0.0863506\n",
      "\tspeed: 0.0346s/iter; left time: 508.8477s\n",
      "\titers: 800, epoch: 4 | loss: 0.0809430\n",
      "\tspeed: 0.0346s/iter; left time: 504.7647s\n",
      "\titers: 900, epoch: 4 | loss: 0.0644707\n",
      "\tspeed: 0.0345s/iter; left time: 500.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0795589 Vali Loss: 0.0984519 Test Loss: 0.0999526\n",
      "Validation loss decreased (0.101772 --> 0.098452).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0721323\n",
      "\tspeed: 0.0989s/iter; left time: 1423.9969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783579\n",
      "\tspeed: 0.0345s/iter; left time: 493.9352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0719792\n",
      "\tspeed: 0.0346s/iter; left time: 490.6305s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887703\n",
      "\tspeed: 0.0346s/iter; left time: 487.6967s\n",
      "\titers: 500, epoch: 5 | loss: 0.0698399\n",
      "\tspeed: 0.0345s/iter; left time: 483.3961s\n",
      "\titers: 600, epoch: 5 | loss: 0.0868544\n",
      "\tspeed: 0.0346s/iter; left time: 480.1936s\n",
      "\titers: 700, epoch: 5 | loss: 0.0848192\n",
      "\tspeed: 0.0346s/iter; left time: 477.6474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0792127\n",
      "\tspeed: 0.0345s/iter; left time: 472.9793s\n",
      "\titers: 900, epoch: 5 | loss: 0.0864622\n",
      "\tspeed: 0.0345s/iter; left time: 469.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0759394 Vali Loss: 0.0958418 Test Loss: 0.1013505\n",
      "Validation loss decreased (0.098452 --> 0.095842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0766028\n",
      "\tspeed: 0.1005s/iter; left time: 1355.8127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0649590\n",
      "\tspeed: 0.0340s/iter; left time: 454.6845s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727186\n",
      "\tspeed: 0.0340s/iter; left time: 451.7025s\n",
      "\titers: 400, epoch: 6 | loss: 0.0766119\n",
      "\tspeed: 0.0340s/iter; left time: 448.5078s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743469\n",
      "\tspeed: 0.0339s/iter; left time: 444.3921s\n",
      "\titers: 600, epoch: 6 | loss: 0.0666672\n",
      "\tspeed: 0.0342s/iter; left time: 444.0445s\n",
      "\titers: 700, epoch: 6 | loss: 0.0702888\n",
      "\tspeed: 0.0346s/iter; left time: 445.4402s\n",
      "\titers: 800, epoch: 6 | loss: 0.0753023\n",
      "\tspeed: 0.0345s/iter; left time: 441.7408s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721991\n",
      "\tspeed: 0.0345s/iter; left time: 438.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 906 | Train Loss: 0.0725840 Vali Loss: 0.0960399 Test Loss: 0.1029606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0633076\n",
      "\tspeed: 0.0959s/iter; left time: 1207.1412s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646344\n",
      "\tspeed: 0.0341s/iter; left time: 425.4750s\n",
      "\titers: 300, epoch: 7 | loss: 0.0732895\n",
      "\tspeed: 0.0341s/iter; left time: 421.7839s\n",
      "\titers: 400, epoch: 7 | loss: 0.0704056\n",
      "\tspeed: 0.0341s/iter; left time: 418.9666s\n",
      "\titers: 500, epoch: 7 | loss: 0.0750957\n",
      "\tspeed: 0.0340s/iter; left time: 414.5119s\n",
      "\titers: 600, epoch: 7 | loss: 0.0560974\n",
      "\tspeed: 0.0340s/iter; left time: 411.1310s\n",
      "\titers: 700, epoch: 7 | loss: 0.0703704\n",
      "\tspeed: 0.0339s/iter; left time: 406.7731s\n",
      "\titers: 800, epoch: 7 | loss: 0.0585428\n",
      "\tspeed: 0.0340s/iter; left time: 404.0264s\n",
      "\titers: 900, epoch: 7 | loss: 0.0656901\n",
      "\tspeed: 0.0340s/iter; left time: 400.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0696662 Vali Loss: 0.0953170 Test Loss: 0.1043832\n",
      "Validation loss decreased (0.095842 --> 0.095317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597942\n",
      "\tspeed: 0.0999s/iter; left time: 1166.6990s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753576\n",
      "\tspeed: 0.0340s/iter; left time: 394.0254s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652202\n",
      "\tspeed: 0.0340s/iter; left time: 389.8927s\n",
      "\titers: 400, epoch: 8 | loss: 0.0703675\n",
      "\tspeed: 0.0340s/iter; left time: 386.8097s\n",
      "\titers: 500, epoch: 8 | loss: 0.0684308\n",
      "\tspeed: 0.0340s/iter; left time: 383.7727s\n",
      "\titers: 600, epoch: 8 | loss: 0.0796844\n",
      "\tspeed: 0.0340s/iter; left time: 379.9436s\n",
      "\titers: 700, epoch: 8 | loss: 0.0586823\n",
      "\tspeed: 0.0340s/iter; left time: 376.6601s\n",
      "\titers: 800, epoch: 8 | loss: 0.0628379\n",
      "\tspeed: 0.0340s/iter; left time: 373.1167s\n",
      "\titers: 900, epoch: 8 | loss: 0.0772258\n",
      "\tspeed: 0.0340s/iter; left time: 369.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0667833 Vali Loss: 0.0989558 Test Loss: 0.1058859\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731515\n",
      "\tspeed: 0.0953s/iter; left time: 1026.8488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666756\n",
      "\tspeed: 0.0339s/iter; left time: 362.1014s\n",
      "\titers: 300, epoch: 9 | loss: 0.0595185\n",
      "\tspeed: 0.0340s/iter; left time: 358.9964s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703624\n",
      "\tspeed: 0.0339s/iter; left time: 354.9658s\n",
      "\titers: 500, epoch: 9 | loss: 0.0656522\n",
      "\tspeed: 0.0339s/iter; left time: 351.8254s\n",
      "\titers: 600, epoch: 9 | loss: 0.0701082\n",
      "\tspeed: 0.0340s/iter; left time: 348.9358s\n",
      "\titers: 700, epoch: 9 | loss: 0.0658102\n",
      "\tspeed: 0.0340s/iter; left time: 345.7134s\n",
      "\titers: 800, epoch: 9 | loss: 0.0694849\n",
      "\tspeed: 0.0340s/iter; left time: 342.2395s\n",
      "\titers: 900, epoch: 9 | loss: 0.0585585\n",
      "\tspeed: 0.0340s/iter; left time: 338.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0644456 Vali Loss: 0.0969864 Test Loss: 0.1054834\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0660802\n",
      "\tspeed: 0.0965s/iter; left time: 952.2213s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685927\n",
      "\tspeed: 0.0346s/iter; left time: 337.5984s\n",
      "\titers: 300, epoch: 10 | loss: 0.0581311\n",
      "\tspeed: 0.0346s/iter; left time: 334.6282s\n",
      "\titers: 400, epoch: 10 | loss: 0.0709546\n",
      "\tspeed: 0.0346s/iter; left time: 330.5468s\n",
      "\titers: 500, epoch: 10 | loss: 0.0617054\n",
      "\tspeed: 0.0345s/iter; left time: 326.9514s\n",
      "\titers: 600, epoch: 10 | loss: 0.0566655\n",
      "\tspeed: 0.0344s/iter; left time: 322.5654s\n",
      "\titers: 700, epoch: 10 | loss: 0.0555644\n",
      "\tspeed: 0.0344s/iter; left time: 318.7316s\n",
      "\titers: 800, epoch: 10 | loss: 0.0605263\n",
      "\tspeed: 0.0342s/iter; left time: 313.3976s\n",
      "\titers: 900, epoch: 10 | loss: 0.0554270\n",
      "\tspeed: 0.0346s/iter; left time: 313.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.0618099 Vali Loss: 0.0958811 Test Loss: 0.1058694\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619151\n",
      "\tspeed: 0.0963s/iter; left time: 863.0085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597805\n",
      "\tspeed: 0.0344s/iter; left time: 304.8721s\n",
      "\titers: 300, epoch: 11 | loss: 0.0536805\n",
      "\tspeed: 0.0343s/iter; left time: 300.7942s\n",
      "\titers: 400, epoch: 11 | loss: 0.0513019\n",
      "\tspeed: 0.0342s/iter; left time: 296.3691s\n",
      "\titers: 500, epoch: 11 | loss: 0.0637296\n",
      "\tspeed: 0.0340s/iter; left time: 291.1695s\n",
      "\titers: 600, epoch: 11 | loss: 0.0655506\n",
      "\tspeed: 0.0345s/iter; left time: 291.5188s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623056\n",
      "\tspeed: 0.0346s/iter; left time: 289.1530s\n",
      "\titers: 800, epoch: 11 | loss: 0.0541347\n",
      "\tspeed: 0.0345s/iter; left time: 285.3061s\n",
      "\titers: 900, epoch: 11 | loss: 0.0503099\n",
      "\tspeed: 0.0346s/iter; left time: 282.1885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0593142 Vali Loss: 0.0960872 Test Loss: 0.1093873\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611448\n",
      "\tspeed: 0.0971s/iter; left time: 782.3115s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560043\n",
      "\tspeed: 0.0345s/iter; left time: 274.5392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0558763\n",
      "\tspeed: 0.0346s/iter; left time: 271.4691s\n",
      "\titers: 400, epoch: 12 | loss: 0.0633862\n",
      "\tspeed: 0.0345s/iter; left time: 267.7986s\n",
      "\titers: 500, epoch: 12 | loss: 0.0537031\n",
      "\tspeed: 0.0345s/iter; left time: 263.8130s\n",
      "\titers: 600, epoch: 12 | loss: 0.0556691\n",
      "\tspeed: 0.0345s/iter; left time: 260.6213s\n",
      "\titers: 700, epoch: 12 | loss: 0.0593802\n",
      "\tspeed: 0.0345s/iter; left time: 257.2170s\n",
      "\titers: 800, epoch: 12 | loss: 0.0507883\n",
      "\tspeed: 0.0341s/iter; left time: 251.0438s\n",
      "\titers: 900, epoch: 12 | loss: 0.0559344\n",
      "\tspeed: 0.0341s/iter; left time: 247.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.50s\n",
      "Steps: 906 | Train Loss: 0.0574293 Vali Loss: 0.0990894 Test Loss: 0.1103720\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025507517158985138, rmse:0.15971073508262634, mae:0.1042659804224968, rse:0.5640227794647217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2230141\n",
      "\tspeed: 0.0367s/iter; left time: 661.5227s\n",
      "\titers: 200, epoch: 1 | loss: 0.1912384\n",
      "\tspeed: 0.0340s/iter; left time: 608.9154s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890538\n",
      "\tspeed: 0.0340s/iter; left time: 606.1844s\n",
      "\titers: 400, epoch: 1 | loss: 0.1821308\n",
      "\tspeed: 0.0340s/iter; left time: 602.3591s\n",
      "\titers: 500, epoch: 1 | loss: 0.1777495\n",
      "\tspeed: 0.0340s/iter; left time: 598.7651s\n",
      "\titers: 600, epoch: 1 | loss: 0.1753001\n",
      "\tspeed: 0.0340s/iter; left time: 594.9457s\n",
      "\titers: 700, epoch: 1 | loss: 0.1703886\n",
      "\tspeed: 0.0339s/iter; left time: 591.3277s\n",
      "\titers: 800, epoch: 1 | loss: 0.1719142\n",
      "\tspeed: 0.0340s/iter; left time: 589.2019s\n",
      "\titers: 900, epoch: 1 | loss: 0.1525570\n",
      "\tspeed: 0.0343s/iter; left time: 590.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.1884397 Vali Loss: 0.1670010 Test Loss: 0.1773647\n",
      "Validation loss decreased (inf --> 0.167001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437568\n",
      "\tspeed: 0.0981s/iter; left time: 1678.7434s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364804\n",
      "\tspeed: 0.0340s/iter; left time: 578.6627s\n",
      "\titers: 300, epoch: 2 | loss: 0.1206845\n",
      "\tspeed: 0.0339s/iter; left time: 574.1556s\n",
      "\titers: 400, epoch: 2 | loss: 0.1204325\n",
      "\tspeed: 0.0339s/iter; left time: 570.6358s\n",
      "\titers: 500, epoch: 2 | loss: 0.1200934\n",
      "\tspeed: 0.0339s/iter; left time: 567.3894s\n",
      "\titers: 600, epoch: 2 | loss: 0.1026905\n",
      "\tspeed: 0.0340s/iter; left time: 565.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.1184056\n",
      "\tspeed: 0.0342s/iter; left time: 564.1581s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938529\n",
      "\tspeed: 0.0340s/iter; left time: 557.4805s\n",
      "\titers: 900, epoch: 2 | loss: 0.1178905\n",
      "\tspeed: 0.0340s/iter; left time: 554.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.1221062 Vali Loss: 0.1266311 Test Loss: 0.1376089\n",
      "Validation loss decreased (0.167001 --> 0.126631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071769\n",
      "\tspeed: 0.0964s/iter; left time: 1562.9527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011983\n",
      "\tspeed: 0.0340s/iter; left time: 547.1883s\n",
      "\titers: 300, epoch: 3 | loss: 0.0976297\n",
      "\tspeed: 0.0339s/iter; left time: 543.1893s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108132\n",
      "\tspeed: 0.0340s/iter; left time: 541.4452s\n",
      "\titers: 500, epoch: 3 | loss: 0.1018856\n",
      "\tspeed: 0.0340s/iter; left time: 537.0724s\n",
      "\titers: 600, epoch: 3 | loss: 0.0973330\n",
      "\tspeed: 0.0339s/iter; left time: 533.1113s\n",
      "\titers: 700, epoch: 3 | loss: 0.1023080\n",
      "\tspeed: 0.0340s/iter; left time: 530.2765s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062835\n",
      "\tspeed: 0.0340s/iter; left time: 527.0927s\n",
      "\titers: 900, epoch: 3 | loss: 0.1069887\n",
      "\tspeed: 0.0340s/iter; left time: 523.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.1036100 Vali Loss: 0.1243204 Test Loss: 0.1360400\n",
      "Validation loss decreased (0.126631 --> 0.124320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992623\n",
      "\tspeed: 0.0962s/iter; left time: 1472.6358s\n",
      "\titers: 200, epoch: 4 | loss: 0.1065900\n",
      "\tspeed: 0.0341s/iter; left time: 518.2205s\n",
      "\titers: 300, epoch: 4 | loss: 0.0931358\n",
      "\tspeed: 0.0339s/iter; left time: 512.1561s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058308\n",
      "\tspeed: 0.0339s/iter; left time: 509.0334s\n",
      "\titers: 500, epoch: 4 | loss: 0.0744899\n",
      "\tspeed: 0.0339s/iter; left time: 505.7343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0765016\n",
      "\tspeed: 0.0340s/iter; left time: 502.9699s\n",
      "\titers: 700, epoch: 4 | loss: 0.0799936\n",
      "\tspeed: 0.0340s/iter; left time: 500.2816s\n",
      "\titers: 800, epoch: 4 | loss: 0.0827769\n",
      "\tspeed: 0.0340s/iter; left time: 496.7079s\n",
      "\titers: 900, epoch: 4 | loss: 0.0796529\n",
      "\tspeed: 0.0340s/iter; left time: 493.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0907794 Vali Loss: 0.0990055 Test Loss: 0.1009647\n",
      "Validation loss decreased (0.124320 --> 0.099006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691942\n",
      "\tspeed: 0.0981s/iter; left time: 1411.9831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784808\n",
      "\tspeed: 0.0342s/iter; left time: 489.5829s\n",
      "\titers: 300, epoch: 5 | loss: 0.0777235\n",
      "\tspeed: 0.0340s/iter; left time: 482.8251s\n",
      "\titers: 400, epoch: 5 | loss: 0.0742996\n",
      "\tspeed: 0.0340s/iter; left time: 478.9214s\n",
      "\titers: 500, epoch: 5 | loss: 0.0769375\n",
      "\tspeed: 0.0340s/iter; left time: 476.0276s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693606\n",
      "\tspeed: 0.0340s/iter; left time: 472.2992s\n",
      "\titers: 700, epoch: 5 | loss: 0.0777253\n",
      "\tspeed: 0.0341s/iter; left time: 469.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0345s/iter; left time: 472.8234s\n",
      "\titers: 900, epoch: 5 | loss: 0.0693382\n",
      "\tspeed: 0.0345s/iter; left time: 469.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0772579 Vali Loss: 0.0970609 Test Loss: 0.1022710\n",
      "Validation loss decreased (0.099006 --> 0.097061).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816712\n",
      "\tspeed: 0.0976s/iter; left time: 1317.1927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686115\n",
      "\tspeed: 0.0340s/iter; left time: 455.8893s\n",
      "\titers: 300, epoch: 6 | loss: 0.0724844\n",
      "\tspeed: 0.0340s/iter; left time: 451.8054s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776625\n",
      "\tspeed: 0.0340s/iter; left time: 448.8444s\n",
      "\titers: 500, epoch: 6 | loss: 0.0742506\n",
      "\tspeed: 0.0340s/iter; left time: 445.3133s\n",
      "\titers: 600, epoch: 6 | loss: 0.0692068\n",
      "\tspeed: 0.0340s/iter; left time: 441.3233s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700073\n",
      "\tspeed: 0.0341s/iter; left time: 438.9639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0682788\n",
      "\tspeed: 0.0340s/iter; left time: 434.4684s\n",
      "\titers: 900, epoch: 6 | loss: 0.0709434\n",
      "\tspeed: 0.0340s/iter; left time: 431.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0735981 Vali Loss: 0.0985253 Test Loss: 0.1054766\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695847\n",
      "\tspeed: 0.0942s/iter; left time: 1185.8467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0663946\n",
      "\tspeed: 0.0347s/iter; left time: 432.8294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0748294\n",
      "\tspeed: 0.0347s/iter; left time: 429.4195s\n",
      "\titers: 400, epoch: 7 | loss: 0.0655389\n",
      "\tspeed: 0.0347s/iter; left time: 426.0399s\n",
      "\titers: 500, epoch: 7 | loss: 0.0710848\n",
      "\tspeed: 0.0347s/iter; left time: 422.4656s\n",
      "\titers: 600, epoch: 7 | loss: 0.0750432\n",
      "\tspeed: 0.0347s/iter; left time: 418.9342s\n",
      "\titers: 700, epoch: 7 | loss: 0.0589826\n",
      "\tspeed: 0.0347s/iter; left time: 415.5421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0753183\n",
      "\tspeed: 0.0345s/iter; left time: 410.4611s\n",
      "\titers: 900, epoch: 7 | loss: 0.0640458\n",
      "\tspeed: 0.0345s/iter; left time: 406.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0701836 Vali Loss: 0.0988405 Test Loss: 0.1049409\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640777\n",
      "\tspeed: 0.0967s/iter; left time: 1129.8765s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628060\n",
      "\tspeed: 0.0340s/iter; left time: 393.7841s\n",
      "\titers: 300, epoch: 8 | loss: 0.0658005\n",
      "\tspeed: 0.0340s/iter; left time: 390.8261s\n",
      "\titers: 400, epoch: 8 | loss: 0.0692687\n",
      "\tspeed: 0.0340s/iter; left time: 386.9866s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804830\n",
      "\tspeed: 0.0340s/iter; left time: 383.3645s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704948\n",
      "\tspeed: 0.0340s/iter; left time: 380.1543s\n",
      "\titers: 700, epoch: 8 | loss: 0.0721590\n",
      "\tspeed: 0.0340s/iter; left time: 376.3733s\n",
      "\titers: 800, epoch: 8 | loss: 0.0717574\n",
      "\tspeed: 0.0340s/iter; left time: 373.2058s\n",
      "\titers: 900, epoch: 8 | loss: 0.0600496\n",
      "\tspeed: 0.0340s/iter; left time: 369.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0675137 Vali Loss: 0.0970914 Test Loss: 0.1058643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0610077\n",
      "\tspeed: 0.0939s/iter; left time: 1012.0603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536139\n",
      "\tspeed: 0.0340s/iter; left time: 363.0301s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636304\n",
      "\tspeed: 0.0340s/iter; left time: 359.2915s\n",
      "\titers: 400, epoch: 9 | loss: 0.0654796\n",
      "\tspeed: 0.0339s/iter; left time: 355.4828s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599042\n",
      "\tspeed: 0.0340s/iter; left time: 352.4805s\n",
      "\titers: 600, epoch: 9 | loss: 0.0565385\n",
      "\tspeed: 0.0340s/iter; left time: 348.7747s\n",
      "\titers: 700, epoch: 9 | loss: 0.0668385\n",
      "\tspeed: 0.0340s/iter; left time: 345.7664s\n",
      "\titers: 800, epoch: 9 | loss: 0.0648912\n",
      "\tspeed: 0.0340s/iter; left time: 342.2205s\n",
      "\titers: 900, epoch: 9 | loss: 0.0582753\n",
      "\tspeed: 0.0340s/iter; left time: 339.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0648913 Vali Loss: 0.0960822 Test Loss: 0.1028538\n",
      "Validation loss decreased (0.097061 --> 0.096082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571060\n",
      "\tspeed: 0.0974s/iter; left time: 961.0195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593772\n",
      "\tspeed: 0.0340s/iter; left time: 332.1973s\n",
      "\titers: 300, epoch: 10 | loss: 0.0612443\n",
      "\tspeed: 0.0340s/iter; left time: 328.9119s\n",
      "\titers: 400, epoch: 10 | loss: 0.0655431\n",
      "\tspeed: 0.0340s/iter; left time: 325.6748s\n",
      "\titers: 500, epoch: 10 | loss: 0.0650016\n",
      "\tspeed: 0.0340s/iter; left time: 322.1937s\n",
      "\titers: 600, epoch: 10 | loss: 0.0638729\n",
      "\tspeed: 0.0341s/iter; left time: 319.2505s\n",
      "\titers: 700, epoch: 10 | loss: 0.0595213\n",
      "\tspeed: 0.0340s/iter; left time: 315.3304s\n",
      "\titers: 800, epoch: 10 | loss: 0.0569092\n",
      "\tspeed: 0.0340s/iter; left time: 311.9479s\n",
      "\titers: 900, epoch: 10 | loss: 0.0640525\n",
      "\tspeed: 0.0340s/iter; left time: 308.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0622086 Vali Loss: 0.0958591 Test Loss: 0.1072349\n",
      "Validation loss decreased (0.096082 --> 0.095859).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0614833\n",
      "\tspeed: 0.0974s/iter; left time: 872.4934s\n",
      "\titers: 200, epoch: 11 | loss: 0.0575255\n",
      "\tspeed: 0.0339s/iter; left time: 300.4564s\n",
      "\titers: 300, epoch: 11 | loss: 0.0580176\n",
      "\tspeed: 0.0339s/iter; left time: 297.3484s\n",
      "\titers: 400, epoch: 11 | loss: 0.0558818\n",
      "\tspeed: 0.0339s/iter; left time: 293.5805s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552967\n",
      "\tspeed: 0.0339s/iter; left time: 290.2811s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624112\n",
      "\tspeed: 0.0340s/iter; left time: 287.2546s\n",
      "\titers: 700, epoch: 11 | loss: 0.0603113\n",
      "\tspeed: 0.0339s/iter; left time: 283.7670s\n",
      "\titers: 800, epoch: 11 | loss: 0.0681967\n",
      "\tspeed: 0.0339s/iter; left time: 280.0891s\n",
      "\titers: 900, epoch: 11 | loss: 0.0524940\n",
      "\tspeed: 0.0339s/iter; left time: 276.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0599555 Vali Loss: 0.0940875 Test Loss: 0.1040663\n",
      "Validation loss decreased (0.095859 --> 0.094087).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0657773\n",
      "\tspeed: 0.0984s/iter; left time: 792.4305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594814\n",
      "\tspeed: 0.0340s/iter; left time: 270.1358s\n",
      "\titers: 300, epoch: 12 | loss: 0.0568700\n",
      "\tspeed: 0.0340s/iter; left time: 267.2081s\n",
      "\titers: 400, epoch: 12 | loss: 0.0558004\n",
      "\tspeed: 0.0341s/iter; left time: 264.1364s\n",
      "\titers: 500, epoch: 12 | loss: 0.0566751\n",
      "\tspeed: 0.0340s/iter; left time: 260.4906s\n",
      "\titers: 600, epoch: 12 | loss: 0.0581444\n",
      "\tspeed: 0.0340s/iter; left time: 257.1118s\n",
      "\titers: 700, epoch: 12 | loss: 0.0557531\n",
      "\tspeed: 0.0340s/iter; left time: 253.6974s\n",
      "\titers: 800, epoch: 12 | loss: 0.0620691\n",
      "\tspeed: 0.0340s/iter; left time: 250.2706s\n",
      "\titers: 900, epoch: 12 | loss: 0.0582283\n",
      "\tspeed: 0.0340s/iter; left time: 246.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0577892 Vali Loss: 0.0964437 Test Loss: 0.1105988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533582\n",
      "\tspeed: 0.0941s/iter; left time: 672.9972s\n",
      "\titers: 200, epoch: 13 | loss: 0.0481930\n",
      "\tspeed: 0.0347s/iter; left time: 244.4470s\n",
      "\titers: 300, epoch: 13 | loss: 0.0606546\n",
      "\tspeed: 0.0347s/iter; left time: 241.1487s\n",
      "\titers: 400, epoch: 13 | loss: 0.0518627\n",
      "\tspeed: 0.0347s/iter; left time: 237.4272s\n",
      "\titers: 500, epoch: 13 | loss: 0.0569521\n",
      "\tspeed: 0.0347s/iter; left time: 233.9909s\n",
      "\titers: 600, epoch: 13 | loss: 0.0532617\n",
      "\tspeed: 0.0347s/iter; left time: 230.4939s\n",
      "\titers: 700, epoch: 13 | loss: 0.0609730\n",
      "\tspeed: 0.0347s/iter; left time: 227.0485s\n",
      "\titers: 800, epoch: 13 | loss: 0.0557893\n",
      "\tspeed: 0.0347s/iter; left time: 223.6601s\n",
      "\titers: 900, epoch: 13 | loss: 0.0557036\n",
      "\tspeed: 0.0347s/iter; left time: 220.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.66s\n",
      "Steps: 906 | Train Loss: 0.0560332 Vali Loss: 0.0970379 Test Loss: 0.1079533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0597315\n",
      "\tspeed: 0.0939s/iter; left time: 586.2774s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535129\n",
      "\tspeed: 0.0345s/iter; left time: 212.0048s\n",
      "\titers: 300, epoch: 14 | loss: 0.0514123\n",
      "\tspeed: 0.0344s/iter; left time: 208.1608s\n",
      "\titers: 400, epoch: 14 | loss: 0.0533041\n",
      "\tspeed: 0.0339s/iter; left time: 201.7241s\n",
      "\titers: 500, epoch: 14 | loss: 0.0519378\n",
      "\tspeed: 0.0339s/iter; left time: 198.1319s\n",
      "\titers: 600, epoch: 14 | loss: 0.0486918\n",
      "\tspeed: 0.0339s/iter; left time: 194.8968s\n",
      "\titers: 700, epoch: 14 | loss: 0.0514592\n",
      "\tspeed: 0.0339s/iter; left time: 191.3317s\n",
      "\titers: 800, epoch: 14 | loss: 0.0511779\n",
      "\tspeed: 0.0340s/iter; left time: 188.2007s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592240\n",
      "\tspeed: 0.0340s/iter; left time: 184.8092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0542619 Vali Loss: 0.1007048 Test Loss: 0.1137719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533272\n",
      "\tspeed: 0.0937s/iter; left time: 500.2540s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540463\n",
      "\tspeed: 0.0340s/iter; left time: 178.0053s\n",
      "\titers: 300, epoch: 15 | loss: 0.0475888\n",
      "\tspeed: 0.0340s/iter; left time: 174.6277s\n",
      "\titers: 400, epoch: 15 | loss: 0.0573437\n",
      "\tspeed: 0.0340s/iter; left time: 171.1498s\n",
      "\titers: 500, epoch: 15 | loss: 0.0579779\n",
      "\tspeed: 0.0340s/iter; left time: 167.7634s\n",
      "\titers: 600, epoch: 15 | loss: 0.0538819\n",
      "\tspeed: 0.0340s/iter; left time: 164.3892s\n",
      "\titers: 700, epoch: 15 | loss: 0.0519059\n",
      "\tspeed: 0.0340s/iter; left time: 161.0040s\n",
      "\titers: 800, epoch: 15 | loss: 0.0557711\n",
      "\tspeed: 0.0341s/iter; left time: 157.8956s\n",
      "\titers: 900, epoch: 15 | loss: 0.0465270\n",
      "\tspeed: 0.0340s/iter; left time: 154.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0528399 Vali Loss: 0.0974168 Test Loss: 0.1095551\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476120\n",
      "\tspeed: 0.0947s/iter; left time: 419.5489s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560914\n",
      "\tspeed: 0.0340s/iter; left time: 147.1741s\n",
      "\titers: 300, epoch: 16 | loss: 0.0469050\n",
      "\tspeed: 0.0340s/iter; left time: 143.6711s\n",
      "\titers: 400, epoch: 16 | loss: 0.0462344\n",
      "\tspeed: 0.0340s/iter; left time: 140.2631s\n",
      "\titers: 500, epoch: 16 | loss: 0.0579376\n",
      "\tspeed: 0.0340s/iter; left time: 136.8792s\n",
      "\titers: 600, epoch: 16 | loss: 0.0472905\n",
      "\tspeed: 0.0340s/iter; left time: 133.6086s\n",
      "\titers: 700, epoch: 16 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 129.8898s\n",
      "\titers: 800, epoch: 16 | loss: 0.0483521\n",
      "\tspeed: 0.0340s/iter; left time: 126.7298s\n",
      "\titers: 900, epoch: 16 | loss: 0.0505118\n",
      "\tspeed: 0.0340s/iter; left time: 123.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0516243 Vali Loss: 0.0969801 Test Loss: 0.1082252\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027125487104058266, rmse:0.16469816863536835, mae:0.10410299152135849, rse:0.5816360116004944\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:33.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2236743\n",
      "\tspeed: 0.0659s/iter; left time: 1184.4053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113647\n",
      "\tspeed: 0.0418s/iter; left time: 747.1035s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026322\n",
      "\tspeed: 0.0415s/iter; left time: 737.3678s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935861\n",
      "\tspeed: 0.0415s/iter; left time: 733.9055s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860587\n",
      "\tspeed: 0.0420s/iter; left time: 738.5568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1778900\n",
      "\tspeed: 0.0416s/iter; left time: 727.0239s\n",
      "\titers: 700, epoch: 1 | loss: 0.1723806\n",
      "\tspeed: 0.0418s/iter; left time: 725.8630s\n",
      "\titers: 800, epoch: 1 | loss: 0.1740834\n",
      "\tspeed: 0.0421s/iter; left time: 727.4376s\n",
      "\titers: 900, epoch: 1 | loss: 0.1730634\n",
      "\tspeed: 0.0421s/iter; left time: 723.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 904 | Train Loss: 0.1950106 Vali Loss: 0.1828621 Test Loss: 0.2036057\n",
      "Validation loss decreased (inf --> 0.182862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645211\n",
      "\tspeed: 0.1168s/iter; left time: 1994.4889s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429543\n",
      "\tspeed: 0.0416s/iter; left time: 705.5633s\n",
      "\titers: 300, epoch: 2 | loss: 0.1374299\n",
      "\tspeed: 0.0416s/iter; left time: 701.5841s\n",
      "\titers: 400, epoch: 2 | loss: 0.1448636\n",
      "\tspeed: 0.0416s/iter; left time: 697.7827s\n",
      "\titers: 500, epoch: 2 | loss: 0.1413144\n",
      "\tspeed: 0.0416s/iter; left time: 693.9163s\n",
      "\titers: 600, epoch: 2 | loss: 0.1236145\n",
      "\tspeed: 0.0416s/iter; left time: 689.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.1246188\n",
      "\tspeed: 0.0416s/iter; left time: 685.3335s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242174\n",
      "\tspeed: 0.0416s/iter; left time: 681.5506s\n",
      "\titers: 900, epoch: 2 | loss: 0.1292692\n",
      "\tspeed: 0.0416s/iter; left time: 677.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1378524 Vali Loss: 0.1397373 Test Loss: 0.1576225\n",
      "Validation loss decreased (0.182862 --> 0.139737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1165264\n",
      "\tspeed: 0.1172s/iter; left time: 1894.8829s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007225\n",
      "\tspeed: 0.0417s/iter; left time: 670.0918s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167652\n",
      "\tspeed: 0.0416s/iter; left time: 665.2381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1072120\n",
      "\tspeed: 0.0416s/iter; left time: 659.8419s\n",
      "\titers: 500, epoch: 3 | loss: 0.1060360\n",
      "\tspeed: 0.0416s/iter; left time: 656.2613s\n",
      "\titers: 600, epoch: 3 | loss: 0.1059219\n",
      "\tspeed: 0.0416s/iter; left time: 651.9737s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176727\n",
      "\tspeed: 0.0416s/iter; left time: 647.9141s\n",
      "\titers: 800, epoch: 3 | loss: 0.0983266\n",
      "\tspeed: 0.0416s/iter; left time: 643.8895s\n",
      "\titers: 900, epoch: 3 | loss: 0.1117628\n",
      "\tspeed: 0.0417s/iter; left time: 640.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.1093381 Vali Loss: 0.1260393 Test Loss: 0.1418328\n",
      "Validation loss decreased (0.139737 --> 0.126039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144765\n",
      "\tspeed: 0.1182s/iter; left time: 1805.4575s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020382\n",
      "\tspeed: 0.0416s/iter; left time: 631.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.1153255\n",
      "\tspeed: 0.0416s/iter; left time: 627.1646s\n",
      "\titers: 400, epoch: 4 | loss: 0.1025088\n",
      "\tspeed: 0.0416s/iter; left time: 622.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.1027884\n",
      "\tspeed: 0.0416s/iter; left time: 618.4806s\n",
      "\titers: 600, epoch: 4 | loss: 0.1016667\n",
      "\tspeed: 0.0416s/iter; left time: 614.3470s\n",
      "\titers: 700, epoch: 4 | loss: 0.1033425\n",
      "\tspeed: 0.0416s/iter; left time: 610.2125s\n",
      "\titers: 800, epoch: 4 | loss: 0.0933737\n",
      "\tspeed: 0.0416s/iter; left time: 606.3138s\n",
      "\titers: 900, epoch: 4 | loss: 0.0934185\n",
      "\tspeed: 0.0416s/iter; left time: 601.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1001598 Vali Loss: 0.1275451 Test Loss: 0.1407701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895917\n",
      "\tspeed: 0.1148s/iter; left time: 1649.6186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927757\n",
      "\tspeed: 0.0416s/iter; left time: 593.4980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965540\n",
      "\tspeed: 0.0416s/iter; left time: 588.6807s\n",
      "\titers: 400, epoch: 5 | loss: 0.0999158\n",
      "\tspeed: 0.0416s/iter; left time: 585.5770s\n",
      "\titers: 500, epoch: 5 | loss: 0.0884686\n",
      "\tspeed: 0.0416s/iter; left time: 581.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.0966759\n",
      "\tspeed: 0.0417s/iter; left time: 578.2581s\n",
      "\titers: 700, epoch: 5 | loss: 0.0977219\n",
      "\tspeed: 0.0416s/iter; left time: 573.0901s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846407\n",
      "\tspeed: 0.0416s/iter; left time: 568.7870s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849928\n",
      "\tspeed: 0.0416s/iter; left time: 564.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 904 | Train Loss: 0.0935273 Vali Loss: 0.1276608 Test Loss: 0.1445250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835068\n",
      "\tspeed: 0.1146s/iter; left time: 1542.3072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837331\n",
      "\tspeed: 0.0416s/iter; left time: 555.9648s\n",
      "\titers: 300, epoch: 6 | loss: 0.0913434\n",
      "\tspeed: 0.0416s/iter; left time: 551.4175s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903796\n",
      "\tspeed: 0.0416s/iter; left time: 547.4075s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856775\n",
      "\tspeed: 0.0416s/iter; left time: 543.5327s\n",
      "\titers: 600, epoch: 6 | loss: 0.0846278\n",
      "\tspeed: 0.0416s/iter; left time: 539.4484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0778856\n",
      "\tspeed: 0.0416s/iter; left time: 535.0167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0858639\n",
      "\tspeed: 0.0416s/iter; left time: 530.9052s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903355\n",
      "\tspeed: 0.0416s/iter; left time: 527.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0873677 Vali Loss: 0.1281512 Test Loss: 0.1463322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829671\n",
      "\tspeed: 0.1144s/iter; left time: 1436.1222s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799333\n",
      "\tspeed: 0.0416s/iter; left time: 518.3830s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816214\n",
      "\tspeed: 0.0416s/iter; left time: 514.4665s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803851\n",
      "\tspeed: 0.0416s/iter; left time: 510.3534s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766140\n",
      "\tspeed: 0.0417s/iter; left time: 506.3998s\n",
      "\titers: 600, epoch: 7 | loss: 0.0814182\n",
      "\tspeed: 0.0416s/iter; left time: 502.0855s\n",
      "\titers: 700, epoch: 7 | loss: 0.0843650\n",
      "\tspeed: 0.0417s/iter; left time: 498.0307s\n",
      "\titers: 800, epoch: 7 | loss: 0.0786219\n",
      "\tspeed: 0.0416s/iter; left time: 493.6940s\n",
      "\titers: 900, epoch: 7 | loss: 0.0786166\n",
      "\tspeed: 0.0416s/iter; left time: 489.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0820126 Vali Loss: 0.1301628 Test Loss: 0.1494684\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744809\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1676s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740958\n",
      "\tspeed: 0.0416s/iter; left time: 480.6162s\n",
      "\titers: 300, epoch: 8 | loss: 0.0821366\n",
      "\tspeed: 0.0416s/iter; left time: 476.9035s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776912\n",
      "\tspeed: 0.0416s/iter; left time: 472.4502s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823452\n",
      "\tspeed: 0.0417s/iter; left time: 468.7491s\n",
      "\titers: 600, epoch: 8 | loss: 0.0832772\n",
      "\tspeed: 0.0416s/iter; left time: 464.2049s\n",
      "\titers: 700, epoch: 8 | loss: 0.0772706\n",
      "\tspeed: 0.0416s/iter; left time: 460.0779s\n",
      "\titers: 800, epoch: 8 | loss: 0.0733887\n",
      "\tspeed: 0.0416s/iter; left time: 455.9084s\n",
      "\titers: 900, epoch: 8 | loss: 0.0711432\n",
      "\tspeed: 0.0417s/iter; left time: 452.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0772220 Vali Loss: 0.1286450 Test Loss: 0.1474413\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111143946647644, rmse:0.20275956392288208, mae:0.14186589419841766, rse:0.7180125713348389\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2234415\n",
      "\tspeed: 0.0448s/iter; left time: 804.8949s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966856\n",
      "\tspeed: 0.0422s/iter; left time: 754.5125s\n",
      "\titers: 300, epoch: 1 | loss: 0.1985690\n",
      "\tspeed: 0.0422s/iter; left time: 750.9129s\n",
      "\titers: 400, epoch: 1 | loss: 0.1968302\n",
      "\tspeed: 0.0422s/iter; left time: 746.5394s\n",
      "\titers: 500, epoch: 1 | loss: 0.2051390\n",
      "\tspeed: 0.0422s/iter; left time: 742.6659s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833022\n",
      "\tspeed: 0.0422s/iter; left time: 737.9051s\n",
      "\titers: 700, epoch: 1 | loss: 0.1789588\n",
      "\tspeed: 0.0422s/iter; left time: 733.3599s\n",
      "\titers: 800, epoch: 1 | loss: 0.1781165\n",
      "\tspeed: 0.0422s/iter; left time: 730.0477s\n",
      "\titers: 900, epoch: 1 | loss: 0.1753210\n",
      "\tspeed: 0.0422s/iter; left time: 725.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 904 | Train Loss: 0.1983297 Vali Loss: 0.1792039 Test Loss: 0.1982639\n",
      "Validation loss decreased (inf --> 0.179204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652503\n",
      "\tspeed: 0.1185s/iter; left time: 2023.6443s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410911\n",
      "\tspeed: 0.0422s/iter; left time: 716.3351s\n",
      "\titers: 300, epoch: 2 | loss: 0.1531194\n",
      "\tspeed: 0.0422s/iter; left time: 712.5301s\n",
      "\titers: 400, epoch: 2 | loss: 0.1385903\n",
      "\tspeed: 0.0422s/iter; left time: 707.9972s\n",
      "\titers: 500, epoch: 2 | loss: 0.1392631\n",
      "\tspeed: 0.0422s/iter; left time: 703.6733s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265477\n",
      "\tspeed: 0.0419s/iter; left time: 694.9356s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320228\n",
      "\tspeed: 0.0417s/iter; left time: 686.5249s\n",
      "\titers: 800, epoch: 2 | loss: 0.1308168\n",
      "\tspeed: 0.0417s/iter; left time: 682.6446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1204412\n",
      "\tspeed: 0.0417s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 904 | Train Loss: 0.1407695 Vali Loss: 0.1408073 Test Loss: 0.1547505\n",
      "Validation loss decreased (0.179204 --> 0.140807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168671\n",
      "\tspeed: 0.1192s/iter; left time: 1927.4650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049146\n",
      "\tspeed: 0.0417s/iter; left time: 670.7429s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167228\n",
      "\tspeed: 0.0417s/iter; left time: 666.5092s\n",
      "\titers: 400, epoch: 3 | loss: 0.1142903\n",
      "\tspeed: 0.0417s/iter; left time: 662.3797s\n",
      "\titers: 500, epoch: 3 | loss: 0.1116785\n",
      "\tspeed: 0.0417s/iter; left time: 657.1454s\n",
      "\titers: 600, epoch: 3 | loss: 0.1235701\n",
      "\tspeed: 0.0417s/iter; left time: 653.4055s\n",
      "\titers: 700, epoch: 3 | loss: 0.1162522\n",
      "\tspeed: 0.0417s/iter; left time: 649.3268s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972967\n",
      "\tspeed: 0.0417s/iter; left time: 644.6283s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052426\n",
      "\tspeed: 0.0417s/iter; left time: 641.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.1110472 Vali Loss: 0.1264536 Test Loss: 0.1413004\n",
      "Validation loss decreased (0.140807 --> 0.126454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090948\n",
      "\tspeed: 0.1191s/iter; left time: 1818.1072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982538\n",
      "\tspeed: 0.0416s/iter; left time: 631.4894s\n",
      "\titers: 300, epoch: 4 | loss: 0.1019681\n",
      "\tspeed: 0.0416s/iter; left time: 627.4270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011304\n",
      "\tspeed: 0.0417s/iter; left time: 623.9304s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932572\n",
      "\tspeed: 0.0417s/iter; left time: 619.6904s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023407\n",
      "\tspeed: 0.0417s/iter; left time: 615.6053s\n",
      "\titers: 700, epoch: 4 | loss: 0.1069069\n",
      "\tspeed: 0.0417s/iter; left time: 611.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006559\n",
      "\tspeed: 0.0417s/iter; left time: 607.7450s\n",
      "\titers: 900, epoch: 4 | loss: 0.0924000\n",
      "\tspeed: 0.0417s/iter; left time: 603.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.1005647 Vali Loss: 0.1294573 Test Loss: 0.1431555\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859475\n",
      "\tspeed: 0.1151s/iter; left time: 1653.0452s\n",
      "\titers: 200, epoch: 5 | loss: 0.0939509\n",
      "\tspeed: 0.0417s/iter; left time: 594.5175s\n",
      "\titers: 300, epoch: 5 | loss: 0.1010361\n",
      "\tspeed: 0.0417s/iter; left time: 590.4591s\n",
      "\titers: 400, epoch: 5 | loss: 0.0910976\n",
      "\tspeed: 0.0417s/iter; left time: 586.6165s\n",
      "\titers: 500, epoch: 5 | loss: 0.0985042\n",
      "\tspeed: 0.0417s/iter; left time: 582.4643s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925515\n",
      "\tspeed: 0.0417s/iter; left time: 578.1049s\n",
      "\titers: 700, epoch: 5 | loss: 0.0912867\n",
      "\tspeed: 0.0417s/iter; left time: 574.5983s\n",
      "\titers: 800, epoch: 5 | loss: 0.0828394\n",
      "\tspeed: 0.0417s/iter; left time: 570.0924s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920023\n",
      "\tspeed: 0.0417s/iter; left time: 565.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.0930013 Vali Loss: 0.1250305 Test Loss: 0.1447869\n",
      "Validation loss decreased (0.126454 --> 0.125030).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0978971\n",
      "\tspeed: 0.1175s/iter; left time: 1581.6357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836452\n",
      "\tspeed: 0.0423s/iter; left time: 564.7488s\n",
      "\titers: 300, epoch: 6 | loss: 0.0813788\n",
      "\tspeed: 0.0423s/iter; left time: 560.4317s\n",
      "\titers: 400, epoch: 6 | loss: 0.0883501\n",
      "\tspeed: 0.0423s/iter; left time: 556.4378s\n",
      "\titers: 500, epoch: 6 | loss: 0.0908173\n",
      "\tspeed: 0.0419s/iter; left time: 547.4124s\n",
      "\titers: 600, epoch: 6 | loss: 0.0855428\n",
      "\tspeed: 0.0417s/iter; left time: 540.3965s\n",
      "\titers: 700, epoch: 6 | loss: 0.0813997\n",
      "\tspeed: 0.0418s/iter; left time: 538.0849s\n",
      "\titers: 800, epoch: 6 | loss: 0.0851901\n",
      "\tspeed: 0.0422s/iter; left time: 538.7857s\n",
      "\titers: 900, epoch: 6 | loss: 0.0928024\n",
      "\tspeed: 0.0422s/iter; left time: 534.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0864959 Vali Loss: 0.1274113 Test Loss: 0.1429392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860452\n",
      "\tspeed: 0.1152s/iter; left time: 1445.9693s\n",
      "\titers: 200, epoch: 7 | loss: 0.0802008\n",
      "\tspeed: 0.0417s/iter; left time: 520.0418s\n",
      "\titers: 300, epoch: 7 | loss: 0.0844645\n",
      "\tspeed: 0.0417s/iter; left time: 515.7681s\n",
      "\titers: 400, epoch: 7 | loss: 0.0800768\n",
      "\tspeed: 0.0417s/iter; left time: 511.2027s\n",
      "\titers: 500, epoch: 7 | loss: 0.0742883\n",
      "\tspeed: 0.0417s/iter; left time: 507.2303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0797856\n",
      "\tspeed: 0.0417s/iter; left time: 502.8343s\n",
      "\titers: 700, epoch: 7 | loss: 0.0820259\n",
      "\tspeed: 0.0417s/iter; left time: 498.4365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776940\n",
      "\tspeed: 0.0417s/iter; left time: 494.1525s\n",
      "\titers: 900, epoch: 7 | loss: 0.0846543\n",
      "\tspeed: 0.0417s/iter; left time: 490.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0810965 Vali Loss: 0.1287853 Test Loss: 0.1496999\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749170\n",
      "\tspeed: 0.1138s/iter; left time: 1326.4466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0768698\n",
      "\tspeed: 0.0416s/iter; left time: 481.0175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0775572\n",
      "\tspeed: 0.0416s/iter; left time: 476.9494s\n",
      "\titers: 400, epoch: 8 | loss: 0.0874197\n",
      "\tspeed: 0.0417s/iter; left time: 473.0103s\n",
      "\titers: 500, epoch: 8 | loss: 0.0777074\n",
      "\tspeed: 0.0417s/iter; left time: 468.9067s\n",
      "\titers: 600, epoch: 8 | loss: 0.0779779\n",
      "\tspeed: 0.0417s/iter; left time: 464.8537s\n",
      "\titers: 700, epoch: 8 | loss: 0.0688209\n",
      "\tspeed: 0.0416s/iter; left time: 460.1467s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773090\n",
      "\tspeed: 0.0416s/iter; left time: 455.8680s\n",
      "\titers: 900, epoch: 8 | loss: 0.0762522\n",
      "\tspeed: 0.0416s/iter; left time: 452.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0761603 Vali Loss: 0.1303706 Test Loss: 0.1481057\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745463\n",
      "\tspeed: 0.1140s/iter; left time: 1225.3924s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718982\n",
      "\tspeed: 0.0417s/iter; left time: 444.2716s\n",
      "\titers: 300, epoch: 9 | loss: 0.0661809\n",
      "\tspeed: 0.0417s/iter; left time: 439.7693s\n",
      "\titers: 400, epoch: 9 | loss: 0.0663692\n",
      "\tspeed: 0.0417s/iter; left time: 435.6156s\n",
      "\titers: 500, epoch: 9 | loss: 0.0759411\n",
      "\tspeed: 0.0417s/iter; left time: 431.6843s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733939\n",
      "\tspeed: 0.0417s/iter; left time: 427.4183s\n",
      "\titers: 700, epoch: 9 | loss: 0.0685498\n",
      "\tspeed: 0.0417s/iter; left time: 423.4725s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660150\n",
      "\tspeed: 0.0417s/iter; left time: 418.9598s\n",
      "\titers: 900, epoch: 9 | loss: 0.0665430\n",
      "\tspeed: 0.0417s/iter; left time: 414.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0720239 Vali Loss: 0.1313181 Test Loss: 0.1486595\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688543\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9525s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704562\n",
      "\tspeed: 0.0416s/iter; left time: 405.8092s\n",
      "\titers: 300, epoch: 10 | loss: 0.0691381\n",
      "\tspeed: 0.0416s/iter; left time: 401.6987s\n",
      "\titers: 400, epoch: 10 | loss: 0.0685972\n",
      "\tspeed: 0.0417s/iter; left time: 397.8337s\n",
      "\titers: 500, epoch: 10 | loss: 0.0678505\n",
      "\tspeed: 0.0417s/iter; left time: 393.6512s\n",
      "\titers: 600, epoch: 10 | loss: 0.0690019\n",
      "\tspeed: 0.0417s/iter; left time: 389.3610s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663853\n",
      "\tspeed: 0.0417s/iter; left time: 385.2586s\n",
      "\titers: 800, epoch: 10 | loss: 0.0663898\n",
      "\tspeed: 0.0417s/iter; left time: 381.0024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0707798\n",
      "\tspeed: 0.0417s/iter; left time: 376.8207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0684217 Vali Loss: 0.1309250 Test Loss: 0.1480408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04497264325618744, rmse:0.21206754446029663, mae:0.14488229155540466, rse:0.7509739995002747\n",
      "Intermediate time for DE and pred_len 96: 00h:13m:48.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2135790\n",
      "\tspeed: 0.0737s/iter; left time: 1322.8469s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131124\n",
      "\tspeed: 0.0512s/iter; left time: 912.6013s\n",
      "\titers: 300, epoch: 1 | loss: 0.1944744\n",
      "\tspeed: 0.0511s/iter; left time: 906.5395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934913\n",
      "\tspeed: 0.0511s/iter; left time: 901.8570s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860318\n",
      "\tspeed: 0.0512s/iter; left time: 898.2652s\n",
      "\titers: 600, epoch: 1 | loss: 0.1891531\n",
      "\tspeed: 0.0507s/iter; left time: 884.7699s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774250\n",
      "\tspeed: 0.0505s/iter; left time: 875.0270s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730052\n",
      "\tspeed: 0.0510s/iter; left time: 878.7949s\n",
      "\titers: 900, epoch: 1 | loss: 0.1795384\n",
      "\tspeed: 0.0510s/iter; left time: 874.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 902 | Train Loss: 0.1965859 Vali Loss: 0.1832028 Test Loss: 0.2074134\n",
      "Validation loss decreased (inf --> 0.183203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704737\n",
      "\tspeed: 0.1414s/iter; left time: 2408.5213s\n",
      "\titers: 200, epoch: 2 | loss: 0.1490840\n",
      "\tspeed: 0.0512s/iter; left time: 866.9052s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521463\n",
      "\tspeed: 0.0511s/iter; left time: 861.3000s\n",
      "\titers: 400, epoch: 2 | loss: 0.1506241\n",
      "\tspeed: 0.0512s/iter; left time: 856.7931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1406512\n",
      "\tspeed: 0.0512s/iter; left time: 851.7499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1345950\n",
      "\tspeed: 0.0512s/iter; left time: 846.4364s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337818\n",
      "\tspeed: 0.0512s/iter; left time: 841.2830s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407173\n",
      "\tspeed: 0.0512s/iter; left time: 835.9682s\n",
      "\titers: 900, epoch: 2 | loss: 0.1290744\n",
      "\tspeed: 0.0512s/iter; left time: 831.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1488273 Vali Loss: 0.1596573 Test Loss: 0.1774935\n",
      "Validation loss decreased (0.183203 --> 0.159657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323122\n",
      "\tspeed: 0.1454s/iter; left time: 2346.2832s\n",
      "\titers: 200, epoch: 3 | loss: 0.1293032\n",
      "\tspeed: 0.0512s/iter; left time: 820.8534s\n",
      "\titers: 300, epoch: 3 | loss: 0.1290850\n",
      "\tspeed: 0.0512s/iter; left time: 815.8447s\n",
      "\titers: 400, epoch: 3 | loss: 0.1349285\n",
      "\tspeed: 0.0512s/iter; left time: 811.2225s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263371\n",
      "\tspeed: 0.0511s/iter; left time: 803.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1262871\n",
      "\tspeed: 0.0510s/iter; left time: 797.6849s\n",
      "\titers: 700, epoch: 3 | loss: 0.1187956\n",
      "\tspeed: 0.0507s/iter; left time: 787.9002s\n",
      "\titers: 800, epoch: 3 | loss: 0.1199932\n",
      "\tspeed: 0.0508s/iter; left time: 784.8815s\n",
      "\titers: 900, epoch: 3 | loss: 0.1152969\n",
      "\tspeed: 0.0510s/iter; left time: 782.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 902 | Train Loss: 0.1267166 Vali Loss: 0.1417985 Test Loss: 0.1600939\n",
      "Validation loss decreased (0.159657 --> 0.141799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117888\n",
      "\tspeed: 0.1424s/iter; left time: 2169.7528s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026877\n",
      "\tspeed: 0.0505s/iter; left time: 763.6327s\n",
      "\titers: 300, epoch: 4 | loss: 0.1014980\n",
      "\tspeed: 0.0506s/iter; left time: 760.6549s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038646\n",
      "\tspeed: 0.0505s/iter; left time: 754.2511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0989735\n",
      "\tspeed: 0.0504s/iter; left time: 747.5785s\n",
      "\titers: 600, epoch: 4 | loss: 0.1064414\n",
      "\tspeed: 0.0504s/iter; left time: 742.2079s\n",
      "\titers: 700, epoch: 4 | loss: 0.0987112\n",
      "\tspeed: 0.0504s/iter; left time: 737.3631s\n",
      "\titers: 800, epoch: 4 | loss: 0.1000495\n",
      "\tspeed: 0.0504s/iter; left time: 732.4440s\n",
      "\titers: 900, epoch: 4 | loss: 0.0978920\n",
      "\tspeed: 0.0504s/iter; left time: 727.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1061221 Vali Loss: 0.1528979 Test Loss: 0.1627806\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918928\n",
      "\tspeed: 0.1384s/iter; left time: 1983.2864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0960290\n",
      "\tspeed: 0.0511s/iter; left time: 727.3949s\n",
      "\titers: 300, epoch: 5 | loss: 0.0931458\n",
      "\tspeed: 0.0512s/iter; left time: 724.2957s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993961\n",
      "\tspeed: 0.0511s/iter; left time: 716.4612s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912344\n",
      "\tspeed: 0.0506s/iter; left time: 704.4801s\n",
      "\titers: 600, epoch: 5 | loss: 0.0892607\n",
      "\tspeed: 0.0505s/iter; left time: 698.8492s\n",
      "\titers: 700, epoch: 5 | loss: 0.0910661\n",
      "\tspeed: 0.0504s/iter; left time: 692.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1011088\n",
      "\tspeed: 0.0505s/iter; left time: 688.4830s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920976\n",
      "\tspeed: 0.0504s/iter; left time: 682.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.0971309 Vali Loss: 0.1423063 Test Loss: 0.1565221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920235\n",
      "\tspeed: 0.1408s/iter; left time: 1890.4647s\n",
      "\titers: 200, epoch: 6 | loss: 0.0922436\n",
      "\tspeed: 0.0511s/iter; left time: 681.2781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902070\n",
      "\tspeed: 0.0511s/iter; left time: 676.7292s\n",
      "\titers: 400, epoch: 6 | loss: 0.0975088\n",
      "\tspeed: 0.0512s/iter; left time: 671.7489s\n",
      "\titers: 500, epoch: 6 | loss: 0.0972495\n",
      "\tspeed: 0.0511s/iter; left time: 666.4803s\n",
      "\titers: 600, epoch: 6 | loss: 0.0895226\n",
      "\tspeed: 0.0511s/iter; left time: 661.3073s\n",
      "\titers: 700, epoch: 6 | loss: 0.0809252\n",
      "\tspeed: 0.0511s/iter; left time: 655.7049s\n",
      "\titers: 800, epoch: 6 | loss: 0.0889638\n",
      "\tspeed: 0.0511s/iter; left time: 651.0962s\n",
      "\titers: 900, epoch: 6 | loss: 0.0874771\n",
      "\tspeed: 0.0511s/iter; left time: 645.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0901457 Vali Loss: 0.1472353 Test Loss: 0.1613897\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832280\n",
      "\tspeed: 0.1385s/iter; left time: 1735.5467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830341\n",
      "\tspeed: 0.0505s/iter; left time: 628.0122s\n",
      "\titers: 300, epoch: 7 | loss: 0.0871024\n",
      "\tspeed: 0.0505s/iter; left time: 622.9652s\n",
      "\titers: 400, epoch: 7 | loss: 0.0823863\n",
      "\tspeed: 0.0505s/iter; left time: 617.8123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869082\n",
      "\tspeed: 0.0506s/iter; left time: 613.9551s\n",
      "\titers: 600, epoch: 7 | loss: 0.0787628\n",
      "\tspeed: 0.0505s/iter; left time: 607.5038s\n",
      "\titers: 700, epoch: 7 | loss: 0.0807302\n",
      "\tspeed: 0.0504s/iter; left time: 601.6845s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859715\n",
      "\tspeed: 0.0505s/iter; left time: 596.9224s\n",
      "\titers: 900, epoch: 7 | loss: 0.0893550\n",
      "\tspeed: 0.0505s/iter; left time: 591.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0839997 Vali Loss: 0.1402461 Test Loss: 0.1580236\n",
      "Validation loss decreased (0.141799 --> 0.140246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807353\n",
      "\tspeed: 0.1480s/iter; left time: 1721.0885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845029\n",
      "\tspeed: 0.0505s/iter; left time: 582.2940s\n",
      "\titers: 300, epoch: 8 | loss: 0.0833175\n",
      "\tspeed: 0.0505s/iter; left time: 577.5719s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774543\n",
      "\tspeed: 0.0504s/iter; left time: 570.9776s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767989\n",
      "\tspeed: 0.0506s/iter; left time: 568.2994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0740711\n",
      "\tspeed: 0.0506s/iter; left time: 562.4822s\n",
      "\titers: 700, epoch: 8 | loss: 0.0755660\n",
      "\tspeed: 0.0506s/iter; left time: 557.9460s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745798\n",
      "\tspeed: 0.0506s/iter; left time: 553.4293s\n",
      "\titers: 900, epoch: 8 | loss: 0.0752394\n",
      "\tspeed: 0.0505s/iter; left time: 546.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.0790876 Vali Loss: 0.1432174 Test Loss: 0.1611511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703514\n",
      "\tspeed: 0.1390s/iter; left time: 1490.3299s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778098\n",
      "\tspeed: 0.0509s/iter; left time: 540.7775s\n",
      "\titers: 300, epoch: 9 | loss: 0.0785731\n",
      "\tspeed: 0.0505s/iter; left time: 531.7624s\n",
      "\titers: 400, epoch: 9 | loss: 0.0750980\n",
      "\tspeed: 0.0506s/iter; left time: 527.9468s\n",
      "\titers: 500, epoch: 9 | loss: 0.0785402\n",
      "\tspeed: 0.0512s/iter; left time: 528.2391s\n",
      "\titers: 600, epoch: 9 | loss: 0.0711287\n",
      "\tspeed: 0.0512s/iter; left time: 523.7596s\n",
      "\titers: 700, epoch: 9 | loss: 0.0769884\n",
      "\tspeed: 0.0513s/iter; left time: 518.9390s\n",
      "\titers: 800, epoch: 9 | loss: 0.0754216\n",
      "\tspeed: 0.0512s/iter; left time: 513.7073s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719022\n",
      "\tspeed: 0.0512s/iter; left time: 508.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.23s\n",
      "Steps: 902 | Train Loss: 0.0748285 Vali Loss: 0.1403084 Test Loss: 0.1591520\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676495\n",
      "\tspeed: 0.1400s/iter; left time: 1375.3179s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732440\n",
      "\tspeed: 0.0512s/iter; left time: 498.0206s\n",
      "\titers: 300, epoch: 10 | loss: 0.0741318\n",
      "\tspeed: 0.0512s/iter; left time: 492.5140s\n",
      "\titers: 400, epoch: 10 | loss: 0.0708465\n",
      "\tspeed: 0.0511s/iter; left time: 486.7042s\n",
      "\titers: 500, epoch: 10 | loss: 0.0714293\n",
      "\tspeed: 0.0512s/iter; left time: 482.4216s\n",
      "\titers: 600, epoch: 10 | loss: 0.0729542\n",
      "\tspeed: 0.0511s/iter; left time: 476.5732s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714578\n",
      "\tspeed: 0.0511s/iter; left time: 471.3907s\n",
      "\titers: 800, epoch: 10 | loss: 0.0682916\n",
      "\tspeed: 0.0511s/iter; left time: 466.2845s\n",
      "\titers: 900, epoch: 10 | loss: 0.0718856\n",
      "\tspeed: 0.0506s/iter; left time: 456.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.0712225 Vali Loss: 0.1423417 Test Loss: 0.1615068\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672577\n",
      "\tspeed: 0.1397s/iter; left time: 1246.3109s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695483\n",
      "\tspeed: 0.0512s/iter; left time: 451.4285s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647759\n",
      "\tspeed: 0.0510s/iter; left time: 445.1117s\n",
      "\titers: 400, epoch: 11 | loss: 0.0645632\n",
      "\tspeed: 0.0510s/iter; left time: 439.9699s\n",
      "\titers: 500, epoch: 11 | loss: 0.0772103\n",
      "\tspeed: 0.0510s/iter; left time: 434.5106s\n",
      "\titers: 600, epoch: 11 | loss: 0.0657790\n",
      "\tspeed: 0.0510s/iter; left time: 429.5179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0685922\n",
      "\tspeed: 0.0507s/iter; left time: 422.0749s\n",
      "\titers: 800, epoch: 11 | loss: 0.0658226\n",
      "\tspeed: 0.0510s/iter; left time: 419.3127s\n",
      "\titers: 900, epoch: 11 | loss: 0.0667105\n",
      "\tspeed: 0.0510s/iter; left time: 414.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.34s\n",
      "Steps: 902 | Train Loss: 0.0681893 Vali Loss: 0.1411986 Test Loss: 0.1595801\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650528\n",
      "\tspeed: 0.1383s/iter; left time: 1108.7168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708718\n",
      "\tspeed: 0.0511s/iter; left time: 404.2901s\n",
      "\titers: 300, epoch: 12 | loss: 0.0652237\n",
      "\tspeed: 0.0506s/iter; left time: 395.8605s\n",
      "\titers: 400, epoch: 12 | loss: 0.0649883\n",
      "\tspeed: 0.0507s/iter; left time: 391.5492s\n",
      "\titers: 500, epoch: 12 | loss: 0.0644263\n",
      "\tspeed: 0.0506s/iter; left time: 385.6037s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660991\n",
      "\tspeed: 0.0506s/iter; left time: 380.4517s\n",
      "\titers: 700, epoch: 12 | loss: 0.0694268\n",
      "\tspeed: 0.0506s/iter; left time: 375.5242s\n",
      "\titers: 800, epoch: 12 | loss: 0.0674071\n",
      "\tspeed: 0.0506s/iter; left time: 370.2007s\n",
      "\titers: 900, epoch: 12 | loss: 0.0676546\n",
      "\tspeed: 0.0506s/iter; left time: 365.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0656815 Vali Loss: 0.1400202 Test Loss: 0.1601845\n",
      "Validation loss decreased (0.140246 --> 0.140020).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625419\n",
      "\tspeed: 0.1435s/iter; left time: 1021.4043s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636671\n",
      "\tspeed: 0.0510s/iter; left time: 357.9900s\n",
      "\titers: 300, epoch: 13 | loss: 0.0667756\n",
      "\tspeed: 0.0510s/iter; left time: 353.0616s\n",
      "\titers: 400, epoch: 13 | loss: 0.0637611\n",
      "\tspeed: 0.0512s/iter; left time: 349.0311s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616729\n",
      "\tspeed: 0.0512s/iter; left time: 344.0386s\n",
      "\titers: 600, epoch: 13 | loss: 0.0642316\n",
      "\tspeed: 0.0509s/iter; left time: 336.7321s\n",
      "\titers: 700, epoch: 13 | loss: 0.0620666\n",
      "\tspeed: 0.0510s/iter; left time: 332.5125s\n",
      "\titers: 800, epoch: 13 | loss: 0.0658408\n",
      "\tspeed: 0.0513s/iter; left time: 328.8980s\n",
      "\titers: 900, epoch: 13 | loss: 0.0617386\n",
      "\tspeed: 0.0513s/iter; left time: 323.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 902 | Train Loss: 0.0634137 Vali Loss: 0.1419839 Test Loss: 0.1631894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0585671\n",
      "\tspeed: 0.1396s/iter; left time: 867.4336s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664492\n",
      "\tspeed: 0.0506s/iter; left time: 309.6088s\n",
      "\titers: 300, epoch: 14 | loss: 0.0629691\n",
      "\tspeed: 0.0507s/iter; left time: 304.6759s\n",
      "\titers: 400, epoch: 14 | loss: 0.0620267\n",
      "\tspeed: 0.0507s/iter; left time: 299.7290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0623624\n",
      "\tspeed: 0.0507s/iter; left time: 294.8488s\n",
      "\titers: 600, epoch: 14 | loss: 0.0619973\n",
      "\tspeed: 0.0506s/iter; left time: 289.3720s\n",
      "\titers: 700, epoch: 14 | loss: 0.0618283\n",
      "\tspeed: 0.0508s/iter; left time: 285.1200s\n",
      "\titers: 800, epoch: 14 | loss: 0.0577629\n",
      "\tspeed: 0.0511s/iter; left time: 281.8709s\n",
      "\titers: 900, epoch: 14 | loss: 0.0643250\n",
      "\tspeed: 0.0512s/iter; left time: 277.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.10s\n",
      "Steps: 902 | Train Loss: 0.0616388 Vali Loss: 0.1407283 Test Loss: 0.1611458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597400\n",
      "\tspeed: 0.1409s/iter; left time: 748.5759s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610378\n",
      "\tspeed: 0.0513s/iter; left time: 267.3372s\n",
      "\titers: 300, epoch: 15 | loss: 0.0592156\n",
      "\tspeed: 0.0513s/iter; left time: 262.3524s\n",
      "\titers: 400, epoch: 15 | loss: 0.0588845\n",
      "\tspeed: 0.0513s/iter; left time: 257.2757s\n",
      "\titers: 500, epoch: 15 | loss: 0.0618582\n",
      "\tspeed: 0.0513s/iter; left time: 251.8946s\n",
      "\titers: 600, epoch: 15 | loss: 0.0604138\n",
      "\tspeed: 0.0513s/iter; left time: 246.7312s\n",
      "\titers: 700, epoch: 15 | loss: 0.0605271\n",
      "\tspeed: 0.0513s/iter; left time: 241.7580s\n",
      "\titers: 800, epoch: 15 | loss: 0.0604768\n",
      "\tspeed: 0.0513s/iter; left time: 236.5873s\n",
      "\titers: 900, epoch: 15 | loss: 0.0590711\n",
      "\tspeed: 0.0513s/iter; left time: 231.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.0600248 Vali Loss: 0.1428889 Test Loss: 0.1618677\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0612130\n",
      "\tspeed: 0.1387s/iter; left time: 611.8801s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578973\n",
      "\tspeed: 0.0506s/iter; left time: 218.1125s\n",
      "\titers: 300, epoch: 16 | loss: 0.0590760\n",
      "\tspeed: 0.0507s/iter; left time: 213.3454s\n",
      "\titers: 400, epoch: 16 | loss: 0.0539181\n",
      "\tspeed: 0.0506s/iter; left time: 208.1322s\n",
      "\titers: 500, epoch: 16 | loss: 0.0605631\n",
      "\tspeed: 0.0507s/iter; left time: 203.3086s\n",
      "\titers: 600, epoch: 16 | loss: 0.0602342\n",
      "\tspeed: 0.0506s/iter; left time: 197.8721s\n",
      "\titers: 700, epoch: 16 | loss: 0.0567739\n",
      "\tspeed: 0.0506s/iter; left time: 192.9792s\n",
      "\titers: 800, epoch: 16 | loss: 0.0596344\n",
      "\tspeed: 0.0506s/iter; left time: 187.9486s\n",
      "\titers: 900, epoch: 16 | loss: 0.0615203\n",
      "\tspeed: 0.0506s/iter; left time: 182.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 902 | Train Loss: 0.0586482 Vali Loss: 0.1421482 Test Loss: 0.1612585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595209\n",
      "\tspeed: 0.1391s/iter; left time: 488.1010s\n",
      "\titers: 200, epoch: 17 | loss: 0.0596009\n",
      "\tspeed: 0.0504s/iter; left time: 171.6961s\n",
      "\titers: 300, epoch: 17 | loss: 0.0585621\n",
      "\tspeed: 0.0504s/iter; left time: 166.7300s\n",
      "\titers: 400, epoch: 17 | loss: 0.0652123\n",
      "\tspeed: 0.0504s/iter; left time: 161.8197s\n",
      "\titers: 500, epoch: 17 | loss: 0.0540461\n",
      "\tspeed: 0.0505s/iter; left time: 157.0520s\n",
      "\titers: 600, epoch: 17 | loss: 0.0559000\n",
      "\tspeed: 0.0506s/iter; left time: 152.3226s\n",
      "\titers: 700, epoch: 17 | loss: 0.0554206\n",
      "\tspeed: 0.0506s/iter; left time: 147.2073s\n",
      "\titers: 800, epoch: 17 | loss: 0.0559492\n",
      "\tspeed: 0.0506s/iter; left time: 142.2411s\n",
      "\titers: 900, epoch: 17 | loss: 0.0555495\n",
      "\tspeed: 0.0507s/iter; left time: 137.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 902 | Train Loss: 0.0575157 Vali Loss: 0.1406434 Test Loss: 0.1615269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05564524605870247, rmse:0.23589244484901428, mae:0.16008244454860687, rse:0.8356959223747253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2329182\n",
      "\tspeed: 0.0528s/iter; left time: 947.6494s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172202\n",
      "\tspeed: 0.0507s/iter; left time: 904.7054s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961658\n",
      "\tspeed: 0.0507s/iter; left time: 899.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1850062\n",
      "\tspeed: 0.0507s/iter; left time: 895.1299s\n",
      "\titers: 500, epoch: 1 | loss: 0.1870918\n",
      "\tspeed: 0.0508s/iter; left time: 890.3390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1944518\n",
      "\tspeed: 0.0506s/iter; left time: 882.1736s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783303\n",
      "\tspeed: 0.0506s/iter; left time: 876.9964s\n",
      "\titers: 800, epoch: 1 | loss: 0.1759333\n",
      "\tspeed: 0.0505s/iter; left time: 871.0565s\n",
      "\titers: 900, epoch: 1 | loss: 0.1763727\n",
      "\tspeed: 0.0506s/iter; left time: 867.0226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.1973616 Vali Loss: 0.1830743 Test Loss: 0.2059395\n",
      "Validation loss decreased (inf --> 0.183074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503127\n",
      "\tspeed: 0.1421s/iter; left time: 2420.4738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512766\n",
      "\tspeed: 0.0506s/iter; left time: 857.6590s\n",
      "\titers: 300, epoch: 2 | loss: 0.1382957\n",
      "\tspeed: 0.0506s/iter; left time: 852.5279s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341342\n",
      "\tspeed: 0.0506s/iter; left time: 847.7158s\n",
      "\titers: 500, epoch: 2 | loss: 0.1374097\n",
      "\tspeed: 0.0506s/iter; left time: 842.4117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1432593\n",
      "\tspeed: 0.0505s/iter; left time: 834.9621s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279730\n",
      "\tspeed: 0.0504s/iter; left time: 828.2137s\n",
      "\titers: 800, epoch: 2 | loss: 0.1409557\n",
      "\tspeed: 0.0504s/iter; left time: 823.0514s\n",
      "\titers: 900, epoch: 2 | loss: 0.1172102\n",
      "\tspeed: 0.0504s/iter; left time: 818.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 902 | Train Loss: 0.1439408 Vali Loss: 0.1546091 Test Loss: 0.1715550\n",
      "Validation loss decreased (0.183074 --> 0.154609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1301890\n",
      "\tspeed: 0.1410s/iter; left time: 2275.0167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247176\n",
      "\tspeed: 0.0505s/iter; left time: 809.6763s\n",
      "\titers: 300, epoch: 3 | loss: 0.1338786\n",
      "\tspeed: 0.0507s/iter; left time: 807.7225s\n",
      "\titers: 400, epoch: 3 | loss: 0.1215102\n",
      "\tspeed: 0.0507s/iter; left time: 802.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1196253\n",
      "\tspeed: 0.0507s/iter; left time: 797.5365s\n",
      "\titers: 600, epoch: 3 | loss: 0.1286701\n",
      "\tspeed: 0.0504s/iter; left time: 787.8341s\n",
      "\titers: 700, epoch: 3 | loss: 0.1157779\n",
      "\tspeed: 0.0504s/iter; left time: 782.7377s\n",
      "\titers: 800, epoch: 3 | loss: 0.1232034\n",
      "\tspeed: 0.0504s/iter; left time: 778.3771s\n",
      "\titers: 900, epoch: 3 | loss: 0.1138987\n",
      "\tspeed: 0.0504s/iter; left time: 773.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.1216343 Vali Loss: 0.1383445 Test Loss: 0.1558911\n",
      "Validation loss decreased (0.154609 --> 0.138345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097272\n",
      "\tspeed: 0.1400s/iter; left time: 2132.6516s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003548\n",
      "\tspeed: 0.0504s/iter; left time: 763.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034977\n",
      "\tspeed: 0.0504s/iter; left time: 757.4019s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083793\n",
      "\tspeed: 0.0504s/iter; left time: 752.3880s\n",
      "\titers: 500, epoch: 4 | loss: 0.1005158\n",
      "\tspeed: 0.0504s/iter; left time: 747.7124s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054492\n",
      "\tspeed: 0.0504s/iter; left time: 742.8598s\n",
      "\titers: 700, epoch: 4 | loss: 0.1030866\n",
      "\tspeed: 0.0504s/iter; left time: 737.7559s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006965\n",
      "\tspeed: 0.0504s/iter; left time: 732.9385s\n",
      "\titers: 900, epoch: 4 | loss: 0.1023383\n",
      "\tspeed: 0.0505s/iter; left time: 728.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.1054264 Vali Loss: 0.1426753 Test Loss: 0.1533596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043797\n",
      "\tspeed: 0.1380s/iter; left time: 1978.4526s\n",
      "\titers: 200, epoch: 5 | loss: 0.1015226\n",
      "\tspeed: 0.0506s/iter; left time: 719.8159s\n",
      "\titers: 300, epoch: 5 | loss: 0.1025427\n",
      "\tspeed: 0.0506s/iter; left time: 715.4537s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976157\n",
      "\tspeed: 0.0505s/iter; left time: 708.6062s\n",
      "\titers: 500, epoch: 5 | loss: 0.0992124\n",
      "\tspeed: 0.0506s/iter; left time: 704.4007s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925273\n",
      "\tspeed: 0.0505s/iter; left time: 698.1557s\n",
      "\titers: 700, epoch: 5 | loss: 0.0902019\n",
      "\tspeed: 0.0506s/iter; left time: 694.8242s\n",
      "\titers: 800, epoch: 5 | loss: 0.0899991\n",
      "\tspeed: 0.0505s/iter; left time: 688.3376s\n",
      "\titers: 900, epoch: 5 | loss: 0.0957246\n",
      "\tspeed: 0.0505s/iter; left time: 683.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0968106 Vali Loss: 0.1373353 Test Loss: 0.1569665\n",
      "Validation loss decreased (0.138345 --> 0.137335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0971396\n",
      "\tspeed: 0.1410s/iter; left time: 1893.4415s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877258\n",
      "\tspeed: 0.0505s/iter; left time: 673.6076s\n",
      "\titers: 300, epoch: 6 | loss: 0.0944563\n",
      "\tspeed: 0.0505s/iter; left time: 668.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0953016\n",
      "\tspeed: 0.0505s/iter; left time: 663.6332s\n",
      "\titers: 500, epoch: 6 | loss: 0.0904507\n",
      "\tspeed: 0.0506s/iter; left time: 658.7336s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920923\n",
      "\tspeed: 0.0507s/iter; left time: 655.0894s\n",
      "\titers: 700, epoch: 6 | loss: 0.0855336\n",
      "\tspeed: 0.0506s/iter; left time: 649.2819s\n",
      "\titers: 800, epoch: 6 | loss: 0.0849263\n",
      "\tspeed: 0.0507s/iter; left time: 645.0929s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849293\n",
      "\tspeed: 0.0505s/iter; left time: 638.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 902 | Train Loss: 0.0900812 Vali Loss: 0.1398693 Test Loss: 0.1587747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829473\n",
      "\tspeed: 0.1391s/iter; left time: 1742.6588s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794557\n",
      "\tspeed: 0.0507s/iter; left time: 630.6465s\n",
      "\titers: 300, epoch: 7 | loss: 0.0834720\n",
      "\tspeed: 0.0507s/iter; left time: 625.3873s\n",
      "\titers: 400, epoch: 7 | loss: 0.0812156\n",
      "\tspeed: 0.0507s/iter; left time: 620.2857s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828412\n",
      "\tspeed: 0.0507s/iter; left time: 614.8473s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856180\n",
      "\tspeed: 0.0506s/iter; left time: 609.1617s\n",
      "\titers: 700, epoch: 7 | loss: 0.0841857\n",
      "\tspeed: 0.0507s/iter; left time: 604.2357s\n",
      "\titers: 800, epoch: 7 | loss: 0.0855514\n",
      "\tspeed: 0.0506s/iter; left time: 598.9587s\n",
      "\titers: 900, epoch: 7 | loss: 0.0821454\n",
      "\tspeed: 0.0507s/iter; left time: 594.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0844364 Vali Loss: 0.1380800 Test Loss: 0.1562963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792243\n",
      "\tspeed: 0.1383s/iter; left time: 1607.5268s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758932\n",
      "\tspeed: 0.0506s/iter; left time: 583.1025s\n",
      "\titers: 300, epoch: 8 | loss: 0.0826427\n",
      "\tspeed: 0.0506s/iter; left time: 578.4702s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799903\n",
      "\tspeed: 0.0506s/iter; left time: 573.5689s\n",
      "\titers: 500, epoch: 8 | loss: 0.0791600\n",
      "\tspeed: 0.0504s/iter; left time: 565.6440s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825389\n",
      "\tspeed: 0.0505s/iter; left time: 562.1391s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792387\n",
      "\tspeed: 0.0506s/iter; left time: 557.6783s\n",
      "\titers: 800, epoch: 8 | loss: 0.0800074\n",
      "\tspeed: 0.0504s/iter; left time: 551.0006s\n",
      "\titers: 900, epoch: 8 | loss: 0.0764232\n",
      "\tspeed: 0.0504s/iter; left time: 545.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0794340 Vali Loss: 0.1406030 Test Loss: 0.1605993\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766746\n",
      "\tspeed: 0.1381s/iter; left time: 1481.6013s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807511\n",
      "\tspeed: 0.0505s/iter; left time: 536.5790s\n",
      "\titers: 300, epoch: 9 | loss: 0.0721841\n",
      "\tspeed: 0.0507s/iter; left time: 533.2897s\n",
      "\titers: 400, epoch: 9 | loss: 0.0782305\n",
      "\tspeed: 0.0507s/iter; left time: 528.4923s\n",
      "\titers: 500, epoch: 9 | loss: 0.0747176\n",
      "\tspeed: 0.0507s/iter; left time: 523.3335s\n",
      "\titers: 600, epoch: 9 | loss: 0.0727979\n",
      "\tspeed: 0.0507s/iter; left time: 518.3577s\n",
      "\titers: 700, epoch: 9 | loss: 0.0737757\n",
      "\tspeed: 0.0507s/iter; left time: 513.0490s\n",
      "\titers: 800, epoch: 9 | loss: 0.0740445\n",
      "\tspeed: 0.0506s/iter; left time: 506.9854s\n",
      "\titers: 900, epoch: 9 | loss: 0.0758738\n",
      "\tspeed: 0.0506s/iter; left time: 501.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 902 | Train Loss: 0.0753867 Vali Loss: 0.1409122 Test Loss: 0.1620111\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738081\n",
      "\tspeed: 0.1402s/iter; left time: 1377.4754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753992\n",
      "\tspeed: 0.0515s/iter; left time: 500.3210s\n",
      "\titers: 300, epoch: 10 | loss: 0.0722770\n",
      "\tspeed: 0.0515s/iter; left time: 495.7508s\n",
      "\titers: 400, epoch: 10 | loss: 0.0743530\n",
      "\tspeed: 0.0511s/iter; left time: 486.2793s\n",
      "\titers: 500, epoch: 10 | loss: 0.0718583\n",
      "\tspeed: 0.0510s/iter; left time: 481.0144s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755678\n",
      "\tspeed: 0.0511s/iter; left time: 476.3854s\n",
      "\titers: 700, epoch: 10 | loss: 0.0725444\n",
      "\tspeed: 0.0510s/iter; left time: 470.1557s\n",
      "\titers: 800, epoch: 10 | loss: 0.0725415\n",
      "\tspeed: 0.0507s/iter; left time: 462.4133s\n",
      "\titers: 900, epoch: 10 | loss: 0.0698420\n",
      "\tspeed: 0.0507s/iter; left time: 457.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0718391 Vali Loss: 0.1405233 Test Loss: 0.1635022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.051229722797870636, rmse:0.22633983194828033, mae:0.1569782793521881, rse:0.8018538951873779\n",
      "Intermediate time for DE and pred_len 168: 00h:24m:56.06s\n",
      "Intermediate time for DE: 00h:56m:17.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2065667\n",
      "\tspeed: 0.0585s/iter; left time: 1055.0276s\n",
      "\titers: 200, epoch: 1 | loss: 0.1898771\n",
      "\tspeed: 0.0340s/iter; left time: 608.9094s\n",
      "\titers: 300, epoch: 1 | loss: 0.1781441\n",
      "\tspeed: 0.0339s/iter; left time: 604.1571s\n",
      "\titers: 400, epoch: 1 | loss: 0.1769260\n",
      "\tspeed: 0.0339s/iter; left time: 601.0270s\n",
      "\titers: 500, epoch: 1 | loss: 0.1623933\n",
      "\tspeed: 0.0340s/iter; left time: 598.4446s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630156\n",
      "\tspeed: 0.0340s/iter; left time: 594.9816s\n",
      "\titers: 700, epoch: 1 | loss: 0.1549021\n",
      "\tspeed: 0.0339s/iter; left time: 591.3637s\n",
      "\titers: 800, epoch: 1 | loss: 0.1450832\n",
      "\tspeed: 0.0340s/iter; left time: 588.7659s\n",
      "\titers: 900, epoch: 1 | loss: 0.1431629\n",
      "\tspeed: 0.0340s/iter; left time: 585.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.1802093 Vali Loss: 0.1521474 Test Loss: 0.1806995\n",
      "Validation loss decreased (inf --> 0.152147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1379461\n",
      "\tspeed: 0.1024s/iter; left time: 1752.2041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1183134\n",
      "\tspeed: 0.0340s/iter; left time: 578.6834s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016329\n",
      "\tspeed: 0.0340s/iter; left time: 575.0825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1114180\n",
      "\tspeed: 0.0340s/iter; left time: 571.9411s\n",
      "\titers: 500, epoch: 2 | loss: 0.1128901\n",
      "\tspeed: 0.0340s/iter; left time: 568.0567s\n",
      "\titers: 600, epoch: 2 | loss: 0.0933868\n",
      "\tspeed: 0.0340s/iter; left time: 565.0899s\n",
      "\titers: 700, epoch: 2 | loss: 0.1148216\n",
      "\tspeed: 0.0340s/iter; left time: 562.1364s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128488\n",
      "\tspeed: 0.0340s/iter; left time: 558.8138s\n",
      "\titers: 900, epoch: 2 | loss: 0.0961874\n",
      "\tspeed: 0.0340s/iter; left time: 555.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.1125205 Vali Loss: 0.1164644 Test Loss: 0.1396194\n",
      "Validation loss decreased (0.152147 --> 0.116464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1032601\n",
      "\tspeed: 0.0965s/iter; left time: 1563.8764s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003233\n",
      "\tspeed: 0.0340s/iter; left time: 548.0625s\n",
      "\titers: 300, epoch: 3 | loss: 0.1062481\n",
      "\tspeed: 0.0340s/iter; left time: 544.6023s\n",
      "\titers: 400, epoch: 3 | loss: 0.0953404\n",
      "\tspeed: 0.0340s/iter; left time: 541.1076s\n",
      "\titers: 500, epoch: 3 | loss: 0.0999686\n",
      "\tspeed: 0.0340s/iter; left time: 538.0603s\n",
      "\titers: 600, epoch: 3 | loss: 0.0992506\n",
      "\tspeed: 0.0340s/iter; left time: 534.1618s\n",
      "\titers: 700, epoch: 3 | loss: 0.0999163\n",
      "\tspeed: 0.0340s/iter; left time: 531.0028s\n",
      "\titers: 800, epoch: 3 | loss: 0.0913728\n",
      "\tspeed: 0.0340s/iter; left time: 527.7707s\n",
      "\titers: 900, epoch: 3 | loss: 0.1034245\n",
      "\tspeed: 0.0340s/iter; left time: 524.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0998791 Vali Loss: 0.1129812 Test Loss: 0.1356770\n",
      "Validation loss decreased (0.116464 --> 0.112981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897522\n",
      "\tspeed: 0.0980s/iter; left time: 1499.8458s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064864\n",
      "\tspeed: 0.0346s/iter; left time: 526.4130s\n",
      "\titers: 300, epoch: 4 | loss: 0.0940685\n",
      "\tspeed: 0.0343s/iter; left time: 518.5255s\n",
      "\titers: 400, epoch: 4 | loss: 0.1048222\n",
      "\tspeed: 0.0341s/iter; left time: 511.0756s\n",
      "\titers: 500, epoch: 4 | loss: 0.1119908\n",
      "\tspeed: 0.0341s/iter; left time: 508.0281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1028988\n",
      "\tspeed: 0.0341s/iter; left time: 504.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.0919001\n",
      "\tspeed: 0.0341s/iter; left time: 501.7008s\n",
      "\titers: 800, epoch: 4 | loss: 0.0971707\n",
      "\tspeed: 0.0341s/iter; left time: 497.9438s\n",
      "\titers: 900, epoch: 4 | loss: 0.0936811\n",
      "\tspeed: 0.0341s/iter; left time: 494.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 906 | Train Loss: 0.0970638 Vali Loss: 0.1139413 Test Loss: 0.1345681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1065073\n",
      "\tspeed: 0.0945s/iter; left time: 1360.9809s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901787\n",
      "\tspeed: 0.0340s/iter; left time: 486.4075s\n",
      "\titers: 300, epoch: 5 | loss: 0.0899963\n",
      "\tspeed: 0.0340s/iter; left time: 483.3176s\n",
      "\titers: 400, epoch: 5 | loss: 0.1047166\n",
      "\tspeed: 0.0340s/iter; left time: 479.6122s\n",
      "\titers: 500, epoch: 5 | loss: 0.0848665\n",
      "\tspeed: 0.0340s/iter; left time: 476.0220s\n",
      "\titers: 600, epoch: 5 | loss: 0.0877800\n",
      "\tspeed: 0.0341s/iter; left time: 473.3804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0995184\n",
      "\tspeed: 0.0340s/iter; left time: 469.2897s\n",
      "\titers: 800, epoch: 5 | loss: 0.1012287\n",
      "\tspeed: 0.0340s/iter; left time: 466.3292s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855802\n",
      "\tspeed: 0.0341s/iter; left time: 463.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0934970 Vali Loss: 0.1173672 Test Loss: 0.1402675\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0928552\n",
      "\tspeed: 0.0936s/iter; left time: 1262.0840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0989584\n",
      "\tspeed: 0.0341s/iter; left time: 456.0414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907293\n",
      "\tspeed: 0.0341s/iter; left time: 453.4878s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939442\n",
      "\tspeed: 0.0341s/iter; left time: 449.2852s\n",
      "\titers: 500, epoch: 6 | loss: 0.0951724\n",
      "\tspeed: 0.0341s/iter; left time: 446.5104s\n",
      "\titers: 600, epoch: 6 | loss: 0.0863666\n",
      "\tspeed: 0.0341s/iter; left time: 442.9592s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910364\n",
      "\tspeed: 0.0341s/iter; left time: 439.9638s\n",
      "\titers: 800, epoch: 6 | loss: 0.0822814\n",
      "\tspeed: 0.0341s/iter; left time: 436.3053s\n",
      "\titers: 900, epoch: 6 | loss: 0.0938590\n",
      "\tspeed: 0.0341s/iter; left time: 433.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0908272 Vali Loss: 0.1192106 Test Loss: 0.1453762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746693\n",
      "\tspeed: 0.0942s/iter; left time: 1185.1489s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773950\n",
      "\tspeed: 0.0341s/iter; left time: 426.2154s\n",
      "\titers: 300, epoch: 7 | loss: 0.0814477\n",
      "\tspeed: 0.0341s/iter; left time: 421.8661s\n",
      "\titers: 400, epoch: 7 | loss: 0.0867475\n",
      "\tspeed: 0.0341s/iter; left time: 418.9123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766155\n",
      "\tspeed: 0.0341s/iter; left time: 415.1243s\n",
      "\titers: 600, epoch: 7 | loss: 0.0661413\n",
      "\tspeed: 0.0341s/iter; left time: 411.8718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0771113\n",
      "\tspeed: 0.0340s/iter; left time: 408.0494s\n",
      "\titers: 800, epoch: 7 | loss: 0.0708948\n",
      "\tspeed: 0.0341s/iter; left time: 404.7029s\n",
      "\titers: 900, epoch: 7 | loss: 0.0775627\n",
      "\tspeed: 0.0341s/iter; left time: 401.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0792233 Vali Loss: 0.1053339 Test Loss: 0.1323265\n",
      "Validation loss decreased (0.112981 --> 0.105334).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742684\n",
      "\tspeed: 0.0994s/iter; left time: 1160.8595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691775\n",
      "\tspeed: 0.0342s/iter; left time: 395.4680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0811470\n",
      "\tspeed: 0.0342s/iter; left time: 392.3738s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708296\n",
      "\tspeed: 0.0341s/iter; left time: 387.5259s\n",
      "\titers: 500, epoch: 8 | loss: 0.0749293\n",
      "\tspeed: 0.0341s/iter; left time: 384.5004s\n",
      "\titers: 600, epoch: 8 | loss: 0.0783654\n",
      "\tspeed: 0.0341s/iter; left time: 381.4007s\n",
      "\titers: 700, epoch: 8 | loss: 0.0806148\n",
      "\tspeed: 0.0341s/iter; left time: 378.3309s\n",
      "\titers: 800, epoch: 8 | loss: 0.0710718\n",
      "\tspeed: 0.0341s/iter; left time: 374.6150s\n",
      "\titers: 900, epoch: 8 | loss: 0.0672735\n",
      "\tspeed: 0.0341s/iter; left time: 371.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0752110 Vali Loss: 0.1059797 Test Loss: 0.1272185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0764559\n",
      "\tspeed: 0.0936s/iter; left time: 1008.6992s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805175\n",
      "\tspeed: 0.0341s/iter; left time: 364.3434s\n",
      "\titers: 300, epoch: 9 | loss: 0.0701884\n",
      "\tspeed: 0.0341s/iter; left time: 360.6060s\n",
      "\titers: 400, epoch: 9 | loss: 0.0753982\n",
      "\tspeed: 0.0341s/iter; left time: 357.3582s\n",
      "\titers: 500, epoch: 9 | loss: 0.0740065\n",
      "\tspeed: 0.0341s/iter; left time: 353.8814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0621589\n",
      "\tspeed: 0.0341s/iter; left time: 350.4821s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747598\n",
      "\tspeed: 0.0341s/iter; left time: 347.1544s\n",
      "\titers: 800, epoch: 9 | loss: 0.0816423\n",
      "\tspeed: 0.0342s/iter; left time: 344.0571s\n",
      "\titers: 900, epoch: 9 | loss: 0.0695066\n",
      "\tspeed: 0.0341s/iter; left time: 339.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0726019 Vali Loss: 0.1069399 Test Loss: 0.1331095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704984\n",
      "\tspeed: 0.0937s/iter; left time: 924.1009s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701090\n",
      "\tspeed: 0.0341s/iter; left time: 332.8216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0659057\n",
      "\tspeed: 0.0341s/iter; left time: 329.1772s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728105\n",
      "\tspeed: 0.0340s/iter; left time: 325.6335s\n",
      "\titers: 500, epoch: 10 | loss: 0.0748692\n",
      "\tspeed: 0.0341s/iter; left time: 322.9291s\n",
      "\titers: 600, epoch: 10 | loss: 0.0678749\n",
      "\tspeed: 0.0341s/iter; left time: 319.4862s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699628\n",
      "\tspeed: 0.0341s/iter; left time: 315.9728s\n",
      "\titers: 800, epoch: 10 | loss: 0.0634394\n",
      "\tspeed: 0.0341s/iter; left time: 312.2789s\n",
      "\titers: 900, epoch: 10 | loss: 0.0716516\n",
      "\tspeed: 0.0341s/iter; left time: 309.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0698472 Vali Loss: 0.0994613 Test Loss: 0.1233056\n",
      "Validation loss decreased (0.105334 --> 0.099461).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0626306\n",
      "\tspeed: 0.0962s/iter; left time: 861.7134s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640720\n",
      "\tspeed: 0.0340s/iter; left time: 301.5909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0588703\n",
      "\tspeed: 0.0341s/iter; left time: 298.7134s\n",
      "\titers: 400, epoch: 11 | loss: 0.0595044\n",
      "\tspeed: 0.0340s/iter; left time: 294.7817s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624516\n",
      "\tspeed: 0.0341s/iter; left time: 291.5805s\n",
      "\titers: 600, epoch: 11 | loss: 0.0580348\n",
      "\tspeed: 0.0340s/iter; left time: 287.6216s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642682\n",
      "\tspeed: 0.0341s/iter; left time: 285.1872s\n",
      "\titers: 800, epoch: 11 | loss: 0.0618705\n",
      "\tspeed: 0.0341s/iter; left time: 281.5465s\n",
      "\titers: 900, epoch: 11 | loss: 0.0543362\n",
      "\tspeed: 0.0340s/iter; left time: 277.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0620900 Vali Loss: 0.1001814 Test Loss: 0.1275305\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608115\n",
      "\tspeed: 0.0933s/iter; left time: 751.3224s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623593\n",
      "\tspeed: 0.0341s/iter; left time: 270.8942s\n",
      "\titers: 300, epoch: 12 | loss: 0.0562274\n",
      "\tspeed: 0.0341s/iter; left time: 268.0192s\n",
      "\titers: 400, epoch: 12 | loss: 0.0648748\n",
      "\tspeed: 0.0341s/iter; left time: 264.4116s\n",
      "\titers: 500, epoch: 12 | loss: 0.0535899\n",
      "\tspeed: 0.0341s/iter; left time: 260.6790s\n",
      "\titers: 600, epoch: 12 | loss: 0.0538404\n",
      "\tspeed: 0.0341s/iter; left time: 257.2894s\n",
      "\titers: 700, epoch: 12 | loss: 0.0548301\n",
      "\tspeed: 0.0341s/iter; left time: 254.1875s\n",
      "\titers: 800, epoch: 12 | loss: 0.0514138\n",
      "\tspeed: 0.0340s/iter; left time: 250.2762s\n",
      "\titers: 900, epoch: 12 | loss: 0.0655189\n",
      "\tspeed: 0.0341s/iter; left time: 247.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0597273 Vali Loss: 0.1036253 Test Loss: 0.1352557\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0566351\n",
      "\tspeed: 0.0941s/iter; left time: 673.0170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536230\n",
      "\tspeed: 0.0341s/iter; left time: 240.1297s\n",
      "\titers: 300, epoch: 13 | loss: 0.0634737\n",
      "\tspeed: 0.0341s/iter; left time: 237.0724s\n",
      "\titers: 400, epoch: 13 | loss: 0.0572632\n",
      "\tspeed: 0.0340s/iter; left time: 233.1244s\n",
      "\titers: 500, epoch: 13 | loss: 0.0540060\n",
      "\tspeed: 0.0341s/iter; left time: 229.8116s\n",
      "\titers: 600, epoch: 13 | loss: 0.0529787\n",
      "\tspeed: 0.0341s/iter; left time: 226.9394s\n",
      "\titers: 700, epoch: 13 | loss: 0.0610991\n",
      "\tspeed: 0.0341s/iter; left time: 223.1880s\n",
      "\titers: 800, epoch: 13 | loss: 0.0578308\n",
      "\tspeed: 0.0341s/iter; left time: 219.6118s\n",
      "\titers: 900, epoch: 13 | loss: 0.0553324\n",
      "\tspeed: 0.0341s/iter; left time: 216.2252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0578906 Vali Loss: 0.1017295 Test Loss: 0.1305108\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0616051\n",
      "\tspeed: 0.0943s/iter; left time: 588.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553820\n",
      "\tspeed: 0.0342s/iter; left time: 209.7892s\n",
      "\titers: 300, epoch: 14 | loss: 0.0544165\n",
      "\tspeed: 0.0342s/iter; left time: 206.4339s\n",
      "\titers: 400, epoch: 14 | loss: 0.0571011\n",
      "\tspeed: 0.0341s/iter; left time: 202.7012s\n",
      "\titers: 500, epoch: 14 | loss: 0.0607028\n",
      "\tspeed: 0.0341s/iter; left time: 199.2424s\n",
      "\titers: 600, epoch: 14 | loss: 0.0542016\n",
      "\tspeed: 0.0341s/iter; left time: 195.8150s\n",
      "\titers: 700, epoch: 14 | loss: 0.0561629\n",
      "\tspeed: 0.0342s/iter; left time: 192.8704s\n",
      "\titers: 800, epoch: 14 | loss: 0.0597202\n",
      "\tspeed: 0.0341s/iter; left time: 189.0456s\n",
      "\titers: 900, epoch: 14 | loss: 0.0638149\n",
      "\tspeed: 0.0342s/iter; left time: 186.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.25s\n",
      "Steps: 906 | Train Loss: 0.0560134 Vali Loss: 0.1008903 Test Loss: 0.1284106\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531591\n",
      "\tspeed: 0.0942s/iter; left time: 502.6085s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574485\n",
      "\tspeed: 0.0341s/iter; left time: 178.4678s\n",
      "\titers: 300, epoch: 15 | loss: 0.0499670\n",
      "\tspeed: 0.0341s/iter; left time: 175.3850s\n",
      "\titers: 400, epoch: 15 | loss: 0.0561084\n",
      "\tspeed: 0.0342s/iter; left time: 172.0325s\n",
      "\titers: 500, epoch: 15 | loss: 0.0534714\n",
      "\tspeed: 0.0342s/iter; left time: 168.7018s\n",
      "\titers: 600, epoch: 15 | loss: 0.0518036\n",
      "\tspeed: 0.0341s/iter; left time: 165.0023s\n",
      "\titers: 700, epoch: 15 | loss: 0.0593414\n",
      "\tspeed: 0.0341s/iter; left time: 161.5421s\n",
      "\titers: 800, epoch: 15 | loss: 0.0531404\n",
      "\tspeed: 0.0341s/iter; left time: 158.3529s\n",
      "\titers: 900, epoch: 15 | loss: 0.0592867\n",
      "\tspeed: 0.0341s/iter; left time: 154.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0546766 Vali Loss: 0.1010287 Test Loss: 0.1288189\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03368111699819565, rmse:0.18352416157722473, mae:0.12335905432701111, rse:0.6327870488166809\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2087424\n",
      "\tspeed: 0.0362s/iter; left time: 652.4385s\n",
      "\titers: 200, epoch: 1 | loss: 0.1828572\n",
      "\tspeed: 0.0342s/iter; left time: 612.3118s\n",
      "\titers: 300, epoch: 1 | loss: 0.1897422\n",
      "\tspeed: 0.0341s/iter; left time: 608.0596s\n",
      "\titers: 400, epoch: 1 | loss: 0.1720902\n",
      "\tspeed: 0.0342s/iter; left time: 605.3768s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669981\n",
      "\tspeed: 0.0341s/iter; left time: 600.9832s\n",
      "\titers: 600, epoch: 1 | loss: 0.1590210\n",
      "\tspeed: 0.0341s/iter; left time: 598.1668s\n",
      "\titers: 700, epoch: 1 | loss: 0.1618395\n",
      "\tspeed: 0.0341s/iter; left time: 594.8208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1537406\n",
      "\tspeed: 0.0342s/iter; left time: 591.7778s\n",
      "\titers: 900, epoch: 1 | loss: 0.1561620\n",
      "\tspeed: 0.0341s/iter; left time: 588.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1811837 Vali Loss: 0.1443907 Test Loss: 0.1706055\n",
      "Validation loss decreased (inf --> 0.144391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1264048\n",
      "\tspeed: 0.0961s/iter; left time: 1644.2747s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242911\n",
      "\tspeed: 0.0342s/iter; left time: 581.1043s\n",
      "\titers: 300, epoch: 2 | loss: 0.1100120\n",
      "\tspeed: 0.0342s/iter; left time: 577.6774s\n",
      "\titers: 400, epoch: 2 | loss: 0.0976940\n",
      "\tspeed: 0.0342s/iter; left time: 574.5811s\n",
      "\titers: 500, epoch: 2 | loss: 0.0993426\n",
      "\tspeed: 0.0341s/iter; left time: 570.3608s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993942\n",
      "\tspeed: 0.0342s/iter; left time: 567.6991s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957400\n",
      "\tspeed: 0.0342s/iter; left time: 564.1766s\n",
      "\titers: 800, epoch: 2 | loss: 0.0965493\n",
      "\tspeed: 0.0342s/iter; left time: 560.8260s\n",
      "\titers: 900, epoch: 2 | loss: 0.1025189\n",
      "\tspeed: 0.0341s/iter; left time: 556.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1120638 Vali Loss: 0.1135424 Test Loss: 0.1331562\n",
      "Validation loss decreased (0.144391 --> 0.113542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881129\n",
      "\tspeed: 0.0991s/iter; left time: 1606.9283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0977456\n",
      "\tspeed: 0.0347s/iter; left time: 559.4386s\n",
      "\titers: 300, epoch: 3 | loss: 0.1086163\n",
      "\tspeed: 0.0343s/iter; left time: 549.2724s\n",
      "\titers: 400, epoch: 3 | loss: 0.1002908\n",
      "\tspeed: 0.0341s/iter; left time: 542.8495s\n",
      "\titers: 500, epoch: 3 | loss: 0.0826901\n",
      "\tspeed: 0.0341s/iter; left time: 539.5337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893644\n",
      "\tspeed: 0.0342s/iter; left time: 536.9598s\n",
      "\titers: 700, epoch: 3 | loss: 0.0908650\n",
      "\tspeed: 0.0341s/iter; left time: 532.7367s\n",
      "\titers: 800, epoch: 3 | loss: 0.0975903\n",
      "\tspeed: 0.0346s/iter; left time: 536.0341s\n",
      "\titers: 900, epoch: 3 | loss: 0.0928147\n",
      "\tspeed: 0.0347s/iter; left time: 534.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.41s\n",
      "Steps: 906 | Train Loss: 0.0944582 Vali Loss: 0.1077265 Test Loss: 0.1298520\n",
      "Validation loss decreased (0.113542 --> 0.107726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863190\n",
      "\tspeed: 0.0970s/iter; left time: 1483.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907177\n",
      "\tspeed: 0.0341s/iter; left time: 518.1031s\n",
      "\titers: 300, epoch: 4 | loss: 0.0833950\n",
      "\tspeed: 0.0341s/iter; left time: 514.8418s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885096\n",
      "\tspeed: 0.0341s/iter; left time: 510.8771s\n",
      "\titers: 500, epoch: 4 | loss: 0.1024313\n",
      "\tspeed: 0.0341s/iter; left time: 508.6603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902057\n",
      "\tspeed: 0.0341s/iter; left time: 504.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877432\n",
      "\tspeed: 0.0341s/iter; left time: 501.8142s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994082\n",
      "\tspeed: 0.0342s/iter; left time: 499.0221s\n",
      "\titers: 900, epoch: 4 | loss: 0.0841573\n",
      "\tspeed: 0.0341s/iter; left time: 494.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0908629 Vali Loss: 0.1066669 Test Loss: 0.1268926\n",
      "Validation loss decreased (0.107726 --> 0.106667).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901364\n",
      "\tspeed: 0.0965s/iter; left time: 1388.7668s\n",
      "\titers: 200, epoch: 5 | loss: 0.0883172\n",
      "\tspeed: 0.0341s/iter; left time: 488.0627s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873815\n",
      "\tspeed: 0.0341s/iter; left time: 484.5753s\n",
      "\titers: 400, epoch: 5 | loss: 0.0802048\n",
      "\tspeed: 0.0342s/iter; left time: 481.8464s\n",
      "\titers: 500, epoch: 5 | loss: 0.0834858\n",
      "\tspeed: 0.0342s/iter; left time: 478.1296s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920321\n",
      "\tspeed: 0.0341s/iter; left time: 474.1742s\n",
      "\titers: 700, epoch: 5 | loss: 0.1012928\n",
      "\tspeed: 0.0341s/iter; left time: 470.7579s\n",
      "\titers: 800, epoch: 5 | loss: 0.0949160\n",
      "\tspeed: 0.0342s/iter; left time: 467.9884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0833733\n",
      "\tspeed: 0.0341s/iter; left time: 464.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0878463 Vali Loss: 0.1098253 Test Loss: 0.1307452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0875461\n",
      "\tspeed: 0.0945s/iter; left time: 1274.8394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793280\n",
      "\tspeed: 0.0347s/iter; left time: 464.6410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0823781\n",
      "\tspeed: 0.0347s/iter; left time: 461.2001s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781062\n",
      "\tspeed: 0.0347s/iter; left time: 458.1822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0726712\n",
      "\tspeed: 0.0347s/iter; left time: 453.9454s\n",
      "\titers: 600, epoch: 6 | loss: 0.0621493\n",
      "\tspeed: 0.0344s/iter; left time: 446.9567s\n",
      "\titers: 700, epoch: 6 | loss: 0.0807547\n",
      "\tspeed: 0.0341s/iter; left time: 439.7816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0704086\n",
      "\tspeed: 0.0341s/iter; left time: 436.5041s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726400\n",
      "\tspeed: 0.0341s/iter; left time: 432.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0782342 Vali Loss: 0.0994923 Test Loss: 0.1179419\n",
      "Validation loss decreased (0.106667 --> 0.099492).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712830\n",
      "\tspeed: 0.0978s/iter; left time: 1231.4343s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739732\n",
      "\tspeed: 0.0347s/iter; left time: 433.0052s\n",
      "\titers: 300, epoch: 7 | loss: 0.0753709\n",
      "\tspeed: 0.0347s/iter; left time: 429.3025s\n",
      "\titers: 400, epoch: 7 | loss: 0.0684797\n",
      "\tspeed: 0.0341s/iter; left time: 419.4674s\n",
      "\titers: 500, epoch: 7 | loss: 0.0776076\n",
      "\tspeed: 0.0342s/iter; left time: 416.5956s\n",
      "\titers: 600, epoch: 7 | loss: 0.0703165\n",
      "\tspeed: 0.0341s/iter; left time: 412.4213s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794782\n",
      "\tspeed: 0.0341s/iter; left time: 409.1995s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693715\n",
      "\tspeed: 0.0341s/iter; left time: 405.5195s\n",
      "\titers: 900, epoch: 7 | loss: 0.0780969\n",
      "\tspeed: 0.0342s/iter; left time: 402.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0721806 Vali Loss: 0.0970641 Test Loss: 0.1169970\n",
      "Validation loss decreased (0.099492 --> 0.097064).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0636127\n",
      "\tspeed: 0.0981s/iter; left time: 1145.4293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0630548\n",
      "\tspeed: 0.0342s/iter; left time: 395.8652s\n",
      "\titers: 300, epoch: 8 | loss: 0.0730316\n",
      "\tspeed: 0.0342s/iter; left time: 392.2474s\n",
      "\titers: 400, epoch: 8 | loss: 0.0669587\n",
      "\tspeed: 0.0341s/iter; left time: 388.5562s\n",
      "\titers: 500, epoch: 8 | loss: 0.0619939\n",
      "\tspeed: 0.0342s/iter; left time: 385.2777s\n",
      "\titers: 600, epoch: 8 | loss: 0.0640725\n",
      "\tspeed: 0.0342s/iter; left time: 382.2546s\n",
      "\titers: 700, epoch: 8 | loss: 0.0613099\n",
      "\tspeed: 0.0341s/iter; left time: 378.3109s\n",
      "\titers: 800, epoch: 8 | loss: 0.0650655\n",
      "\tspeed: 0.0342s/iter; left time: 375.4917s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699186\n",
      "\tspeed: 0.0342s/iter; left time: 371.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.21s\n",
      "Steps: 906 | Train Loss: 0.0689264 Vali Loss: 0.0993467 Test Loss: 0.1192917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681697\n",
      "\tspeed: 0.0938s/iter; left time: 1010.6405s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609449\n",
      "\tspeed: 0.0341s/iter; left time: 364.2415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0758209\n",
      "\tspeed: 0.0341s/iter; left time: 360.3506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0647182\n",
      "\tspeed: 0.0341s/iter; left time: 357.5211s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599880\n",
      "\tspeed: 0.0341s/iter; left time: 353.8521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696192\n",
      "\tspeed: 0.0342s/iter; left time: 351.0960s\n",
      "\titers: 700, epoch: 9 | loss: 0.0631149\n",
      "\tspeed: 0.0342s/iter; left time: 347.4902s\n",
      "\titers: 800, epoch: 9 | loss: 0.0657809\n",
      "\tspeed: 0.0342s/iter; left time: 344.1916s\n",
      "\titers: 900, epoch: 9 | loss: 0.0715103\n",
      "\tspeed: 0.0341s/iter; left time: 340.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.17s\n",
      "Steps: 906 | Train Loss: 0.0663550 Vali Loss: 0.0995142 Test Loss: 0.1232103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0680644\n",
      "\tspeed: 0.0938s/iter; left time: 925.4896s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559841\n",
      "\tspeed: 0.0342s/iter; left time: 333.7656s\n",
      "\titers: 300, epoch: 10 | loss: 0.0640021\n",
      "\tspeed: 0.0342s/iter; left time: 330.1482s\n",
      "\titers: 400, epoch: 10 | loss: 0.0558519\n",
      "\tspeed: 0.0342s/iter; left time: 327.0613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0592567\n",
      "\tspeed: 0.0341s/iter; left time: 323.1783s\n",
      "\titers: 600, epoch: 10 | loss: 0.0703132\n",
      "\tspeed: 0.0342s/iter; left time: 320.2512s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663644\n",
      "\tspeed: 0.0342s/iter; left time: 316.9101s\n",
      "\titers: 800, epoch: 10 | loss: 0.0713700\n",
      "\tspeed: 0.0342s/iter; left time: 313.5720s\n",
      "\titers: 900, epoch: 10 | loss: 0.0612881\n",
      "\tspeed: 0.0342s/iter; left time: 309.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0636049 Vali Loss: 0.1003592 Test Loss: 0.1226154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0635687\n",
      "\tspeed: 0.0959s/iter; left time: 858.9658s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579782\n",
      "\tspeed: 0.0341s/iter; left time: 302.2018s\n",
      "\titers: 300, epoch: 11 | loss: 0.0577329\n",
      "\tspeed: 0.0341s/iter; left time: 298.8250s\n",
      "\titers: 400, epoch: 11 | loss: 0.0584427\n",
      "\tspeed: 0.0341s/iter; left time: 295.6880s\n",
      "\titers: 500, epoch: 11 | loss: 0.0652117\n",
      "\tspeed: 0.0341s/iter; left time: 292.0533s\n",
      "\titers: 600, epoch: 11 | loss: 0.0556371\n",
      "\tspeed: 0.0341s/iter; left time: 288.8224s\n",
      "\titers: 700, epoch: 11 | loss: 0.0617914\n",
      "\tspeed: 0.0341s/iter; left time: 285.2151s\n",
      "\titers: 800, epoch: 11 | loss: 0.0650759\n",
      "\tspeed: 0.0341s/iter; left time: 281.8704s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628121\n",
      "\tspeed: 0.0341s/iter; left time: 278.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0608432 Vali Loss: 0.1019767 Test Loss: 0.1295339\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601404\n",
      "\tspeed: 0.0934s/iter; left time: 752.6225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608226\n",
      "\tspeed: 0.0342s/iter; left time: 271.9253s\n",
      "\titers: 300, epoch: 12 | loss: 0.0585720\n",
      "\tspeed: 0.0342s/iter; left time: 268.3737s\n",
      "\titers: 400, epoch: 12 | loss: 0.0671864\n",
      "\tspeed: 0.0342s/iter; left time: 264.9392s\n",
      "\titers: 500, epoch: 12 | loss: 0.0586702\n",
      "\tspeed: 0.0342s/iter; left time: 261.5608s\n",
      "\titers: 600, epoch: 12 | loss: 0.0578963\n",
      "\tspeed: 0.0342s/iter; left time: 258.2738s\n",
      "\titers: 700, epoch: 12 | loss: 0.0511237\n",
      "\tspeed: 0.0342s/iter; left time: 254.6666s\n",
      "\titers: 800, epoch: 12 | loss: 0.0598192\n",
      "\tspeed: 0.0342s/iter; left time: 251.4330s\n",
      "\titers: 900, epoch: 12 | loss: 0.0562920\n",
      "\tspeed: 0.0342s/iter; left time: 247.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0588874 Vali Loss: 0.1025693 Test Loss: 0.1268519\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03127928450703621, rmse:0.17685949802398682, mae:0.11696060001850128, rse:0.6098074316978455\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:51.71s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2268764\n",
      "\tspeed: 0.0655s/iter; left time: 1178.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.1978672\n",
      "\tspeed: 0.0413s/iter; left time: 739.0064s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943929\n",
      "\tspeed: 0.0420s/iter; left time: 747.6673s\n",
      "\titers: 400, epoch: 1 | loss: 0.1920299\n",
      "\tspeed: 0.0420s/iter; left time: 743.2215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1802773\n",
      "\tspeed: 0.0421s/iter; left time: 739.5867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717280\n",
      "\tspeed: 0.0421s/iter; left time: 735.5826s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656476\n",
      "\tspeed: 0.0420s/iter; left time: 730.7696s\n",
      "\titers: 800, epoch: 1 | loss: 0.1696963\n",
      "\tspeed: 0.0420s/iter; left time: 726.1528s\n",
      "\titers: 900, epoch: 1 | loss: 0.1643242\n",
      "\tspeed: 0.0421s/iter; left time: 723.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 904 | Train Loss: 0.1897053 Vali Loss: 0.1728368 Test Loss: 0.2124270\n",
      "Validation loss decreased (inf --> 0.172837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1457785\n",
      "\tspeed: 0.1164s/iter; left time: 1987.5548s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392656\n",
      "\tspeed: 0.0415s/iter; left time: 705.1681s\n",
      "\titers: 300, epoch: 2 | loss: 0.1343261\n",
      "\tspeed: 0.0415s/iter; left time: 699.7559s\n",
      "\titers: 400, epoch: 2 | loss: 0.1345560\n",
      "\tspeed: 0.0421s/iter; left time: 705.8104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1346623\n",
      "\tspeed: 0.0421s/iter; left time: 702.6320s\n",
      "\titers: 600, epoch: 2 | loss: 0.1332583\n",
      "\tspeed: 0.0419s/iter; left time: 694.3021s\n",
      "\titers: 700, epoch: 2 | loss: 0.1261364\n",
      "\tspeed: 0.0421s/iter; left time: 693.9271s\n",
      "\titers: 800, epoch: 2 | loss: 0.1254614\n",
      "\tspeed: 0.0421s/iter; left time: 689.2999s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305606\n",
      "\tspeed: 0.0421s/iter; left time: 684.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 904 | Train Loss: 0.1357239 Vali Loss: 0.1446885 Test Loss: 0.1781681\n",
      "Validation loss decreased (0.172837 --> 0.144689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1175372\n",
      "\tspeed: 0.1192s/iter; left time: 1927.9999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1188484\n",
      "\tspeed: 0.0421s/iter; left time: 676.6233s\n",
      "\titers: 300, epoch: 3 | loss: 0.1154065\n",
      "\tspeed: 0.0421s/iter; left time: 672.0777s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113715\n",
      "\tspeed: 0.0420s/iter; left time: 667.4296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1078852\n",
      "\tspeed: 0.0421s/iter; left time: 663.4356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1149738\n",
      "\tspeed: 0.0421s/iter; left time: 659.3680s\n",
      "\titers: 700, epoch: 3 | loss: 0.1066848\n",
      "\tspeed: 0.0421s/iter; left time: 655.3036s\n",
      "\titers: 800, epoch: 3 | loss: 0.1042039\n",
      "\tspeed: 0.0420s/iter; left time: 649.6626s\n",
      "\titers: 900, epoch: 3 | loss: 0.1103720\n",
      "\tspeed: 0.0420s/iter; left time: 645.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.1113842 Vali Loss: 0.1260925 Test Loss: 0.1568912\n",
      "Validation loss decreased (0.144689 --> 0.126093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1156684\n",
      "\tspeed: 0.1176s/iter; left time: 1795.7961s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072669\n",
      "\tspeed: 0.0415s/iter; left time: 629.9717s\n",
      "\titers: 300, epoch: 4 | loss: 0.1097675\n",
      "\tspeed: 0.0415s/iter; left time: 626.0487s\n",
      "\titers: 400, epoch: 4 | loss: 0.0987495\n",
      "\tspeed: 0.0416s/iter; left time: 622.0291s\n",
      "\titers: 500, epoch: 4 | loss: 0.0966180\n",
      "\tspeed: 0.0416s/iter; left time: 618.0380s\n",
      "\titers: 600, epoch: 4 | loss: 0.1013041\n",
      "\tspeed: 0.0416s/iter; left time: 613.6836s\n",
      "\titers: 700, epoch: 4 | loss: 0.0967172\n",
      "\tspeed: 0.0416s/iter; left time: 609.5065s\n",
      "\titers: 800, epoch: 4 | loss: 0.1014885\n",
      "\tspeed: 0.0415s/iter; left time: 605.2582s\n",
      "\titers: 900, epoch: 4 | loss: 0.1030009\n",
      "\tspeed: 0.0415s/iter; left time: 601.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1018708 Vali Loss: 0.1277115 Test Loss: 0.1587207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942518\n",
      "\tspeed: 0.1139s/iter; left time: 1636.5789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950471\n",
      "\tspeed: 0.0415s/iter; left time: 592.5768s\n",
      "\titers: 300, epoch: 5 | loss: 0.0928046\n",
      "\tspeed: 0.0415s/iter; left time: 588.2587s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033714\n",
      "\tspeed: 0.0415s/iter; left time: 583.5658s\n",
      "\titers: 500, epoch: 5 | loss: 0.0941585\n",
      "\tspeed: 0.0415s/iter; left time: 579.3170s\n",
      "\titers: 600, epoch: 5 | loss: 0.0995664\n",
      "\tspeed: 0.0415s/iter; left time: 575.1951s\n",
      "\titers: 700, epoch: 5 | loss: 0.1031185\n",
      "\tspeed: 0.0415s/iter; left time: 571.0616s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025636\n",
      "\tspeed: 0.0415s/iter; left time: 567.0282s\n",
      "\titers: 900, epoch: 5 | loss: 0.1002272\n",
      "\tspeed: 0.0415s/iter; left time: 562.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0953789 Vali Loss: 0.1268768 Test Loss: 0.1636338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910520\n",
      "\tspeed: 0.1140s/iter; left time: 1534.1408s\n",
      "\titers: 200, epoch: 6 | loss: 0.0860340\n",
      "\tspeed: 0.0415s/iter; left time: 554.6341s\n",
      "\titers: 300, epoch: 6 | loss: 0.0880820\n",
      "\tspeed: 0.0415s/iter; left time: 550.1306s\n",
      "\titers: 400, epoch: 6 | loss: 0.0941288\n",
      "\tspeed: 0.0415s/iter; left time: 546.4273s\n",
      "\titers: 500, epoch: 6 | loss: 0.0841647\n",
      "\tspeed: 0.0415s/iter; left time: 542.0510s\n",
      "\titers: 600, epoch: 6 | loss: 0.0876083\n",
      "\tspeed: 0.0415s/iter; left time: 537.7534s\n",
      "\titers: 700, epoch: 6 | loss: 0.0830211\n",
      "\tspeed: 0.0415s/iter; left time: 534.1377s\n",
      "\titers: 800, epoch: 6 | loss: 0.0914322\n",
      "\tspeed: 0.0415s/iter; left time: 529.4035s\n",
      "\titers: 900, epoch: 6 | loss: 0.0899133\n",
      "\tspeed: 0.0415s/iter; left time: 525.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0895236 Vali Loss: 0.1278808 Test Loss: 0.1652189\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0836434\n",
      "\tspeed: 0.1132s/iter; left time: 1421.1546s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844925\n",
      "\tspeed: 0.0415s/iter; left time: 517.5073s\n",
      "\titers: 300, epoch: 7 | loss: 0.0794558\n",
      "\tspeed: 0.0415s/iter; left time: 513.3383s\n",
      "\titers: 400, epoch: 7 | loss: 0.0855794\n",
      "\tspeed: 0.0415s/iter; left time: 508.9053s\n",
      "\titers: 500, epoch: 7 | loss: 0.0898345\n",
      "\tspeed: 0.0415s/iter; left time: 504.9240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0911049\n",
      "\tspeed: 0.0415s/iter; left time: 500.8588s\n",
      "\titers: 700, epoch: 7 | loss: 0.0897632\n",
      "\tspeed: 0.0415s/iter; left time: 496.6991s\n",
      "\titers: 800, epoch: 7 | loss: 0.0752865\n",
      "\tspeed: 0.0415s/iter; left time: 492.4032s\n",
      "\titers: 900, epoch: 7 | loss: 0.0809941\n",
      "\tspeed: 0.0415s/iter; left time: 488.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0841153 Vali Loss: 0.1298804 Test Loss: 0.1732888\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823286\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1804s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805886\n",
      "\tspeed: 0.0416s/iter; left time: 480.0498s\n",
      "\titers: 300, epoch: 8 | loss: 0.0787768\n",
      "\tspeed: 0.0415s/iter; left time: 475.3546s\n",
      "\titers: 400, epoch: 8 | loss: 0.0750168\n",
      "\tspeed: 0.0415s/iter; left time: 471.2326s\n",
      "\titers: 500, epoch: 8 | loss: 0.0819786\n",
      "\tspeed: 0.0415s/iter; left time: 466.9707s\n",
      "\titers: 600, epoch: 8 | loss: 0.0769879\n",
      "\tspeed: 0.0416s/iter; left time: 463.5953s\n",
      "\titers: 700, epoch: 8 | loss: 0.0801579\n",
      "\tspeed: 0.0415s/iter; left time: 458.9882s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806662\n",
      "\tspeed: 0.0415s/iter; left time: 454.6568s\n",
      "\titers: 900, epoch: 8 | loss: 0.0836962\n",
      "\tspeed: 0.0415s/iter; left time: 450.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0791007 Vali Loss: 0.1308822 Test Loss: 0.1750989\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049356184899806976, rmse:0.22216251492500305, mae:0.15691299736499786, rse:0.7682689428329468\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2278353\n",
      "\tspeed: 0.0436s/iter; left time: 783.7662s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020534\n",
      "\tspeed: 0.0415s/iter; left time: 742.9428s\n",
      "\titers: 300, epoch: 1 | loss: 0.1878239\n",
      "\tspeed: 0.0416s/iter; left time: 739.1002s\n",
      "\titers: 400, epoch: 1 | loss: 0.1944844\n",
      "\tspeed: 0.0416s/iter; left time: 734.9105s\n",
      "\titers: 500, epoch: 1 | loss: 0.1941353\n",
      "\tspeed: 0.0416s/iter; left time: 731.1568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1729999\n",
      "\tspeed: 0.0416s/iter; left time: 726.9874s\n",
      "\titers: 700, epoch: 1 | loss: 0.1679289\n",
      "\tspeed: 0.0416s/iter; left time: 722.5073s\n",
      "\titers: 800, epoch: 1 | loss: 0.1699705\n",
      "\tspeed: 0.0416s/iter; left time: 719.0877s\n",
      "\titers: 900, epoch: 1 | loss: 0.1647512\n",
      "\tspeed: 0.0416s/iter; left time: 715.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.1937501 Vali Loss: 0.1664132 Test Loss: 0.2047869\n",
      "Validation loss decreased (inf --> 0.166413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1548872\n",
      "\tspeed: 0.1165s/iter; left time: 1990.3129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364976\n",
      "\tspeed: 0.0416s/iter; left time: 706.8648s\n",
      "\titers: 300, epoch: 2 | loss: 0.1455883\n",
      "\tspeed: 0.0417s/iter; left time: 703.0128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1231301\n",
      "\tspeed: 0.0416s/iter; left time: 697.4636s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362744\n",
      "\tspeed: 0.0416s/iter; left time: 693.1189s\n",
      "\titers: 600, epoch: 2 | loss: 0.1244080\n",
      "\tspeed: 0.0416s/iter; left time: 689.3567s\n",
      "\titers: 700, epoch: 2 | loss: 0.1334690\n",
      "\tspeed: 0.0416s/iter; left time: 685.3067s\n",
      "\titers: 800, epoch: 2 | loss: 0.1270750\n",
      "\tspeed: 0.0416s/iter; left time: 680.8819s\n",
      "\titers: 900, epoch: 2 | loss: 0.1180649\n",
      "\tspeed: 0.0416s/iter; left time: 677.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1352863 Vali Loss: 0.1410898 Test Loss: 0.1708414\n",
      "Validation loss decreased (0.166413 --> 0.141090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147558\n",
      "\tspeed: 0.1170s/iter; left time: 1891.8432s\n",
      "\titers: 200, epoch: 3 | loss: 0.1144703\n",
      "\tspeed: 0.0417s/iter; left time: 669.6380s\n",
      "\titers: 300, epoch: 3 | loss: 0.1129461\n",
      "\tspeed: 0.0416s/iter; left time: 665.2663s\n",
      "\titers: 400, epoch: 3 | loss: 0.1159053\n",
      "\tspeed: 0.0417s/iter; left time: 661.1881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1037145\n",
      "\tspeed: 0.0416s/iter; left time: 656.4345s\n",
      "\titers: 600, epoch: 3 | loss: 0.1191663\n",
      "\tspeed: 0.0416s/iter; left time: 652.6964s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158241\n",
      "\tspeed: 0.0416s/iter; left time: 648.3619s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989802\n",
      "\tspeed: 0.0417s/iter; left time: 644.6881s\n",
      "\titers: 900, epoch: 3 | loss: 0.1078756\n",
      "\tspeed: 0.0416s/iter; left time: 639.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.1118837 Vali Loss: 0.1274420 Test Loss: 0.1581856\n",
      "Validation loss decreased (0.141090 --> 0.127442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1074443\n",
      "\tspeed: 0.1171s/iter; left time: 1788.3894s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052178\n",
      "\tspeed: 0.0416s/iter; left time: 630.7722s\n",
      "\titers: 300, epoch: 4 | loss: 0.1018802\n",
      "\tspeed: 0.0416s/iter; left time: 626.5580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1033611\n",
      "\tspeed: 0.0416s/iter; left time: 622.8882s\n",
      "\titers: 500, epoch: 4 | loss: 0.1052628\n",
      "\tspeed: 0.0416s/iter; left time: 618.2769s\n",
      "\titers: 600, epoch: 4 | loss: 0.1043086\n",
      "\tspeed: 0.0416s/iter; left time: 614.4294s\n",
      "\titers: 700, epoch: 4 | loss: 0.1040385\n",
      "\tspeed: 0.0416s/iter; left time: 610.2642s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061757\n",
      "\tspeed: 0.0416s/iter; left time: 606.3039s\n",
      "\titers: 900, epoch: 4 | loss: 0.1004524\n",
      "\tspeed: 0.0416s/iter; left time: 601.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.1023712 Vali Loss: 0.1312658 Test Loss: 0.1651838\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0989314\n",
      "\tspeed: 0.1142s/iter; left time: 1640.3943s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047119\n",
      "\tspeed: 0.0417s/iter; left time: 594.2167s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982214\n",
      "\tspeed: 0.0417s/iter; left time: 590.0576s\n",
      "\titers: 400, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0417s/iter; left time: 585.9079s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974938\n",
      "\tspeed: 0.0416s/iter; left time: 581.2475s\n",
      "\titers: 600, epoch: 5 | loss: 0.0970161\n",
      "\tspeed: 0.0416s/iter; left time: 576.9025s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918606\n",
      "\tspeed: 0.0416s/iter; left time: 572.8600s\n",
      "\titers: 800, epoch: 5 | loss: 0.0898132\n",
      "\tspeed: 0.0417s/iter; left time: 569.1998s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893147\n",
      "\tspeed: 0.0416s/iter; left time: 564.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0967186 Vali Loss: 0.1319823 Test Loss: 0.1671596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0955259\n",
      "\tspeed: 0.1140s/iter; left time: 1534.6863s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896132\n",
      "\tspeed: 0.0416s/iter; left time: 556.4829s\n",
      "\titers: 300, epoch: 6 | loss: 0.0947796\n",
      "\tspeed: 0.0417s/iter; left time: 552.5246s\n",
      "\titers: 400, epoch: 6 | loss: 0.0908911\n",
      "\tspeed: 0.0416s/iter; left time: 548.1117s\n",
      "\titers: 500, epoch: 6 | loss: 0.0873807\n",
      "\tspeed: 0.0417s/iter; left time: 544.2589s\n",
      "\titers: 600, epoch: 6 | loss: 0.0879827\n",
      "\tspeed: 0.0417s/iter; left time: 540.0754s\n",
      "\titers: 700, epoch: 6 | loss: 0.0896935\n",
      "\tspeed: 0.0417s/iter; left time: 536.0600s\n",
      "\titers: 800, epoch: 6 | loss: 0.0941269\n",
      "\tspeed: 0.0416s/iter; left time: 531.3673s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933578\n",
      "\tspeed: 0.0417s/iter; left time: 527.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0908674 Vali Loss: 0.1343007 Test Loss: 0.1725691\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869733\n",
      "\tspeed: 0.1148s/iter; left time: 1441.3462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865798\n",
      "\tspeed: 0.0417s/iter; left time: 519.1138s\n",
      "\titers: 300, epoch: 7 | loss: 0.0872979\n",
      "\tspeed: 0.0417s/iter; left time: 515.1221s\n",
      "\titers: 400, epoch: 7 | loss: 0.0808157\n",
      "\tspeed: 0.0417s/iter; left time: 510.9330s\n",
      "\titers: 500, epoch: 7 | loss: 0.0819069\n",
      "\tspeed: 0.0417s/iter; left time: 506.6866s\n",
      "\titers: 600, epoch: 7 | loss: 0.0884176\n",
      "\tspeed: 0.0417s/iter; left time: 502.3795s\n",
      "\titers: 700, epoch: 7 | loss: 0.0929823\n",
      "\tspeed: 0.0417s/iter; left time: 498.2833s\n",
      "\titers: 800, epoch: 7 | loss: 0.0822935\n",
      "\tspeed: 0.0417s/iter; left time: 494.2249s\n",
      "\titers: 900, epoch: 7 | loss: 0.0851985\n",
      "\tspeed: 0.0417s/iter; left time: 490.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0852665 Vali Loss: 0.1313283 Test Loss: 0.1676679\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839205\n",
      "\tspeed: 0.1140s/iter; left time: 1328.2757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803091\n",
      "\tspeed: 0.0416s/iter; left time: 481.1273s\n",
      "\titers: 300, epoch: 8 | loss: 0.0736933\n",
      "\tspeed: 0.0416s/iter; left time: 476.6921s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799875\n",
      "\tspeed: 0.0416s/iter; left time: 472.7424s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814201\n",
      "\tspeed: 0.0416s/iter; left time: 468.2029s\n",
      "\titers: 600, epoch: 8 | loss: 0.0776833\n",
      "\tspeed: 0.0416s/iter; left time: 464.3979s\n",
      "\titers: 700, epoch: 8 | loss: 0.0707026\n",
      "\tspeed: 0.0417s/iter; left time: 460.3869s\n",
      "\titers: 800, epoch: 8 | loss: 0.0765746\n",
      "\tspeed: 0.0417s/iter; left time: 456.2890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0856424\n",
      "\tspeed: 0.0416s/iter; left time: 451.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0801459 Vali Loss: 0.1328648 Test Loss: 0.1732243\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051835522055625916, rmse:0.22767415642738342, mae:0.158115953207016, rse:0.7873289585113525\n",
      "Intermediate time for GB and pred_len 96: 00h:12m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2144550\n",
      "\tspeed: 0.0736s/iter; left time: 1320.3347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2042320\n",
      "\tspeed: 0.0505s/iter; left time: 901.4268s\n",
      "\titers: 300, epoch: 1 | loss: 0.1855985\n",
      "\tspeed: 0.0507s/iter; left time: 899.5263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1828096\n",
      "\tspeed: 0.0508s/iter; left time: 896.1169s\n",
      "\titers: 500, epoch: 1 | loss: 0.1863522\n",
      "\tspeed: 0.0508s/iter; left time: 890.4390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1806218\n",
      "\tspeed: 0.0507s/iter; left time: 885.0513s\n",
      "\titers: 700, epoch: 1 | loss: 0.1707170\n",
      "\tspeed: 0.0508s/iter; left time: 880.8659s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668490\n",
      "\tspeed: 0.0507s/iter; left time: 874.7028s\n",
      "\titers: 900, epoch: 1 | loss: 0.1642738\n",
      "\tspeed: 0.0508s/iter; left time: 870.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 902 | Train Loss: 0.1902878 Vali Loss: 0.1756261 Test Loss: 0.2136206\n",
      "Validation loss decreased (inf --> 0.175626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546461\n",
      "\tspeed: 0.1416s/iter; left time: 2412.0118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1453713\n",
      "\tspeed: 0.0507s/iter; left time: 858.6454s\n",
      "\titers: 300, epoch: 2 | loss: 0.1408072\n",
      "\tspeed: 0.0507s/iter; left time: 853.8900s\n",
      "\titers: 400, epoch: 2 | loss: 0.1328956\n",
      "\tspeed: 0.0507s/iter; left time: 848.6835s\n",
      "\titers: 500, epoch: 2 | loss: 0.1344081\n",
      "\tspeed: 0.0507s/iter; left time: 844.3704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1351472\n",
      "\tspeed: 0.0507s/iter; left time: 838.7043s\n",
      "\titers: 700, epoch: 2 | loss: 0.1377063\n",
      "\tspeed: 0.0507s/iter; left time: 834.0462s\n",
      "\titers: 800, epoch: 2 | loss: 0.1352134\n",
      "\tspeed: 0.0508s/iter; left time: 829.4362s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376040\n",
      "\tspeed: 0.0507s/iter; left time: 823.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1412551 Vali Loss: 0.1557616 Test Loss: 0.1941232\n",
      "Validation loss decreased (0.175626 --> 0.155762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1322913\n",
      "\tspeed: 0.1434s/iter; left time: 2314.1137s\n",
      "\titers: 200, epoch: 3 | loss: 0.1251840\n",
      "\tspeed: 0.0507s/iter; left time: 812.6631s\n",
      "\titers: 300, epoch: 3 | loss: 0.1327689\n",
      "\tspeed: 0.0507s/iter; left time: 807.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.1270881\n",
      "\tspeed: 0.0507s/iter; left time: 802.8697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1229750\n",
      "\tspeed: 0.0506s/iter; left time: 797.0577s\n",
      "\titers: 600, epoch: 3 | loss: 0.1328987\n",
      "\tspeed: 0.0507s/iter; left time: 793.3704s\n",
      "\titers: 700, epoch: 3 | loss: 0.1204278\n",
      "\tspeed: 0.0506s/iter; left time: 785.9965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1188312\n",
      "\tspeed: 0.0508s/iter; left time: 784.4461s\n",
      "\titers: 900, epoch: 3 | loss: 0.1182145\n",
      "\tspeed: 0.0508s/iter; left time: 779.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.1258696 Vali Loss: 0.1498645 Test Loss: 0.1913567\n",
      "Validation loss decreased (0.155762 --> 0.149865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1236095\n",
      "\tspeed: 0.1429s/iter; left time: 2177.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127460\n",
      "\tspeed: 0.0517s/iter; left time: 783.0264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1189013\n",
      "\tspeed: 0.0511s/iter; left time: 768.8154s\n",
      "\titers: 400, epoch: 4 | loss: 0.1107328\n",
      "\tspeed: 0.0506s/iter; left time: 756.4537s\n",
      "\titers: 500, epoch: 4 | loss: 0.1057849\n",
      "\tspeed: 0.0507s/iter; left time: 751.7938s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077283\n",
      "\tspeed: 0.0506s/iter; left time: 745.7883s\n",
      "\titers: 700, epoch: 4 | loss: 0.1090573\n",
      "\tspeed: 0.0507s/iter; left time: 742.5099s\n",
      "\titers: 800, epoch: 4 | loss: 0.1042960\n",
      "\tspeed: 0.0508s/iter; left time: 737.7649s\n",
      "\titers: 900, epoch: 4 | loss: 0.0960267\n",
      "\tspeed: 0.0508s/iter; left time: 733.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1102404 Vali Loss: 0.1309775 Test Loss: 0.1653814\n",
      "Validation loss decreased (0.149865 --> 0.130978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 128 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "informer_df_itrs = pd.DataFrame(informer_results)\n",
    "\n",
    "# Set multi-index \n",
    "informer_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df_itrs.to_csv(os.path.join(path, 'informer_df_itrs_128.csv'))\n",
    "informer_df_itrs = informer_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DF\n",
    "informer_df = informer_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer_128.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "patchtst_df_itrs = pd.DataFrame(patchtst_results)\n",
    "\n",
    "# Set multi-index \n",
    "patchtst_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df_itrs.to_csv(os.path.join(path, 'patchtst_df_itrs_128.csv'))\n",
    "patchtst_df_itrs = patchtst_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DF\n",
    "patchtst_df = patchtst_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 512\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFs per iteration\n",
    "# Convert the collected data into DataFrame\n",
    "patchtst_df_itrs = pd.DataFrame(patchtst_results)\n",
    "\n",
    "# Set multi-index \n",
    "patchtst_df_itrs.set_index(['Country', 'Pred_len', 'Iteration'], inplace=True)\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df_itrs.to_csv(os.path.join(path, 'patchtst_df_itrs_bs128_pl512.csv'))\n",
    "patchtst_df_itrs = patchtst_df_itrs.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DF\n",
    "patchtst_df = patchtst_df_itrs.groupby(['Country', 'Pred_len']).mean()\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
