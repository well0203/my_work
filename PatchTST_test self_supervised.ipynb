{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Standard - BETTER THAN SUPERVISED\n",
    "## Epochs = 10\n",
    "## Mask_ratio = 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=20, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "scaler_type: standard overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.00020565123083486514\n",
      "scaler_type: standard overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.8937587405919447.\n",
      "              0       0.941797       0.893759          00:11\n",
      "Better model found at epoch 1 with valid_loss value: 0.8819435262408463.\n",
      "              1       0.888402       0.881944          00:11\n",
      "Better model found at epoch 2 with valid_loss value: 0.8802761391375101.\n",
      "              2       0.875099       0.880276          00:11\n",
      "Better model found at epoch 3 with valid_loss value: 0.8768467281580553.\n",
      "              3       0.870150       0.876847          00:10\n",
      "Better model found at epoch 4 with valid_loss value: 0.8768031046582587.\n",
      "              4       0.869331       0.876803          00:10\n",
      "Better model found at epoch 5 with valid_loss value: 0.48734974127847847.\n",
      "              5       0.651341       0.487350          00:11\n",
      "Better model found at epoch 6 with valid_loss value: 0.47806604073433684.\n",
      "              6       0.495102       0.478066          00:11\n",
      "Better model found at epoch 7 with valid_loss value: 0.4758775951612083.\n",
      "              7       0.488275       0.475878          00:11\n",
      "Better model found at epoch 8 with valid_loss value: 0.47378120391324247.\n",
      "              8       0.484444       0.473781          00:11\n",
      "              9       0.483298       0.474195          00:11\n",
      "Better model found at epoch 10 with valid_loss value: 0.47264071558431653.\n",
      "             10       0.481517       0.472641          00:11\n",
      "Better model found at epoch 11 with valid_loss value: 0.4299471353107201.\n",
      "             11       0.467830       0.429947          00:11\n",
      "Better model found at epoch 12 with valid_loss value: 0.41059582231489017.\n",
      "             12       0.433492       0.410596          00:11\n",
      "Better model found at epoch 13 with valid_loss value: 0.3373667059728438.\n",
      "             13       0.399865       0.337367          00:11\n",
      "Better model found at epoch 14 with valid_loss value: 0.29700483752034174.\n",
      "             14       0.343583       0.297005          00:11\n",
      "Better model found at epoch 15 with valid_loss value: 0.2836998290022376.\n",
      "             15       0.322142       0.283700          00:11\n",
      "Better model found at epoch 16 with valid_loss value: 0.2697752118401648.\n",
      "             16       0.310738       0.269775          00:11\n",
      "Better model found at epoch 17 with valid_loss value: 0.26187087602980064.\n",
      "             17       0.299388       0.261871          00:11\n",
      "Better model found at epoch 18 with valid_loss value: 0.2602101436953316.\n",
      "             18       0.295597       0.260210          00:11\n",
      "Better model found at epoch 19 with valid_loss value: 0.25925435996618185.\n",
      "             19       0.294021       0.259254          00:11\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "# 29       0.473083       0.481049          \n",
    "# Define parameters in a dictionary\n",
    "params = {\n",
    "    \"--dset\": \"IT\",\n",
    "    \"--mask_ratio\": 0.4,\n",
    "    \"--scaler_type\": \"standard\",\n",
    "    #\"--if_relu\": None,  # Flags that don't require a value\n",
    "    #\"--batch_size\": 32,\n",
    "    \"--stride\": 12, # non-overlapping\n",
    "    \"--patch_len\": 12,\n",
    "    #\"--n_layers\": 2,\n",
    "    #\"--d_ff\": 2048,\n",
    "    #\"--n_heads\": 8,\n",
    "    #\"--d_model\": 512,\n",
    "    #\"--dropout\": 0.2, # 0.05\n",
    "    #\"--head_dropout\": 0.2,\n",
    "    \"--n_epochs_pretrain\": 20,\n",
    "}\n",
    "\n",
    "# Build the command string\n",
    "command = \"python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py \"\n",
    "\n",
    "# Add parameters to the command\n",
    "for key, value in params.items():\n",
    "    if value is not None:\n",
    "        command += f\"{key} {value} \"\n",
    "    else:\n",
    "        command += f\"{key} \"  # Add flags with no value\n",
    "\n",
    "# Complete command\n",
    "!{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(linear_prob_finetune=1, is_finetune=0, is_linear_probe=0, n_epochs_linear_probe=10, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "scaler_type: standard overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 9.770099572992256e-05\n",
      "Performing linear probing followed by end-to-end fine-tuning\n",
      "scaler_type: standard overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Starting linear probing for 10 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.4375233612184703.\n",
      "              0       0.650660       0.437523          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.39925256019884053.\n",
      "              1       0.534552       0.399253          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.3851482245473963.\n",
      "              2       0.477258       0.385148          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.3769201094004272.\n",
      "              3       0.434919       0.376920          00:02\n",
      "Better model found at epoch 4 with valid_loss value: 0.37526229721826687.\n",
      "              4       0.412840       0.375262          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.37286940125355983.\n",
      "              5       0.402566       0.372869          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.37191715349115134.\n",
      "              6       0.397621       0.371917          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.369649963130594.\n",
      "              7       0.394739       0.369650          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.3689524638934093.\n",
      "              8       0.393010       0.368952          00:02\n",
      "Better model found at epoch 9 with valid_loss value: 0.36836581125406836.\n",
      "              9       0.392102       0.368366          00:02\n",
      "Starting full fine-tuning for 20 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss           time\n",
      "              0       0.392289       0.369331          00:02\n",
      "              1       0.394288       0.373728          00:02\n",
      "              2       0.396998       0.375672          00:02\n",
      "              3       0.398068       0.374551          00:02\n",
      "              4       0.397380       0.373747          00:02\n",
      "              5       0.395958       0.372862          00:02\n",
      "              6       0.394284       0.371301          00:02\n",
      "              7       0.392629       0.369872          00:02\n",
      "              8       0.391455       0.368582          00:02\n",
      "              9       0.390467       0.368538          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.3653418445509561.\n",
      "              0       0.389783       0.365342          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.36065255670260377.\n",
      "              1       0.383243       0.360653          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.3565081255721115.\n",
      "              2       0.373628       0.356508          00:11\n",
      "Better model found at epoch 3 with valid_loss value: 0.35262742193856794.\n",
      "              3       0.364340       0.352627          00:10\n",
      "Better model found at epoch 4 with valid_loss value: 0.35019491520036616.\n",
      "              4       0.357580       0.350195          00:11\n",
      "              5       0.352688       0.350716          00:11\n",
      "Better model found at epoch 6 with valid_loss value: 0.3495237171989422.\n",
      "              6       0.348728       0.349524          00:10\n",
      "Better model found at epoch 7 with valid_loss value: 0.3484562128127543.\n",
      "              7       0.345784       0.348456          00:10\n",
      "Better model found at epoch 8 with valid_loss value: 0.3472458792081977.\n",
      "              8       0.342872       0.347246          00:11\n",
      "              9       0.340873       0.349340          00:11\n",
      "             10       0.338958       0.347374          00:11\n",
      "Better model found at epoch 11 with valid_loss value: 0.345904834024105.\n",
      "             11       0.336281       0.345905          00:10\n",
      "             12       0.335310       0.345941          00:10\n",
      "             13       0.333409       0.346668          00:10\n",
      "             14       0.332135       0.346921          00:10\n",
      "             15       0.331348       0.346034          00:10\n",
      "Better model found at epoch 16 with valid_loss value: 0.3456414243668633.\n",
      "             16       0.330452       0.345641          00:10\n",
      "             17       0.329622       0.345953          00:10\n",
      "Better model found at epoch 18 with valid_loss value: 0.3454782931372051.\n",
      "             18       0.329364       0.345478          00:10\n",
      "             19       0.329505       0.345754          00:10\n",
      "Linear probing and finetune completed\n",
      "scaler_type: standard overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "scores: mse: 0.37064707 rmse: 0.6088079 mae: 0.36373523\n",
      "----------- Complete! -----------\n"
     ]
    }
   ],
   "source": [
    "# Define parameters in a dictionary\n",
    "params = {\n",
    "    \"--dset\": \"IT\",\n",
    "    \"--linear_prob_finetune\": 1,\n",
    "    \"--pretrained_model\": \"saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1.pth\",    \n",
    "    #\"--scaler_type\": \"minmax\",\n",
    "    #\"--if_relu\": None,  # Flags that don't require a value\n",
    "    #\"--batch_size\": 32,\n",
    "    \"--stride\": 12,\n",
    "    \"--patch_len\": 12,\n",
    "    #\"--n_layers\": 2,\n",
    "    #\"--d_ff\": 2048,\n",
    "    #\"--n_heads\": 8,\n",
    "    #\"--d_model\": 512,\n",
    "    #\"--dropout\": 0.05,\n",
    "    #\"--head_dropout\": 0.0,\n",
    "    \"--n_epochs_finetune\": 20,\n",
    "    \"--n_epochs_linear_probe\": 10\n",
    "}\n",
    "\n",
    "# Build the command string\n",
    "command = \"python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py \"\n",
    "\n",
    "# Add parameters to the command\n",
    "for key, value in params.items():\n",
    "    if value is not None:\n",
    "        command += f\"{key} {value} \"\n",
    "    else:\n",
    "        command += f\"{key} \"  # Add flags with no value\n",
    "\n",
    "# Run the command with !\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain Standard Fine-tune min-max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(linear_prob_finetune=1, is_finetune=0, is_linear_probe=0, n_epochs_linear_probe=20, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 8.111308307896872e-05\n",
      "Performing linear probing followed by end-to-end fine-tuning\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Starting linear probing for 20 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.10652322295819772.\n",
      "              0       0.156235       0.106523          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.09552283042615949.\n",
      "              1       0.131654       0.095523          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.0905092467516782.\n",
      "              2       0.122404       0.090509          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.08772259705235455.\n",
      "              3       0.113228       0.087723          00:02\n",
      "Better model found at epoch 4 with valid_loss value: 0.08630030409313975.\n",
      "              4       0.104344       0.086300          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.08550790983841029.\n",
      "              5       0.097408       0.085508          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.08546888508187551.\n",
      "              6       0.093293       0.085469          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.08459200506000814.\n",
      "              7       0.091355       0.084592          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.08441685551642596.\n",
      "              8       0.090437       0.084417          00:02\n",
      "              9       0.090052       0.084508          00:02\n",
      "Better model found at epoch 10 with valid_loss value: 0.08405048565907242.\n",
      "             10       0.089746       0.084050          00:02\n",
      "             11       0.089542       0.084142          00:02\n",
      "             12       0.089317       0.084111          00:02\n",
      "Better model found at epoch 13 with valid_loss value: 0.08376485701980776.\n",
      "             13       0.089126       0.083765          00:02\n",
      "Better model found at epoch 14 with valid_loss value: 0.0836509810122559.\n",
      "             14       0.088907       0.083651          00:02\n",
      "Better model found at epoch 15 with valid_loss value: 0.08354810027207078.\n",
      "             15       0.088743       0.083548          00:02\n",
      "Better model found at epoch 16 with valid_loss value: 0.08336318708998677.\n",
      "             16       0.088704       0.083363          00:02\n",
      "             17       0.088523       0.083391          00:02\n",
      "Better model found at epoch 18 with valid_loss value: 0.08333079723733727.\n",
      "             18       0.088485       0.083331          00:02\n",
      "Better model found at epoch 19 with valid_loss value: 0.08329011375483117.\n",
      "             19       0.088411       0.083290          00:02\n",
      "Starting full fine-tuning for 20 epochs\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss           time\n",
      "              0       0.088540       0.083651          00:02\n",
      "              1       0.089005       0.084538          00:02\n",
      "              2       0.089768       0.084842          00:02\n",
      "              3       0.089999       0.084746          00:02\n",
      "              4       0.089878       0.084811          00:02\n",
      "              5       0.089639       0.084139          00:02\n",
      "              6       0.089322       0.083964          00:02\n",
      "              7       0.088969       0.083630          00:02\n",
      "              8       0.088685       0.083425          00:02\n",
      "              9       0.088565       0.083319          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.08275200616450112.\n",
      "              0       0.088003       0.082752          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.08193227272871745.\n",
      "              1       0.086737       0.081932          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.08073258178810262.\n",
      "              2       0.084777       0.080733          00:10\n",
      "Better model found at epoch 3 with valid_loss value: 0.07988959639124797.\n",
      "              3       0.082739       0.079890          00:11\n",
      "Better model found at epoch 4 with valid_loss value: 0.07931453000247915.\n",
      "              4       0.081035       0.079315          00:11\n",
      "Better model found at epoch 5 with valid_loss value: 0.07887239510495067.\n",
      "              5       0.079923       0.078872          00:10\n",
      "              6       0.079023       0.078872          00:10\n",
      "Better model found at epoch 7 with valid_loss value: 0.07855782318736015.\n",
      "              7       0.078454       0.078558          00:10\n",
      "              8       0.077914       0.078653          00:11\n",
      "              9       0.077445       0.078616          00:10\n",
      "Better model found at epoch 10 with valid_loss value: 0.0783978951859998.\n",
      "             10       0.076967       0.078398          00:10\n",
      "Better model found at epoch 11 with valid_loss value: 0.07802483579606133.\n",
      "             11       0.076681       0.078025          00:10\n",
      "             12       0.076255       0.078392          00:10\n",
      "             13       0.075951       0.078236          00:10\n",
      "Better model found at epoch 14 with valid_loss value: 0.07798015945223505.\n",
      "             14       0.075747       0.077980          00:10\n",
      "Better model found at epoch 15 with valid_loss value: 0.07794565397903529.\n",
      "             15       0.075530       0.077946          00:10\n",
      "Better model found at epoch 16 with valid_loss value: 0.07782339991545464.\n",
      "             16       0.075295       0.077823          00:10\n",
      "             17       0.075283       0.077925          00:11\n",
      "             18       0.075176       0.077925          00:11\n",
      "             19       0.075173       0.077881          00:10\n",
      "Linear probing and finetune completed\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "scores: mse: 0.018597834 rmse: 0.13637388 mae: 0.082329504\n",
      "----------- Complete! -----------\n"
     ]
    }
   ],
   "source": [
    "# Define parameters in a dictionary\n",
    "params = {\n",
    "    \"--dset\": \"IT\",\n",
    "    \"--linear_prob_finetune\": 1,\n",
    "    \"--pretrained_model\": \"saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain20_mask0.4_model1.pth\",    \n",
    "    \"--scaler_type\": \"minmax\",\n",
    "    #\"--if_relu\": None,  # Flags that don't require a value\n",
    "    #\"--batch_size\": 32,\n",
    "    \"--stride\": 12,\n",
    "    \"--patch_len\": 12,\n",
    "    #\"--n_layers\": 2,\n",
    "    #\"--d_ff\": 2048,\n",
    "    #\"--n_heads\": 8,\n",
    "    #\"--d_model\": 512,\n",
    "    #\"--dropout\": 0.05,\n",
    "    #\"--head_dropout\": 0.0,\n",
    "    \"--n_epochs_finetune\": 20,\n",
    "    \"--n_epochs_linear_probe\": 20\n",
    "}\n",
    "\n",
    "# Build the command string\n",
    "command = \"python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py \"\n",
    "\n",
    "# Add parameters to the command\n",
    "for key, value in params.items():\n",
    "    if value is not None:\n",
    "        command += f\"{key} {value} \"\n",
    "    else:\n",
    "        command += f\"{key} \"  # Add flags with no value\n",
    "\n",
    "# Run the command with !\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.000298364724028334\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.9396839560872661.\n",
      "              0       0.960868       0.939684          00:11\n",
      "Better model found at epoch 1 with valid_loss value: 0.936014099369406.\n",
      "              1       0.933757       0.936014          00:11\n",
      "Better model found at epoch 2 with valid_loss value: 0.9334741628102116.\n",
      "              2       0.930378       0.933474          00:11\n",
      "Better model found at epoch 3 with valid_loss value: 0.7131503000406835.\n",
      "              3       0.765316       0.713150          00:11\n",
      "Better model found at epoch 4 with valid_loss value: 0.7123715132984133.\n",
      "              4       0.713887       0.712372          00:11\n",
      "Better model found at epoch 5 with valid_loss value: 0.7093881903478437.\n",
      "              5       0.711447       0.709388          00:11\n",
      "              6       0.709750       0.710327          00:11\n",
      "              7       0.708047       0.709833          00:11\n",
      "Better model found at epoch 8 with valid_loss value: 0.7070547701383239.\n",
      "              8       0.706682       0.707055          00:11\n",
      "              9       0.707885       0.707937          00:11\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4 --scaler_type minmax --if_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(is_finetune=1, is_linear_probe=0, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='minmax', if_relu=True, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.2_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 0.00011768119524349978\n",
      "end-to-end finetuning\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.03460147072378458.\n",
      "              0       0.042033       0.034601       0.152185          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.0333345020564229.\n",
      "              1       0.035798       0.033335       0.147897          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.03277997109247864.\n",
      "              2       0.034525       0.032780       0.146029          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.03252638218556118.\n",
      "              3       0.033726       0.032526       0.144965          00:02\n",
      "Better model found at epoch 4 with valid_loss value: 0.03236253333343928.\n",
      "              4       0.033212       0.032363       0.144487          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.03230625832342733.\n",
      "              5       0.032906       0.032306       0.144476          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.032278213935523034.\n",
      "              6       0.032711       0.032278       0.144110          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.03222903817334342.\n",
      "              7       0.032558       0.032229       0.144060          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.032199307745117985.\n",
      "              8       0.032491       0.032199       0.143825          00:02\n",
      "Better model found at epoch 9 with valid_loss value: 0.03218804678362108.\n",
      "              9       0.032462       0.032188       0.143845          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss      valid_mae           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.03212651500282877.\n",
      "              0       0.032431       0.032127       0.143555          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.0320320868123538.\n",
      "              1       0.032273       0.032032       0.143026          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.03191563580655004.\n",
      "              2       0.032034       0.031916       0.142443          00:10\n",
      "Better model found at epoch 3 with valid_loss value: 0.03179110471944289.\n",
      "              3       0.031767       0.031791       0.142093          00:10\n",
      "              4       0.031502       0.031792       0.142047          00:10\n",
      "              5       0.031277       0.031823       0.141809          00:09\n",
      "              6       0.031070       0.031855       0.141777          00:10\n",
      "              7       0.030878       0.031848       0.141774          00:10\n",
      "              8       0.030716       0.031928       0.141821          00:11\n",
      "              9       0.030553       0.031869       0.141748          00:10\n",
      "             10       0.030400       0.032169       0.142450          00:10\n",
      "             11       0.030259       0.032027       0.141980          00:10\n",
      "             12       0.030156       0.032077       0.142149          00:10\n",
      "             13       0.030062       0.032000       0.142007          00:04\n",
      "             14       0.029978       0.032048       0.142020          00:04\n",
      "             15       0.029923       0.032062       0.142047          00:04\n",
      "             16       0.029878       0.032079       0.142072          00:04\n",
      "             17       0.029831       0.032098       0.142140          00:10\n",
      "             18       0.029822       0.032100       0.142139          00:10\n",
      "             19       0.029821       0.032032       0.142040          00:10\n",
      "finetune completed\n",
      "scaler_type: minmax overlapping_windows: True\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "scores: mse: 0.03523118 rmse: 0.1876997 mae: 0.15119967\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py\", line 230, in <module>\n",
      "    out = test_func(args.save_path+args.save_finetuned_model)         \n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work/PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py\", line 216, in test_func\n",
      "    pd.DataFrame(np.array(out[2]).reshape(1,-1), columns=['mse','mae']).to_csv(args.save_path + args.save_finetuned_model + '_acc.csv', float_format='%.6f', index=False)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/frame.py\", line 722, in __init__\n",
      "    mgr = ndarray_to_mgr(\n",
      "          ^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/internals/construction.py\", line 349, in ndarray_to_mgr\n",
      "    _check_values_indices_shape_match(values, index, columns)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/pandas/core/internals/construction.py\", line 420, in _check_values_indices_shape_match\n",
      "    raise ValueError(f\"Shape of passed values is {passed}, indices imply {implied}\")\n",
      "ValueError: Shape of passed values is (1, 3), indices imply (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# score: [array(0.03520434, dtype=float32), array(0.15043405, dtype=float32)]\n",
    "# scores: mse: 0.03537787 mae: 0.15080553\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py --dset IT --is_finetune 1 --pretrained_model saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.2_model1.pth --scaler_type minmax --if_relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.0002477076355991711\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.8858883937652563.\n",
      "              0       0.933535       0.885888          00:11\n",
      "^C\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(dset_pretrain='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=512, dropout=0.2, head_dropout=0.2, mask_ratio=0.4, n_epochs_pretrain=10, lr=0.0001, pretrained_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "suggested_lr 0.00017073526474706903\n",
      "number of patches: 42\n",
      "number of model params 603404\n",
      "          epoch     train_loss     valid_loss           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.8872300746287632.\n",
      "              0       0.942443       0.887230          00:08\n",
      "Better model found at epoch 1 with valid_loss value: 0.8765522496694467.\n",
      "              1       0.879432       0.876552          00:05\n",
      "^C\n",
      "pretraining completed\n",
      "Model saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1\n",
      "Metrics saved in: saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1_losses.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_pretrain.py --dset IT --mask_ratio  0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(is_finetune=1, is_linear_probe=0, dset_finetune='IT', context_points=512, target_points=96, batch_size=64, num_workers=0, scaler='standard', features='M', patch_len=12, stride=12, revin=1, overlapping_windows=True, scaler_type='standard', if_relu=False, n_layers=3, n_heads=16, d_model=128, d_ff=256, dropout=0.2, head_dropout=0.2, n_epochs_finetune=20, lr=0.0001, pretrained_model='saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1.pth', finetuned_model_id=1, model_type='based_model')\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "suggested_lr 8.111308307896872e-05\n",
      "end-to-end finetuning\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "check unmatched_layers: ['backbone.encoder.layers.0.ff.0.weight', 'backbone.encoder.layers.0.ff.0.bias', 'backbone.encoder.layers.0.ff.3.weight', 'backbone.encoder.layers.1.ff.0.weight', 'backbone.encoder.layers.1.ff.0.bias', 'backbone.encoder.layers.1.ff.3.weight', 'backbone.encoder.layers.2.ff.0.weight', 'backbone.encoder.layers.2.ff.0.bias', 'backbone.encoder.layers.2.ff.3.weight']\n",
      "Finetune the head\n",
      "          epoch     train_loss     valid_loss      valid_mse           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.41477148119660295.\n",
      "              0       0.755971       0.414771       0.414771          00:02\n",
      "Better model found at epoch 1 with valid_loss value: 0.36928234177939384.\n",
      "              1       0.528718       0.369282       0.369282          00:02\n",
      "Better model found at epoch 2 with valid_loss value: 0.3521397763679821.\n",
      "              2       0.458563       0.352140       0.352140          00:02\n",
      "Better model found at epoch 3 with valid_loss value: 0.34393247972182667.\n",
      "              3       0.412447       0.343932       0.343933          00:02\n",
      "              4       0.387422       0.344598       0.344598          00:02\n",
      "Better model found at epoch 5 with valid_loss value: 0.33935693875864525.\n",
      "              5       0.373936       0.339357       0.339357          00:02\n",
      "Better model found at epoch 6 with valid_loss value: 0.33897092243439786.\n",
      "              6       0.365762       0.338971       0.338971          00:02\n",
      "Better model found at epoch 7 with valid_loss value: 0.33810230624491455.\n",
      "              7       0.361831       0.338102       0.338102          00:02\n",
      "Better model found at epoch 8 with valid_loss value: 0.33741946736421885.\n",
      "              8       0.359460       0.337419       0.337419          00:02\n",
      "              9       0.358488       0.337625       0.337625          00:02\n",
      "Finetune the entire network\n",
      "          epoch     train_loss     valid_loss      valid_mse           time\n",
      "Better model found at epoch 0 with valid_loss value: 0.33576598574806754.\n",
      "              0       0.356681       0.335766       0.335766          00:10\n",
      "Better model found at epoch 1 with valid_loss value: 0.33318790842402357.\n",
      "              1       0.352328       0.333188       0.333188          00:10\n",
      "Better model found at epoch 2 with valid_loss value: 0.33019371932846825.\n",
      "              2       0.346426       0.330194       0.330194          00:10\n",
      "Better model found at epoch 3 with valid_loss value: 0.32762317083248577.\n",
      "              3       0.339938       0.327623       0.327623          00:10\n",
      "              4       0.332391       0.328190       0.328189          00:10\n",
      "Better model found at epoch 5 with valid_loss value: 0.3253272159784378.\n",
      "              5       0.325821       0.325327       0.325327          00:09\n",
      "              6       0.319472       0.325361       0.325361          00:10\n",
      "Better model found at epoch 7 with valid_loss value: 0.3207517743401648.\n",
      "              7       0.314101       0.320752       0.320752          00:04\n",
      "              8       0.309127       0.324733       0.324733          00:04\n",
      "              9       0.305546       0.322477       0.322477          00:05\n",
      "             10       0.302396       0.320871       0.320871          00:10\n",
      "             11       0.298669       0.322160       0.322160          00:08\n",
      "             12       0.295239       0.321158       0.321158          00:09\n",
      "             13       0.293238       0.324921       0.324921          00:04\n",
      "             14       0.291271       0.326656       0.326657          00:04\n",
      "             15       0.290286       0.325635       0.325635          00:10\n",
      "             16       0.288479       0.324677       0.324677          00:10\n",
      "             17       0.287576       0.324321       0.324321          00:10\n",
      "             18       0.287653       0.324585       0.324585          00:10\n",
      "             19       0.287561       0.324591       0.324591          00:10\n",
      "finetune completed\n",
      "number of patches: 42\n",
      "number of model params 920672\n",
      "score: [array(0.34755072, dtype=float32), array(0.37232623, dtype=float32)]\n",
      "----------- Complete! -----------\n"
     ]
    }
   ],
   "source": [
    "!python PatchTST-main/PatchTST_self_supervised/patchtst_finetune.py --dset IT --is_finetune 1 --pretrained_model saved_models/IT/masked_patchtst/based_model/patchtst_pretrained_cw512_patch12_stride12_epochs-pretrain10_mask0.4_model1.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
