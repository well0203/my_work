{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Connecting to CUDA](#1-connecting-to-cuda)\n",
    "- [2. Informer](#2-informer)\n",
    "- [3. PatchTST 336](#3-patchtst-336)\n",
    "- [4. PatchTST 512](#4-patchtst-512)\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "Script with Informer and PatchTST (default parameters). PatchTST with seq_len = 336 and 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "from utils.helper import extract_metrics_from_output, running_time, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connecting to CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on GPU, because running it on CPU will cost a lot of time.\n",
    "\n",
    "\n",
    "I do not recommend to run it in Google Colab, because it interrupts training process.\n",
    "\n",
    "If you are not going to use remote servers with multiple GPUs, skip this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n"
     ]
    }
   ],
   "source": [
    "# For CUDA making it available this works:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of available GPUs:\", num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quadro RTX 6000'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the GPU you want to use (e.g., 0, 1, 2, etc.)\n",
    "# Choose that one that is not used by other processes\n",
    "cuda_device = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/informer/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 96\n",
    "model = \"Informer\"\n",
    "itr = 2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning\n",
    "lr = 0.0001\n",
    "#n_heads = 16\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "loss = \"MAE\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2157750\n",
      "\tspeed: 0.0573s/iter; left time: 1032.1750s\n",
      "\titers: 200, epoch: 1 | loss: 0.1963026\n",
      "\tspeed: 0.0345s/iter; left time: 618.3465s\n",
      "\titers: 300, epoch: 1 | loss: 0.1900428\n",
      "\tspeed: 0.0346s/iter; left time: 616.3469s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759242\n",
      "\tspeed: 0.0346s/iter; left time: 612.6584s\n",
      "\titers: 500, epoch: 1 | loss: 0.1711153\n",
      "\tspeed: 0.0346s/iter; left time: 609.0709s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630517\n",
      "\tspeed: 0.0346s/iter; left time: 605.7895s\n",
      "\titers: 700, epoch: 1 | loss: 0.1811213\n",
      "\tspeed: 0.0346s/iter; left time: 602.2036s\n",
      "\titers: 800, epoch: 1 | loss: 0.1556394\n",
      "\tspeed: 0.0346s/iter; left time: 598.6039s\n",
      "\titers: 900, epoch: 1 | loss: 0.1458707\n",
      "\tspeed: 0.0346s/iter; left time: 595.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.96s\n",
      "Steps: 906 | Train Loss: 0.1844934 Vali Loss: 0.1649067 Test Loss: 0.1739943\n",
      "Validation loss decreased (inf --> 0.164907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1358088\n",
      "\tspeed: 0.1027s/iter; left time: 1757.8565s\n",
      "\titers: 200, epoch: 2 | loss: 0.1412189\n",
      "\tspeed: 0.0345s/iter; left time: 586.6060s\n",
      "\titers: 300, epoch: 2 | loss: 0.1239359\n",
      "\tspeed: 0.0345s/iter; left time: 582.8982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1101899\n",
      "\tspeed: 0.0345s/iter; left time: 579.3501s\n",
      "\titers: 500, epoch: 2 | loss: 0.1120785\n",
      "\tspeed: 0.0344s/iter; left time: 575.1125s\n",
      "\titers: 600, epoch: 2 | loss: 0.1019989\n",
      "\tspeed: 0.0344s/iter; left time: 571.9308s\n",
      "\titers: 700, epoch: 2 | loss: 0.1072432\n",
      "\tspeed: 0.0339s/iter; left time: 559.6339s\n",
      "\titers: 800, epoch: 2 | loss: 0.1118224\n",
      "\tspeed: 0.0338s/iter; left time: 555.2880s\n",
      "\titers: 900, epoch: 2 | loss: 0.1012448\n",
      "\tspeed: 0.0338s/iter; left time: 551.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.1192783 Vali Loss: 0.1259812 Test Loss: 0.1363558\n",
      "Validation loss decreased (0.164907 --> 0.125981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092039\n",
      "\tspeed: 0.0994s/iter; left time: 1611.1556s\n",
      "\titers: 200, epoch: 3 | loss: 0.0914676\n",
      "\tspeed: 0.0344s/iter; left time: 554.0304s\n",
      "\titers: 300, epoch: 3 | loss: 0.0905245\n",
      "\tspeed: 0.0344s/iter; left time: 550.6343s\n",
      "\titers: 400, epoch: 3 | loss: 0.0860451\n",
      "\tspeed: 0.0344s/iter; left time: 547.1417s\n",
      "\titers: 500, epoch: 3 | loss: 0.0840570\n",
      "\tspeed: 0.0344s/iter; left time: 544.1619s\n",
      "\titers: 600, epoch: 3 | loss: 0.0864475\n",
      "\tspeed: 0.0345s/iter; left time: 541.2266s\n",
      "\titers: 700, epoch: 3 | loss: 0.0776535\n",
      "\tspeed: 0.0344s/iter; left time: 537.5386s\n",
      "\titers: 800, epoch: 3 | loss: 0.0880026\n",
      "\tspeed: 0.0339s/iter; left time: 525.2373s\n",
      "\titers: 900, epoch: 3 | loss: 0.0833839\n",
      "\tspeed: 0.0339s/iter; left time: 522.1821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.37s\n",
      "Steps: 906 | Train Loss: 0.0881952 Vali Loss: 0.1017724 Test Loss: 0.1044518\n",
      "Validation loss decreased (0.125981 --> 0.101772).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744945\n",
      "\tspeed: 0.0997s/iter; left time: 1525.1724s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867104\n",
      "\tspeed: 0.0346s/iter; left time: 526.1904s\n",
      "\titers: 300, epoch: 4 | loss: 0.0777602\n",
      "\tspeed: 0.0346s/iter; left time: 522.0265s\n",
      "\titers: 400, epoch: 4 | loss: 0.0799538\n",
      "\tspeed: 0.0345s/iter; left time: 518.2007s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863173\n",
      "\tspeed: 0.0345s/iter; left time: 514.7978s\n",
      "\titers: 600, epoch: 4 | loss: 0.0789659\n",
      "\tspeed: 0.0345s/iter; left time: 510.7476s\n",
      "\titers: 700, epoch: 4 | loss: 0.0863506\n",
      "\tspeed: 0.0346s/iter; left time: 508.8477s\n",
      "\titers: 800, epoch: 4 | loss: 0.0809430\n",
      "\tspeed: 0.0346s/iter; left time: 504.7647s\n",
      "\titers: 900, epoch: 4 | loss: 0.0644707\n",
      "\tspeed: 0.0345s/iter; left time: 500.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0795589 Vali Loss: 0.0984519 Test Loss: 0.0999526\n",
      "Validation loss decreased (0.101772 --> 0.098452).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0721323\n",
      "\tspeed: 0.0989s/iter; left time: 1423.9969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783579\n",
      "\tspeed: 0.0345s/iter; left time: 493.9352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0719792\n",
      "\tspeed: 0.0346s/iter; left time: 490.6305s\n",
      "\titers: 400, epoch: 5 | loss: 0.0887703\n",
      "\tspeed: 0.0346s/iter; left time: 487.6967s\n",
      "\titers: 500, epoch: 5 | loss: 0.0698399\n",
      "\tspeed: 0.0345s/iter; left time: 483.3961s\n",
      "\titers: 600, epoch: 5 | loss: 0.0868544\n",
      "\tspeed: 0.0346s/iter; left time: 480.1936s\n",
      "\titers: 700, epoch: 5 | loss: 0.0848192\n",
      "\tspeed: 0.0346s/iter; left time: 477.6474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0792127\n",
      "\tspeed: 0.0345s/iter; left time: 472.9793s\n",
      "\titers: 900, epoch: 5 | loss: 0.0864622\n",
      "\tspeed: 0.0345s/iter; left time: 469.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0759394 Vali Loss: 0.0958418 Test Loss: 0.1013505\n",
      "Validation loss decreased (0.098452 --> 0.095842).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0766028\n",
      "\tspeed: 0.1005s/iter; left time: 1355.8127s\n",
      "\titers: 200, epoch: 6 | loss: 0.0649590\n",
      "\tspeed: 0.0340s/iter; left time: 454.6845s\n",
      "\titers: 300, epoch: 6 | loss: 0.0727186\n",
      "\tspeed: 0.0340s/iter; left time: 451.7025s\n",
      "\titers: 400, epoch: 6 | loss: 0.0766119\n",
      "\tspeed: 0.0340s/iter; left time: 448.5078s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743469\n",
      "\tspeed: 0.0339s/iter; left time: 444.3921s\n",
      "\titers: 600, epoch: 6 | loss: 0.0666672\n",
      "\tspeed: 0.0342s/iter; left time: 444.0445s\n",
      "\titers: 700, epoch: 6 | loss: 0.0702888\n",
      "\tspeed: 0.0346s/iter; left time: 445.4402s\n",
      "\titers: 800, epoch: 6 | loss: 0.0753023\n",
      "\tspeed: 0.0345s/iter; left time: 441.7408s\n",
      "\titers: 900, epoch: 6 | loss: 0.0721991\n",
      "\tspeed: 0.0345s/iter; left time: 438.1652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 906 | Train Loss: 0.0725840 Vali Loss: 0.0960399 Test Loss: 0.1029606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0633076\n",
      "\tspeed: 0.0959s/iter; left time: 1207.1412s\n",
      "\titers: 200, epoch: 7 | loss: 0.0646344\n",
      "\tspeed: 0.0341s/iter; left time: 425.4750s\n",
      "\titers: 300, epoch: 7 | loss: 0.0732895\n",
      "\tspeed: 0.0341s/iter; left time: 421.7839s\n",
      "\titers: 400, epoch: 7 | loss: 0.0704056\n",
      "\tspeed: 0.0341s/iter; left time: 418.9666s\n",
      "\titers: 500, epoch: 7 | loss: 0.0750957\n",
      "\tspeed: 0.0340s/iter; left time: 414.5119s\n",
      "\titers: 600, epoch: 7 | loss: 0.0560974\n",
      "\tspeed: 0.0340s/iter; left time: 411.1310s\n",
      "\titers: 700, epoch: 7 | loss: 0.0703704\n",
      "\tspeed: 0.0339s/iter; left time: 406.7731s\n",
      "\titers: 800, epoch: 7 | loss: 0.0585428\n",
      "\tspeed: 0.0340s/iter; left time: 404.0264s\n",
      "\titers: 900, epoch: 7 | loss: 0.0656901\n",
      "\tspeed: 0.0340s/iter; left time: 400.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0696662 Vali Loss: 0.0953170 Test Loss: 0.1043832\n",
      "Validation loss decreased (0.095842 --> 0.095317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0597942\n",
      "\tspeed: 0.0999s/iter; left time: 1166.6990s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753576\n",
      "\tspeed: 0.0340s/iter; left time: 394.0254s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652202\n",
      "\tspeed: 0.0340s/iter; left time: 389.8927s\n",
      "\titers: 400, epoch: 8 | loss: 0.0703675\n",
      "\tspeed: 0.0340s/iter; left time: 386.8097s\n",
      "\titers: 500, epoch: 8 | loss: 0.0684308\n",
      "\tspeed: 0.0340s/iter; left time: 383.7727s\n",
      "\titers: 600, epoch: 8 | loss: 0.0796844\n",
      "\tspeed: 0.0340s/iter; left time: 379.9436s\n",
      "\titers: 700, epoch: 8 | loss: 0.0586823\n",
      "\tspeed: 0.0340s/iter; left time: 376.6601s\n",
      "\titers: 800, epoch: 8 | loss: 0.0628379\n",
      "\tspeed: 0.0340s/iter; left time: 373.1167s\n",
      "\titers: 900, epoch: 8 | loss: 0.0772258\n",
      "\tspeed: 0.0340s/iter; left time: 369.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0667833 Vali Loss: 0.0989558 Test Loss: 0.1058859\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731515\n",
      "\tspeed: 0.0953s/iter; left time: 1026.8488s\n",
      "\titers: 200, epoch: 9 | loss: 0.0666756\n",
      "\tspeed: 0.0339s/iter; left time: 362.1014s\n",
      "\titers: 300, epoch: 9 | loss: 0.0595185\n",
      "\tspeed: 0.0340s/iter; left time: 358.9964s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703624\n",
      "\tspeed: 0.0339s/iter; left time: 354.9658s\n",
      "\titers: 500, epoch: 9 | loss: 0.0656522\n",
      "\tspeed: 0.0339s/iter; left time: 351.8254s\n",
      "\titers: 600, epoch: 9 | loss: 0.0701082\n",
      "\tspeed: 0.0340s/iter; left time: 348.9358s\n",
      "\titers: 700, epoch: 9 | loss: 0.0658102\n",
      "\tspeed: 0.0340s/iter; left time: 345.7134s\n",
      "\titers: 800, epoch: 9 | loss: 0.0694849\n",
      "\tspeed: 0.0340s/iter; left time: 342.2395s\n",
      "\titers: 900, epoch: 9 | loss: 0.0585585\n",
      "\tspeed: 0.0340s/iter; left time: 338.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0644456 Vali Loss: 0.0969864 Test Loss: 0.1054834\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0660802\n",
      "\tspeed: 0.0965s/iter; left time: 952.2213s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685927\n",
      "\tspeed: 0.0346s/iter; left time: 337.5984s\n",
      "\titers: 300, epoch: 10 | loss: 0.0581311\n",
      "\tspeed: 0.0346s/iter; left time: 334.6282s\n",
      "\titers: 400, epoch: 10 | loss: 0.0709546\n",
      "\tspeed: 0.0346s/iter; left time: 330.5468s\n",
      "\titers: 500, epoch: 10 | loss: 0.0617054\n",
      "\tspeed: 0.0345s/iter; left time: 326.9514s\n",
      "\titers: 600, epoch: 10 | loss: 0.0566655\n",
      "\tspeed: 0.0344s/iter; left time: 322.5654s\n",
      "\titers: 700, epoch: 10 | loss: 0.0555644\n",
      "\tspeed: 0.0344s/iter; left time: 318.7316s\n",
      "\titers: 800, epoch: 10 | loss: 0.0605263\n",
      "\tspeed: 0.0342s/iter; left time: 313.3976s\n",
      "\titers: 900, epoch: 10 | loss: 0.0554270\n",
      "\tspeed: 0.0346s/iter; left time: 313.4243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.0618099 Vali Loss: 0.0958811 Test Loss: 0.1058694\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0619151\n",
      "\tspeed: 0.0963s/iter; left time: 863.0085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0597805\n",
      "\tspeed: 0.0344s/iter; left time: 304.8721s\n",
      "\titers: 300, epoch: 11 | loss: 0.0536805\n",
      "\tspeed: 0.0343s/iter; left time: 300.7942s\n",
      "\titers: 400, epoch: 11 | loss: 0.0513019\n",
      "\tspeed: 0.0342s/iter; left time: 296.3691s\n",
      "\titers: 500, epoch: 11 | loss: 0.0637296\n",
      "\tspeed: 0.0340s/iter; left time: 291.1695s\n",
      "\titers: 600, epoch: 11 | loss: 0.0655506\n",
      "\tspeed: 0.0345s/iter; left time: 291.5188s\n",
      "\titers: 700, epoch: 11 | loss: 0.0623056\n",
      "\tspeed: 0.0346s/iter; left time: 289.1530s\n",
      "\titers: 800, epoch: 11 | loss: 0.0541347\n",
      "\tspeed: 0.0345s/iter; left time: 285.3061s\n",
      "\titers: 900, epoch: 11 | loss: 0.0503099\n",
      "\tspeed: 0.0346s/iter; left time: 282.1885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0593142 Vali Loss: 0.0960872 Test Loss: 0.1093873\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0611448\n",
      "\tspeed: 0.0971s/iter; left time: 782.3115s\n",
      "\titers: 200, epoch: 12 | loss: 0.0560043\n",
      "\tspeed: 0.0345s/iter; left time: 274.5392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0558763\n",
      "\tspeed: 0.0346s/iter; left time: 271.4691s\n",
      "\titers: 400, epoch: 12 | loss: 0.0633862\n",
      "\tspeed: 0.0345s/iter; left time: 267.7986s\n",
      "\titers: 500, epoch: 12 | loss: 0.0537031\n",
      "\tspeed: 0.0345s/iter; left time: 263.8130s\n",
      "\titers: 600, epoch: 12 | loss: 0.0556691\n",
      "\tspeed: 0.0345s/iter; left time: 260.6213s\n",
      "\titers: 700, epoch: 12 | loss: 0.0593802\n",
      "\tspeed: 0.0345s/iter; left time: 257.2170s\n",
      "\titers: 800, epoch: 12 | loss: 0.0507883\n",
      "\tspeed: 0.0341s/iter; left time: 251.0438s\n",
      "\titers: 900, epoch: 12 | loss: 0.0559344\n",
      "\tspeed: 0.0341s/iter; left time: 247.7023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.50s\n",
      "Steps: 906 | Train Loss: 0.0574293 Vali Loss: 0.0990894 Test Loss: 0.1103720\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025507517158985138, rmse:0.15971073508262634, mae:0.1042659804224968, rse:0.5640227794647217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2230141\n",
      "\tspeed: 0.0367s/iter; left time: 661.5227s\n",
      "\titers: 200, epoch: 1 | loss: 0.1912384\n",
      "\tspeed: 0.0340s/iter; left time: 608.9154s\n",
      "\titers: 300, epoch: 1 | loss: 0.1890538\n",
      "\tspeed: 0.0340s/iter; left time: 606.1844s\n",
      "\titers: 400, epoch: 1 | loss: 0.1821308\n",
      "\tspeed: 0.0340s/iter; left time: 602.3591s\n",
      "\titers: 500, epoch: 1 | loss: 0.1777495\n",
      "\tspeed: 0.0340s/iter; left time: 598.7651s\n",
      "\titers: 600, epoch: 1 | loss: 0.1753001\n",
      "\tspeed: 0.0340s/iter; left time: 594.9457s\n",
      "\titers: 700, epoch: 1 | loss: 0.1703886\n",
      "\tspeed: 0.0339s/iter; left time: 591.3277s\n",
      "\titers: 800, epoch: 1 | loss: 0.1719142\n",
      "\tspeed: 0.0340s/iter; left time: 589.2019s\n",
      "\titers: 900, epoch: 1 | loss: 0.1525570\n",
      "\tspeed: 0.0343s/iter; left time: 590.9110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.1884397 Vali Loss: 0.1670010 Test Loss: 0.1773647\n",
      "Validation loss decreased (inf --> 0.167001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437568\n",
      "\tspeed: 0.0981s/iter; left time: 1678.7434s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364804\n",
      "\tspeed: 0.0340s/iter; left time: 578.6627s\n",
      "\titers: 300, epoch: 2 | loss: 0.1206845\n",
      "\tspeed: 0.0339s/iter; left time: 574.1556s\n",
      "\titers: 400, epoch: 2 | loss: 0.1204325\n",
      "\tspeed: 0.0339s/iter; left time: 570.6358s\n",
      "\titers: 500, epoch: 2 | loss: 0.1200934\n",
      "\tspeed: 0.0339s/iter; left time: 567.3894s\n",
      "\titers: 600, epoch: 2 | loss: 0.1026905\n",
      "\tspeed: 0.0340s/iter; left time: 565.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.1184056\n",
      "\tspeed: 0.0342s/iter; left time: 564.1581s\n",
      "\titers: 800, epoch: 2 | loss: 0.0938529\n",
      "\tspeed: 0.0340s/iter; left time: 557.4805s\n",
      "\titers: 900, epoch: 2 | loss: 0.1178905\n",
      "\tspeed: 0.0340s/iter; left time: 554.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.1221062 Vali Loss: 0.1266311 Test Loss: 0.1376089\n",
      "Validation loss decreased (0.167001 --> 0.126631).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071769\n",
      "\tspeed: 0.0964s/iter; left time: 1562.9527s\n",
      "\titers: 200, epoch: 3 | loss: 0.1011983\n",
      "\tspeed: 0.0340s/iter; left time: 547.1883s\n",
      "\titers: 300, epoch: 3 | loss: 0.0976297\n",
      "\tspeed: 0.0339s/iter; left time: 543.1893s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108132\n",
      "\tspeed: 0.0340s/iter; left time: 541.4452s\n",
      "\titers: 500, epoch: 3 | loss: 0.1018856\n",
      "\tspeed: 0.0340s/iter; left time: 537.0724s\n",
      "\titers: 600, epoch: 3 | loss: 0.0973330\n",
      "\tspeed: 0.0339s/iter; left time: 533.1113s\n",
      "\titers: 700, epoch: 3 | loss: 0.1023080\n",
      "\tspeed: 0.0340s/iter; left time: 530.2765s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062835\n",
      "\tspeed: 0.0340s/iter; left time: 527.0927s\n",
      "\titers: 900, epoch: 3 | loss: 0.1069887\n",
      "\tspeed: 0.0340s/iter; left time: 523.1523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.1036100 Vali Loss: 0.1243204 Test Loss: 0.1360400\n",
      "Validation loss decreased (0.126631 --> 0.124320).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992623\n",
      "\tspeed: 0.0962s/iter; left time: 1472.6358s\n",
      "\titers: 200, epoch: 4 | loss: 0.1065900\n",
      "\tspeed: 0.0341s/iter; left time: 518.2205s\n",
      "\titers: 300, epoch: 4 | loss: 0.0931358\n",
      "\tspeed: 0.0339s/iter; left time: 512.1561s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058308\n",
      "\tspeed: 0.0339s/iter; left time: 509.0334s\n",
      "\titers: 500, epoch: 4 | loss: 0.0744899\n",
      "\tspeed: 0.0339s/iter; left time: 505.7343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0765016\n",
      "\tspeed: 0.0340s/iter; left time: 502.9699s\n",
      "\titers: 700, epoch: 4 | loss: 0.0799936\n",
      "\tspeed: 0.0340s/iter; left time: 500.2816s\n",
      "\titers: 800, epoch: 4 | loss: 0.0827769\n",
      "\tspeed: 0.0340s/iter; left time: 496.7079s\n",
      "\titers: 900, epoch: 4 | loss: 0.0796529\n",
      "\tspeed: 0.0340s/iter; left time: 493.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0907794 Vali Loss: 0.0990055 Test Loss: 0.1009647\n",
      "Validation loss decreased (0.124320 --> 0.099006).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0691942\n",
      "\tspeed: 0.0981s/iter; left time: 1411.9831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784808\n",
      "\tspeed: 0.0342s/iter; left time: 489.5829s\n",
      "\titers: 300, epoch: 5 | loss: 0.0777235\n",
      "\tspeed: 0.0340s/iter; left time: 482.8251s\n",
      "\titers: 400, epoch: 5 | loss: 0.0742996\n",
      "\tspeed: 0.0340s/iter; left time: 478.9214s\n",
      "\titers: 500, epoch: 5 | loss: 0.0769375\n",
      "\tspeed: 0.0340s/iter; left time: 476.0276s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693606\n",
      "\tspeed: 0.0340s/iter; left time: 472.2992s\n",
      "\titers: 700, epoch: 5 | loss: 0.0777253\n",
      "\tspeed: 0.0341s/iter; left time: 469.8957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749777\n",
      "\tspeed: 0.0345s/iter; left time: 472.8234s\n",
      "\titers: 900, epoch: 5 | loss: 0.0693382\n",
      "\tspeed: 0.0345s/iter; left time: 469.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0772579 Vali Loss: 0.0970609 Test Loss: 0.1022710\n",
      "Validation loss decreased (0.099006 --> 0.097061).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0816712\n",
      "\tspeed: 0.0976s/iter; left time: 1317.1927s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686115\n",
      "\tspeed: 0.0340s/iter; left time: 455.8893s\n",
      "\titers: 300, epoch: 6 | loss: 0.0724844\n",
      "\tspeed: 0.0340s/iter; left time: 451.8054s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776625\n",
      "\tspeed: 0.0340s/iter; left time: 448.8444s\n",
      "\titers: 500, epoch: 6 | loss: 0.0742506\n",
      "\tspeed: 0.0340s/iter; left time: 445.3133s\n",
      "\titers: 600, epoch: 6 | loss: 0.0692068\n",
      "\tspeed: 0.0340s/iter; left time: 441.3233s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700073\n",
      "\tspeed: 0.0341s/iter; left time: 438.9639s\n",
      "\titers: 800, epoch: 6 | loss: 0.0682788\n",
      "\tspeed: 0.0340s/iter; left time: 434.4684s\n",
      "\titers: 900, epoch: 6 | loss: 0.0709434\n",
      "\tspeed: 0.0340s/iter; left time: 431.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0735981 Vali Loss: 0.0985253 Test Loss: 0.1054766\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0695847\n",
      "\tspeed: 0.0942s/iter; left time: 1185.8467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0663946\n",
      "\tspeed: 0.0347s/iter; left time: 432.8294s\n",
      "\titers: 300, epoch: 7 | loss: 0.0748294\n",
      "\tspeed: 0.0347s/iter; left time: 429.4195s\n",
      "\titers: 400, epoch: 7 | loss: 0.0655389\n",
      "\tspeed: 0.0347s/iter; left time: 426.0399s\n",
      "\titers: 500, epoch: 7 | loss: 0.0710848\n",
      "\tspeed: 0.0347s/iter; left time: 422.4656s\n",
      "\titers: 600, epoch: 7 | loss: 0.0750432\n",
      "\tspeed: 0.0347s/iter; left time: 418.9342s\n",
      "\titers: 700, epoch: 7 | loss: 0.0589826\n",
      "\tspeed: 0.0347s/iter; left time: 415.5421s\n",
      "\titers: 800, epoch: 7 | loss: 0.0753183\n",
      "\tspeed: 0.0345s/iter; left time: 410.4611s\n",
      "\titers: 900, epoch: 7 | loss: 0.0640458\n",
      "\tspeed: 0.0345s/iter; left time: 406.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.60s\n",
      "Steps: 906 | Train Loss: 0.0701836 Vali Loss: 0.0988405 Test Loss: 0.1049409\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0640777\n",
      "\tspeed: 0.0967s/iter; left time: 1129.8765s\n",
      "\titers: 200, epoch: 8 | loss: 0.0628060\n",
      "\tspeed: 0.0340s/iter; left time: 393.7841s\n",
      "\titers: 300, epoch: 8 | loss: 0.0658005\n",
      "\tspeed: 0.0340s/iter; left time: 390.8261s\n",
      "\titers: 400, epoch: 8 | loss: 0.0692687\n",
      "\tspeed: 0.0340s/iter; left time: 386.9866s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804830\n",
      "\tspeed: 0.0340s/iter; left time: 383.3645s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704948\n",
      "\tspeed: 0.0340s/iter; left time: 380.1543s\n",
      "\titers: 700, epoch: 8 | loss: 0.0721590\n",
      "\tspeed: 0.0340s/iter; left time: 376.3733s\n",
      "\titers: 800, epoch: 8 | loss: 0.0717574\n",
      "\tspeed: 0.0340s/iter; left time: 373.2058s\n",
      "\titers: 900, epoch: 8 | loss: 0.0600496\n",
      "\tspeed: 0.0340s/iter; left time: 369.6240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0675137 Vali Loss: 0.0970914 Test Loss: 0.1058643\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0610077\n",
      "\tspeed: 0.0939s/iter; left time: 1012.0603s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536139\n",
      "\tspeed: 0.0340s/iter; left time: 363.0301s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636304\n",
      "\tspeed: 0.0340s/iter; left time: 359.2915s\n",
      "\titers: 400, epoch: 9 | loss: 0.0654796\n",
      "\tspeed: 0.0339s/iter; left time: 355.4828s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599042\n",
      "\tspeed: 0.0340s/iter; left time: 352.4805s\n",
      "\titers: 600, epoch: 9 | loss: 0.0565385\n",
      "\tspeed: 0.0340s/iter; left time: 348.7747s\n",
      "\titers: 700, epoch: 9 | loss: 0.0668385\n",
      "\tspeed: 0.0340s/iter; left time: 345.7664s\n",
      "\titers: 800, epoch: 9 | loss: 0.0648912\n",
      "\tspeed: 0.0340s/iter; left time: 342.2205s\n",
      "\titers: 900, epoch: 9 | loss: 0.0582753\n",
      "\tspeed: 0.0340s/iter; left time: 339.0551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0648913 Vali Loss: 0.0960822 Test Loss: 0.1028538\n",
      "Validation loss decreased (0.097061 --> 0.096082).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0571060\n",
      "\tspeed: 0.0974s/iter; left time: 961.0195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0593772\n",
      "\tspeed: 0.0340s/iter; left time: 332.1973s\n",
      "\titers: 300, epoch: 10 | loss: 0.0612443\n",
      "\tspeed: 0.0340s/iter; left time: 328.9119s\n",
      "\titers: 400, epoch: 10 | loss: 0.0655431\n",
      "\tspeed: 0.0340s/iter; left time: 325.6748s\n",
      "\titers: 500, epoch: 10 | loss: 0.0650016\n",
      "\tspeed: 0.0340s/iter; left time: 322.1937s\n",
      "\titers: 600, epoch: 10 | loss: 0.0638729\n",
      "\tspeed: 0.0341s/iter; left time: 319.2505s\n",
      "\titers: 700, epoch: 10 | loss: 0.0595213\n",
      "\tspeed: 0.0340s/iter; left time: 315.3304s\n",
      "\titers: 800, epoch: 10 | loss: 0.0569092\n",
      "\tspeed: 0.0340s/iter; left time: 311.9479s\n",
      "\titers: 900, epoch: 10 | loss: 0.0640525\n",
      "\tspeed: 0.0340s/iter; left time: 308.5881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0622086 Vali Loss: 0.0958591 Test Loss: 0.1072349\n",
      "Validation loss decreased (0.096082 --> 0.095859).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0614833\n",
      "\tspeed: 0.0974s/iter; left time: 872.4934s\n",
      "\titers: 200, epoch: 11 | loss: 0.0575255\n",
      "\tspeed: 0.0339s/iter; left time: 300.4564s\n",
      "\titers: 300, epoch: 11 | loss: 0.0580176\n",
      "\tspeed: 0.0339s/iter; left time: 297.3484s\n",
      "\titers: 400, epoch: 11 | loss: 0.0558818\n",
      "\tspeed: 0.0339s/iter; left time: 293.5805s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552967\n",
      "\tspeed: 0.0339s/iter; left time: 290.2811s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624112\n",
      "\tspeed: 0.0340s/iter; left time: 287.2546s\n",
      "\titers: 700, epoch: 11 | loss: 0.0603113\n",
      "\tspeed: 0.0339s/iter; left time: 283.7670s\n",
      "\titers: 800, epoch: 11 | loss: 0.0681967\n",
      "\tspeed: 0.0339s/iter; left time: 280.0891s\n",
      "\titers: 900, epoch: 11 | loss: 0.0524940\n",
      "\tspeed: 0.0339s/iter; left time: 276.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0599555 Vali Loss: 0.0940875 Test Loss: 0.1040663\n",
      "Validation loss decreased (0.095859 --> 0.094087).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0657773\n",
      "\tspeed: 0.0984s/iter; left time: 792.4305s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594814\n",
      "\tspeed: 0.0340s/iter; left time: 270.1358s\n",
      "\titers: 300, epoch: 12 | loss: 0.0568700\n",
      "\tspeed: 0.0340s/iter; left time: 267.2081s\n",
      "\titers: 400, epoch: 12 | loss: 0.0558004\n",
      "\tspeed: 0.0341s/iter; left time: 264.1364s\n",
      "\titers: 500, epoch: 12 | loss: 0.0566751\n",
      "\tspeed: 0.0340s/iter; left time: 260.4906s\n",
      "\titers: 600, epoch: 12 | loss: 0.0581444\n",
      "\tspeed: 0.0340s/iter; left time: 257.1118s\n",
      "\titers: 700, epoch: 12 | loss: 0.0557531\n",
      "\tspeed: 0.0340s/iter; left time: 253.6974s\n",
      "\titers: 800, epoch: 12 | loss: 0.0620691\n",
      "\tspeed: 0.0340s/iter; left time: 250.2706s\n",
      "\titers: 900, epoch: 12 | loss: 0.0582283\n",
      "\tspeed: 0.0340s/iter; left time: 246.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0577892 Vali Loss: 0.0964437 Test Loss: 0.1105988\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0533582\n",
      "\tspeed: 0.0941s/iter; left time: 672.9972s\n",
      "\titers: 200, epoch: 13 | loss: 0.0481930\n",
      "\tspeed: 0.0347s/iter; left time: 244.4470s\n",
      "\titers: 300, epoch: 13 | loss: 0.0606546\n",
      "\tspeed: 0.0347s/iter; left time: 241.1487s\n",
      "\titers: 400, epoch: 13 | loss: 0.0518627\n",
      "\tspeed: 0.0347s/iter; left time: 237.4272s\n",
      "\titers: 500, epoch: 13 | loss: 0.0569521\n",
      "\tspeed: 0.0347s/iter; left time: 233.9909s\n",
      "\titers: 600, epoch: 13 | loss: 0.0532617\n",
      "\tspeed: 0.0347s/iter; left time: 230.4939s\n",
      "\titers: 700, epoch: 13 | loss: 0.0609730\n",
      "\tspeed: 0.0347s/iter; left time: 227.0485s\n",
      "\titers: 800, epoch: 13 | loss: 0.0557893\n",
      "\tspeed: 0.0347s/iter; left time: 223.6601s\n",
      "\titers: 900, epoch: 13 | loss: 0.0557036\n",
      "\tspeed: 0.0347s/iter; left time: 220.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.66s\n",
      "Steps: 906 | Train Loss: 0.0560332 Vali Loss: 0.0970379 Test Loss: 0.1079533\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0597315\n",
      "\tspeed: 0.0939s/iter; left time: 586.2774s\n",
      "\titers: 200, epoch: 14 | loss: 0.0535129\n",
      "\tspeed: 0.0345s/iter; left time: 212.0048s\n",
      "\titers: 300, epoch: 14 | loss: 0.0514123\n",
      "\tspeed: 0.0344s/iter; left time: 208.1608s\n",
      "\titers: 400, epoch: 14 | loss: 0.0533041\n",
      "\tspeed: 0.0339s/iter; left time: 201.7241s\n",
      "\titers: 500, epoch: 14 | loss: 0.0519378\n",
      "\tspeed: 0.0339s/iter; left time: 198.1319s\n",
      "\titers: 600, epoch: 14 | loss: 0.0486918\n",
      "\tspeed: 0.0339s/iter; left time: 194.8968s\n",
      "\titers: 700, epoch: 14 | loss: 0.0514592\n",
      "\tspeed: 0.0339s/iter; left time: 191.3317s\n",
      "\titers: 800, epoch: 14 | loss: 0.0511779\n",
      "\tspeed: 0.0340s/iter; left time: 188.2007s\n",
      "\titers: 900, epoch: 14 | loss: 0.0592240\n",
      "\tspeed: 0.0340s/iter; left time: 184.8092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0542619 Vali Loss: 0.1007048 Test Loss: 0.1137719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533272\n",
      "\tspeed: 0.0937s/iter; left time: 500.2540s\n",
      "\titers: 200, epoch: 15 | loss: 0.0540463\n",
      "\tspeed: 0.0340s/iter; left time: 178.0053s\n",
      "\titers: 300, epoch: 15 | loss: 0.0475888\n",
      "\tspeed: 0.0340s/iter; left time: 174.6277s\n",
      "\titers: 400, epoch: 15 | loss: 0.0573437\n",
      "\tspeed: 0.0340s/iter; left time: 171.1498s\n",
      "\titers: 500, epoch: 15 | loss: 0.0579779\n",
      "\tspeed: 0.0340s/iter; left time: 167.7634s\n",
      "\titers: 600, epoch: 15 | loss: 0.0538819\n",
      "\tspeed: 0.0340s/iter; left time: 164.3892s\n",
      "\titers: 700, epoch: 15 | loss: 0.0519059\n",
      "\tspeed: 0.0340s/iter; left time: 161.0040s\n",
      "\titers: 800, epoch: 15 | loss: 0.0557711\n",
      "\tspeed: 0.0341s/iter; left time: 157.8956s\n",
      "\titers: 900, epoch: 15 | loss: 0.0465270\n",
      "\tspeed: 0.0340s/iter; left time: 154.1965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0528399 Vali Loss: 0.0974168 Test Loss: 0.1095551\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476120\n",
      "\tspeed: 0.0947s/iter; left time: 419.5489s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560914\n",
      "\tspeed: 0.0340s/iter; left time: 147.1741s\n",
      "\titers: 300, epoch: 16 | loss: 0.0469050\n",
      "\tspeed: 0.0340s/iter; left time: 143.6711s\n",
      "\titers: 400, epoch: 16 | loss: 0.0462344\n",
      "\tspeed: 0.0340s/iter; left time: 140.2631s\n",
      "\titers: 500, epoch: 16 | loss: 0.0579376\n",
      "\tspeed: 0.0340s/iter; left time: 136.8792s\n",
      "\titers: 600, epoch: 16 | loss: 0.0472905\n",
      "\tspeed: 0.0340s/iter; left time: 133.6086s\n",
      "\titers: 700, epoch: 16 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 129.8898s\n",
      "\titers: 800, epoch: 16 | loss: 0.0483521\n",
      "\tspeed: 0.0340s/iter; left time: 126.7298s\n",
      "\titers: 900, epoch: 16 | loss: 0.0505118\n",
      "\tspeed: 0.0340s/iter; left time: 123.2878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0516243 Vali Loss: 0.0969801 Test Loss: 0.1082252\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027125487104058266, rmse:0.16469816863536835, mae:0.10410299152135849, rse:0.5816360116004944\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:33.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2236743\n",
      "\tspeed: 0.0659s/iter; left time: 1184.4053s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113647\n",
      "\tspeed: 0.0418s/iter; left time: 747.1035s\n",
      "\titers: 300, epoch: 1 | loss: 0.2026322\n",
      "\tspeed: 0.0415s/iter; left time: 737.3678s\n",
      "\titers: 400, epoch: 1 | loss: 0.1935861\n",
      "\tspeed: 0.0415s/iter; left time: 733.9055s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860587\n",
      "\tspeed: 0.0420s/iter; left time: 738.5568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1778900\n",
      "\tspeed: 0.0416s/iter; left time: 727.0239s\n",
      "\titers: 700, epoch: 1 | loss: 0.1723806\n",
      "\tspeed: 0.0418s/iter; left time: 725.8630s\n",
      "\titers: 800, epoch: 1 | loss: 0.1740834\n",
      "\tspeed: 0.0421s/iter; left time: 727.4376s\n",
      "\titers: 900, epoch: 1 | loss: 0.1730634\n",
      "\tspeed: 0.0421s/iter; left time: 723.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 904 | Train Loss: 0.1950106 Vali Loss: 0.1828621 Test Loss: 0.2036057\n",
      "Validation loss decreased (inf --> 0.182862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1645211\n",
      "\tspeed: 0.1168s/iter; left time: 1994.4889s\n",
      "\titers: 200, epoch: 2 | loss: 0.1429543\n",
      "\tspeed: 0.0416s/iter; left time: 705.5633s\n",
      "\titers: 300, epoch: 2 | loss: 0.1374299\n",
      "\tspeed: 0.0416s/iter; left time: 701.5841s\n",
      "\titers: 400, epoch: 2 | loss: 0.1448636\n",
      "\tspeed: 0.0416s/iter; left time: 697.7827s\n",
      "\titers: 500, epoch: 2 | loss: 0.1413144\n",
      "\tspeed: 0.0416s/iter; left time: 693.9163s\n",
      "\titers: 600, epoch: 2 | loss: 0.1236145\n",
      "\tspeed: 0.0416s/iter; left time: 689.8717s\n",
      "\titers: 700, epoch: 2 | loss: 0.1246188\n",
      "\tspeed: 0.0416s/iter; left time: 685.3335s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242174\n",
      "\tspeed: 0.0416s/iter; left time: 681.5506s\n",
      "\titers: 900, epoch: 2 | loss: 0.1292692\n",
      "\tspeed: 0.0416s/iter; left time: 677.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1378524 Vali Loss: 0.1397373 Test Loss: 0.1576225\n",
      "Validation loss decreased (0.182862 --> 0.139737).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1165264\n",
      "\tspeed: 0.1172s/iter; left time: 1894.8829s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007225\n",
      "\tspeed: 0.0417s/iter; left time: 670.0918s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167652\n",
      "\tspeed: 0.0416s/iter; left time: 665.2381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1072120\n",
      "\tspeed: 0.0416s/iter; left time: 659.8419s\n",
      "\titers: 500, epoch: 3 | loss: 0.1060360\n",
      "\tspeed: 0.0416s/iter; left time: 656.2613s\n",
      "\titers: 600, epoch: 3 | loss: 0.1059219\n",
      "\tspeed: 0.0416s/iter; left time: 651.9737s\n",
      "\titers: 700, epoch: 3 | loss: 0.1176727\n",
      "\tspeed: 0.0416s/iter; left time: 647.9141s\n",
      "\titers: 800, epoch: 3 | loss: 0.0983266\n",
      "\tspeed: 0.0416s/iter; left time: 643.8895s\n",
      "\titers: 900, epoch: 3 | loss: 0.1117628\n",
      "\tspeed: 0.0417s/iter; left time: 640.6619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.1093381 Vali Loss: 0.1260393 Test Loss: 0.1418328\n",
      "Validation loss decreased (0.139737 --> 0.126039).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1144765\n",
      "\tspeed: 0.1182s/iter; left time: 1805.4575s\n",
      "\titers: 200, epoch: 4 | loss: 0.1020382\n",
      "\tspeed: 0.0416s/iter; left time: 631.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.1153255\n",
      "\tspeed: 0.0416s/iter; left time: 627.1646s\n",
      "\titers: 400, epoch: 4 | loss: 0.1025088\n",
      "\tspeed: 0.0416s/iter; left time: 622.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.1027884\n",
      "\tspeed: 0.0416s/iter; left time: 618.4806s\n",
      "\titers: 600, epoch: 4 | loss: 0.1016667\n",
      "\tspeed: 0.0416s/iter; left time: 614.3470s\n",
      "\titers: 700, epoch: 4 | loss: 0.1033425\n",
      "\tspeed: 0.0416s/iter; left time: 610.2125s\n",
      "\titers: 800, epoch: 4 | loss: 0.0933737\n",
      "\tspeed: 0.0416s/iter; left time: 606.3138s\n",
      "\titers: 900, epoch: 4 | loss: 0.0934185\n",
      "\tspeed: 0.0416s/iter; left time: 601.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1001598 Vali Loss: 0.1275451 Test Loss: 0.1407701\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0895917\n",
      "\tspeed: 0.1148s/iter; left time: 1649.6186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0927757\n",
      "\tspeed: 0.0416s/iter; left time: 593.4980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965540\n",
      "\tspeed: 0.0416s/iter; left time: 588.6807s\n",
      "\titers: 400, epoch: 5 | loss: 0.0999158\n",
      "\tspeed: 0.0416s/iter; left time: 585.5770s\n",
      "\titers: 500, epoch: 5 | loss: 0.0884686\n",
      "\tspeed: 0.0416s/iter; left time: 581.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.0966759\n",
      "\tspeed: 0.0417s/iter; left time: 578.2581s\n",
      "\titers: 700, epoch: 5 | loss: 0.0977219\n",
      "\tspeed: 0.0416s/iter; left time: 573.0901s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846407\n",
      "\tspeed: 0.0416s/iter; left time: 568.7870s\n",
      "\titers: 900, epoch: 5 | loss: 0.0849928\n",
      "\tspeed: 0.0416s/iter; left time: 564.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 904 | Train Loss: 0.0935273 Vali Loss: 0.1276608 Test Loss: 0.1445250\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835068\n",
      "\tspeed: 0.1146s/iter; left time: 1542.3072s\n",
      "\titers: 200, epoch: 6 | loss: 0.0837331\n",
      "\tspeed: 0.0416s/iter; left time: 555.9648s\n",
      "\titers: 300, epoch: 6 | loss: 0.0913434\n",
      "\tspeed: 0.0416s/iter; left time: 551.4175s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903796\n",
      "\tspeed: 0.0416s/iter; left time: 547.4075s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856775\n",
      "\tspeed: 0.0416s/iter; left time: 543.5327s\n",
      "\titers: 600, epoch: 6 | loss: 0.0846278\n",
      "\tspeed: 0.0416s/iter; left time: 539.4484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0778856\n",
      "\tspeed: 0.0416s/iter; left time: 535.0167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0858639\n",
      "\tspeed: 0.0416s/iter; left time: 530.9052s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903355\n",
      "\tspeed: 0.0416s/iter; left time: 527.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0873677 Vali Loss: 0.1281512 Test Loss: 0.1463322\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829671\n",
      "\tspeed: 0.1144s/iter; left time: 1436.1222s\n",
      "\titers: 200, epoch: 7 | loss: 0.0799333\n",
      "\tspeed: 0.0416s/iter; left time: 518.3830s\n",
      "\titers: 300, epoch: 7 | loss: 0.0816214\n",
      "\tspeed: 0.0416s/iter; left time: 514.4665s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803851\n",
      "\tspeed: 0.0416s/iter; left time: 510.3534s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766140\n",
      "\tspeed: 0.0417s/iter; left time: 506.3998s\n",
      "\titers: 600, epoch: 7 | loss: 0.0814182\n",
      "\tspeed: 0.0416s/iter; left time: 502.0855s\n",
      "\titers: 700, epoch: 7 | loss: 0.0843650\n",
      "\tspeed: 0.0417s/iter; left time: 498.0307s\n",
      "\titers: 800, epoch: 7 | loss: 0.0786219\n",
      "\tspeed: 0.0416s/iter; left time: 493.6940s\n",
      "\titers: 900, epoch: 7 | loss: 0.0786166\n",
      "\tspeed: 0.0416s/iter; left time: 489.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0820126 Vali Loss: 0.1301628 Test Loss: 0.1494684\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744809\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1676s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740958\n",
      "\tspeed: 0.0416s/iter; left time: 480.6162s\n",
      "\titers: 300, epoch: 8 | loss: 0.0821366\n",
      "\tspeed: 0.0416s/iter; left time: 476.9035s\n",
      "\titers: 400, epoch: 8 | loss: 0.0776912\n",
      "\tspeed: 0.0416s/iter; left time: 472.4502s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823452\n",
      "\tspeed: 0.0417s/iter; left time: 468.7491s\n",
      "\titers: 600, epoch: 8 | loss: 0.0832772\n",
      "\tspeed: 0.0416s/iter; left time: 464.2049s\n",
      "\titers: 700, epoch: 8 | loss: 0.0772706\n",
      "\tspeed: 0.0416s/iter; left time: 460.0779s\n",
      "\titers: 800, epoch: 8 | loss: 0.0733887\n",
      "\tspeed: 0.0416s/iter; left time: 455.9084s\n",
      "\titers: 900, epoch: 8 | loss: 0.0711432\n",
      "\tspeed: 0.0417s/iter; left time: 452.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0772220 Vali Loss: 0.1286450 Test Loss: 0.1474413\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111143946647644, rmse:0.20275956392288208, mae:0.14186589419841766, rse:0.7180125713348389\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2234415\n",
      "\tspeed: 0.0448s/iter; left time: 804.8949s\n",
      "\titers: 200, epoch: 1 | loss: 0.1966856\n",
      "\tspeed: 0.0422s/iter; left time: 754.5125s\n",
      "\titers: 300, epoch: 1 | loss: 0.1985690\n",
      "\tspeed: 0.0422s/iter; left time: 750.9129s\n",
      "\titers: 400, epoch: 1 | loss: 0.1968302\n",
      "\tspeed: 0.0422s/iter; left time: 746.5394s\n",
      "\titers: 500, epoch: 1 | loss: 0.2051390\n",
      "\tspeed: 0.0422s/iter; left time: 742.6659s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833022\n",
      "\tspeed: 0.0422s/iter; left time: 737.9051s\n",
      "\titers: 700, epoch: 1 | loss: 0.1789588\n",
      "\tspeed: 0.0422s/iter; left time: 733.3599s\n",
      "\titers: 800, epoch: 1 | loss: 0.1781165\n",
      "\tspeed: 0.0422s/iter; left time: 730.0477s\n",
      "\titers: 900, epoch: 1 | loss: 0.1753210\n",
      "\tspeed: 0.0422s/iter; left time: 725.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 904 | Train Loss: 0.1983297 Vali Loss: 0.1792039 Test Loss: 0.1982639\n",
      "Validation loss decreased (inf --> 0.179204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652503\n",
      "\tspeed: 0.1185s/iter; left time: 2023.6443s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410911\n",
      "\tspeed: 0.0422s/iter; left time: 716.3351s\n",
      "\titers: 300, epoch: 2 | loss: 0.1531194\n",
      "\tspeed: 0.0422s/iter; left time: 712.5301s\n",
      "\titers: 400, epoch: 2 | loss: 0.1385903\n",
      "\tspeed: 0.0422s/iter; left time: 707.9972s\n",
      "\titers: 500, epoch: 2 | loss: 0.1392631\n",
      "\tspeed: 0.0422s/iter; left time: 703.6733s\n",
      "\titers: 600, epoch: 2 | loss: 0.1265477\n",
      "\tspeed: 0.0419s/iter; left time: 694.9356s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320228\n",
      "\tspeed: 0.0417s/iter; left time: 686.5249s\n",
      "\titers: 800, epoch: 2 | loss: 0.1308168\n",
      "\tspeed: 0.0417s/iter; left time: 682.6446s\n",
      "\titers: 900, epoch: 2 | loss: 0.1204412\n",
      "\tspeed: 0.0417s/iter; left time: 678.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 904 | Train Loss: 0.1407695 Vali Loss: 0.1408073 Test Loss: 0.1547505\n",
      "Validation loss decreased (0.179204 --> 0.140807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1168671\n",
      "\tspeed: 0.1192s/iter; left time: 1927.4650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049146\n",
      "\tspeed: 0.0417s/iter; left time: 670.7429s\n",
      "\titers: 300, epoch: 3 | loss: 0.1167228\n",
      "\tspeed: 0.0417s/iter; left time: 666.5092s\n",
      "\titers: 400, epoch: 3 | loss: 0.1142903\n",
      "\tspeed: 0.0417s/iter; left time: 662.3797s\n",
      "\titers: 500, epoch: 3 | loss: 0.1116785\n",
      "\tspeed: 0.0417s/iter; left time: 657.1454s\n",
      "\titers: 600, epoch: 3 | loss: 0.1235701\n",
      "\tspeed: 0.0417s/iter; left time: 653.4055s\n",
      "\titers: 700, epoch: 3 | loss: 0.1162522\n",
      "\tspeed: 0.0417s/iter; left time: 649.3268s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972967\n",
      "\tspeed: 0.0417s/iter; left time: 644.6283s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052426\n",
      "\tspeed: 0.0417s/iter; left time: 641.1443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.1110472 Vali Loss: 0.1264536 Test Loss: 0.1413004\n",
      "Validation loss decreased (0.140807 --> 0.126454).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1090948\n",
      "\tspeed: 0.1191s/iter; left time: 1818.1072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0982538\n",
      "\tspeed: 0.0416s/iter; left time: 631.4894s\n",
      "\titers: 300, epoch: 4 | loss: 0.1019681\n",
      "\tspeed: 0.0416s/iter; left time: 627.4270s\n",
      "\titers: 400, epoch: 4 | loss: 0.1011304\n",
      "\tspeed: 0.0417s/iter; left time: 623.9304s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932572\n",
      "\tspeed: 0.0417s/iter; left time: 619.6904s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023407\n",
      "\tspeed: 0.0417s/iter; left time: 615.6053s\n",
      "\titers: 700, epoch: 4 | loss: 0.1069069\n",
      "\tspeed: 0.0417s/iter; left time: 611.4718s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006559\n",
      "\tspeed: 0.0417s/iter; left time: 607.7450s\n",
      "\titers: 900, epoch: 4 | loss: 0.0924000\n",
      "\tspeed: 0.0417s/iter; left time: 603.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.1005647 Vali Loss: 0.1294573 Test Loss: 0.1431555\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0859475\n",
      "\tspeed: 0.1151s/iter; left time: 1653.0452s\n",
      "\titers: 200, epoch: 5 | loss: 0.0939509\n",
      "\tspeed: 0.0417s/iter; left time: 594.5175s\n",
      "\titers: 300, epoch: 5 | loss: 0.1010361\n",
      "\tspeed: 0.0417s/iter; left time: 590.4591s\n",
      "\titers: 400, epoch: 5 | loss: 0.0910976\n",
      "\tspeed: 0.0417s/iter; left time: 586.6165s\n",
      "\titers: 500, epoch: 5 | loss: 0.0985042\n",
      "\tspeed: 0.0417s/iter; left time: 582.4643s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925515\n",
      "\tspeed: 0.0417s/iter; left time: 578.1049s\n",
      "\titers: 700, epoch: 5 | loss: 0.0912867\n",
      "\tspeed: 0.0417s/iter; left time: 574.5983s\n",
      "\titers: 800, epoch: 5 | loss: 0.0828394\n",
      "\tspeed: 0.0417s/iter; left time: 570.0924s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920023\n",
      "\tspeed: 0.0417s/iter; left time: 565.9148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 904 | Train Loss: 0.0930013 Vali Loss: 0.1250305 Test Loss: 0.1447869\n",
      "Validation loss decreased (0.126454 --> 0.125030).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0978971\n",
      "\tspeed: 0.1175s/iter; left time: 1581.6357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0836452\n",
      "\tspeed: 0.0423s/iter; left time: 564.7488s\n",
      "\titers: 300, epoch: 6 | loss: 0.0813788\n",
      "\tspeed: 0.0423s/iter; left time: 560.4317s\n",
      "\titers: 400, epoch: 6 | loss: 0.0883501\n",
      "\tspeed: 0.0423s/iter; left time: 556.4378s\n",
      "\titers: 500, epoch: 6 | loss: 0.0908173\n",
      "\tspeed: 0.0419s/iter; left time: 547.4124s\n",
      "\titers: 600, epoch: 6 | loss: 0.0855428\n",
      "\tspeed: 0.0417s/iter; left time: 540.3965s\n",
      "\titers: 700, epoch: 6 | loss: 0.0813997\n",
      "\tspeed: 0.0418s/iter; left time: 538.0849s\n",
      "\titers: 800, epoch: 6 | loss: 0.0851901\n",
      "\tspeed: 0.0422s/iter; left time: 538.7857s\n",
      "\titers: 900, epoch: 6 | loss: 0.0928024\n",
      "\tspeed: 0.0422s/iter; left time: 534.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0864959 Vali Loss: 0.1274113 Test Loss: 0.1429392\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860452\n",
      "\tspeed: 0.1152s/iter; left time: 1445.9693s\n",
      "\titers: 200, epoch: 7 | loss: 0.0802008\n",
      "\tspeed: 0.0417s/iter; left time: 520.0418s\n",
      "\titers: 300, epoch: 7 | loss: 0.0844645\n",
      "\tspeed: 0.0417s/iter; left time: 515.7681s\n",
      "\titers: 400, epoch: 7 | loss: 0.0800768\n",
      "\tspeed: 0.0417s/iter; left time: 511.2027s\n",
      "\titers: 500, epoch: 7 | loss: 0.0742883\n",
      "\tspeed: 0.0417s/iter; left time: 507.2303s\n",
      "\titers: 600, epoch: 7 | loss: 0.0797856\n",
      "\tspeed: 0.0417s/iter; left time: 502.8343s\n",
      "\titers: 700, epoch: 7 | loss: 0.0820259\n",
      "\tspeed: 0.0417s/iter; left time: 498.4365s\n",
      "\titers: 800, epoch: 7 | loss: 0.0776940\n",
      "\tspeed: 0.0417s/iter; left time: 494.1525s\n",
      "\titers: 900, epoch: 7 | loss: 0.0846543\n",
      "\tspeed: 0.0417s/iter; left time: 490.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0810965 Vali Loss: 0.1287853 Test Loss: 0.1496999\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749170\n",
      "\tspeed: 0.1138s/iter; left time: 1326.4466s\n",
      "\titers: 200, epoch: 8 | loss: 0.0768698\n",
      "\tspeed: 0.0416s/iter; left time: 481.0175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0775572\n",
      "\tspeed: 0.0416s/iter; left time: 476.9494s\n",
      "\titers: 400, epoch: 8 | loss: 0.0874197\n",
      "\tspeed: 0.0417s/iter; left time: 473.0103s\n",
      "\titers: 500, epoch: 8 | loss: 0.0777074\n",
      "\tspeed: 0.0417s/iter; left time: 468.9067s\n",
      "\titers: 600, epoch: 8 | loss: 0.0779779\n",
      "\tspeed: 0.0417s/iter; left time: 464.8537s\n",
      "\titers: 700, epoch: 8 | loss: 0.0688209\n",
      "\tspeed: 0.0416s/iter; left time: 460.1467s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773090\n",
      "\tspeed: 0.0416s/iter; left time: 455.8680s\n",
      "\titers: 900, epoch: 8 | loss: 0.0762522\n",
      "\tspeed: 0.0416s/iter; left time: 452.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.0761603 Vali Loss: 0.1303706 Test Loss: 0.1481057\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0745463\n",
      "\tspeed: 0.1140s/iter; left time: 1225.3924s\n",
      "\titers: 200, epoch: 9 | loss: 0.0718982\n",
      "\tspeed: 0.0417s/iter; left time: 444.2716s\n",
      "\titers: 300, epoch: 9 | loss: 0.0661809\n",
      "\tspeed: 0.0417s/iter; left time: 439.7693s\n",
      "\titers: 400, epoch: 9 | loss: 0.0663692\n",
      "\tspeed: 0.0417s/iter; left time: 435.6156s\n",
      "\titers: 500, epoch: 9 | loss: 0.0759411\n",
      "\tspeed: 0.0417s/iter; left time: 431.6843s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733939\n",
      "\tspeed: 0.0417s/iter; left time: 427.4183s\n",
      "\titers: 700, epoch: 9 | loss: 0.0685498\n",
      "\tspeed: 0.0417s/iter; left time: 423.4725s\n",
      "\titers: 800, epoch: 9 | loss: 0.0660150\n",
      "\tspeed: 0.0417s/iter; left time: 418.9598s\n",
      "\titers: 900, epoch: 9 | loss: 0.0665430\n",
      "\tspeed: 0.0417s/iter; left time: 414.8382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 904 | Train Loss: 0.0720239 Vali Loss: 0.1313181 Test Loss: 0.1486595\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0688543\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9525s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704562\n",
      "\tspeed: 0.0416s/iter; left time: 405.8092s\n",
      "\titers: 300, epoch: 10 | loss: 0.0691381\n",
      "\tspeed: 0.0416s/iter; left time: 401.6987s\n",
      "\titers: 400, epoch: 10 | loss: 0.0685972\n",
      "\tspeed: 0.0417s/iter; left time: 397.8337s\n",
      "\titers: 500, epoch: 10 | loss: 0.0678505\n",
      "\tspeed: 0.0417s/iter; left time: 393.6512s\n",
      "\titers: 600, epoch: 10 | loss: 0.0690019\n",
      "\tspeed: 0.0417s/iter; left time: 389.3610s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663853\n",
      "\tspeed: 0.0417s/iter; left time: 385.2586s\n",
      "\titers: 800, epoch: 10 | loss: 0.0663898\n",
      "\tspeed: 0.0417s/iter; left time: 381.0024s\n",
      "\titers: 900, epoch: 10 | loss: 0.0707798\n",
      "\tspeed: 0.0417s/iter; left time: 376.8207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.0684217 Vali Loss: 0.1309250 Test Loss: 0.1480408\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04497264325618744, rmse:0.21206754446029663, mae:0.14488229155540466, rse:0.7509739995002747\n",
      "Intermediate time for DE and pred_len 96: 00h:13m:48.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2135790\n",
      "\tspeed: 0.0737s/iter; left time: 1322.8469s\n",
      "\titers: 200, epoch: 1 | loss: 0.2131124\n",
      "\tspeed: 0.0512s/iter; left time: 912.6013s\n",
      "\titers: 300, epoch: 1 | loss: 0.1944744\n",
      "\tspeed: 0.0511s/iter; left time: 906.5395s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934913\n",
      "\tspeed: 0.0511s/iter; left time: 901.8570s\n",
      "\titers: 500, epoch: 1 | loss: 0.1860318\n",
      "\tspeed: 0.0512s/iter; left time: 898.2652s\n",
      "\titers: 600, epoch: 1 | loss: 0.1891531\n",
      "\tspeed: 0.0507s/iter; left time: 884.7699s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774250\n",
      "\tspeed: 0.0505s/iter; left time: 875.0270s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730052\n",
      "\tspeed: 0.0510s/iter; left time: 878.7949s\n",
      "\titers: 900, epoch: 1 | loss: 0.1795384\n",
      "\tspeed: 0.0510s/iter; left time: 874.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.62s\n",
      "Steps: 902 | Train Loss: 0.1965859 Vali Loss: 0.1832028 Test Loss: 0.2074134\n",
      "Validation loss decreased (inf --> 0.183203).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1704737\n",
      "\tspeed: 0.1414s/iter; left time: 2408.5213s\n",
      "\titers: 200, epoch: 2 | loss: 0.1490840\n",
      "\tspeed: 0.0512s/iter; left time: 866.9052s\n",
      "\titers: 300, epoch: 2 | loss: 0.1521463\n",
      "\tspeed: 0.0511s/iter; left time: 861.3000s\n",
      "\titers: 400, epoch: 2 | loss: 0.1506241\n",
      "\tspeed: 0.0512s/iter; left time: 856.7931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1406512\n",
      "\tspeed: 0.0512s/iter; left time: 851.7499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1345950\n",
      "\tspeed: 0.0512s/iter; left time: 846.4364s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337818\n",
      "\tspeed: 0.0512s/iter; left time: 841.2830s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407173\n",
      "\tspeed: 0.0512s/iter; left time: 835.9682s\n",
      "\titers: 900, epoch: 2 | loss: 0.1290744\n",
      "\tspeed: 0.0512s/iter; left time: 831.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1488273 Vali Loss: 0.1596573 Test Loss: 0.1774935\n",
      "Validation loss decreased (0.183203 --> 0.159657).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323122\n",
      "\tspeed: 0.1454s/iter; left time: 2346.2832s\n",
      "\titers: 200, epoch: 3 | loss: 0.1293032\n",
      "\tspeed: 0.0512s/iter; left time: 820.8534s\n",
      "\titers: 300, epoch: 3 | loss: 0.1290850\n",
      "\tspeed: 0.0512s/iter; left time: 815.8447s\n",
      "\titers: 400, epoch: 3 | loss: 0.1349285\n",
      "\tspeed: 0.0512s/iter; left time: 811.2225s\n",
      "\titers: 500, epoch: 3 | loss: 0.1263371\n",
      "\tspeed: 0.0511s/iter; left time: 803.5386s\n",
      "\titers: 600, epoch: 3 | loss: 0.1262871\n",
      "\tspeed: 0.0510s/iter; left time: 797.6849s\n",
      "\titers: 700, epoch: 3 | loss: 0.1187956\n",
      "\tspeed: 0.0507s/iter; left time: 787.9002s\n",
      "\titers: 800, epoch: 3 | loss: 0.1199932\n",
      "\tspeed: 0.0508s/iter; left time: 784.8815s\n",
      "\titers: 900, epoch: 3 | loss: 0.1152969\n",
      "\tspeed: 0.0510s/iter; left time: 782.5886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.36s\n",
      "Steps: 902 | Train Loss: 0.1267166 Vali Loss: 0.1417985 Test Loss: 0.1600939\n",
      "Validation loss decreased (0.159657 --> 0.141799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1117888\n",
      "\tspeed: 0.1424s/iter; left time: 2169.7528s\n",
      "\titers: 200, epoch: 4 | loss: 0.1026877\n",
      "\tspeed: 0.0505s/iter; left time: 763.6327s\n",
      "\titers: 300, epoch: 4 | loss: 0.1014980\n",
      "\tspeed: 0.0506s/iter; left time: 760.6549s\n",
      "\titers: 400, epoch: 4 | loss: 0.1038646\n",
      "\tspeed: 0.0505s/iter; left time: 754.2511s\n",
      "\titers: 500, epoch: 4 | loss: 0.0989735\n",
      "\tspeed: 0.0504s/iter; left time: 747.5785s\n",
      "\titers: 600, epoch: 4 | loss: 0.1064414\n",
      "\tspeed: 0.0504s/iter; left time: 742.2079s\n",
      "\titers: 700, epoch: 4 | loss: 0.0987112\n",
      "\tspeed: 0.0504s/iter; left time: 737.3631s\n",
      "\titers: 800, epoch: 4 | loss: 0.1000495\n",
      "\tspeed: 0.0504s/iter; left time: 732.4440s\n",
      "\titers: 900, epoch: 4 | loss: 0.0978920\n",
      "\tspeed: 0.0504s/iter; left time: 727.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1061221 Vali Loss: 0.1528979 Test Loss: 0.1627806\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918928\n",
      "\tspeed: 0.1384s/iter; left time: 1983.2864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0960290\n",
      "\tspeed: 0.0511s/iter; left time: 727.3949s\n",
      "\titers: 300, epoch: 5 | loss: 0.0931458\n",
      "\tspeed: 0.0512s/iter; left time: 724.2957s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993961\n",
      "\tspeed: 0.0511s/iter; left time: 716.4612s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912344\n",
      "\tspeed: 0.0506s/iter; left time: 704.4801s\n",
      "\titers: 600, epoch: 5 | loss: 0.0892607\n",
      "\tspeed: 0.0505s/iter; left time: 698.8492s\n",
      "\titers: 700, epoch: 5 | loss: 0.0910661\n",
      "\tspeed: 0.0504s/iter; left time: 692.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1011088\n",
      "\tspeed: 0.0505s/iter; left time: 688.4830s\n",
      "\titers: 900, epoch: 5 | loss: 0.0920976\n",
      "\tspeed: 0.0504s/iter; left time: 682.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.06s\n",
      "Steps: 902 | Train Loss: 0.0971309 Vali Loss: 0.1423063 Test Loss: 0.1565221\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920235\n",
      "\tspeed: 0.1408s/iter; left time: 1890.4647s\n",
      "\titers: 200, epoch: 6 | loss: 0.0922436\n",
      "\tspeed: 0.0511s/iter; left time: 681.2781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0902070\n",
      "\tspeed: 0.0511s/iter; left time: 676.7292s\n",
      "\titers: 400, epoch: 6 | loss: 0.0975088\n",
      "\tspeed: 0.0512s/iter; left time: 671.7489s\n",
      "\titers: 500, epoch: 6 | loss: 0.0972495\n",
      "\tspeed: 0.0511s/iter; left time: 666.4803s\n",
      "\titers: 600, epoch: 6 | loss: 0.0895226\n",
      "\tspeed: 0.0511s/iter; left time: 661.3073s\n",
      "\titers: 700, epoch: 6 | loss: 0.0809252\n",
      "\tspeed: 0.0511s/iter; left time: 655.7049s\n",
      "\titers: 800, epoch: 6 | loss: 0.0889638\n",
      "\tspeed: 0.0511s/iter; left time: 651.0962s\n",
      "\titers: 900, epoch: 6 | loss: 0.0874771\n",
      "\tspeed: 0.0511s/iter; left time: 645.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0901457 Vali Loss: 0.1472353 Test Loss: 0.1613897\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832280\n",
      "\tspeed: 0.1385s/iter; left time: 1735.5467s\n",
      "\titers: 200, epoch: 7 | loss: 0.0830341\n",
      "\tspeed: 0.0505s/iter; left time: 628.0122s\n",
      "\titers: 300, epoch: 7 | loss: 0.0871024\n",
      "\tspeed: 0.0505s/iter; left time: 622.9652s\n",
      "\titers: 400, epoch: 7 | loss: 0.0823863\n",
      "\tspeed: 0.0505s/iter; left time: 617.8123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0869082\n",
      "\tspeed: 0.0506s/iter; left time: 613.9551s\n",
      "\titers: 600, epoch: 7 | loss: 0.0787628\n",
      "\tspeed: 0.0505s/iter; left time: 607.5038s\n",
      "\titers: 700, epoch: 7 | loss: 0.0807302\n",
      "\tspeed: 0.0504s/iter; left time: 601.6845s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859715\n",
      "\tspeed: 0.0505s/iter; left time: 596.9224s\n",
      "\titers: 900, epoch: 7 | loss: 0.0893550\n",
      "\tspeed: 0.0505s/iter; left time: 591.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0839997 Vali Loss: 0.1402461 Test Loss: 0.1580236\n",
      "Validation loss decreased (0.141799 --> 0.140246).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0807353\n",
      "\tspeed: 0.1480s/iter; left time: 1721.0885s\n",
      "\titers: 200, epoch: 8 | loss: 0.0845029\n",
      "\tspeed: 0.0505s/iter; left time: 582.2940s\n",
      "\titers: 300, epoch: 8 | loss: 0.0833175\n",
      "\tspeed: 0.0505s/iter; left time: 577.5719s\n",
      "\titers: 400, epoch: 8 | loss: 0.0774543\n",
      "\tspeed: 0.0504s/iter; left time: 570.9776s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767989\n",
      "\tspeed: 0.0506s/iter; left time: 568.2994s\n",
      "\titers: 600, epoch: 8 | loss: 0.0740711\n",
      "\tspeed: 0.0506s/iter; left time: 562.4822s\n",
      "\titers: 700, epoch: 8 | loss: 0.0755660\n",
      "\tspeed: 0.0506s/iter; left time: 557.9460s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745798\n",
      "\tspeed: 0.0506s/iter; left time: 553.4293s\n",
      "\titers: 900, epoch: 8 | loss: 0.0752394\n",
      "\tspeed: 0.0505s/iter; left time: 546.4044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.0790876 Vali Loss: 0.1432174 Test Loss: 0.1611511\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0703514\n",
      "\tspeed: 0.1390s/iter; left time: 1490.3299s\n",
      "\titers: 200, epoch: 9 | loss: 0.0778098\n",
      "\tspeed: 0.0509s/iter; left time: 540.7775s\n",
      "\titers: 300, epoch: 9 | loss: 0.0785731\n",
      "\tspeed: 0.0505s/iter; left time: 531.7624s\n",
      "\titers: 400, epoch: 9 | loss: 0.0750980\n",
      "\tspeed: 0.0506s/iter; left time: 527.9468s\n",
      "\titers: 500, epoch: 9 | loss: 0.0785402\n",
      "\tspeed: 0.0512s/iter; left time: 528.2391s\n",
      "\titers: 600, epoch: 9 | loss: 0.0711287\n",
      "\tspeed: 0.0512s/iter; left time: 523.7596s\n",
      "\titers: 700, epoch: 9 | loss: 0.0769884\n",
      "\tspeed: 0.0513s/iter; left time: 518.9390s\n",
      "\titers: 800, epoch: 9 | loss: 0.0754216\n",
      "\tspeed: 0.0512s/iter; left time: 513.7073s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719022\n",
      "\tspeed: 0.0512s/iter; left time: 508.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.23s\n",
      "Steps: 902 | Train Loss: 0.0748285 Vali Loss: 0.1403084 Test Loss: 0.1591520\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0676495\n",
      "\tspeed: 0.1400s/iter; left time: 1375.3179s\n",
      "\titers: 200, epoch: 10 | loss: 0.0732440\n",
      "\tspeed: 0.0512s/iter; left time: 498.0206s\n",
      "\titers: 300, epoch: 10 | loss: 0.0741318\n",
      "\tspeed: 0.0512s/iter; left time: 492.5140s\n",
      "\titers: 400, epoch: 10 | loss: 0.0708465\n",
      "\tspeed: 0.0511s/iter; left time: 486.7042s\n",
      "\titers: 500, epoch: 10 | loss: 0.0714293\n",
      "\tspeed: 0.0512s/iter; left time: 482.4216s\n",
      "\titers: 600, epoch: 10 | loss: 0.0729542\n",
      "\tspeed: 0.0511s/iter; left time: 476.5732s\n",
      "\titers: 700, epoch: 10 | loss: 0.0714578\n",
      "\tspeed: 0.0511s/iter; left time: 471.3907s\n",
      "\titers: 800, epoch: 10 | loss: 0.0682916\n",
      "\tspeed: 0.0511s/iter; left time: 466.2845s\n",
      "\titers: 900, epoch: 10 | loss: 0.0718856\n",
      "\tspeed: 0.0506s/iter; left time: 456.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.0712225 Vali Loss: 0.1423417 Test Loss: 0.1615068\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672577\n",
      "\tspeed: 0.1397s/iter; left time: 1246.3109s\n",
      "\titers: 200, epoch: 11 | loss: 0.0695483\n",
      "\tspeed: 0.0512s/iter; left time: 451.4285s\n",
      "\titers: 300, epoch: 11 | loss: 0.0647759\n",
      "\tspeed: 0.0510s/iter; left time: 445.1117s\n",
      "\titers: 400, epoch: 11 | loss: 0.0645632\n",
      "\tspeed: 0.0510s/iter; left time: 439.9699s\n",
      "\titers: 500, epoch: 11 | loss: 0.0772103\n",
      "\tspeed: 0.0510s/iter; left time: 434.5106s\n",
      "\titers: 600, epoch: 11 | loss: 0.0657790\n",
      "\tspeed: 0.0510s/iter; left time: 429.5179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0685922\n",
      "\tspeed: 0.0507s/iter; left time: 422.0749s\n",
      "\titers: 800, epoch: 11 | loss: 0.0658226\n",
      "\tspeed: 0.0510s/iter; left time: 419.3127s\n",
      "\titers: 900, epoch: 11 | loss: 0.0667105\n",
      "\tspeed: 0.0510s/iter; left time: 414.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:46.34s\n",
      "Steps: 902 | Train Loss: 0.0681893 Vali Loss: 0.1411986 Test Loss: 0.1595801\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0650528\n",
      "\tspeed: 0.1383s/iter; left time: 1108.7168s\n",
      "\titers: 200, epoch: 12 | loss: 0.0708718\n",
      "\tspeed: 0.0511s/iter; left time: 404.2901s\n",
      "\titers: 300, epoch: 12 | loss: 0.0652237\n",
      "\tspeed: 0.0506s/iter; left time: 395.8605s\n",
      "\titers: 400, epoch: 12 | loss: 0.0649883\n",
      "\tspeed: 0.0507s/iter; left time: 391.5492s\n",
      "\titers: 500, epoch: 12 | loss: 0.0644263\n",
      "\tspeed: 0.0506s/iter; left time: 385.6037s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660991\n",
      "\tspeed: 0.0506s/iter; left time: 380.4517s\n",
      "\titers: 700, epoch: 12 | loss: 0.0694268\n",
      "\tspeed: 0.0506s/iter; left time: 375.5242s\n",
      "\titers: 800, epoch: 12 | loss: 0.0674071\n",
      "\tspeed: 0.0506s/iter; left time: 370.2007s\n",
      "\titers: 900, epoch: 12 | loss: 0.0676546\n",
      "\tspeed: 0.0506s/iter; left time: 365.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0656815 Vali Loss: 0.1400202 Test Loss: 0.1601845\n",
      "Validation loss decreased (0.140246 --> 0.140020).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625419\n",
      "\tspeed: 0.1435s/iter; left time: 1021.4043s\n",
      "\titers: 200, epoch: 13 | loss: 0.0636671\n",
      "\tspeed: 0.0510s/iter; left time: 357.9900s\n",
      "\titers: 300, epoch: 13 | loss: 0.0667756\n",
      "\tspeed: 0.0510s/iter; left time: 353.0616s\n",
      "\titers: 400, epoch: 13 | loss: 0.0637611\n",
      "\tspeed: 0.0512s/iter; left time: 349.0311s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616729\n",
      "\tspeed: 0.0512s/iter; left time: 344.0386s\n",
      "\titers: 600, epoch: 13 | loss: 0.0642316\n",
      "\tspeed: 0.0509s/iter; left time: 336.7321s\n",
      "\titers: 700, epoch: 13 | loss: 0.0620666\n",
      "\tspeed: 0.0510s/iter; left time: 332.5125s\n",
      "\titers: 800, epoch: 13 | loss: 0.0658408\n",
      "\tspeed: 0.0513s/iter; left time: 328.8980s\n",
      "\titers: 900, epoch: 13 | loss: 0.0617386\n",
      "\tspeed: 0.0513s/iter; left time: 323.8158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:46.37s\n",
      "Steps: 902 | Train Loss: 0.0634137 Vali Loss: 0.1419839 Test Loss: 0.1631894\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0585671\n",
      "\tspeed: 0.1396s/iter; left time: 867.4336s\n",
      "\titers: 200, epoch: 14 | loss: 0.0664492\n",
      "\tspeed: 0.0506s/iter; left time: 309.6088s\n",
      "\titers: 300, epoch: 14 | loss: 0.0629691\n",
      "\tspeed: 0.0507s/iter; left time: 304.6759s\n",
      "\titers: 400, epoch: 14 | loss: 0.0620267\n",
      "\tspeed: 0.0507s/iter; left time: 299.7290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0623624\n",
      "\tspeed: 0.0507s/iter; left time: 294.8488s\n",
      "\titers: 600, epoch: 14 | loss: 0.0619973\n",
      "\tspeed: 0.0506s/iter; left time: 289.3720s\n",
      "\titers: 700, epoch: 14 | loss: 0.0618283\n",
      "\tspeed: 0.0508s/iter; left time: 285.1200s\n",
      "\titers: 800, epoch: 14 | loss: 0.0577629\n",
      "\tspeed: 0.0511s/iter; left time: 281.8709s\n",
      "\titers: 900, epoch: 14 | loss: 0.0643250\n",
      "\tspeed: 0.0512s/iter; left time: 277.0635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.10s\n",
      "Steps: 902 | Train Loss: 0.0616388 Vali Loss: 0.1407283 Test Loss: 0.1611458\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597400\n",
      "\tspeed: 0.1409s/iter; left time: 748.5759s\n",
      "\titers: 200, epoch: 15 | loss: 0.0610378\n",
      "\tspeed: 0.0513s/iter; left time: 267.3372s\n",
      "\titers: 300, epoch: 15 | loss: 0.0592156\n",
      "\tspeed: 0.0513s/iter; left time: 262.3524s\n",
      "\titers: 400, epoch: 15 | loss: 0.0588845\n",
      "\tspeed: 0.0513s/iter; left time: 257.2757s\n",
      "\titers: 500, epoch: 15 | loss: 0.0618582\n",
      "\tspeed: 0.0513s/iter; left time: 251.8946s\n",
      "\titers: 600, epoch: 15 | loss: 0.0604138\n",
      "\tspeed: 0.0513s/iter; left time: 246.7312s\n",
      "\titers: 700, epoch: 15 | loss: 0.0605271\n",
      "\tspeed: 0.0513s/iter; left time: 241.7580s\n",
      "\titers: 800, epoch: 15 | loss: 0.0604768\n",
      "\tspeed: 0.0513s/iter; left time: 236.5873s\n",
      "\titers: 900, epoch: 15 | loss: 0.0590711\n",
      "\tspeed: 0.0513s/iter; left time: 231.5640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.0600248 Vali Loss: 0.1428889 Test Loss: 0.1618677\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0612130\n",
      "\tspeed: 0.1387s/iter; left time: 611.8801s\n",
      "\titers: 200, epoch: 16 | loss: 0.0578973\n",
      "\tspeed: 0.0506s/iter; left time: 218.1125s\n",
      "\titers: 300, epoch: 16 | loss: 0.0590760\n",
      "\tspeed: 0.0507s/iter; left time: 213.3454s\n",
      "\titers: 400, epoch: 16 | loss: 0.0539181\n",
      "\tspeed: 0.0506s/iter; left time: 208.1322s\n",
      "\titers: 500, epoch: 16 | loss: 0.0605631\n",
      "\tspeed: 0.0507s/iter; left time: 203.3086s\n",
      "\titers: 600, epoch: 16 | loss: 0.0602342\n",
      "\tspeed: 0.0506s/iter; left time: 197.8721s\n",
      "\titers: 700, epoch: 16 | loss: 0.0567739\n",
      "\tspeed: 0.0506s/iter; left time: 192.9792s\n",
      "\titers: 800, epoch: 16 | loss: 0.0596344\n",
      "\tspeed: 0.0506s/iter; left time: 187.9486s\n",
      "\titers: 900, epoch: 16 | loss: 0.0615203\n",
      "\tspeed: 0.0506s/iter; left time: 182.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 902 | Train Loss: 0.0586482 Vali Loss: 0.1421482 Test Loss: 0.1612585\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595209\n",
      "\tspeed: 0.1391s/iter; left time: 488.1010s\n",
      "\titers: 200, epoch: 17 | loss: 0.0596009\n",
      "\tspeed: 0.0504s/iter; left time: 171.6961s\n",
      "\titers: 300, epoch: 17 | loss: 0.0585621\n",
      "\tspeed: 0.0504s/iter; left time: 166.7300s\n",
      "\titers: 400, epoch: 17 | loss: 0.0652123\n",
      "\tspeed: 0.0504s/iter; left time: 161.8197s\n",
      "\titers: 500, epoch: 17 | loss: 0.0540461\n",
      "\tspeed: 0.0505s/iter; left time: 157.0520s\n",
      "\titers: 600, epoch: 17 | loss: 0.0559000\n",
      "\tspeed: 0.0506s/iter; left time: 152.3226s\n",
      "\titers: 700, epoch: 17 | loss: 0.0554206\n",
      "\tspeed: 0.0506s/iter; left time: 147.2073s\n",
      "\titers: 800, epoch: 17 | loss: 0.0559492\n",
      "\tspeed: 0.0506s/iter; left time: 142.2411s\n",
      "\titers: 900, epoch: 17 | loss: 0.0555495\n",
      "\tspeed: 0.0507s/iter; left time: 137.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:45.85s\n",
      "Steps: 902 | Train Loss: 0.0575157 Vali Loss: 0.1406434 Test Loss: 0.1615269\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05564524605870247, rmse:0.23589244484901428, mae:0.16008244454860687, rse:0.8356959223747253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2329182\n",
      "\tspeed: 0.0528s/iter; left time: 947.6494s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172202\n",
      "\tspeed: 0.0507s/iter; left time: 904.7054s\n",
      "\titers: 300, epoch: 1 | loss: 0.1961658\n",
      "\tspeed: 0.0507s/iter; left time: 899.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1850062\n",
      "\tspeed: 0.0507s/iter; left time: 895.1299s\n",
      "\titers: 500, epoch: 1 | loss: 0.1870918\n",
      "\tspeed: 0.0508s/iter; left time: 890.3390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1944518\n",
      "\tspeed: 0.0506s/iter; left time: 882.1736s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783303\n",
      "\tspeed: 0.0506s/iter; left time: 876.9964s\n",
      "\titers: 800, epoch: 1 | loss: 0.1759333\n",
      "\tspeed: 0.0505s/iter; left time: 871.0565s\n",
      "\titers: 900, epoch: 1 | loss: 0.1763727\n",
      "\tspeed: 0.0506s/iter; left time: 867.0226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.1973616 Vali Loss: 0.1830743 Test Loss: 0.2059395\n",
      "Validation loss decreased (inf --> 0.183074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1503127\n",
      "\tspeed: 0.1421s/iter; left time: 2420.4738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1512766\n",
      "\tspeed: 0.0506s/iter; left time: 857.6590s\n",
      "\titers: 300, epoch: 2 | loss: 0.1382957\n",
      "\tspeed: 0.0506s/iter; left time: 852.5279s\n",
      "\titers: 400, epoch: 2 | loss: 0.1341342\n",
      "\tspeed: 0.0506s/iter; left time: 847.7158s\n",
      "\titers: 500, epoch: 2 | loss: 0.1374097\n",
      "\tspeed: 0.0506s/iter; left time: 842.4117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1432593\n",
      "\tspeed: 0.0505s/iter; left time: 834.9621s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279730\n",
      "\tspeed: 0.0504s/iter; left time: 828.2137s\n",
      "\titers: 800, epoch: 2 | loss: 0.1409557\n",
      "\tspeed: 0.0504s/iter; left time: 823.0514s\n",
      "\titers: 900, epoch: 2 | loss: 0.1172102\n",
      "\tspeed: 0.0504s/iter; left time: 818.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 902 | Train Loss: 0.1439408 Vali Loss: 0.1546091 Test Loss: 0.1715550\n",
      "Validation loss decreased (0.183074 --> 0.154609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1301890\n",
      "\tspeed: 0.1410s/iter; left time: 2275.0167s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247176\n",
      "\tspeed: 0.0505s/iter; left time: 809.6763s\n",
      "\titers: 300, epoch: 3 | loss: 0.1338786\n",
      "\tspeed: 0.0507s/iter; left time: 807.7225s\n",
      "\titers: 400, epoch: 3 | loss: 0.1215102\n",
      "\tspeed: 0.0507s/iter; left time: 802.9834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1196253\n",
      "\tspeed: 0.0507s/iter; left time: 797.5365s\n",
      "\titers: 600, epoch: 3 | loss: 0.1286701\n",
      "\tspeed: 0.0504s/iter; left time: 787.8341s\n",
      "\titers: 700, epoch: 3 | loss: 0.1157779\n",
      "\tspeed: 0.0504s/iter; left time: 782.7377s\n",
      "\titers: 800, epoch: 3 | loss: 0.1232034\n",
      "\tspeed: 0.0504s/iter; left time: 778.3771s\n",
      "\titers: 900, epoch: 3 | loss: 0.1138987\n",
      "\tspeed: 0.0504s/iter; left time: 773.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.1216343 Vali Loss: 0.1383445 Test Loss: 0.1558911\n",
      "Validation loss decreased (0.154609 --> 0.138345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097272\n",
      "\tspeed: 0.1400s/iter; left time: 2132.6516s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003548\n",
      "\tspeed: 0.0504s/iter; left time: 763.2827s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034977\n",
      "\tspeed: 0.0504s/iter; left time: 757.4019s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083793\n",
      "\tspeed: 0.0504s/iter; left time: 752.3880s\n",
      "\titers: 500, epoch: 4 | loss: 0.1005158\n",
      "\tspeed: 0.0504s/iter; left time: 747.7124s\n",
      "\titers: 600, epoch: 4 | loss: 0.1054492\n",
      "\tspeed: 0.0504s/iter; left time: 742.8598s\n",
      "\titers: 700, epoch: 4 | loss: 0.1030866\n",
      "\tspeed: 0.0504s/iter; left time: 737.7559s\n",
      "\titers: 800, epoch: 4 | loss: 0.1006965\n",
      "\tspeed: 0.0504s/iter; left time: 732.9385s\n",
      "\titers: 900, epoch: 4 | loss: 0.1023383\n",
      "\tspeed: 0.0505s/iter; left time: 728.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.1054264 Vali Loss: 0.1426753 Test Loss: 0.1533596\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1043797\n",
      "\tspeed: 0.1380s/iter; left time: 1978.4526s\n",
      "\titers: 200, epoch: 5 | loss: 0.1015226\n",
      "\tspeed: 0.0506s/iter; left time: 719.8159s\n",
      "\titers: 300, epoch: 5 | loss: 0.1025427\n",
      "\tspeed: 0.0506s/iter; left time: 715.4537s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976157\n",
      "\tspeed: 0.0505s/iter; left time: 708.6062s\n",
      "\titers: 500, epoch: 5 | loss: 0.0992124\n",
      "\tspeed: 0.0506s/iter; left time: 704.4007s\n",
      "\titers: 600, epoch: 5 | loss: 0.0925273\n",
      "\tspeed: 0.0505s/iter; left time: 698.1557s\n",
      "\titers: 700, epoch: 5 | loss: 0.0902019\n",
      "\tspeed: 0.0506s/iter; left time: 694.8242s\n",
      "\titers: 800, epoch: 5 | loss: 0.0899991\n",
      "\tspeed: 0.0505s/iter; left time: 688.3376s\n",
      "\titers: 900, epoch: 5 | loss: 0.0957246\n",
      "\tspeed: 0.0505s/iter; left time: 683.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0968106 Vali Loss: 0.1373353 Test Loss: 0.1569665\n",
      "Validation loss decreased (0.138345 --> 0.137335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0971396\n",
      "\tspeed: 0.1410s/iter; left time: 1893.4415s\n",
      "\titers: 200, epoch: 6 | loss: 0.0877258\n",
      "\tspeed: 0.0505s/iter; left time: 673.6076s\n",
      "\titers: 300, epoch: 6 | loss: 0.0944563\n",
      "\tspeed: 0.0505s/iter; left time: 668.4162s\n",
      "\titers: 400, epoch: 6 | loss: 0.0953016\n",
      "\tspeed: 0.0505s/iter; left time: 663.6332s\n",
      "\titers: 500, epoch: 6 | loss: 0.0904507\n",
      "\tspeed: 0.0506s/iter; left time: 658.7336s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920923\n",
      "\tspeed: 0.0507s/iter; left time: 655.0894s\n",
      "\titers: 700, epoch: 6 | loss: 0.0855336\n",
      "\tspeed: 0.0506s/iter; left time: 649.2819s\n",
      "\titers: 800, epoch: 6 | loss: 0.0849263\n",
      "\tspeed: 0.0507s/iter; left time: 645.0929s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849293\n",
      "\tspeed: 0.0505s/iter; left time: 638.3477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 902 | Train Loss: 0.0900812 Vali Loss: 0.1398693 Test Loss: 0.1587747\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0829473\n",
      "\tspeed: 0.1391s/iter; left time: 1742.6588s\n",
      "\titers: 200, epoch: 7 | loss: 0.0794557\n",
      "\tspeed: 0.0507s/iter; left time: 630.6465s\n",
      "\titers: 300, epoch: 7 | loss: 0.0834720\n",
      "\tspeed: 0.0507s/iter; left time: 625.3873s\n",
      "\titers: 400, epoch: 7 | loss: 0.0812156\n",
      "\tspeed: 0.0507s/iter; left time: 620.2857s\n",
      "\titers: 500, epoch: 7 | loss: 0.0828412\n",
      "\tspeed: 0.0507s/iter; left time: 614.8473s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856180\n",
      "\tspeed: 0.0506s/iter; left time: 609.1617s\n",
      "\titers: 700, epoch: 7 | loss: 0.0841857\n",
      "\tspeed: 0.0507s/iter; left time: 604.2357s\n",
      "\titers: 800, epoch: 7 | loss: 0.0855514\n",
      "\tspeed: 0.0506s/iter; left time: 598.9587s\n",
      "\titers: 900, epoch: 7 | loss: 0.0821454\n",
      "\tspeed: 0.0507s/iter; left time: 594.1401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0844364 Vali Loss: 0.1380800 Test Loss: 0.1562963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0792243\n",
      "\tspeed: 0.1383s/iter; left time: 1607.5268s\n",
      "\titers: 200, epoch: 8 | loss: 0.0758932\n",
      "\tspeed: 0.0506s/iter; left time: 583.1025s\n",
      "\titers: 300, epoch: 8 | loss: 0.0826427\n",
      "\tspeed: 0.0506s/iter; left time: 578.4702s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799903\n",
      "\tspeed: 0.0506s/iter; left time: 573.5689s\n",
      "\titers: 500, epoch: 8 | loss: 0.0791600\n",
      "\tspeed: 0.0504s/iter; left time: 565.6440s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825389\n",
      "\tspeed: 0.0505s/iter; left time: 562.1391s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792387\n",
      "\tspeed: 0.0506s/iter; left time: 557.6783s\n",
      "\titers: 800, epoch: 8 | loss: 0.0800074\n",
      "\tspeed: 0.0504s/iter; left time: 551.0006s\n",
      "\titers: 900, epoch: 8 | loss: 0.0764232\n",
      "\tspeed: 0.0504s/iter; left time: 545.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0794340 Vali Loss: 0.1406030 Test Loss: 0.1605993\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766746\n",
      "\tspeed: 0.1381s/iter; left time: 1481.6013s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807511\n",
      "\tspeed: 0.0505s/iter; left time: 536.5790s\n",
      "\titers: 300, epoch: 9 | loss: 0.0721841\n",
      "\tspeed: 0.0507s/iter; left time: 533.2897s\n",
      "\titers: 400, epoch: 9 | loss: 0.0782305\n",
      "\tspeed: 0.0507s/iter; left time: 528.4923s\n",
      "\titers: 500, epoch: 9 | loss: 0.0747176\n",
      "\tspeed: 0.0507s/iter; left time: 523.3335s\n",
      "\titers: 600, epoch: 9 | loss: 0.0727979\n",
      "\tspeed: 0.0507s/iter; left time: 518.3577s\n",
      "\titers: 700, epoch: 9 | loss: 0.0737757\n",
      "\tspeed: 0.0507s/iter; left time: 513.0490s\n",
      "\titers: 800, epoch: 9 | loss: 0.0740445\n",
      "\tspeed: 0.0506s/iter; left time: 506.9854s\n",
      "\titers: 900, epoch: 9 | loss: 0.0758738\n",
      "\tspeed: 0.0506s/iter; left time: 501.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 902 | Train Loss: 0.0753867 Vali Loss: 0.1409122 Test Loss: 0.1620111\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738081\n",
      "\tspeed: 0.1402s/iter; left time: 1377.4754s\n",
      "\titers: 200, epoch: 10 | loss: 0.0753992\n",
      "\tspeed: 0.0515s/iter; left time: 500.3210s\n",
      "\titers: 300, epoch: 10 | loss: 0.0722770\n",
      "\tspeed: 0.0515s/iter; left time: 495.7508s\n",
      "\titers: 400, epoch: 10 | loss: 0.0743530\n",
      "\tspeed: 0.0511s/iter; left time: 486.2793s\n",
      "\titers: 500, epoch: 10 | loss: 0.0718583\n",
      "\tspeed: 0.0510s/iter; left time: 481.0144s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755678\n",
      "\tspeed: 0.0511s/iter; left time: 476.3854s\n",
      "\titers: 700, epoch: 10 | loss: 0.0725444\n",
      "\tspeed: 0.0510s/iter; left time: 470.1557s\n",
      "\titers: 800, epoch: 10 | loss: 0.0725415\n",
      "\tspeed: 0.0507s/iter; left time: 462.4133s\n",
      "\titers: 900, epoch: 10 | loss: 0.0698420\n",
      "\tspeed: 0.0507s/iter; left time: 457.4770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 902 | Train Loss: 0.0718391 Vali Loss: 0.1405233 Test Loss: 0.1635022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.051229722797870636, rmse:0.22633983194828033, mae:0.1569782793521881, rse:0.8018538951873779\n",
      "Intermediate time for DE and pred_len 168: 00h:24m:56.06s\n",
      "Intermediate time for DE: 00h:56m:17.98s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_24_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2065667\n",
      "\tspeed: 0.0585s/iter; left time: 1055.0276s\n",
      "\titers: 200, epoch: 1 | loss: 0.1898771\n",
      "\tspeed: 0.0340s/iter; left time: 608.9094s\n",
      "\titers: 300, epoch: 1 | loss: 0.1781441\n",
      "\tspeed: 0.0339s/iter; left time: 604.1571s\n",
      "\titers: 400, epoch: 1 | loss: 0.1769260\n",
      "\tspeed: 0.0339s/iter; left time: 601.0270s\n",
      "\titers: 500, epoch: 1 | loss: 0.1623933\n",
      "\tspeed: 0.0340s/iter; left time: 598.4446s\n",
      "\titers: 600, epoch: 1 | loss: 0.1630156\n",
      "\tspeed: 0.0340s/iter; left time: 594.9816s\n",
      "\titers: 700, epoch: 1 | loss: 0.1549021\n",
      "\tspeed: 0.0339s/iter; left time: 591.3637s\n",
      "\titers: 800, epoch: 1 | loss: 0.1450832\n",
      "\tspeed: 0.0340s/iter; left time: 588.7659s\n",
      "\titers: 900, epoch: 1 | loss: 0.1431629\n",
      "\tspeed: 0.0340s/iter; left time: 585.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.49s\n",
      "Steps: 906 | Train Loss: 0.1802093 Vali Loss: 0.1521474 Test Loss: 0.1806995\n",
      "Validation loss decreased (inf --> 0.152147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1379461\n",
      "\tspeed: 0.1024s/iter; left time: 1752.2041s\n",
      "\titers: 200, epoch: 2 | loss: 0.1183134\n",
      "\tspeed: 0.0340s/iter; left time: 578.6834s\n",
      "\titers: 300, epoch: 2 | loss: 0.1016329\n",
      "\tspeed: 0.0340s/iter; left time: 575.0825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1114180\n",
      "\tspeed: 0.0340s/iter; left time: 571.9411s\n",
      "\titers: 500, epoch: 2 | loss: 0.1128901\n",
      "\tspeed: 0.0340s/iter; left time: 568.0567s\n",
      "\titers: 600, epoch: 2 | loss: 0.0933868\n",
      "\tspeed: 0.0340s/iter; left time: 565.0899s\n",
      "\titers: 700, epoch: 2 | loss: 0.1148216\n",
      "\tspeed: 0.0340s/iter; left time: 562.1364s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128488\n",
      "\tspeed: 0.0340s/iter; left time: 558.8138s\n",
      "\titers: 900, epoch: 2 | loss: 0.0961874\n",
      "\tspeed: 0.0340s/iter; left time: 555.3933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.1125205 Vali Loss: 0.1164644 Test Loss: 0.1396194\n",
      "Validation loss decreased (0.152147 --> 0.116464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1032601\n",
      "\tspeed: 0.0965s/iter; left time: 1563.8764s\n",
      "\titers: 200, epoch: 3 | loss: 0.1003233\n",
      "\tspeed: 0.0340s/iter; left time: 548.0625s\n",
      "\titers: 300, epoch: 3 | loss: 0.1062481\n",
      "\tspeed: 0.0340s/iter; left time: 544.6023s\n",
      "\titers: 400, epoch: 3 | loss: 0.0953404\n",
      "\tspeed: 0.0340s/iter; left time: 541.1076s\n",
      "\titers: 500, epoch: 3 | loss: 0.0999686\n",
      "\tspeed: 0.0340s/iter; left time: 538.0603s\n",
      "\titers: 600, epoch: 3 | loss: 0.0992506\n",
      "\tspeed: 0.0340s/iter; left time: 534.1618s\n",
      "\titers: 700, epoch: 3 | loss: 0.0999163\n",
      "\tspeed: 0.0340s/iter; left time: 531.0028s\n",
      "\titers: 800, epoch: 3 | loss: 0.0913728\n",
      "\tspeed: 0.0340s/iter; left time: 527.7707s\n",
      "\titers: 900, epoch: 3 | loss: 0.1034245\n",
      "\tspeed: 0.0340s/iter; left time: 524.1288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0998791 Vali Loss: 0.1129812 Test Loss: 0.1356770\n",
      "Validation loss decreased (0.116464 --> 0.112981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0897522\n",
      "\tspeed: 0.0980s/iter; left time: 1499.8458s\n",
      "\titers: 200, epoch: 4 | loss: 0.1064864\n",
      "\tspeed: 0.0346s/iter; left time: 526.4130s\n",
      "\titers: 300, epoch: 4 | loss: 0.0940685\n",
      "\tspeed: 0.0343s/iter; left time: 518.5255s\n",
      "\titers: 400, epoch: 4 | loss: 0.1048222\n",
      "\tspeed: 0.0341s/iter; left time: 511.0756s\n",
      "\titers: 500, epoch: 4 | loss: 0.1119908\n",
      "\tspeed: 0.0341s/iter; left time: 508.0281s\n",
      "\titers: 600, epoch: 4 | loss: 0.1028988\n",
      "\tspeed: 0.0341s/iter; left time: 504.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.0919001\n",
      "\tspeed: 0.0341s/iter; left time: 501.7008s\n",
      "\titers: 800, epoch: 4 | loss: 0.0971707\n",
      "\tspeed: 0.0341s/iter; left time: 497.9438s\n",
      "\titers: 900, epoch: 4 | loss: 0.0936811\n",
      "\tspeed: 0.0341s/iter; left time: 494.6094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.35s\n",
      "Steps: 906 | Train Loss: 0.0970638 Vali Loss: 0.1139413 Test Loss: 0.1345681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1065073\n",
      "\tspeed: 0.0945s/iter; left time: 1360.9809s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901787\n",
      "\tspeed: 0.0340s/iter; left time: 486.4075s\n",
      "\titers: 300, epoch: 5 | loss: 0.0899963\n",
      "\tspeed: 0.0340s/iter; left time: 483.3176s\n",
      "\titers: 400, epoch: 5 | loss: 0.1047166\n",
      "\tspeed: 0.0340s/iter; left time: 479.6122s\n",
      "\titers: 500, epoch: 5 | loss: 0.0848665\n",
      "\tspeed: 0.0340s/iter; left time: 476.0220s\n",
      "\titers: 600, epoch: 5 | loss: 0.0877800\n",
      "\tspeed: 0.0341s/iter; left time: 473.3804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0995184\n",
      "\tspeed: 0.0340s/iter; left time: 469.2897s\n",
      "\titers: 800, epoch: 5 | loss: 0.1012287\n",
      "\tspeed: 0.0340s/iter; left time: 466.3292s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855802\n",
      "\tspeed: 0.0341s/iter; left time: 463.0074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0934970 Vali Loss: 0.1173672 Test Loss: 0.1402675\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0928552\n",
      "\tspeed: 0.0936s/iter; left time: 1262.0840s\n",
      "\titers: 200, epoch: 6 | loss: 0.0989584\n",
      "\tspeed: 0.0341s/iter; left time: 456.0414s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907293\n",
      "\tspeed: 0.0341s/iter; left time: 453.4878s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939442\n",
      "\tspeed: 0.0341s/iter; left time: 449.2852s\n",
      "\titers: 500, epoch: 6 | loss: 0.0951724\n",
      "\tspeed: 0.0341s/iter; left time: 446.5104s\n",
      "\titers: 600, epoch: 6 | loss: 0.0863666\n",
      "\tspeed: 0.0341s/iter; left time: 442.9592s\n",
      "\titers: 700, epoch: 6 | loss: 0.0910364\n",
      "\tspeed: 0.0341s/iter; left time: 439.9638s\n",
      "\titers: 800, epoch: 6 | loss: 0.0822814\n",
      "\tspeed: 0.0341s/iter; left time: 436.3053s\n",
      "\titers: 900, epoch: 6 | loss: 0.0938590\n",
      "\tspeed: 0.0341s/iter; left time: 433.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0908272 Vali Loss: 0.1192106 Test Loss: 0.1453762\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0746693\n",
      "\tspeed: 0.0942s/iter; left time: 1185.1489s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773950\n",
      "\tspeed: 0.0341s/iter; left time: 426.2154s\n",
      "\titers: 300, epoch: 7 | loss: 0.0814477\n",
      "\tspeed: 0.0341s/iter; left time: 421.8661s\n",
      "\titers: 400, epoch: 7 | loss: 0.0867475\n",
      "\tspeed: 0.0341s/iter; left time: 418.9123s\n",
      "\titers: 500, epoch: 7 | loss: 0.0766155\n",
      "\tspeed: 0.0341s/iter; left time: 415.1243s\n",
      "\titers: 600, epoch: 7 | loss: 0.0661413\n",
      "\tspeed: 0.0341s/iter; left time: 411.8718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0771113\n",
      "\tspeed: 0.0340s/iter; left time: 408.0494s\n",
      "\titers: 800, epoch: 7 | loss: 0.0708948\n",
      "\tspeed: 0.0341s/iter; left time: 404.7029s\n",
      "\titers: 900, epoch: 7 | loss: 0.0775627\n",
      "\tspeed: 0.0341s/iter; left time: 401.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0792233 Vali Loss: 0.1053339 Test Loss: 0.1323265\n",
      "Validation loss decreased (0.112981 --> 0.105334).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742684\n",
      "\tspeed: 0.0994s/iter; left time: 1160.8595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691775\n",
      "\tspeed: 0.0342s/iter; left time: 395.4680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0811470\n",
      "\tspeed: 0.0342s/iter; left time: 392.3738s\n",
      "\titers: 400, epoch: 8 | loss: 0.0708296\n",
      "\tspeed: 0.0341s/iter; left time: 387.5259s\n",
      "\titers: 500, epoch: 8 | loss: 0.0749293\n",
      "\tspeed: 0.0341s/iter; left time: 384.5004s\n",
      "\titers: 600, epoch: 8 | loss: 0.0783654\n",
      "\tspeed: 0.0341s/iter; left time: 381.4007s\n",
      "\titers: 700, epoch: 8 | loss: 0.0806148\n",
      "\tspeed: 0.0341s/iter; left time: 378.3309s\n",
      "\titers: 800, epoch: 8 | loss: 0.0710718\n",
      "\tspeed: 0.0341s/iter; left time: 374.6150s\n",
      "\titers: 900, epoch: 8 | loss: 0.0672735\n",
      "\tspeed: 0.0341s/iter; left time: 371.3417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0752110 Vali Loss: 0.1059797 Test Loss: 0.1272185\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0764559\n",
      "\tspeed: 0.0936s/iter; left time: 1008.6992s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805175\n",
      "\tspeed: 0.0341s/iter; left time: 364.3434s\n",
      "\titers: 300, epoch: 9 | loss: 0.0701884\n",
      "\tspeed: 0.0341s/iter; left time: 360.6060s\n",
      "\titers: 400, epoch: 9 | loss: 0.0753982\n",
      "\tspeed: 0.0341s/iter; left time: 357.3582s\n",
      "\titers: 500, epoch: 9 | loss: 0.0740065\n",
      "\tspeed: 0.0341s/iter; left time: 353.8814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0621589\n",
      "\tspeed: 0.0341s/iter; left time: 350.4821s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747598\n",
      "\tspeed: 0.0341s/iter; left time: 347.1544s\n",
      "\titers: 800, epoch: 9 | loss: 0.0816423\n",
      "\tspeed: 0.0342s/iter; left time: 344.0571s\n",
      "\titers: 900, epoch: 9 | loss: 0.0695066\n",
      "\tspeed: 0.0341s/iter; left time: 339.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.18s\n",
      "Steps: 906 | Train Loss: 0.0726019 Vali Loss: 0.1069399 Test Loss: 0.1331095\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0704984\n",
      "\tspeed: 0.0937s/iter; left time: 924.1009s\n",
      "\titers: 200, epoch: 10 | loss: 0.0701090\n",
      "\tspeed: 0.0341s/iter; left time: 332.8216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0659057\n",
      "\tspeed: 0.0341s/iter; left time: 329.1772s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728105\n",
      "\tspeed: 0.0340s/iter; left time: 325.6335s\n",
      "\titers: 500, epoch: 10 | loss: 0.0748692\n",
      "\tspeed: 0.0341s/iter; left time: 322.9291s\n",
      "\titers: 600, epoch: 10 | loss: 0.0678749\n",
      "\tspeed: 0.0341s/iter; left time: 319.4862s\n",
      "\titers: 700, epoch: 10 | loss: 0.0699628\n",
      "\tspeed: 0.0341s/iter; left time: 315.9728s\n",
      "\titers: 800, epoch: 10 | loss: 0.0634394\n",
      "\tspeed: 0.0341s/iter; left time: 312.2789s\n",
      "\titers: 900, epoch: 10 | loss: 0.0716516\n",
      "\tspeed: 0.0341s/iter; left time: 309.1606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0698472 Vali Loss: 0.0994613 Test Loss: 0.1233056\n",
      "Validation loss decreased (0.105334 --> 0.099461).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0626306\n",
      "\tspeed: 0.0962s/iter; left time: 861.7134s\n",
      "\titers: 200, epoch: 11 | loss: 0.0640720\n",
      "\tspeed: 0.0340s/iter; left time: 301.5909s\n",
      "\titers: 300, epoch: 11 | loss: 0.0588703\n",
      "\tspeed: 0.0341s/iter; left time: 298.7134s\n",
      "\titers: 400, epoch: 11 | loss: 0.0595044\n",
      "\tspeed: 0.0340s/iter; left time: 294.7817s\n",
      "\titers: 500, epoch: 11 | loss: 0.0624516\n",
      "\tspeed: 0.0341s/iter; left time: 291.5805s\n",
      "\titers: 600, epoch: 11 | loss: 0.0580348\n",
      "\tspeed: 0.0340s/iter; left time: 287.6216s\n",
      "\titers: 700, epoch: 11 | loss: 0.0642682\n",
      "\tspeed: 0.0341s/iter; left time: 285.1872s\n",
      "\titers: 800, epoch: 11 | loss: 0.0618705\n",
      "\tspeed: 0.0341s/iter; left time: 281.5465s\n",
      "\titers: 900, epoch: 11 | loss: 0.0543362\n",
      "\tspeed: 0.0340s/iter; left time: 277.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0620900 Vali Loss: 0.1001814 Test Loss: 0.1275305\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0608115\n",
      "\tspeed: 0.0933s/iter; left time: 751.3224s\n",
      "\titers: 200, epoch: 12 | loss: 0.0623593\n",
      "\tspeed: 0.0341s/iter; left time: 270.8942s\n",
      "\titers: 300, epoch: 12 | loss: 0.0562274\n",
      "\tspeed: 0.0341s/iter; left time: 268.0192s\n",
      "\titers: 400, epoch: 12 | loss: 0.0648748\n",
      "\tspeed: 0.0341s/iter; left time: 264.4116s\n",
      "\titers: 500, epoch: 12 | loss: 0.0535899\n",
      "\tspeed: 0.0341s/iter; left time: 260.6790s\n",
      "\titers: 600, epoch: 12 | loss: 0.0538404\n",
      "\tspeed: 0.0341s/iter; left time: 257.2894s\n",
      "\titers: 700, epoch: 12 | loss: 0.0548301\n",
      "\tspeed: 0.0341s/iter; left time: 254.1875s\n",
      "\titers: 800, epoch: 12 | loss: 0.0514138\n",
      "\tspeed: 0.0340s/iter; left time: 250.2762s\n",
      "\titers: 900, epoch: 12 | loss: 0.0655189\n",
      "\tspeed: 0.0341s/iter; left time: 247.1409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0597273 Vali Loss: 0.1036253 Test Loss: 0.1352557\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0566351\n",
      "\tspeed: 0.0941s/iter; left time: 673.0170s\n",
      "\titers: 200, epoch: 13 | loss: 0.0536230\n",
      "\tspeed: 0.0341s/iter; left time: 240.1297s\n",
      "\titers: 300, epoch: 13 | loss: 0.0634737\n",
      "\tspeed: 0.0341s/iter; left time: 237.0724s\n",
      "\titers: 400, epoch: 13 | loss: 0.0572632\n",
      "\tspeed: 0.0340s/iter; left time: 233.1244s\n",
      "\titers: 500, epoch: 13 | loss: 0.0540060\n",
      "\tspeed: 0.0341s/iter; left time: 229.8116s\n",
      "\titers: 600, epoch: 13 | loss: 0.0529787\n",
      "\tspeed: 0.0341s/iter; left time: 226.9394s\n",
      "\titers: 700, epoch: 13 | loss: 0.0610991\n",
      "\tspeed: 0.0341s/iter; left time: 223.1880s\n",
      "\titers: 800, epoch: 13 | loss: 0.0578308\n",
      "\tspeed: 0.0341s/iter; left time: 219.6118s\n",
      "\titers: 900, epoch: 13 | loss: 0.0553324\n",
      "\tspeed: 0.0341s/iter; left time: 216.2252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0578906 Vali Loss: 0.1017295 Test Loss: 0.1305108\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0616051\n",
      "\tspeed: 0.0943s/iter; left time: 588.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0553820\n",
      "\tspeed: 0.0342s/iter; left time: 209.7892s\n",
      "\titers: 300, epoch: 14 | loss: 0.0544165\n",
      "\tspeed: 0.0342s/iter; left time: 206.4339s\n",
      "\titers: 400, epoch: 14 | loss: 0.0571011\n",
      "\tspeed: 0.0341s/iter; left time: 202.7012s\n",
      "\titers: 500, epoch: 14 | loss: 0.0607028\n",
      "\tspeed: 0.0341s/iter; left time: 199.2424s\n",
      "\titers: 600, epoch: 14 | loss: 0.0542016\n",
      "\tspeed: 0.0341s/iter; left time: 195.8150s\n",
      "\titers: 700, epoch: 14 | loss: 0.0561629\n",
      "\tspeed: 0.0342s/iter; left time: 192.8704s\n",
      "\titers: 800, epoch: 14 | loss: 0.0597202\n",
      "\tspeed: 0.0341s/iter; left time: 189.0456s\n",
      "\titers: 900, epoch: 14 | loss: 0.0638149\n",
      "\tspeed: 0.0342s/iter; left time: 186.1832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.25s\n",
      "Steps: 906 | Train Loss: 0.0560134 Vali Loss: 0.1008903 Test Loss: 0.1284106\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0531591\n",
      "\tspeed: 0.0942s/iter; left time: 502.6085s\n",
      "\titers: 200, epoch: 15 | loss: 0.0574485\n",
      "\tspeed: 0.0341s/iter; left time: 178.4678s\n",
      "\titers: 300, epoch: 15 | loss: 0.0499670\n",
      "\tspeed: 0.0341s/iter; left time: 175.3850s\n",
      "\titers: 400, epoch: 15 | loss: 0.0561084\n",
      "\tspeed: 0.0342s/iter; left time: 172.0325s\n",
      "\titers: 500, epoch: 15 | loss: 0.0534714\n",
      "\tspeed: 0.0342s/iter; left time: 168.7018s\n",
      "\titers: 600, epoch: 15 | loss: 0.0518036\n",
      "\tspeed: 0.0341s/iter; left time: 165.0023s\n",
      "\titers: 700, epoch: 15 | loss: 0.0593414\n",
      "\tspeed: 0.0341s/iter; left time: 161.5421s\n",
      "\titers: 800, epoch: 15 | loss: 0.0531404\n",
      "\tspeed: 0.0341s/iter; left time: 158.3529s\n",
      "\titers: 900, epoch: 15 | loss: 0.0592867\n",
      "\tspeed: 0.0341s/iter; left time: 154.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0546766 Vali Loss: 0.1010287 Test Loss: 0.1288189\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03368111699819565, rmse:0.18352416157722473, mae:0.12335905432701111, rse:0.6327870488166809\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2087424\n",
      "\tspeed: 0.0362s/iter; left time: 652.4385s\n",
      "\titers: 200, epoch: 1 | loss: 0.1828572\n",
      "\tspeed: 0.0342s/iter; left time: 612.3118s\n",
      "\titers: 300, epoch: 1 | loss: 0.1897422\n",
      "\tspeed: 0.0341s/iter; left time: 608.0596s\n",
      "\titers: 400, epoch: 1 | loss: 0.1720902\n",
      "\tspeed: 0.0342s/iter; left time: 605.3768s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669981\n",
      "\tspeed: 0.0341s/iter; left time: 600.9832s\n",
      "\titers: 600, epoch: 1 | loss: 0.1590210\n",
      "\tspeed: 0.0341s/iter; left time: 598.1668s\n",
      "\titers: 700, epoch: 1 | loss: 0.1618395\n",
      "\tspeed: 0.0341s/iter; left time: 594.8208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1537406\n",
      "\tspeed: 0.0342s/iter; left time: 591.7778s\n",
      "\titers: 900, epoch: 1 | loss: 0.1561620\n",
      "\tspeed: 0.0341s/iter; left time: 588.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1811837 Vali Loss: 0.1443907 Test Loss: 0.1706055\n",
      "Validation loss decreased (inf --> 0.144391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1264048\n",
      "\tspeed: 0.0961s/iter; left time: 1644.2747s\n",
      "\titers: 200, epoch: 2 | loss: 0.1242911\n",
      "\tspeed: 0.0342s/iter; left time: 581.1043s\n",
      "\titers: 300, epoch: 2 | loss: 0.1100120\n",
      "\tspeed: 0.0342s/iter; left time: 577.6774s\n",
      "\titers: 400, epoch: 2 | loss: 0.0976940\n",
      "\tspeed: 0.0342s/iter; left time: 574.5811s\n",
      "\titers: 500, epoch: 2 | loss: 0.0993426\n",
      "\tspeed: 0.0341s/iter; left time: 570.3608s\n",
      "\titers: 600, epoch: 2 | loss: 0.0993942\n",
      "\tspeed: 0.0342s/iter; left time: 567.6991s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957400\n",
      "\tspeed: 0.0342s/iter; left time: 564.1766s\n",
      "\titers: 800, epoch: 2 | loss: 0.0965493\n",
      "\tspeed: 0.0342s/iter; left time: 560.8260s\n",
      "\titers: 900, epoch: 2 | loss: 0.1025189\n",
      "\tspeed: 0.0341s/iter; left time: 556.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.1120638 Vali Loss: 0.1135424 Test Loss: 0.1331562\n",
      "Validation loss decreased (0.144391 --> 0.113542).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0881129\n",
      "\tspeed: 0.0991s/iter; left time: 1606.9283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0977456\n",
      "\tspeed: 0.0347s/iter; left time: 559.4386s\n",
      "\titers: 300, epoch: 3 | loss: 0.1086163\n",
      "\tspeed: 0.0343s/iter; left time: 549.2724s\n",
      "\titers: 400, epoch: 3 | loss: 0.1002908\n",
      "\tspeed: 0.0341s/iter; left time: 542.8495s\n",
      "\titers: 500, epoch: 3 | loss: 0.0826901\n",
      "\tspeed: 0.0341s/iter; left time: 539.5337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0893644\n",
      "\tspeed: 0.0342s/iter; left time: 536.9598s\n",
      "\titers: 700, epoch: 3 | loss: 0.0908650\n",
      "\tspeed: 0.0341s/iter; left time: 532.7367s\n",
      "\titers: 800, epoch: 3 | loss: 0.0975903\n",
      "\tspeed: 0.0346s/iter; left time: 536.0341s\n",
      "\titers: 900, epoch: 3 | loss: 0.0928147\n",
      "\tspeed: 0.0347s/iter; left time: 534.3495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.41s\n",
      "Steps: 906 | Train Loss: 0.0944582 Vali Loss: 0.1077265 Test Loss: 0.1298520\n",
      "Validation loss decreased (0.113542 --> 0.107726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0863190\n",
      "\tspeed: 0.0970s/iter; left time: 1483.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907177\n",
      "\tspeed: 0.0341s/iter; left time: 518.1031s\n",
      "\titers: 300, epoch: 4 | loss: 0.0833950\n",
      "\tspeed: 0.0341s/iter; left time: 514.8418s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885096\n",
      "\tspeed: 0.0341s/iter; left time: 510.8771s\n",
      "\titers: 500, epoch: 4 | loss: 0.1024313\n",
      "\tspeed: 0.0341s/iter; left time: 508.6603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0902057\n",
      "\tspeed: 0.0341s/iter; left time: 504.3585s\n",
      "\titers: 700, epoch: 4 | loss: 0.0877432\n",
      "\tspeed: 0.0341s/iter; left time: 501.8142s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994082\n",
      "\tspeed: 0.0342s/iter; left time: 499.0221s\n",
      "\titers: 900, epoch: 4 | loss: 0.0841573\n",
      "\tspeed: 0.0341s/iter; left time: 494.4069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0908629 Vali Loss: 0.1066669 Test Loss: 0.1268926\n",
      "Validation loss decreased (0.107726 --> 0.106667).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0901364\n",
      "\tspeed: 0.0965s/iter; left time: 1388.7668s\n",
      "\titers: 200, epoch: 5 | loss: 0.0883172\n",
      "\tspeed: 0.0341s/iter; left time: 488.0627s\n",
      "\titers: 300, epoch: 5 | loss: 0.0873815\n",
      "\tspeed: 0.0341s/iter; left time: 484.5753s\n",
      "\titers: 400, epoch: 5 | loss: 0.0802048\n",
      "\tspeed: 0.0342s/iter; left time: 481.8464s\n",
      "\titers: 500, epoch: 5 | loss: 0.0834858\n",
      "\tspeed: 0.0342s/iter; left time: 478.1296s\n",
      "\titers: 600, epoch: 5 | loss: 0.0920321\n",
      "\tspeed: 0.0341s/iter; left time: 474.1742s\n",
      "\titers: 700, epoch: 5 | loss: 0.1012928\n",
      "\tspeed: 0.0341s/iter; left time: 470.7579s\n",
      "\titers: 800, epoch: 5 | loss: 0.0949160\n",
      "\tspeed: 0.0342s/iter; left time: 467.9884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0833733\n",
      "\tspeed: 0.0341s/iter; left time: 464.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0878463 Vali Loss: 0.1098253 Test Loss: 0.1307452\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0875461\n",
      "\tspeed: 0.0945s/iter; left time: 1274.8394s\n",
      "\titers: 200, epoch: 6 | loss: 0.0793280\n",
      "\tspeed: 0.0347s/iter; left time: 464.6410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0823781\n",
      "\tspeed: 0.0347s/iter; left time: 461.2001s\n",
      "\titers: 400, epoch: 6 | loss: 0.0781062\n",
      "\tspeed: 0.0347s/iter; left time: 458.1822s\n",
      "\titers: 500, epoch: 6 | loss: 0.0726712\n",
      "\tspeed: 0.0347s/iter; left time: 453.9454s\n",
      "\titers: 600, epoch: 6 | loss: 0.0621493\n",
      "\tspeed: 0.0344s/iter; left time: 446.9567s\n",
      "\titers: 700, epoch: 6 | loss: 0.0807547\n",
      "\tspeed: 0.0341s/iter; left time: 439.7816s\n",
      "\titers: 800, epoch: 6 | loss: 0.0704086\n",
      "\tspeed: 0.0341s/iter; left time: 436.5041s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726400\n",
      "\tspeed: 0.0341s/iter; left time: 432.8790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.47s\n",
      "Steps: 906 | Train Loss: 0.0782342 Vali Loss: 0.0994923 Test Loss: 0.1179419\n",
      "Validation loss decreased (0.106667 --> 0.099492).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0712830\n",
      "\tspeed: 0.0978s/iter; left time: 1231.4343s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739732\n",
      "\tspeed: 0.0347s/iter; left time: 433.0052s\n",
      "\titers: 300, epoch: 7 | loss: 0.0753709\n",
      "\tspeed: 0.0347s/iter; left time: 429.3025s\n",
      "\titers: 400, epoch: 7 | loss: 0.0684797\n",
      "\tspeed: 0.0341s/iter; left time: 419.4674s\n",
      "\titers: 500, epoch: 7 | loss: 0.0776076\n",
      "\tspeed: 0.0342s/iter; left time: 416.5956s\n",
      "\titers: 600, epoch: 7 | loss: 0.0703165\n",
      "\tspeed: 0.0341s/iter; left time: 412.4213s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794782\n",
      "\tspeed: 0.0341s/iter; left time: 409.1995s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693715\n",
      "\tspeed: 0.0341s/iter; left time: 405.5195s\n",
      "\titers: 900, epoch: 7 | loss: 0.0780969\n",
      "\tspeed: 0.0342s/iter; left time: 402.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0721806 Vali Loss: 0.0970641 Test Loss: 0.1169970\n",
      "Validation loss decreased (0.099492 --> 0.097064).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0636127\n",
      "\tspeed: 0.0981s/iter; left time: 1145.4293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0630548\n",
      "\tspeed: 0.0342s/iter; left time: 395.8652s\n",
      "\titers: 300, epoch: 8 | loss: 0.0730316\n",
      "\tspeed: 0.0342s/iter; left time: 392.2474s\n",
      "\titers: 400, epoch: 8 | loss: 0.0669587\n",
      "\tspeed: 0.0341s/iter; left time: 388.5562s\n",
      "\titers: 500, epoch: 8 | loss: 0.0619939\n",
      "\tspeed: 0.0342s/iter; left time: 385.2777s\n",
      "\titers: 600, epoch: 8 | loss: 0.0640725\n",
      "\tspeed: 0.0342s/iter; left time: 382.2546s\n",
      "\titers: 700, epoch: 8 | loss: 0.0613099\n",
      "\tspeed: 0.0341s/iter; left time: 378.3109s\n",
      "\titers: 800, epoch: 8 | loss: 0.0650655\n",
      "\tspeed: 0.0342s/iter; left time: 375.4917s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699186\n",
      "\tspeed: 0.0342s/iter; left time: 371.8955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.21s\n",
      "Steps: 906 | Train Loss: 0.0689264 Vali Loss: 0.0993467 Test Loss: 0.1192917\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0681697\n",
      "\tspeed: 0.0938s/iter; left time: 1010.6405s\n",
      "\titers: 200, epoch: 9 | loss: 0.0609449\n",
      "\tspeed: 0.0341s/iter; left time: 364.2415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0758209\n",
      "\tspeed: 0.0341s/iter; left time: 360.3506s\n",
      "\titers: 400, epoch: 9 | loss: 0.0647182\n",
      "\tspeed: 0.0341s/iter; left time: 357.5211s\n",
      "\titers: 500, epoch: 9 | loss: 0.0599880\n",
      "\tspeed: 0.0341s/iter; left time: 353.8521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0696192\n",
      "\tspeed: 0.0342s/iter; left time: 351.0960s\n",
      "\titers: 700, epoch: 9 | loss: 0.0631149\n",
      "\tspeed: 0.0342s/iter; left time: 347.4902s\n",
      "\titers: 800, epoch: 9 | loss: 0.0657809\n",
      "\tspeed: 0.0342s/iter; left time: 344.1916s\n",
      "\titers: 900, epoch: 9 | loss: 0.0715103\n",
      "\tspeed: 0.0341s/iter; left time: 340.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.17s\n",
      "Steps: 906 | Train Loss: 0.0663550 Vali Loss: 0.0995142 Test Loss: 0.1232103\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0680644\n",
      "\tspeed: 0.0938s/iter; left time: 925.4896s\n",
      "\titers: 200, epoch: 10 | loss: 0.0559841\n",
      "\tspeed: 0.0342s/iter; left time: 333.7656s\n",
      "\titers: 300, epoch: 10 | loss: 0.0640021\n",
      "\tspeed: 0.0342s/iter; left time: 330.1482s\n",
      "\titers: 400, epoch: 10 | loss: 0.0558519\n",
      "\tspeed: 0.0342s/iter; left time: 327.0613s\n",
      "\titers: 500, epoch: 10 | loss: 0.0592567\n",
      "\tspeed: 0.0341s/iter; left time: 323.1783s\n",
      "\titers: 600, epoch: 10 | loss: 0.0703132\n",
      "\tspeed: 0.0342s/iter; left time: 320.2512s\n",
      "\titers: 700, epoch: 10 | loss: 0.0663644\n",
      "\tspeed: 0.0342s/iter; left time: 316.9101s\n",
      "\titers: 800, epoch: 10 | loss: 0.0713700\n",
      "\tspeed: 0.0342s/iter; left time: 313.5720s\n",
      "\titers: 900, epoch: 10 | loss: 0.0612881\n",
      "\tspeed: 0.0342s/iter; left time: 309.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.20s\n",
      "Steps: 906 | Train Loss: 0.0636049 Vali Loss: 0.1003592 Test Loss: 0.1226154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0635687\n",
      "\tspeed: 0.0959s/iter; left time: 858.9658s\n",
      "\titers: 200, epoch: 11 | loss: 0.0579782\n",
      "\tspeed: 0.0341s/iter; left time: 302.2018s\n",
      "\titers: 300, epoch: 11 | loss: 0.0577329\n",
      "\tspeed: 0.0341s/iter; left time: 298.8250s\n",
      "\titers: 400, epoch: 11 | loss: 0.0584427\n",
      "\tspeed: 0.0341s/iter; left time: 295.6880s\n",
      "\titers: 500, epoch: 11 | loss: 0.0652117\n",
      "\tspeed: 0.0341s/iter; left time: 292.0533s\n",
      "\titers: 600, epoch: 11 | loss: 0.0556371\n",
      "\tspeed: 0.0341s/iter; left time: 288.8224s\n",
      "\titers: 700, epoch: 11 | loss: 0.0617914\n",
      "\tspeed: 0.0341s/iter; left time: 285.2151s\n",
      "\titers: 800, epoch: 11 | loss: 0.0650759\n",
      "\tspeed: 0.0341s/iter; left time: 281.8704s\n",
      "\titers: 900, epoch: 11 | loss: 0.0628121\n",
      "\tspeed: 0.0341s/iter; left time: 278.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0608432 Vali Loss: 0.1019767 Test Loss: 0.1295339\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0601404\n",
      "\tspeed: 0.0934s/iter; left time: 752.6225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0608226\n",
      "\tspeed: 0.0342s/iter; left time: 271.9253s\n",
      "\titers: 300, epoch: 12 | loss: 0.0585720\n",
      "\tspeed: 0.0342s/iter; left time: 268.3737s\n",
      "\titers: 400, epoch: 12 | loss: 0.0671864\n",
      "\tspeed: 0.0342s/iter; left time: 264.9392s\n",
      "\titers: 500, epoch: 12 | loss: 0.0586702\n",
      "\tspeed: 0.0342s/iter; left time: 261.5608s\n",
      "\titers: 600, epoch: 12 | loss: 0.0578963\n",
      "\tspeed: 0.0342s/iter; left time: 258.2738s\n",
      "\titers: 700, epoch: 12 | loss: 0.0511237\n",
      "\tspeed: 0.0342s/iter; left time: 254.6666s\n",
      "\titers: 800, epoch: 12 | loss: 0.0598192\n",
      "\tspeed: 0.0342s/iter; left time: 251.4330s\n",
      "\titers: 900, epoch: 12 | loss: 0.0562920\n",
      "\tspeed: 0.0342s/iter; left time: 247.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.19s\n",
      "Steps: 906 | Train Loss: 0.0588874 Vali Loss: 0.1025693 Test Loss: 0.1268519\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_24_GB_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.03127928450703621, rmse:0.17685949802398682, mae:0.11696060001850128, rse:0.6098074316978455\n",
      "Intermediate time for GB and pred_len 24: 00h:16m:51.71s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_96_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2268764\n",
      "\tspeed: 0.0655s/iter; left time: 1178.1274s\n",
      "\titers: 200, epoch: 1 | loss: 0.1978672\n",
      "\tspeed: 0.0413s/iter; left time: 739.0064s\n",
      "\titers: 300, epoch: 1 | loss: 0.1943929\n",
      "\tspeed: 0.0420s/iter; left time: 747.6673s\n",
      "\titers: 400, epoch: 1 | loss: 0.1920299\n",
      "\tspeed: 0.0420s/iter; left time: 743.2215s\n",
      "\titers: 500, epoch: 1 | loss: 0.1802773\n",
      "\tspeed: 0.0421s/iter; left time: 739.5867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717280\n",
      "\tspeed: 0.0421s/iter; left time: 735.5826s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656476\n",
      "\tspeed: 0.0420s/iter; left time: 730.7696s\n",
      "\titers: 800, epoch: 1 | loss: 0.1696963\n",
      "\tspeed: 0.0420s/iter; left time: 726.1528s\n",
      "\titers: 900, epoch: 1 | loss: 0.1643242\n",
      "\tspeed: 0.0421s/iter; left time: 723.0111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 904 | Train Loss: 0.1897053 Vali Loss: 0.1728368 Test Loss: 0.2124270\n",
      "Validation loss decreased (inf --> 0.172837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1457785\n",
      "\tspeed: 0.1164s/iter; left time: 1987.5548s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392656\n",
      "\tspeed: 0.0415s/iter; left time: 705.1681s\n",
      "\titers: 300, epoch: 2 | loss: 0.1343261\n",
      "\tspeed: 0.0415s/iter; left time: 699.7559s\n",
      "\titers: 400, epoch: 2 | loss: 0.1345560\n",
      "\tspeed: 0.0421s/iter; left time: 705.8104s\n",
      "\titers: 500, epoch: 2 | loss: 0.1346623\n",
      "\tspeed: 0.0421s/iter; left time: 702.6320s\n",
      "\titers: 600, epoch: 2 | loss: 0.1332583\n",
      "\tspeed: 0.0419s/iter; left time: 694.3021s\n",
      "\titers: 700, epoch: 2 | loss: 0.1261364\n",
      "\tspeed: 0.0421s/iter; left time: 693.9271s\n",
      "\titers: 800, epoch: 2 | loss: 0.1254614\n",
      "\tspeed: 0.0421s/iter; left time: 689.2999s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305606\n",
      "\tspeed: 0.0421s/iter; left time: 684.9690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 904 | Train Loss: 0.1357239 Vali Loss: 0.1446885 Test Loss: 0.1781681\n",
      "Validation loss decreased (0.172837 --> 0.144689).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1175372\n",
      "\tspeed: 0.1192s/iter; left time: 1927.9999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1188484\n",
      "\tspeed: 0.0421s/iter; left time: 676.6233s\n",
      "\titers: 300, epoch: 3 | loss: 0.1154065\n",
      "\tspeed: 0.0421s/iter; left time: 672.0777s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113715\n",
      "\tspeed: 0.0420s/iter; left time: 667.4296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1078852\n",
      "\tspeed: 0.0421s/iter; left time: 663.4356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1149738\n",
      "\tspeed: 0.0421s/iter; left time: 659.3680s\n",
      "\titers: 700, epoch: 3 | loss: 0.1066848\n",
      "\tspeed: 0.0421s/iter; left time: 655.3036s\n",
      "\titers: 800, epoch: 3 | loss: 0.1042039\n",
      "\tspeed: 0.0420s/iter; left time: 649.6626s\n",
      "\titers: 900, epoch: 3 | loss: 0.1103720\n",
      "\tspeed: 0.0420s/iter; left time: 645.8128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.1113842 Vali Loss: 0.1260925 Test Loss: 0.1568912\n",
      "Validation loss decreased (0.144689 --> 0.126093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1156684\n",
      "\tspeed: 0.1176s/iter; left time: 1795.7961s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072669\n",
      "\tspeed: 0.0415s/iter; left time: 629.9717s\n",
      "\titers: 300, epoch: 4 | loss: 0.1097675\n",
      "\tspeed: 0.0415s/iter; left time: 626.0487s\n",
      "\titers: 400, epoch: 4 | loss: 0.0987495\n",
      "\tspeed: 0.0416s/iter; left time: 622.0291s\n",
      "\titers: 500, epoch: 4 | loss: 0.0966180\n",
      "\tspeed: 0.0416s/iter; left time: 618.0380s\n",
      "\titers: 600, epoch: 4 | loss: 0.1013041\n",
      "\tspeed: 0.0416s/iter; left time: 613.6836s\n",
      "\titers: 700, epoch: 4 | loss: 0.0967172\n",
      "\tspeed: 0.0416s/iter; left time: 609.5065s\n",
      "\titers: 800, epoch: 4 | loss: 0.1014885\n",
      "\tspeed: 0.0415s/iter; left time: 605.2582s\n",
      "\titers: 900, epoch: 4 | loss: 0.1030009\n",
      "\tspeed: 0.0415s/iter; left time: 601.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1018708 Vali Loss: 0.1277115 Test Loss: 0.1587207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0942518\n",
      "\tspeed: 0.1139s/iter; left time: 1636.5789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0950471\n",
      "\tspeed: 0.0415s/iter; left time: 592.5768s\n",
      "\titers: 300, epoch: 5 | loss: 0.0928046\n",
      "\tspeed: 0.0415s/iter; left time: 588.2587s\n",
      "\titers: 400, epoch: 5 | loss: 0.1033714\n",
      "\tspeed: 0.0415s/iter; left time: 583.5658s\n",
      "\titers: 500, epoch: 5 | loss: 0.0941585\n",
      "\tspeed: 0.0415s/iter; left time: 579.3170s\n",
      "\titers: 600, epoch: 5 | loss: 0.0995664\n",
      "\tspeed: 0.0415s/iter; left time: 575.1951s\n",
      "\titers: 700, epoch: 5 | loss: 0.1031185\n",
      "\tspeed: 0.0415s/iter; left time: 571.0616s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025636\n",
      "\tspeed: 0.0415s/iter; left time: 567.0282s\n",
      "\titers: 900, epoch: 5 | loss: 0.1002272\n",
      "\tspeed: 0.0415s/iter; left time: 562.8079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0953789 Vali Loss: 0.1268768 Test Loss: 0.1636338\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0910520\n",
      "\tspeed: 0.1140s/iter; left time: 1534.1408s\n",
      "\titers: 200, epoch: 6 | loss: 0.0860340\n",
      "\tspeed: 0.0415s/iter; left time: 554.6341s\n",
      "\titers: 300, epoch: 6 | loss: 0.0880820\n",
      "\tspeed: 0.0415s/iter; left time: 550.1306s\n",
      "\titers: 400, epoch: 6 | loss: 0.0941288\n",
      "\tspeed: 0.0415s/iter; left time: 546.4273s\n",
      "\titers: 500, epoch: 6 | loss: 0.0841647\n",
      "\tspeed: 0.0415s/iter; left time: 542.0510s\n",
      "\titers: 600, epoch: 6 | loss: 0.0876083\n",
      "\tspeed: 0.0415s/iter; left time: 537.7534s\n",
      "\titers: 700, epoch: 6 | loss: 0.0830211\n",
      "\tspeed: 0.0415s/iter; left time: 534.1377s\n",
      "\titers: 800, epoch: 6 | loss: 0.0914322\n",
      "\tspeed: 0.0415s/iter; left time: 529.4035s\n",
      "\titers: 900, epoch: 6 | loss: 0.0899133\n",
      "\tspeed: 0.0415s/iter; left time: 525.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0895236 Vali Loss: 0.1278808 Test Loss: 0.1652189\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0836434\n",
      "\tspeed: 0.1132s/iter; left time: 1421.1546s\n",
      "\titers: 200, epoch: 7 | loss: 0.0844925\n",
      "\tspeed: 0.0415s/iter; left time: 517.5073s\n",
      "\titers: 300, epoch: 7 | loss: 0.0794558\n",
      "\tspeed: 0.0415s/iter; left time: 513.3383s\n",
      "\titers: 400, epoch: 7 | loss: 0.0855794\n",
      "\tspeed: 0.0415s/iter; left time: 508.9053s\n",
      "\titers: 500, epoch: 7 | loss: 0.0898345\n",
      "\tspeed: 0.0415s/iter; left time: 504.9240s\n",
      "\titers: 600, epoch: 7 | loss: 0.0911049\n",
      "\tspeed: 0.0415s/iter; left time: 500.8588s\n",
      "\titers: 700, epoch: 7 | loss: 0.0897632\n",
      "\tspeed: 0.0415s/iter; left time: 496.6991s\n",
      "\titers: 800, epoch: 7 | loss: 0.0752865\n",
      "\tspeed: 0.0415s/iter; left time: 492.4032s\n",
      "\titers: 900, epoch: 7 | loss: 0.0809941\n",
      "\tspeed: 0.0415s/iter; left time: 488.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0841153 Vali Loss: 0.1298804 Test Loss: 0.1732888\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0823286\n",
      "\tspeed: 0.1140s/iter; left time: 1328.1804s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805886\n",
      "\tspeed: 0.0416s/iter; left time: 480.0498s\n",
      "\titers: 300, epoch: 8 | loss: 0.0787768\n",
      "\tspeed: 0.0415s/iter; left time: 475.3546s\n",
      "\titers: 400, epoch: 8 | loss: 0.0750168\n",
      "\tspeed: 0.0415s/iter; left time: 471.2326s\n",
      "\titers: 500, epoch: 8 | loss: 0.0819786\n",
      "\tspeed: 0.0415s/iter; left time: 466.9707s\n",
      "\titers: 600, epoch: 8 | loss: 0.0769879\n",
      "\tspeed: 0.0416s/iter; left time: 463.5953s\n",
      "\titers: 700, epoch: 8 | loss: 0.0801579\n",
      "\tspeed: 0.0415s/iter; left time: 458.9882s\n",
      "\titers: 800, epoch: 8 | loss: 0.0806662\n",
      "\tspeed: 0.0415s/iter; left time: 454.6568s\n",
      "\titers: 900, epoch: 8 | loss: 0.0836962\n",
      "\tspeed: 0.0415s/iter; left time: 450.6388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0791007 Vali Loss: 0.1308822 Test Loss: 0.1750989\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.049356184899806976, rmse:0.22216251492500305, mae:0.15691299736499786, rse:0.7682689428329468\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2278353\n",
      "\tspeed: 0.0436s/iter; left time: 783.7662s\n",
      "\titers: 200, epoch: 1 | loss: 0.2020534\n",
      "\tspeed: 0.0415s/iter; left time: 742.9428s\n",
      "\titers: 300, epoch: 1 | loss: 0.1878239\n",
      "\tspeed: 0.0416s/iter; left time: 739.1002s\n",
      "\titers: 400, epoch: 1 | loss: 0.1944844\n",
      "\tspeed: 0.0416s/iter; left time: 734.9105s\n",
      "\titers: 500, epoch: 1 | loss: 0.1941353\n",
      "\tspeed: 0.0416s/iter; left time: 731.1568s\n",
      "\titers: 600, epoch: 1 | loss: 0.1729999\n",
      "\tspeed: 0.0416s/iter; left time: 726.9874s\n",
      "\titers: 700, epoch: 1 | loss: 0.1679289\n",
      "\tspeed: 0.0416s/iter; left time: 722.5073s\n",
      "\titers: 800, epoch: 1 | loss: 0.1699705\n",
      "\tspeed: 0.0416s/iter; left time: 719.0877s\n",
      "\titers: 900, epoch: 1 | loss: 0.1647512\n",
      "\tspeed: 0.0416s/iter; left time: 715.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.1937501 Vali Loss: 0.1664132 Test Loss: 0.2047869\n",
      "Validation loss decreased (inf --> 0.166413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1548872\n",
      "\tspeed: 0.1165s/iter; left time: 1990.3129s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364976\n",
      "\tspeed: 0.0416s/iter; left time: 706.8648s\n",
      "\titers: 300, epoch: 2 | loss: 0.1455883\n",
      "\tspeed: 0.0417s/iter; left time: 703.0128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1231301\n",
      "\tspeed: 0.0416s/iter; left time: 697.4636s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362744\n",
      "\tspeed: 0.0416s/iter; left time: 693.1189s\n",
      "\titers: 600, epoch: 2 | loss: 0.1244080\n",
      "\tspeed: 0.0416s/iter; left time: 689.3567s\n",
      "\titers: 700, epoch: 2 | loss: 0.1334690\n",
      "\tspeed: 0.0416s/iter; left time: 685.3067s\n",
      "\titers: 800, epoch: 2 | loss: 0.1270750\n",
      "\tspeed: 0.0416s/iter; left time: 680.8819s\n",
      "\titers: 900, epoch: 2 | loss: 0.1180649\n",
      "\tspeed: 0.0416s/iter; left time: 677.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1352863 Vali Loss: 0.1410898 Test Loss: 0.1708414\n",
      "Validation loss decreased (0.166413 --> 0.141090).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147558\n",
      "\tspeed: 0.1170s/iter; left time: 1891.8432s\n",
      "\titers: 200, epoch: 3 | loss: 0.1144703\n",
      "\tspeed: 0.0417s/iter; left time: 669.6380s\n",
      "\titers: 300, epoch: 3 | loss: 0.1129461\n",
      "\tspeed: 0.0416s/iter; left time: 665.2663s\n",
      "\titers: 400, epoch: 3 | loss: 0.1159053\n",
      "\tspeed: 0.0417s/iter; left time: 661.1881s\n",
      "\titers: 500, epoch: 3 | loss: 0.1037145\n",
      "\tspeed: 0.0416s/iter; left time: 656.4345s\n",
      "\titers: 600, epoch: 3 | loss: 0.1191663\n",
      "\tspeed: 0.0416s/iter; left time: 652.6964s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158241\n",
      "\tspeed: 0.0416s/iter; left time: 648.3619s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989802\n",
      "\tspeed: 0.0417s/iter; left time: 644.6881s\n",
      "\titers: 900, epoch: 3 | loss: 0.1078756\n",
      "\tspeed: 0.0416s/iter; left time: 639.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 904 | Train Loss: 0.1118837 Vali Loss: 0.1274420 Test Loss: 0.1581856\n",
      "Validation loss decreased (0.141090 --> 0.127442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1074443\n",
      "\tspeed: 0.1171s/iter; left time: 1788.3894s\n",
      "\titers: 200, epoch: 4 | loss: 0.1052178\n",
      "\tspeed: 0.0416s/iter; left time: 630.7722s\n",
      "\titers: 300, epoch: 4 | loss: 0.1018802\n",
      "\tspeed: 0.0416s/iter; left time: 626.5580s\n",
      "\titers: 400, epoch: 4 | loss: 0.1033611\n",
      "\tspeed: 0.0416s/iter; left time: 622.8882s\n",
      "\titers: 500, epoch: 4 | loss: 0.1052628\n",
      "\tspeed: 0.0416s/iter; left time: 618.2769s\n",
      "\titers: 600, epoch: 4 | loss: 0.1043086\n",
      "\tspeed: 0.0416s/iter; left time: 614.4294s\n",
      "\titers: 700, epoch: 4 | loss: 0.1040385\n",
      "\tspeed: 0.0416s/iter; left time: 610.2642s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061757\n",
      "\tspeed: 0.0416s/iter; left time: 606.3039s\n",
      "\titers: 900, epoch: 4 | loss: 0.1004524\n",
      "\tspeed: 0.0416s/iter; left time: 601.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.89s\n",
      "Steps: 904 | Train Loss: 0.1023712 Vali Loss: 0.1312658 Test Loss: 0.1651838\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0989314\n",
      "\tspeed: 0.1142s/iter; left time: 1640.3943s\n",
      "\titers: 200, epoch: 5 | loss: 0.1047119\n",
      "\tspeed: 0.0417s/iter; left time: 594.2167s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982214\n",
      "\tspeed: 0.0417s/iter; left time: 590.0576s\n",
      "\titers: 400, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0417s/iter; left time: 585.9079s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974938\n",
      "\tspeed: 0.0416s/iter; left time: 581.2475s\n",
      "\titers: 600, epoch: 5 | loss: 0.0970161\n",
      "\tspeed: 0.0416s/iter; left time: 576.9025s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918606\n",
      "\tspeed: 0.0416s/iter; left time: 572.8600s\n",
      "\titers: 800, epoch: 5 | loss: 0.0898132\n",
      "\tspeed: 0.0417s/iter; left time: 569.1998s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893147\n",
      "\tspeed: 0.0416s/iter; left time: 564.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0967186 Vali Loss: 0.1319823 Test Loss: 0.1671596\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0955259\n",
      "\tspeed: 0.1140s/iter; left time: 1534.6863s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896132\n",
      "\tspeed: 0.0416s/iter; left time: 556.4829s\n",
      "\titers: 300, epoch: 6 | loss: 0.0947796\n",
      "\tspeed: 0.0417s/iter; left time: 552.5246s\n",
      "\titers: 400, epoch: 6 | loss: 0.0908911\n",
      "\tspeed: 0.0416s/iter; left time: 548.1117s\n",
      "\titers: 500, epoch: 6 | loss: 0.0873807\n",
      "\tspeed: 0.0417s/iter; left time: 544.2589s\n",
      "\titers: 600, epoch: 6 | loss: 0.0879827\n",
      "\tspeed: 0.0417s/iter; left time: 540.0754s\n",
      "\titers: 700, epoch: 6 | loss: 0.0896935\n",
      "\tspeed: 0.0417s/iter; left time: 536.0600s\n",
      "\titers: 800, epoch: 6 | loss: 0.0941269\n",
      "\tspeed: 0.0416s/iter; left time: 531.3673s\n",
      "\titers: 900, epoch: 6 | loss: 0.0933578\n",
      "\tspeed: 0.0417s/iter; left time: 527.5178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0908674 Vali Loss: 0.1343007 Test Loss: 0.1725691\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0869733\n",
      "\tspeed: 0.1148s/iter; left time: 1441.3462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0865798\n",
      "\tspeed: 0.0417s/iter; left time: 519.1138s\n",
      "\titers: 300, epoch: 7 | loss: 0.0872979\n",
      "\tspeed: 0.0417s/iter; left time: 515.1221s\n",
      "\titers: 400, epoch: 7 | loss: 0.0808157\n",
      "\tspeed: 0.0417s/iter; left time: 510.9330s\n",
      "\titers: 500, epoch: 7 | loss: 0.0819069\n",
      "\tspeed: 0.0417s/iter; left time: 506.6866s\n",
      "\titers: 600, epoch: 7 | loss: 0.0884176\n",
      "\tspeed: 0.0417s/iter; left time: 502.3795s\n",
      "\titers: 700, epoch: 7 | loss: 0.0929823\n",
      "\tspeed: 0.0417s/iter; left time: 498.2833s\n",
      "\titers: 800, epoch: 7 | loss: 0.0822935\n",
      "\tspeed: 0.0417s/iter; left time: 494.2249s\n",
      "\titers: 900, epoch: 7 | loss: 0.0851985\n",
      "\tspeed: 0.0417s/iter; left time: 490.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 904 | Train Loss: 0.0852665 Vali Loss: 0.1313283 Test Loss: 0.1676679\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0839205\n",
      "\tspeed: 0.1140s/iter; left time: 1328.2757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0803091\n",
      "\tspeed: 0.0416s/iter; left time: 481.1273s\n",
      "\titers: 300, epoch: 8 | loss: 0.0736933\n",
      "\tspeed: 0.0416s/iter; left time: 476.6921s\n",
      "\titers: 400, epoch: 8 | loss: 0.0799875\n",
      "\tspeed: 0.0416s/iter; left time: 472.7424s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814201\n",
      "\tspeed: 0.0416s/iter; left time: 468.2029s\n",
      "\titers: 600, epoch: 8 | loss: 0.0776833\n",
      "\tspeed: 0.0416s/iter; left time: 464.3979s\n",
      "\titers: 700, epoch: 8 | loss: 0.0707026\n",
      "\tspeed: 0.0417s/iter; left time: 460.3869s\n",
      "\titers: 800, epoch: 8 | loss: 0.0765746\n",
      "\tspeed: 0.0417s/iter; left time: 456.2890s\n",
      "\titers: 900, epoch: 8 | loss: 0.0856424\n",
      "\tspeed: 0.0416s/iter; left time: 451.8437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0801459 Vali Loss: 0.1328648 Test Loss: 0.1732243\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_96_GB_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.051835522055625916, rmse:0.22767415642738342, mae:0.158115953207016, rse:0.7873289585113525\n",
      "Intermediate time for GB and pred_len 96: 00h:12m:16.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_96_168_GB', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2144550\n",
      "\tspeed: 0.0736s/iter; left time: 1320.3347s\n",
      "\titers: 200, epoch: 1 | loss: 0.2042320\n",
      "\tspeed: 0.0505s/iter; left time: 901.4268s\n",
      "\titers: 300, epoch: 1 | loss: 0.1855985\n",
      "\tspeed: 0.0507s/iter; left time: 899.5263s\n",
      "\titers: 400, epoch: 1 | loss: 0.1828096\n",
      "\tspeed: 0.0508s/iter; left time: 896.1169s\n",
      "\titers: 500, epoch: 1 | loss: 0.1863522\n",
      "\tspeed: 0.0508s/iter; left time: 890.4390s\n",
      "\titers: 600, epoch: 1 | loss: 0.1806218\n",
      "\tspeed: 0.0507s/iter; left time: 885.0513s\n",
      "\titers: 700, epoch: 1 | loss: 0.1707170\n",
      "\tspeed: 0.0508s/iter; left time: 880.8659s\n",
      "\titers: 800, epoch: 1 | loss: 0.1668490\n",
      "\tspeed: 0.0507s/iter; left time: 874.7028s\n",
      "\titers: 900, epoch: 1 | loss: 0.1642738\n",
      "\tspeed: 0.0508s/iter; left time: 870.4333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.46s\n",
      "Steps: 902 | Train Loss: 0.1902878 Vali Loss: 0.1756261 Test Loss: 0.2136206\n",
      "Validation loss decreased (inf --> 0.175626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1546461\n",
      "\tspeed: 0.1416s/iter; left time: 2412.0118s\n",
      "\titers: 200, epoch: 2 | loss: 0.1453713\n",
      "\tspeed: 0.0507s/iter; left time: 858.6454s\n",
      "\titers: 300, epoch: 2 | loss: 0.1408072\n",
      "\tspeed: 0.0507s/iter; left time: 853.8900s\n",
      "\titers: 400, epoch: 2 | loss: 0.1328956\n",
      "\tspeed: 0.0507s/iter; left time: 848.6835s\n",
      "\titers: 500, epoch: 2 | loss: 0.1344081\n",
      "\tspeed: 0.0507s/iter; left time: 844.3704s\n",
      "\titers: 600, epoch: 2 | loss: 0.1351472\n",
      "\tspeed: 0.0507s/iter; left time: 838.7043s\n",
      "\titers: 700, epoch: 2 | loss: 0.1377063\n",
      "\tspeed: 0.0507s/iter; left time: 834.0462s\n",
      "\titers: 800, epoch: 2 | loss: 0.1352134\n",
      "\tspeed: 0.0508s/iter; left time: 829.4362s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376040\n",
      "\tspeed: 0.0507s/iter; left time: 823.7256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1412551 Vali Loss: 0.1557616 Test Loss: 0.1941232\n",
      "Validation loss decreased (0.175626 --> 0.155762).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1322913\n",
      "\tspeed: 0.1434s/iter; left time: 2314.1137s\n",
      "\titers: 200, epoch: 3 | loss: 0.1251840\n",
      "\tspeed: 0.0507s/iter; left time: 812.6631s\n",
      "\titers: 300, epoch: 3 | loss: 0.1327689\n",
      "\tspeed: 0.0507s/iter; left time: 807.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.1270881\n",
      "\tspeed: 0.0507s/iter; left time: 802.8697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1229750\n",
      "\tspeed: 0.0506s/iter; left time: 797.0577s\n",
      "\titers: 600, epoch: 3 | loss: 0.1328987\n",
      "\tspeed: 0.0507s/iter; left time: 793.3704s\n",
      "\titers: 700, epoch: 3 | loss: 0.1204278\n",
      "\tspeed: 0.0506s/iter; left time: 785.9965s\n",
      "\titers: 800, epoch: 3 | loss: 0.1188312\n",
      "\tspeed: 0.0508s/iter; left time: 784.4461s\n",
      "\titers: 900, epoch: 3 | loss: 0.1182145\n",
      "\tspeed: 0.0508s/iter; left time: 779.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.1258696 Vali Loss: 0.1498645 Test Loss: 0.1913567\n",
      "Validation loss decreased (0.155762 --> 0.149865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1236095\n",
      "\tspeed: 0.1429s/iter; left time: 2177.7977s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127460\n",
      "\tspeed: 0.0517s/iter; left time: 783.0264s\n",
      "\titers: 300, epoch: 4 | loss: 0.1189013\n",
      "\tspeed: 0.0511s/iter; left time: 768.8154s\n",
      "\titers: 400, epoch: 4 | loss: 0.1107328\n",
      "\tspeed: 0.0506s/iter; left time: 756.4537s\n",
      "\titers: 500, epoch: 4 | loss: 0.1057849\n",
      "\tspeed: 0.0507s/iter; left time: 751.7938s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077283\n",
      "\tspeed: 0.0506s/iter; left time: 745.7883s\n",
      "\titers: 700, epoch: 4 | loss: 0.1090573\n",
      "\tspeed: 0.0507s/iter; left time: 742.5099s\n",
      "\titers: 800, epoch: 4 | loss: 0.1042960\n",
      "\tspeed: 0.0508s/iter; left time: 737.7649s\n",
      "\titers: 900, epoch: 4 | loss: 0.0960267\n",
      "\tspeed: 0.0508s/iter; left time: 733.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1102404 Vali Loss: 0.1309775 Test Loss: 0.1653814\n",
      "Validation loss decreased (0.149865 --> 0.130978).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0952837\n",
      "\tspeed: 0.1428s/iter; left time: 2046.0842s\n",
      "\titers: 200, epoch: 5 | loss: 0.1016937\n",
      "\tspeed: 0.0508s/iter; left time: 722.8595s\n",
      "\titers: 300, epoch: 5 | loss: 0.0965871\n",
      "\tspeed: 0.0509s/iter; left time: 718.7543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0990509\n",
      "\tspeed: 0.0507s/iter; left time: 711.1350s\n",
      "\titers: 500, epoch: 5 | loss: 0.0965394\n",
      "\tspeed: 0.0507s/iter; left time: 706.1450s\n",
      "\titers: 600, epoch: 5 | loss: 0.0947464\n",
      "\tspeed: 0.0508s/iter; left time: 702.9266s\n",
      "\titers: 700, epoch: 5 | loss: 0.0906473\n",
      "\tspeed: 0.0507s/iter; left time: 696.2827s\n",
      "\titers: 800, epoch: 5 | loss: 0.1027681\n",
      "\tspeed: 0.0507s/iter; left time: 691.5529s\n",
      "\titers: 900, epoch: 5 | loss: 0.0998390\n",
      "\tspeed: 0.0507s/iter; left time: 686.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0975682 Vali Loss: 0.1345402 Test Loss: 0.1749502\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0953098\n",
      "\tspeed: 0.1394s/iter; left time: 1871.6152s\n",
      "\titers: 200, epoch: 6 | loss: 0.0979535\n",
      "\tspeed: 0.0509s/iter; left time: 678.3546s\n",
      "\titers: 300, epoch: 6 | loss: 0.0898484\n",
      "\tspeed: 0.0508s/iter; left time: 671.7667s\n",
      "\titers: 400, epoch: 6 | loss: 0.0891806\n",
      "\tspeed: 0.0508s/iter; left time: 666.6549s\n",
      "\titers: 500, epoch: 6 | loss: 0.1021477\n",
      "\tspeed: 0.0507s/iter; left time: 660.9795s\n",
      "\titers: 600, epoch: 6 | loss: 0.0873509\n",
      "\tspeed: 0.0507s/iter; left time: 656.0776s\n",
      "\titers: 700, epoch: 6 | loss: 0.0811544\n",
      "\tspeed: 0.0508s/iter; left time: 651.4109s\n",
      "\titers: 800, epoch: 6 | loss: 0.0884078\n",
      "\tspeed: 0.0510s/iter; left time: 649.1018s\n",
      "\titers: 900, epoch: 6 | loss: 0.0890452\n",
      "\tspeed: 0.0508s/iter; left time: 641.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0908929 Vali Loss: 0.1383472 Test Loss: 0.1792563\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0930536\n",
      "\tspeed: 0.1397s/iter; left time: 1750.8723s\n",
      "\titers: 200, epoch: 7 | loss: 0.0848575\n",
      "\tspeed: 0.0508s/iter; left time: 630.9018s\n",
      "\titers: 300, epoch: 7 | loss: 0.0895651\n",
      "\tspeed: 0.0507s/iter; left time: 625.6852s\n",
      "\titers: 400, epoch: 7 | loss: 0.0846024\n",
      "\tspeed: 0.0508s/iter; left time: 620.9344s\n",
      "\titers: 500, epoch: 7 | loss: 0.0824052\n",
      "\tspeed: 0.0508s/iter; left time: 616.3262s\n",
      "\titers: 600, epoch: 7 | loss: 0.0801848\n",
      "\tspeed: 0.0507s/iter; left time: 610.1180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0878324\n",
      "\tspeed: 0.0507s/iter; left time: 605.1832s\n",
      "\titers: 800, epoch: 7 | loss: 0.0794692\n",
      "\tspeed: 0.0508s/iter; left time: 600.5393s\n",
      "\titers: 900, epoch: 7 | loss: 0.0923864\n",
      "\tspeed: 0.0508s/iter; left time: 595.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 902 | Train Loss: 0.0853172 Vali Loss: 0.1356244 Test Loss: 0.1794397\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0795482\n",
      "\tspeed: 0.1391s/iter; left time: 1616.8590s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793333\n",
      "\tspeed: 0.0509s/iter; left time: 586.2408s\n",
      "\titers: 300, epoch: 8 | loss: 0.0832426\n",
      "\tspeed: 0.0508s/iter; left time: 579.9564s\n",
      "\titers: 400, epoch: 8 | loss: 0.0788528\n",
      "\tspeed: 0.0507s/iter; left time: 574.7891s\n",
      "\titers: 500, epoch: 8 | loss: 0.0814730\n",
      "\tspeed: 0.0508s/iter; left time: 569.9731s\n",
      "\titers: 600, epoch: 8 | loss: 0.0817954\n",
      "\tspeed: 0.0507s/iter; left time: 564.5199s\n",
      "\titers: 700, epoch: 8 | loss: 0.0758450\n",
      "\tspeed: 0.0507s/iter; left time: 559.4593s\n",
      "\titers: 800, epoch: 8 | loss: 0.0744339\n",
      "\tspeed: 0.0507s/iter; left time: 553.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0780436\n",
      "\tspeed: 0.0507s/iter; left time: 549.0381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0805622 Vali Loss: 0.1370406 Test Loss: 0.1795973\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742666\n",
      "\tspeed: 0.1390s/iter; left time: 1490.7365s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785919\n",
      "\tspeed: 0.0507s/iter; left time: 539.1281s\n",
      "\titers: 300, epoch: 9 | loss: 0.0799072\n",
      "\tspeed: 0.0508s/iter; left time: 534.4281s\n",
      "\titers: 400, epoch: 9 | loss: 0.0714043\n",
      "\tspeed: 0.0508s/iter; left time: 529.4868s\n",
      "\titers: 500, epoch: 9 | loss: 0.0772576\n",
      "\tspeed: 0.0507s/iter; left time: 523.5973s\n",
      "\titers: 600, epoch: 9 | loss: 0.0725148\n",
      "\tspeed: 0.0507s/iter; left time: 518.2077s\n",
      "\titers: 700, epoch: 9 | loss: 0.0799865\n",
      "\tspeed: 0.0506s/iter; left time: 512.3497s\n",
      "\titers: 800, epoch: 9 | loss: 0.0802605\n",
      "\tspeed: 0.0507s/iter; left time: 508.6986s\n",
      "\titers: 900, epoch: 9 | loss: 0.0742895\n",
      "\tspeed: 0.0506s/iter; left time: 502.6092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 902 | Train Loss: 0.0766087 Vali Loss: 0.1366436 Test Loss: 0.1790668\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05534675344824791, rmse:0.23525890707969666, mae:0.1653159260749817, rse:0.815612256526947\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2155263\n",
      "\tspeed: 0.0535s/iter; left time: 959.0820s\n",
      "\titers: 200, epoch: 1 | loss: 0.1987825\n",
      "\tspeed: 0.0508s/iter; left time: 906.4877s\n",
      "\titers: 300, epoch: 1 | loss: 0.1921764\n",
      "\tspeed: 0.0509s/iter; left time: 902.4375s\n",
      "\titers: 400, epoch: 1 | loss: 0.1906046\n",
      "\tspeed: 0.0508s/iter; left time: 895.3965s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840005\n",
      "\tspeed: 0.0507s/iter; left time: 888.9264s\n",
      "\titers: 600, epoch: 1 | loss: 0.1789132\n",
      "\tspeed: 0.0506s/iter; left time: 883.3171s\n",
      "\titers: 700, epoch: 1 | loss: 0.1818265\n",
      "\tspeed: 0.0507s/iter; left time: 878.3863s\n",
      "\titers: 800, epoch: 1 | loss: 0.1734744\n",
      "\tspeed: 0.0507s/iter; left time: 873.2800s\n",
      "\titers: 900, epoch: 1 | loss: 0.1659183\n",
      "\tspeed: 0.0507s/iter; left time: 868.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1887618 Vali Loss: 0.1742335 Test Loss: 0.2129559\n",
      "Validation loss decreased (inf --> 0.174234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1481940\n",
      "\tspeed: 0.1416s/iter; left time: 2412.2036s\n",
      "\titers: 200, epoch: 2 | loss: 0.1454901\n",
      "\tspeed: 0.0507s/iter; left time: 859.2595s\n",
      "\titers: 300, epoch: 2 | loss: 0.1338724\n",
      "\tspeed: 0.0507s/iter; left time: 853.2802s\n",
      "\titers: 400, epoch: 2 | loss: 0.1323974\n",
      "\tspeed: 0.0507s/iter; left time: 849.0272s\n",
      "\titers: 500, epoch: 2 | loss: 0.1412918\n",
      "\tspeed: 0.0506s/iter; left time: 842.7404s\n",
      "\titers: 600, epoch: 2 | loss: 0.1327669\n",
      "\tspeed: 0.0507s/iter; left time: 837.7773s\n",
      "\titers: 700, epoch: 2 | loss: 0.1384447\n",
      "\tspeed: 0.0506s/iter; left time: 832.4445s\n",
      "\titers: 800, epoch: 2 | loss: 0.1426750\n",
      "\tspeed: 0.0507s/iter; left time: 828.2160s\n",
      "\titers: 900, epoch: 2 | loss: 0.1431397\n",
      "\tspeed: 0.0506s/iter; left time: 821.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 902 | Train Loss: 0.1400927 Vali Loss: 0.1554372 Test Loss: 0.1979454\n",
      "Validation loss decreased (0.174234 --> 0.155437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1327099\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4999s\n",
      "\titers: 200, epoch: 3 | loss: 0.1331211\n",
      "\tspeed: 0.0508s/iter; left time: 814.9257s\n",
      "\titers: 300, epoch: 3 | loss: 0.1262807\n",
      "\tspeed: 0.0507s/iter; left time: 808.6486s\n",
      "\titers: 400, epoch: 3 | loss: 0.1330259\n",
      "\tspeed: 0.0507s/iter; left time: 803.5242s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233167\n",
      "\tspeed: 0.0508s/iter; left time: 798.7087s\n",
      "\titers: 600, epoch: 3 | loss: 0.1312564\n",
      "\tspeed: 0.0508s/iter; left time: 794.0562s\n",
      "\titers: 700, epoch: 3 | loss: 0.1340061\n",
      "\tspeed: 0.0508s/iter; left time: 788.8538s\n",
      "\titers: 800, epoch: 3 | loss: 0.1299911\n",
      "\tspeed: 0.0508s/iter; left time: 783.7229s\n",
      "\titers: 900, epoch: 3 | loss: 0.1227380\n",
      "\tspeed: 0.0508s/iter; left time: 778.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 902 | Train Loss: 0.1299872 Vali Loss: 0.1563615 Test Loss: 0.1916026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1271074\n",
      "\tspeed: 0.1384s/iter; left time: 2107.9744s\n",
      "\titers: 200, epoch: 4 | loss: 0.1254569\n",
      "\tspeed: 0.0508s/iter; left time: 768.8118s\n",
      "\titers: 300, epoch: 4 | loss: 0.1280436\n",
      "\tspeed: 0.0508s/iter; left time: 763.2334s\n",
      "\titers: 400, epoch: 4 | loss: 0.1153991\n",
      "\tspeed: 0.0508s/iter; left time: 758.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.1159150\n",
      "\tspeed: 0.0508s/iter; left time: 753.6041s\n",
      "\titers: 600, epoch: 4 | loss: 0.1088557\n",
      "\tspeed: 0.0508s/iter; left time: 748.8954s\n",
      "\titers: 700, epoch: 4 | loss: 0.1164074\n",
      "\tspeed: 0.0508s/iter; left time: 743.0256s\n",
      "\titers: 800, epoch: 4 | loss: 0.1089536\n",
      "\tspeed: 0.0508s/iter; left time: 738.1433s\n",
      "\titers: 900, epoch: 4 | loss: 0.1018279\n",
      "\tspeed: 0.0508s/iter; left time: 733.1267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 902 | Train Loss: 0.1170789 Vali Loss: 0.1380812 Test Loss: 0.1758089\n",
      "Validation loss decreased (0.155437 --> 0.138081).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0984079\n",
      "\tspeed: 0.1416s/iter; left time: 2029.5328s\n",
      "\titers: 200, epoch: 5 | loss: 0.1044581\n",
      "\tspeed: 0.0508s/iter; left time: 722.8784s\n",
      "\titers: 300, epoch: 5 | loss: 0.1054922\n",
      "\tspeed: 0.0508s/iter; left time: 717.7790s\n",
      "\titers: 400, epoch: 5 | loss: 0.1023428\n",
      "\tspeed: 0.0507s/iter; left time: 711.4377s\n",
      "\titers: 500, epoch: 5 | loss: 0.0925209\n",
      "\tspeed: 0.0507s/iter; left time: 706.7249s\n",
      "\titers: 600, epoch: 5 | loss: 0.1032169\n",
      "\tspeed: 0.0506s/iter; left time: 700.3312s\n",
      "\titers: 700, epoch: 5 | loss: 0.0928220\n",
      "\tspeed: 0.0507s/iter; left time: 696.7048s\n",
      "\titers: 800, epoch: 5 | loss: 0.0937007\n",
      "\tspeed: 0.0507s/iter; left time: 691.8461s\n",
      "\titers: 900, epoch: 5 | loss: 0.0924801\n",
      "\tspeed: 0.0508s/iter; left time: 687.8166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0993847 Vali Loss: 0.1335634 Test Loss: 0.1753410\n",
      "Validation loss decreased (0.138081 --> 0.133563).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0887428\n",
      "\tspeed: 0.1454s/iter; left time: 1952.7363s\n",
      "\titers: 200, epoch: 6 | loss: 0.0971114\n",
      "\tspeed: 0.0520s/iter; left time: 692.8835s\n",
      "\titers: 300, epoch: 6 | loss: 0.0936855\n",
      "\tspeed: 0.0519s/iter; left time: 687.2491s\n",
      "\titers: 400, epoch: 6 | loss: 0.0994137\n",
      "\tspeed: 0.0518s/iter; left time: 680.3947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0940784\n",
      "\tspeed: 0.0512s/iter; left time: 666.7375s\n",
      "\titers: 600, epoch: 6 | loss: 0.0946007\n",
      "\tspeed: 0.0512s/iter; left time: 662.5407s\n",
      "\titers: 700, epoch: 6 | loss: 0.0885791\n",
      "\tspeed: 0.0515s/iter; left time: 660.2895s\n",
      "\titers: 800, epoch: 6 | loss: 0.0929599\n",
      "\tspeed: 0.0519s/iter; left time: 661.1869s\n",
      "\titers: 900, epoch: 6 | loss: 0.0841106\n",
      "\tspeed: 0.0519s/iter; left time: 655.4540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 902 | Train Loss: 0.0917087 Vali Loss: 0.1354960 Test Loss: 0.1834424\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0964288\n",
      "\tspeed: 0.1416s/iter; left time: 1773.7211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0859183\n",
      "\tspeed: 0.0512s/iter; left time: 636.0309s\n",
      "\titers: 300, epoch: 7 | loss: 0.0867437\n",
      "\tspeed: 0.0512s/iter; left time: 630.7155s\n",
      "\titers: 400, epoch: 7 | loss: 0.0866471\n",
      "\tspeed: 0.0512s/iter; left time: 625.6057s\n",
      "\titers: 500, epoch: 7 | loss: 0.0843690\n",
      "\tspeed: 0.0512s/iter; left time: 621.0936s\n",
      "\titers: 600, epoch: 7 | loss: 0.0867086\n",
      "\tspeed: 0.0511s/iter; left time: 615.2524s\n",
      "\titers: 700, epoch: 7 | loss: 0.0789776\n",
      "\tspeed: 0.0512s/iter; left time: 610.4739s\n",
      "\titers: 800, epoch: 7 | loss: 0.0838990\n",
      "\tspeed: 0.0513s/iter; left time: 606.5523s\n",
      "\titers: 900, epoch: 7 | loss: 0.0761397\n",
      "\tspeed: 0.0512s/iter; left time: 600.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.55s\n",
      "Steps: 902 | Train Loss: 0.0856256 Vali Loss: 0.1398314 Test Loss: 0.1858543\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0796307\n",
      "\tspeed: 0.1429s/iter; left time: 1661.3558s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775476\n",
      "\tspeed: 0.0512s/iter; left time: 589.7926s\n",
      "\titers: 300, epoch: 8 | loss: 0.0838974\n",
      "\tspeed: 0.0522s/iter; left time: 596.2414s\n",
      "\titers: 400, epoch: 8 | loss: 0.0857031\n",
      "\tspeed: 0.0522s/iter; left time: 590.7387s\n",
      "\titers: 500, epoch: 8 | loss: 0.0767407\n",
      "\tspeed: 0.0521s/iter; left time: 585.4244s\n",
      "\titers: 600, epoch: 8 | loss: 0.0837792\n",
      "\tspeed: 0.0519s/iter; left time: 577.5250s\n",
      "\titers: 700, epoch: 8 | loss: 0.0778488\n",
      "\tspeed: 0.0513s/iter; left time: 565.8063s\n",
      "\titers: 800, epoch: 8 | loss: 0.0795030\n",
      "\tspeed: 0.0516s/iter; left time: 563.3232s\n",
      "\titers: 900, epoch: 8 | loss: 0.0821027\n",
      "\tspeed: 0.0516s/iter; left time: 558.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.02s\n",
      "Steps: 902 | Train Loss: 0.0805042 Vali Loss: 0.1397548 Test Loss: 0.1822339\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0796983\n",
      "\tspeed: 0.1412s/iter; left time: 1514.5020s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759311\n",
      "\tspeed: 0.0512s/iter; left time: 544.0384s\n",
      "\titers: 300, epoch: 9 | loss: 0.0725377\n",
      "\tspeed: 0.0512s/iter; left time: 538.8407s\n",
      "\titers: 400, epoch: 9 | loss: 0.0776962\n",
      "\tspeed: 0.0512s/iter; left time: 533.6721s\n",
      "\titers: 500, epoch: 9 | loss: 0.0771654\n",
      "\tspeed: 0.0512s/iter; left time: 528.1837s\n",
      "\titers: 600, epoch: 9 | loss: 0.0781724\n",
      "\tspeed: 0.0511s/iter; left time: 522.8375s\n",
      "\titers: 700, epoch: 9 | loss: 0.0747964\n",
      "\tspeed: 0.0512s/iter; left time: 518.1575s\n",
      "\titers: 800, epoch: 9 | loss: 0.0739248\n",
      "\tspeed: 0.0517s/iter; left time: 517.8308s\n",
      "\titers: 900, epoch: 9 | loss: 0.0719263\n",
      "\tspeed: 0.0518s/iter; left time: 514.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.59s\n",
      "Steps: 902 | Train Loss: 0.0762764 Vali Loss: 0.1386382 Test Loss: 0.1837785\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0757313\n",
      "\tspeed: 0.1425s/iter; left time: 1399.7111s\n",
      "\titers: 200, epoch: 10 | loss: 0.0703537\n",
      "\tspeed: 0.0512s/iter; left time: 497.8154s\n",
      "\titers: 300, epoch: 10 | loss: 0.0718045\n",
      "\tspeed: 0.0513s/iter; left time: 493.2416s\n",
      "\titers: 400, epoch: 10 | loss: 0.0759848\n",
      "\tspeed: 0.0512s/iter; left time: 487.4466s\n",
      "\titers: 500, epoch: 10 | loss: 0.0713861\n",
      "\tspeed: 0.0512s/iter; left time: 482.5811s\n",
      "\titers: 600, epoch: 10 | loss: 0.0714854\n",
      "\tspeed: 0.0512s/iter; left time: 477.5115s\n",
      "\titers: 700, epoch: 10 | loss: 0.0705916\n",
      "\tspeed: 0.0512s/iter; left time: 472.0964s\n",
      "\titers: 800, epoch: 10 | loss: 0.0715127\n",
      "\tspeed: 0.0511s/iter; left time: 466.4510s\n",
      "\titers: 900, epoch: 10 | loss: 0.0668258\n",
      "\tspeed: 0.0511s/iter; left time: 461.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:46.54s\n",
      "Steps: 902 | Train Loss: 0.0727178 Vali Loss: 0.1394037 Test Loss: 0.1799662\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_96_168_GB_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06533545255661011, rmse:0.2556079924106598, mae:0.17534701526165009, rse:0.8861599564552307\n",
      "Intermediate time for GB and pred_len 168: 00h:17m:42.97s\n",
      "Intermediate time for GB: 00h:46m:50.95s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_24_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2269582\n",
      "\tspeed: 0.0550s/iter; left time: 992.0042s\n",
      "\titers: 200, epoch: 1 | loss: 0.2340235\n",
      "\tspeed: 0.0340s/iter; left time: 609.4055s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960561\n",
      "\tspeed: 0.0340s/iter; left time: 605.0591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1941898\n",
      "\tspeed: 0.0340s/iter; left time: 602.1440s\n",
      "\titers: 500, epoch: 1 | loss: 0.1761629\n",
      "\tspeed: 0.0340s/iter; left time: 598.6742s\n",
      "\titers: 600, epoch: 1 | loss: 0.1717397\n",
      "\tspeed: 0.0340s/iter; left time: 595.3969s\n",
      "\titers: 700, epoch: 1 | loss: 0.1656946\n",
      "\tspeed: 0.0340s/iter; left time: 592.7206s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516853\n",
      "\tspeed: 0.0341s/iter; left time: 590.1445s\n",
      "\titers: 900, epoch: 1 | loss: 0.1433492\n",
      "\tspeed: 0.0340s/iter; left time: 585.5575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.53s\n",
      "Steps: 906 | Train Loss: 0.1867150 Vali Loss: 0.1149514 Test Loss: 0.1356010\n",
      "Validation loss decreased (inf --> 0.114951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1169975\n",
      "\tspeed: 0.0965s/iter; left time: 1651.4534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0949514\n",
      "\tspeed: 0.0340s/iter; left time: 578.8318s\n",
      "\titers: 300, epoch: 2 | loss: 0.0899529\n",
      "\tspeed: 0.0340s/iter; left time: 575.2054s\n",
      "\titers: 400, epoch: 2 | loss: 0.0936027\n",
      "\tspeed: 0.0340s/iter; left time: 571.3918s\n",
      "\titers: 500, epoch: 2 | loss: 0.0845074\n",
      "\tspeed: 0.0340s/iter; left time: 569.1422s\n",
      "\titers: 600, epoch: 2 | loss: 0.0868874\n",
      "\tspeed: 0.0340s/iter; left time: 564.8397s\n",
      "\titers: 700, epoch: 2 | loss: 0.0824947\n",
      "\tspeed: 0.0341s/iter; left time: 562.8252s\n",
      "\titers: 800, epoch: 2 | loss: 0.0807727\n",
      "\tspeed: 0.0341s/iter; left time: 559.1457s\n",
      "\titers: 900, epoch: 2 | loss: 0.0765388\n",
      "\tspeed: 0.0341s/iter; left time: 556.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0929535 Vali Loss: 0.0793667 Test Loss: 0.1067031\n",
      "Validation loss decreased (0.114951 --> 0.079367).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0782373\n",
      "\tspeed: 0.0961s/iter; left time: 1557.6559s\n",
      "\titers: 200, epoch: 3 | loss: 0.0824538\n",
      "\tspeed: 0.0341s/iter; left time: 548.9010s\n",
      "\titers: 300, epoch: 3 | loss: 0.0756728\n",
      "\tspeed: 0.0341s/iter; left time: 545.3158s\n",
      "\titers: 400, epoch: 3 | loss: 0.0700887\n",
      "\tspeed: 0.0341s/iter; left time: 542.1123s\n",
      "\titers: 500, epoch: 3 | loss: 0.0729940\n",
      "\tspeed: 0.0340s/iter; left time: 538.0838s\n",
      "\titers: 600, epoch: 3 | loss: 0.0716531\n",
      "\tspeed: 0.0340s/iter; left time: 534.1571s\n",
      "\titers: 700, epoch: 3 | loss: 0.0698253\n",
      "\tspeed: 0.0340s/iter; left time: 530.2364s\n",
      "\titers: 800, epoch: 3 | loss: 0.0800202\n",
      "\tspeed: 0.0340s/iter; left time: 527.0752s\n",
      "\titers: 900, epoch: 3 | loss: 0.0685005\n",
      "\tspeed: 0.0340s/iter; left time: 523.5511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0724489 Vali Loss: 0.0711922 Test Loss: 0.0986497\n",
      "Validation loss decreased (0.079367 --> 0.071192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0684435\n",
      "\tspeed: 0.0961s/iter; left time: 1470.2668s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712164\n",
      "\tspeed: 0.0340s/iter; left time: 516.3544s\n",
      "\titers: 300, epoch: 4 | loss: 0.0667114\n",
      "\tspeed: 0.0340s/iter; left time: 513.2033s\n",
      "\titers: 400, epoch: 4 | loss: 0.0691570\n",
      "\tspeed: 0.0340s/iter; left time: 509.5055s\n",
      "\titers: 500, epoch: 4 | loss: 0.0596550\n",
      "\tspeed: 0.0340s/iter; left time: 506.2716s\n",
      "\titers: 600, epoch: 4 | loss: 0.0636415\n",
      "\tspeed: 0.0340s/iter; left time: 503.0966s\n",
      "\titers: 700, epoch: 4 | loss: 0.0748894\n",
      "\tspeed: 0.0340s/iter; left time: 499.3996s\n",
      "\titers: 800, epoch: 4 | loss: 0.0641811\n",
      "\tspeed: 0.0340s/iter; left time: 496.2536s\n",
      "\titers: 900, epoch: 4 | loss: 0.0688866\n",
      "\tspeed: 0.0340s/iter; left time: 493.0114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0664552 Vali Loss: 0.0674176 Test Loss: 0.0996465\n",
      "Validation loss decreased (0.071192 --> 0.067418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659110\n",
      "\tspeed: 0.0963s/iter; left time: 1386.2203s\n",
      "\titers: 200, epoch: 5 | loss: 0.0593955\n",
      "\tspeed: 0.0340s/iter; left time: 486.4223s\n",
      "\titers: 300, epoch: 5 | loss: 0.0572287\n",
      "\tspeed: 0.0341s/iter; left time: 483.8240s\n",
      "\titers: 400, epoch: 5 | loss: 0.0633422\n",
      "\tspeed: 0.0341s/iter; left time: 480.0095s\n",
      "\titers: 500, epoch: 5 | loss: 0.0599107\n",
      "\tspeed: 0.0340s/iter; left time: 476.1896s\n",
      "\titers: 600, epoch: 5 | loss: 0.0616285\n",
      "\tspeed: 0.0340s/iter; left time: 472.5554s\n",
      "\titers: 700, epoch: 5 | loss: 0.0670126\n",
      "\tspeed: 0.0341s/iter; left time: 469.9486s\n",
      "\titers: 800, epoch: 5 | loss: 0.0574715\n",
      "\tspeed: 0.0340s/iter; left time: 465.9960s\n",
      "\titers: 900, epoch: 5 | loss: 0.0618266\n",
      "\tspeed: 0.0341s/iter; left time: 463.4051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0625747 Vali Loss: 0.0616929 Test Loss: 0.0898060\n",
      "Validation loss decreased (0.067418 --> 0.061693).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630031\n",
      "\tspeed: 0.0964s/iter; left time: 1300.5169s\n",
      "\titers: 200, epoch: 6 | loss: 0.0529410\n",
      "\tspeed: 0.0341s/iter; left time: 456.7115s\n",
      "\titers: 300, epoch: 6 | loss: 0.0593784\n",
      "\tspeed: 0.0341s/iter; left time: 452.8869s\n",
      "\titers: 400, epoch: 6 | loss: 0.0604928\n",
      "\tspeed: 0.0341s/iter; left time: 449.6964s\n",
      "\titers: 500, epoch: 6 | loss: 0.0600843\n",
      "\tspeed: 0.0341s/iter; left time: 445.9873s\n",
      "\titers: 600, epoch: 6 | loss: 0.0581049\n",
      "\tspeed: 0.0340s/iter; left time: 442.1294s\n",
      "\titers: 700, epoch: 6 | loss: 0.0540081\n",
      "\tspeed: 0.0340s/iter; left time: 438.9322s\n",
      "\titers: 800, epoch: 6 | loss: 0.0625412\n",
      "\tspeed: 0.0341s/iter; left time: 436.3913s\n",
      "\titers: 900, epoch: 6 | loss: 0.0629828\n",
      "\tspeed: 0.0340s/iter; left time: 432.0029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0593687 Vali Loss: 0.0626056 Test Loss: 0.0942342\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0566213\n",
      "\tspeed: 0.0931s/iter; left time: 1171.3166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0615168\n",
      "\tspeed: 0.0341s/iter; left time: 425.2691s\n",
      "\titers: 300, epoch: 7 | loss: 0.0562484\n",
      "\tspeed: 0.0340s/iter; left time: 421.6475s\n",
      "\titers: 400, epoch: 7 | loss: 0.0569425\n",
      "\tspeed: 0.0340s/iter; left time: 417.6220s\n",
      "\titers: 500, epoch: 7 | loss: 0.0591812\n",
      "\tspeed: 0.0340s/iter; left time: 414.2646s\n",
      "\titers: 600, epoch: 7 | loss: 0.0496640\n",
      "\tspeed: 0.0340s/iter; left time: 410.5183s\n",
      "\titers: 700, epoch: 7 | loss: 0.0547029\n",
      "\tspeed: 0.0341s/iter; left time: 408.5837s\n",
      "\titers: 800, epoch: 7 | loss: 0.0546945\n",
      "\tspeed: 0.0341s/iter; left time: 404.6913s\n",
      "\titers: 900, epoch: 7 | loss: 0.0594512\n",
      "\tspeed: 0.0340s/iter; left time: 400.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0569890 Vali Loss: 0.0593294 Test Loss: 0.0925540\n",
      "Validation loss decreased (0.061693 --> 0.059329).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0525238\n",
      "\tspeed: 0.0961s/iter; left time: 1122.0307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0508008\n",
      "\tspeed: 0.0341s/iter; left time: 395.2702s\n",
      "\titers: 300, epoch: 8 | loss: 0.0481101\n",
      "\tspeed: 0.0341s/iter; left time: 391.3141s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521681\n",
      "\tspeed: 0.0340s/iter; left time: 387.3520s\n",
      "\titers: 500, epoch: 8 | loss: 0.0577647\n",
      "\tspeed: 0.0341s/iter; left time: 384.1358s\n",
      "\titers: 600, epoch: 8 | loss: 0.0543726\n",
      "\tspeed: 0.0341s/iter; left time: 380.7608s\n",
      "\titers: 700, epoch: 8 | loss: 0.0620679\n",
      "\tspeed: 0.0340s/iter; left time: 377.0847s\n",
      "\titers: 800, epoch: 8 | loss: 0.0583911\n",
      "\tspeed: 0.0341s/iter; left time: 374.1237s\n",
      "\titers: 900, epoch: 8 | loss: 0.0578499\n",
      "\tspeed: 0.0341s/iter; left time: 371.3481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0550839 Vali Loss: 0.0594405 Test Loss: 0.0994523\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0505213\n",
      "\tspeed: 0.0943s/iter; left time: 1016.4260s\n",
      "\titers: 200, epoch: 9 | loss: 0.0526453\n",
      "\tspeed: 0.0341s/iter; left time: 363.7700s\n",
      "\titers: 300, epoch: 9 | loss: 0.0561748\n",
      "\tspeed: 0.0340s/iter; left time: 359.7932s\n",
      "\titers: 400, epoch: 9 | loss: 0.0582262\n",
      "\tspeed: 0.0340s/iter; left time: 356.2626s\n",
      "\titers: 500, epoch: 9 | loss: 0.0561789\n",
      "\tspeed: 0.0340s/iter; left time: 353.0543s\n",
      "\titers: 600, epoch: 9 | loss: 0.0563085\n",
      "\tspeed: 0.0340s/iter; left time: 349.3051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0522479\n",
      "\tspeed: 0.0340s/iter; left time: 345.8892s\n",
      "\titers: 800, epoch: 9 | loss: 0.0538578\n",
      "\tspeed: 0.0341s/iter; left time: 343.1276s\n",
      "\titers: 900, epoch: 9 | loss: 0.0456325\n",
      "\tspeed: 0.0341s/iter; left time: 339.8296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0536204 Vali Loss: 0.0587028 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.059329 --> 0.058703).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546516\n",
      "\tspeed: 0.0962s/iter; left time: 949.1378s\n",
      "\titers: 200, epoch: 10 | loss: 0.0576164\n",
      "\tspeed: 0.0341s/iter; left time: 332.6549s\n",
      "\titers: 300, epoch: 10 | loss: 0.0522396\n",
      "\tspeed: 0.0341s/iter; left time: 329.2737s\n",
      "\titers: 400, epoch: 10 | loss: 0.0645304\n",
      "\tspeed: 0.0341s/iter; left time: 326.1944s\n",
      "\titers: 500, epoch: 10 | loss: 0.0542212\n",
      "\tspeed: 0.0341s/iter; left time: 322.6437s\n",
      "\titers: 600, epoch: 10 | loss: 0.0521068\n",
      "\tspeed: 0.0341s/iter; left time: 319.2733s\n",
      "\titers: 700, epoch: 10 | loss: 0.0592318\n",
      "\tspeed: 0.0341s/iter; left time: 315.9926s\n",
      "\titers: 800, epoch: 10 | loss: 0.0469309\n",
      "\tspeed: 0.0341s/iter; left time: 312.1414s\n",
      "\titers: 900, epoch: 10 | loss: 0.0504858\n",
      "\tspeed: 0.0341s/iter; left time: 309.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0521291 Vali Loss: 0.0587004 Test Loss: 0.0948160\n",
      "Validation loss decreased (0.058703 --> 0.058700).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0521655\n",
      "\tspeed: 0.0968s/iter; left time: 867.6632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465787\n",
      "\tspeed: 0.0340s/iter; left time: 301.1818s\n",
      "\titers: 300, epoch: 11 | loss: 0.0509172\n",
      "\tspeed: 0.0340s/iter; left time: 297.5199s\n",
      "\titers: 400, epoch: 11 | loss: 0.0459693\n",
      "\tspeed: 0.0340s/iter; left time: 294.1597s\n",
      "\titers: 500, epoch: 11 | loss: 0.0552192\n",
      "\tspeed: 0.0340s/iter; left time: 290.9819s\n",
      "\titers: 600, epoch: 11 | loss: 0.0559179\n",
      "\tspeed: 0.0340s/iter; left time: 287.9101s\n",
      "\titers: 700, epoch: 11 | loss: 0.0514091\n",
      "\tspeed: 0.0340s/iter; left time: 284.3034s\n",
      "\titers: 800, epoch: 11 | loss: 0.0528125\n",
      "\tspeed: 0.0340s/iter; left time: 281.0131s\n",
      "\titers: 900, epoch: 11 | loss: 0.0530001\n",
      "\tspeed: 0.0341s/iter; left time: 278.1233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0510566 Vali Loss: 0.0590035 Test Loss: 0.0986896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558984\n",
      "\tspeed: 0.0930s/iter; left time: 748.7564s\n",
      "\titers: 200, epoch: 12 | loss: 0.0513471\n",
      "\tspeed: 0.0340s/iter; left time: 270.8496s\n",
      "\titers: 300, epoch: 12 | loss: 0.0471879\n",
      "\tspeed: 0.0340s/iter; left time: 267.1381s\n",
      "\titers: 400, epoch: 12 | loss: 0.0593381\n",
      "\tspeed: 0.0341s/iter; left time: 264.3435s\n",
      "\titers: 500, epoch: 12 | loss: 0.0527025\n",
      "\tspeed: 0.0340s/iter; left time: 260.3050s\n",
      "\titers: 600, epoch: 12 | loss: 0.0466901\n",
      "\tspeed: 0.0340s/iter; left time: 257.1148s\n",
      "\titers: 700, epoch: 12 | loss: 0.0478527\n",
      "\tspeed: 0.0341s/iter; left time: 254.0793s\n",
      "\titers: 800, epoch: 12 | loss: 0.0519875\n",
      "\tspeed: 0.0340s/iter; left time: 250.2279s\n",
      "\titers: 900, epoch: 12 | loss: 0.0480679\n",
      "\tspeed: 0.0341s/iter; left time: 247.1559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0497550 Vali Loss: 0.0586147 Test Loss: 0.0984036\n",
      "Validation loss decreased (0.058700 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0475071\n",
      "\tspeed: 0.0975s/iter; left time: 697.0758s\n",
      "\titers: 200, epoch: 13 | loss: 0.0483188\n",
      "\tspeed: 0.0340s/iter; left time: 239.9376s\n",
      "\titers: 300, epoch: 13 | loss: 0.0545818\n",
      "\tspeed: 0.0340s/iter; left time: 236.5292s\n",
      "\titers: 400, epoch: 13 | loss: 0.0468574\n",
      "\tspeed: 0.0341s/iter; left time: 233.2553s\n",
      "\titers: 500, epoch: 13 | loss: 0.0488363\n",
      "\tspeed: 0.0341s/iter; left time: 230.0322s\n",
      "\titers: 600, epoch: 13 | loss: 0.0478834\n",
      "\tspeed: 0.0341s/iter; left time: 226.4960s\n",
      "\titers: 700, epoch: 13 | loss: 0.0478704\n",
      "\tspeed: 0.0341s/iter; left time: 223.1881s\n",
      "\titers: 800, epoch: 13 | loss: 0.0492090\n",
      "\tspeed: 0.0341s/iter; left time: 219.5957s\n",
      "\titers: 900, epoch: 13 | loss: 0.0455686\n",
      "\tspeed: 0.0341s/iter; left time: 216.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0488156 Vali Loss: 0.0577360 Test Loss: 0.0999878\n",
      "Validation loss decreased (0.058615 --> 0.057736).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0482094\n",
      "\tspeed: 0.0963s/iter; left time: 600.9922s\n",
      "\titers: 200, epoch: 14 | loss: 0.0487748\n",
      "\tspeed: 0.0340s/iter; left time: 209.1014s\n",
      "\titers: 300, epoch: 14 | loss: 0.0462699\n",
      "\tspeed: 0.0340s/iter; left time: 205.6403s\n",
      "\titers: 400, epoch: 14 | loss: 0.0482816\n",
      "\tspeed: 0.0340s/iter; left time: 202.0444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0434202\n",
      "\tspeed: 0.0340s/iter; left time: 198.6776s\n",
      "\titers: 600, epoch: 14 | loss: 0.0466136\n",
      "\tspeed: 0.0340s/iter; left time: 195.1986s\n",
      "\titers: 700, epoch: 14 | loss: 0.0498906\n",
      "\tspeed: 0.0340s/iter; left time: 191.8812s\n",
      "\titers: 800, epoch: 14 | loss: 0.0559277\n",
      "\tspeed: 0.0340s/iter; left time: 188.5343s\n",
      "\titers: 900, epoch: 14 | loss: 0.0500410\n",
      "\tspeed: 0.0340s/iter; left time: 185.3321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0481153 Vali Loss: 0.0569008 Test Loss: 0.0974887\n",
      "Validation loss decreased (0.057736 --> 0.056901).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0479455\n",
      "\tspeed: 0.0969s/iter; left time: 516.9925s\n",
      "\titers: 200, epoch: 15 | loss: 0.0423490\n",
      "\tspeed: 0.0340s/iter; left time: 178.2323s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470223\n",
      "\tspeed: 0.0340s/iter; left time: 174.7335s\n",
      "\titers: 400, epoch: 15 | loss: 0.0487020\n",
      "\tspeed: 0.0339s/iter; left time: 170.9948s\n",
      "\titers: 500, epoch: 15 | loss: 0.0482308\n",
      "\tspeed: 0.0341s/iter; left time: 168.3506s\n",
      "\titers: 600, epoch: 15 | loss: 0.0490022\n",
      "\tspeed: 0.0340s/iter; left time: 164.6517s\n",
      "\titers: 700, epoch: 15 | loss: 0.0457250\n",
      "\tspeed: 0.0341s/iter; left time: 161.4815s\n",
      "\titers: 800, epoch: 15 | loss: 0.0414258\n",
      "\tspeed: 0.0341s/iter; left time: 158.1757s\n",
      "\titers: 900, epoch: 15 | loss: 0.0480889\n",
      "\tspeed: 0.0341s/iter; left time: 154.7693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0471749 Vali Loss: 0.0581755 Test Loss: 0.1011218\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0504668\n",
      "\tspeed: 0.0941s/iter; left time: 417.0276s\n",
      "\titers: 200, epoch: 16 | loss: 0.0505805\n",
      "\tspeed: 0.0341s/iter; left time: 147.6880s\n",
      "\titers: 300, epoch: 16 | loss: 0.0436730\n",
      "\tspeed: 0.0341s/iter; left time: 144.1782s\n",
      "\titers: 400, epoch: 16 | loss: 0.0441560\n",
      "\tspeed: 0.0341s/iter; left time: 140.7082s\n",
      "\titers: 500, epoch: 16 | loss: 0.0476777\n",
      "\tspeed: 0.0340s/iter; left time: 137.1863s\n",
      "\titers: 600, epoch: 16 | loss: 0.0439132\n",
      "\tspeed: 0.0340s/iter; left time: 133.7169s\n",
      "\titers: 700, epoch: 16 | loss: 0.0488481\n",
      "\tspeed: 0.0341s/iter; left time: 130.6403s\n",
      "\titers: 800, epoch: 16 | loss: 0.0411422\n",
      "\tspeed: 0.0341s/iter; left time: 127.0459s\n",
      "\titers: 900, epoch: 16 | loss: 0.0461350\n",
      "\tspeed: 0.0341s/iter; left time: 123.7014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0463692 Vali Loss: 0.0586193 Test Loss: 0.1046662\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0439602\n",
      "\tspeed: 0.0929s/iter; left time: 327.3871s\n",
      "\titers: 200, epoch: 17 | loss: 0.0481706\n",
      "\tspeed: 0.0340s/iter; left time: 116.5163s\n",
      "\titers: 300, epoch: 17 | loss: 0.0420253\n",
      "\tspeed: 0.0340s/iter; left time: 112.9836s\n",
      "\titers: 400, epoch: 17 | loss: 0.0496195\n",
      "\tspeed: 0.0340s/iter; left time: 109.5946s\n",
      "\titers: 500, epoch: 17 | loss: 0.0452397\n",
      "\tspeed: 0.0340s/iter; left time: 106.2796s\n",
      "\titers: 600, epoch: 17 | loss: 0.0468022\n",
      "\tspeed: 0.0340s/iter; left time: 102.8425s\n",
      "\titers: 700, epoch: 17 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 99.4661s\n",
      "\titers: 800, epoch: 17 | loss: 0.0520706\n",
      "\tspeed: 0.0341s/iter; left time: 96.2139s\n",
      "\titers: 900, epoch: 17 | loss: 0.0444759\n",
      "\tspeed: 0.0340s/iter; left time: 92.7338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0455342 Vali Loss: 0.0581641 Test Loss: 0.1017385\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0446145\n",
      "\tspeed: 0.0929s/iter; left time: 243.4311s\n",
      "\titers: 200, epoch: 18 | loss: 0.0440156\n",
      "\tspeed: 0.0340s/iter; left time: 85.6971s\n",
      "\titers: 300, epoch: 18 | loss: 0.0425779\n",
      "\tspeed: 0.0340s/iter; left time: 82.2397s\n",
      "\titers: 400, epoch: 18 | loss: 0.0449517\n",
      "\tspeed: 0.0340s/iter; left time: 78.9489s\n",
      "\titers: 500, epoch: 18 | loss: 0.0484834\n",
      "\tspeed: 0.0340s/iter; left time: 75.5547s\n",
      "\titers: 600, epoch: 18 | loss: 0.0420635\n",
      "\tspeed: 0.0340s/iter; left time: 72.1029s\n",
      "\titers: 700, epoch: 18 | loss: 0.0470141\n",
      "\tspeed: 0.0340s/iter; left time: 68.6295s\n",
      "\titers: 800, epoch: 18 | loss: 0.0419604\n",
      "\tspeed: 0.0341s/iter; left time: 65.3850s\n",
      "\titers: 900, epoch: 18 | loss: 0.0463720\n",
      "\tspeed: 0.0340s/iter; left time: 61.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0450904 Vali Loss: 0.0583875 Test Loss: 0.1041857\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0424898\n",
      "\tspeed: 0.0931s/iter; left time: 159.4494s\n",
      "\titers: 200, epoch: 19 | loss: 0.0434248\n",
      "\tspeed: 0.0340s/iter; left time: 54.8737s\n",
      "\titers: 300, epoch: 19 | loss: 0.0410817\n",
      "\tspeed: 0.0340s/iter; left time: 51.4603s\n",
      "\titers: 400, epoch: 19 | loss: 0.0418899\n",
      "\tspeed: 0.0340s/iter; left time: 48.0451s\n",
      "\titers: 500, epoch: 19 | loss: 0.0446364\n",
      "\tspeed: 0.0341s/iter; left time: 44.7165s\n",
      "\titers: 600, epoch: 19 | loss: 0.0444938\n",
      "\tspeed: 0.0340s/iter; left time: 41.2340s\n",
      "\titers: 700, epoch: 19 | loss: 0.0418383\n",
      "\tspeed: 0.0341s/iter; left time: 37.9425s\n",
      "\titers: 800, epoch: 19 | loss: 0.0464259\n",
      "\tspeed: 0.0340s/iter; left time: 34.4403s\n",
      "\titers: 900, epoch: 19 | loss: 0.0461343\n",
      "\tspeed: 0.0340s/iter; left time: 31.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0444866 Vali Loss: 0.0587221 Test Loss: 0.1070130\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.027461538091301918, rmse:0.16571523249149323, mae:0.09743039309978485, rse:0.4869214594364166\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2149062\n",
      "\tspeed: 0.0359s/iter; left time: 647.8177s\n",
      "\titers: 200, epoch: 1 | loss: 0.2208412\n",
      "\tspeed: 0.0340s/iter; left time: 609.6411s\n",
      "\titers: 300, epoch: 1 | loss: 0.1960506\n",
      "\tspeed: 0.0341s/iter; left time: 607.1201s\n",
      "\titers: 400, epoch: 1 | loss: 0.1785244\n",
      "\tspeed: 0.0341s/iter; left time: 604.3089s\n",
      "\titers: 500, epoch: 1 | loss: 0.1606690\n",
      "\tspeed: 0.0341s/iter; left time: 601.1981s\n",
      "\titers: 600, epoch: 1 | loss: 0.1587723\n",
      "\tspeed: 0.0341s/iter; left time: 597.8329s\n",
      "\titers: 700, epoch: 1 | loss: 0.1492396\n",
      "\tspeed: 0.0341s/iter; left time: 593.4278s\n",
      "\titers: 800, epoch: 1 | loss: 0.1445469\n",
      "\tspeed: 0.0341s/iter; left time: 590.6606s\n",
      "\titers: 900, epoch: 1 | loss: 0.1369113\n",
      "\tspeed: 0.0341s/iter; left time: 587.7602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.1828038 Vali Loss: 0.1089664 Test Loss: 0.1298395\n",
      "Validation loss decreased (inf --> 0.108966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1135225\n",
      "\tspeed: 0.0967s/iter; left time: 1655.7642s\n",
      "\titers: 200, epoch: 2 | loss: 0.1148164\n",
      "\tspeed: 0.0341s/iter; left time: 579.4230s\n",
      "\titers: 300, epoch: 2 | loss: 0.0936463\n",
      "\tspeed: 0.0340s/iter; left time: 575.6874s\n",
      "\titers: 400, epoch: 2 | loss: 0.0820305\n",
      "\tspeed: 0.0340s/iter; left time: 571.7097s\n",
      "\titers: 500, epoch: 2 | loss: 0.0843619\n",
      "\tspeed: 0.0340s/iter; left time: 568.8378s\n",
      "\titers: 600, epoch: 2 | loss: 0.0846980\n",
      "\tspeed: 0.0341s/iter; left time: 565.9215s\n",
      "\titers: 700, epoch: 2 | loss: 0.0829176\n",
      "\tspeed: 0.0341s/iter; left time: 562.3783s\n",
      "\titers: 800, epoch: 2 | loss: 0.0821716\n",
      "\tspeed: 0.0341s/iter; left time: 559.9984s\n",
      "\titers: 900, epoch: 2 | loss: 0.0759475\n",
      "\tspeed: 0.0341s/iter; left time: 555.7600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0933928 Vali Loss: 0.0766692 Test Loss: 0.1036709\n",
      "Validation loss decreased (0.108966 --> 0.076669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689353\n",
      "\tspeed: 0.0964s/iter; left time: 1562.7546s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678947\n",
      "\tspeed: 0.0341s/iter; left time: 548.5724s\n",
      "\titers: 300, epoch: 3 | loss: 0.0727085\n",
      "\tspeed: 0.0340s/iter; left time: 544.8113s\n",
      "\titers: 400, epoch: 3 | loss: 0.0748758\n",
      "\tspeed: 0.0341s/iter; left time: 542.3137s\n",
      "\titers: 500, epoch: 3 | loss: 0.0773622\n",
      "\tspeed: 0.0341s/iter; left time: 538.4005s\n",
      "\titers: 600, epoch: 3 | loss: 0.0685271\n",
      "\tspeed: 0.0341s/iter; left time: 535.4238s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751804\n",
      "\tspeed: 0.0341s/iter; left time: 532.3713s\n",
      "\titers: 800, epoch: 3 | loss: 0.0565176\n",
      "\tspeed: 0.0341s/iter; left time: 528.6195s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646926\n",
      "\tspeed: 0.0341s/iter; left time: 524.9288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0711776 Vali Loss: 0.0796852 Test Loss: 0.1065500\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657408\n",
      "\tspeed: 0.0928s/iter; left time: 1419.9932s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647836\n",
      "\tspeed: 0.0341s/iter; left time: 518.5229s\n",
      "\titers: 300, epoch: 4 | loss: 0.0649817\n",
      "\tspeed: 0.0341s/iter; left time: 514.9193s\n",
      "\titers: 400, epoch: 4 | loss: 0.0786881\n",
      "\tspeed: 0.0341s/iter; left time: 512.0881s\n",
      "\titers: 500, epoch: 4 | loss: 0.0712274\n",
      "\tspeed: 0.0341s/iter; left time: 507.5204s\n",
      "\titers: 600, epoch: 4 | loss: 0.0682974\n",
      "\tspeed: 0.0342s/iter; left time: 505.6659s\n",
      "\titers: 700, epoch: 4 | loss: 0.0697354\n",
      "\tspeed: 0.0342s/iter; left time: 502.1557s\n",
      "\titers: 800, epoch: 4 | loss: 0.0585399\n",
      "\tspeed: 0.0341s/iter; left time: 498.6690s\n",
      "\titers: 900, epoch: 4 | loss: 0.0596235\n",
      "\tspeed: 0.0341s/iter; left time: 494.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0653138 Vali Loss: 0.0680534 Test Loss: 0.0976341\n",
      "Validation loss decreased (0.076669 --> 0.068053).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0725577\n",
      "\tspeed: 0.0963s/iter; left time: 1386.6411s\n",
      "\titers: 200, epoch: 5 | loss: 0.0573841\n",
      "\tspeed: 0.0340s/iter; left time: 486.6671s\n",
      "\titers: 300, epoch: 5 | loss: 0.0539423\n",
      "\tspeed: 0.0341s/iter; left time: 483.5814s\n",
      "\titers: 400, epoch: 5 | loss: 0.0593723\n",
      "\tspeed: 0.0341s/iter; left time: 480.2758s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631876\n",
      "\tspeed: 0.0340s/iter; left time: 476.5368s\n",
      "\titers: 600, epoch: 5 | loss: 0.0533562\n",
      "\tspeed: 0.0341s/iter; left time: 473.4310s\n",
      "\titers: 700, epoch: 5 | loss: 0.0583013\n",
      "\tspeed: 0.0341s/iter; left time: 470.4378s\n",
      "\titers: 800, epoch: 5 | loss: 0.0527938\n",
      "\tspeed: 0.0340s/iter; left time: 466.2385s\n",
      "\titers: 900, epoch: 5 | loss: 0.0549873\n",
      "\tspeed: 0.0341s/iter; left time: 463.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0610250 Vali Loss: 0.0610558 Test Loss: 0.0921888\n",
      "Validation loss decreased (0.068053 --> 0.061056).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0580953\n",
      "\tspeed: 0.0960s/iter; left time: 1295.5002s\n",
      "\titers: 200, epoch: 6 | loss: 0.0602082\n",
      "\tspeed: 0.0340s/iter; left time: 455.9594s\n",
      "\titers: 300, epoch: 6 | loss: 0.0604460\n",
      "\tspeed: 0.0340s/iter; left time: 452.2778s\n",
      "\titers: 400, epoch: 6 | loss: 0.0563742\n",
      "\tspeed: 0.0341s/iter; left time: 449.4301s\n",
      "\titers: 500, epoch: 6 | loss: 0.0530320\n",
      "\tspeed: 0.0341s/iter; left time: 445.9065s\n",
      "\titers: 600, epoch: 6 | loss: 0.0533875\n",
      "\tspeed: 0.0340s/iter; left time: 441.9325s\n",
      "\titers: 700, epoch: 6 | loss: 0.0524571\n",
      "\tspeed: 0.0340s/iter; left time: 438.9373s\n",
      "\titers: 800, epoch: 6 | loss: 0.0500506\n",
      "\tspeed: 0.0340s/iter; left time: 435.2579s\n",
      "\titers: 900, epoch: 6 | loss: 0.0613379\n",
      "\tspeed: 0.0340s/iter; left time: 432.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0579149 Vali Loss: 0.0589280 Test Loss: 0.0870637\n",
      "Validation loss decreased (0.061056 --> 0.058928).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0542730\n",
      "\tspeed: 0.0957s/iter; left time: 1203.9772s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584979\n",
      "\tspeed: 0.0341s/iter; left time: 425.1150s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552041\n",
      "\tspeed: 0.0341s/iter; left time: 421.9635s\n",
      "\titers: 400, epoch: 7 | loss: 0.0513719\n",
      "\tspeed: 0.0340s/iter; left time: 418.0528s\n",
      "\titers: 500, epoch: 7 | loss: 0.0545608\n",
      "\tspeed: 0.0341s/iter; left time: 415.9115s\n",
      "\titers: 600, epoch: 7 | loss: 0.0571133\n",
      "\tspeed: 0.0341s/iter; left time: 411.7257s\n",
      "\titers: 700, epoch: 7 | loss: 0.0540548\n",
      "\tspeed: 0.0341s/iter; left time: 408.3959s\n",
      "\titers: 800, epoch: 7 | loss: 0.0513388\n",
      "\tspeed: 0.0341s/iter; left time: 405.2208s\n",
      "\titers: 900, epoch: 7 | loss: 0.0515127\n",
      "\tspeed: 0.0341s/iter; left time: 401.5690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0555515 Vali Loss: 0.0638483 Test Loss: 0.0944871\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0527631\n",
      "\tspeed: 0.0929s/iter; left time: 1085.3560s\n",
      "\titers: 200, epoch: 8 | loss: 0.0519219\n",
      "\tspeed: 0.0341s/iter; left time: 394.8668s\n",
      "\titers: 300, epoch: 8 | loss: 0.0529470\n",
      "\tspeed: 0.0341s/iter; left time: 391.2811s\n",
      "\titers: 400, epoch: 8 | loss: 0.0566683\n",
      "\tspeed: 0.0341s/iter; left time: 387.8255s\n",
      "\titers: 500, epoch: 8 | loss: 0.0511631\n",
      "\tspeed: 0.0341s/iter; left time: 384.8334s\n",
      "\titers: 600, epoch: 8 | loss: 0.0515833\n",
      "\tspeed: 0.0341s/iter; left time: 381.1682s\n",
      "\titers: 700, epoch: 8 | loss: 0.0480705\n",
      "\tspeed: 0.0341s/iter; left time: 377.5911s\n",
      "\titers: 800, epoch: 8 | loss: 0.0580791\n",
      "\tspeed: 0.0340s/iter; left time: 373.7311s\n",
      "\titers: 900, epoch: 8 | loss: 0.0615418\n",
      "\tspeed: 0.0341s/iter; left time: 370.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0541977 Vali Loss: 0.0600997 Test Loss: 0.0928956\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0542574\n",
      "\tspeed: 0.0933s/iter; left time: 1004.7664s\n",
      "\titers: 200, epoch: 9 | loss: 0.0516183\n",
      "\tspeed: 0.0340s/iter; left time: 363.3126s\n",
      "\titers: 300, epoch: 9 | loss: 0.0530071\n",
      "\tspeed: 0.0340s/iter; left time: 359.3725s\n",
      "\titers: 400, epoch: 9 | loss: 0.0483792\n",
      "\tspeed: 0.0340s/iter; left time: 356.3748s\n",
      "\titers: 500, epoch: 9 | loss: 0.0543778\n",
      "\tspeed: 0.0340s/iter; left time: 353.1151s\n",
      "\titers: 600, epoch: 9 | loss: 0.0531961\n",
      "\tspeed: 0.0340s/iter; left time: 349.6051s\n",
      "\titers: 700, epoch: 9 | loss: 0.0557334\n",
      "\tspeed: 0.0340s/iter; left time: 346.2001s\n",
      "\titers: 800, epoch: 9 | loss: 0.0548735\n",
      "\tspeed: 0.0340s/iter; left time: 342.9241s\n",
      "\titers: 900, epoch: 9 | loss: 0.0554635\n",
      "\tspeed: 0.0340s/iter; left time: 339.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0527868 Vali Loss: 0.0606648 Test Loss: 0.0891905\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0564716\n",
      "\tspeed: 0.0931s/iter; left time: 918.4250s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536913\n",
      "\tspeed: 0.0340s/iter; left time: 332.3861s\n",
      "\titers: 300, epoch: 10 | loss: 0.0534131\n",
      "\tspeed: 0.0341s/iter; left time: 329.2227s\n",
      "\titers: 400, epoch: 10 | loss: 0.0569648\n",
      "\tspeed: 0.0340s/iter; left time: 325.5396s\n",
      "\titers: 500, epoch: 10 | loss: 0.0553950\n",
      "\tspeed: 0.0340s/iter; left time: 322.3328s\n",
      "\titers: 600, epoch: 10 | loss: 0.0504877\n",
      "\tspeed: 0.0341s/iter; left time: 319.2523s\n",
      "\titers: 700, epoch: 10 | loss: 0.0442066\n",
      "\tspeed: 0.0341s/iter; left time: 315.9050s\n",
      "\titers: 800, epoch: 10 | loss: 0.0492407\n",
      "\tspeed: 0.0341s/iter; left time: 312.2782s\n",
      "\titers: 900, epoch: 10 | loss: 0.0494081\n",
      "\tspeed: 0.0341s/iter; left time: 308.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0516848 Vali Loss: 0.0591269 Test Loss: 0.0909714\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0543662\n",
      "\tspeed: 0.0930s/iter; left time: 833.5490s\n",
      "\titers: 200, epoch: 11 | loss: 0.0554431\n",
      "\tspeed: 0.0340s/iter; left time: 301.3541s\n",
      "\titers: 300, epoch: 11 | loss: 0.0557188\n",
      "\tspeed: 0.0341s/iter; left time: 298.3951s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493816\n",
      "\tspeed: 0.0340s/iter; left time: 294.7068s\n",
      "\titers: 500, epoch: 11 | loss: 0.0470877\n",
      "\tspeed: 0.0341s/iter; left time: 291.9255s\n",
      "\titers: 600, epoch: 11 | loss: 0.0478654\n",
      "\tspeed: 0.0341s/iter; left time: 288.4091s\n",
      "\titers: 700, epoch: 11 | loss: 0.0479112\n",
      "\tspeed: 0.0341s/iter; left time: 284.7780s\n",
      "\titers: 800, epoch: 11 | loss: 0.0557325\n",
      "\tspeed: 0.0341s/iter; left time: 281.5655s\n",
      "\titers: 900, epoch: 11 | loss: 0.0540772\n",
      "\tspeed: 0.0341s/iter; left time: 277.9774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0503803 Vali Loss: 0.0596729 Test Loss: 0.0918079\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_24_ES_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.019272608682513237, rmse:0.13882581889629364, mae:0.08702108263969421, rse:0.4079122245311737\n",
      "Intermediate time for ES and pred_len 24: 00h:18m:37.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_96_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2373950\n",
      "\tspeed: 0.0630s/iter; left time: 1132.0348s\n",
      "\titers: 200, epoch: 1 | loss: 0.2127535\n",
      "\tspeed: 0.0421s/iter; left time: 753.0910s\n",
      "\titers: 300, epoch: 1 | loss: 0.2200992\n",
      "\tspeed: 0.0421s/iter; left time: 748.5457s\n",
      "\titers: 400, epoch: 1 | loss: 0.2059206\n",
      "\tspeed: 0.0421s/iter; left time: 744.3850s\n",
      "\titers: 500, epoch: 1 | loss: 0.1971000\n",
      "\tspeed: 0.0421s/iter; left time: 740.1027s\n",
      "\titers: 600, epoch: 1 | loss: 0.1864508\n",
      "\tspeed: 0.0421s/iter; left time: 736.0255s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921179\n",
      "\tspeed: 0.0422s/iter; left time: 733.0808s\n",
      "\titers: 800, epoch: 1 | loss: 0.1733235\n",
      "\tspeed: 0.0421s/iter; left time: 727.6188s\n",
      "\titers: 900, epoch: 1 | loss: 0.1764061\n",
      "\tspeed: 0.0425s/iter; left time: 730.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 904 | Train Loss: 0.2055957 Vali Loss: 0.1704240 Test Loss: 0.2081109\n",
      "Validation loss decreased (inf --> 0.170424).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1474789\n",
      "\tspeed: 0.1169s/iter; left time: 1995.5735s\n",
      "\titers: 200, epoch: 2 | loss: 0.1373694\n",
      "\tspeed: 0.0420s/iter; left time: 713.7136s\n",
      "\titers: 300, epoch: 2 | loss: 0.1301654\n",
      "\tspeed: 0.0421s/iter; left time: 710.1622s\n",
      "\titers: 400, epoch: 2 | loss: 0.1124775\n",
      "\tspeed: 0.0421s/iter; left time: 706.2904s\n",
      "\titers: 500, epoch: 2 | loss: 0.1012060\n",
      "\tspeed: 0.0421s/iter; left time: 701.8246s\n",
      "\titers: 600, epoch: 2 | loss: 0.1080255\n",
      "\tspeed: 0.0421s/iter; left time: 698.2995s\n",
      "\titers: 700, epoch: 2 | loss: 0.0986939\n",
      "\tspeed: 0.0421s/iter; left time: 693.9462s\n",
      "\titers: 800, epoch: 2 | loss: 0.0948638\n",
      "\tspeed: 0.0421s/iter; left time: 689.3840s\n",
      "\titers: 900, epoch: 2 | loss: 0.0981427\n",
      "\tspeed: 0.0421s/iter; left time: 684.8347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 904 | Train Loss: 0.1190556 Vali Loss: 0.0968713 Test Loss: 0.1262738\n",
      "Validation loss decreased (0.170424 --> 0.096871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0954394\n",
      "\tspeed: 0.1166s/iter; left time: 1886.4918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901963\n",
      "\tspeed: 0.0421s/iter; left time: 676.3143s\n",
      "\titers: 300, epoch: 3 | loss: 0.0962261\n",
      "\tspeed: 0.0421s/iter; left time: 672.3038s\n",
      "\titers: 400, epoch: 3 | loss: 0.0960315\n",
      "\tspeed: 0.0421s/iter; left time: 668.6412s\n",
      "\titers: 500, epoch: 3 | loss: 0.0871150\n",
      "\tspeed: 0.0420s/iter; left time: 663.1879s\n",
      "\titers: 600, epoch: 3 | loss: 0.0901583\n",
      "\tspeed: 0.0421s/iter; left time: 659.3545s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950876\n",
      "\tspeed: 0.0420s/iter; left time: 654.3531s\n",
      "\titers: 800, epoch: 3 | loss: 0.0905125\n",
      "\tspeed: 0.0420s/iter; left time: 650.5121s\n",
      "\titers: 900, epoch: 3 | loss: 0.0831911\n",
      "\tspeed: 0.0421s/iter; left time: 646.6106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0922454 Vali Loss: 0.0891734 Test Loss: 0.1277304\n",
      "Validation loss decreased (0.096871 --> 0.089173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0830763\n",
      "\tspeed: 0.1176s/iter; left time: 1796.2948s\n",
      "\titers: 200, epoch: 4 | loss: 0.0852754\n",
      "\tspeed: 0.0421s/iter; left time: 638.2523s\n",
      "\titers: 300, epoch: 4 | loss: 0.0858199\n",
      "\tspeed: 0.0421s/iter; left time: 634.1683s\n",
      "\titers: 400, epoch: 4 | loss: 0.0820458\n",
      "\tspeed: 0.0421s/iter; left time: 629.8990s\n",
      "\titers: 500, epoch: 4 | loss: 0.0901307\n",
      "\tspeed: 0.0420s/iter; left time: 625.0486s\n",
      "\titers: 600, epoch: 4 | loss: 0.0855317\n",
      "\tspeed: 0.0421s/iter; left time: 621.2486s\n",
      "\titers: 700, epoch: 4 | loss: 0.0796080\n",
      "\tspeed: 0.0421s/iter; left time: 617.0458s\n",
      "\titers: 800, epoch: 4 | loss: 0.0797859\n",
      "\tspeed: 0.0421s/iter; left time: 612.8719s\n",
      "\titers: 900, epoch: 4 | loss: 0.0875236\n",
      "\tspeed: 0.0421s/iter; left time: 608.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 904 | Train Loss: 0.0864976 Vali Loss: 0.0881260 Test Loss: 0.1281893\n",
      "Validation loss decreased (0.089173 --> 0.088126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0831923\n",
      "\tspeed: 0.1170s/iter; left time: 1681.0620s\n",
      "\titers: 200, epoch: 5 | loss: 0.0823494\n",
      "\tspeed: 0.0421s/iter; left time: 600.7790s\n",
      "\titers: 300, epoch: 5 | loss: 0.0849803\n",
      "\tspeed: 0.0421s/iter; left time: 596.2569s\n",
      "\titers: 400, epoch: 5 | loss: 0.0798522\n",
      "\tspeed: 0.0421s/iter; left time: 592.0255s\n",
      "\titers: 500, epoch: 5 | loss: 0.0811485\n",
      "\tspeed: 0.0421s/iter; left time: 588.2881s\n",
      "\titers: 600, epoch: 5 | loss: 0.0798577\n",
      "\tspeed: 0.0421s/iter; left time: 583.7078s\n",
      "\titers: 700, epoch: 5 | loss: 0.0791995\n",
      "\tspeed: 0.0421s/iter; left time: 579.9353s\n",
      "\titers: 800, epoch: 5 | loss: 0.0825909\n",
      "\tspeed: 0.0422s/iter; left time: 576.0551s\n",
      "\titers: 900, epoch: 5 | loss: 0.0805139\n",
      "\tspeed: 0.0421s/iter; left time: 570.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0819588 Vali Loss: 0.0869265 Test Loss: 0.1323719\n",
      "Validation loss decreased (0.088126 --> 0.086926).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0814526\n",
      "\tspeed: 0.1178s/iter; left time: 1585.9811s\n",
      "\titers: 200, epoch: 6 | loss: 0.0821762\n",
      "\tspeed: 0.0421s/iter; left time: 562.3599s\n",
      "\titers: 300, epoch: 6 | loss: 0.0794167\n",
      "\tspeed: 0.0421s/iter; left time: 558.7318s\n",
      "\titers: 400, epoch: 6 | loss: 0.0752672\n",
      "\tspeed: 0.0421s/iter; left time: 554.3897s\n",
      "\titers: 500, epoch: 6 | loss: 0.0766867\n",
      "\tspeed: 0.0420s/iter; left time: 549.1725s\n",
      "\titers: 600, epoch: 6 | loss: 0.0775365\n",
      "\tspeed: 0.0421s/iter; left time: 545.3077s\n",
      "\titers: 700, epoch: 6 | loss: 0.0771111\n",
      "\tspeed: 0.0421s/iter; left time: 541.3962s\n",
      "\titers: 800, epoch: 6 | loss: 0.0805728\n",
      "\tspeed: 0.0421s/iter; left time: 537.0451s\n",
      "\titers: 900, epoch: 6 | loss: 0.0751420\n",
      "\tspeed: 0.0421s/iter; left time: 533.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0784264 Vali Loss: 0.0879058 Test Loss: 0.1440845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763488\n",
      "\tspeed: 0.1153s/iter; left time: 1447.5681s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769644\n",
      "\tspeed: 0.0420s/iter; left time: 523.5385s\n",
      "\titers: 300, epoch: 7 | loss: 0.0803116\n",
      "\tspeed: 0.0421s/iter; left time: 519.9943s\n",
      "\titers: 400, epoch: 7 | loss: 0.0778039\n",
      "\tspeed: 0.0421s/iter; left time: 515.5707s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726631\n",
      "\tspeed: 0.0421s/iter; left time: 511.8159s\n",
      "\titers: 600, epoch: 7 | loss: 0.0671688\n",
      "\tspeed: 0.0421s/iter; left time: 507.5547s\n",
      "\titers: 700, epoch: 7 | loss: 0.0728735\n",
      "\tspeed: 0.0418s/iter; left time: 499.7380s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 491.7005s\n",
      "\titers: 900, epoch: 7 | loss: 0.0791964\n",
      "\tspeed: 0.0415s/iter; left time: 487.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 904 | Train Loss: 0.0751993 Vali Loss: 0.0868586 Test Loss: 0.1397843\n",
      "Validation loss decreased (0.086926 --> 0.086859).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776971\n",
      "\tspeed: 0.1174s/iter; left time: 1368.3659s\n",
      "\titers: 200, epoch: 8 | loss: 0.0721895\n",
      "\tspeed: 0.0416s/iter; left time: 480.0903s\n",
      "\titers: 300, epoch: 8 | loss: 0.0700485\n",
      "\tspeed: 0.0415s/iter; left time: 475.8155s\n",
      "\titers: 400, epoch: 8 | loss: 0.0711599\n",
      "\tspeed: 0.0416s/iter; left time: 471.8501s\n",
      "\titers: 500, epoch: 8 | loss: 0.0706868\n",
      "\tspeed: 0.0415s/iter; left time: 467.5249s\n",
      "\titers: 600, epoch: 8 | loss: 0.0683769\n",
      "\tspeed: 0.0416s/iter; left time: 463.6050s\n",
      "\titers: 700, epoch: 8 | loss: 0.0641797\n",
      "\tspeed: 0.0416s/iter; left time: 459.2867s\n",
      "\titers: 800, epoch: 8 | loss: 0.0709313\n",
      "\tspeed: 0.0416s/iter; left time: 455.4383s\n",
      "\titers: 900, epoch: 8 | loss: 0.0689372\n",
      "\tspeed: 0.0416s/iter; left time: 451.7127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 904 | Train Loss: 0.0718957 Vali Loss: 0.0874921 Test Loss: 0.1515969\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0712285\n",
      "\tspeed: 0.1141s/iter; left time: 1225.9544s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697914\n",
      "\tspeed: 0.0415s/iter; left time: 441.5640s\n",
      "\titers: 300, epoch: 9 | loss: 0.0708499\n",
      "\tspeed: 0.0415s/iter; left time: 437.6952s\n",
      "\titers: 400, epoch: 9 | loss: 0.0671885\n",
      "\tspeed: 0.0415s/iter; left time: 433.7513s\n",
      "\titers: 500, epoch: 9 | loss: 0.0713352\n",
      "\tspeed: 0.0415s/iter; left time: 429.1352s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717964\n",
      "\tspeed: 0.0415s/iter; left time: 425.3757s\n",
      "\titers: 700, epoch: 9 | loss: 0.0682684\n",
      "\tspeed: 0.0415s/iter; left time: 421.1203s\n",
      "\titers: 800, epoch: 9 | loss: 0.0685369\n",
      "\tspeed: 0.0415s/iter; left time: 417.1008s\n",
      "\titers: 900, epoch: 9 | loss: 0.0697512\n",
      "\tspeed: 0.0415s/iter; left time: 412.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0691556 Vali Loss: 0.0882018 Test Loss: 0.1587183\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682209\n",
      "\tspeed: 0.1132s/iter; left time: 1114.3122s\n",
      "\titers: 200, epoch: 10 | loss: 0.0657655\n",
      "\tspeed: 0.0414s/iter; left time: 403.9179s\n",
      "\titers: 300, epoch: 10 | loss: 0.0661185\n",
      "\tspeed: 0.0415s/iter; left time: 400.0127s\n",
      "\titers: 400, epoch: 10 | loss: 0.0667656\n",
      "\tspeed: 0.0414s/iter; left time: 395.5766s\n",
      "\titers: 500, epoch: 10 | loss: 0.0639189\n",
      "\tspeed: 0.0415s/iter; left time: 391.6025s\n",
      "\titers: 600, epoch: 10 | loss: 0.0679160\n",
      "\tspeed: 0.0415s/iter; left time: 387.4287s\n",
      "\titers: 700, epoch: 10 | loss: 0.0706274\n",
      "\tspeed: 0.0414s/iter; left time: 383.2033s\n",
      "\titers: 800, epoch: 10 | loss: 0.0604116\n",
      "\tspeed: 0.0414s/iter; left time: 379.0521s\n",
      "\titers: 900, epoch: 10 | loss: 0.0648436\n",
      "\tspeed: 0.0414s/iter; left time: 374.8803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 904 | Train Loss: 0.0665796 Vali Loss: 0.0873402 Test Loss: 0.1584590\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0683132\n",
      "\tspeed: 0.1138s/iter; left time: 1017.2489s\n",
      "\titers: 200, epoch: 11 | loss: 0.0653537\n",
      "\tspeed: 0.0415s/iter; left time: 367.2876s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655010\n",
      "\tspeed: 0.0415s/iter; left time: 363.0876s\n",
      "\titers: 400, epoch: 11 | loss: 0.0705099\n",
      "\tspeed: 0.0415s/iter; left time: 358.8113s\n",
      "\titers: 500, epoch: 11 | loss: 0.0668215\n",
      "\tspeed: 0.0415s/iter; left time: 354.5913s\n",
      "\titers: 600, epoch: 11 | loss: 0.0674020\n",
      "\tspeed: 0.0415s/iter; left time: 350.3595s\n",
      "\titers: 700, epoch: 11 | loss: 0.0653524\n",
      "\tspeed: 0.0415s/iter; left time: 346.5444s\n",
      "\titers: 800, epoch: 11 | loss: 0.0633563\n",
      "\tspeed: 0.0415s/iter; left time: 342.0408s\n",
      "\titers: 900, epoch: 11 | loss: 0.0604338\n",
      "\tspeed: 0.0416s/iter; left time: 338.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0644156 Vali Loss: 0.0880552 Test Loss: 0.1590489\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0583263\n",
      "\tspeed: 0.1149s/iter; left time: 923.2915s\n",
      "\titers: 200, epoch: 12 | loss: 0.0638356\n",
      "\tspeed: 0.0415s/iter; left time: 329.0060s\n",
      "\titers: 300, epoch: 12 | loss: 0.0610895\n",
      "\tspeed: 0.0415s/iter; left time: 325.0781s\n",
      "\titers: 400, epoch: 12 | loss: 0.0576380\n",
      "\tspeed: 0.0415s/iter; left time: 321.0412s\n",
      "\titers: 500, epoch: 12 | loss: 0.0655818\n",
      "\tspeed: 0.0415s/iter; left time: 316.7267s\n",
      "\titers: 600, epoch: 12 | loss: 0.0575109\n",
      "\tspeed: 0.0418s/iter; left time: 314.9701s\n",
      "\titers: 700, epoch: 12 | loss: 0.0618829\n",
      "\tspeed: 0.0420s/iter; left time: 312.4757s\n",
      "\titers: 800, epoch: 12 | loss: 0.0603857\n",
      "\tspeed: 0.0420s/iter; left time: 308.1376s\n",
      "\titers: 900, epoch: 12 | loss: 0.0614875\n",
      "\tspeed: 0.0420s/iter; left time: 304.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 904 | Train Loss: 0.0624188 Vali Loss: 0.0871061 Test Loss: 0.1609867\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04883919283747673, rmse:0.2209959179162979, mae:0.1398049145936966, rse:0.6492194533348083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2255370\n",
      "\tspeed: 0.0439s/iter; left time: 789.5778s\n",
      "\titers: 200, epoch: 1 | loss: 0.2166498\n",
      "\tspeed: 0.0415s/iter; left time: 742.5966s\n",
      "\titers: 300, epoch: 1 | loss: 0.2044076\n",
      "\tspeed: 0.0415s/iter; left time: 738.6653s\n",
      "\titers: 400, epoch: 1 | loss: 0.2036429\n",
      "\tspeed: 0.0416s/iter; left time: 735.0498s\n",
      "\titers: 500, epoch: 1 | loss: 0.1952279\n",
      "\tspeed: 0.0416s/iter; left time: 730.7050s\n",
      "\titers: 600, epoch: 1 | loss: 0.1890704\n",
      "\tspeed: 0.0416s/iter; left time: 726.8284s\n",
      "\titers: 700, epoch: 1 | loss: 0.1774556\n",
      "\tspeed: 0.0416s/iter; left time: 722.6038s\n",
      "\titers: 800, epoch: 1 | loss: 0.1774660\n",
      "\tspeed: 0.0416s/iter; left time: 718.2065s\n",
      "\titers: 900, epoch: 1 | loss: 0.1773101\n",
      "\tspeed: 0.0415s/iter; left time: 713.2413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.2017067 Vali Loss: 0.1653294 Test Loss: 0.2053860\n",
      "Validation loss decreased (inf --> 0.165329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1482454\n",
      "\tspeed: 0.1171s/iter; left time: 2000.5558s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250862\n",
      "\tspeed: 0.0415s/iter; left time: 704.8476s\n",
      "\titers: 300, epoch: 2 | loss: 0.1308347\n",
      "\tspeed: 0.0415s/iter; left time: 700.7665s\n",
      "\titers: 400, epoch: 2 | loss: 0.1253198\n",
      "\tspeed: 0.0415s/iter; left time: 696.8225s\n",
      "\titers: 500, epoch: 2 | loss: 0.1118068\n",
      "\tspeed: 0.0415s/iter; left time: 692.3480s\n",
      "\titers: 600, epoch: 2 | loss: 0.1140664\n",
      "\tspeed: 0.0416s/iter; left time: 688.8759s\n",
      "\titers: 700, epoch: 2 | loss: 0.1062072\n",
      "\tspeed: 0.0416s/iter; left time: 684.9127s\n",
      "\titers: 800, epoch: 2 | loss: 0.1010479\n",
      "\tspeed: 0.0416s/iter; left time: 680.5475s\n",
      "\titers: 900, epoch: 2 | loss: 0.0990625\n",
      "\tspeed: 0.0416s/iter; left time: 676.4182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.1223058 Vali Loss: 0.0981640 Test Loss: 0.1313140\n",
      "Validation loss decreased (0.165329 --> 0.098164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0917345\n",
      "\tspeed: 0.1206s/iter; left time: 1950.2871s\n",
      "\titers: 200, epoch: 3 | loss: 0.0968400\n",
      "\tspeed: 0.0415s/iter; left time: 667.5402s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922163\n",
      "\tspeed: 0.0415s/iter; left time: 663.6097s\n",
      "\titers: 400, epoch: 3 | loss: 0.0844943\n",
      "\tspeed: 0.0416s/iter; left time: 659.5445s\n",
      "\titers: 500, epoch: 3 | loss: 0.0870728\n",
      "\tspeed: 0.0416s/iter; left time: 655.7148s\n",
      "\titers: 600, epoch: 3 | loss: 0.0913326\n",
      "\tspeed: 0.0416s/iter; left time: 651.5126s\n",
      "\titers: 700, epoch: 3 | loss: 0.0907997\n",
      "\tspeed: 0.0415s/iter; left time: 646.4715s\n",
      "\titers: 800, epoch: 3 | loss: 0.0945480\n",
      "\tspeed: 0.0416s/iter; left time: 643.3192s\n",
      "\titers: 900, epoch: 3 | loss: 0.0911530\n",
      "\tspeed: 0.0416s/iter; left time: 639.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.0923384 Vali Loss: 0.0945549 Test Loss: 0.1335031\n",
      "Validation loss decreased (0.098164 --> 0.094555).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0901370\n",
      "\tspeed: 0.1166s/iter; left time: 1779.6277s\n",
      "\titers: 200, epoch: 4 | loss: 0.0939121\n",
      "\tspeed: 0.0416s/iter; left time: 630.3666s\n",
      "\titers: 300, epoch: 4 | loss: 0.0888266\n",
      "\tspeed: 0.0416s/iter; left time: 626.5277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0939008\n",
      "\tspeed: 0.0416s/iter; left time: 622.4458s\n",
      "\titers: 500, epoch: 4 | loss: 0.0792086\n",
      "\tspeed: 0.0416s/iter; left time: 618.3303s\n",
      "\titers: 600, epoch: 4 | loss: 0.0830760\n",
      "\tspeed: 0.0416s/iter; left time: 613.8589s\n",
      "\titers: 700, epoch: 4 | loss: 0.0812820\n",
      "\tspeed: 0.0416s/iter; left time: 609.6404s\n",
      "\titers: 800, epoch: 4 | loss: 0.0889937\n",
      "\tspeed: 0.0416s/iter; left time: 605.5328s\n",
      "\titers: 900, epoch: 4 | loss: 0.0849229\n",
      "\tspeed: 0.0416s/iter; left time: 601.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0863824 Vali Loss: 0.0888520 Test Loss: 0.1328815\n",
      "Validation loss decreased (0.094555 --> 0.088852).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0871914\n",
      "\tspeed: 0.1170s/iter; left time: 1680.2305s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801925\n",
      "\tspeed: 0.0416s/iter; left time: 592.9057s\n",
      "\titers: 300, epoch: 5 | loss: 0.0851149\n",
      "\tspeed: 0.0415s/iter; left time: 587.8497s\n",
      "\titers: 400, epoch: 5 | loss: 0.0847745\n",
      "\tspeed: 0.0415s/iter; left time: 583.5027s\n",
      "\titers: 500, epoch: 5 | loss: 0.0800787\n",
      "\tspeed: 0.0415s/iter; left time: 579.6990s\n",
      "\titers: 600, epoch: 5 | loss: 0.0951516\n",
      "\tspeed: 0.0415s/iter; left time: 575.3423s\n",
      "\titers: 700, epoch: 5 | loss: 0.0797609\n",
      "\tspeed: 0.0415s/iter; left time: 570.9798s\n",
      "\titers: 800, epoch: 5 | loss: 0.0892005\n",
      "\tspeed: 0.0415s/iter; left time: 567.0856s\n",
      "\titers: 900, epoch: 5 | loss: 0.0754987\n",
      "\tspeed: 0.0415s/iter; left time: 562.8520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0823251 Vali Loss: 0.0867483 Test Loss: 0.1332777\n",
      "Validation loss decreased (0.088852 --> 0.086748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733105\n",
      "\tspeed: 0.1167s/iter; left time: 1570.2430s\n",
      "\titers: 200, epoch: 6 | loss: 0.0700598\n",
      "\tspeed: 0.0415s/iter; left time: 554.4218s\n",
      "\titers: 300, epoch: 6 | loss: 0.0821968\n",
      "\tspeed: 0.0415s/iter; left time: 550.3302s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788260\n",
      "\tspeed: 0.0415s/iter; left time: 546.0061s\n",
      "\titers: 500, epoch: 6 | loss: 0.0736750\n",
      "\tspeed: 0.0415s/iter; left time: 541.9977s\n",
      "\titers: 600, epoch: 6 | loss: 0.0731835\n",
      "\tspeed: 0.0416s/iter; left time: 538.6953s\n",
      "\titers: 700, epoch: 6 | loss: 0.0804928\n",
      "\tspeed: 0.0416s/iter; left time: 534.4559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0761644\n",
      "\tspeed: 0.0415s/iter; left time: 529.8287s\n",
      "\titers: 900, epoch: 6 | loss: 0.0761853\n",
      "\tspeed: 0.0415s/iter; left time: 525.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0791167 Vali Loss: 0.0868076 Test Loss: 0.1432561\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0792830\n",
      "\tspeed: 0.1135s/iter; left time: 1425.4236s\n",
      "\titers: 200, epoch: 7 | loss: 0.0736702\n",
      "\tspeed: 0.0416s/iter; left time: 518.0054s\n",
      "\titers: 300, epoch: 7 | loss: 0.0709306\n",
      "\tspeed: 0.0416s/iter; left time: 513.8523s\n",
      "\titers: 400, epoch: 7 | loss: 0.0709575\n",
      "\tspeed: 0.0416s/iter; left time: 509.4117s\n",
      "\titers: 500, epoch: 7 | loss: 0.0705057\n",
      "\tspeed: 0.0416s/iter; left time: 506.0713s\n",
      "\titers: 600, epoch: 7 | loss: 0.0775761\n",
      "\tspeed: 0.0416s/iter; left time: 501.3616s\n",
      "\titers: 700, epoch: 7 | loss: 0.0763834\n",
      "\tspeed: 0.0416s/iter; left time: 497.1976s\n",
      "\titers: 800, epoch: 7 | loss: 0.0740358\n",
      "\tspeed: 0.0416s/iter; left time: 492.9521s\n",
      "\titers: 900, epoch: 7 | loss: 0.0736507\n",
      "\tspeed: 0.0416s/iter; left time: 488.6911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0762565 Vali Loss: 0.0854730 Test Loss: 0.1467339\n",
      "Validation loss decreased (0.086748 --> 0.085473).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729528\n",
      "\tspeed: 0.1162s/iter; left time: 1353.5860s\n",
      "\titers: 200, epoch: 8 | loss: 0.0769066\n",
      "\tspeed: 0.0415s/iter; left time: 479.8011s\n",
      "\titers: 300, epoch: 8 | loss: 0.0709053\n",
      "\tspeed: 0.0415s/iter; left time: 475.2179s\n",
      "\titers: 400, epoch: 8 | loss: 0.0712793\n",
      "\tspeed: 0.0415s/iter; left time: 471.3423s\n",
      "\titers: 500, epoch: 8 | loss: 0.0678615\n",
      "\tspeed: 0.0416s/iter; left time: 467.9069s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719967\n",
      "\tspeed: 0.0416s/iter; left time: 463.7415s\n",
      "\titers: 700, epoch: 8 | loss: 0.0767970\n",
      "\tspeed: 0.0416s/iter; left time: 459.7097s\n",
      "\titers: 800, epoch: 8 | loss: 0.0820074\n",
      "\tspeed: 0.0416s/iter; left time: 455.3627s\n",
      "\titers: 900, epoch: 8 | loss: 0.0792067\n",
      "\tspeed: 0.0416s/iter; left time: 451.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0729809 Vali Loss: 0.0853084 Test Loss: 0.1464679\n",
      "Validation loss decreased (0.085473 --> 0.085308).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0680521\n",
      "\tspeed: 0.1170s/iter; left time: 1257.4653s\n",
      "\titers: 200, epoch: 9 | loss: 0.0709191\n",
      "\tspeed: 0.0416s/iter; left time: 442.6350s\n",
      "\titers: 300, epoch: 9 | loss: 0.0691477\n",
      "\tspeed: 0.0416s/iter; left time: 438.5318s\n",
      "\titers: 400, epoch: 9 | loss: 0.0703399\n",
      "\tspeed: 0.0416s/iter; left time: 434.4762s\n",
      "\titers: 500, epoch: 9 | loss: 0.0686584\n",
      "\tspeed: 0.0416s/iter; left time: 430.2977s\n",
      "\titers: 600, epoch: 9 | loss: 0.0730306\n",
      "\tspeed: 0.0416s/iter; left time: 426.3882s\n",
      "\titers: 700, epoch: 9 | loss: 0.0717609\n",
      "\tspeed: 0.0416s/iter; left time: 422.0754s\n",
      "\titers: 800, epoch: 9 | loss: 0.0705330\n",
      "\tspeed: 0.0416s/iter; left time: 417.9879s\n",
      "\titers: 900, epoch: 9 | loss: 0.0692707\n",
      "\tspeed: 0.0416s/iter; left time: 413.4969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0702632 Vali Loss: 0.0855913 Test Loss: 0.1535130\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698408\n",
      "\tspeed: 0.1140s/iter; left time: 1121.8448s\n",
      "\titers: 200, epoch: 10 | loss: 0.0679938\n",
      "\tspeed: 0.0415s/iter; left time: 404.7121s\n",
      "\titers: 300, epoch: 10 | loss: 0.0702723\n",
      "\tspeed: 0.0415s/iter; left time: 400.3426s\n",
      "\titers: 400, epoch: 10 | loss: 0.0665980\n",
      "\tspeed: 0.0415s/iter; left time: 396.1537s\n",
      "\titers: 500, epoch: 10 | loss: 0.0640535\n",
      "\tspeed: 0.0415s/iter; left time: 392.4156s\n",
      "\titers: 600, epoch: 10 | loss: 0.0687447\n",
      "\tspeed: 0.0416s/iter; left time: 388.9352s\n",
      "\titers: 700, epoch: 10 | loss: 0.0636232\n",
      "\tspeed: 0.0415s/iter; left time: 383.7071s\n",
      "\titers: 800, epoch: 10 | loss: 0.0637815\n",
      "\tspeed: 0.0415s/iter; left time: 379.4254s\n",
      "\titers: 900, epoch: 10 | loss: 0.0650070\n",
      "\tspeed: 0.0415s/iter; left time: 375.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0675522 Vali Loss: 0.0878237 Test Loss: 0.1574765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680077\n",
      "\tspeed: 0.1152s/iter; left time: 1029.7413s\n",
      "\titers: 200, epoch: 11 | loss: 0.0625419\n",
      "\tspeed: 0.0416s/iter; left time: 367.5794s\n",
      "\titers: 300, epoch: 11 | loss: 0.0644673\n",
      "\tspeed: 0.0415s/iter; left time: 363.0404s\n",
      "\titers: 400, epoch: 11 | loss: 0.0685582\n",
      "\tspeed: 0.0415s/iter; left time: 358.5762s\n",
      "\titers: 500, epoch: 11 | loss: 0.0674249\n",
      "\tspeed: 0.0415s/iter; left time: 354.2847s\n",
      "\titers: 600, epoch: 11 | loss: 0.0653215\n",
      "\tspeed: 0.0415s/iter; left time: 350.3671s\n",
      "\titers: 700, epoch: 11 | loss: 0.0610816\n",
      "\tspeed: 0.0415s/iter; left time: 346.5466s\n",
      "\titers: 800, epoch: 11 | loss: 0.0660871\n",
      "\tspeed: 0.0415s/iter; left time: 342.1604s\n",
      "\titers: 900, epoch: 11 | loss: 0.0601333\n",
      "\tspeed: 0.0415s/iter; left time: 337.9419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0652383 Vali Loss: 0.0865308 Test Loss: 0.1594289\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0594552\n",
      "\tspeed: 0.1140s/iter; left time: 916.4326s\n",
      "\titers: 200, epoch: 12 | loss: 0.0654352\n",
      "\tspeed: 0.0415s/iter; left time: 329.3632s\n",
      "\titers: 300, epoch: 12 | loss: 0.0618489\n",
      "\tspeed: 0.0415s/iter; left time: 325.2592s\n",
      "\titers: 400, epoch: 12 | loss: 0.0673705\n",
      "\tspeed: 0.0415s/iter; left time: 321.0622s\n",
      "\titers: 500, epoch: 12 | loss: 0.0666839\n",
      "\tspeed: 0.0415s/iter; left time: 316.9643s\n",
      "\titers: 600, epoch: 12 | loss: 0.0667761\n",
      "\tspeed: 0.0415s/iter; left time: 312.8686s\n",
      "\titers: 700, epoch: 12 | loss: 0.0607388\n",
      "\tspeed: 0.0415s/iter; left time: 308.6200s\n",
      "\titers: 800, epoch: 12 | loss: 0.0608705\n",
      "\tspeed: 0.0415s/iter; left time: 304.4714s\n",
      "\titers: 900, epoch: 12 | loss: 0.0617118\n",
      "\tspeed: 0.0415s/iter; left time: 300.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0632101 Vali Loss: 0.0859873 Test Loss: 0.1564025\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0644529\n",
      "\tspeed: 0.1137s/iter; left time: 811.0558s\n",
      "\titers: 200, epoch: 13 | loss: 0.0554359\n",
      "\tspeed: 0.0416s/iter; left time: 292.4215s\n",
      "\titers: 300, epoch: 13 | loss: 0.0615502\n",
      "\tspeed: 0.0416s/iter; left time: 288.4158s\n",
      "\titers: 400, epoch: 13 | loss: 0.0606781\n",
      "\tspeed: 0.0416s/iter; left time: 284.2330s\n",
      "\titers: 500, epoch: 13 | loss: 0.0597327\n",
      "\tspeed: 0.0416s/iter; left time: 280.1644s\n",
      "\titers: 600, epoch: 13 | loss: 0.0621458\n",
      "\tspeed: 0.0416s/iter; left time: 275.8850s\n",
      "\titers: 700, epoch: 13 | loss: 0.0588029\n",
      "\tspeed: 0.0416s/iter; left time: 271.6671s\n",
      "\titers: 800, epoch: 13 | loss: 0.0633195\n",
      "\tspeed: 0.0416s/iter; left time: 267.5730s\n",
      "\titers: 900, epoch: 13 | loss: 0.0699742\n",
      "\tspeed: 0.0416s/iter; left time: 263.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0609191 Vali Loss: 0.0863986 Test Loss: 0.1637643\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_96_ES_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.05644026771187782, rmse:0.2375716120004654, mae:0.14639423787593842, rse:0.6979138851165771\n",
      "Intermediate time for ES and pred_len 96: 00h:19m:00.42s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_96_168_ES', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2492964\n",
      "\tspeed: 0.0712s/iter; left time: 1277.1901s\n",
      "\titers: 200, epoch: 1 | loss: 0.2172240\n",
      "\tspeed: 0.0504s/iter; left time: 899.7993s\n",
      "\titers: 300, epoch: 1 | loss: 0.2131199\n",
      "\tspeed: 0.0505s/iter; left time: 896.4523s\n",
      "\titers: 400, epoch: 1 | loss: 0.2037690\n",
      "\tspeed: 0.0505s/iter; left time: 891.4202s\n",
      "\titers: 500, epoch: 1 | loss: 0.1987259\n",
      "\tspeed: 0.0505s/iter; left time: 885.4587s\n",
      "\titers: 600, epoch: 1 | loss: 0.1937901\n",
      "\tspeed: 0.0505s/iter; left time: 880.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.1921680\n",
      "\tspeed: 0.0506s/iter; left time: 876.8671s\n",
      "\titers: 800, epoch: 1 | loss: 0.1843900\n",
      "\tspeed: 0.0506s/iter; left time: 871.9005s\n",
      "\titers: 900, epoch: 1 | loss: 0.1844022\n",
      "\tspeed: 0.0505s/iter; left time: 865.9526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 902 | Train Loss: 0.2083722 Vali Loss: 0.1819980 Test Loss: 0.2220403\n",
      "Validation loss decreased (inf --> 0.181998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1653086\n",
      "\tspeed: 0.1417s/iter; left time: 2413.8571s\n",
      "\titers: 200, epoch: 2 | loss: 0.1531178\n",
      "\tspeed: 0.0504s/iter; left time: 853.2940s\n",
      "\titers: 300, epoch: 2 | loss: 0.1426768\n",
      "\tspeed: 0.0504s/iter; left time: 849.1057s\n",
      "\titers: 400, epoch: 2 | loss: 0.1295031\n",
      "\tspeed: 0.0504s/iter; left time: 844.0830s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160058\n",
      "\tspeed: 0.0504s/iter; left time: 838.5864s\n",
      "\titers: 600, epoch: 2 | loss: 0.1129280\n",
      "\tspeed: 0.0504s/iter; left time: 834.3003s\n",
      "\titers: 700, epoch: 2 | loss: 0.1077385\n",
      "\tspeed: 0.0504s/iter; left time: 827.7760s\n",
      "\titers: 800, epoch: 2 | loss: 0.1035756\n",
      "\tspeed: 0.0504s/iter; left time: 824.1451s\n",
      "\titers: 900, epoch: 2 | loss: 0.0996339\n",
      "\tspeed: 0.0504s/iter; left time: 818.4497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1298264 Vali Loss: 0.1035160 Test Loss: 0.1475300\n",
      "Validation loss decreased (0.181998 --> 0.103516).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1033866\n",
      "\tspeed: 0.1412s/iter; left time: 2278.6888s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975054\n",
      "\tspeed: 0.0505s/iter; left time: 809.1720s\n",
      "\titers: 300, epoch: 3 | loss: 0.0915680\n",
      "\tspeed: 0.0504s/iter; left time: 803.1125s\n",
      "\titers: 400, epoch: 3 | loss: 0.0927011\n",
      "\tspeed: 0.0504s/iter; left time: 798.1891s\n",
      "\titers: 500, epoch: 3 | loss: 0.0954466\n",
      "\tspeed: 0.0504s/iter; left time: 793.2339s\n",
      "\titers: 600, epoch: 3 | loss: 0.1021520\n",
      "\tspeed: 0.0504s/iter; left time: 788.3923s\n",
      "\titers: 700, epoch: 3 | loss: 0.0969066\n",
      "\tspeed: 0.0504s/iter; left time: 783.1803s\n",
      "\titers: 800, epoch: 3 | loss: 0.0930721\n",
      "\tspeed: 0.0504s/iter; left time: 778.3916s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931172\n",
      "\tspeed: 0.0504s/iter; left time: 773.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0972800 Vali Loss: 0.0986148 Test Loss: 0.1403995\n",
      "Validation loss decreased (0.103516 --> 0.098615).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0925042\n",
      "\tspeed: 0.1410s/iter; left time: 2147.4261s\n",
      "\titers: 200, epoch: 4 | loss: 0.0977211\n",
      "\tspeed: 0.0504s/iter; left time: 763.3308s\n",
      "\titers: 300, epoch: 4 | loss: 0.0909184\n",
      "\tspeed: 0.0504s/iter; left time: 758.0967s\n",
      "\titers: 400, epoch: 4 | loss: 0.0948582\n",
      "\tspeed: 0.0505s/iter; left time: 753.4728s\n",
      "\titers: 500, epoch: 4 | loss: 0.0912337\n",
      "\tspeed: 0.0504s/iter; left time: 748.1623s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878440\n",
      "\tspeed: 0.0504s/iter; left time: 743.1452s\n",
      "\titers: 700, epoch: 4 | loss: 0.0873194\n",
      "\tspeed: 0.0504s/iter; left time: 737.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.0957726\n",
      "\tspeed: 0.0504s/iter; left time: 733.0270s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906419\n",
      "\tspeed: 0.0504s/iter; left time: 727.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0912431 Vali Loss: 0.0933874 Test Loss: 0.1351360\n",
      "Validation loss decreased (0.098615 --> 0.093387).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0860944\n",
      "\tspeed: 0.1425s/iter; left time: 2042.0201s\n",
      "\titers: 200, epoch: 5 | loss: 0.0850665\n",
      "\tspeed: 0.0504s/iter; left time: 717.2623s\n",
      "\titers: 300, epoch: 5 | loss: 0.0901280\n",
      "\tspeed: 0.0504s/iter; left time: 712.9415s\n",
      "\titers: 400, epoch: 5 | loss: 0.0854654\n",
      "\tspeed: 0.0506s/iter; left time: 709.8097s\n",
      "\titers: 500, epoch: 5 | loss: 0.0851015\n",
      "\tspeed: 0.0506s/iter; left time: 705.2464s\n",
      "\titers: 600, epoch: 5 | loss: 0.0846908\n",
      "\tspeed: 0.0506s/iter; left time: 699.8147s\n",
      "\titers: 700, epoch: 5 | loss: 0.0850851\n",
      "\tspeed: 0.0506s/iter; left time: 694.3147s\n",
      "\titers: 800, epoch: 5 | loss: 0.0879443\n",
      "\tspeed: 0.0504s/iter; left time: 687.0974s\n",
      "\titers: 900, epoch: 5 | loss: 0.0815824\n",
      "\tspeed: 0.0504s/iter; left time: 682.0890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 902 | Train Loss: 0.0865540 Vali Loss: 0.0953768 Test Loss: 0.1449964\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0880546\n",
      "\tspeed: 0.1384s/iter; left time: 1858.1879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0880220\n",
      "\tspeed: 0.0504s/iter; left time: 672.1573s\n",
      "\titers: 300, epoch: 6 | loss: 0.0851828\n",
      "\tspeed: 0.0504s/iter; left time: 667.0128s\n",
      "\titers: 400, epoch: 6 | loss: 0.0814955\n",
      "\tspeed: 0.0504s/iter; left time: 662.3892s\n",
      "\titers: 500, epoch: 6 | loss: 0.0808422\n",
      "\tspeed: 0.0504s/iter; left time: 656.7175s\n",
      "\titers: 600, epoch: 6 | loss: 0.0843075\n",
      "\tspeed: 0.0504s/iter; left time: 652.3007s\n",
      "\titers: 700, epoch: 6 | loss: 0.0827094\n",
      "\tspeed: 0.0505s/iter; left time: 648.1374s\n",
      "\titers: 800, epoch: 6 | loss: 0.0847130\n",
      "\tspeed: 0.0504s/iter; left time: 641.5816s\n",
      "\titers: 900, epoch: 6 | loss: 0.0832033\n",
      "\tspeed: 0.0504s/iter; left time: 636.7428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0824581 Vali Loss: 0.0938004 Test Loss: 0.1515495\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0807643\n",
      "\tspeed: 0.1365s/iter; left time: 1709.5910s\n",
      "\titers: 200, epoch: 7 | loss: 0.0733612\n",
      "\tspeed: 0.0504s/iter; left time: 626.5840s\n",
      "\titers: 300, epoch: 7 | loss: 0.0787084\n",
      "\tspeed: 0.0504s/iter; left time: 621.0739s\n",
      "\titers: 400, epoch: 7 | loss: 0.0756619\n",
      "\tspeed: 0.0504s/iter; left time: 616.5083s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772191\n",
      "\tspeed: 0.0504s/iter; left time: 611.6287s\n",
      "\titers: 600, epoch: 7 | loss: 0.0766708\n",
      "\tspeed: 0.0505s/iter; left time: 606.9050s\n",
      "\titers: 700, epoch: 7 | loss: 0.0778410\n",
      "\tspeed: 0.0504s/iter; left time: 601.0559s\n",
      "\titers: 800, epoch: 7 | loss: 0.0783041\n",
      "\tspeed: 0.0504s/iter; left time: 596.3140s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758551\n",
      "\tspeed: 0.0505s/iter; left time: 592.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0786968 Vali Loss: 0.0945030 Test Loss: 0.1575315\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0765909\n",
      "\tspeed: 0.1369s/iter; left time: 1591.5120s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756120\n",
      "\tspeed: 0.0504s/iter; left time: 580.6304s\n",
      "\titers: 300, epoch: 8 | loss: 0.0762664\n",
      "\tspeed: 0.0504s/iter; left time: 575.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0798623\n",
      "\tspeed: 0.0504s/iter; left time: 570.8086s\n",
      "\titers: 500, epoch: 8 | loss: 0.0781074\n",
      "\tspeed: 0.0505s/iter; left time: 566.7603s\n",
      "\titers: 600, epoch: 8 | loss: 0.0719266\n",
      "\tspeed: 0.0504s/iter; left time: 561.2141s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752170\n",
      "\tspeed: 0.0504s/iter; left time: 555.5328s\n",
      "\titers: 800, epoch: 8 | loss: 0.0754173\n",
      "\tspeed: 0.0505s/iter; left time: 552.1497s\n",
      "\titers: 900, epoch: 8 | loss: 0.0684457\n",
      "\tspeed: 0.0505s/iter; left time: 546.4118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0753874 Vali Loss: 0.0934107 Test Loss: 0.1613924\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0704094\n",
      "\tspeed: 0.1380s/iter; left time: 1480.5162s\n",
      "\titers: 200, epoch: 9 | loss: 0.0717454\n",
      "\tspeed: 0.0504s/iter; left time: 535.8080s\n",
      "\titers: 300, epoch: 9 | loss: 0.0741613\n",
      "\tspeed: 0.0504s/iter; left time: 530.6156s\n",
      "\titers: 400, epoch: 9 | loss: 0.0742769\n",
      "\tspeed: 0.0504s/iter; left time: 525.9377s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733934\n",
      "\tspeed: 0.0504s/iter; left time: 520.7536s\n",
      "\titers: 600, epoch: 9 | loss: 0.0716762\n",
      "\tspeed: 0.0505s/iter; left time: 515.9702s\n",
      "\titers: 700, epoch: 9 | loss: 0.0709206\n",
      "\tspeed: 0.0504s/iter; left time: 510.4875s\n",
      "\titers: 800, epoch: 9 | loss: 0.0728439\n",
      "\tspeed: 0.0504s/iter; left time: 505.7294s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723040\n",
      "\tspeed: 0.0504s/iter; left time: 500.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0723324 Vali Loss: 0.0969553 Test Loss: 0.1759281\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04438893124461174, rmse:0.2106868028640747, mae:0.13518424332141876, rse:0.6188546419143677\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2389837\n",
      "\tspeed: 0.0525s/iter; left time: 941.8531s\n",
      "\titers: 200, epoch: 1 | loss: 0.2256297\n",
      "\tspeed: 0.0505s/iter; left time: 901.0100s\n",
      "\titers: 300, epoch: 1 | loss: 0.2167884\n",
      "\tspeed: 0.0504s/iter; left time: 893.7508s\n",
      "\titers: 400, epoch: 1 | loss: 0.2074835\n",
      "\tspeed: 0.0505s/iter; left time: 891.2074s\n",
      "\titers: 500, epoch: 1 | loss: 0.2109853\n",
      "\tspeed: 0.0505s/iter; left time: 885.3476s\n",
      "\titers: 600, epoch: 1 | loss: 0.2032430\n",
      "\tspeed: 0.0504s/iter; left time: 879.2211s\n",
      "\titers: 700, epoch: 1 | loss: 0.1951404\n",
      "\tspeed: 0.0505s/iter; left time: 875.8518s\n",
      "\titers: 800, epoch: 1 | loss: 0.1859338\n",
      "\tspeed: 0.0504s/iter; left time: 868.6547s\n",
      "\titers: 900, epoch: 1 | loss: 0.1889469\n",
      "\tspeed: 0.0504s/iter; left time: 864.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.2128992 Vali Loss: 0.1829299 Test Loss: 0.2247479\n",
      "Validation loss decreased (inf --> 0.182930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1616415\n",
      "\tspeed: 0.1418s/iter; left time: 2415.6081s\n",
      "\titers: 200, epoch: 2 | loss: 0.1435303\n",
      "\tspeed: 0.0504s/iter; left time: 854.1932s\n",
      "\titers: 300, epoch: 2 | loss: 0.1445888\n",
      "\tspeed: 0.0504s/iter; left time: 849.3128s\n",
      "\titers: 400, epoch: 2 | loss: 0.1351373\n",
      "\tspeed: 0.0504s/iter; left time: 843.8295s\n",
      "\titers: 500, epoch: 2 | loss: 0.1191210\n",
      "\tspeed: 0.0504s/iter; left time: 839.0269s\n",
      "\titers: 600, epoch: 2 | loss: 0.1166453\n",
      "\tspeed: 0.0505s/iter; left time: 834.4495s\n",
      "\titers: 700, epoch: 2 | loss: 0.1043696\n",
      "\tspeed: 0.0505s/iter; left time: 829.7016s\n",
      "\titers: 800, epoch: 2 | loss: 0.0989133\n",
      "\tspeed: 0.0505s/iter; left time: 824.4989s\n",
      "\titers: 900, epoch: 2 | loss: 0.1004393\n",
      "\tspeed: 0.0504s/iter; left time: 819.0569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.80s\n",
      "Steps: 902 | Train Loss: 0.1309356 Vali Loss: 0.1029980 Test Loss: 0.1407493\n",
      "Validation loss decreased (0.182930 --> 0.102998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1012470\n",
      "\tspeed: 0.1409s/iter; left time: 2274.3233s\n",
      "\titers: 200, epoch: 3 | loss: 0.0983157\n",
      "\tspeed: 0.0505s/iter; left time: 809.2159s\n",
      "\titers: 300, epoch: 3 | loss: 0.0947418\n",
      "\tspeed: 0.0504s/iter; left time: 802.6096s\n",
      "\titers: 400, epoch: 3 | loss: 0.0990990\n",
      "\tspeed: 0.0504s/iter; left time: 798.1440s\n",
      "\titers: 500, epoch: 3 | loss: 0.0928705\n",
      "\tspeed: 0.0505s/iter; left time: 795.0857s\n",
      "\titers: 600, epoch: 3 | loss: 0.0926267\n",
      "\tspeed: 0.0505s/iter; left time: 788.9751s\n",
      "\titers: 700, epoch: 3 | loss: 0.0929120\n",
      "\tspeed: 0.0505s/iter; left time: 784.3314s\n",
      "\titers: 800, epoch: 3 | loss: 0.0964417\n",
      "\tspeed: 0.0505s/iter; left time: 778.9006s\n",
      "\titers: 900, epoch: 3 | loss: 0.0912257\n",
      "\tspeed: 0.0505s/iter; left time: 773.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0973411 Vali Loss: 0.0984464 Test Loss: 0.1338115\n",
      "Validation loss decreased (0.102998 --> 0.098446).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0919027\n",
      "\tspeed: 0.1410s/iter; left time: 2148.1578s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967809\n",
      "\tspeed: 0.0504s/iter; left time: 762.2060s\n",
      "\titers: 300, epoch: 4 | loss: 0.0983866\n",
      "\tspeed: 0.0504s/iter; left time: 758.0238s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937310\n",
      "\tspeed: 0.0504s/iter; left time: 752.4804s\n",
      "\titers: 500, epoch: 4 | loss: 0.0924264\n",
      "\tspeed: 0.0504s/iter; left time: 747.6431s\n",
      "\titers: 600, epoch: 4 | loss: 0.0878538\n",
      "\tspeed: 0.0504s/iter; left time: 742.4975s\n",
      "\titers: 700, epoch: 4 | loss: 0.0897520\n",
      "\tspeed: 0.0504s/iter; left time: 737.5460s\n",
      "\titers: 800, epoch: 4 | loss: 0.0854635\n",
      "\tspeed: 0.0505s/iter; left time: 734.1163s\n",
      "\titers: 900, epoch: 4 | loss: 0.0885362\n",
      "\tspeed: 0.0504s/iter; left time: 728.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0909175 Vali Loss: 0.0953376 Test Loss: 0.1429246\n",
      "Validation loss decreased (0.098446 --> 0.095338).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0883355\n",
      "\tspeed: 0.1403s/iter; left time: 2010.8001s\n",
      "\titers: 200, epoch: 5 | loss: 0.0869098\n",
      "\tspeed: 0.0504s/iter; left time: 717.2617s\n",
      "\titers: 300, epoch: 5 | loss: 0.0865536\n",
      "\tspeed: 0.0504s/iter; left time: 712.0929s\n",
      "\titers: 400, epoch: 5 | loss: 0.0860558\n",
      "\tspeed: 0.0504s/iter; left time: 707.2679s\n",
      "\titers: 500, epoch: 5 | loss: 0.0856702\n",
      "\tspeed: 0.0504s/iter; left time: 702.2311s\n",
      "\titers: 600, epoch: 5 | loss: 0.0879596\n",
      "\tspeed: 0.0504s/iter; left time: 697.0911s\n",
      "\titers: 700, epoch: 5 | loss: 0.0895608\n",
      "\tspeed: 0.0504s/iter; left time: 691.9814s\n",
      "\titers: 800, epoch: 5 | loss: 0.0870850\n",
      "\tspeed: 0.0504s/iter; left time: 687.2620s\n",
      "\titers: 900, epoch: 5 | loss: 0.0834234\n",
      "\tspeed: 0.0504s/iter; left time: 682.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0860294 Vali Loss: 0.0938435 Test Loss: 0.1573096\n",
      "Validation loss decreased (0.095338 --> 0.093843).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0819926\n",
      "\tspeed: 0.1410s/iter; left time: 1893.2018s\n",
      "\titers: 200, epoch: 6 | loss: 0.0884785\n",
      "\tspeed: 0.0505s/iter; left time: 673.4415s\n",
      "\titers: 300, epoch: 6 | loss: 0.0834609\n",
      "\tspeed: 0.0505s/iter; left time: 667.7094s\n",
      "\titers: 400, epoch: 6 | loss: 0.0848006\n",
      "\tspeed: 0.0504s/iter; left time: 662.3203s\n",
      "\titers: 500, epoch: 6 | loss: 0.0842216\n",
      "\tspeed: 0.0504s/iter; left time: 656.7688s\n",
      "\titers: 600, epoch: 6 | loss: 0.0790967\n",
      "\tspeed: 0.0505s/iter; left time: 653.3962s\n",
      "\titers: 700, epoch: 6 | loss: 0.0801027\n",
      "\tspeed: 0.0505s/iter; left time: 648.2780s\n",
      "\titers: 800, epoch: 6 | loss: 0.0799710\n",
      "\tspeed: 0.0504s/iter; left time: 642.1083s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813835\n",
      "\tspeed: 0.0506s/iter; left time: 638.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.82s\n",
      "Steps: 902 | Train Loss: 0.0821843 Vali Loss: 0.0972141 Test Loss: 0.1531661\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797309\n",
      "\tspeed: 0.1377s/iter; left time: 1725.4798s\n",
      "\titers: 200, epoch: 7 | loss: 0.0862694\n",
      "\tspeed: 0.0511s/iter; left time: 635.3108s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818903\n",
      "\tspeed: 0.0511s/iter; left time: 629.6545s\n",
      "\titers: 400, epoch: 7 | loss: 0.0793917\n",
      "\tspeed: 0.0511s/iter; left time: 624.5239s\n",
      "\titers: 500, epoch: 7 | loss: 0.0825225\n",
      "\tspeed: 0.0511s/iter; left time: 619.4273s\n",
      "\titers: 600, epoch: 7 | loss: 0.0773069\n",
      "\tspeed: 0.0511s/iter; left time: 614.2800s\n",
      "\titers: 700, epoch: 7 | loss: 0.0710885\n",
      "\tspeed: 0.0506s/iter; left time: 603.8980s\n",
      "\titers: 800, epoch: 7 | loss: 0.0778921\n",
      "\tspeed: 0.0504s/iter; left time: 596.4990s\n",
      "\titers: 900, epoch: 7 | loss: 0.0772341\n",
      "\tspeed: 0.0504s/iter; left time: 590.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.15s\n",
      "Steps: 902 | Train Loss: 0.0783491 Vali Loss: 0.0925858 Test Loss: 0.1583009\n",
      "Validation loss decreased (0.093843 --> 0.092586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0754644\n",
      "\tspeed: 0.1407s/iter; left time: 1635.5573s\n",
      "\titers: 200, epoch: 8 | loss: 0.0817999\n",
      "\tspeed: 0.0511s/iter; left time: 589.0371s\n",
      "\titers: 300, epoch: 8 | loss: 0.0772513\n",
      "\tspeed: 0.0511s/iter; left time: 583.9912s\n",
      "\titers: 400, epoch: 8 | loss: 0.0731126\n",
      "\tspeed: 0.0506s/iter; left time: 573.3439s\n",
      "\titers: 500, epoch: 8 | loss: 0.0765568\n",
      "\tspeed: 0.0506s/iter; left time: 567.7213s\n",
      "\titers: 600, epoch: 8 | loss: 0.0775171\n",
      "\tspeed: 0.0505s/iter; left time: 562.0332s\n",
      "\titers: 700, epoch: 8 | loss: 0.0783013\n",
      "\tspeed: 0.0505s/iter; left time: 556.3621s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769860\n",
      "\tspeed: 0.0504s/iter; left time: 550.9337s\n",
      "\titers: 900, epoch: 8 | loss: 0.0720528\n",
      "\tspeed: 0.0504s/iter; left time: 546.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0750094 Vali Loss: 0.0931359 Test Loss: 0.1548578\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725504\n",
      "\tspeed: 0.1379s/iter; left time: 1478.9149s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699559\n",
      "\tspeed: 0.0504s/iter; left time: 535.1801s\n",
      "\titers: 300, epoch: 9 | loss: 0.0776160\n",
      "\tspeed: 0.0504s/iter; left time: 530.1342s\n",
      "\titers: 400, epoch: 9 | loss: 0.0731432\n",
      "\tspeed: 0.0504s/iter; left time: 525.0941s\n",
      "\titers: 500, epoch: 9 | loss: 0.0761598\n",
      "\tspeed: 0.0504s/iter; left time: 520.3729s\n",
      "\titers: 600, epoch: 9 | loss: 0.0740233\n",
      "\tspeed: 0.0504s/iter; left time: 515.5336s\n",
      "\titers: 700, epoch: 9 | loss: 0.0749604\n",
      "\tspeed: 0.0504s/iter; left time: 510.5437s\n",
      "\titers: 800, epoch: 9 | loss: 0.0692300\n",
      "\tspeed: 0.0504s/iter; left time: 505.5818s\n",
      "\titers: 900, epoch: 9 | loss: 0.0723800\n",
      "\tspeed: 0.0505s/iter; left time: 500.9820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0717975 Vali Loss: 0.0956336 Test Loss: 0.1646968\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0664784\n",
      "\tspeed: 0.1388s/iter; left time: 1363.0090s\n",
      "\titers: 200, epoch: 10 | loss: 0.0747654\n",
      "\tspeed: 0.0504s/iter; left time: 489.7599s\n",
      "\titers: 300, epoch: 10 | loss: 0.0689450\n",
      "\tspeed: 0.0504s/iter; left time: 485.1702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0679197\n",
      "\tspeed: 0.0504s/iter; left time: 480.0177s\n",
      "\titers: 500, epoch: 10 | loss: 0.0737662\n",
      "\tspeed: 0.0505s/iter; left time: 475.8619s\n",
      "\titers: 600, epoch: 10 | loss: 0.0641387\n",
      "\tspeed: 0.0504s/iter; left time: 470.0892s\n",
      "\titers: 700, epoch: 10 | loss: 0.0697696\n",
      "\tspeed: 0.0504s/iter; left time: 464.7363s\n",
      "\titers: 800, epoch: 10 | loss: 0.0677867\n",
      "\tspeed: 0.0504s/iter; left time: 459.8094s\n",
      "\titers: 900, epoch: 10 | loss: 0.0695094\n",
      "\tspeed: 0.0504s/iter; left time: 454.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 902 | Train Loss: 0.0689554 Vali Loss: 0.0961502 Test Loss: 0.1730712\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672925\n",
      "\tspeed: 0.1373s/iter; left time: 1224.9632s\n",
      "\titers: 200, epoch: 11 | loss: 0.0610949\n",
      "\tspeed: 0.0505s/iter; left time: 445.6581s\n",
      "\titers: 300, epoch: 11 | loss: 0.0667393\n",
      "\tspeed: 0.0505s/iter; left time: 440.8279s\n",
      "\titers: 400, epoch: 11 | loss: 0.0678346\n",
      "\tspeed: 0.0505s/iter; left time: 435.7379s\n",
      "\titers: 500, epoch: 11 | loss: 0.0672898\n",
      "\tspeed: 0.0505s/iter; left time: 429.9508s\n",
      "\titers: 600, epoch: 11 | loss: 0.0637237\n",
      "\tspeed: 0.0504s/iter; left time: 424.2824s\n",
      "\titers: 700, epoch: 11 | loss: 0.0640562\n",
      "\tspeed: 0.0504s/iter; left time: 419.1978s\n",
      "\titers: 800, epoch: 11 | loss: 0.0617589\n",
      "\tspeed: 0.0504s/iter; left time: 414.6768s\n",
      "\titers: 900, epoch: 11 | loss: 0.0612631\n",
      "\tspeed: 0.0504s/iter; left time: 409.3253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0663154 Vali Loss: 0.0945666 Test Loss: 0.1649144\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0646060\n",
      "\tspeed: 0.1378s/iter; left time: 1104.9374s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642981\n",
      "\tspeed: 0.0504s/iter; left time: 399.1010s\n",
      "\titers: 300, epoch: 12 | loss: 0.0621096\n",
      "\tspeed: 0.0504s/iter; left time: 394.0479s\n",
      "\titers: 400, epoch: 12 | loss: 0.0637253\n",
      "\tspeed: 0.0504s/iter; left time: 388.9243s\n",
      "\titers: 500, epoch: 12 | loss: 0.0630992\n",
      "\tspeed: 0.0504s/iter; left time: 383.9630s\n",
      "\titers: 600, epoch: 12 | loss: 0.0635810\n",
      "\tspeed: 0.0504s/iter; left time: 378.8416s\n",
      "\titers: 700, epoch: 12 | loss: 0.0700417\n",
      "\tspeed: 0.0504s/iter; left time: 373.9896s\n",
      "\titers: 800, epoch: 12 | loss: 0.0633632\n",
      "\tspeed: 0.0504s/iter; left time: 368.9444s\n",
      "\titers: 900, epoch: 12 | loss: 0.0606417\n",
      "\tspeed: 0.0504s/iter; left time: 363.8252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 902 | Train Loss: 0.0640580 Vali Loss: 0.0962546 Test Loss: 0.1658105\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_96_168_ES_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.060231514275074005, rmse:0.24542109668254852, mae:0.15826410055160522, rse:0.7208803296089172\n",
      "Intermediate time for ES and pred_len 168: 00h:19m:19.39s\n",
      "Intermediate time for ES: 00h:56m:56.97s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_24_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1754016\n",
      "\tspeed: 0.0559s/iter; left time: 1007.9014s\n",
      "\titers: 200, epoch: 1 | loss: 0.1718795\n",
      "\tspeed: 0.0346s/iter; left time: 619.4958s\n",
      "\titers: 300, epoch: 1 | loss: 0.1623744\n",
      "\tspeed: 0.0345s/iter; left time: 615.5059s\n",
      "\titers: 400, epoch: 1 | loss: 0.1527693\n",
      "\tspeed: 0.0345s/iter; left time: 612.0520s\n",
      "\titers: 500, epoch: 1 | loss: 0.1545722\n",
      "\tspeed: 0.0345s/iter; left time: 608.5005s\n",
      "\titers: 600, epoch: 1 | loss: 0.1503175\n",
      "\tspeed: 0.0345s/iter; left time: 605.0299s\n",
      "\titers: 700, epoch: 1 | loss: 0.1476793\n",
      "\tspeed: 0.0345s/iter; left time: 601.1617s\n",
      "\titers: 800, epoch: 1 | loss: 0.1516313\n",
      "\tspeed: 0.0345s/iter; left time: 597.7319s\n",
      "\titers: 900, epoch: 1 | loss: 0.1358661\n",
      "\tspeed: 0.0345s/iter; left time: 593.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.99s\n",
      "Steps: 906 | Train Loss: 0.1572264 Vali Loss: 0.1465191 Test Loss: 0.1681759\n",
      "Validation loss decreased (inf --> 0.146519).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1367733\n",
      "\tspeed: 0.0988s/iter; left time: 1691.4399s\n",
      "\titers: 200, epoch: 2 | loss: 0.0841815\n",
      "\tspeed: 0.0345s/iter; left time: 586.9984s\n",
      "\titers: 300, epoch: 2 | loss: 0.0651053\n",
      "\tspeed: 0.0345s/iter; left time: 583.7436s\n",
      "\titers: 400, epoch: 2 | loss: 0.0618266\n",
      "\tspeed: 0.0345s/iter; left time: 579.9539s\n",
      "\titers: 500, epoch: 2 | loss: 0.0634880\n",
      "\tspeed: 0.0342s/iter; left time: 571.3485s\n",
      "\titers: 600, epoch: 2 | loss: 0.0748803\n",
      "\tspeed: 0.0339s/iter; left time: 563.6168s\n",
      "\titers: 700, epoch: 2 | loss: 0.0605217\n",
      "\tspeed: 0.0339s/iter; left time: 559.9852s\n",
      "\titers: 800, epoch: 2 | loss: 0.0677919\n",
      "\tspeed: 0.0339s/iter; left time: 557.1336s\n",
      "\titers: 900, epoch: 2 | loss: 0.0628310\n",
      "\tspeed: 0.0339s/iter; left time: 553.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.31s\n",
      "Steps: 906 | Train Loss: 0.0795633 Vali Loss: 0.0664881 Test Loss: 0.0766027\n",
      "Validation loss decreased (0.146519 --> 0.066488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0596052\n",
      "\tspeed: 0.0963s/iter; left time: 1561.5185s\n",
      "\titers: 200, epoch: 3 | loss: 0.0513732\n",
      "\tspeed: 0.0339s/iter; left time: 546.1884s\n",
      "\titers: 300, epoch: 3 | loss: 0.0622984\n",
      "\tspeed: 0.0339s/iter; left time: 542.8349s\n",
      "\titers: 400, epoch: 3 | loss: 0.0550099\n",
      "\tspeed: 0.0339s/iter; left time: 539.8263s\n",
      "\titers: 500, epoch: 3 | loss: 0.0614815\n",
      "\tspeed: 0.0339s/iter; left time: 536.5546s\n",
      "\titers: 600, epoch: 3 | loss: 0.0572914\n",
      "\tspeed: 0.0340s/iter; left time: 533.4422s\n",
      "\titers: 700, epoch: 3 | loss: 0.0545936\n",
      "\tspeed: 0.0339s/iter; left time: 529.3358s\n",
      "\titers: 800, epoch: 3 | loss: 0.0497180\n",
      "\tspeed: 0.0340s/iter; left time: 527.2602s\n",
      "\titers: 900, epoch: 3 | loss: 0.0469406\n",
      "\tspeed: 0.0340s/iter; left time: 523.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0554530 Vali Loss: 0.0634343 Test Loss: 0.0724585\n",
      "Validation loss decreased (0.066488 --> 0.063434).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0495711\n",
      "\tspeed: 0.0963s/iter; left time: 1474.0030s\n",
      "\titers: 200, epoch: 4 | loss: 0.0469635\n",
      "\tspeed: 0.0340s/iter; left time: 516.6050s\n",
      "\titers: 300, epoch: 4 | loss: 0.0530830\n",
      "\tspeed: 0.0340s/iter; left time: 513.3490s\n",
      "\titers: 400, epoch: 4 | loss: 0.0561377\n",
      "\tspeed: 0.0340s/iter; left time: 509.8152s\n",
      "\titers: 500, epoch: 4 | loss: 0.0476814\n",
      "\tspeed: 0.0340s/iter; left time: 507.0071s\n",
      "\titers: 600, epoch: 4 | loss: 0.0456952\n",
      "\tspeed: 0.0340s/iter; left time: 503.4136s\n",
      "\titers: 700, epoch: 4 | loss: 0.0571596\n",
      "\tspeed: 0.0341s/iter; left time: 500.8640s\n",
      "\titers: 800, epoch: 4 | loss: 0.0540078\n",
      "\tspeed: 0.0340s/iter; left time: 496.0978s\n",
      "\titers: 900, epoch: 4 | loss: 0.0462834\n",
      "\tspeed: 0.0340s/iter; left time: 492.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0518115 Vali Loss: 0.0635223 Test Loss: 0.0695745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0488895\n",
      "\tspeed: 0.0948s/iter; left time: 1364.1187s\n",
      "\titers: 200, epoch: 5 | loss: 0.0499913\n",
      "\tspeed: 0.0339s/iter; left time: 485.1753s\n",
      "\titers: 300, epoch: 5 | loss: 0.0501154\n",
      "\tspeed: 0.0339s/iter; left time: 481.4244s\n",
      "\titers: 400, epoch: 5 | loss: 0.0502475\n",
      "\tspeed: 0.0339s/iter; left time: 478.0747s\n",
      "\titers: 500, epoch: 5 | loss: 0.0491475\n",
      "\tspeed: 0.0339s/iter; left time: 474.6270s\n",
      "\titers: 600, epoch: 5 | loss: 0.0568916\n",
      "\tspeed: 0.0339s/iter; left time: 471.4574s\n",
      "\titers: 700, epoch: 5 | loss: 0.0549902\n",
      "\tspeed: 0.0339s/iter; left time: 468.3713s\n",
      "\titers: 800, epoch: 5 | loss: 0.0451431\n",
      "\tspeed: 0.0340s/iter; left time: 465.8810s\n",
      "\titers: 900, epoch: 5 | loss: 0.0446936\n",
      "\tspeed: 0.0340s/iter; left time: 462.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.01s\n",
      "Steps: 906 | Train Loss: 0.0493321 Vali Loss: 0.0611000 Test Loss: 0.0659227\n",
      "Validation loss decreased (0.063434 --> 0.061100).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0444498\n",
      "\tspeed: 0.0979s/iter; left time: 1320.1492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0404346\n",
      "\tspeed: 0.0340s/iter; left time: 455.4152s\n",
      "\titers: 300, epoch: 6 | loss: 0.0465716\n",
      "\tspeed: 0.0341s/iter; left time: 452.5626s\n",
      "\titers: 400, epoch: 6 | loss: 0.0545136\n",
      "\tspeed: 0.0340s/iter; left time: 448.8263s\n",
      "\titers: 500, epoch: 6 | loss: 0.0427680\n",
      "\tspeed: 0.0340s/iter; left time: 445.3560s\n",
      "\titers: 600, epoch: 6 | loss: 0.0515021\n",
      "\tspeed: 0.0340s/iter; left time: 442.2144s\n",
      "\titers: 700, epoch: 6 | loss: 0.0444518\n",
      "\tspeed: 0.0340s/iter; left time: 438.8689s\n",
      "\titers: 800, epoch: 6 | loss: 0.0440863\n",
      "\tspeed: 0.0340s/iter; left time: 435.0576s\n",
      "\titers: 900, epoch: 6 | loss: 0.0484343\n",
      "\tspeed: 0.0340s/iter; left time: 431.8529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0473150 Vali Loss: 0.0597577 Test Loss: 0.0665739\n",
      "Validation loss decreased (0.061100 --> 0.059758).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0403488\n",
      "\tspeed: 0.0966s/iter; left time: 1215.3639s\n",
      "\titers: 200, epoch: 7 | loss: 0.0512392\n",
      "\tspeed: 0.0341s/iter; left time: 425.2229s\n",
      "\titers: 300, epoch: 7 | loss: 0.0439793\n",
      "\tspeed: 0.0340s/iter; left time: 421.6574s\n",
      "\titers: 400, epoch: 7 | loss: 0.0472125\n",
      "\tspeed: 0.0341s/iter; left time: 419.0718s\n",
      "\titers: 500, epoch: 7 | loss: 0.0420035\n",
      "\tspeed: 0.0341s/iter; left time: 415.1392s\n",
      "\titers: 600, epoch: 7 | loss: 0.0384621\n",
      "\tspeed: 0.0340s/iter; left time: 411.1737s\n",
      "\titers: 700, epoch: 7 | loss: 0.0459063\n",
      "\tspeed: 0.0340s/iter; left time: 407.8058s\n",
      "\titers: 800, epoch: 7 | loss: 0.0440278\n",
      "\tspeed: 0.0340s/iter; left time: 404.4169s\n",
      "\titers: 900, epoch: 7 | loss: 0.0393112\n",
      "\tspeed: 0.0341s/iter; left time: 401.6649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0454778 Vali Loss: 0.0590582 Test Loss: 0.0647275\n",
      "Validation loss decreased (0.059758 --> 0.059058).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0406533\n",
      "\tspeed: 0.0963s/iter; left time: 1124.3786s\n",
      "\titers: 200, epoch: 8 | loss: 0.0469764\n",
      "\tspeed: 0.0340s/iter; left time: 393.9680s\n",
      "\titers: 300, epoch: 8 | loss: 0.0392994\n",
      "\tspeed: 0.0341s/iter; left time: 390.9760s\n",
      "\titers: 400, epoch: 8 | loss: 0.0500969\n",
      "\tspeed: 0.0340s/iter; left time: 386.7208s\n",
      "\titers: 500, epoch: 8 | loss: 0.0434114\n",
      "\tspeed: 0.0341s/iter; left time: 384.0735s\n",
      "\titers: 600, epoch: 8 | loss: 0.0427843\n",
      "\tspeed: 0.0340s/iter; left time: 380.4872s\n",
      "\titers: 700, epoch: 8 | loss: 0.0442753\n",
      "\tspeed: 0.0340s/iter; left time: 377.0512s\n",
      "\titers: 800, epoch: 8 | loss: 0.0417612\n",
      "\tspeed: 0.0341s/iter; left time: 373.8817s\n",
      "\titers: 900, epoch: 8 | loss: 0.0468672\n",
      "\tspeed: 0.0340s/iter; left time: 370.3954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0443256 Vali Loss: 0.0590278 Test Loss: 0.0666126\n",
      "Validation loss decreased (0.059058 --> 0.059028).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0409645\n",
      "\tspeed: 0.0981s/iter; left time: 1056.9135s\n",
      "\titers: 200, epoch: 9 | loss: 0.0432575\n",
      "\tspeed: 0.0340s/iter; left time: 363.3648s\n",
      "\titers: 300, epoch: 9 | loss: 0.0464971\n",
      "\tspeed: 0.0340s/iter; left time: 359.6136s\n",
      "\titers: 400, epoch: 9 | loss: 0.0420422\n",
      "\tspeed: 0.0340s/iter; left time: 356.5808s\n",
      "\titers: 500, epoch: 9 | loss: 0.0445137\n",
      "\tspeed: 0.0340s/iter; left time: 352.9895s\n",
      "\titers: 600, epoch: 9 | loss: 0.0377047\n",
      "\tspeed: 0.0340s/iter; left time: 349.1521s\n",
      "\titers: 700, epoch: 9 | loss: 0.0373535\n",
      "\tspeed: 0.0340s/iter; left time: 345.8586s\n",
      "\titers: 800, epoch: 9 | loss: 0.0378851\n",
      "\tspeed: 0.0341s/iter; left time: 343.0847s\n",
      "\titers: 900, epoch: 9 | loss: 0.0343114\n",
      "\tspeed: 0.0340s/iter; left time: 339.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0427961 Vali Loss: 0.0573571 Test Loss: 0.0648689\n",
      "Validation loss decreased (0.059028 --> 0.057357).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0417384\n",
      "\tspeed: 0.0961s/iter; left time: 948.5302s\n",
      "\titers: 200, epoch: 10 | loss: 0.0398730\n",
      "\tspeed: 0.0341s/iter; left time: 332.5684s\n",
      "\titers: 300, epoch: 10 | loss: 0.0431907\n",
      "\tspeed: 0.0341s/iter; left time: 329.3007s\n",
      "\titers: 400, epoch: 10 | loss: 0.0450556\n",
      "\tspeed: 0.0340s/iter; left time: 325.5051s\n",
      "\titers: 500, epoch: 10 | loss: 0.0350549\n",
      "\tspeed: 0.0340s/iter; left time: 321.8316s\n",
      "\titers: 600, epoch: 10 | loss: 0.0404603\n",
      "\tspeed: 0.0340s/iter; left time: 318.3607s\n",
      "\titers: 700, epoch: 10 | loss: 0.0432734\n",
      "\tspeed: 0.0340s/iter; left time: 315.3881s\n",
      "\titers: 800, epoch: 10 | loss: 0.0391883\n",
      "\tspeed: 0.0340s/iter; left time: 311.7923s\n",
      "\titers: 900, epoch: 10 | loss: 0.0427314\n",
      "\tspeed: 0.0340s/iter; left time: 308.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0417776 Vali Loss: 0.0574123 Test Loss: 0.0637241\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0417736\n",
      "\tspeed: 0.0940s/iter; left time: 842.1604s\n",
      "\titers: 200, epoch: 11 | loss: 0.0475188\n",
      "\tspeed: 0.0346s/iter; left time: 306.1956s\n",
      "\titers: 300, epoch: 11 | loss: 0.0371066\n",
      "\tspeed: 0.0345s/iter; left time: 302.6752s\n",
      "\titers: 400, epoch: 11 | loss: 0.0418829\n",
      "\tspeed: 0.0346s/iter; left time: 299.4190s\n",
      "\titers: 500, epoch: 11 | loss: 0.0450594\n",
      "\tspeed: 0.0345s/iter; left time: 295.7692s\n",
      "\titers: 600, epoch: 11 | loss: 0.0439484\n",
      "\tspeed: 0.0346s/iter; left time: 292.4431s\n",
      "\titers: 700, epoch: 11 | loss: 0.0418536\n",
      "\tspeed: 0.0347s/iter; left time: 290.4458s\n",
      "\titers: 800, epoch: 11 | loss: 0.0409613\n",
      "\tspeed: 0.0346s/iter; left time: 285.9516s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418191\n",
      "\tspeed: 0.0346s/iter; left time: 282.1074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.57s\n",
      "Steps: 906 | Train Loss: 0.0406990 Vali Loss: 0.0576143 Test Loss: 0.0632747\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0370599\n",
      "\tspeed: 0.0946s/iter; left time: 761.8586s\n",
      "\titers: 200, epoch: 12 | loss: 0.0422251\n",
      "\tspeed: 0.0341s/iter; left time: 270.9392s\n",
      "\titers: 300, epoch: 12 | loss: 0.0389508\n",
      "\tspeed: 0.0340s/iter; left time: 267.0887s\n",
      "\titers: 400, epoch: 12 | loss: 0.0401749\n",
      "\tspeed: 0.0340s/iter; left time: 263.7060s\n",
      "\titers: 500, epoch: 12 | loss: 0.0385777\n",
      "\tspeed: 0.0340s/iter; left time: 260.1403s\n",
      "\titers: 600, epoch: 12 | loss: 0.0389454\n",
      "\tspeed: 0.0339s/iter; left time: 256.3173s\n",
      "\titers: 700, epoch: 12 | loss: 0.0357124\n",
      "\tspeed: 0.0340s/iter; left time: 253.4781s\n",
      "\titers: 800, epoch: 12 | loss: 0.0377932\n",
      "\tspeed: 0.0340s/iter; left time: 250.0363s\n",
      "\titers: 900, epoch: 12 | loss: 0.0412504\n",
      "\tspeed: 0.0340s/iter; left time: 246.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.06s\n",
      "Steps: 906 | Train Loss: 0.0396205 Vali Loss: 0.0564137 Test Loss: 0.0632015\n",
      "Validation loss decreased (0.057357 --> 0.056414).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0420268\n",
      "\tspeed: 0.0988s/iter; left time: 706.5339s\n",
      "\titers: 200, epoch: 13 | loss: 0.0387494\n",
      "\tspeed: 0.0340s/iter; left time: 239.5933s\n",
      "\titers: 300, epoch: 13 | loss: 0.0355878\n",
      "\tspeed: 0.0340s/iter; left time: 236.3251s\n",
      "\titers: 400, epoch: 13 | loss: 0.0343830\n",
      "\tspeed: 0.0339s/iter; left time: 232.1565s\n",
      "\titers: 500, epoch: 13 | loss: 0.0421653\n",
      "\tspeed: 0.0340s/iter; left time: 229.2012s\n",
      "\titers: 600, epoch: 13 | loss: 0.0360691\n",
      "\tspeed: 0.0339s/iter; left time: 225.5456s\n",
      "\titers: 700, epoch: 13 | loss: 0.0363027\n",
      "\tspeed: 0.0340s/iter; left time: 222.5785s\n",
      "\titers: 800, epoch: 13 | loss: 0.0376486\n",
      "\tspeed: 0.0339s/iter; left time: 218.7247s\n",
      "\titers: 900, epoch: 13 | loss: 0.0431237\n",
      "\tspeed: 0.0340s/iter; left time: 215.7283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.05s\n",
      "Steps: 906 | Train Loss: 0.0385994 Vali Loss: 0.0564743 Test Loss: 0.0633992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0412338\n",
      "\tspeed: 0.0937s/iter; left time: 584.9274s\n",
      "\titers: 200, epoch: 14 | loss: 0.0365248\n",
      "\tspeed: 0.0339s/iter; left time: 208.4826s\n",
      "\titers: 300, epoch: 14 | loss: 0.0365122\n",
      "\tspeed: 0.0340s/iter; left time: 205.2606s\n",
      "\titers: 400, epoch: 14 | loss: 0.0376992\n",
      "\tspeed: 0.0340s/iter; left time: 202.1956s\n",
      "\titers: 500, epoch: 14 | loss: 0.0416844\n",
      "\tspeed: 0.0340s/iter; left time: 198.5506s\n",
      "\titers: 600, epoch: 14 | loss: 0.0383253\n",
      "\tspeed: 0.0339s/iter; left time: 194.8081s\n",
      "\titers: 700, epoch: 14 | loss: 0.0366903\n",
      "\tspeed: 0.0341s/iter; left time: 192.1697s\n",
      "\titers: 800, epoch: 14 | loss: 0.0462296\n",
      "\tspeed: 0.0340s/iter; left time: 188.3393s\n",
      "\titers: 900, epoch: 14 | loss: 0.0353763\n",
      "\tspeed: 0.0340s/iter; left time: 185.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.09s\n",
      "Steps: 906 | Train Loss: 0.0376544 Vali Loss: 0.0559921 Test Loss: 0.0616274\n",
      "Validation loss decreased (0.056414 --> 0.055992).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0385241\n",
      "\tspeed: 0.0967s/iter; left time: 516.1917s\n",
      "\titers: 200, epoch: 15 | loss: 0.0367979\n",
      "\tspeed: 0.0339s/iter; left time: 177.7850s\n",
      "\titers: 300, epoch: 15 | loss: 0.0331814\n",
      "\tspeed: 0.0340s/iter; left time: 174.4053s\n",
      "\titers: 400, epoch: 15 | loss: 0.0364987\n",
      "\tspeed: 0.0340s/iter; left time: 171.0100s\n",
      "\titers: 500, epoch: 15 | loss: 0.0332029\n",
      "\tspeed: 0.0340s/iter; left time: 168.0468s\n",
      "\titers: 600, epoch: 15 | loss: 0.0384601\n",
      "\tspeed: 0.0339s/iter; left time: 163.9847s\n",
      "\titers: 700, epoch: 15 | loss: 0.0368570\n",
      "\tspeed: 0.0339s/iter; left time: 160.6274s\n",
      "\titers: 800, epoch: 15 | loss: 0.0354397\n",
      "\tspeed: 0.0339s/iter; left time: 157.0704s\n",
      "\titers: 900, epoch: 15 | loss: 0.0366562\n",
      "\tspeed: 0.0339s/iter; left time: 153.7298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0369873 Vali Loss: 0.0558398 Test Loss: 0.0628962\n",
      "Validation loss decreased (0.055992 --> 0.055840).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0392919\n",
      "\tspeed: 0.0961s/iter; left time: 426.0157s\n",
      "\titers: 200, epoch: 16 | loss: 0.0445064\n",
      "\tspeed: 0.0339s/iter; left time: 146.8060s\n",
      "\titers: 300, epoch: 16 | loss: 0.0404944\n",
      "\tspeed: 0.0339s/iter; left time: 143.4647s\n",
      "\titers: 400, epoch: 16 | loss: 0.0348784\n",
      "\tspeed: 0.0339s/iter; left time: 140.0167s\n",
      "\titers: 500, epoch: 16 | loss: 0.0308083\n",
      "\tspeed: 0.0340s/iter; left time: 136.9805s\n",
      "\titers: 600, epoch: 16 | loss: 0.0367714\n",
      "\tspeed: 0.0339s/iter; left time: 133.3032s\n",
      "\titers: 700, epoch: 16 | loss: 0.0356430\n",
      "\tspeed: 0.0339s/iter; left time: 129.9085s\n",
      "\titers: 800, epoch: 16 | loss: 0.0364897\n",
      "\tspeed: 0.0340s/iter; left time: 126.9509s\n",
      "\titers: 900, epoch: 16 | loss: 0.0351077\n",
      "\tspeed: 0.0340s/iter; left time: 123.5172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0361995 Vali Loss: 0.0570393 Test Loss: 0.0630939\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0382720\n",
      "\tspeed: 0.0941s/iter; left time: 331.8666s\n",
      "\titers: 200, epoch: 17 | loss: 0.0357151\n",
      "\tspeed: 0.0340s/iter; left time: 116.4433s\n",
      "\titers: 300, epoch: 17 | loss: 0.0355730\n",
      "\tspeed: 0.0340s/iter; left time: 113.2038s\n",
      "\titers: 400, epoch: 17 | loss: 0.0348953\n",
      "\tspeed: 0.0345s/iter; left time: 111.3173s\n",
      "\titers: 500, epoch: 17 | loss: 0.0320778\n",
      "\tspeed: 0.0345s/iter; left time: 107.8330s\n",
      "\titers: 600, epoch: 17 | loss: 0.0328302\n",
      "\tspeed: 0.0345s/iter; left time: 104.5112s\n",
      "\titers: 700, epoch: 17 | loss: 0.0377763\n",
      "\tspeed: 0.0345s/iter; left time: 100.9964s\n",
      "\titers: 800, epoch: 17 | loss: 0.0368321\n",
      "\tspeed: 0.0346s/iter; left time: 97.6821s\n",
      "\titers: 900, epoch: 17 | loss: 0.0395076\n",
      "\tspeed: 0.0345s/iter; left time: 93.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0355288 Vali Loss: 0.0563765 Test Loss: 0.0635618\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0334214\n",
      "\tspeed: 0.0942s/iter; left time: 246.8353s\n",
      "\titers: 200, epoch: 18 | loss: 0.0349425\n",
      "\tspeed: 0.0341s/iter; left time: 85.7858s\n",
      "\titers: 300, epoch: 18 | loss: 0.0340762\n",
      "\tspeed: 0.0341s/iter; left time: 82.3672s\n",
      "\titers: 400, epoch: 18 | loss: 0.0363117\n",
      "\tspeed: 0.0341s/iter; left time: 78.9903s\n",
      "\titers: 500, epoch: 18 | loss: 0.0395520\n",
      "\tspeed: 0.0340s/iter; left time: 75.5496s\n",
      "\titers: 600, epoch: 18 | loss: 0.0366950\n",
      "\tspeed: 0.0341s/iter; left time: 72.1646s\n",
      "\titers: 700, epoch: 18 | loss: 0.0427621\n",
      "\tspeed: 0.0340s/iter; left time: 68.7282s\n",
      "\titers: 800, epoch: 18 | loss: 0.0320136\n",
      "\tspeed: 0.0340s/iter; left time: 65.3171s\n",
      "\titers: 900, epoch: 18 | loss: 0.0407823\n",
      "\tspeed: 0.0341s/iter; left time: 61.9651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.15s\n",
      "Steps: 906 | Train Loss: 0.0349199 Vali Loss: 0.0566797 Test Loss: 0.0626437\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0350009\n",
      "\tspeed: 0.0930s/iter; left time: 159.3698s\n",
      "\titers: 200, epoch: 19 | loss: 0.0359370\n",
      "\tspeed: 0.0340s/iter; left time: 54.8002s\n",
      "\titers: 300, epoch: 19 | loss: 0.0364045\n",
      "\tspeed: 0.0340s/iter; left time: 51.4413s\n",
      "\titers: 400, epoch: 19 | loss: 0.0337826\n",
      "\tspeed: 0.0340s/iter; left time: 47.9738s\n",
      "\titers: 500, epoch: 19 | loss: 0.0354946\n",
      "\tspeed: 0.0340s/iter; left time: 44.6339s\n",
      "\titers: 600, epoch: 19 | loss: 0.0339434\n",
      "\tspeed: 0.0340s/iter; left time: 41.2057s\n",
      "\titers: 700, epoch: 19 | loss: 0.0348568\n",
      "\tspeed: 0.0340s/iter; left time: 37.8161s\n",
      "\titers: 800, epoch: 19 | loss: 0.0328255\n",
      "\tspeed: 0.0340s/iter; left time: 34.4323s\n",
      "\titers: 900, epoch: 19 | loss: 0.0363572\n",
      "\tspeed: 0.0340s/iter; left time: 31.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.03s\n",
      "Steps: 906 | Train Loss: 0.0345114 Vali Loss: 0.0565572 Test Loss: 0.0630916\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0393753\n",
      "\tspeed: 0.0944s/iter; left time: 76.2104s\n",
      "\titers: 200, epoch: 20 | loss: 0.0383313\n",
      "\tspeed: 0.0339s/iter; left time: 23.9371s\n",
      "\titers: 300, epoch: 20 | loss: 0.0362157\n",
      "\tspeed: 0.0339s/iter; left time: 20.5805s\n",
      "\titers: 400, epoch: 20 | loss: 0.0314259\n",
      "\tspeed: 0.0340s/iter; left time: 17.2133s\n",
      "\titers: 500, epoch: 20 | loss: 0.0358881\n",
      "\tspeed: 0.0340s/iter; left time: 13.8198s\n",
      "\titers: 600, epoch: 20 | loss: 0.0343928\n",
      "\tspeed: 0.0340s/iter; left time: 10.4321s\n",
      "\titers: 700, epoch: 20 | loss: 0.0340157\n",
      "\tspeed: 0.0339s/iter; left time: 7.0263s\n",
      "\titers: 800, epoch: 20 | loss: 0.0352002\n",
      "\tspeed: 0.0339s/iter; left time: 3.6284s\n",
      "\titers: 900, epoch: 20 | loss: 0.0332215\n",
      "\tspeed: 0.0340s/iter; left time: 0.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.00s\n",
      "Steps: 906 | Train Loss: 0.0340116 Vali Loss: 0.0563868 Test Loss: 0.0630755\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012454495765268803, rmse:0.11159971356391907, mae:0.06283904612064362, rse:0.4306430518627167\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1799639\n",
      "\tspeed: 0.0362s/iter; left time: 652.4446s\n",
      "\titers: 200, epoch: 1 | loss: 0.1643134\n",
      "\tspeed: 0.0340s/iter; left time: 610.0871s\n",
      "\titers: 300, epoch: 1 | loss: 0.1678073\n",
      "\tspeed: 0.0340s/iter; left time: 606.4789s\n",
      "\titers: 400, epoch: 1 | loss: 0.1560568\n",
      "\tspeed: 0.0340s/iter; left time: 603.2615s\n",
      "\titers: 500, epoch: 1 | loss: 0.1497856\n",
      "\tspeed: 0.0340s/iter; left time: 599.3590s\n",
      "\titers: 600, epoch: 1 | loss: 0.1513730\n",
      "\tspeed: 0.0340s/iter; left time: 596.2770s\n",
      "\titers: 700, epoch: 1 | loss: 0.1495658\n",
      "\tspeed: 0.0341s/iter; left time: 593.4248s\n",
      "\titers: 800, epoch: 1 | loss: 0.1475314\n",
      "\tspeed: 0.0340s/iter; left time: 589.2816s\n",
      "\titers: 900, epoch: 1 | loss: 0.1326258\n",
      "\tspeed: 0.0340s/iter; left time: 586.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.1621176 Vali Loss: 0.1434601 Test Loss: 0.1637105\n",
      "Validation loss decreased (inf --> 0.143460).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1280499\n",
      "\tspeed: 0.0969s/iter; left time: 1658.2526s\n",
      "\titers: 200, epoch: 2 | loss: 0.0996244\n",
      "\tspeed: 0.0341s/iter; left time: 580.6063s\n",
      "\titers: 300, epoch: 2 | loss: 0.1066693\n",
      "\tspeed: 0.0341s/iter; left time: 576.4870s\n",
      "\titers: 400, epoch: 2 | loss: 0.0870007\n",
      "\tspeed: 0.0341s/iter; left time: 573.9577s\n",
      "\titers: 500, epoch: 2 | loss: 0.0831003\n",
      "\tspeed: 0.0341s/iter; left time: 570.0731s\n",
      "\titers: 600, epoch: 2 | loss: 0.0833607\n",
      "\tspeed: 0.0341s/iter; left time: 566.2976s\n",
      "\titers: 700, epoch: 2 | loss: 0.0783962\n",
      "\tspeed: 0.0340s/iter; left time: 561.6904s\n",
      "\titers: 800, epoch: 2 | loss: 0.0747123\n",
      "\tspeed: 0.0340s/iter; left time: 558.8937s\n",
      "\titers: 900, epoch: 2 | loss: 0.0690103\n",
      "\tspeed: 0.0341s/iter; left time: 555.5888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0950980 Vali Loss: 0.0901362 Test Loss: 0.1025138\n",
      "Validation loss decreased (0.143460 --> 0.090136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0686186\n",
      "\tspeed: 0.0970s/iter; left time: 1573.0713s\n",
      "\titers: 200, epoch: 3 | loss: 0.0774667\n",
      "\tspeed: 0.0340s/iter; left time: 547.6336s\n",
      "\titers: 300, epoch: 3 | loss: 0.0744100\n",
      "\tspeed: 0.0341s/iter; left time: 545.1095s\n",
      "\titers: 400, epoch: 3 | loss: 0.0659564\n",
      "\tspeed: 0.0340s/iter; left time: 540.8907s\n",
      "\titers: 500, epoch: 3 | loss: 0.0685518\n",
      "\tspeed: 0.0340s/iter; left time: 538.1349s\n",
      "\titers: 600, epoch: 3 | loss: 0.0650003\n",
      "\tspeed: 0.0340s/iter; left time: 534.8691s\n",
      "\titers: 700, epoch: 3 | loss: 0.0603844\n",
      "\tspeed: 0.0340s/iter; left time: 531.0855s\n",
      "\titers: 800, epoch: 3 | loss: 0.0562463\n",
      "\tspeed: 0.0340s/iter; left time: 527.6460s\n",
      "\titers: 900, epoch: 3 | loss: 0.0498774\n",
      "\tspeed: 0.0341s/iter; left time: 524.9010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 906 | Train Loss: 0.0693412 Vali Loss: 0.0679662 Test Loss: 0.0759230\n",
      "Validation loss decreased (0.090136 --> 0.067966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609032\n",
      "\tspeed: 0.1011s/iter; left time: 1547.7745s\n",
      "\titers: 200, epoch: 4 | loss: 0.0538243\n",
      "\tspeed: 0.0341s/iter; left time: 517.9878s\n",
      "\titers: 300, epoch: 4 | loss: 0.0516822\n",
      "\tspeed: 0.0341s/iter; left time: 514.3943s\n",
      "\titers: 400, epoch: 4 | loss: 0.0576723\n",
      "\tspeed: 0.0340s/iter; left time: 510.6228s\n",
      "\titers: 500, epoch: 4 | loss: 0.0511567\n",
      "\tspeed: 0.0340s/iter; left time: 506.6648s\n",
      "\titers: 600, epoch: 4 | loss: 0.0473879\n",
      "\tspeed: 0.0340s/iter; left time: 503.3008s\n",
      "\titers: 700, epoch: 4 | loss: 0.0561181\n",
      "\tspeed: 0.0341s/iter; left time: 500.8967s\n",
      "\titers: 800, epoch: 4 | loss: 0.0411501\n",
      "\tspeed: 0.0340s/iter; left time: 496.7483s\n",
      "\titers: 900, epoch: 4 | loss: 0.0510259\n",
      "\tspeed: 0.0341s/iter; left time: 493.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0531958 Vali Loss: 0.0632272 Test Loss: 0.0694707\n",
      "Validation loss decreased (0.067966 --> 0.063227).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619297\n",
      "\tspeed: 0.0968s/iter; left time: 1393.6483s\n",
      "\titers: 200, epoch: 5 | loss: 0.0546464\n",
      "\tspeed: 0.0340s/iter; left time: 486.8072s\n",
      "\titers: 300, epoch: 5 | loss: 0.0613711\n",
      "\tspeed: 0.0341s/iter; left time: 483.9119s\n",
      "\titers: 400, epoch: 5 | loss: 0.0470468\n",
      "\tspeed: 0.0341s/iter; left time: 480.5576s\n",
      "\titers: 500, epoch: 5 | loss: 0.0465499\n",
      "\tspeed: 0.0341s/iter; left time: 477.5381s\n",
      "\titers: 600, epoch: 5 | loss: 0.0433100\n",
      "\tspeed: 0.0341s/iter; left time: 474.1792s\n",
      "\titers: 700, epoch: 5 | loss: 0.0539502\n",
      "\tspeed: 0.0341s/iter; left time: 470.8634s\n",
      "\titers: 800, epoch: 5 | loss: 0.0489548\n",
      "\tspeed: 0.0341s/iter; left time: 467.0049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0480206\n",
      "\tspeed: 0.0340s/iter; left time: 462.8215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.14s\n",
      "Steps: 906 | Train Loss: 0.0503956 Vali Loss: 0.0638788 Test Loss: 0.0694296\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0558476\n",
      "\tspeed: 0.0931s/iter; left time: 1255.5520s\n",
      "\titers: 200, epoch: 6 | loss: 0.0517960\n",
      "\tspeed: 0.0341s/iter; left time: 456.0462s\n",
      "\titers: 300, epoch: 6 | loss: 0.0477182\n",
      "\tspeed: 0.0340s/iter; left time: 451.8443s\n",
      "\titers: 400, epoch: 6 | loss: 0.0510341\n",
      "\tspeed: 0.0340s/iter; left time: 449.0183s\n",
      "\titers: 500, epoch: 6 | loss: 0.0578296\n",
      "\tspeed: 0.0341s/iter; left time: 446.2099s\n",
      "\titers: 600, epoch: 6 | loss: 0.0474456\n",
      "\tspeed: 0.0340s/iter; left time: 442.1500s\n",
      "\titers: 700, epoch: 6 | loss: 0.0449998\n",
      "\tspeed: 0.0340s/iter; left time: 438.3822s\n",
      "\titers: 800, epoch: 6 | loss: 0.0488756\n",
      "\tspeed: 0.0341s/iter; left time: 435.7082s\n",
      "\titers: 900, epoch: 6 | loss: 0.0458535\n",
      "\tspeed: 0.0341s/iter; left time: 432.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0484827 Vali Loss: 0.0618802 Test Loss: 0.0675384\n",
      "Validation loss decreased (0.063227 --> 0.061880).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0504562\n",
      "\tspeed: 0.0961s/iter; left time: 1209.5752s\n",
      "\titers: 200, epoch: 7 | loss: 0.0376698\n",
      "\tspeed: 0.0340s/iter; left time: 424.8540s\n",
      "\titers: 300, epoch: 7 | loss: 0.0475422\n",
      "\tspeed: 0.0340s/iter; left time: 421.4028s\n",
      "\titers: 400, epoch: 7 | loss: 0.0474081\n",
      "\tspeed: 0.0340s/iter; left time: 417.7398s\n",
      "\titers: 500, epoch: 7 | loss: 0.0480068\n",
      "\tspeed: 0.0341s/iter; left time: 415.1552s\n",
      "\titers: 600, epoch: 7 | loss: 0.0499294\n",
      "\tspeed: 0.0340s/iter; left time: 411.3285s\n",
      "\titers: 700, epoch: 7 | loss: 0.0466667\n",
      "\tspeed: 0.0341s/iter; left time: 409.0004s\n",
      "\titers: 800, epoch: 7 | loss: 0.0481679\n",
      "\tspeed: 0.0347s/iter; left time: 412.2438s\n",
      "\titers: 900, epoch: 7 | loss: 0.0472499\n",
      "\tspeed: 0.0346s/iter; left time: 408.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.23s\n",
      "Steps: 906 | Train Loss: 0.0468621 Vali Loss: 0.0617771 Test Loss: 0.0675191\n",
      "Validation loss decreased (0.061880 --> 0.061777).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513489\n",
      "\tspeed: 0.0969s/iter; left time: 1132.0153s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440349\n",
      "\tspeed: 0.0341s/iter; left time: 394.6745s\n",
      "\titers: 300, epoch: 8 | loss: 0.0446530\n",
      "\tspeed: 0.0340s/iter; left time: 390.7435s\n",
      "\titers: 400, epoch: 8 | loss: 0.0405290\n",
      "\tspeed: 0.0340s/iter; left time: 387.3347s\n",
      "\titers: 500, epoch: 8 | loss: 0.0435242\n",
      "\tspeed: 0.0341s/iter; left time: 384.3399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0423415\n",
      "\tspeed: 0.0340s/iter; left time: 380.4947s\n",
      "\titers: 700, epoch: 8 | loss: 0.0417117\n",
      "\tspeed: 0.0341s/iter; left time: 377.3020s\n",
      "\titers: 800, epoch: 8 | loss: 0.0462200\n",
      "\tspeed: 0.0341s/iter; left time: 374.0436s\n",
      "\titers: 900, epoch: 8 | loss: 0.0429036\n",
      "\tspeed: 0.0340s/iter; left time: 370.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0452779 Vali Loss: 0.0590413 Test Loss: 0.0656133\n",
      "Validation loss decreased (0.061777 --> 0.059041).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0433994\n",
      "\tspeed: 0.0971s/iter; left time: 1045.5309s\n",
      "\titers: 200, epoch: 9 | loss: 0.0410988\n",
      "\tspeed: 0.0340s/iter; left time: 363.1287s\n",
      "\titers: 300, epoch: 9 | loss: 0.0437933\n",
      "\tspeed: 0.0340s/iter; left time: 359.9408s\n",
      "\titers: 400, epoch: 9 | loss: 0.0443417\n",
      "\tspeed: 0.0340s/iter; left time: 356.3902s\n",
      "\titers: 500, epoch: 9 | loss: 0.0440277\n",
      "\tspeed: 0.0340s/iter; left time: 353.1507s\n",
      "\titers: 600, epoch: 9 | loss: 0.0452474\n",
      "\tspeed: 0.0340s/iter; left time: 349.6943s\n",
      "\titers: 700, epoch: 9 | loss: 0.0401173\n",
      "\tspeed: 0.0341s/iter; left time: 346.4884s\n",
      "\titers: 800, epoch: 9 | loss: 0.0455280\n",
      "\tspeed: 0.0340s/iter; left time: 342.8749s\n",
      "\titers: 900, epoch: 9 | loss: 0.0525242\n",
      "\tspeed: 0.0340s/iter; left time: 339.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.11s\n",
      "Steps: 906 | Train Loss: 0.0436650 Vali Loss: 0.0592790 Test Loss: 0.0648833\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0408640\n",
      "\tspeed: 0.0932s/iter; left time: 919.7983s\n",
      "\titers: 200, epoch: 10 | loss: 0.0427431\n",
      "\tspeed: 0.0341s/iter; left time: 332.7807s\n",
      "\titers: 300, epoch: 10 | loss: 0.0461511\n",
      "\tspeed: 0.0340s/iter; left time: 328.8849s\n",
      "\titers: 400, epoch: 10 | loss: 0.0389742\n",
      "\tspeed: 0.0340s/iter; left time: 325.4653s\n",
      "\titers: 500, epoch: 10 | loss: 0.0366748\n",
      "\tspeed: 0.0340s/iter; left time: 322.2732s\n",
      "\titers: 600, epoch: 10 | loss: 0.0407804\n",
      "\tspeed: 0.0340s/iter; left time: 318.5451s\n",
      "\titers: 700, epoch: 10 | loss: 0.0439256\n",
      "\tspeed: 0.0341s/iter; left time: 315.6877s\n",
      "\titers: 800, epoch: 10 | loss: 0.0396320\n",
      "\tspeed: 0.0340s/iter; left time: 311.9610s\n",
      "\titers: 900, epoch: 10 | loss: 0.0464057\n",
      "\tspeed: 0.0341s/iter; left time: 308.8464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0421371 Vali Loss: 0.0582751 Test Loss: 0.0668456\n",
      "Validation loss decreased (0.059041 --> 0.058275).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0364203\n",
      "\tspeed: 0.0983s/iter; left time: 881.0335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0393139\n",
      "\tspeed: 0.0346s/iter; left time: 306.7814s\n",
      "\titers: 300, epoch: 11 | loss: 0.0412469\n",
      "\tspeed: 0.0347s/iter; left time: 303.6201s\n",
      "\titers: 400, epoch: 11 | loss: 0.0424502\n",
      "\tspeed: 0.0344s/iter; left time: 298.1432s\n",
      "\titers: 500, epoch: 11 | loss: 0.0420882\n",
      "\tspeed: 0.0341s/iter; left time: 291.6435s\n",
      "\titers: 600, epoch: 11 | loss: 0.0404220\n",
      "\tspeed: 0.0340s/iter; left time: 287.9176s\n",
      "\titers: 700, epoch: 11 | loss: 0.0364543\n",
      "\tspeed: 0.0340s/iter; left time: 284.3522s\n",
      "\titers: 800, epoch: 11 | loss: 0.0391739\n",
      "\tspeed: 0.0341s/iter; left time: 281.5530s\n",
      "\titers: 900, epoch: 11 | loss: 0.0418266\n",
      "\tspeed: 0.0341s/iter; left time: 277.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.33s\n",
      "Steps: 906 | Train Loss: 0.0407368 Vali Loss: 0.0578185 Test Loss: 0.0662903\n",
      "Validation loss decreased (0.058275 --> 0.057818).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0390506\n",
      "\tspeed: 0.0988s/iter; left time: 795.8017s\n",
      "\titers: 200, epoch: 12 | loss: 0.0443430\n",
      "\tspeed: 0.0341s/iter; left time: 271.1316s\n",
      "\titers: 300, epoch: 12 | loss: 0.0402047\n",
      "\tspeed: 0.0341s/iter; left time: 267.5208s\n",
      "\titers: 400, epoch: 12 | loss: 0.0388500\n",
      "\tspeed: 0.0341s/iter; left time: 264.2932s\n",
      "\titers: 500, epoch: 12 | loss: 0.0390783\n",
      "\tspeed: 0.0341s/iter; left time: 260.9770s\n",
      "\titers: 600, epoch: 12 | loss: 0.0352140\n",
      "\tspeed: 0.0341s/iter; left time: 257.9070s\n",
      "\titers: 700, epoch: 12 | loss: 0.0395783\n",
      "\tspeed: 0.0341s/iter; left time: 254.4347s\n",
      "\titers: 800, epoch: 12 | loss: 0.0411608\n",
      "\tspeed: 0.0341s/iter; left time: 250.6289s\n",
      "\titers: 900, epoch: 12 | loss: 0.0375333\n",
      "\tspeed: 0.0341s/iter; left time: 247.4066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.16s\n",
      "Steps: 906 | Train Loss: 0.0397211 Vali Loss: 0.0578994 Test Loss: 0.0657681\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463221\n",
      "\tspeed: 0.0943s/iter; left time: 674.1530s\n",
      "\titers: 200, epoch: 13 | loss: 0.0320999\n",
      "\tspeed: 0.0341s/iter; left time: 240.3496s\n",
      "\titers: 300, epoch: 13 | loss: 0.0338570\n",
      "\tspeed: 0.0340s/iter; left time: 236.4549s\n",
      "\titers: 400, epoch: 13 | loss: 0.0367805\n",
      "\tspeed: 0.0340s/iter; left time: 232.9457s\n",
      "\titers: 500, epoch: 13 | loss: 0.0399524\n",
      "\tspeed: 0.0340s/iter; left time: 229.3342s\n",
      "\titers: 600, epoch: 13 | loss: 0.0407709\n",
      "\tspeed: 0.0340s/iter; left time: 226.0676s\n",
      "\titers: 700, epoch: 13 | loss: 0.0385915\n",
      "\tspeed: 0.0340s/iter; left time: 222.9273s\n",
      "\titers: 800, epoch: 13 | loss: 0.0377566\n",
      "\tspeed: 0.0341s/iter; left time: 219.7198s\n",
      "\titers: 900, epoch: 13 | loss: 0.0359108\n",
      "\tspeed: 0.0341s/iter; left time: 216.4138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0386944 Vali Loss: 0.0576511 Test Loss: 0.0644637\n",
      "Validation loss decreased (0.057818 --> 0.057651).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0370453\n",
      "\tspeed: 0.0966s/iter; left time: 603.2771s\n",
      "\titers: 200, epoch: 14 | loss: 0.0355818\n",
      "\tspeed: 0.0341s/iter; left time: 209.5007s\n",
      "\titers: 300, epoch: 14 | loss: 0.0373862\n",
      "\tspeed: 0.0341s/iter; left time: 206.0621s\n",
      "\titers: 400, epoch: 14 | loss: 0.0363934\n",
      "\tspeed: 0.0341s/iter; left time: 202.8280s\n",
      "\titers: 500, epoch: 14 | loss: 0.0408763\n",
      "\tspeed: 0.0341s/iter; left time: 199.0434s\n",
      "\titers: 600, epoch: 14 | loss: 0.0316915\n",
      "\tspeed: 0.0341s/iter; left time: 195.7352s\n",
      "\titers: 700, epoch: 14 | loss: 0.0352258\n",
      "\tspeed: 0.0340s/iter; left time: 191.6210s\n",
      "\titers: 800, epoch: 14 | loss: 0.0406870\n",
      "\tspeed: 0.0340s/iter; left time: 188.4585s\n",
      "\titers: 900, epoch: 14 | loss: 0.0330149\n",
      "\tspeed: 0.0341s/iter; left time: 185.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.12s\n",
      "Steps: 906 | Train Loss: 0.0376825 Vali Loss: 0.0588694 Test Loss: 0.0671663\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0404172\n",
      "\tspeed: 0.0934s/iter; left time: 498.3921s\n",
      "\titers: 200, epoch: 15 | loss: 0.0358362\n",
      "\tspeed: 0.0339s/iter; left time: 177.7817s\n",
      "\titers: 300, epoch: 15 | loss: 0.0366841\n",
      "\tspeed: 0.0340s/iter; left time: 174.6389s\n",
      "\titers: 400, epoch: 15 | loss: 0.0430892\n",
      "\tspeed: 0.0340s/iter; left time: 171.3631s\n",
      "\titers: 500, epoch: 15 | loss: 0.0377812\n",
      "\tspeed: 0.0339s/iter; left time: 167.5859s\n",
      "\titers: 600, epoch: 15 | loss: 0.0361609\n",
      "\tspeed: 0.0340s/iter; left time: 164.3873s\n",
      "\titers: 700, epoch: 15 | loss: 0.0323415\n",
      "\tspeed: 0.0340s/iter; left time: 160.8702s\n",
      "\titers: 800, epoch: 15 | loss: 0.0385448\n",
      "\tspeed: 0.0340s/iter; left time: 157.5110s\n",
      "\titers: 900, epoch: 15 | loss: 0.0349694\n",
      "\tspeed: 0.0340s/iter; left time: 154.1695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.02s\n",
      "Steps: 906 | Train Loss: 0.0371047 Vali Loss: 0.0579351 Test Loss: 0.0650045\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0371176\n",
      "\tspeed: 0.0933s/iter; left time: 413.5632s\n",
      "\titers: 200, epoch: 16 | loss: 0.0388558\n",
      "\tspeed: 0.0340s/iter; left time: 147.1480s\n",
      "\titers: 300, epoch: 16 | loss: 0.0379867\n",
      "\tspeed: 0.0340s/iter; left time: 143.8585s\n",
      "\titers: 400, epoch: 16 | loss: 0.0419456\n",
      "\tspeed: 0.0340s/iter; left time: 140.3840s\n",
      "\titers: 500, epoch: 16 | loss: 0.0323641\n",
      "\tspeed: 0.0340s/iter; left time: 137.0274s\n",
      "\titers: 600, epoch: 16 | loss: 0.0388941\n",
      "\tspeed: 0.0340s/iter; left time: 133.6431s\n",
      "\titers: 700, epoch: 16 | loss: 0.0388042\n",
      "\tspeed: 0.0340s/iter; left time: 130.1446s\n",
      "\titers: 800, epoch: 16 | loss: 0.0336426\n",
      "\tspeed: 0.0340s/iter; left time: 126.8455s\n",
      "\titers: 900, epoch: 16 | loss: 0.0334118\n",
      "\tspeed: 0.0340s/iter; left time: 123.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 906 | Train Loss: 0.0364606 Vali Loss: 0.0591877 Test Loss: 0.0641280\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0336711\n",
      "\tspeed: 0.0932s/iter; left time: 328.4885s\n",
      "\titers: 200, epoch: 17 | loss: 0.0368703\n",
      "\tspeed: 0.0340s/iter; left time: 116.6046s\n",
      "\titers: 300, epoch: 17 | loss: 0.0379302\n",
      "\tspeed: 0.0341s/iter; left time: 113.4628s\n",
      "\titers: 400, epoch: 17 | loss: 0.0395388\n",
      "\tspeed: 0.0340s/iter; left time: 109.7315s\n",
      "\titers: 500, epoch: 17 | loss: 0.0376200\n",
      "\tspeed: 0.0340s/iter; left time: 106.2791s\n",
      "\titers: 600, epoch: 17 | loss: 0.0365006\n",
      "\tspeed: 0.0341s/iter; left time: 103.0427s\n",
      "\titers: 700, epoch: 17 | loss: 0.0371170\n",
      "\tspeed: 0.0341s/iter; left time: 99.6480s\n",
      "\titers: 800, epoch: 17 | loss: 0.0356720\n",
      "\tspeed: 0.0340s/iter; left time: 96.0678s\n",
      "\titers: 900, epoch: 17 | loss: 0.0351860\n",
      "\tspeed: 0.0341s/iter; left time: 92.7990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.08s\n",
      "Steps: 906 | Train Loss: 0.0358196 Vali Loss: 0.0584597 Test Loss: 0.0634428\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0369047\n",
      "\tspeed: 0.0937s/iter; left time: 245.2724s\n",
      "\titers: 200, epoch: 18 | loss: 0.0333894\n",
      "\tspeed: 0.0341s/iter; left time: 85.8503s\n",
      "\titers: 300, epoch: 18 | loss: 0.0319502\n",
      "\tspeed: 0.0341s/iter; left time: 82.3783s\n",
      "\titers: 400, epoch: 18 | loss: 0.0355705\n",
      "\tspeed: 0.0341s/iter; left time: 79.0800s\n",
      "\titers: 500, epoch: 18 | loss: 0.0322271\n",
      "\tspeed: 0.0340s/iter; left time: 75.5469s\n",
      "\titers: 600, epoch: 18 | loss: 0.0342900\n",
      "\tspeed: 0.0341s/iter; left time: 72.2025s\n",
      "\titers: 700, epoch: 18 | loss: 0.0366018\n",
      "\tspeed: 0.0341s/iter; left time: 68.7861s\n",
      "\titers: 800, epoch: 18 | loss: 0.0388807\n",
      "\tspeed: 0.0340s/iter; left time: 65.3016s\n",
      "\titers: 900, epoch: 18 | loss: 0.0359373\n",
      "\tspeed: 0.0341s/iter; left time: 62.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:31.10s\n",
      "Steps: 906 | Train Loss: 0.0352443 Vali Loss: 0.0587067 Test Loss: 0.0646590\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_24_FR_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01250072754919529, rmse:0.11180665343999863, mae:0.06438585370779037, rse:0.4314415752887726\n",
      "Intermediate time for FR and pred_len 24: 00h:23m:35.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_96_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1902333\n",
      "\tspeed: 0.0636s/iter; left time: 1142.9379s\n",
      "\titers: 200, epoch: 1 | loss: 0.1634794\n",
      "\tspeed: 0.0419s/iter; left time: 749.2805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1666822\n",
      "\tspeed: 0.0420s/iter; left time: 746.1554s\n",
      "\titers: 400, epoch: 1 | loss: 0.1558330\n",
      "\tspeed: 0.0419s/iter; left time: 741.1753s\n",
      "\titers: 500, epoch: 1 | loss: 0.1509849\n",
      "\tspeed: 0.0420s/iter; left time: 738.1542s\n",
      "\titers: 600, epoch: 1 | loss: 0.1476412\n",
      "\tspeed: 0.0420s/iter; left time: 734.5278s\n",
      "\titers: 700, epoch: 1 | loss: 0.1512190\n",
      "\tspeed: 0.0420s/iter; left time: 730.4839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1417792\n",
      "\tspeed: 0.0420s/iter; left time: 726.5070s\n",
      "\titers: 900, epoch: 1 | loss: 0.1403145\n",
      "\tspeed: 0.0424s/iter; left time: 729.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 904 | Train Loss: 0.1621709 Vali Loss: 0.1583142 Test Loss: 0.1844553\n",
      "Validation loss decreased (inf --> 0.158314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330157\n",
      "\tspeed: 0.1175s/iter; left time: 2006.5724s\n",
      "\titers: 200, epoch: 2 | loss: 0.1246072\n",
      "\tspeed: 0.0420s/iter; left time: 713.5594s\n",
      "\titers: 300, epoch: 2 | loss: 0.1126059\n",
      "\tspeed: 0.0421s/iter; left time: 710.1757s\n",
      "\titers: 400, epoch: 2 | loss: 0.1093363\n",
      "\tspeed: 0.0421s/iter; left time: 705.6017s\n",
      "\titers: 500, epoch: 2 | loss: 0.1034709\n",
      "\tspeed: 0.0421s/iter; left time: 701.4904s\n",
      "\titers: 600, epoch: 2 | loss: 0.1020617\n",
      "\tspeed: 0.0420s/iter; left time: 696.0989s\n",
      "\titers: 700, epoch: 2 | loss: 0.0958327\n",
      "\tspeed: 0.0420s/iter; left time: 692.4386s\n",
      "\titers: 800, epoch: 2 | loss: 0.0837372\n",
      "\tspeed: 0.0418s/iter; left time: 684.7476s\n",
      "\titers: 900, epoch: 2 | loss: 0.0910152\n",
      "\tspeed: 0.0415s/iter; left time: 675.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.1095183 Vali Loss: 0.1063607 Test Loss: 0.1212249\n",
      "Validation loss decreased (0.158314 --> 0.106361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888553\n",
      "\tspeed: 0.1167s/iter; left time: 1886.6447s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888103\n",
      "\tspeed: 0.0421s/iter; left time: 676.2275s\n",
      "\titers: 300, epoch: 3 | loss: 0.0863014\n",
      "\tspeed: 0.0421s/iter; left time: 671.7998s\n",
      "\titers: 400, epoch: 3 | loss: 0.0804213\n",
      "\tspeed: 0.0421s/iter; left time: 667.5718s\n",
      "\titers: 500, epoch: 3 | loss: 0.0833842\n",
      "\tspeed: 0.0421s/iter; left time: 663.2878s\n",
      "\titers: 600, epoch: 3 | loss: 0.0776550\n",
      "\tspeed: 0.0421s/iter; left time: 659.6652s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751079\n",
      "\tspeed: 0.0420s/iter; left time: 654.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0775777\n",
      "\tspeed: 0.0415s/iter; left time: 641.7995s\n",
      "\titers: 900, epoch: 3 | loss: 0.0718875\n",
      "\tspeed: 0.0415s/iter; left time: 637.9233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 904 | Train Loss: 0.0825873 Vali Loss: 0.0874852 Test Loss: 0.1007140\n",
      "Validation loss decreased (0.106361 --> 0.087485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0644550\n",
      "\tspeed: 0.1176s/iter; left time: 1794.9362s\n",
      "\titers: 200, epoch: 4 | loss: 0.0673058\n",
      "\tspeed: 0.0414s/iter; left time: 628.7548s\n",
      "\titers: 300, epoch: 4 | loss: 0.0663593\n",
      "\tspeed: 0.0414s/iter; left time: 624.2688s\n",
      "\titers: 400, epoch: 4 | loss: 0.0698647\n",
      "\tspeed: 0.0415s/iter; left time: 620.4678s\n",
      "\titers: 500, epoch: 4 | loss: 0.0648271\n",
      "\tspeed: 0.0415s/iter; left time: 616.3495s\n",
      "\titers: 600, epoch: 4 | loss: 0.0635923\n",
      "\tspeed: 0.0414s/iter; left time: 612.1505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0624922\n",
      "\tspeed: 0.0415s/iter; left time: 608.3211s\n",
      "\titers: 800, epoch: 4 | loss: 0.0619351\n",
      "\tspeed: 0.0414s/iter; left time: 603.8803s\n",
      "\titers: 900, epoch: 4 | loss: 0.0630612\n",
      "\tspeed: 0.0415s/iter; left time: 600.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.74s\n",
      "Steps: 904 | Train Loss: 0.0674741 Vali Loss: 0.0844296 Test Loss: 0.0921732\n",
      "Validation loss decreased (0.087485 --> 0.084430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639159\n",
      "\tspeed: 0.1174s/iter; left time: 1686.5920s\n",
      "\titers: 200, epoch: 5 | loss: 0.0614217\n",
      "\tspeed: 0.0416s/iter; left time: 592.8504s\n",
      "\titers: 300, epoch: 5 | loss: 0.0670402\n",
      "\tspeed: 0.0415s/iter; left time: 588.2780s\n",
      "\titers: 400, epoch: 5 | loss: 0.0595234\n",
      "\tspeed: 0.0415s/iter; left time: 583.8364s\n",
      "\titers: 500, epoch: 5 | loss: 0.0611329\n",
      "\tspeed: 0.0415s/iter; left time: 579.7432s\n",
      "\titers: 600, epoch: 5 | loss: 0.0632634\n",
      "\tspeed: 0.0415s/iter; left time: 575.5308s\n",
      "\titers: 700, epoch: 5 | loss: 0.0614533\n",
      "\tspeed: 0.0415s/iter; left time: 571.4856s\n",
      "\titers: 800, epoch: 5 | loss: 0.0643962\n",
      "\tspeed: 0.0415s/iter; left time: 567.3923s\n",
      "\titers: 900, epoch: 5 | loss: 0.0656714\n",
      "\tspeed: 0.0415s/iter; left time: 563.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0626034 Vali Loss: 0.0815981 Test Loss: 0.0909119\n",
      "Validation loss decreased (0.084430 --> 0.081598).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0579641\n",
      "\tspeed: 0.1187s/iter; left time: 1598.3911s\n",
      "\titers: 200, epoch: 6 | loss: 0.0595998\n",
      "\tspeed: 0.0415s/iter; left time: 554.7178s\n",
      "\titers: 300, epoch: 6 | loss: 0.0583193\n",
      "\tspeed: 0.0415s/iter; left time: 550.5876s\n",
      "\titers: 400, epoch: 6 | loss: 0.0573336\n",
      "\tspeed: 0.0415s/iter; left time: 546.7790s\n",
      "\titers: 500, epoch: 6 | loss: 0.0537359\n",
      "\tspeed: 0.0416s/iter; left time: 542.7198s\n",
      "\titers: 600, epoch: 6 | loss: 0.0568817\n",
      "\tspeed: 0.0415s/iter; left time: 537.9688s\n",
      "\titers: 700, epoch: 6 | loss: 0.0555145\n",
      "\tspeed: 0.0415s/iter; left time: 533.7798s\n",
      "\titers: 800, epoch: 6 | loss: 0.0552718\n",
      "\tspeed: 0.0415s/iter; left time: 530.2181s\n",
      "\titers: 900, epoch: 6 | loss: 0.0597004\n",
      "\tspeed: 0.0416s/iter; left time: 526.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.0590999 Vali Loss: 0.0809355 Test Loss: 0.0917555\n",
      "Validation loss decreased (0.081598 --> 0.080936).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0539223\n",
      "\tspeed: 0.1172s/iter; left time: 1472.2428s\n",
      "\titers: 200, epoch: 7 | loss: 0.0613421\n",
      "\tspeed: 0.0415s/iter; left time: 516.5350s\n",
      "\titers: 300, epoch: 7 | loss: 0.0540870\n",
      "\tspeed: 0.0415s/iter; left time: 512.4116s\n",
      "\titers: 400, epoch: 7 | loss: 0.0517807\n",
      "\tspeed: 0.0415s/iter; left time: 508.2118s\n",
      "\titers: 500, epoch: 7 | loss: 0.0519386\n",
      "\tspeed: 0.0415s/iter; left time: 504.1703s\n",
      "\titers: 600, epoch: 7 | loss: 0.0478697\n",
      "\tspeed: 0.0415s/iter; left time: 500.2220s\n",
      "\titers: 700, epoch: 7 | loss: 0.0569892\n",
      "\tspeed: 0.0415s/iter; left time: 495.9877s\n",
      "\titers: 800, epoch: 7 | loss: 0.0547691\n",
      "\tspeed: 0.0415s/iter; left time: 491.9064s\n",
      "\titers: 900, epoch: 7 | loss: 0.0566718\n",
      "\tspeed: 0.0415s/iter; left time: 487.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.0561235 Vali Loss: 0.0818110 Test Loss: 0.0925347\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0545926\n",
      "\tspeed: 0.1134s/iter; left time: 1320.9235s\n",
      "\titers: 200, epoch: 8 | loss: 0.0537039\n",
      "\tspeed: 0.0415s/iter; left time: 479.6749s\n",
      "\titers: 300, epoch: 8 | loss: 0.0538438\n",
      "\tspeed: 0.0420s/iter; left time: 481.5297s\n",
      "\titers: 400, epoch: 8 | loss: 0.0485980\n",
      "\tspeed: 0.0421s/iter; left time: 477.8452s\n",
      "\titers: 500, epoch: 8 | loss: 0.0490118\n",
      "\tspeed: 0.0421s/iter; left time: 473.5320s\n",
      "\titers: 600, epoch: 8 | loss: 0.0507474\n",
      "\tspeed: 0.0421s/iter; left time: 469.4826s\n",
      "\titers: 700, epoch: 8 | loss: 0.0488948\n",
      "\tspeed: 0.0421s/iter; left time: 465.4635s\n",
      "\titers: 800, epoch: 8 | loss: 0.0515667\n",
      "\tspeed: 0.0421s/iter; left time: 461.2118s\n",
      "\titers: 900, epoch: 8 | loss: 0.0471621\n",
      "\tspeed: 0.0421s/iter; left time: 456.8298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 904 | Train Loss: 0.0534966 Vali Loss: 0.0834365 Test Loss: 0.0937311\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0504029\n",
      "\tspeed: 0.1146s/iter; left time: 1232.1206s\n",
      "\titers: 200, epoch: 9 | loss: 0.0501226\n",
      "\tspeed: 0.0421s/iter; left time: 447.8415s\n",
      "\titers: 300, epoch: 9 | loss: 0.0521222\n",
      "\tspeed: 0.0421s/iter; left time: 443.8949s\n",
      "\titers: 400, epoch: 9 | loss: 0.0458085\n",
      "\tspeed: 0.0421s/iter; left time: 439.7019s\n",
      "\titers: 500, epoch: 9 | loss: 0.0503745\n",
      "\tspeed: 0.0421s/iter; left time: 435.3861s\n",
      "\titers: 600, epoch: 9 | loss: 0.0523974\n",
      "\tspeed: 0.0421s/iter; left time: 431.0932s\n",
      "\titers: 700, epoch: 9 | loss: 0.0510676\n",
      "\tspeed: 0.0421s/iter; left time: 426.9360s\n",
      "\titers: 800, epoch: 9 | loss: 0.0508459\n",
      "\tspeed: 0.0421s/iter; left time: 422.6381s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501447\n",
      "\tspeed: 0.0421s/iter; left time: 418.5754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0511315 Vali Loss: 0.0806643 Test Loss: 0.0902437\n",
      "Validation loss decreased (0.080936 --> 0.080664).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0479229\n",
      "\tspeed: 0.1181s/iter; left time: 1162.5802s\n",
      "\titers: 200, epoch: 10 | loss: 0.0458388\n",
      "\tspeed: 0.0421s/iter; left time: 410.0027s\n",
      "\titers: 300, epoch: 10 | loss: 0.0468625\n",
      "\tspeed: 0.0422s/iter; left time: 406.5477s\n",
      "\titers: 400, epoch: 10 | loss: 0.0468525\n",
      "\tspeed: 0.0421s/iter; left time: 402.3018s\n",
      "\titers: 500, epoch: 10 | loss: 0.0479589\n",
      "\tspeed: 0.0421s/iter; left time: 397.7641s\n",
      "\titers: 600, epoch: 10 | loss: 0.0515600\n",
      "\tspeed: 0.0421s/iter; left time: 393.0768s\n",
      "\titers: 700, epoch: 10 | loss: 0.0529387\n",
      "\tspeed: 0.0421s/iter; left time: 388.9255s\n",
      "\titers: 800, epoch: 10 | loss: 0.0519285\n",
      "\tspeed: 0.0421s/iter; left time: 385.1772s\n",
      "\titers: 900, epoch: 10 | loss: 0.0498877\n",
      "\tspeed: 0.0421s/iter; left time: 380.8352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 904 | Train Loss: 0.0491287 Vali Loss: 0.0825551 Test Loss: 0.0938539\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0456407\n",
      "\tspeed: 0.1147s/iter; left time: 1025.6345s\n",
      "\titers: 200, epoch: 11 | loss: 0.0484030\n",
      "\tspeed: 0.0415s/iter; left time: 367.2298s\n",
      "\titers: 300, epoch: 11 | loss: 0.0500798\n",
      "\tspeed: 0.0415s/iter; left time: 363.0895s\n",
      "\titers: 400, epoch: 11 | loss: 0.0489990\n",
      "\tspeed: 0.0415s/iter; left time: 358.7714s\n",
      "\titers: 500, epoch: 11 | loss: 0.0480193\n",
      "\tspeed: 0.0415s/iter; left time: 354.8332s\n",
      "\titers: 600, epoch: 11 | loss: 0.0455437\n",
      "\tspeed: 0.0415s/iter; left time: 350.5578s\n",
      "\titers: 700, epoch: 11 | loss: 0.0465373\n",
      "\tspeed: 0.0415s/iter; left time: 346.4876s\n",
      "\titers: 800, epoch: 11 | loss: 0.0471579\n",
      "\tspeed: 0.0415s/iter; left time: 342.2289s\n",
      "\titers: 900, epoch: 11 | loss: 0.0470960\n",
      "\tspeed: 0.0415s/iter; left time: 338.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 904 | Train Loss: 0.0474263 Vali Loss: 0.0815087 Test Loss: 0.0885854\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0434840\n",
      "\tspeed: 0.1146s/iter; left time: 920.6887s\n",
      "\titers: 200, epoch: 12 | loss: 0.0445123\n",
      "\tspeed: 0.0420s/iter; left time: 333.5449s\n",
      "\titers: 300, epoch: 12 | loss: 0.0451364\n",
      "\tspeed: 0.0420s/iter; left time: 329.3751s\n",
      "\titers: 400, epoch: 12 | loss: 0.0416487\n",
      "\tspeed: 0.0420s/iter; left time: 325.0469s\n",
      "\titers: 500, epoch: 12 | loss: 0.0491649\n",
      "\tspeed: 0.0420s/iter; left time: 320.6819s\n",
      "\titers: 600, epoch: 12 | loss: 0.0467862\n",
      "\tspeed: 0.0420s/iter; left time: 316.8661s\n",
      "\titers: 700, epoch: 12 | loss: 0.0475624\n",
      "\tspeed: 0.0420s/iter; left time: 312.2396s\n",
      "\titers: 800, epoch: 12 | loss: 0.0455075\n",
      "\tspeed: 0.0420s/iter; left time: 308.3541s\n",
      "\titers: 900, epoch: 12 | loss: 0.0451173\n",
      "\tspeed: 0.0420s/iter; left time: 304.0306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 904 | Train Loss: 0.0458701 Vali Loss: 0.0813544 Test Loss: 0.0891244\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0434529\n",
      "\tspeed: 0.1139s/iter; left time: 812.5212s\n",
      "\titers: 200, epoch: 13 | loss: 0.0425601\n",
      "\tspeed: 0.0414s/iter; left time: 291.4937s\n",
      "\titers: 300, epoch: 13 | loss: 0.0390885\n",
      "\tspeed: 0.0415s/iter; left time: 287.4257s\n",
      "\titers: 400, epoch: 13 | loss: 0.0431902\n",
      "\tspeed: 0.0415s/iter; left time: 283.3661s\n",
      "\titers: 500, epoch: 13 | loss: 0.0442528\n",
      "\tspeed: 0.0415s/iter; left time: 279.1462s\n",
      "\titers: 600, epoch: 13 | loss: 0.0448327\n",
      "\tspeed: 0.0414s/iter; left time: 274.9087s\n",
      "\titers: 700, epoch: 13 | loss: 0.0427357\n",
      "\tspeed: 0.0415s/iter; left time: 270.9401s\n",
      "\titers: 800, epoch: 13 | loss: 0.0454790\n",
      "\tspeed: 0.0415s/iter; left time: 266.7131s\n",
      "\titers: 900, epoch: 13 | loss: 0.0471705\n",
      "\tspeed: 0.0415s/iter; left time: 262.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 904 | Train Loss: 0.0444942 Vali Loss: 0.0826097 Test Loss: 0.0910248\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0420628\n",
      "\tspeed: 0.1133s/iter; left time: 705.8496s\n",
      "\titers: 200, epoch: 14 | loss: 0.0434183\n",
      "\tspeed: 0.0415s/iter; left time: 254.3482s\n",
      "\titers: 300, epoch: 14 | loss: 0.0415930\n",
      "\tspeed: 0.0415s/iter; left time: 250.2050s\n",
      "\titers: 400, epoch: 14 | loss: 0.0413548\n",
      "\tspeed: 0.0415s/iter; left time: 245.9290s\n",
      "\titers: 500, epoch: 14 | loss: 0.0413789\n",
      "\tspeed: 0.0415s/iter; left time: 241.9992s\n",
      "\titers: 600, epoch: 14 | loss: 0.0463429\n",
      "\tspeed: 0.0415s/iter; left time: 237.8058s\n",
      "\titers: 700, epoch: 14 | loss: 0.0457477\n",
      "\tspeed: 0.0415s/iter; left time: 233.6698s\n",
      "\titers: 800, epoch: 14 | loss: 0.0433612\n",
      "\tspeed: 0.0415s/iter; left time: 229.5864s\n",
      "\titers: 900, epoch: 14 | loss: 0.0437617\n",
      "\tspeed: 0.0416s/iter; left time: 225.8041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0433176 Vali Loss: 0.0822506 Test Loss: 0.0912996\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022864822298288345, rmse:0.1512111872434616, mae:0.09028714150190353, rse:0.5849250555038452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1801853\n",
      "\tspeed: 0.0440s/iter; left time: 791.3338s\n",
      "\titers: 200, epoch: 1 | loss: 0.1757706\n",
      "\tspeed: 0.0415s/iter; left time: 742.3598s\n",
      "\titers: 300, epoch: 1 | loss: 0.1683250\n",
      "\tspeed: 0.0416s/iter; left time: 738.8906s\n",
      "\titers: 400, epoch: 1 | loss: 0.1585326\n",
      "\tspeed: 0.0416s/iter; left time: 734.6853s\n",
      "\titers: 500, epoch: 1 | loss: 0.1467624\n",
      "\tspeed: 0.0415s/iter; left time: 730.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.1519888\n",
      "\tspeed: 0.0415s/iter; left time: 726.2310s\n",
      "\titers: 700, epoch: 1 | loss: 0.1499733\n",
      "\tspeed: 0.0415s/iter; left time: 722.0790s\n",
      "\titers: 800, epoch: 1 | loss: 0.1427606\n",
      "\tspeed: 0.0416s/iter; left time: 718.2521s\n",
      "\titers: 900, epoch: 1 | loss: 0.1468351\n",
      "\tspeed: 0.0416s/iter; left time: 713.8953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.86s\n",
      "Steps: 904 | Train Loss: 0.1637526 Vali Loss: 0.1575865 Test Loss: 0.1835811\n",
      "Validation loss decreased (inf --> 0.157586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1303630\n",
      "\tspeed: 0.1164s/iter; left time: 1988.3099s\n",
      "\titers: 200, epoch: 2 | loss: 0.1302949\n",
      "\tspeed: 0.0415s/iter; left time: 705.1301s\n",
      "\titers: 300, epoch: 2 | loss: 0.1157242\n",
      "\tspeed: 0.0415s/iter; left time: 700.7159s\n",
      "\titers: 400, epoch: 2 | loss: 0.1105489\n",
      "\tspeed: 0.0415s/iter; left time: 696.8772s\n",
      "\titers: 500, epoch: 2 | loss: 0.1054600\n",
      "\tspeed: 0.0415s/iter; left time: 692.2461s\n",
      "\titers: 600, epoch: 2 | loss: 0.1001050\n",
      "\tspeed: 0.0415s/iter; left time: 688.4405s\n",
      "\titers: 700, epoch: 2 | loss: 0.1084336\n",
      "\tspeed: 0.0416s/iter; left time: 684.7686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0790982\n",
      "\tspeed: 0.0415s/iter; left time: 680.0364s\n",
      "\titers: 900, epoch: 2 | loss: 0.0886261\n",
      "\tspeed: 0.0415s/iter; left time: 676.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1079180 Vali Loss: 0.1051555 Test Loss: 0.1193966\n",
      "Validation loss decreased (0.157586 --> 0.105156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0876562\n",
      "\tspeed: 0.1174s/iter; left time: 1899.3789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0827423\n",
      "\tspeed: 0.0416s/iter; left time: 668.4151s\n",
      "\titers: 300, epoch: 3 | loss: 0.0847814\n",
      "\tspeed: 0.0420s/iter; left time: 671.6212s\n",
      "\titers: 400, epoch: 3 | loss: 0.0777887\n",
      "\tspeed: 0.0422s/iter; left time: 669.6548s\n",
      "\titers: 500, epoch: 3 | loss: 0.0885318\n",
      "\tspeed: 0.0422s/iter; left time: 665.4361s\n",
      "\titers: 600, epoch: 3 | loss: 0.0824113\n",
      "\tspeed: 0.0422s/iter; left time: 660.7655s\n",
      "\titers: 700, epoch: 3 | loss: 0.0705649\n",
      "\tspeed: 0.0421s/iter; left time: 656.3357s\n",
      "\titers: 800, epoch: 3 | loss: 0.0739427\n",
      "\tspeed: 0.0422s/iter; left time: 652.2881s\n",
      "\titers: 900, epoch: 3 | loss: 0.0669540\n",
      "\tspeed: 0.0422s/iter; left time: 648.1564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 904 | Train Loss: 0.0807194 Vali Loss: 0.0859751 Test Loss: 0.0970179\n",
      "Validation loss decreased (0.105156 --> 0.085975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0694406\n",
      "\tspeed: 0.1169s/iter; left time: 1785.3883s\n",
      "\titers: 200, epoch: 4 | loss: 0.0649310\n",
      "\tspeed: 0.0421s/iter; left time: 639.1821s\n",
      "\titers: 300, epoch: 4 | loss: 0.0693028\n",
      "\tspeed: 0.0421s/iter; left time: 634.7391s\n",
      "\titers: 400, epoch: 4 | loss: 0.0685778\n",
      "\tspeed: 0.0421s/iter; left time: 630.5093s\n",
      "\titers: 500, epoch: 4 | loss: 0.0600520\n",
      "\tspeed: 0.0421s/iter; left time: 626.5364s\n",
      "\titers: 600, epoch: 4 | loss: 0.0625884\n",
      "\tspeed: 0.0421s/iter; left time: 622.2753s\n",
      "\titers: 700, epoch: 4 | loss: 0.0620745\n",
      "\tspeed: 0.0422s/iter; left time: 618.5591s\n",
      "\titers: 800, epoch: 4 | loss: 0.0639772\n",
      "\tspeed: 0.0421s/iter; left time: 613.7473s\n",
      "\titers: 900, epoch: 4 | loss: 0.0614068\n",
      "\tspeed: 0.0422s/iter; left time: 609.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 904 | Train Loss: 0.0670069 Vali Loss: 0.0825358 Test Loss: 0.0950642\n",
      "Validation loss decreased (0.085975 --> 0.082536).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0631184\n",
      "\tspeed: 0.1167s/iter; left time: 1676.0975s\n",
      "\titers: 200, epoch: 5 | loss: 0.0672402\n",
      "\tspeed: 0.0422s/iter; left time: 601.3006s\n",
      "\titers: 300, epoch: 5 | loss: 0.0590044\n",
      "\tspeed: 0.0421s/iter; left time: 596.7791s\n",
      "\titers: 400, epoch: 5 | loss: 0.0598044\n",
      "\tspeed: 0.0421s/iter; left time: 592.5886s\n",
      "\titers: 500, epoch: 5 | loss: 0.0639175\n",
      "\tspeed: 0.0422s/iter; left time: 588.8828s\n",
      "\titers: 600, epoch: 5 | loss: 0.0653268\n",
      "\tspeed: 0.0422s/iter; left time: 584.6260s\n",
      "\titers: 700, epoch: 5 | loss: 0.0598224\n",
      "\tspeed: 0.0422s/iter; left time: 580.9071s\n",
      "\titers: 800, epoch: 5 | loss: 0.0627552\n",
      "\tspeed: 0.0422s/iter; left time: 576.0732s\n",
      "\titers: 900, epoch: 5 | loss: 0.0581154\n",
      "\tspeed: 0.0422s/iter; left time: 572.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 904 | Train Loss: 0.0621152 Vali Loss: 0.0814626 Test Loss: 0.0897293\n",
      "Validation loss decreased (0.082536 --> 0.081463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0614372\n",
      "\tspeed: 0.1186s/iter; left time: 1596.5839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0612931\n",
      "\tspeed: 0.0422s/iter; left time: 563.4863s\n",
      "\titers: 300, epoch: 6 | loss: 0.0573931\n",
      "\tspeed: 0.0422s/iter; left time: 559.7017s\n",
      "\titers: 400, epoch: 6 | loss: 0.0569089\n",
      "\tspeed: 0.0422s/iter; left time: 555.2582s\n",
      "\titers: 500, epoch: 6 | loss: 0.0555158\n",
      "\tspeed: 0.0422s/iter; left time: 551.2511s\n",
      "\titers: 600, epoch: 6 | loss: 0.0548578\n",
      "\tspeed: 0.0422s/iter; left time: 546.4935s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584947\n",
      "\tspeed: 0.0422s/iter; left time: 542.6575s\n",
      "\titers: 800, epoch: 6 | loss: 0.0564002\n",
      "\tspeed: 0.0422s/iter; left time: 538.6592s\n",
      "\titers: 900, epoch: 6 | loss: 0.0607242\n",
      "\tspeed: 0.0422s/iter; left time: 534.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.0587400 Vali Loss: 0.0810837 Test Loss: 0.0917180\n",
      "Validation loss decreased (0.081463 --> 0.081084).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583565\n",
      "\tspeed: 0.1175s/iter; left time: 1475.7372s\n",
      "\titers: 200, epoch: 7 | loss: 0.0520255\n",
      "\tspeed: 0.0421s/iter; left time: 524.7099s\n",
      "\titers: 300, epoch: 7 | loss: 0.0552256\n",
      "\tspeed: 0.0422s/iter; left time: 521.0978s\n",
      "\titers: 400, epoch: 7 | loss: 0.0547102\n",
      "\tspeed: 0.0422s/iter; left time: 516.6803s\n",
      "\titers: 500, epoch: 7 | loss: 0.0543888\n",
      "\tspeed: 0.0422s/iter; left time: 512.5356s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582229\n",
      "\tspeed: 0.0421s/iter; left time: 507.9209s\n",
      "\titers: 700, epoch: 7 | loss: 0.0542132\n",
      "\tspeed: 0.0421s/iter; left time: 503.5968s\n",
      "\titers: 800, epoch: 7 | loss: 0.0564435\n",
      "\tspeed: 0.0421s/iter; left time: 499.4522s\n",
      "\titers: 900, epoch: 7 | loss: 0.0559337\n",
      "\tspeed: 0.0422s/iter; left time: 495.7002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 904 | Train Loss: 0.0559357 Vali Loss: 0.0815365 Test Loss: 0.0903651\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0521917\n",
      "\tspeed: 0.1150s/iter; left time: 1340.4555s\n",
      "\titers: 200, epoch: 8 | loss: 0.0473949\n",
      "\tspeed: 0.0418s/iter; left time: 483.2140s\n",
      "\titers: 300, epoch: 8 | loss: 0.0566309\n",
      "\tspeed: 0.0415s/iter; left time: 475.8055s\n",
      "\titers: 400, epoch: 8 | loss: 0.0504954\n",
      "\tspeed: 0.0415s/iter; left time: 471.6473s\n",
      "\titers: 500, epoch: 8 | loss: 0.0503554\n",
      "\tspeed: 0.0416s/iter; left time: 467.7012s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523519\n",
      "\tspeed: 0.0417s/iter; left time: 465.5451s\n",
      "\titers: 700, epoch: 8 | loss: 0.0601990\n",
      "\tspeed: 0.0422s/iter; left time: 466.3816s\n",
      "\titers: 800, epoch: 8 | loss: 0.0574024\n",
      "\tspeed: 0.0422s/iter; left time: 462.0786s\n",
      "\titers: 900, epoch: 8 | loss: 0.0504944\n",
      "\tspeed: 0.0422s/iter; left time: 458.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 904 | Train Loss: 0.0534219 Vali Loss: 0.0815038 Test Loss: 0.0924361\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0555919\n",
      "\tspeed: 0.1144s/iter; left time: 1229.5071s\n",
      "\titers: 200, epoch: 9 | loss: 0.0495185\n",
      "\tspeed: 0.0422s/iter; left time: 449.3055s\n",
      "\titers: 300, epoch: 9 | loss: 0.0503814\n",
      "\tspeed: 0.0422s/iter; left time: 444.9955s\n",
      "\titers: 400, epoch: 9 | loss: 0.0510218\n",
      "\tspeed: 0.0422s/iter; left time: 440.9606s\n",
      "\titers: 500, epoch: 9 | loss: 0.0455104\n",
      "\tspeed: 0.0422s/iter; left time: 436.7347s\n",
      "\titers: 600, epoch: 9 | loss: 0.0525810\n",
      "\tspeed: 0.0422s/iter; left time: 432.1226s\n",
      "\titers: 700, epoch: 9 | loss: 0.0497616\n",
      "\tspeed: 0.0422s/iter; left time: 428.2829s\n",
      "\titers: 800, epoch: 9 | loss: 0.0543077\n",
      "\tspeed: 0.0422s/iter; left time: 424.1257s\n",
      "\titers: 900, epoch: 9 | loss: 0.0499346\n",
      "\tspeed: 0.0422s/iter; left time: 419.7030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 904 | Train Loss: 0.0513986 Vali Loss: 0.0811884 Test Loss: 0.0904090\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0520169\n",
      "\tspeed: 0.1141s/iter; left time: 1123.7260s\n",
      "\titers: 200, epoch: 10 | loss: 0.0472272\n",
      "\tspeed: 0.0421s/iter; left time: 410.3697s\n",
      "\titers: 300, epoch: 10 | loss: 0.0494040\n",
      "\tspeed: 0.0421s/iter; left time: 406.2686s\n",
      "\titers: 400, epoch: 10 | loss: 0.0476900\n",
      "\tspeed: 0.0422s/iter; left time: 402.5648s\n",
      "\titers: 500, epoch: 10 | loss: 0.0437683\n",
      "\tspeed: 0.0422s/iter; left time: 398.5206s\n",
      "\titers: 600, epoch: 10 | loss: 0.0510910\n",
      "\tspeed: 0.0422s/iter; left time: 394.2528s\n",
      "\titers: 700, epoch: 10 | loss: 0.0468750\n",
      "\tspeed: 0.0422s/iter; left time: 389.9539s\n",
      "\titers: 800, epoch: 10 | loss: 0.0480250\n",
      "\tspeed: 0.0421s/iter; left time: 385.1841s\n",
      "\titers: 900, epoch: 10 | loss: 0.0472614\n",
      "\tspeed: 0.0421s/iter; left time: 381.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 904 | Train Loss: 0.0495849 Vali Loss: 0.0814730 Test Loss: 0.0901214\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0507243\n",
      "\tspeed: 0.1141s/iter; left time: 1020.6024s\n",
      "\titers: 200, epoch: 11 | loss: 0.0478392\n",
      "\tspeed: 0.0422s/iter; left time: 372.7031s\n",
      "\titers: 300, epoch: 11 | loss: 0.0494696\n",
      "\tspeed: 0.0421s/iter; left time: 367.6222s\n",
      "\titers: 400, epoch: 11 | loss: 0.0495104\n",
      "\tspeed: 0.0416s/iter; left time: 359.1142s\n",
      "\titers: 500, epoch: 11 | loss: 0.0487904\n",
      "\tspeed: 0.0416s/iter; left time: 355.1483s\n",
      "\titers: 600, epoch: 11 | loss: 0.0512776\n",
      "\tspeed: 0.0415s/iter; left time: 350.6539s\n",
      "\titers: 700, epoch: 11 | loss: 0.0480168\n",
      "\tspeed: 0.0416s/iter; left time: 346.8143s\n",
      "\titers: 800, epoch: 11 | loss: 0.0467180\n",
      "\tspeed: 0.0416s/iter; left time: 342.6088s\n",
      "\titers: 900, epoch: 11 | loss: 0.0499095\n",
      "\tspeed: 0.0416s/iter; left time: 338.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 904 | Train Loss: 0.0479882 Vali Loss: 0.0793715 Test Loss: 0.0891887\n",
      "Validation loss decreased (0.081084 --> 0.079371).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0468300\n",
      "\tspeed: 0.1166s/iter; left time: 937.1695s\n",
      "\titers: 200, epoch: 12 | loss: 0.0471748\n",
      "\tspeed: 0.0415s/iter; left time: 329.6437s\n",
      "\titers: 300, epoch: 12 | loss: 0.0472506\n",
      "\tspeed: 0.0415s/iter; left time: 325.5373s\n",
      "\titers: 400, epoch: 12 | loss: 0.0449921\n",
      "\tspeed: 0.0415s/iter; left time: 321.2439s\n",
      "\titers: 500, epoch: 12 | loss: 0.0452186\n",
      "\tspeed: 0.0416s/iter; left time: 317.3878s\n",
      "\titers: 600, epoch: 12 | loss: 0.0509672\n",
      "\tspeed: 0.0415s/iter; left time: 313.1249s\n",
      "\titers: 700, epoch: 12 | loss: 0.0462397\n",
      "\tspeed: 0.0416s/iter; left time: 309.5066s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501083\n",
      "\tspeed: 0.0415s/iter; left time: 304.8201s\n",
      "\titers: 900, epoch: 12 | loss: 0.0409865\n",
      "\tspeed: 0.0415s/iter; left time: 300.6787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0465710 Vali Loss: 0.0800179 Test Loss: 0.0904158\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0508476\n",
      "\tspeed: 0.1133s/iter; left time: 808.3958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0427458\n",
      "\tspeed: 0.0415s/iter; left time: 292.0275s\n",
      "\titers: 300, epoch: 13 | loss: 0.0444610\n",
      "\tspeed: 0.0415s/iter; left time: 287.6441s\n",
      "\titers: 400, epoch: 13 | loss: 0.0467233\n",
      "\tspeed: 0.0415s/iter; left time: 283.5360s\n",
      "\titers: 500, epoch: 13 | loss: 0.0473262\n",
      "\tspeed: 0.0415s/iter; left time: 279.3990s\n",
      "\titers: 600, epoch: 13 | loss: 0.0471629\n",
      "\tspeed: 0.0415s/iter; left time: 275.2035s\n",
      "\titers: 700, epoch: 13 | loss: 0.0465323\n",
      "\tspeed: 0.0415s/iter; left time: 271.1061s\n",
      "\titers: 800, epoch: 13 | loss: 0.0462343\n",
      "\tspeed: 0.0415s/iter; left time: 267.0899s\n",
      "\titers: 900, epoch: 13 | loss: 0.0459190\n",
      "\tspeed: 0.0415s/iter; left time: 262.9103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0452570 Vali Loss: 0.0803579 Test Loss: 0.0906105\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0445291\n",
      "\tspeed: 0.1147s/iter; left time: 714.6974s\n",
      "\titers: 200, epoch: 14 | loss: 0.0431228\n",
      "\tspeed: 0.0416s/iter; left time: 254.9392s\n",
      "\titers: 300, epoch: 14 | loss: 0.0411837\n",
      "\tspeed: 0.0416s/iter; left time: 250.7114s\n",
      "\titers: 400, epoch: 14 | loss: 0.0460565\n",
      "\tspeed: 0.0416s/iter; left time: 246.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0461464\n",
      "\tspeed: 0.0416s/iter; left time: 242.3795s\n",
      "\titers: 600, epoch: 14 | loss: 0.0450274\n",
      "\tspeed: 0.0416s/iter; left time: 238.2954s\n",
      "\titers: 700, epoch: 14 | loss: 0.0455625\n",
      "\tspeed: 0.0416s/iter; left time: 234.2062s\n",
      "\titers: 800, epoch: 14 | loss: 0.0467562\n",
      "\tspeed: 0.0416s/iter; left time: 230.0066s\n",
      "\titers: 900, epoch: 14 | loss: 0.0428233\n",
      "\tspeed: 0.0416s/iter; left time: 225.8443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0440268 Vali Loss: 0.0806199 Test Loss: 0.0894073\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0441201\n",
      "\tspeed: 0.1141s/iter; left time: 607.4821s\n",
      "\titers: 200, epoch: 15 | loss: 0.0444535\n",
      "\tspeed: 0.0416s/iter; left time: 217.3685s\n",
      "\titers: 300, epoch: 15 | loss: 0.0421129\n",
      "\tspeed: 0.0416s/iter; left time: 213.2131s\n",
      "\titers: 400, epoch: 15 | loss: 0.0428866\n",
      "\tspeed: 0.0416s/iter; left time: 208.9029s\n",
      "\titers: 500, epoch: 15 | loss: 0.0471378\n",
      "\tspeed: 0.0416s/iter; left time: 204.8338s\n",
      "\titers: 600, epoch: 15 | loss: 0.0420919\n",
      "\tspeed: 0.0415s/iter; left time: 200.3340s\n",
      "\titers: 700, epoch: 15 | loss: 0.0439522\n",
      "\tspeed: 0.0415s/iter; left time: 196.2551s\n",
      "\titers: 800, epoch: 15 | loss: 0.0430104\n",
      "\tspeed: 0.0415s/iter; left time: 192.0512s\n",
      "\titers: 900, epoch: 15 | loss: 0.0440404\n",
      "\tspeed: 0.0415s/iter; left time: 188.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 904 | Train Loss: 0.0429491 Vali Loss: 0.0811198 Test Loss: 0.0907875\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0435821\n",
      "\tspeed: 0.1137s/iter; left time: 502.4845s\n",
      "\titers: 200, epoch: 16 | loss: 0.0400924\n",
      "\tspeed: 0.0415s/iter; left time: 179.4197s\n",
      "\titers: 300, epoch: 16 | loss: 0.0406727\n",
      "\tspeed: 0.0415s/iter; left time: 175.2932s\n",
      "\titers: 400, epoch: 16 | loss: 0.0391660\n",
      "\tspeed: 0.0415s/iter; left time: 171.1423s\n",
      "\titers: 500, epoch: 16 | loss: 0.0432506\n",
      "\tspeed: 0.0415s/iter; left time: 167.0319s\n",
      "\titers: 600, epoch: 16 | loss: 0.0443221\n",
      "\tspeed: 0.0415s/iter; left time: 162.8413s\n",
      "\titers: 700, epoch: 16 | loss: 0.0404722\n",
      "\tspeed: 0.0416s/iter; left time: 158.7643s\n",
      "\titers: 800, epoch: 16 | loss: 0.0418555\n",
      "\tspeed: 0.0415s/iter; left time: 154.5318s\n",
      "\titers: 900, epoch: 16 | loss: 0.0435021\n",
      "\tspeed: 0.0415s/iter; left time: 150.4151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0420716 Vali Loss: 0.0813945 Test Loss: 0.0900143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_96_FR_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022085649892687798, rmse:0.14861240983009338, mae:0.08917967230081558, rse:0.5748723149299622\n",
      "Intermediate time for FR and pred_len 96: 00h:22m:47.32s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_96_168_FR', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1909381\n",
      "\tspeed: 0.0731s/iter; left time: 1312.3339s\n",
      "\titers: 200, epoch: 1 | loss: 0.1680391\n",
      "\tspeed: 0.0507s/iter; left time: 904.6320s\n",
      "\titers: 300, epoch: 1 | loss: 0.1600669\n",
      "\tspeed: 0.0508s/iter; left time: 900.5058s\n",
      "\titers: 400, epoch: 1 | loss: 0.1592189\n",
      "\tspeed: 0.0508s/iter; left time: 896.9464s\n",
      "\titers: 500, epoch: 1 | loss: 0.1627102\n",
      "\tspeed: 0.0507s/iter; left time: 889.1758s\n",
      "\titers: 600, epoch: 1 | loss: 0.1537818\n",
      "\tspeed: 0.0509s/iter; left time: 887.1121s\n",
      "\titers: 700, epoch: 1 | loss: 0.1487422\n",
      "\tspeed: 0.0509s/iter; left time: 882.5645s\n",
      "\titers: 800, epoch: 1 | loss: 0.1472233\n",
      "\tspeed: 0.0508s/iter; left time: 876.6289s\n",
      "\titers: 900, epoch: 1 | loss: 0.1481563\n",
      "\tspeed: 0.0508s/iter; left time: 871.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.49s\n",
      "Steps: 902 | Train Loss: 0.1627582 Vali Loss: 0.1600794 Test Loss: 0.1866036\n",
      "Validation loss decreased (inf --> 0.160079).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1354579\n",
      "\tspeed: 0.1418s/iter; left time: 2415.9916s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132466\n",
      "\tspeed: 0.0504s/iter; left time: 852.9638s\n",
      "\titers: 300, epoch: 2 | loss: 0.1104991\n",
      "\tspeed: 0.0503s/iter; left time: 847.4892s\n",
      "\titers: 400, epoch: 2 | loss: 0.1086443\n",
      "\tspeed: 0.0503s/iter; left time: 841.3644s\n",
      "\titers: 500, epoch: 2 | loss: 0.1163496\n",
      "\tspeed: 0.0503s/iter; left time: 837.1216s\n",
      "\titers: 600, epoch: 2 | loss: 0.1089604\n",
      "\tspeed: 0.0504s/iter; left time: 834.3447s\n",
      "\titers: 700, epoch: 2 | loss: 0.1045236\n",
      "\tspeed: 0.0504s/iter; left time: 828.4931s\n",
      "\titers: 800, epoch: 2 | loss: 0.0951248\n",
      "\tspeed: 0.0503s/iter; left time: 821.6065s\n",
      "\titers: 900, epoch: 2 | loss: 0.0957951\n",
      "\tspeed: 0.0503s/iter; left time: 817.0893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.1135591 Vali Loss: 0.1164185 Test Loss: 0.1333146\n",
      "Validation loss decreased (0.160079 --> 0.116418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982654\n",
      "\tspeed: 0.1420s/iter; left time: 2291.4045s\n",
      "\titers: 200, epoch: 3 | loss: 0.1013190\n",
      "\tspeed: 0.0505s/iter; left time: 809.4094s\n",
      "\titers: 300, epoch: 3 | loss: 0.0925633\n",
      "\tspeed: 0.0504s/iter; left time: 803.6832s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857650\n",
      "\tspeed: 0.0504s/iter; left time: 798.1677s\n",
      "\titers: 500, epoch: 3 | loss: 0.0912207\n",
      "\tspeed: 0.0504s/iter; left time: 792.8329s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933190\n",
      "\tspeed: 0.0504s/iter; left time: 787.6501s\n",
      "\titers: 700, epoch: 3 | loss: 0.0857234\n",
      "\tspeed: 0.0504s/iter; left time: 783.2593s\n",
      "\titers: 800, epoch: 3 | loss: 0.0845863\n",
      "\tspeed: 0.0504s/iter; left time: 777.4839s\n",
      "\titers: 900, epoch: 3 | loss: 0.0849761\n",
      "\tspeed: 0.0504s/iter; left time: 772.3460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0924629 Vali Loss: 0.1071270 Test Loss: 0.1229606\n",
      "Validation loss decreased (0.116418 --> 0.107127).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0786718\n",
      "\tspeed: 0.1427s/iter; left time: 2173.8139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772330\n",
      "\tspeed: 0.0508s/iter; left time: 769.2309s\n",
      "\titers: 300, epoch: 4 | loss: 0.0676827\n",
      "\tspeed: 0.0508s/iter; left time: 764.0135s\n",
      "\titers: 400, epoch: 4 | loss: 0.0790973\n",
      "\tspeed: 0.0508s/iter; left time: 758.7215s\n",
      "\titers: 500, epoch: 4 | loss: 0.0708028\n",
      "\tspeed: 0.0508s/iter; left time: 753.5663s\n",
      "\titers: 600, epoch: 4 | loss: 0.0716025\n",
      "\tspeed: 0.0508s/iter; left time: 748.6905s\n",
      "\titers: 700, epoch: 4 | loss: 0.0682254\n",
      "\tspeed: 0.0509s/iter; left time: 744.3430s\n",
      "\titers: 800, epoch: 4 | loss: 0.0689737\n",
      "\tspeed: 0.0509s/iter; left time: 740.2185s\n",
      "\titers: 900, epoch: 4 | loss: 0.0658434\n",
      "\tspeed: 0.0509s/iter; left time: 735.3688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 902 | Train Loss: 0.0725442 Vali Loss: 0.0860735 Test Loss: 0.0965769\n",
      "Validation loss decreased (0.107127 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0697073\n",
      "\tspeed: 0.1409s/iter; left time: 2019.6899s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624888\n",
      "\tspeed: 0.0504s/iter; left time: 716.8856s\n",
      "\titers: 300, epoch: 5 | loss: 0.0617630\n",
      "\tspeed: 0.0504s/iter; left time: 711.9624s\n",
      "\titers: 400, epoch: 5 | loss: 0.0649016\n",
      "\tspeed: 0.0504s/iter; left time: 707.4037s\n",
      "\titers: 500, epoch: 5 | loss: 0.0683278\n",
      "\tspeed: 0.0503s/iter; left time: 701.4687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0693546\n",
      "\tspeed: 0.0504s/iter; left time: 696.8262s\n",
      "\titers: 700, epoch: 5 | loss: 0.0664765\n",
      "\tspeed: 0.0504s/iter; left time: 691.6092s\n",
      "\titers: 800, epoch: 5 | loss: 0.0678215\n",
      "\tspeed: 0.0504s/iter; left time: 687.0570s\n",
      "\titers: 900, epoch: 5 | loss: 0.0628805\n",
      "\tspeed: 0.0504s/iter; left time: 681.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0666008 Vali Loss: 0.0907133 Test Loss: 0.1022113\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630694\n",
      "\tspeed: 0.1370s/iter; left time: 1839.6319s\n",
      "\titers: 200, epoch: 6 | loss: 0.0735694\n",
      "\tspeed: 0.0509s/iter; left time: 678.4986s\n",
      "\titers: 300, epoch: 6 | loss: 0.0657603\n",
      "\tspeed: 0.0504s/iter; left time: 667.1797s\n",
      "\titers: 400, epoch: 6 | loss: 0.0630703\n",
      "\tspeed: 0.0504s/iter; left time: 662.3338s\n",
      "\titers: 500, epoch: 6 | loss: 0.0608161\n",
      "\tspeed: 0.0505s/iter; left time: 657.7881s\n",
      "\titers: 600, epoch: 6 | loss: 0.0605147\n",
      "\tspeed: 0.0504s/iter; left time: 652.2240s\n",
      "\titers: 700, epoch: 6 | loss: 0.0623604\n",
      "\tspeed: 0.0505s/iter; left time: 647.8566s\n",
      "\titers: 800, epoch: 6 | loss: 0.0683586\n",
      "\tspeed: 0.0504s/iter; left time: 641.5434s\n",
      "\titers: 900, epoch: 6 | loss: 0.0637278\n",
      "\tspeed: 0.0504s/iter; left time: 636.4203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.0630607 Vali Loss: 0.0877217 Test Loss: 0.1008626\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0606438\n",
      "\tspeed: 0.1377s/iter; left time: 1725.1466s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599479\n",
      "\tspeed: 0.0508s/iter; left time: 631.3995s\n",
      "\titers: 300, epoch: 7 | loss: 0.0584510\n",
      "\tspeed: 0.0508s/iter; left time: 626.5690s\n",
      "\titers: 400, epoch: 7 | loss: 0.0613597\n",
      "\tspeed: 0.0508s/iter; left time: 621.3450s\n",
      "\titers: 500, epoch: 7 | loss: 0.0601924\n",
      "\tspeed: 0.0508s/iter; left time: 615.9718s\n",
      "\titers: 600, epoch: 7 | loss: 0.0676273\n",
      "\tspeed: 0.0508s/iter; left time: 611.1803s\n",
      "\titers: 700, epoch: 7 | loss: 0.0549083\n",
      "\tspeed: 0.0508s/iter; left time: 606.1187s\n",
      "\titers: 800, epoch: 7 | loss: 0.0545960\n",
      "\tspeed: 0.0508s/iter; left time: 600.9414s\n",
      "\titers: 900, epoch: 7 | loss: 0.0554606\n",
      "\tspeed: 0.0504s/iter; left time: 591.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.09s\n",
      "Steps: 902 | Train Loss: 0.0600904 Vali Loss: 0.0871552 Test Loss: 0.0970986\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0598685\n",
      "\tspeed: 0.1370s/iter; left time: 1592.5344s\n",
      "\titers: 200, epoch: 8 | loss: 0.0554238\n",
      "\tspeed: 0.0505s/iter; left time: 582.0014s\n",
      "\titers: 300, epoch: 8 | loss: 0.0563658\n",
      "\tspeed: 0.0505s/iter; left time: 576.7205s\n",
      "\titers: 400, epoch: 8 | loss: 0.0521641\n",
      "\tspeed: 0.0504s/iter; left time: 570.6692s\n",
      "\titers: 500, epoch: 8 | loss: 0.0586885\n",
      "\tspeed: 0.0504s/iter; left time: 566.0399s\n",
      "\titers: 600, epoch: 8 | loss: 0.0537777\n",
      "\tspeed: 0.0504s/iter; left time: 560.2831s\n",
      "\titers: 700, epoch: 8 | loss: 0.0583096\n",
      "\tspeed: 0.0505s/iter; left time: 556.6289s\n",
      "\titers: 800, epoch: 8 | loss: 0.0598436\n",
      "\tspeed: 0.0505s/iter; left time: 551.8235s\n",
      "\titers: 900, epoch: 8 | loss: 0.0546309\n",
      "\tspeed: 0.0504s/iter; left time: 546.0885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.74s\n",
      "Steps: 902 | Train Loss: 0.0570632 Vali Loss: 0.0868398 Test Loss: 0.0970632\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570800\n",
      "\tspeed: 0.1395s/iter; left time: 1495.6201s\n",
      "\titers: 200, epoch: 9 | loss: 0.0570607\n",
      "\tspeed: 0.0510s/iter; left time: 541.7118s\n",
      "\titers: 300, epoch: 9 | loss: 0.0564059\n",
      "\tspeed: 0.0508s/iter; left time: 534.7881s\n",
      "\titers: 400, epoch: 9 | loss: 0.0511184\n",
      "\tspeed: 0.0508s/iter; left time: 529.3799s\n",
      "\titers: 500, epoch: 9 | loss: 0.0548899\n",
      "\tspeed: 0.0509s/iter; left time: 525.9523s\n",
      "\titers: 600, epoch: 9 | loss: 0.0602870\n",
      "\tspeed: 0.0506s/iter; left time: 517.3814s\n",
      "\titers: 700, epoch: 9 | loss: 0.0530320\n",
      "\tspeed: 0.0504s/iter; left time: 510.6846s\n",
      "\titers: 800, epoch: 9 | loss: 0.0585114\n",
      "\tspeed: 0.0504s/iter; left time: 505.1865s\n",
      "\titers: 900, epoch: 9 | loss: 0.0489683\n",
      "\tspeed: 0.0504s/iter; left time: 499.9557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 902 | Train Loss: 0.0545657 Vali Loss: 0.0866638 Test Loss: 0.0968798\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024343758821487427, rmse:0.15602487325668335, mae:0.09656928479671478, rse:0.6042738556861877\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1787698\n",
      "\tspeed: 0.0528s/iter; left time: 947.9105s\n",
      "\titers: 200, epoch: 1 | loss: 0.1756977\n",
      "\tspeed: 0.0507s/iter; left time: 904.1720s\n",
      "\titers: 300, epoch: 1 | loss: 0.1726988\n",
      "\tspeed: 0.0503s/iter; left time: 892.9432s\n",
      "\titers: 400, epoch: 1 | loss: 0.1645466\n",
      "\tspeed: 0.0504s/iter; left time: 888.6241s\n",
      "\titers: 500, epoch: 1 | loss: 0.1546046\n",
      "\tspeed: 0.0504s/iter; left time: 883.5847s\n",
      "\titers: 600, epoch: 1 | loss: 0.1575418\n",
      "\tspeed: 0.0504s/iter; left time: 878.7539s\n",
      "\titers: 700, epoch: 1 | loss: 0.1498622\n",
      "\tspeed: 0.0503s/iter; left time: 873.0147s\n",
      "\titers: 800, epoch: 1 | loss: 0.1442681\n",
      "\tspeed: 0.0504s/iter; left time: 869.3829s\n",
      "\titers: 900, epoch: 1 | loss: 0.1440777\n",
      "\tspeed: 0.0504s/iter; left time: 863.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.1643646 Vali Loss: 0.1578211 Test Loss: 0.1845102\n",
      "Validation loss decreased (inf --> 0.157821).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1305881\n",
      "\tspeed: 0.1433s/iter; left time: 2441.5336s\n",
      "\titers: 200, epoch: 2 | loss: 0.1231588\n",
      "\tspeed: 0.0508s/iter; left time: 860.5270s\n",
      "\titers: 300, epoch: 2 | loss: 0.1234287\n",
      "\tspeed: 0.0509s/iter; left time: 856.2911s\n",
      "\titers: 400, epoch: 2 | loss: 0.1189174\n",
      "\tspeed: 0.0506s/iter; left time: 846.5236s\n",
      "\titers: 500, epoch: 2 | loss: 0.1040148\n",
      "\tspeed: 0.0504s/iter; left time: 838.9250s\n",
      "\titers: 600, epoch: 2 | loss: 0.1109011\n",
      "\tspeed: 0.0505s/iter; left time: 835.5339s\n",
      "\titers: 700, epoch: 2 | loss: 0.0989013\n",
      "\tspeed: 0.0510s/iter; left time: 838.0980s\n",
      "\titers: 800, epoch: 2 | loss: 0.1028772\n",
      "\tspeed: 0.0510s/iter; left time: 832.7449s\n",
      "\titers: 900, epoch: 2 | loss: 0.1027167\n",
      "\tspeed: 0.0509s/iter; left time: 826.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 902 | Train Loss: 0.1155884 Vali Loss: 0.1181208 Test Loss: 0.1364703\n",
      "Validation loss decreased (0.157821 --> 0.118121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007679\n",
      "\tspeed: 0.1420s/iter; left time: 2291.0337s\n",
      "\titers: 200, epoch: 3 | loss: 0.0926124\n",
      "\tspeed: 0.0504s/iter; left time: 808.8751s\n",
      "\titers: 300, epoch: 3 | loss: 0.0921094\n",
      "\tspeed: 0.0504s/iter; left time: 802.8691s\n",
      "\titers: 400, epoch: 3 | loss: 0.0896702\n",
      "\tspeed: 0.0505s/iter; left time: 799.8326s\n",
      "\titers: 500, epoch: 3 | loss: 0.0918375\n",
      "\tspeed: 0.0505s/iter; left time: 794.0894s\n",
      "\titers: 600, epoch: 3 | loss: 0.0904693\n",
      "\tspeed: 0.0505s/iter; left time: 789.4782s\n",
      "\titers: 700, epoch: 3 | loss: 0.0870313\n",
      "\tspeed: 0.0505s/iter; left time: 785.1167s\n",
      "\titers: 800, epoch: 3 | loss: 0.0861187\n",
      "\tspeed: 0.0504s/iter; left time: 778.1310s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808909\n",
      "\tspeed: 0.0504s/iter; left time: 773.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0923859 Vali Loss: 0.0995988 Test Loss: 0.1143600\n",
      "Validation loss decreased (0.118121 --> 0.099599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0715621\n",
      "\tspeed: 0.1421s/iter; left time: 2165.4658s\n",
      "\titers: 200, epoch: 4 | loss: 0.0746090\n",
      "\tspeed: 0.0504s/iter; left time: 763.2307s\n",
      "\titers: 300, epoch: 4 | loss: 0.0718534\n",
      "\tspeed: 0.0505s/iter; left time: 759.2869s\n",
      "\titers: 400, epoch: 4 | loss: 0.0711537\n",
      "\tspeed: 0.0505s/iter; left time: 754.1019s\n",
      "\titers: 500, epoch: 4 | loss: 0.0706193\n",
      "\tspeed: 0.0505s/iter; left time: 749.3533s\n",
      "\titers: 600, epoch: 4 | loss: 0.0673912\n",
      "\tspeed: 0.0509s/iter; left time: 749.8819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0730096\n",
      "\tspeed: 0.0509s/iter; left time: 745.2173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0678658\n",
      "\tspeed: 0.0509s/iter; left time: 739.5509s\n",
      "\titers: 900, epoch: 4 | loss: 0.0666774\n",
      "\tspeed: 0.0504s/iter; left time: 728.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 902 | Train Loss: 0.0718374 Vali Loss: 0.0865255 Test Loss: 0.0977247\n",
      "Validation loss decreased (0.099599 --> 0.086525).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0699938\n",
      "\tspeed: 0.1422s/iter; left time: 2037.8694s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737990\n",
      "\tspeed: 0.0509s/iter; left time: 724.3411s\n",
      "\titers: 300, epoch: 5 | loss: 0.0675461\n",
      "\tspeed: 0.0508s/iter; left time: 718.6058s\n",
      "\titers: 400, epoch: 5 | loss: 0.0678671\n",
      "\tspeed: 0.0505s/iter; left time: 709.2199s\n",
      "\titers: 500, epoch: 5 | loss: 0.0709195\n",
      "\tspeed: 0.0504s/iter; left time: 702.5562s\n",
      "\titers: 600, epoch: 5 | loss: 0.0634956\n",
      "\tspeed: 0.0504s/iter; left time: 697.4582s\n",
      "\titers: 700, epoch: 5 | loss: 0.0716952\n",
      "\tspeed: 0.0504s/iter; left time: 692.1110s\n",
      "\titers: 800, epoch: 5 | loss: 0.0626705\n",
      "\tspeed: 0.0504s/iter; left time: 686.9049s\n",
      "\titers: 900, epoch: 5 | loss: 0.0658662\n",
      "\tspeed: 0.0506s/iter; left time: 684.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.0667991 Vali Loss: 0.0870556 Test Loss: 0.0983676\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0631729\n",
      "\tspeed: 0.1376s/iter; left time: 1847.8868s\n",
      "\titers: 200, epoch: 6 | loss: 0.0667560\n",
      "\tspeed: 0.0504s/iter; left time: 672.2412s\n",
      "\titers: 300, epoch: 6 | loss: 0.0655189\n",
      "\tspeed: 0.0505s/iter; left time: 667.6030s\n",
      "\titers: 400, epoch: 6 | loss: 0.0713132\n",
      "\tspeed: 0.0505s/iter; left time: 663.0947s\n",
      "\titers: 500, epoch: 6 | loss: 0.0651720\n",
      "\tspeed: 0.0505s/iter; left time: 658.5894s\n",
      "\titers: 600, epoch: 6 | loss: 0.0628549\n",
      "\tspeed: 0.0504s/iter; left time: 651.5607s\n",
      "\titers: 700, epoch: 6 | loss: 0.0626928\n",
      "\tspeed: 0.0505s/iter; left time: 647.3282s\n",
      "\titers: 800, epoch: 6 | loss: 0.0640463\n",
      "\tspeed: 0.0504s/iter; left time: 641.8127s\n",
      "\titers: 900, epoch: 6 | loss: 0.0650508\n",
      "\tspeed: 0.0504s/iter; left time: 636.7878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0635975 Vali Loss: 0.0885732 Test Loss: 0.0982766\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0599360\n",
      "\tspeed: 0.1378s/iter; left time: 1725.9544s\n",
      "\titers: 200, epoch: 7 | loss: 0.0667914\n",
      "\tspeed: 0.0504s/iter; left time: 626.5123s\n",
      "\titers: 300, epoch: 7 | loss: 0.0598708\n",
      "\tspeed: 0.0505s/iter; left time: 622.5029s\n",
      "\titers: 400, epoch: 7 | loss: 0.0618586\n",
      "\tspeed: 0.0504s/iter; left time: 616.3025s\n",
      "\titers: 500, epoch: 7 | loss: 0.0605755\n",
      "\tspeed: 0.0505s/iter; left time: 612.4694s\n",
      "\titers: 600, epoch: 7 | loss: 0.0601703\n",
      "\tspeed: 0.0505s/iter; left time: 607.2587s\n",
      "\titers: 700, epoch: 7 | loss: 0.0572209\n",
      "\tspeed: 0.0505s/iter; left time: 602.3009s\n",
      "\titers: 800, epoch: 7 | loss: 0.0604722\n",
      "\tspeed: 0.0505s/iter; left time: 597.2390s\n",
      "\titers: 900, epoch: 7 | loss: 0.0577094\n",
      "\tspeed: 0.0504s/iter; left time: 591.6045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0607851 Vali Loss: 0.0876664 Test Loss: 0.0979006\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569773\n",
      "\tspeed: 0.1371s/iter; left time: 1593.5984s\n",
      "\titers: 200, epoch: 8 | loss: 0.0633521\n",
      "\tspeed: 0.0504s/iter; left time: 580.9436s\n",
      "\titers: 300, epoch: 8 | loss: 0.0593943\n",
      "\tspeed: 0.0504s/iter; left time: 576.3091s\n",
      "\titers: 400, epoch: 8 | loss: 0.0533727\n",
      "\tspeed: 0.0504s/iter; left time: 571.3853s\n",
      "\titers: 500, epoch: 8 | loss: 0.0565611\n",
      "\tspeed: 0.0504s/iter; left time: 566.2452s\n",
      "\titers: 600, epoch: 8 | loss: 0.0577994\n",
      "\tspeed: 0.0504s/iter; left time: 561.2605s\n",
      "\titers: 700, epoch: 8 | loss: 0.0628309\n",
      "\tspeed: 0.0504s/iter; left time: 556.1685s\n",
      "\titers: 800, epoch: 8 | loss: 0.0571598\n",
      "\tspeed: 0.0505s/iter; left time: 551.2688s\n",
      "\titers: 900, epoch: 8 | loss: 0.0570874\n",
      "\tspeed: 0.0504s/iter; left time: 546.0568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 902 | Train Loss: 0.0579347 Vali Loss: 0.0868271 Test Loss: 0.0977674\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0567947\n",
      "\tspeed: 0.1387s/iter; left time: 1487.3222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0572171\n",
      "\tspeed: 0.0505s/iter; left time: 536.7575s\n",
      "\titers: 300, epoch: 9 | loss: 0.0628344\n",
      "\tspeed: 0.0508s/iter; left time: 534.4601s\n",
      "\titers: 400, epoch: 9 | loss: 0.0569898\n",
      "\tspeed: 0.0505s/iter; left time: 526.7027s\n",
      "\titers: 500, epoch: 9 | loss: 0.0498729\n",
      "\tspeed: 0.0504s/iter; left time: 520.5277s\n",
      "\titers: 600, epoch: 9 | loss: 0.0571429\n",
      "\tspeed: 0.0509s/iter; left time: 520.5847s\n",
      "\titers: 700, epoch: 9 | loss: 0.0585564\n",
      "\tspeed: 0.0509s/iter; left time: 515.6574s\n",
      "\titers: 800, epoch: 9 | loss: 0.0577915\n",
      "\tspeed: 0.0504s/iter; left time: 505.6153s\n",
      "\titers: 900, epoch: 9 | loss: 0.0516842\n",
      "\tspeed: 0.0507s/iter; left time: 503.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 902 | Train Loss: 0.0556215 Vali Loss: 0.0889604 Test Loss: 0.0997862\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_96_168_FR_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.024290841072797775, rmse:0.155855193734169, mae:0.09771759808063507, rse:0.6036167144775391\n",
      "Intermediate time for FR and pred_len 168: 00h:16m:38.56s\n",
      "Intermediate time for FR: 01h:03m:01.02s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2289756\n",
      "\tspeed: 0.0571s/iter; left time: 1028.6264s\n",
      "\titers: 200, epoch: 1 | loss: 0.2147405\n",
      "\tspeed: 0.0344s/iter; left time: 616.8185s\n",
      "\titers: 300, epoch: 1 | loss: 0.2024794\n",
      "\tspeed: 0.0344s/iter; left time: 612.3553s\n",
      "\titers: 400, epoch: 1 | loss: 0.1978398\n",
      "\tspeed: 0.0344s/iter; left time: 608.9401s\n",
      "\titers: 500, epoch: 1 | loss: 0.1838570\n",
      "\tspeed: 0.0344s/iter; left time: 605.7099s\n",
      "\titers: 600, epoch: 1 | loss: 0.1871906\n",
      "\tspeed: 0.0342s/iter; left time: 599.0307s\n",
      "\titers: 700, epoch: 1 | loss: 0.1718587\n",
      "\tspeed: 0.0338s/iter; left time: 589.5431s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741228\n",
      "\tspeed: 0.0338s/iter; left time: 585.1718s\n",
      "\titers: 900, epoch: 1 | loss: 0.1741925\n",
      "\tspeed: 0.0339s/iter; left time: 583.2042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.1946895 Vali Loss: 0.1531637 Test Loss: 0.1688930\n",
      "Validation loss decreased (inf --> 0.153164).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200996\n",
      "\tspeed: 0.0980s/iter; left time: 1676.6751s\n",
      "\titers: 200, epoch: 2 | loss: 0.0943886\n",
      "\tspeed: 0.0344s/iter; left time: 585.0408s\n",
      "\titers: 300, epoch: 2 | loss: 0.0873010\n",
      "\tspeed: 0.0344s/iter; left time: 581.0857s\n",
      "\titers: 400, epoch: 2 | loss: 0.0911078\n",
      "\tspeed: 0.0344s/iter; left time: 577.9463s\n",
      "\titers: 500, epoch: 2 | loss: 0.0900601\n",
      "\tspeed: 0.0344s/iter; left time: 574.3511s\n",
      "\titers: 600, epoch: 2 | loss: 0.0939043\n",
      "\tspeed: 0.0343s/iter; left time: 570.6688s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763428\n",
      "\tspeed: 0.0343s/iter; left time: 566.8765s\n",
      "\titers: 800, epoch: 2 | loss: 0.0738119\n",
      "\tspeed: 0.0343s/iter; left time: 563.4438s\n",
      "\titers: 900, epoch: 2 | loss: 0.0727385\n",
      "\tspeed: 0.0343s/iter; left time: 560.2103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.43s\n",
      "Steps: 906 | Train Loss: 0.0941843 Vali Loss: 0.0731850 Test Loss: 0.0763463\n",
      "Validation loss decreased (0.153164 --> 0.073185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0689264\n",
      "\tspeed: 0.0987s/iter; left time: 1600.0744s\n",
      "\titers: 200, epoch: 3 | loss: 0.0680265\n",
      "\tspeed: 0.0338s/iter; left time: 544.5820s\n",
      "\titers: 300, epoch: 3 | loss: 0.0720875\n",
      "\tspeed: 0.0338s/iter; left time: 541.3244s\n",
      "\titers: 400, epoch: 3 | loss: 0.0637039\n",
      "\tspeed: 0.0338s/iter; left time: 538.2675s\n",
      "\titers: 500, epoch: 3 | loss: 0.0603021\n",
      "\tspeed: 0.0338s/iter; left time: 534.1296s\n",
      "\titers: 600, epoch: 3 | loss: 0.0701781\n",
      "\tspeed: 0.0338s/iter; left time: 531.0419s\n",
      "\titers: 700, epoch: 3 | loss: 0.0690891\n",
      "\tspeed: 0.0338s/iter; left time: 527.4586s\n",
      "\titers: 800, epoch: 3 | loss: 0.0771389\n",
      "\tspeed: 0.0338s/iter; left time: 524.0841s\n",
      "\titers: 900, epoch: 3 | loss: 0.0653842\n",
      "\tspeed: 0.0338s/iter; left time: 520.8941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.91s\n",
      "Steps: 906 | Train Loss: 0.0697471 Vali Loss: 0.0669245 Test Loss: 0.0713615\n",
      "Validation loss decreased (0.073185 --> 0.066924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0727013\n",
      "\tspeed: 0.0986s/iter; left time: 1508.1638s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631000\n",
      "\tspeed: 0.0344s/iter; left time: 522.7673s\n",
      "\titers: 300, epoch: 4 | loss: 0.0641052\n",
      "\tspeed: 0.0344s/iter; left time: 519.2833s\n",
      "\titers: 400, epoch: 4 | loss: 0.0677283\n",
      "\tspeed: 0.0344s/iter; left time: 515.5153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0661093\n",
      "\tspeed: 0.0344s/iter; left time: 512.0733s\n",
      "\titers: 600, epoch: 4 | loss: 0.0596208\n",
      "\tspeed: 0.0344s/iter; left time: 509.0584s\n",
      "\titers: 700, epoch: 4 | loss: 0.0618208\n",
      "\tspeed: 0.0344s/iter; left time: 505.2721s\n",
      "\titers: 800, epoch: 4 | loss: 0.0644566\n",
      "\tspeed: 0.0344s/iter; left time: 501.6529s\n",
      "\titers: 900, epoch: 4 | loss: 0.0667040\n",
      "\tspeed: 0.0344s/iter; left time: 498.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.44s\n",
      "Steps: 906 | Train Loss: 0.0649319 Vali Loss: 0.0651137 Test Loss: 0.0699982\n",
      "Validation loss decreased (0.066924 --> 0.065114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597008\n",
      "\tspeed: 0.1023s/iter; left time: 1472.9348s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717447\n",
      "\tspeed: 0.0344s/iter; left time: 491.7666s\n",
      "\titers: 300, epoch: 5 | loss: 0.0594414\n",
      "\tspeed: 0.0344s/iter; left time: 487.9869s\n",
      "\titers: 400, epoch: 5 | loss: 0.0574381\n",
      "\tspeed: 0.0344s/iter; left time: 484.3206s\n",
      "\titers: 500, epoch: 5 | loss: 0.0629130\n",
      "\tspeed: 0.0344s/iter; left time: 481.3928s\n",
      "\titers: 600, epoch: 5 | loss: 0.0602561\n",
      "\tspeed: 0.0341s/iter; left time: 473.7533s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723139\n",
      "\tspeed: 0.0338s/iter; left time: 466.4928s\n",
      "\titers: 800, epoch: 5 | loss: 0.0493080\n",
      "\tspeed: 0.0339s/iter; left time: 463.7789s\n",
      "\titers: 900, epoch: 5 | loss: 0.0612842\n",
      "\tspeed: 0.0338s/iter; left time: 459.8525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.0610163 Vali Loss: 0.0614561 Test Loss: 0.0658055\n",
      "Validation loss decreased (0.065114 --> 0.061456).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0591033\n",
      "\tspeed: 0.0984s/iter; left time: 1327.4845s\n",
      "\titers: 200, epoch: 6 | loss: 0.0583568\n",
      "\tspeed: 0.0345s/iter; left time: 461.3400s\n",
      "\titers: 300, epoch: 6 | loss: 0.0663953\n",
      "\tspeed: 0.0344s/iter; left time: 457.4677s\n",
      "\titers: 400, epoch: 6 | loss: 0.0580835\n",
      "\tspeed: 0.0344s/iter; left time: 454.0186s\n",
      "\titers: 500, epoch: 6 | loss: 0.0495465\n",
      "\tspeed: 0.0344s/iter; left time: 450.4742s\n",
      "\titers: 600, epoch: 6 | loss: 0.0566977\n",
      "\tspeed: 0.0344s/iter; left time: 447.1341s\n",
      "\titers: 700, epoch: 6 | loss: 0.0582300\n",
      "\tspeed: 0.0344s/iter; left time: 443.7517s\n",
      "\titers: 800, epoch: 6 | loss: 0.0565420\n",
      "\tspeed: 0.0344s/iter; left time: 439.5191s\n",
      "\titers: 900, epoch: 6 | loss: 0.0544238\n",
      "\tspeed: 0.0344s/iter; left time: 436.5878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0582357 Vali Loss: 0.0605395 Test Loss: 0.0657733\n",
      "Validation loss decreased (0.061456 --> 0.060540).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0518394\n",
      "\tspeed: 0.0998s/iter; left time: 1255.3815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0625482\n",
      "\tspeed: 0.0339s/iter; left time: 423.0757s\n",
      "\titers: 300, epoch: 7 | loss: 0.0538388\n",
      "\tspeed: 0.0339s/iter; left time: 419.8996s\n",
      "\titers: 400, epoch: 7 | loss: 0.0608252\n",
      "\tspeed: 0.0339s/iter; left time: 416.6479s\n",
      "\titers: 500, epoch: 7 | loss: 0.0573636\n",
      "\tspeed: 0.0339s/iter; left time: 412.7597s\n",
      "\titers: 600, epoch: 7 | loss: 0.0511362\n",
      "\tspeed: 0.0339s/iter; left time: 409.0841s\n",
      "\titers: 700, epoch: 7 | loss: 0.0534262\n",
      "\tspeed: 0.0339s/iter; left time: 405.9108s\n",
      "\titers: 800, epoch: 7 | loss: 0.0597523\n",
      "\tspeed: 0.0339s/iter; left time: 402.6076s\n",
      "\titers: 900, epoch: 7 | loss: 0.0498654\n",
      "\tspeed: 0.0339s/iter; left time: 399.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.99s\n",
      "Steps: 906 | Train Loss: 0.0561592 Vali Loss: 0.0586244 Test Loss: 0.0642837\n",
      "Validation loss decreased (0.060540 --> 0.058624).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0509520\n",
      "\tspeed: 0.0982s/iter; left time: 1147.2853s\n",
      "\titers: 200, epoch: 8 | loss: 0.0509359\n",
      "\tspeed: 0.0344s/iter; left time: 398.2165s\n",
      "\titers: 300, epoch: 8 | loss: 0.0527956\n",
      "\tspeed: 0.0344s/iter; left time: 394.5786s\n",
      "\titers: 400, epoch: 8 | loss: 0.0565501\n",
      "\tspeed: 0.0344s/iter; left time: 391.4198s\n",
      "\titers: 500, epoch: 8 | loss: 0.0532382\n",
      "\tspeed: 0.0344s/iter; left time: 387.9617s\n",
      "\titers: 600, epoch: 8 | loss: 0.0565472\n",
      "\tspeed: 0.0344s/iter; left time: 384.0717s\n",
      "\titers: 700, epoch: 8 | loss: 0.0503138\n",
      "\tspeed: 0.0344s/iter; left time: 380.9368s\n",
      "\titers: 800, epoch: 8 | loss: 0.0552599\n",
      "\tspeed: 0.0344s/iter; left time: 377.7964s\n",
      "\titers: 900, epoch: 8 | loss: 0.0519355\n",
      "\tspeed: 0.0344s/iter; left time: 374.0193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0541787 Vali Loss: 0.0579991 Test Loss: 0.0646259\n",
      "Validation loss decreased (0.058624 --> 0.057999).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0463596\n",
      "\tspeed: 0.0994s/iter; left time: 1071.2717s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533909\n",
      "\tspeed: 0.0339s/iter; left time: 362.2133s\n",
      "\titers: 300, epoch: 9 | loss: 0.0609420\n",
      "\tspeed: 0.0339s/iter; left time: 357.8963s\n",
      "\titers: 400, epoch: 9 | loss: 0.0476018\n",
      "\tspeed: 0.0338s/iter; left time: 354.5008s\n",
      "\titers: 500, epoch: 9 | loss: 0.0494947\n",
      "\tspeed: 0.0344s/iter; left time: 356.5728s\n",
      "\titers: 600, epoch: 9 | loss: 0.0558363\n",
      "\tspeed: 0.0344s/iter; left time: 353.4206s\n",
      "\titers: 700, epoch: 9 | loss: 0.0526480\n",
      "\tspeed: 0.0344s/iter; left time: 349.5025s\n",
      "\titers: 800, epoch: 9 | loss: 0.0504616\n",
      "\tspeed: 0.0344s/iter; left time: 346.5170s\n",
      "\titers: 900, epoch: 9 | loss: 0.0483640\n",
      "\tspeed: 0.0344s/iter; left time: 342.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.30s\n",
      "Steps: 906 | Train Loss: 0.0524793 Vali Loss: 0.0583450 Test Loss: 0.0629489\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0541091\n",
      "\tspeed: 0.0952s/iter; left time: 939.3233s\n",
      "\titers: 200, epoch: 10 | loss: 0.0536419\n",
      "\tspeed: 0.0344s/iter; left time: 336.0498s\n",
      "\titers: 300, epoch: 10 | loss: 0.0514194\n",
      "\tspeed: 0.0344s/iter; left time: 332.4185s\n",
      "\titers: 400, epoch: 10 | loss: 0.0504203\n",
      "\tspeed: 0.0344s/iter; left time: 328.9377s\n",
      "\titers: 500, epoch: 10 | loss: 0.0432660\n",
      "\tspeed: 0.0344s/iter; left time: 326.0878s\n",
      "\titers: 600, epoch: 10 | loss: 0.0556666\n",
      "\tspeed: 0.0344s/iter; left time: 322.5387s\n",
      "\titers: 700, epoch: 10 | loss: 0.0505122\n",
      "\tspeed: 0.0344s/iter; left time: 318.9934s\n",
      "\titers: 800, epoch: 10 | loss: 0.0518186\n",
      "\tspeed: 0.0344s/iter; left time: 315.5373s\n",
      "\titers: 900, epoch: 10 | loss: 0.0462847\n",
      "\tspeed: 0.0344s/iter; left time: 312.0584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0511121 Vali Loss: 0.0566754 Test Loss: 0.0640028\n",
      "Validation loss decreased (0.057999 --> 0.056675).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0522779\n",
      "\tspeed: 0.0990s/iter; left time: 886.7043s\n",
      "\titers: 200, epoch: 11 | loss: 0.0463553\n",
      "\tspeed: 0.0339s/iter; left time: 300.1341s\n",
      "\titers: 300, epoch: 11 | loss: 0.0524409\n",
      "\tspeed: 0.0339s/iter; left time: 296.7200s\n",
      "\titers: 400, epoch: 11 | loss: 0.0493511\n",
      "\tspeed: 0.0339s/iter; left time: 293.1921s\n",
      "\titers: 500, epoch: 11 | loss: 0.0535235\n",
      "\tspeed: 0.0339s/iter; left time: 289.8067s\n",
      "\titers: 600, epoch: 11 | loss: 0.0537348\n",
      "\tspeed: 0.0339s/iter; left time: 286.5283s\n",
      "\titers: 700, epoch: 11 | loss: 0.0487254\n",
      "\tspeed: 0.0339s/iter; left time: 283.1318s\n",
      "\titers: 800, epoch: 11 | loss: 0.0524150\n",
      "\tspeed: 0.0340s/iter; left time: 280.5251s\n",
      "\titers: 900, epoch: 11 | loss: 0.0441130\n",
      "\tspeed: 0.0344s/iter; left time: 280.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.07s\n",
      "Steps: 906 | Train Loss: 0.0498137 Vali Loss: 0.0567335 Test Loss: 0.0640843\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0454959\n",
      "\tspeed: 0.0955s/iter; left time: 769.3419s\n",
      "\titers: 200, epoch: 12 | loss: 0.0510769\n",
      "\tspeed: 0.0344s/iter; left time: 273.4583s\n",
      "\titers: 300, epoch: 12 | loss: 0.0456563\n",
      "\tspeed: 0.0344s/iter; left time: 270.4168s\n",
      "\titers: 400, epoch: 12 | loss: 0.0503837\n",
      "\tspeed: 0.0344s/iter; left time: 266.6420s\n",
      "\titers: 500, epoch: 12 | loss: 0.0526142\n",
      "\tspeed: 0.0344s/iter; left time: 263.1913s\n",
      "\titers: 600, epoch: 12 | loss: 0.0477144\n",
      "\tspeed: 0.0344s/iter; left time: 259.7137s\n",
      "\titers: 700, epoch: 12 | loss: 0.0439736\n",
      "\tspeed: 0.0344s/iter; left time: 256.6034s\n",
      "\titers: 800, epoch: 12 | loss: 0.0518971\n",
      "\tspeed: 0.0344s/iter; left time: 253.0095s\n",
      "\titers: 900, epoch: 12 | loss: 0.0473772\n",
      "\tspeed: 0.0339s/iter; left time: 246.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.39s\n",
      "Steps: 906 | Train Loss: 0.0486576 Vali Loss: 0.0559295 Test Loss: 0.0642169\n",
      "Validation loss decreased (0.056675 --> 0.055930).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0414750\n",
      "\tspeed: 0.0990s/iter; left time: 707.4082s\n",
      "\titers: 200, epoch: 13 | loss: 0.0494478\n",
      "\tspeed: 0.0344s/iter; left time: 242.4017s\n",
      "\titers: 300, epoch: 13 | loss: 0.0469200\n",
      "\tspeed: 0.0344s/iter; left time: 239.2543s\n",
      "\titers: 400, epoch: 13 | loss: 0.0549754\n",
      "\tspeed: 0.0344s/iter; left time: 235.6954s\n",
      "\titers: 500, epoch: 13 | loss: 0.0429797\n",
      "\tspeed: 0.0344s/iter; left time: 232.2055s\n",
      "\titers: 600, epoch: 13 | loss: 0.0493610\n",
      "\tspeed: 0.0344s/iter; left time: 228.8044s\n",
      "\titers: 700, epoch: 13 | loss: 0.0470018\n",
      "\tspeed: 0.0344s/iter; left time: 225.2410s\n",
      "\titers: 800, epoch: 13 | loss: 0.0505446\n",
      "\tspeed: 0.0344s/iter; left time: 222.0993s\n",
      "\titers: 900, epoch: 13 | loss: 0.0527018\n",
      "\tspeed: 0.0344s/iter; left time: 218.3424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.48s\n",
      "Steps: 906 | Train Loss: 0.0474767 Vali Loss: 0.0565293 Test Loss: 0.0645984\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0478024\n",
      "\tspeed: 0.0952s/iter; left time: 594.1187s\n",
      "\titers: 200, epoch: 14 | loss: 0.0465574\n",
      "\tspeed: 0.0345s/iter; left time: 211.7217s\n",
      "\titers: 300, epoch: 14 | loss: 0.0409424\n",
      "\tspeed: 0.0344s/iter; left time: 208.0992s\n",
      "\titers: 400, epoch: 14 | loss: 0.0393596\n",
      "\tspeed: 0.0344s/iter; left time: 204.6496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0479720\n",
      "\tspeed: 0.0344s/iter; left time: 200.9919s\n",
      "\titers: 600, epoch: 14 | loss: 0.0455824\n",
      "\tspeed: 0.0344s/iter; left time: 197.4515s\n",
      "\titers: 700, epoch: 14 | loss: 0.0412655\n",
      "\tspeed: 0.0340s/iter; left time: 191.9091s\n",
      "\titers: 800, epoch: 14 | loss: 0.0518019\n",
      "\tspeed: 0.0339s/iter; left time: 187.7954s\n",
      "\titers: 900, epoch: 14 | loss: 0.0401611\n",
      "\tspeed: 0.0342s/iter; left time: 186.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.34s\n",
      "Steps: 906 | Train Loss: 0.0464986 Vali Loss: 0.0564530 Test Loss: 0.0648331\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0453141\n",
      "\tspeed: 0.0946s/iter; left time: 504.9078s\n",
      "\titers: 200, epoch: 15 | loss: 0.0427157\n",
      "\tspeed: 0.0339s/iter; left time: 177.6196s\n",
      "\titers: 300, epoch: 15 | loss: 0.0424050\n",
      "\tspeed: 0.0339s/iter; left time: 174.0996s\n",
      "\titers: 400, epoch: 15 | loss: 0.0450250\n",
      "\tspeed: 0.0340s/iter; left time: 171.1165s\n",
      "\titers: 500, epoch: 15 | loss: 0.0498884\n",
      "\tspeed: 0.0339s/iter; left time: 167.4988s\n",
      "\titers: 600, epoch: 15 | loss: 0.0426898\n",
      "\tspeed: 0.0339s/iter; left time: 163.9400s\n",
      "\titers: 700, epoch: 15 | loss: 0.0478519\n",
      "\tspeed: 0.0339s/iter; left time: 160.6394s\n",
      "\titers: 800, epoch: 15 | loss: 0.0399454\n",
      "\tspeed: 0.0339s/iter; left time: 157.2868s\n",
      "\titers: 900, epoch: 15 | loss: 0.0482494\n",
      "\tspeed: 0.0339s/iter; left time: 153.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:30.98s\n",
      "Steps: 906 | Train Loss: 0.0455909 Vali Loss: 0.0574777 Test Loss: 0.0649152\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0477243\n",
      "\tspeed: 0.0966s/iter; left time: 428.0084s\n",
      "\titers: 200, epoch: 16 | loss: 0.0499466\n",
      "\tspeed: 0.0344s/iter; left time: 149.0762s\n",
      "\titers: 300, epoch: 16 | loss: 0.0453695\n",
      "\tspeed: 0.0344s/iter; left time: 145.5417s\n",
      "\titers: 400, epoch: 16 | loss: 0.0438813\n",
      "\tspeed: 0.0344s/iter; left time: 142.2158s\n",
      "\titers: 500, epoch: 16 | loss: 0.0471978\n",
      "\tspeed: 0.0344s/iter; left time: 138.8512s\n",
      "\titers: 600, epoch: 16 | loss: 0.0432691\n",
      "\tspeed: 0.0344s/iter; left time: 135.0316s\n",
      "\titers: 700, epoch: 16 | loss: 0.0403846\n",
      "\tspeed: 0.0344s/iter; left time: 131.8651s\n",
      "\titers: 800, epoch: 16 | loss: 0.0475129\n",
      "\tspeed: 0.0344s/iter; left time: 128.3959s\n",
      "\titers: 900, epoch: 16 | loss: 0.0473321\n",
      "\tspeed: 0.0344s/iter; left time: 125.0653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.0446047 Vali Loss: 0.0561414 Test Loss: 0.0642355\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0387600\n",
      "\tspeed: 0.0965s/iter; left time: 340.1043s\n",
      "\titers: 200, epoch: 17 | loss: 0.0365247\n",
      "\tspeed: 0.0344s/iter; left time: 117.9369s\n",
      "\titers: 300, epoch: 17 | loss: 0.0416560\n",
      "\tspeed: 0.0344s/iter; left time: 114.4035s\n",
      "\titers: 400, epoch: 17 | loss: 0.0426961\n",
      "\tspeed: 0.0344s/iter; left time: 110.9422s\n",
      "\titers: 500, epoch: 17 | loss: 0.0431453\n",
      "\tspeed: 0.0344s/iter; left time: 107.5261s\n",
      "\titers: 600, epoch: 17 | loss: 0.0430919\n",
      "\tspeed: 0.0344s/iter; left time: 104.1321s\n",
      "\titers: 700, epoch: 17 | loss: 0.0497445\n",
      "\tspeed: 0.0344s/iter; left time: 100.7481s\n",
      "\titers: 800, epoch: 17 | loss: 0.0412744\n",
      "\tspeed: 0.0344s/iter; left time: 97.1845s\n",
      "\titers: 900, epoch: 17 | loss: 0.0451680\n",
      "\tspeed: 0.0344s/iter; left time: 93.8345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0439459 Vali Loss: 0.0560204 Test Loss: 0.0647921\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01203176286071539, rmse:0.1096893921494484, mae:0.06421584635972977, rse:0.4145238697528839\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2498116\n",
      "\tspeed: 0.0370s/iter; left time: 666.5389s\n",
      "\titers: 200, epoch: 1 | loss: 0.2011735\n",
      "\tspeed: 0.0340s/iter; left time: 608.7283s\n",
      "\titers: 300, epoch: 1 | loss: 0.2150934\n",
      "\tspeed: 0.0338s/iter; left time: 602.7235s\n",
      "\titers: 400, epoch: 1 | loss: 0.1960537\n",
      "\tspeed: 0.0339s/iter; left time: 600.7765s\n",
      "\titers: 500, epoch: 1 | loss: 0.1826794\n",
      "\tspeed: 0.0342s/iter; left time: 603.0035s\n",
      "\titers: 600, epoch: 1 | loss: 0.1927706\n",
      "\tspeed: 0.0340s/iter; left time: 595.9660s\n",
      "\titers: 700, epoch: 1 | loss: 0.1779167\n",
      "\tspeed: 0.0344s/iter; left time: 599.7866s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746279\n",
      "\tspeed: 0.0344s/iter; left time: 595.2989s\n",
      "\titers: 900, epoch: 1 | loss: 0.1654574\n",
      "\tspeed: 0.0341s/iter; left time: 587.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.24s\n",
      "Steps: 906 | Train Loss: 0.1992125 Vali Loss: 0.1432941 Test Loss: 0.1544233\n",
      "Validation loss decreased (inf --> 0.143294).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1207117\n",
      "\tspeed: 0.0978s/iter; left time: 1673.5689s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950160\n",
      "\tspeed: 0.0344s/iter; left time: 585.2503s\n",
      "\titers: 300, epoch: 2 | loss: 0.1002817\n",
      "\tspeed: 0.0344s/iter; left time: 581.7880s\n",
      "\titers: 400, epoch: 2 | loss: 0.0960616\n",
      "\tspeed: 0.0344s/iter; left time: 578.6741s\n",
      "\titers: 500, epoch: 2 | loss: 0.0890009\n",
      "\tspeed: 0.0344s/iter; left time: 575.1517s\n",
      "\titers: 600, epoch: 2 | loss: 0.0752527\n",
      "\tspeed: 0.0344s/iter; left time: 571.0349s\n",
      "\titers: 700, epoch: 2 | loss: 0.0765394\n",
      "\tspeed: 0.0344s/iter; left time: 567.7912s\n",
      "\titers: 800, epoch: 2 | loss: 0.0737386\n",
      "\tspeed: 0.0345s/iter; left time: 565.7726s\n",
      "\titers: 900, epoch: 2 | loss: 0.0719303\n",
      "\tspeed: 0.0344s/iter; left time: 561.6777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.45s\n",
      "Steps: 906 | Train Loss: 0.0930362 Vali Loss: 0.0793414 Test Loss: 0.0821712\n",
      "Validation loss decreased (0.143294 --> 0.079341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0749184\n",
      "\tspeed: 0.0985s/iter; left time: 1596.5709s\n",
      "\titers: 200, epoch: 3 | loss: 0.0750817\n",
      "\tspeed: 0.0354s/iter; left time: 570.6225s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689839\n",
      "\tspeed: 0.0354s/iter; left time: 567.1619s\n",
      "\titers: 400, epoch: 3 | loss: 0.0704358\n",
      "\tspeed: 0.0353s/iter; left time: 562.2200s\n",
      "\titers: 500, epoch: 3 | loss: 0.0624443\n",
      "\tspeed: 0.0347s/iter; left time: 548.4937s\n",
      "\titers: 600, epoch: 3 | loss: 0.0694029\n",
      "\tspeed: 0.0347s/iter; left time: 544.7530s\n",
      "\titers: 700, epoch: 3 | loss: 0.0815309\n",
      "\tspeed: 0.0347s/iter; left time: 541.4119s\n",
      "\titers: 800, epoch: 3 | loss: 0.0664670\n",
      "\tspeed: 0.0347s/iter; left time: 537.6137s\n",
      "\titers: 900, epoch: 3 | loss: 0.0646821\n",
      "\tspeed: 0.0347s/iter; left time: 534.5490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.02s\n",
      "Steps: 906 | Train Loss: 0.0724885 Vali Loss: 0.0685023 Test Loss: 0.0725131\n",
      "Validation loss decreased (0.079341 --> 0.068502).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0744193\n",
      "\tspeed: 0.0981s/iter; left time: 1501.0904s\n",
      "\titers: 200, epoch: 4 | loss: 0.0712759\n",
      "\tspeed: 0.0347s/iter; left time: 527.5156s\n",
      "\titers: 300, epoch: 4 | loss: 0.0668154\n",
      "\tspeed: 0.0346s/iter; left time: 523.0114s\n",
      "\titers: 400, epoch: 4 | loss: 0.0690735\n",
      "\tspeed: 0.0347s/iter; left time: 520.1602s\n",
      "\titers: 500, epoch: 4 | loss: 0.0684960\n",
      "\tspeed: 0.0347s/iter; left time: 517.1179s\n",
      "\titers: 600, epoch: 4 | loss: 0.0681758\n",
      "\tspeed: 0.0347s/iter; left time: 513.0677s\n",
      "\titers: 700, epoch: 4 | loss: 0.0672854\n",
      "\tspeed: 0.0347s/iter; left time: 509.7975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0688433\n",
      "\tspeed: 0.0347s/iter; left time: 506.9368s\n",
      "\titers: 900, epoch: 4 | loss: 0.0717380\n",
      "\tspeed: 0.0347s/iter; left time: 503.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:31.71s\n",
      "Steps: 906 | Train Loss: 0.0678150 Vali Loss: 0.0665552 Test Loss: 0.0727431\n",
      "Validation loss decreased (0.068502 --> 0.066555).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0659932\n",
      "\tspeed: 0.0981s/iter; left time: 1412.5186s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691543\n",
      "\tspeed: 0.0349s/iter; left time: 498.3155s\n",
      "\titers: 300, epoch: 5 | loss: 0.0622396\n",
      "\tspeed: 0.0347s/iter; left time: 492.6222s\n",
      "\titers: 400, epoch: 5 | loss: 0.0609198\n",
      "\tspeed: 0.0347s/iter; left time: 488.8965s\n",
      "\titers: 500, epoch: 5 | loss: 0.0666150\n",
      "\tspeed: 0.0347s/iter; left time: 485.7598s\n",
      "\titers: 600, epoch: 5 | loss: 0.0587350\n",
      "\tspeed: 0.0347s/iter; left time: 482.1804s\n",
      "\titers: 700, epoch: 5 | loss: 0.0578601\n",
      "\tspeed: 0.0348s/iter; left time: 480.5091s\n",
      "\titers: 800, epoch: 5 | loss: 0.0598911\n",
      "\tspeed: 0.0347s/iter; left time: 475.9499s\n",
      "\titers: 900, epoch: 5 | loss: 0.0647039\n",
      "\tspeed: 0.0350s/iter; left time: 476.3878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:31.87s\n",
      "Steps: 906 | Train Loss: 0.0635315 Vali Loss: 0.0618177 Test Loss: 0.0684821\n",
      "Validation loss decreased (0.066555 --> 0.061818).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0551207\n",
      "\tspeed: 0.0990s/iter; left time: 1335.9846s\n",
      "\titers: 200, epoch: 6 | loss: 0.0664826\n",
      "\tspeed: 0.0354s/iter; left time: 473.8274s\n",
      "\titers: 300, epoch: 6 | loss: 0.0643861\n",
      "\tspeed: 0.0349s/iter; left time: 464.2556s\n",
      "\titers: 400, epoch: 6 | loss: 0.0645496\n",
      "\tspeed: 0.0348s/iter; left time: 459.4172s\n",
      "\titers: 500, epoch: 6 | loss: 0.0522045\n",
      "\tspeed: 0.0348s/iter; left time: 456.0432s\n",
      "\titers: 600, epoch: 6 | loss: 0.0588533\n",
      "\tspeed: 0.0348s/iter; left time: 452.3222s\n",
      "\titers: 700, epoch: 6 | loss: 0.0584210\n",
      "\tspeed: 0.0349s/iter; left time: 449.8974s\n",
      "\titers: 800, epoch: 6 | loss: 0.0518436\n",
      "\tspeed: 0.0348s/iter; left time: 445.5703s\n",
      "\titers: 900, epoch: 6 | loss: 0.0592274\n",
      "\tspeed: 0.0348s/iter; left time: 441.7159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.00s\n",
      "Steps: 906 | Train Loss: 0.0598389 Vali Loss: 0.0608522 Test Loss: 0.0686492\n",
      "Validation loss decreased (0.061818 --> 0.060852).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0570249\n",
      "\tspeed: 0.1002s/iter; left time: 1261.3629s\n",
      "\titers: 200, epoch: 7 | loss: 0.0546420\n",
      "\tspeed: 0.0348s/iter; left time: 434.3797s\n",
      "\titers: 300, epoch: 7 | loss: 0.0586133\n",
      "\tspeed: 0.0348s/iter; left time: 431.3394s\n",
      "\titers: 400, epoch: 7 | loss: 0.0534843\n",
      "\tspeed: 0.0347s/iter; left time: 426.7654s\n",
      "\titers: 500, epoch: 7 | loss: 0.0500044\n",
      "\tspeed: 0.0347s/iter; left time: 422.9477s\n",
      "\titers: 600, epoch: 7 | loss: 0.0479839\n",
      "\tspeed: 0.0348s/iter; left time: 420.8973s\n",
      "\titers: 700, epoch: 7 | loss: 0.0544220\n",
      "\tspeed: 0.0348s/iter; left time: 417.2883s\n",
      "\titers: 800, epoch: 7 | loss: 0.0504415\n",
      "\tspeed: 0.0348s/iter; left time: 413.2339s\n",
      "\titers: 900, epoch: 7 | loss: 0.0664917\n",
      "\tspeed: 0.0347s/iter; left time: 409.0704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:31.82s\n",
      "Steps: 906 | Train Loss: 0.0572039 Vali Loss: 0.0600482 Test Loss: 0.0666491\n",
      "Validation loss decreased (0.060852 --> 0.060048).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569239\n",
      "\tspeed: 0.0975s/iter; left time: 1139.1124s\n",
      "\titers: 200, epoch: 8 | loss: 0.0524420\n",
      "\tspeed: 0.0347s/iter; left time: 402.1669s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549767\n",
      "\tspeed: 0.0347s/iter; left time: 398.7406s\n",
      "\titers: 400, epoch: 8 | loss: 0.0569074\n",
      "\tspeed: 0.0347s/iter; left time: 394.5755s\n",
      "\titers: 500, epoch: 8 | loss: 0.0560224\n",
      "\tspeed: 0.0347s/iter; left time: 391.2381s\n",
      "\titers: 600, epoch: 8 | loss: 0.0586272\n",
      "\tspeed: 0.0347s/iter; left time: 387.4443s\n",
      "\titers: 700, epoch: 8 | loss: 0.0534134\n",
      "\tspeed: 0.0347s/iter; left time: 384.2815s\n",
      "\titers: 800, epoch: 8 | loss: 0.0507184\n",
      "\tspeed: 0.0347s/iter; left time: 381.3517s\n",
      "\titers: 900, epoch: 8 | loss: 0.0588685\n",
      "\tspeed: 0.0347s/iter; left time: 377.2593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0554143 Vali Loss: 0.0588686 Test Loss: 0.0643074\n",
      "Validation loss decreased (0.060048 --> 0.058869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0554289\n",
      "\tspeed: 0.0976s/iter; left time: 1051.5838s\n",
      "\titers: 200, epoch: 9 | loss: 0.0491354\n",
      "\tspeed: 0.0348s/iter; left time: 371.0447s\n",
      "\titers: 300, epoch: 9 | loss: 0.0533709\n",
      "\tspeed: 0.0346s/iter; left time: 366.2234s\n",
      "\titers: 400, epoch: 9 | loss: 0.0478047\n",
      "\tspeed: 0.0346s/iter; left time: 362.6454s\n",
      "\titers: 500, epoch: 9 | loss: 0.0562404\n",
      "\tspeed: 0.0347s/iter; left time: 359.5503s\n",
      "\titers: 600, epoch: 9 | loss: 0.0546994\n",
      "\tspeed: 0.0347s/iter; left time: 356.9094s\n",
      "\titers: 700, epoch: 9 | loss: 0.0573833\n",
      "\tspeed: 0.0347s/iter; left time: 352.8255s\n",
      "\titers: 800, epoch: 9 | loss: 0.0525519\n",
      "\tspeed: 0.0347s/iter; left time: 349.5498s\n",
      "\titers: 900, epoch: 9 | loss: 0.0501279\n",
      "\tspeed: 0.0347s/iter; left time: 346.4388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:31.75s\n",
      "Steps: 906 | Train Loss: 0.0537802 Vali Loss: 0.0572465 Test Loss: 0.0636292\n",
      "Validation loss decreased (0.058869 --> 0.057246).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0570313\n",
      "\tspeed: 0.0972s/iter; left time: 959.5169s\n",
      "\titers: 200, epoch: 10 | loss: 0.0489191\n",
      "\tspeed: 0.0346s/iter; left time: 337.5840s\n",
      "\titers: 300, epoch: 10 | loss: 0.0466328\n",
      "\tspeed: 0.0347s/iter; left time: 335.0048s\n",
      "\titers: 400, epoch: 10 | loss: 0.0506991\n",
      "\tspeed: 0.0345s/iter; left time: 330.5165s\n",
      "\titers: 500, epoch: 10 | loss: 0.0551326\n",
      "\tspeed: 0.0346s/iter; left time: 327.4180s\n",
      "\titers: 600, epoch: 10 | loss: 0.0489854\n",
      "\tspeed: 0.0347s/iter; left time: 324.7745s\n",
      "\titers: 700, epoch: 10 | loss: 0.0582220\n",
      "\tspeed: 0.0346s/iter; left time: 320.6847s\n",
      "\titers: 800, epoch: 10 | loss: 0.0630818\n",
      "\tspeed: 0.0346s/iter; left time: 317.2015s\n",
      "\titers: 900, epoch: 10 | loss: 0.0590224\n",
      "\tspeed: 0.0347s/iter; left time: 314.2078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:31.64s\n",
      "Steps: 906 | Train Loss: 0.0524546 Vali Loss: 0.0584495 Test Loss: 0.0668093\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0541355\n",
      "\tspeed: 0.0950s/iter; left time: 850.9173s\n",
      "\titers: 200, epoch: 11 | loss: 0.0514751\n",
      "\tspeed: 0.0347s/iter; left time: 307.1480s\n",
      "\titers: 300, epoch: 11 | loss: 0.0508684\n",
      "\tspeed: 0.0347s/iter; left time: 304.1859s\n",
      "\titers: 400, epoch: 11 | loss: 0.0488365\n",
      "\tspeed: 0.0347s/iter; left time: 300.4539s\n",
      "\titers: 500, epoch: 11 | loss: 0.0411242\n",
      "\tspeed: 0.0347s/iter; left time: 297.1902s\n",
      "\titers: 600, epoch: 11 | loss: 0.0533406\n",
      "\tspeed: 0.0347s/iter; left time: 293.6787s\n",
      "\titers: 700, epoch: 11 | loss: 0.0518379\n",
      "\tspeed: 0.0346s/iter; left time: 288.9753s\n",
      "\titers: 800, epoch: 11 | loss: 0.0526628\n",
      "\tspeed: 0.0346s/iter; left time: 285.9920s\n",
      "\titers: 900, epoch: 11 | loss: 0.0498659\n",
      "\tspeed: 0.0346s/iter; left time: 282.5677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0511982 Vali Loss: 0.0571466 Test Loss: 0.0659549\n",
      "Validation loss decreased (0.057246 --> 0.057147).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0479833\n",
      "\tspeed: 0.0978s/iter; left time: 787.9345s\n",
      "\titers: 200, epoch: 12 | loss: 0.0515542\n",
      "\tspeed: 0.0347s/iter; left time: 276.0988s\n",
      "\titers: 300, epoch: 12 | loss: 0.0507848\n",
      "\tspeed: 0.0347s/iter; left time: 272.2591s\n",
      "\titers: 400, epoch: 12 | loss: 0.0510435\n",
      "\tspeed: 0.0347s/iter; left time: 268.7503s\n",
      "\titers: 500, epoch: 12 | loss: 0.0462130\n",
      "\tspeed: 0.0347s/iter; left time: 265.9512s\n",
      "\titers: 600, epoch: 12 | loss: 0.0533448\n",
      "\tspeed: 0.0347s/iter; left time: 262.1570s\n",
      "\titers: 700, epoch: 12 | loss: 0.0432821\n",
      "\tspeed: 0.0346s/iter; left time: 258.2145s\n",
      "\titers: 800, epoch: 12 | loss: 0.0530810\n",
      "\tspeed: 0.0347s/iter; left time: 255.3143s\n",
      "\titers: 900, epoch: 12 | loss: 0.0456739\n",
      "\tspeed: 0.0347s/iter; left time: 251.8942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:31.72s\n",
      "Steps: 906 | Train Loss: 0.0497971 Vali Loss: 0.0571572 Test Loss: 0.0657481\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0520588\n",
      "\tspeed: 0.0957s/iter; left time: 683.8958s\n",
      "\titers: 200, epoch: 13 | loss: 0.0471978\n",
      "\tspeed: 0.0353s/iter; left time: 248.8270s\n",
      "\titers: 300, epoch: 13 | loss: 0.0492734\n",
      "\tspeed: 0.0347s/iter; left time: 240.9171s\n",
      "\titers: 400, epoch: 13 | loss: 0.0487693\n",
      "\tspeed: 0.0347s/iter; left time: 237.8179s\n",
      "\titers: 500, epoch: 13 | loss: 0.0490274\n",
      "\tspeed: 0.0350s/iter; left time: 235.9805s\n",
      "\titers: 600, epoch: 13 | loss: 0.0444182\n",
      "\tspeed: 0.0345s/iter; left time: 229.6636s\n",
      "\titers: 700, epoch: 13 | loss: 0.0454526\n",
      "\tspeed: 0.0347s/iter; left time: 227.3076s\n",
      "\titers: 800, epoch: 13 | loss: 0.0502009\n",
      "\tspeed: 0.0347s/iter; left time: 224.0524s\n",
      "\titers: 900, epoch: 13 | loss: 0.0519659\n",
      "\tspeed: 0.0347s/iter; left time: 220.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.0487688 Vali Loss: 0.0568870 Test Loss: 0.0654286\n",
      "Validation loss decreased (0.057147 --> 0.056887).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0472592\n",
      "\tspeed: 0.0989s/iter; left time: 617.6909s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461481\n",
      "\tspeed: 0.0346s/iter; left time: 212.8299s\n",
      "\titers: 300, epoch: 14 | loss: 0.0439564\n",
      "\tspeed: 0.0347s/iter; left time: 209.6598s\n",
      "\titers: 400, epoch: 14 | loss: 0.0481552\n",
      "\tspeed: 0.0346s/iter; left time: 205.6444s\n",
      "\titers: 500, epoch: 14 | loss: 0.0552839\n",
      "\tspeed: 0.0346s/iter; left time: 202.3369s\n",
      "\titers: 600, epoch: 14 | loss: 0.0544599\n",
      "\tspeed: 0.0346s/iter; left time: 198.9589s\n",
      "\titers: 700, epoch: 14 | loss: 0.0492873\n",
      "\tspeed: 0.0346s/iter; left time: 195.4065s\n",
      "\titers: 800, epoch: 14 | loss: 0.0519501\n",
      "\tspeed: 0.0347s/iter; left time: 192.1339s\n",
      "\titers: 900, epoch: 14 | loss: 0.0444011\n",
      "\tspeed: 0.0347s/iter; left time: 188.8453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:31.68s\n",
      "Steps: 906 | Train Loss: 0.0478288 Vali Loss: 0.0574118 Test Loss: 0.0649276\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0518620\n",
      "\tspeed: 0.0950s/iter; left time: 506.9968s\n",
      "\titers: 200, epoch: 15 | loss: 0.0447321\n",
      "\tspeed: 0.0346s/iter; left time: 181.3134s\n",
      "\titers: 300, epoch: 15 | loss: 0.0470643\n",
      "\tspeed: 0.0346s/iter; left time: 177.8876s\n",
      "\titers: 400, epoch: 15 | loss: 0.0505560\n",
      "\tspeed: 0.0348s/iter; left time: 175.1414s\n",
      "\titers: 500, epoch: 15 | loss: 0.0455437\n",
      "\tspeed: 0.0347s/iter; left time: 171.4088s\n",
      "\titers: 600, epoch: 15 | loss: 0.0463022\n",
      "\tspeed: 0.0346s/iter; left time: 167.5804s\n",
      "\titers: 700, epoch: 15 | loss: 0.0565158\n",
      "\tspeed: 0.0347s/iter; left time: 164.3168s\n",
      "\titers: 800, epoch: 15 | loss: 0.0485040\n",
      "\tspeed: 0.0346s/iter; left time: 160.5875s\n",
      "\titers: 900, epoch: 15 | loss: 0.0463231\n",
      "\tspeed: 0.0346s/iter; left time: 157.0765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:31.70s\n",
      "Steps: 906 | Train Loss: 0.0470613 Vali Loss: 0.0568892 Test Loss: 0.0665978\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0476478\n",
      "\tspeed: 0.0958s/iter; left time: 424.5514s\n",
      "\titers: 200, epoch: 16 | loss: 0.0442408\n",
      "\tspeed: 0.0347s/iter; left time: 150.2413s\n",
      "\titers: 300, epoch: 16 | loss: 0.0460189\n",
      "\tspeed: 0.0347s/iter; left time: 146.8148s\n",
      "\titers: 400, epoch: 16 | loss: 0.0477852\n",
      "\tspeed: 0.0347s/iter; left time: 143.2491s\n",
      "\titers: 500, epoch: 16 | loss: 0.0508246\n",
      "\tspeed: 0.0347s/iter; left time: 139.7995s\n",
      "\titers: 600, epoch: 16 | loss: 0.0476234\n",
      "\tspeed: 0.0347s/iter; left time: 136.2444s\n",
      "\titers: 700, epoch: 16 | loss: 0.0496349\n",
      "\tspeed: 0.0347s/iter; left time: 132.8671s\n",
      "\titers: 800, epoch: 16 | loss: 0.0451010\n",
      "\tspeed: 0.0347s/iter; left time: 129.3319s\n",
      "\titers: 900, epoch: 16 | loss: 0.0472244\n",
      "\tspeed: 0.0347s/iter; left time: 125.8357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:31.73s\n",
      "Steps: 906 | Train Loss: 0.0462200 Vali Loss: 0.0565890 Test Loss: 0.0651991\n",
      "Validation loss decreased (0.056887 --> 0.056589).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0511533\n",
      "\tspeed: 0.0990s/iter; left time: 348.8845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0410157\n",
      "\tspeed: 0.0347s/iter; left time: 118.8367s\n",
      "\titers: 300, epoch: 17 | loss: 0.0532006\n",
      "\tspeed: 0.0346s/iter; left time: 115.1362s\n",
      "\titers: 400, epoch: 17 | loss: 0.0506476\n",
      "\tspeed: 0.0347s/iter; left time: 111.8803s\n",
      "\titers: 500, epoch: 17 | loss: 0.0444746\n",
      "\tspeed: 0.0347s/iter; left time: 108.5460s\n",
      "\titers: 600, epoch: 17 | loss: 0.0454823\n",
      "\tspeed: 0.0347s/iter; left time: 104.8775s\n",
      "\titers: 700, epoch: 17 | loss: 0.0417460\n",
      "\tspeed: 0.0348s/iter; left time: 101.7171s\n",
      "\titers: 800, epoch: 17 | loss: 0.0485935\n",
      "\tspeed: 0.0347s/iter; left time: 98.1239s\n",
      "\titers: 900, epoch: 17 | loss: 0.0427209\n",
      "\tspeed: 0.0347s/iter; left time: 94.6065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:31.77s\n",
      "Steps: 906 | Train Loss: 0.0454245 Vali Loss: 0.0563723 Test Loss: 0.0671997\n",
      "Validation loss decreased (0.056589 --> 0.056372).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0397315\n",
      "\tspeed: 0.0992s/iter; left time: 259.7061s\n",
      "\titers: 200, epoch: 18 | loss: 0.0411270\n",
      "\tspeed: 0.0354s/iter; left time: 89.2592s\n",
      "\titers: 300, epoch: 18 | loss: 0.0484297\n",
      "\tspeed: 0.0353s/iter; left time: 85.4810s\n",
      "\titers: 400, epoch: 18 | loss: 0.0467603\n",
      "\tspeed: 0.0347s/iter; left time: 80.3745s\n",
      "\titers: 500, epoch: 18 | loss: 0.0422288\n",
      "\tspeed: 0.0347s/iter; left time: 77.1078s\n",
      "\titers: 600, epoch: 18 | loss: 0.0504954\n",
      "\tspeed: 0.0347s/iter; left time: 73.4995s\n",
      "\titers: 700, epoch: 18 | loss: 0.0396327\n",
      "\tspeed: 0.0347s/iter; left time: 70.1133s\n",
      "\titers: 800, epoch: 18 | loss: 0.0461913\n",
      "\tspeed: 0.0348s/iter; left time: 66.7656s\n",
      "\titers: 900, epoch: 18 | loss: 0.0522097\n",
      "\tspeed: 0.0353s/iter; left time: 64.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:32.05s\n",
      "Steps: 906 | Train Loss: 0.0448353 Vali Loss: 0.0574077 Test Loss: 0.0666983\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0404343\n",
      "\tspeed: 0.0962s/iter; left time: 164.8634s\n",
      "\titers: 200, epoch: 19 | loss: 0.0435289\n",
      "\tspeed: 0.0354s/iter; left time: 57.0615s\n",
      "\titers: 300, epoch: 19 | loss: 0.0437113\n",
      "\tspeed: 0.0354s/iter; left time: 53.5034s\n",
      "\titers: 400, epoch: 19 | loss: 0.0464690\n",
      "\tspeed: 0.0347s/iter; left time: 49.0817s\n",
      "\titers: 500, epoch: 19 | loss: 0.0434488\n",
      "\tspeed: 0.0345s/iter; left time: 45.3597s\n",
      "\titers: 600, epoch: 19 | loss: 0.0420474\n",
      "\tspeed: 0.0346s/iter; left time: 41.9174s\n",
      "\titers: 700, epoch: 19 | loss: 0.0488688\n",
      "\tspeed: 0.0346s/iter; left time: 38.4872s\n",
      "\titers: 800, epoch: 19 | loss: 0.0425040\n",
      "\tspeed: 0.0347s/iter; left time: 35.1069s\n",
      "\titers: 900, epoch: 19 | loss: 0.0387297\n",
      "\tspeed: 0.0346s/iter; left time: 31.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:31.91s\n",
      "Steps: 906 | Train Loss: 0.0441012 Vali Loss: 0.0579686 Test Loss: 0.0662565\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0443658\n",
      "\tspeed: 0.0947s/iter; left time: 76.3905s\n",
      "\titers: 200, epoch: 20 | loss: 0.0434084\n",
      "\tspeed: 0.0346s/iter; left time: 24.4717s\n",
      "\titers: 300, epoch: 20 | loss: 0.0444593\n",
      "\tspeed: 0.0347s/iter; left time: 21.0411s\n",
      "\titers: 400, epoch: 20 | loss: 0.0421418\n",
      "\tspeed: 0.0346s/iter; left time: 17.5626s\n",
      "\titers: 500, epoch: 20 | loss: 0.0421504\n",
      "\tspeed: 0.0346s/iter; left time: 14.0774s\n",
      "\titers: 600, epoch: 20 | loss: 0.0476669\n",
      "\tspeed: 0.0347s/iter; left time: 10.6547s\n",
      "\titers: 700, epoch: 20 | loss: 0.0507700\n",
      "\tspeed: 0.0346s/iter; left time: 7.1550s\n",
      "\titers: 800, epoch: 20 | loss: 0.0446998\n",
      "\tspeed: 0.0346s/iter; left time: 3.7025s\n",
      "\titers: 900, epoch: 20 | loss: 0.0413743\n",
      "\tspeed: 0.0346s/iter; left time: 0.2421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:31.65s\n",
      "Steps: 906 | Train Loss: 0.0435656 Vali Loss: 0.0569343 Test Loss: 0.0663891\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_IT_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.013082382269203663, rmse:0.11437824368476868, mae:0.06724400073289871, rse:0.43224334716796875\n",
      "Intermediate time for IT and pred_len 24: 00h:23m:18.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2329149\n",
      "\tspeed: 0.0654s/iter; left time: 1176.2400s\n",
      "\titers: 200, epoch: 1 | loss: 0.2132984\n",
      "\tspeed: 0.0419s/iter; left time: 749.7176s\n",
      "\titers: 300, epoch: 1 | loss: 0.2021164\n",
      "\tspeed: 0.0419s/iter; left time: 745.8109s\n",
      "\titers: 400, epoch: 1 | loss: 0.1994694\n",
      "\tspeed: 0.0419s/iter; left time: 741.5871s\n",
      "\titers: 500, epoch: 1 | loss: 0.1993076\n",
      "\tspeed: 0.0419s/iter; left time: 737.5135s\n",
      "\titers: 600, epoch: 1 | loss: 0.1911502\n",
      "\tspeed: 0.0420s/iter; left time: 733.4970s\n",
      "\titers: 700, epoch: 1 | loss: 0.1889577\n",
      "\tspeed: 0.0419s/iter; left time: 728.8116s\n",
      "\titers: 800, epoch: 1 | loss: 0.1783947\n",
      "\tspeed: 0.0415s/iter; left time: 717.1408s\n",
      "\titers: 900, epoch: 1 | loss: 0.1868250\n",
      "\tspeed: 0.0420s/iter; left time: 720.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 904 | Train Loss: 0.2045878 Vali Loss: 0.1702724 Test Loss: 0.1878111\n",
      "Validation loss decreased (inf --> 0.170272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1723534\n",
      "\tspeed: 0.1170s/iter; left time: 1998.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.1603348\n",
      "\tspeed: 0.0415s/iter; left time: 704.5081s\n",
      "\titers: 300, epoch: 2 | loss: 0.1485798\n",
      "\tspeed: 0.0415s/iter; left time: 700.8199s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373307\n",
      "\tspeed: 0.0415s/iter; left time: 696.6399s\n",
      "\titers: 500, epoch: 2 | loss: 0.1285997\n",
      "\tspeed: 0.0415s/iter; left time: 692.2526s\n",
      "\titers: 600, epoch: 2 | loss: 0.1198477\n",
      "\tspeed: 0.0415s/iter; left time: 688.1834s\n",
      "\titers: 700, epoch: 2 | loss: 0.1147303\n",
      "\tspeed: 0.0415s/iter; left time: 683.9993s\n",
      "\titers: 800, epoch: 2 | loss: 0.1007503\n",
      "\tspeed: 0.0415s/iter; left time: 679.8908s\n",
      "\titers: 900, epoch: 2 | loss: 0.0971180\n",
      "\tspeed: 0.0415s/iter; left time: 676.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 904 | Train Loss: 0.1339202 Vali Loss: 0.0941798 Test Loss: 0.1007875\n",
      "Validation loss decreased (0.170272 --> 0.094180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0933497\n",
      "\tspeed: 0.1176s/iter; left time: 1901.4621s\n",
      "\titers: 200, epoch: 3 | loss: 0.0936517\n",
      "\tspeed: 0.0420s/iter; left time: 675.2535s\n",
      "\titers: 300, epoch: 3 | loss: 0.0927260\n",
      "\tspeed: 0.0420s/iter; left time: 670.9438s\n",
      "\titers: 400, epoch: 3 | loss: 0.0904723\n",
      "\tspeed: 0.0420s/iter; left time: 666.9150s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878174\n",
      "\tspeed: 0.0419s/iter; left time: 661.3822s\n",
      "\titers: 600, epoch: 3 | loss: 0.0923175\n",
      "\tspeed: 0.0415s/iter; left time: 650.1710s\n",
      "\titers: 700, epoch: 3 | loss: 0.0842094\n",
      "\tspeed: 0.0415s/iter; left time: 645.7592s\n",
      "\titers: 800, epoch: 3 | loss: 0.0947829\n",
      "\tspeed: 0.0416s/iter; left time: 643.4295s\n",
      "\titers: 900, epoch: 3 | loss: 0.0795053\n",
      "\tspeed: 0.0420s/iter; left time: 645.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 904 | Train Loss: 0.0910683 Vali Loss: 0.0842124 Test Loss: 0.0916354\n",
      "Validation loss decreased (0.094180 --> 0.084212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0810681\n",
      "\tspeed: 0.1176s/iter; left time: 1795.0221s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898334\n",
      "\tspeed: 0.0415s/iter; left time: 629.5262s\n",
      "\titers: 300, epoch: 4 | loss: 0.0877813\n",
      "\tspeed: 0.0415s/iter; left time: 625.5383s\n",
      "\titers: 400, epoch: 4 | loss: 0.0827008\n",
      "\tspeed: 0.0415s/iter; left time: 620.9080s\n",
      "\titers: 500, epoch: 4 | loss: 0.0800275\n",
      "\tspeed: 0.0415s/iter; left time: 617.5306s\n",
      "\titers: 600, epoch: 4 | loss: 0.0795660\n",
      "\tspeed: 0.0415s/iter; left time: 613.3683s\n",
      "\titers: 700, epoch: 4 | loss: 0.0887710\n",
      "\tspeed: 0.0415s/iter; left time: 609.4629s\n",
      "\titers: 800, epoch: 4 | loss: 0.0751216\n",
      "\tspeed: 0.0415s/iter; left time: 605.2594s\n",
      "\titers: 900, epoch: 4 | loss: 0.0814652\n",
      "\tspeed: 0.0415s/iter; left time: 600.9843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0842684 Vali Loss: 0.0824417 Test Loss: 0.0909199\n",
      "Validation loss decreased (0.084212 --> 0.082442).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0819404\n",
      "\tspeed: 0.1164s/iter; left time: 1672.1114s\n",
      "\titers: 200, epoch: 5 | loss: 0.0734804\n",
      "\tspeed: 0.0415s/iter; left time: 591.8577s\n",
      "\titers: 300, epoch: 5 | loss: 0.0850687\n",
      "\tspeed: 0.0415s/iter; left time: 587.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.0805629\n",
      "\tspeed: 0.0415s/iter; left time: 583.3193s\n",
      "\titers: 500, epoch: 5 | loss: 0.0772669\n",
      "\tspeed: 0.0415s/iter; left time: 579.6728s\n",
      "\titers: 600, epoch: 5 | loss: 0.0835028\n",
      "\tspeed: 0.0415s/iter; left time: 575.0510s\n",
      "\titers: 700, epoch: 5 | loss: 0.0755597\n",
      "\tspeed: 0.0415s/iter; left time: 571.0340s\n",
      "\titers: 800, epoch: 5 | loss: 0.0821126\n",
      "\tspeed: 0.0415s/iter; left time: 566.8882s\n",
      "\titers: 900, epoch: 5 | loss: 0.0793681\n",
      "\tspeed: 0.0415s/iter; left time: 563.0824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 904 | Train Loss: 0.0794752 Vali Loss: 0.0815711 Test Loss: 0.0942506\n",
      "Validation loss decreased (0.082442 --> 0.081571).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0839607\n",
      "\tspeed: 0.1197s/iter; left time: 1610.7661s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795517\n",
      "\tspeed: 0.0415s/iter; left time: 555.1379s\n",
      "\titers: 300, epoch: 6 | loss: 0.0796291\n",
      "\tspeed: 0.0415s/iter; left time: 550.8724s\n",
      "\titers: 400, epoch: 6 | loss: 0.0740407\n",
      "\tspeed: 0.0415s/iter; left time: 546.6841s\n",
      "\titers: 500, epoch: 6 | loss: 0.0732674\n",
      "\tspeed: 0.0415s/iter; left time: 542.1567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0717258\n",
      "\tspeed: 0.0415s/iter; left time: 538.1807s\n",
      "\titers: 700, epoch: 6 | loss: 0.0781353\n",
      "\tspeed: 0.0415s/iter; left time: 533.8559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0775410\n",
      "\tspeed: 0.0415s/iter; left time: 529.6971s\n",
      "\titers: 900, epoch: 6 | loss: 0.0719830\n",
      "\tspeed: 0.0415s/iter; left time: 526.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0759981 Vali Loss: 0.0810199 Test Loss: 0.0920831\n",
      "Validation loss decreased (0.081571 --> 0.081020).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0723580\n",
      "\tspeed: 0.1173s/iter; left time: 1472.4495s\n",
      "\titers: 200, epoch: 7 | loss: 0.0775005\n",
      "\tspeed: 0.0415s/iter; left time: 516.4661s\n",
      "\titers: 300, epoch: 7 | loss: 0.0755266\n",
      "\tspeed: 0.0415s/iter; left time: 512.4093s\n",
      "\titers: 400, epoch: 7 | loss: 0.0716491\n",
      "\tspeed: 0.0415s/iter; left time: 508.4572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0726988\n",
      "\tspeed: 0.0415s/iter; left time: 504.2027s\n",
      "\titers: 600, epoch: 7 | loss: 0.0645041\n",
      "\tspeed: 0.0415s/iter; left time: 500.0718s\n",
      "\titers: 700, epoch: 7 | loss: 0.0743607\n",
      "\tspeed: 0.0415s/iter; left time: 496.0049s\n",
      "\titers: 800, epoch: 7 | loss: 0.0622560\n",
      "\tspeed: 0.0415s/iter; left time: 491.8869s\n",
      "\titers: 900, epoch: 7 | loss: 0.0748020\n",
      "\tspeed: 0.0415s/iter; left time: 487.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 904 | Train Loss: 0.0728088 Vali Loss: 0.0797380 Test Loss: 0.0911746\n",
      "Validation loss decreased (0.081020 --> 0.079738).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0803198\n",
      "\tspeed: 0.1181s/iter; left time: 1376.5631s\n",
      "\titers: 200, epoch: 8 | loss: 0.0780065\n",
      "\tspeed: 0.0415s/iter; left time: 479.7795s\n",
      "\titers: 300, epoch: 8 | loss: 0.0705057\n",
      "\tspeed: 0.0415s/iter; left time: 475.6276s\n",
      "\titers: 400, epoch: 8 | loss: 0.0695511\n",
      "\tspeed: 0.0416s/iter; left time: 471.7291s\n",
      "\titers: 500, epoch: 8 | loss: 0.0667554\n",
      "\tspeed: 0.0415s/iter; left time: 467.1372s\n",
      "\titers: 600, epoch: 8 | loss: 0.0727597\n",
      "\tspeed: 0.0415s/iter; left time: 463.1018s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681027\n",
      "\tspeed: 0.0415s/iter; left time: 459.0644s\n",
      "\titers: 800, epoch: 8 | loss: 0.0727258\n",
      "\tspeed: 0.0415s/iter; left time: 454.9328s\n",
      "\titers: 900, epoch: 8 | loss: 0.0665395\n",
      "\tspeed: 0.0415s/iter; left time: 450.5433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0701697 Vali Loss: 0.0797013 Test Loss: 0.0913741\n",
      "Validation loss decreased (0.079738 --> 0.079701).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698563\n",
      "\tspeed: 0.1180s/iter; left time: 1268.2817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0712313\n",
      "\tspeed: 0.0415s/iter; left time: 441.8347s\n",
      "\titers: 300, epoch: 9 | loss: 0.0642897\n",
      "\tspeed: 0.0415s/iter; left time: 437.9253s\n",
      "\titers: 400, epoch: 9 | loss: 0.0650743\n",
      "\tspeed: 0.0415s/iter; left time: 433.4531s\n",
      "\titers: 500, epoch: 9 | loss: 0.0677874\n",
      "\tspeed: 0.0416s/iter; left time: 430.0321s\n",
      "\titers: 600, epoch: 9 | loss: 0.0642288\n",
      "\tspeed: 0.0416s/iter; left time: 426.0446s\n",
      "\titers: 700, epoch: 9 | loss: 0.0613472\n",
      "\tspeed: 0.0415s/iter; left time: 421.6572s\n",
      "\titers: 800, epoch: 9 | loss: 0.0655759\n",
      "\tspeed: 0.0416s/iter; left time: 417.8767s\n",
      "\titers: 900, epoch: 9 | loss: 0.0630118\n",
      "\tspeed: 0.0415s/iter; left time: 413.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0675159 Vali Loss: 0.0817569 Test Loss: 0.0939381\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0707889\n",
      "\tspeed: 0.1142s/iter; left time: 1123.9164s\n",
      "\titers: 200, epoch: 10 | loss: 0.0646257\n",
      "\tspeed: 0.0415s/iter; left time: 404.3090s\n",
      "\titers: 300, epoch: 10 | loss: 0.0597870\n",
      "\tspeed: 0.0415s/iter; left time: 400.0274s\n",
      "\titers: 400, epoch: 10 | loss: 0.0606851\n",
      "\tspeed: 0.0415s/iter; left time: 396.0367s\n",
      "\titers: 500, epoch: 10 | loss: 0.0722949\n",
      "\tspeed: 0.0415s/iter; left time: 391.8655s\n",
      "\titers: 600, epoch: 10 | loss: 0.0613441\n",
      "\tspeed: 0.0415s/iter; left time: 387.7212s\n",
      "\titers: 700, epoch: 10 | loss: 0.0637856\n",
      "\tspeed: 0.0415s/iter; left time: 383.5531s\n",
      "\titers: 800, epoch: 10 | loss: 0.0674466\n",
      "\tspeed: 0.0415s/iter; left time: 379.4913s\n",
      "\titers: 900, epoch: 10 | loss: 0.0660359\n",
      "\tspeed: 0.0415s/iter; left time: 375.4005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 904 | Train Loss: 0.0650114 Vali Loss: 0.0814649 Test Loss: 0.0932802\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0628955\n",
      "\tspeed: 0.1142s/iter; left time: 1021.1997s\n",
      "\titers: 200, epoch: 11 | loss: 0.0667712\n",
      "\tspeed: 0.0415s/iter; left time: 367.1091s\n",
      "\titers: 300, epoch: 11 | loss: 0.0622564\n",
      "\tspeed: 0.0415s/iter; left time: 362.8662s\n",
      "\titers: 400, epoch: 11 | loss: 0.0667247\n",
      "\tspeed: 0.0415s/iter; left time: 358.5564s\n",
      "\titers: 500, epoch: 11 | loss: 0.0588989\n",
      "\tspeed: 0.0415s/iter; left time: 354.8069s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601503\n",
      "\tspeed: 0.0415s/iter; left time: 350.5460s\n",
      "\titers: 700, epoch: 11 | loss: 0.0651884\n",
      "\tspeed: 0.0415s/iter; left time: 346.4933s\n",
      "\titers: 800, epoch: 11 | loss: 0.0648965\n",
      "\tspeed: 0.0415s/iter; left time: 342.2225s\n",
      "\titers: 900, epoch: 11 | loss: 0.0662556\n",
      "\tspeed: 0.0415s/iter; left time: 338.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.76s\n",
      "Steps: 904 | Train Loss: 0.0628507 Vali Loss: 0.0824759 Test Loss: 0.0953183\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0586193\n",
      "\tspeed: 0.1132s/iter; left time: 910.0730s\n",
      "\titers: 200, epoch: 12 | loss: 0.0632593\n",
      "\tspeed: 0.0414s/iter; left time: 328.9784s\n",
      "\titers: 300, epoch: 12 | loss: 0.0581805\n",
      "\tspeed: 0.0414s/iter; left time: 324.8005s\n",
      "\titers: 400, epoch: 12 | loss: 0.0527286\n",
      "\tspeed: 0.0415s/iter; left time: 320.8751s\n",
      "\titers: 500, epoch: 12 | loss: 0.0617137\n",
      "\tspeed: 0.0415s/iter; left time: 316.7904s\n",
      "\titers: 600, epoch: 12 | loss: 0.0588900\n",
      "\tspeed: 0.0414s/iter; left time: 312.4074s\n",
      "\titers: 700, epoch: 12 | loss: 0.0644570\n",
      "\tspeed: 0.0415s/iter; left time: 308.3568s\n",
      "\titers: 800, epoch: 12 | loss: 0.0602104\n",
      "\tspeed: 0.0415s/iter; left time: 304.2294s\n",
      "\titers: 900, epoch: 12 | loss: 0.0594495\n",
      "\tspeed: 0.0415s/iter; left time: 300.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 904 | Train Loss: 0.0606359 Vali Loss: 0.0830488 Test Loss: 0.0953343\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0596162\n",
      "\tspeed: 0.1131s/iter; left time: 807.0245s\n",
      "\titers: 200, epoch: 13 | loss: 0.0571232\n",
      "\tspeed: 0.0415s/iter; left time: 291.9264s\n",
      "\titers: 300, epoch: 13 | loss: 0.0555218\n",
      "\tspeed: 0.0415s/iter; left time: 287.6298s\n",
      "\titers: 400, epoch: 13 | loss: 0.0576127\n",
      "\tspeed: 0.0415s/iter; left time: 283.7168s\n",
      "\titers: 500, epoch: 13 | loss: 0.0613527\n",
      "\tspeed: 0.0415s/iter; left time: 279.3836s\n",
      "\titers: 600, epoch: 13 | loss: 0.0561092\n",
      "\tspeed: 0.0415s/iter; left time: 275.2104s\n",
      "\titers: 700, epoch: 13 | loss: 0.0549113\n",
      "\tspeed: 0.0415s/iter; left time: 271.0120s\n",
      "\titers: 800, epoch: 13 | loss: 0.0601151\n",
      "\tspeed: 0.0415s/iter; left time: 266.8849s\n",
      "\titers: 900, epoch: 13 | loss: 0.0564174\n",
      "\tspeed: 0.0415s/iter; left time: 262.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 904 | Train Loss: 0.0588037 Vali Loss: 0.0848033 Test Loss: 0.0960292\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.022316191345453262, rmse:0.14938604831695557, mae:0.09133996814489365, rse:0.5648447275161743\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2292959\n",
      "\tspeed: 0.0439s/iter; left time: 790.0637s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081810\n",
      "\tspeed: 0.0416s/iter; left time: 743.1444s\n",
      "\titers: 300, epoch: 1 | loss: 0.2096158\n",
      "\tspeed: 0.0416s/iter; left time: 738.9012s\n",
      "\titers: 400, epoch: 1 | loss: 0.2077726\n",
      "\tspeed: 0.0416s/iter; left time: 734.8712s\n",
      "\titers: 500, epoch: 1 | loss: 0.1998558\n",
      "\tspeed: 0.0416s/iter; left time: 730.8517s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957197\n",
      "\tspeed: 0.0416s/iter; left time: 726.7343s\n",
      "\titers: 700, epoch: 1 | loss: 0.1891191\n",
      "\tspeed: 0.0416s/iter; left time: 722.6622s\n",
      "\titers: 800, epoch: 1 | loss: 0.1786730\n",
      "\tspeed: 0.0416s/iter; left time: 718.8404s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799013\n",
      "\tspeed: 0.0416s/iter; left time: 714.3080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.2049319 Vali Loss: 0.1680077 Test Loss: 0.1860517\n",
      "Validation loss decreased (inf --> 0.168008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1652640\n",
      "\tspeed: 0.1168s/iter; left time: 1995.2893s\n",
      "\titers: 200, epoch: 2 | loss: 0.1542776\n",
      "\tspeed: 0.0416s/iter; left time: 705.8684s\n",
      "\titers: 300, epoch: 2 | loss: 0.1318608\n",
      "\tspeed: 0.0416s/iter; left time: 701.9676s\n",
      "\titers: 400, epoch: 2 | loss: 0.1279899\n",
      "\tspeed: 0.0416s/iter; left time: 697.8615s\n",
      "\titers: 500, epoch: 2 | loss: 0.1211760\n",
      "\tspeed: 0.0416s/iter; left time: 693.6336s\n",
      "\titers: 600, epoch: 2 | loss: 0.1045376\n",
      "\tspeed: 0.0416s/iter; left time: 689.3137s\n",
      "\titers: 700, epoch: 2 | loss: 0.1058448\n",
      "\tspeed: 0.0416s/iter; left time: 685.0528s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937553\n",
      "\tspeed: 0.0416s/iter; left time: 681.1193s\n",
      "\titers: 900, epoch: 2 | loss: 0.0992664\n",
      "\tspeed: 0.0416s/iter; left time: 676.6432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.1267896 Vali Loss: 0.0913177 Test Loss: 0.0968462\n",
      "Validation loss decreased (0.168008 --> 0.091318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0841759\n",
      "\tspeed: 0.1182s/iter; left time: 1911.4221s\n",
      "\titers: 200, epoch: 3 | loss: 0.0893953\n",
      "\tspeed: 0.0422s/iter; left time: 678.8770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0954204\n",
      "\tspeed: 0.0421s/iter; left time: 673.1054s\n",
      "\titers: 400, epoch: 3 | loss: 0.1050853\n",
      "\tspeed: 0.0421s/iter; left time: 668.4050s\n",
      "\titers: 500, epoch: 3 | loss: 0.0887890\n",
      "\tspeed: 0.0421s/iter; left time: 664.0398s\n",
      "\titers: 600, epoch: 3 | loss: 0.0911384\n",
      "\tspeed: 0.0421s/iter; left time: 660.1369s\n",
      "\titers: 700, epoch: 3 | loss: 0.0956997\n",
      "\tspeed: 0.0421s/iter; left time: 655.4478s\n",
      "\titers: 800, epoch: 3 | loss: 0.0855911\n",
      "\tspeed: 0.0421s/iter; left time: 651.3994s\n",
      "\titers: 900, epoch: 3 | loss: 0.0926109\n",
      "\tspeed: 0.0421s/iter; left time: 647.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 904 | Train Loss: 0.0894015 Vali Loss: 0.0832333 Test Loss: 0.0903517\n",
      "Validation loss decreased (0.091318 --> 0.083233).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818864\n",
      "\tspeed: 0.1173s/iter; left time: 1791.4033s\n",
      "\titers: 200, epoch: 4 | loss: 0.0908587\n",
      "\tspeed: 0.0416s/iter; left time: 630.3665s\n",
      "\titers: 300, epoch: 4 | loss: 0.0815956\n",
      "\tspeed: 0.0416s/iter; left time: 626.1857s\n",
      "\titers: 400, epoch: 4 | loss: 0.0794364\n",
      "\tspeed: 0.0415s/iter; left time: 621.8439s\n",
      "\titers: 500, epoch: 4 | loss: 0.0824227\n",
      "\tspeed: 0.0416s/iter; left time: 618.1104s\n",
      "\titers: 600, epoch: 4 | loss: 0.0863480\n",
      "\tspeed: 0.0416s/iter; left time: 613.9127s\n",
      "\titers: 700, epoch: 4 | loss: 0.0751134\n",
      "\tspeed: 0.0416s/iter; left time: 609.5003s\n",
      "\titers: 800, epoch: 4 | loss: 0.0925940\n",
      "\tspeed: 0.0416s/iter; left time: 605.9970s\n",
      "\titers: 900, epoch: 4 | loss: 0.0779531\n",
      "\tspeed: 0.0416s/iter; left time: 601.3005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 904 | Train Loss: 0.0827076 Vali Loss: 0.0849494 Test Loss: 0.0960318\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0767040\n",
      "\tspeed: 0.1147s/iter; left time: 1646.9957s\n",
      "\titers: 200, epoch: 5 | loss: 0.0699800\n",
      "\tspeed: 0.0416s/iter; left time: 593.1308s\n",
      "\titers: 300, epoch: 5 | loss: 0.0853455\n",
      "\tspeed: 0.0416s/iter; left time: 588.8973s\n",
      "\titers: 400, epoch: 5 | loss: 0.0704516\n",
      "\tspeed: 0.0416s/iter; left time: 585.1993s\n",
      "\titers: 500, epoch: 5 | loss: 0.0756307\n",
      "\tspeed: 0.0416s/iter; left time: 580.8204s\n",
      "\titers: 600, epoch: 5 | loss: 0.0742427\n",
      "\tspeed: 0.0416s/iter; left time: 576.6748s\n",
      "\titers: 700, epoch: 5 | loss: 0.0752169\n",
      "\tspeed: 0.0416s/iter; left time: 572.6171s\n",
      "\titers: 800, epoch: 5 | loss: 0.0806310\n",
      "\tspeed: 0.0416s/iter; left time: 568.3955s\n",
      "\titers: 900, epoch: 5 | loss: 0.0723156\n",
      "\tspeed: 0.0416s/iter; left time: 564.1423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 904 | Train Loss: 0.0782667 Vali Loss: 0.0774129 Test Loss: 0.0860390\n",
      "Validation loss decreased (0.083233 --> 0.077413).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741043\n",
      "\tspeed: 0.1177s/iter; left time: 1584.3770s\n",
      "\titers: 200, epoch: 6 | loss: 0.0707103\n",
      "\tspeed: 0.0419s/iter; left time: 559.2264s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718977\n",
      "\tspeed: 0.0416s/iter; left time: 551.5400s\n",
      "\titers: 400, epoch: 6 | loss: 0.0712616\n",
      "\tspeed: 0.0416s/iter; left time: 547.3957s\n",
      "\titers: 500, epoch: 6 | loss: 0.0730634\n",
      "\tspeed: 0.0416s/iter; left time: 543.2703s\n",
      "\titers: 600, epoch: 6 | loss: 0.0824830\n",
      "\tspeed: 0.0416s/iter; left time: 539.1506s\n",
      "\titers: 700, epoch: 6 | loss: 0.0697925\n",
      "\tspeed: 0.0416s/iter; left time: 535.2309s\n",
      "\titers: 800, epoch: 6 | loss: 0.0703837\n",
      "\tspeed: 0.0416s/iter; left time: 530.9931s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704858\n",
      "\tspeed: 0.0416s/iter; left time: 526.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 904 | Train Loss: 0.0749824 Vali Loss: 0.0792238 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0748432\n",
      "\tspeed: 0.1146s/iter; left time: 1439.4933s\n",
      "\titers: 200, epoch: 7 | loss: 0.0809488\n",
      "\tspeed: 0.0421s/iter; left time: 524.7787s\n",
      "\titers: 300, epoch: 7 | loss: 0.0747016\n",
      "\tspeed: 0.0421s/iter; left time: 520.0955s\n",
      "\titers: 400, epoch: 7 | loss: 0.0723035\n",
      "\tspeed: 0.0420s/iter; left time: 515.3437s\n",
      "\titers: 500, epoch: 7 | loss: 0.0700389\n",
      "\tspeed: 0.0418s/iter; left time: 508.5885s\n",
      "\titers: 600, epoch: 7 | loss: 0.0682066\n",
      "\tspeed: 0.0420s/iter; left time: 506.9452s\n",
      "\titers: 700, epoch: 7 | loss: 0.0772949\n",
      "\tspeed: 0.0421s/iter; left time: 503.4054s\n",
      "\titers: 800, epoch: 7 | loss: 0.0649828\n",
      "\tspeed: 0.0421s/iter; left time: 499.1290s\n",
      "\titers: 900, epoch: 7 | loss: 0.0713191\n",
      "\tspeed: 0.0420s/iter; left time: 494.2797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 904 | Train Loss: 0.0719335 Vali Loss: 0.0794691 Test Loss: 0.0918467\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724586\n",
      "\tspeed: 0.1142s/iter; left time: 1330.5487s\n",
      "\titers: 200, epoch: 8 | loss: 0.0715756\n",
      "\tspeed: 0.0415s/iter; left time: 479.8969s\n",
      "\titers: 300, epoch: 8 | loss: 0.0657794\n",
      "\tspeed: 0.0415s/iter; left time: 475.6346s\n",
      "\titers: 400, epoch: 8 | loss: 0.0654476\n",
      "\tspeed: 0.0415s/iter; left time: 471.6994s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704021\n",
      "\tspeed: 0.0415s/iter; left time: 467.4944s\n",
      "\titers: 600, epoch: 8 | loss: 0.0675833\n",
      "\tspeed: 0.0416s/iter; left time: 463.5340s\n",
      "\titers: 700, epoch: 8 | loss: 0.0698371\n",
      "\tspeed: 0.0416s/iter; left time: 459.3636s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766558\n",
      "\tspeed: 0.0415s/iter; left time: 455.0782s\n",
      "\titers: 900, epoch: 8 | loss: 0.0691651\n",
      "\tspeed: 0.0416s/iter; left time: 451.2284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 904 | Train Loss: 0.0692788 Vali Loss: 0.0809576 Test Loss: 0.0899754\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0643936\n",
      "\tspeed: 0.1136s/iter; left time: 1221.2237s\n",
      "\titers: 200, epoch: 9 | loss: 0.0613265\n",
      "\tspeed: 0.0415s/iter; left time: 441.8698s\n",
      "\titers: 300, epoch: 9 | loss: 0.0656117\n",
      "\tspeed: 0.0415s/iter; left time: 437.8691s\n",
      "\titers: 400, epoch: 9 | loss: 0.0665474\n",
      "\tspeed: 0.0415s/iter; left time: 433.7844s\n",
      "\titers: 500, epoch: 9 | loss: 0.0646721\n",
      "\tspeed: 0.0415s/iter; left time: 429.7658s\n",
      "\titers: 600, epoch: 9 | loss: 0.0673045\n",
      "\tspeed: 0.0415s/iter; left time: 425.3731s\n",
      "\titers: 700, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0415s/iter; left time: 421.4103s\n",
      "\titers: 800, epoch: 9 | loss: 0.0713633\n",
      "\tspeed: 0.0415s/iter; left time: 417.2159s\n",
      "\titers: 900, epoch: 9 | loss: 0.0673369\n",
      "\tspeed: 0.0415s/iter; left time: 413.1840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 904 | Train Loss: 0.0662697 Vali Loss: 0.0811222 Test Loss: 0.0916531\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0716086\n",
      "\tspeed: 0.1136s/iter; left time: 1118.5103s\n",
      "\titers: 200, epoch: 10 | loss: 0.0616231\n",
      "\tspeed: 0.0416s/iter; left time: 405.1216s\n",
      "\titers: 300, epoch: 10 | loss: 0.0624919\n",
      "\tspeed: 0.0416s/iter; left time: 400.7687s\n",
      "\titers: 400, epoch: 10 | loss: 0.0612750\n",
      "\tspeed: 0.0416s/iter; left time: 396.6213s\n",
      "\titers: 500, epoch: 10 | loss: 0.0687094\n",
      "\tspeed: 0.0416s/iter; left time: 392.6357s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689967\n",
      "\tspeed: 0.0416s/iter; left time: 388.3021s\n",
      "\titers: 700, epoch: 10 | loss: 0.0666971\n",
      "\tspeed: 0.0416s/iter; left time: 384.3920s\n",
      "\titers: 800, epoch: 10 | loss: 0.0618813\n",
      "\tspeed: 0.0416s/iter; left time: 380.2382s\n",
      "\titers: 900, epoch: 10 | loss: 0.0615688\n",
      "\tspeed: 0.0416s/iter; left time: 375.8254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.82s\n",
      "Steps: 904 | Train Loss: 0.0640776 Vali Loss: 0.0819628 Test Loss: 0.0911019\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_IT_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019260551780462265, rmse:0.13878239691257477, mae:0.08605317771434784, rse:0.5247511863708496\n",
      "Intermediate time for IT and pred_len 96: 00h:17m:29.87s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2417706\n",
      "\tspeed: 0.0736s/iter; left time: 1320.0040s\n",
      "\titers: 200, epoch: 1 | loss: 0.2105667\n",
      "\tspeed: 0.0507s/iter; left time: 905.0718s\n",
      "\titers: 300, epoch: 1 | loss: 0.2133086\n",
      "\tspeed: 0.0508s/iter; left time: 900.7788s\n",
      "\titers: 400, epoch: 1 | loss: 0.2001980\n",
      "\tspeed: 0.0508s/iter; left time: 896.6578s\n",
      "\titers: 500, epoch: 1 | loss: 0.1996722\n",
      "\tspeed: 0.0509s/iter; left time: 892.1233s\n",
      "\titers: 600, epoch: 1 | loss: 0.1957152\n",
      "\tspeed: 0.0508s/iter; left time: 886.5263s\n",
      "\titers: 700, epoch: 1 | loss: 0.1911985\n",
      "\tspeed: 0.0508s/iter; left time: 881.4821s\n",
      "\titers: 800, epoch: 1 | loss: 0.1923567\n",
      "\tspeed: 0.0504s/iter; left time: 869.0295s\n",
      "\titers: 900, epoch: 1 | loss: 0.1911421\n",
      "\tspeed: 0.0507s/iter; left time: 869.7827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.2067105 Vali Loss: 0.1742837 Test Loss: 0.1910858\n",
      "Validation loss decreased (inf --> 0.174284).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1741898\n",
      "\tspeed: 0.1420s/iter; left time: 2419.5547s\n",
      "\titers: 200, epoch: 2 | loss: 0.1590756\n",
      "\tspeed: 0.0504s/iter; left time: 853.3194s\n",
      "\titers: 300, epoch: 2 | loss: 0.1492482\n",
      "\tspeed: 0.0504s/iter; left time: 848.3516s\n",
      "\titers: 400, epoch: 2 | loss: 0.1439626\n",
      "\tspeed: 0.0504s/iter; left time: 843.9217s\n",
      "\titers: 500, epoch: 2 | loss: 0.1376841\n",
      "\tspeed: 0.0504s/iter; left time: 837.8947s\n",
      "\titers: 600, epoch: 2 | loss: 0.1318157\n",
      "\tspeed: 0.0504s/iter; left time: 834.1674s\n",
      "\titers: 700, epoch: 2 | loss: 0.1226903\n",
      "\tspeed: 0.0505s/iter; left time: 829.4095s\n",
      "\titers: 800, epoch: 2 | loss: 0.1155013\n",
      "\tspeed: 0.0504s/iter; left time: 823.6467s\n",
      "\titers: 900, epoch: 2 | loss: 0.1036045\n",
      "\tspeed: 0.0503s/iter; left time: 817.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 902 | Train Loss: 0.1425180 Vali Loss: 0.0997220 Test Loss: 0.1080564\n",
      "Validation loss decreased (0.174284 --> 0.099722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1070874\n",
      "\tspeed: 0.1400s/iter; left time: 2259.1733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0982135\n",
      "\tspeed: 0.0504s/iter; left time: 808.0465s\n",
      "\titers: 300, epoch: 3 | loss: 0.0975068\n",
      "\tspeed: 0.0504s/iter; left time: 803.1246s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913634\n",
      "\tspeed: 0.0505s/iter; left time: 799.1843s\n",
      "\titers: 500, epoch: 3 | loss: 0.0938966\n",
      "\tspeed: 0.0504s/iter; left time: 792.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.0963875\n",
      "\tspeed: 0.0504s/iter; left time: 787.6281s\n",
      "\titers: 700, epoch: 3 | loss: 0.0930466\n",
      "\tspeed: 0.0504s/iter; left time: 782.8578s\n",
      "\titers: 800, epoch: 3 | loss: 0.0894339\n",
      "\tspeed: 0.0504s/iter; left time: 777.7969s\n",
      "\titers: 900, epoch: 3 | loss: 0.0931466\n",
      "\tspeed: 0.0503s/iter; left time: 771.7141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0965498 Vali Loss: 0.0912357 Test Loss: 0.1002337\n",
      "Validation loss decreased (0.099722 --> 0.091236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912320\n",
      "\tspeed: 0.1400s/iter; left time: 2132.5732s\n",
      "\titers: 200, epoch: 4 | loss: 0.0867965\n",
      "\tspeed: 0.0507s/iter; left time: 766.7007s\n",
      "\titers: 300, epoch: 4 | loss: 0.0868980\n",
      "\tspeed: 0.0504s/iter; left time: 757.3387s\n",
      "\titers: 400, epoch: 4 | loss: 0.0909916\n",
      "\tspeed: 0.0505s/iter; left time: 754.3584s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869087\n",
      "\tspeed: 0.0504s/iter; left time: 747.6462s\n",
      "\titers: 600, epoch: 4 | loss: 0.0885214\n",
      "\tspeed: 0.0505s/iter; left time: 743.8012s\n",
      "\titers: 700, epoch: 4 | loss: 0.0855719\n",
      "\tspeed: 0.0504s/iter; left time: 736.8779s\n",
      "\titers: 800, epoch: 4 | loss: 0.0911454\n",
      "\tspeed: 0.0505s/iter; left time: 733.7025s\n",
      "\titers: 900, epoch: 4 | loss: 0.0852361\n",
      "\tspeed: 0.0505s/iter; left time: 729.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.88s\n",
      "Steps: 902 | Train Loss: 0.0885773 Vali Loss: 0.0855312 Test Loss: 0.0943597\n",
      "Validation loss decreased (0.091236 --> 0.085531).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867432\n",
      "\tspeed: 0.1406s/iter; left time: 2015.7843s\n",
      "\titers: 200, epoch: 5 | loss: 0.0810685\n",
      "\tspeed: 0.0508s/iter; left time: 723.4109s\n",
      "\titers: 300, epoch: 5 | loss: 0.0855442\n",
      "\tspeed: 0.0509s/iter; left time: 718.7145s\n",
      "\titers: 400, epoch: 5 | loss: 0.0874002\n",
      "\tspeed: 0.0508s/iter; left time: 713.4811s\n",
      "\titers: 500, epoch: 5 | loss: 0.0819072\n",
      "\tspeed: 0.0508s/iter; left time: 708.2703s\n",
      "\titers: 600, epoch: 5 | loss: 0.0860219\n",
      "\tspeed: 0.0505s/iter; left time: 698.6841s\n",
      "\titers: 700, epoch: 5 | loss: 0.0811444\n",
      "\tspeed: 0.0504s/iter; left time: 692.2963s\n",
      "\titers: 800, epoch: 5 | loss: 0.0809208\n",
      "\tspeed: 0.0504s/iter; left time: 687.4578s\n",
      "\titers: 900, epoch: 5 | loss: 0.0855082\n",
      "\tspeed: 0.0504s/iter; left time: 682.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 902 | Train Loss: 0.0836334 Vali Loss: 0.0855765 Test Loss: 0.0958990\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0837307\n",
      "\tspeed: 0.1369s/iter; left time: 1838.9239s\n",
      "\titers: 200, epoch: 6 | loss: 0.0879220\n",
      "\tspeed: 0.0504s/iter; left time: 671.5331s\n",
      "\titers: 300, epoch: 6 | loss: 0.0843503\n",
      "\tspeed: 0.0504s/iter; left time: 667.0104s\n",
      "\titers: 400, epoch: 6 | loss: 0.0791846\n",
      "\tspeed: 0.0505s/iter; left time: 662.9974s\n",
      "\titers: 500, epoch: 6 | loss: 0.0788330\n",
      "\tspeed: 0.0504s/iter; left time: 656.3321s\n",
      "\titers: 600, epoch: 6 | loss: 0.0786551\n",
      "\tspeed: 0.0504s/iter; left time: 651.4243s\n",
      "\titers: 700, epoch: 6 | loss: 0.0774791\n",
      "\tspeed: 0.0503s/iter; left time: 645.9442s\n",
      "\titers: 800, epoch: 6 | loss: 0.0832842\n",
      "\tspeed: 0.0504s/iter; left time: 641.4467s\n",
      "\titers: 900, epoch: 6 | loss: 0.0777149\n",
      "\tspeed: 0.0504s/iter; left time: 636.7863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 902 | Train Loss: 0.0799680 Vali Loss: 0.0855314 Test Loss: 0.0941967\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0832227\n",
      "\tspeed: 0.1374s/iter; left time: 1721.4858s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769130\n",
      "\tspeed: 0.0504s/iter; left time: 626.6860s\n",
      "\titers: 300, epoch: 7 | loss: 0.0797686\n",
      "\tspeed: 0.0504s/iter; left time: 621.5318s\n",
      "\titers: 400, epoch: 7 | loss: 0.0803033\n",
      "\tspeed: 0.0504s/iter; left time: 616.8940s\n",
      "\titers: 500, epoch: 7 | loss: 0.0713358\n",
      "\tspeed: 0.0504s/iter; left time: 611.6196s\n",
      "\titers: 600, epoch: 7 | loss: 0.0767121\n",
      "\tspeed: 0.0504s/iter; left time: 606.4779s\n",
      "\titers: 700, epoch: 7 | loss: 0.0724495\n",
      "\tspeed: 0.0504s/iter; left time: 601.4541s\n",
      "\titers: 800, epoch: 7 | loss: 0.0772860\n",
      "\tspeed: 0.0504s/iter; left time: 596.5747s\n",
      "\titers: 900, epoch: 7 | loss: 0.0758775\n",
      "\tspeed: 0.0504s/iter; left time: 591.4901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0763688 Vali Loss: 0.0862588 Test Loss: 0.0960034\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0746740\n",
      "\tspeed: 0.1380s/iter; left time: 1604.7483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710704\n",
      "\tspeed: 0.0504s/iter; left time: 581.3052s\n",
      "\titers: 300, epoch: 8 | loss: 0.0767001\n",
      "\tspeed: 0.0504s/iter; left time: 576.2394s\n",
      "\titers: 400, epoch: 8 | loss: 0.0722365\n",
      "\tspeed: 0.0505s/iter; left time: 571.5276s\n",
      "\titers: 500, epoch: 8 | loss: 0.0735169\n",
      "\tspeed: 0.0504s/iter; left time: 566.0925s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702938\n",
      "\tspeed: 0.0504s/iter; left time: 561.0255s\n",
      "\titers: 700, epoch: 8 | loss: 0.0752317\n",
      "\tspeed: 0.0504s/iter; left time: 556.1749s\n",
      "\titers: 800, epoch: 8 | loss: 0.0745411\n",
      "\tspeed: 0.0504s/iter; left time: 551.2586s\n",
      "\titers: 900, epoch: 8 | loss: 0.0704616\n",
      "\tspeed: 0.0505s/iter; left time: 546.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.0728395 Vali Loss: 0.0874766 Test Loss: 0.0982277\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0669056\n",
      "\tspeed: 0.1385s/iter; left time: 1485.4205s\n",
      "\titers: 200, epoch: 9 | loss: 0.0704915\n",
      "\tspeed: 0.0505s/iter; left time: 536.4953s\n",
      "\titers: 300, epoch: 9 | loss: 0.0730468\n",
      "\tspeed: 0.0505s/iter; left time: 531.1503s\n",
      "\titers: 400, epoch: 9 | loss: 0.0681769\n",
      "\tspeed: 0.0504s/iter; left time: 525.8961s\n",
      "\titers: 500, epoch: 9 | loss: 0.0706938\n",
      "\tspeed: 0.0504s/iter; left time: 520.7010s\n",
      "\titers: 600, epoch: 9 | loss: 0.0717596\n",
      "\tspeed: 0.0504s/iter; left time: 515.5981s\n",
      "\titers: 700, epoch: 9 | loss: 0.0657810\n",
      "\tspeed: 0.0504s/iter; left time: 510.4238s\n",
      "\titers: 800, epoch: 9 | loss: 0.0699422\n",
      "\tspeed: 0.0504s/iter; left time: 505.3338s\n",
      "\titers: 900, epoch: 9 | loss: 0.0668692\n",
      "\tspeed: 0.0504s/iter; left time: 500.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0693792 Vali Loss: 0.0873247 Test Loss: 0.0969773\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020803824067115784, rmse:0.14423531293869019, mae:0.09436223655939102, rse:0.5457460880279541\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2284859\n",
      "\tspeed: 0.0530s/iter; left time: 950.1871s\n",
      "\titers: 200, epoch: 1 | loss: 0.2267227\n",
      "\tspeed: 0.0508s/iter; left time: 906.6906s\n",
      "\titers: 300, epoch: 1 | loss: 0.2108397\n",
      "\tspeed: 0.0504s/iter; left time: 893.5250s\n",
      "\titers: 400, epoch: 1 | loss: 0.2069933\n",
      "\tspeed: 0.0504s/iter; left time: 889.6918s\n",
      "\titers: 500, epoch: 1 | loss: 0.2013356\n",
      "\tspeed: 0.0504s/iter; left time: 884.5309s\n",
      "\titers: 600, epoch: 1 | loss: 0.1998173\n",
      "\tspeed: 0.0504s/iter; left time: 879.8400s\n",
      "\titers: 700, epoch: 1 | loss: 0.1979535\n",
      "\tspeed: 0.0507s/iter; left time: 879.3869s\n",
      "\titers: 800, epoch: 1 | loss: 0.1894962\n",
      "\tspeed: 0.0504s/iter; left time: 869.3943s\n",
      "\titers: 900, epoch: 1 | loss: 0.1864503\n",
      "\tspeed: 0.0504s/iter; left time: 864.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.86s\n",
      "Steps: 902 | Train Loss: 0.2082656 Vali Loss: 0.1732536 Test Loss: 0.1907203\n",
      "Validation loss decreased (inf --> 0.173254).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1713080\n",
      "\tspeed: 0.1403s/iter; left time: 2391.2121s\n",
      "\titers: 200, epoch: 2 | loss: 0.1709103\n",
      "\tspeed: 0.0504s/iter; left time: 853.8744s\n",
      "\titers: 300, epoch: 2 | loss: 0.1648743\n",
      "\tspeed: 0.0504s/iter; left time: 849.1595s\n",
      "\titers: 400, epoch: 2 | loss: 0.1496821\n",
      "\tspeed: 0.0506s/iter; left time: 846.7754s\n",
      "\titers: 500, epoch: 2 | loss: 0.1361954\n",
      "\tspeed: 0.0506s/iter; left time: 841.4153s\n",
      "\titers: 600, epoch: 2 | loss: 0.1361084\n",
      "\tspeed: 0.0505s/iter; left time: 835.2886s\n",
      "\titers: 700, epoch: 2 | loss: 0.1295184\n",
      "\tspeed: 0.0504s/iter; left time: 829.2730s\n",
      "\titers: 800, epoch: 2 | loss: 0.1168782\n",
      "\tspeed: 0.0504s/iter; left time: 824.1832s\n",
      "\titers: 900, epoch: 2 | loss: 0.1084049\n",
      "\tspeed: 0.0504s/iter; left time: 819.1696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 902 | Train Loss: 0.1460171 Vali Loss: 0.0987828 Test Loss: 0.1063009\n",
      "Validation loss decreased (0.173254 --> 0.098783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1028040\n",
      "\tspeed: 0.1409s/iter; left time: 2274.2749s\n",
      "\titers: 200, epoch: 3 | loss: 0.1012544\n",
      "\tspeed: 0.0504s/iter; left time: 808.7178s\n",
      "\titers: 300, epoch: 3 | loss: 0.0942322\n",
      "\tspeed: 0.0505s/iter; left time: 804.2001s\n",
      "\titers: 400, epoch: 3 | loss: 0.0913546\n",
      "\tspeed: 0.0505s/iter; left time: 799.2814s\n",
      "\titers: 500, epoch: 3 | loss: 0.0966000\n",
      "\tspeed: 0.0506s/iter; left time: 796.0874s\n",
      "\titers: 600, epoch: 3 | loss: 0.0914325\n",
      "\tspeed: 0.0505s/iter; left time: 789.9978s\n",
      "\titers: 700, epoch: 3 | loss: 0.0900648\n",
      "\tspeed: 0.0504s/iter; left time: 783.6762s\n",
      "\titers: 800, epoch: 3 | loss: 0.0941671\n",
      "\tspeed: 0.0504s/iter; left time: 778.7342s\n",
      "\titers: 900, epoch: 3 | loss: 0.0972075\n",
      "\tspeed: 0.0504s/iter; left time: 773.5955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0964605 Vali Loss: 0.0890032 Test Loss: 0.0937895\n",
      "Validation loss decreased (0.098783 --> 0.089003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857249\n",
      "\tspeed: 0.1414s/iter; left time: 2154.7841s\n",
      "\titers: 200, epoch: 4 | loss: 0.0923728\n",
      "\tspeed: 0.0510s/iter; left time: 772.5200s\n",
      "\titers: 300, epoch: 4 | loss: 0.0903793\n",
      "\tspeed: 0.0511s/iter; left time: 768.5896s\n",
      "\titers: 400, epoch: 4 | loss: 0.0886440\n",
      "\tspeed: 0.0510s/iter; left time: 761.8474s\n",
      "\titers: 500, epoch: 4 | loss: 0.0932834\n",
      "\tspeed: 0.0510s/iter; left time: 757.3216s\n",
      "\titers: 600, epoch: 4 | loss: 0.0853107\n",
      "\tspeed: 0.0510s/iter; left time: 751.9702s\n",
      "\titers: 700, epoch: 4 | loss: 0.0900107\n",
      "\tspeed: 0.0510s/iter; left time: 746.5617s\n",
      "\titers: 800, epoch: 4 | loss: 0.0842938\n",
      "\tspeed: 0.0512s/iter; left time: 743.4796s\n",
      "\titers: 900, epoch: 4 | loss: 0.0850098\n",
      "\tspeed: 0.0510s/iter; left time: 736.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.39s\n",
      "Steps: 902 | Train Loss: 0.0881512 Vali Loss: 0.0848641 Test Loss: 0.0966458\n",
      "Validation loss decreased (0.089003 --> 0.084864).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882770\n",
      "\tspeed: 0.1422s/iter; left time: 2038.8512s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824666\n",
      "\tspeed: 0.0504s/iter; left time: 717.6569s\n",
      "\titers: 300, epoch: 5 | loss: 0.0812579\n",
      "\tspeed: 0.0504s/iter; left time: 712.7247s\n",
      "\titers: 400, epoch: 5 | loss: 0.0867619\n",
      "\tspeed: 0.0504s/iter; left time: 707.9227s\n",
      "\titers: 500, epoch: 5 | loss: 0.0906413\n",
      "\tspeed: 0.0504s/iter; left time: 702.4616s\n",
      "\titers: 600, epoch: 5 | loss: 0.0816955\n",
      "\tspeed: 0.0504s/iter; left time: 697.5462s\n",
      "\titers: 700, epoch: 5 | loss: 0.0825760\n",
      "\tspeed: 0.0504s/iter; left time: 692.3392s\n",
      "\titers: 800, epoch: 5 | loss: 0.0871430\n",
      "\tspeed: 0.0505s/iter; left time: 688.0002s\n",
      "\titers: 900, epoch: 5 | loss: 0.0818188\n",
      "\tspeed: 0.0505s/iter; left time: 682.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.78s\n",
      "Steps: 902 | Train Loss: 0.0832878 Vali Loss: 0.0822736 Test Loss: 0.0991102\n",
      "Validation loss decreased (0.084864 --> 0.082274).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807753\n",
      "\tspeed: 0.1417s/iter; left time: 1903.7318s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926194\n",
      "\tspeed: 0.0504s/iter; left time: 672.3669s\n",
      "\titers: 300, epoch: 6 | loss: 0.0734528\n",
      "\tspeed: 0.0504s/iter; left time: 667.3297s\n",
      "\titers: 400, epoch: 6 | loss: 0.0836199\n",
      "\tspeed: 0.0504s/iter; left time: 662.0244s\n",
      "\titers: 500, epoch: 6 | loss: 0.0807985\n",
      "\tspeed: 0.0504s/iter; left time: 657.1533s\n",
      "\titers: 600, epoch: 6 | loss: 0.0781274\n",
      "\tspeed: 0.0504s/iter; left time: 651.9781s\n",
      "\titers: 700, epoch: 6 | loss: 0.0795121\n",
      "\tspeed: 0.0504s/iter; left time: 647.0378s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790593\n",
      "\tspeed: 0.0505s/iter; left time: 642.5466s\n",
      "\titers: 900, epoch: 6 | loss: 0.0770177\n",
      "\tspeed: 0.0504s/iter; left time: 637.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.79s\n",
      "Steps: 902 | Train Loss: 0.0793978 Vali Loss: 0.0833777 Test Loss: 0.0989826\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754626\n",
      "\tspeed: 0.1373s/iter; left time: 1720.0845s\n",
      "\titers: 200, epoch: 7 | loss: 0.0837843\n",
      "\tspeed: 0.0504s/iter; left time: 626.6227s\n",
      "\titers: 300, epoch: 7 | loss: 0.0735349\n",
      "\tspeed: 0.0505s/iter; left time: 622.1110s\n",
      "\titers: 400, epoch: 7 | loss: 0.0791819\n",
      "\tspeed: 0.0505s/iter; left time: 617.3518s\n",
      "\titers: 500, epoch: 7 | loss: 0.0693690\n",
      "\tspeed: 0.0504s/iter; left time: 611.2815s\n",
      "\titers: 600, epoch: 7 | loss: 0.0743524\n",
      "\tspeed: 0.0504s/iter; left time: 606.8297s\n",
      "\titers: 700, epoch: 7 | loss: 0.0732933\n",
      "\tspeed: 0.0505s/iter; left time: 602.0026s\n",
      "\titers: 800, epoch: 7 | loss: 0.0761782\n",
      "\tspeed: 0.0504s/iter; left time: 596.3598s\n",
      "\titers: 900, epoch: 7 | loss: 0.0737806\n",
      "\tspeed: 0.0505s/iter; left time: 591.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.77s\n",
      "Steps: 902 | Train Loss: 0.0760379 Vali Loss: 0.0858319 Test Loss: 0.0968157\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726987\n",
      "\tspeed: 0.1384s/iter; left time: 1609.0217s\n",
      "\titers: 200, epoch: 8 | loss: 0.0783981\n",
      "\tspeed: 0.0504s/iter; left time: 581.5175s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806944\n",
      "\tspeed: 0.0505s/iter; left time: 576.9424s\n",
      "\titers: 400, epoch: 8 | loss: 0.0715075\n",
      "\tspeed: 0.0505s/iter; left time: 572.5696s\n",
      "\titers: 500, epoch: 8 | loss: 0.0750728\n",
      "\tspeed: 0.0504s/iter; left time: 566.3231s\n",
      "\titers: 600, epoch: 8 | loss: 0.0702019\n",
      "\tspeed: 0.0505s/iter; left time: 561.4528s\n",
      "\titers: 700, epoch: 8 | loss: 0.0728789\n",
      "\tspeed: 0.0504s/iter; left time: 556.0862s\n",
      "\titers: 800, epoch: 8 | loss: 0.0746686\n",
      "\tspeed: 0.0504s/iter; left time: 551.0988s\n",
      "\titers: 900, epoch: 8 | loss: 0.0702752\n",
      "\tspeed: 0.0504s/iter; left time: 545.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0726852 Vali Loss: 0.0867959 Test Loss: 0.0998598\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0709978\n",
      "\tspeed: 0.1381s/iter; left time: 1481.3268s\n",
      "\titers: 200, epoch: 9 | loss: 0.0679601\n",
      "\tspeed: 0.0510s/iter; left time: 541.8042s\n",
      "\titers: 300, epoch: 9 | loss: 0.0751877\n",
      "\tspeed: 0.0511s/iter; left time: 537.3441s\n",
      "\titers: 400, epoch: 9 | loss: 0.0699946\n",
      "\tspeed: 0.0510s/iter; left time: 531.8428s\n",
      "\titers: 500, epoch: 9 | loss: 0.0732694\n",
      "\tspeed: 0.0511s/iter; left time: 527.1437s\n",
      "\titers: 600, epoch: 9 | loss: 0.0649203\n",
      "\tspeed: 0.0510s/iter; left time: 521.5651s\n",
      "\titers: 700, epoch: 9 | loss: 0.0642313\n",
      "\tspeed: 0.0510s/iter; left time: 516.1117s\n",
      "\titers: 800, epoch: 9 | loss: 0.0708400\n",
      "\tspeed: 0.0510s/iter; left time: 511.2901s\n",
      "\titers: 900, epoch: 9 | loss: 0.0663069\n",
      "\tspeed: 0.0506s/iter; left time: 501.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:46.25s\n",
      "Steps: 902 | Train Loss: 0.0691620 Vali Loss: 0.0897910 Test Loss: 0.1007773\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0708059\n",
      "\tspeed: 0.1368s/iter; left time: 1344.0071s\n",
      "\titers: 200, epoch: 10 | loss: 0.0699524\n",
      "\tspeed: 0.0504s/iter; left time: 490.3308s\n",
      "\titers: 300, epoch: 10 | loss: 0.0707789\n",
      "\tspeed: 0.0504s/iter; left time: 485.3786s\n",
      "\titers: 400, epoch: 10 | loss: 0.0686859\n",
      "\tspeed: 0.0504s/iter; left time: 480.1413s\n",
      "\titers: 500, epoch: 10 | loss: 0.0652517\n",
      "\tspeed: 0.0504s/iter; left time: 474.8593s\n",
      "\titers: 600, epoch: 10 | loss: 0.0646466\n",
      "\tspeed: 0.0504s/iter; left time: 470.0499s\n",
      "\titers: 700, epoch: 10 | loss: 0.0682247\n",
      "\tspeed: 0.0504s/iter; left time: 465.0166s\n",
      "\titers: 800, epoch: 10 | loss: 0.0651449\n",
      "\tspeed: 0.0506s/iter; left time: 461.9457s\n",
      "\titers: 900, epoch: 10 | loss: 0.0604966\n",
      "\tspeed: 0.0505s/iter; left time: 455.3794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.75s\n",
      "Steps: 902 | Train Loss: 0.0659150 Vali Loss: 0.0909240 Test Loss: 0.1030022\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_IT_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023398978635668755, rmse:0.15296724438667297, mae:0.09908542037010193, rse:0.578785240650177\n",
      "Intermediate time for IT and pred_len 168: 00h:17m:32.00s\n",
      "Intermediate time for IT: 00h:58m:20.06s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[26], line 98\u001b[0m\n",
      "\u001b[1;32m     96\u001b[0m hours, mins, secs \u001b[38;5;241m=\u001b[39m running_time(start, end)\n",
      "\u001b[1;32m     97\u001b[0m statement_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time: \u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mh:\u001b[39m\u001b[38;5;132;01m{:0>2}\u001b[39;00m\u001b[38;5;124mm:\u001b[39m\u001b[38;5;132;01m{:05.2f}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hours, mins, secs)\n",
      "\u001b[0;32m---> 98\u001b[0m \u001b[43mlog_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement_5\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(statement_5)\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --d_layers {d_layers} \\\n",
    "              --factor 5 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --dec_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                informer_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Informer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2074</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2311</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1523</td>\n",
       "      <td>0.0922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.2281</td>\n",
       "      <td>0.1467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.0897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>0.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>0.1703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>0.0657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.0967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Informer                \n",
       "Metrics               MSE    RMSE     MAE\n",
       "Country Pred_len                         \n",
       "DE      24         0.0263  0.1622  0.1042\n",
       "        96         0.0430  0.2074  0.1434\n",
       "        168        0.0534  0.2311  0.1585\n",
       "ES      24         0.0234  0.1523  0.0922\n",
       "        96         0.0526  0.2293  0.1431\n",
       "        168        0.0523  0.2281  0.1467\n",
       "FR      24         0.0125  0.1117  0.0636\n",
       "        96         0.0225  0.1499  0.0897\n",
       "        168        0.0243  0.1559  0.0971\n",
       "GB      24         0.0325  0.1802  0.1202\n",
       "        96         0.0506  0.2249  0.1575\n",
       "        168        0.0603  0.2454  0.1703\n",
       "IT      24         0.0126  0.1120  0.0657\n",
       "        96         0.0208  0.1441  0.0887\n",
       "        168        0.0221  0.1486  0.0967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/informer'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "informer_df = convert_results_into_df(informer_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "informer_df.columns = pd.MultiIndex.from_product([['Informer'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "informer_df.to_csv(os.path.join(path, 'informer.csv'))\n",
    "informer_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PatchTST 336\n",
    "\n",
    "We separated PatchTST from Informer, because it has additional arguments. It is not so easy to modify f-string (as e. g. distionary) to unpack some arguments with if statement. Moreover, it has different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1552846\n",
      "\tspeed: 0.0386s/iter; left time: 861.6427s\n",
      "\titers: 200, epoch: 1 | loss: 0.1349387\n",
      "\tspeed: 0.0174s/iter; left time: 386.0485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1540624 Vali Loss: 0.1402043 Test Loss: 0.1497415\n",
      "Validation loss decreased (inf --> 0.140204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0870196\n",
      "\tspeed: 0.0367s/iter; left time: 810.3247s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852675\n",
      "\tspeed: 0.0172s/iter; left time: 377.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0921912 Vali Loss: 0.0948991 Test Loss: 0.0956263\n",
      "Validation loss decreased (0.140204 --> 0.094899).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0780745\n",
      "\tspeed: 0.0373s/iter; left time: 815.1621s\n",
      "\titers: 200, epoch: 3 | loss: 0.0829521\n",
      "\tspeed: 0.0172s/iter; left time: 374.4951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0813875 Vali Loss: 0.0914835 Test Loss: 0.0926128\n",
      "Validation loss decreased (0.094899 --> 0.091483).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0763411\n",
      "\tspeed: 0.0375s/iter; left time: 812.0682s\n",
      "\titers: 200, epoch: 4 | loss: 0.0788606\n",
      "\tspeed: 0.0174s/iter; left time: 374.7984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0785792 Vali Loss: 0.0897479 Test Loss: 0.0915311\n",
      "Validation loss decreased (0.091483 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786201\n",
      "\tspeed: 0.0363s/iter; left time: 777.6392s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775603\n",
      "\tspeed: 0.0172s/iter; left time: 366.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0770201 Vali Loss: 0.0888097 Test Loss: 0.0907630\n",
      "Validation loss decreased (0.089748 --> 0.088810).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0797430\n",
      "\tspeed: 0.0361s/iter; left time: 764.9986s\n",
      "\titers: 200, epoch: 6 | loss: 0.0739905\n",
      "\tspeed: 0.0172s/iter; left time: 362.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0759351 Vali Loss: 0.0882563 Test Loss: 0.0899552\n",
      "Validation loss decreased (0.088810 --> 0.088256).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0744912\n",
      "\tspeed: 0.0361s/iter; left time: 757.1966s\n",
      "\titers: 200, epoch: 7 | loss: 0.0771100\n",
      "\tspeed: 0.0172s/iter; left time: 359.1646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0752218 Vali Loss: 0.0878177 Test Loss: 0.0892529\n",
      "Validation loss decreased (0.088256 --> 0.087818).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781358\n",
      "\tspeed: 0.0361s/iter; left time: 749.3890s\n",
      "\titers: 200, epoch: 8 | loss: 0.0730628\n",
      "\tspeed: 0.0173s/iter; left time: 357.7871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0746178 Vali Loss: 0.0877714 Test Loss: 0.0892701\n",
      "Validation loss decreased (0.087818 --> 0.087771).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0749489\n",
      "\tspeed: 0.0362s/iter; left time: 743.1516s\n",
      "\titers: 200, epoch: 9 | loss: 0.0725721\n",
      "\tspeed: 0.0172s/iter; left time: 351.6598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0740126 Vali Loss: 0.0871786 Test Loss: 0.0891943\n",
      "Validation loss decreased (0.087771 --> 0.087179).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0726015\n",
      "\tspeed: 0.0366s/iter; left time: 743.1618s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741761\n",
      "\tspeed: 0.0172s/iter; left time: 347.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0736832 Vali Loss: 0.0868305 Test Loss: 0.0889153\n",
      "Validation loss decreased (0.087179 --> 0.086830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0685348\n",
      "\tspeed: 0.0367s/iter; left time: 735.7039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0705283\n",
      "\tspeed: 0.0172s/iter; left time: 344.1391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0734142 Vali Loss: 0.0868541 Test Loss: 0.0888376\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0706811\n",
      "\tspeed: 0.0363s/iter; left time: 720.0150s\n",
      "\titers: 200, epoch: 12 | loss: 0.0724820\n",
      "\tspeed: 0.0173s/iter; left time: 340.6964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0730704 Vali Loss: 0.0866896 Test Loss: 0.0885880\n",
      "Validation loss decreased (0.086830 --> 0.086690).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0729633\n",
      "\tspeed: 0.0370s/iter; left time: 725.3168s\n",
      "\titers: 200, epoch: 13 | loss: 0.0778621\n",
      "\tspeed: 0.0172s/iter; left time: 335.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0727560 Vali Loss: 0.0865001 Test Loss: 0.0886636\n",
      "Validation loss decreased (0.086690 --> 0.086500).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709714\n",
      "\tspeed: 0.0362s/iter; left time: 701.5415s\n",
      "\titers: 200, epoch: 14 | loss: 0.0751399\n",
      "\tspeed: 0.0172s/iter; left time: 332.2395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0725595 Vali Loss: 0.0860851 Test Loss: 0.0884585\n",
      "Validation loss decreased (0.086500 --> 0.086085).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0737076\n",
      "\tspeed: 0.0377s/iter; left time: 723.0361s\n",
      "\titers: 200, epoch: 15 | loss: 0.0740580\n",
      "\tspeed: 0.0176s/iter; left time: 334.9621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0723475 Vali Loss: 0.0862519 Test Loss: 0.0885224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741089\n",
      "\tspeed: 0.0365s/iter; left time: 692.2804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0679487\n",
      "\tspeed: 0.0171s/iter; left time: 322.6943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0722050 Vali Loss: 0.0863559 Test Loss: 0.0885100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0714612\n",
      "\tspeed: 0.0365s/iter; left time: 683.0564s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703044\n",
      "\tspeed: 0.0171s/iter; left time: 319.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 224 | Train Loss: 0.0720605 Vali Loss: 0.0860859 Test Loss: 0.0882050\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0692411\n",
      "\tspeed: 0.0360s/iter; left time: 666.4414s\n",
      "\titers: 200, epoch: 18 | loss: 0.0696555\n",
      "\tspeed: 0.0173s/iter; left time: 317.7652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0719251 Vali Loss: 0.0860834 Test Loss: 0.0883264\n",
      "Validation loss decreased (0.086085 --> 0.086083).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0666350\n",
      "\tspeed: 0.0369s/iter; left time: 673.8571s\n",
      "\titers: 200, epoch: 19 | loss: 0.0690289\n",
      "\tspeed: 0.0172s/iter; left time: 312.4787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0718146 Vali Loss: 0.0862328 Test Loss: 0.0883009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727314\n",
      "\tspeed: 0.0364s/iter; left time: 656.1519s\n",
      "\titers: 200, epoch: 20 | loss: 0.0679560\n",
      "\tspeed: 0.0172s/iter; left time: 307.8711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0717518 Vali Loss: 0.0859731 Test Loss: 0.0882746\n",
      "Validation loss decreased (0.086083 --> 0.085973).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0678350\n",
      "\tspeed: 0.0376s/iter; left time: 670.3565s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704678\n",
      "\tspeed: 0.0172s/iter; left time: 304.1626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0716916 Vali Loss: 0.0861745 Test Loss: 0.0883600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0665134\n",
      "\tspeed: 0.0376s/iter; left time: 662.1639s\n",
      "\titers: 200, epoch: 22 | loss: 0.0713014\n",
      "\tspeed: 0.0175s/iter; left time: 305.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0715454 Vali Loss: 0.0859216 Test Loss: 0.0880715\n",
      "Validation loss decreased (0.085973 --> 0.085922).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0776097\n",
      "\tspeed: 0.0378s/iter; left time: 657.4605s\n",
      "\titers: 200, epoch: 23 | loss: 0.0763447\n",
      "\tspeed: 0.0175s/iter; left time: 301.9333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0714682 Vali Loss: 0.0859278 Test Loss: 0.0881196\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0704927\n",
      "\tspeed: 0.0372s/iter; left time: 637.1536s\n",
      "\titers: 200, epoch: 24 | loss: 0.0695393\n",
      "\tspeed: 0.0175s/iter; left time: 297.7642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0713978 Vali Loss: 0.0858666 Test Loss: 0.0880751\n",
      "Validation loss decreased (0.085922 --> 0.085867).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0731220\n",
      "\tspeed: 0.0382s/iter; left time: 646.4578s\n",
      "\titers: 200, epoch: 25 | loss: 0.0717855\n",
      "\tspeed: 0.0175s/iter; left time: 294.3752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0713309 Vali Loss: 0.0858693 Test Loss: 0.0880437\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0735057\n",
      "\tspeed: 0.0381s/iter; left time: 636.9624s\n",
      "\titers: 200, epoch: 26 | loss: 0.0790921\n",
      "\tspeed: 0.0175s/iter; left time: 290.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0712935 Vali Loss: 0.0858808 Test Loss: 0.0880306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0726050\n",
      "\tspeed: 0.0374s/iter; left time: 617.0444s\n",
      "\titers: 200, epoch: 27 | loss: 0.0766401\n",
      "\tspeed: 0.0175s/iter; left time: 286.9332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0712784 Vali Loss: 0.0857484 Test Loss: 0.0880223\n",
      "Validation loss decreased (0.085867 --> 0.085748).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0689519\n",
      "\tspeed: 0.0378s/iter; left time: 613.5825s\n",
      "\titers: 200, epoch: 28 | loss: 0.0694582\n",
      "\tspeed: 0.0175s/iter; left time: 282.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0711782 Vali Loss: 0.0857762 Test Loss: 0.0880048\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0721677\n",
      "\tspeed: 0.0375s/iter; left time: 601.0099s\n",
      "\titers: 200, epoch: 29 | loss: 0.0722472\n",
      "\tspeed: 0.0176s/iter; left time: 279.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0712058 Vali Loss: 0.0857808 Test Loss: 0.0880437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0728532\n",
      "\tspeed: 0.0375s/iter; left time: 593.0144s\n",
      "\titers: 200, epoch: 30 | loss: 0.0690279\n",
      "\tspeed: 0.0175s/iter; left time: 274.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0711695 Vali Loss: 0.0857775 Test Loss: 0.0880615\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0712753\n",
      "\tspeed: 0.0372s/iter; left time: 580.1246s\n",
      "\titers: 200, epoch: 31 | loss: 0.0702444\n",
      "\tspeed: 0.0175s/iter; left time: 270.9416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0710913 Vali Loss: 0.0856238 Test Loss: 0.0879199\n",
      "Validation loss decreased (0.085748 --> 0.085624).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0739763\n",
      "\tspeed: 0.0379s/iter; left time: 582.0779s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705086\n",
      "\tspeed: 0.0175s/iter; left time: 266.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0710666 Vali Loss: 0.0857762 Test Loss: 0.0879514\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0721442\n",
      "\tspeed: 0.0371s/iter; left time: 562.1502s\n",
      "\titers: 200, epoch: 33 | loss: 0.0714343\n",
      "\tspeed: 0.0173s/iter; left time: 260.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0710919 Vali Loss: 0.0856497 Test Loss: 0.0879790\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0714671\n",
      "\tspeed: 0.0374s/iter; left time: 557.8535s\n",
      "\titers: 200, epoch: 34 | loss: 0.0668482\n",
      "\tspeed: 0.0175s/iter; left time: 259.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0710325 Vali Loss: 0.0856610 Test Loss: 0.0879750\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0680839\n",
      "\tspeed: 0.0375s/iter; left time: 550.3824s\n",
      "\titers: 200, epoch: 35 | loss: 0.0771664\n",
      "\tspeed: 0.0176s/iter; left time: 256.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0710762 Vali Loss: 0.0856469 Test Loss: 0.0880436\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0663177\n",
      "\tspeed: 0.0379s/iter; left time: 547.4149s\n",
      "\titers: 200, epoch: 36 | loss: 0.0724510\n",
      "\tspeed: 0.0175s/iter; left time: 251.3001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0709524 Vali Loss: 0.0856974 Test Loss: 0.0879670\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0726528\n",
      "\tspeed: 0.0375s/iter; left time: 534.3101s\n",
      "\titers: 200, epoch: 37 | loss: 0.0703345\n",
      "\tspeed: 0.0176s/iter; left time: 248.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0710302 Vali Loss: 0.0855373 Test Loss: 0.0879779\n",
      "Validation loss decreased (0.085624 --> 0.085537).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0688919\n",
      "\tspeed: 0.0372s/iter; left time: 520.8924s\n",
      "\titers: 200, epoch: 38 | loss: 0.0671603\n",
      "\tspeed: 0.0175s/iter; left time: 243.1850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0710106 Vali Loss: 0.0856418 Test Loss: 0.0879765\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0690466\n",
      "\tspeed: 0.0375s/iter; left time: 516.5527s\n",
      "\titers: 200, epoch: 39 | loss: 0.0687962\n",
      "\tspeed: 0.0174s/iter; left time: 238.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0709240 Vali Loss: 0.0856256 Test Loss: 0.0879940\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0725030\n",
      "\tspeed: 0.0377s/iter; left time: 511.6712s\n",
      "\titers: 200, epoch: 40 | loss: 0.0654697\n",
      "\tspeed: 0.0176s/iter; left time: 236.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0709026 Vali Loss: 0.0857639 Test Loss: 0.0879715\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0701949\n",
      "\tspeed: 0.0375s/iter; left time: 500.3095s\n",
      "\titers: 200, epoch: 41 | loss: 0.0745832\n",
      "\tspeed: 0.0172s/iter; left time: 227.9037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0709682 Vali Loss: 0.0855893 Test Loss: 0.0879618\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0736992\n",
      "\tspeed: 0.0366s/iter; left time: 479.4726s\n",
      "\titers: 200, epoch: 42 | loss: 0.0768942\n",
      "\tspeed: 0.0172s/iter; left time: 223.9038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0709252 Vali Loss: 0.0856495 Test Loss: 0.0879604\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0685949\n",
      "\tspeed: 0.0367s/iter; left time: 472.9860s\n",
      "\titers: 200, epoch: 43 | loss: 0.0760462\n",
      "\tspeed: 0.0172s/iter; left time: 219.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0709714 Vali Loss: 0.0856753 Test Loss: 0.0879659\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0715806\n",
      "\tspeed: 0.0373s/iter; left time: 472.7205s\n",
      "\titers: 200, epoch: 44 | loss: 0.0702154\n",
      "\tspeed: 0.0172s/iter; left time: 216.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0709581 Vali Loss: 0.0856275 Test Loss: 0.0879641\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0768256\n",
      "\tspeed: 0.0376s/iter; left time: 467.8745s\n",
      "\titers: 200, epoch: 45 | loss: 0.0725973\n",
      "\tspeed: 0.0174s/iter; left time: 214.9464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0708796 Vali Loss: 0.0856954 Test Loss: 0.0879712\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0733044\n",
      "\tspeed: 0.0384s/iter; left time: 469.3111s\n",
      "\titers: 200, epoch: 46 | loss: 0.0735912\n",
      "\tspeed: 0.0175s/iter; left time: 211.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0709229 Vali Loss: 0.0855423 Test Loss: 0.0879411\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753453\n",
      "\tspeed: 0.0380s/iter; left time: 456.4103s\n",
      "\titers: 200, epoch: 47 | loss: 0.0677157\n",
      "\tspeed: 0.0175s/iter; left time: 207.6632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0708528 Vali Loss: 0.0855900 Test Loss: 0.0879525\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021038785576820374, rmse:0.14504753053188324, mae:0.08797794580459595, rse:0.5118927955627441\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1618907\n",
      "\tspeed: 0.0198s/iter; left time: 440.6314s\n",
      "\titers: 200, epoch: 1 | loss: 0.1356750\n",
      "\tspeed: 0.0175s/iter; left time: 387.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1518951 Vali Loss: 0.1383925 Test Loss: 0.1470300\n",
      "Validation loss decreased (inf --> 0.138392).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0922690\n",
      "\tspeed: 0.0383s/iter; left time: 846.1081s\n",
      "\titers: 200, epoch: 2 | loss: 0.0839261\n",
      "\tspeed: 0.0174s/iter; left time: 382.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0916023 Vali Loss: 0.0949052 Test Loss: 0.0956600\n",
      "Validation loss decreased (0.138392 --> 0.094905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0771559\n",
      "\tspeed: 0.0375s/iter; left time: 819.5183s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782623\n",
      "\tspeed: 0.0175s/iter; left time: 380.2679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0813828 Vali Loss: 0.0917901 Test Loss: 0.0929726\n",
      "Validation loss decreased (0.094905 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0835997\n",
      "\tspeed: 0.0412s/iter; left time: 892.1003s\n",
      "\titers: 200, epoch: 4 | loss: 0.0820832\n",
      "\tspeed: 0.0176s/iter; left time: 378.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0786816 Vali Loss: 0.0895929 Test Loss: 0.0916904\n",
      "Validation loss decreased (0.091790 --> 0.089593).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0771580\n",
      "\tspeed: 0.0383s/iter; left time: 819.2429s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791769\n",
      "\tspeed: 0.0176s/iter; left time: 374.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0770481 Vali Loss: 0.0892979 Test Loss: 0.0910974\n",
      "Validation loss decreased (0.089593 --> 0.089298).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0763034\n",
      "\tspeed: 0.0383s/iter; left time: 811.8433s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729890\n",
      "\tspeed: 0.0176s/iter; left time: 371.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0760860 Vali Loss: 0.0883108 Test Loss: 0.0903440\n",
      "Validation loss decreased (0.089298 --> 0.088311).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0710650\n",
      "\tspeed: 0.0379s/iter; left time: 793.2889s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729649\n",
      "\tspeed: 0.0177s/iter; left time: 369.0317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0752415 Vali Loss: 0.0880376 Test Loss: 0.0898637\n",
      "Validation loss decreased (0.088311 --> 0.088038).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756950\n",
      "\tspeed: 0.0381s/iter; left time: 789.4882s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749687\n",
      "\tspeed: 0.0176s/iter; left time: 363.8126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0746587 Vali Loss: 0.0876495 Test Loss: 0.0892023\n",
      "Validation loss decreased (0.088038 --> 0.087650).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0731060\n",
      "\tspeed: 0.0380s/iter; left time: 779.6359s\n",
      "\titers: 200, epoch: 9 | loss: 0.0737636\n",
      "\tspeed: 0.0177s/iter; left time: 360.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0741169 Vali Loss: 0.0871505 Test Loss: 0.0893474\n",
      "Validation loss decreased (0.087650 --> 0.087151).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0686012\n",
      "\tspeed: 0.0393s/iter; left time: 796.5075s\n",
      "\titers: 200, epoch: 10 | loss: 0.0725156\n",
      "\tspeed: 0.0176s/iter; left time: 355.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0737419 Vali Loss: 0.0870753 Test Loss: 0.0892118\n",
      "Validation loss decreased (0.087151 --> 0.087075).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0740497\n",
      "\tspeed: 0.0384s/iter; left time: 769.4467s\n",
      "\titers: 200, epoch: 11 | loss: 0.0740248\n",
      "\tspeed: 0.0176s/iter; left time: 350.6924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0734699 Vali Loss: 0.0869775 Test Loss: 0.0888800\n",
      "Validation loss decreased (0.087075 --> 0.086978).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0726143\n",
      "\tspeed: 0.0378s/iter; left time: 749.9280s\n",
      "\titers: 200, epoch: 12 | loss: 0.0733080\n",
      "\tspeed: 0.0176s/iter; left time: 348.2411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0731677 Vali Loss: 0.0865889 Test Loss: 0.0886001\n",
      "Validation loss decreased (0.086978 --> 0.086589).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0684362\n",
      "\tspeed: 0.0387s/iter; left time: 758.0467s\n",
      "\titers: 200, epoch: 13 | loss: 0.0761535\n",
      "\tspeed: 0.0177s/iter; left time: 345.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0729098 Vali Loss: 0.0864399 Test Loss: 0.0887024\n",
      "Validation loss decreased (0.086589 --> 0.086440).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0697097\n",
      "\tspeed: 0.0378s/iter; left time: 733.1213s\n",
      "\titers: 200, epoch: 14 | loss: 0.0703276\n",
      "\tspeed: 0.0176s/iter; left time: 339.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0726469 Vali Loss: 0.0863408 Test Loss: 0.0884712\n",
      "Validation loss decreased (0.086440 --> 0.086341).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0687292\n",
      "\tspeed: 0.0379s/iter; left time: 726.5989s\n",
      "\titers: 200, epoch: 15 | loss: 0.0727377\n",
      "\tspeed: 0.0177s/iter; left time: 337.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0724740 Vali Loss: 0.0864177 Test Loss: 0.0886259\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0764132\n",
      "\tspeed: 0.0374s/iter; left time: 707.9527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0711039\n",
      "\tspeed: 0.0172s/iter; left time: 323.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0722996 Vali Loss: 0.0859163 Test Loss: 0.0881575\n",
      "Validation loss decreased (0.086341 --> 0.085916).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0702144\n",
      "\tspeed: 0.0375s/iter; left time: 701.8406s\n",
      "\titers: 200, epoch: 17 | loss: 0.0735202\n",
      "\tspeed: 0.0175s/iter; left time: 326.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0721276 Vali Loss: 0.0859863 Test Loss: 0.0883674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0726468\n",
      "\tspeed: 0.0380s/iter; left time: 703.2248s\n",
      "\titers: 200, epoch: 18 | loss: 0.0714917\n",
      "\tspeed: 0.0175s/iter; left time: 321.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0720372 Vali Loss: 0.0858580 Test Loss: 0.0882091\n",
      "Validation loss decreased (0.085916 --> 0.085858).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0752174\n",
      "\tspeed: 0.0380s/iter; left time: 694.7653s\n",
      "\titers: 200, epoch: 19 | loss: 0.0734035\n",
      "\tspeed: 0.0175s/iter; left time: 318.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0718775 Vali Loss: 0.0860360 Test Loss: 0.0884038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0726007\n",
      "\tspeed: 0.0383s/iter; left time: 690.2722s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717402\n",
      "\tspeed: 0.0175s/iter; left time: 314.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0717959 Vali Loss: 0.0855787 Test Loss: 0.0880988\n",
      "Validation loss decreased (0.085858 --> 0.085579).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0766495\n",
      "\tspeed: 0.0377s/iter; left time: 672.5901s\n",
      "\titers: 200, epoch: 21 | loss: 0.0732664\n",
      "\tspeed: 0.0172s/iter; left time: 303.9865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0717139 Vali Loss: 0.0856575 Test Loss: 0.0881889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0787946\n",
      "\tspeed: 0.0371s/iter; left time: 652.6753s\n",
      "\titers: 200, epoch: 22 | loss: 0.0699147\n",
      "\tspeed: 0.0173s/iter; left time: 302.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0716789 Vali Loss: 0.0857231 Test Loss: 0.0880389\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0736762\n",
      "\tspeed: 0.0371s/iter; left time: 643.8660s\n",
      "\titers: 200, epoch: 23 | loss: 0.0686188\n",
      "\tspeed: 0.0176s/iter; left time: 303.2078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0714955 Vali Loss: 0.0857413 Test Loss: 0.0879468\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0668539\n",
      "\tspeed: 0.0374s/iter; left time: 641.8091s\n",
      "\titers: 200, epoch: 24 | loss: 0.0713219\n",
      "\tspeed: 0.0175s/iter; left time: 298.6575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0714538 Vali Loss: 0.0855703 Test Loss: 0.0879494\n",
      "Validation loss decreased (0.085579 --> 0.085570).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0722134\n",
      "\tspeed: 0.0376s/iter; left time: 635.7732s\n",
      "\titers: 200, epoch: 25 | loss: 0.0711080\n",
      "\tspeed: 0.0175s/iter; left time: 293.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0714819 Vali Loss: 0.0855873 Test Loss: 0.0879707\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0721501\n",
      "\tspeed: 0.0371s/iter; left time: 620.3601s\n",
      "\titers: 200, epoch: 26 | loss: 0.0678660\n",
      "\tspeed: 0.0175s/iter; left time: 290.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0713297 Vali Loss: 0.0856317 Test Loss: 0.0880067\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0653764\n",
      "\tspeed: 0.0372s/iter; left time: 613.2353s\n",
      "\titers: 200, epoch: 27 | loss: 0.0691022\n",
      "\tspeed: 0.0175s/iter; left time: 287.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0713143 Vali Loss: 0.0853627 Test Loss: 0.0880434\n",
      "Validation loss decreased (0.085570 --> 0.085363).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0707972\n",
      "\tspeed: 0.0374s/iter; left time: 607.9239s\n",
      "\titers: 200, epoch: 28 | loss: 0.0710721\n",
      "\tspeed: 0.0175s/iter; left time: 283.1085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0712135 Vali Loss: 0.0855246 Test Loss: 0.0879216\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0688014\n",
      "\tspeed: 0.0366s/iter; left time: 587.1155s\n",
      "\titers: 200, epoch: 29 | loss: 0.0708765\n",
      "\tspeed: 0.0177s/iter; left time: 281.6164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0712429 Vali Loss: 0.0856149 Test Loss: 0.0879831\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0696037\n",
      "\tspeed: 0.0375s/iter; left time: 592.0673s\n",
      "\titers: 200, epoch: 30 | loss: 0.0648152\n",
      "\tspeed: 0.0175s/iter; left time: 274.4826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0712099 Vali Loss: 0.0855503 Test Loss: 0.0880210\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0723737\n",
      "\tspeed: 0.0374s/iter; left time: 583.3538s\n",
      "\titers: 200, epoch: 31 | loss: 0.0680507\n",
      "\tspeed: 0.0175s/iter; left time: 271.1756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0712439 Vali Loss: 0.0854979 Test Loss: 0.0878840\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0709765\n",
      "\tspeed: 0.0377s/iter; left time: 578.8067s\n",
      "\titers: 200, epoch: 32 | loss: 0.0720585\n",
      "\tspeed: 0.0177s/iter; left time: 270.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0710870 Vali Loss: 0.0855163 Test Loss: 0.0878411\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0689521\n",
      "\tspeed: 0.0384s/iter; left time: 581.6034s\n",
      "\titers: 200, epoch: 33 | loss: 0.0726045\n",
      "\tspeed: 0.0177s/iter; left time: 266.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0711043 Vali Loss: 0.0854339 Test Loss: 0.0879172\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0746690\n",
      "\tspeed: 0.0382s/iter; left time: 569.8673s\n",
      "\titers: 200, epoch: 34 | loss: 0.0695244\n",
      "\tspeed: 0.0177s/iter; left time: 261.8876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0710936 Vali Loss: 0.0855676 Test Loss: 0.0878891\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0674897\n",
      "\tspeed: 0.0377s/iter; left time: 553.9573s\n",
      "\titers: 200, epoch: 35 | loss: 0.0678919\n",
      "\tspeed: 0.0177s/iter; left time: 257.5767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0710598 Vali Loss: 0.0853509 Test Loss: 0.0879121\n",
      "Validation loss decreased (0.085363 --> 0.085351).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0729884\n",
      "\tspeed: 0.0373s/iter; left time: 539.9409s\n",
      "\titers: 200, epoch: 36 | loss: 0.0675389\n",
      "\tspeed: 0.0175s/iter; left time: 251.9915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0711338 Vali Loss: 0.0854555 Test Loss: 0.0878715\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0730350\n",
      "\tspeed: 0.0377s/iter; left time: 536.3076s\n",
      "\titers: 200, epoch: 37 | loss: 0.0693841\n",
      "\tspeed: 0.0177s/iter; left time: 250.3066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0711093 Vali Loss: 0.0854478 Test Loss: 0.0878776\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0664466\n",
      "\tspeed: 0.0374s/iter; left time: 524.3687s\n",
      "\titers: 200, epoch: 38 | loss: 0.0693127\n",
      "\tspeed: 0.0176s/iter; left time: 245.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0710369 Vali Loss: 0.0854512 Test Loss: 0.0878834\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0726018\n",
      "\tspeed: 0.0374s/iter; left time: 516.0011s\n",
      "\titers: 200, epoch: 39 | loss: 0.0671694\n",
      "\tspeed: 0.0176s/iter; left time: 241.3114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0710215 Vali Loss: 0.0853200 Test Loss: 0.0879039\n",
      "Validation loss decreased (0.085351 --> 0.085320).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0702993\n",
      "\tspeed: 0.0379s/iter; left time: 514.6323s\n",
      "\titers: 200, epoch: 40 | loss: 0.0727114\n",
      "\tspeed: 0.0178s/iter; left time: 239.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0710287 Vali Loss: 0.0853794 Test Loss: 0.0879181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0722102\n",
      "\tspeed: 0.0378s/iter; left time: 504.6395s\n",
      "\titers: 200, epoch: 41 | loss: 0.0684715\n",
      "\tspeed: 0.0177s/iter; left time: 233.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0709616 Vali Loss: 0.0852869 Test Loss: 0.0878864\n",
      "Validation loss decreased (0.085320 --> 0.085287).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0738794\n",
      "\tspeed: 0.0379s/iter; left time: 497.1909s\n",
      "\titers: 200, epoch: 42 | loss: 0.0678000\n",
      "\tspeed: 0.0177s/iter; left time: 230.0540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0709819 Vali Loss: 0.0853545 Test Loss: 0.0878797\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0708027\n",
      "\tspeed: 0.0377s/iter; left time: 486.1711s\n",
      "\titers: 200, epoch: 43 | loss: 0.0688639\n",
      "\tspeed: 0.0176s/iter; left time: 225.6991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0709747 Vali Loss: 0.0853905 Test Loss: 0.0878676\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0686643\n",
      "\tspeed: 0.0377s/iter; left time: 477.4667s\n",
      "\titers: 200, epoch: 44 | loss: 0.0730933\n",
      "\tspeed: 0.0177s/iter; left time: 222.8450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0709635 Vali Loss: 0.0853305 Test Loss: 0.0878929\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0712212\n",
      "\tspeed: 0.0377s/iter; left time: 469.2875s\n",
      "\titers: 200, epoch: 45 | loss: 0.0735664\n",
      "\tspeed: 0.0177s/iter; left time: 218.2085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0709827 Vali Loss: 0.0853609 Test Loss: 0.0878869\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757927\n",
      "\tspeed: 0.0374s/iter; left time: 456.7939s\n",
      "\titers: 200, epoch: 46 | loss: 0.0715199\n",
      "\tspeed: 0.0177s/iter; left time: 214.0855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0709216 Vali Loss: 0.0853052 Test Loss: 0.0878892\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0664239\n",
      "\tspeed: 0.0376s/iter; left time: 451.4881s\n",
      "\titers: 200, epoch: 47 | loss: 0.0720629\n",
      "\tspeed: 0.0176s/iter; left time: 209.8724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0709506 Vali Loss: 0.0853040 Test Loss: 0.0878811\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0679180\n",
      "\tspeed: 0.0380s/iter; left time: 447.0534s\n",
      "\titers: 200, epoch: 48 | loss: 0.0706777\n",
      "\tspeed: 0.0176s/iter; left time: 205.8416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0709696 Vali Loss: 0.0854424 Test Loss: 0.0878901\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0706393\n",
      "\tspeed: 0.0373s/iter; left time: 431.2659s\n",
      "\titers: 200, epoch: 49 | loss: 0.0673425\n",
      "\tspeed: 0.0176s/iter; left time: 201.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0709573 Vali Loss: 0.0853643 Test Loss: 0.0878793\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0748387\n",
      "\tspeed: 0.0374s/iter; left time: 423.9158s\n",
      "\titers: 200, epoch: 50 | loss: 0.0699826\n",
      "\tspeed: 0.0178s/iter; left time: 199.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0709248 Vali Loss: 0.0853929 Test Loss: 0.0878900\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0713937\n",
      "\tspeed: 0.0375s/iter; left time: 416.3586s\n",
      "\titers: 200, epoch: 51 | loss: 0.0679263\n",
      "\tspeed: 0.0176s/iter; left time: 193.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0709251 Vali Loss: 0.0853064 Test Loss: 0.0878784\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02103678695857525, rmse:0.14504064619541168, mae:0.08788637816905975, rse:0.5118684768676758\n",
      "Intermediate time for DE and pred_len 24: 00h:09m:09.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1619344\n",
      "\tspeed: 0.0392s/iter; left time: 874.2074s\n",
      "\titers: 200, epoch: 1 | loss: 0.1504099\n",
      "\tspeed: 0.0172s/iter; left time: 382.9474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1589250 Vali Loss: 0.1489491 Test Loss: 0.1608326\n",
      "Validation loss decreased (inf --> 0.148949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1089703\n",
      "\tspeed: 0.0373s/iter; left time: 823.5144s\n",
      "\titers: 200, epoch: 2 | loss: 0.1149744\n",
      "\tspeed: 0.0172s/iter; left time: 378.4259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1169351 Vali Loss: 0.1223615 Test Loss: 0.1302950\n",
      "Validation loss decreased (0.148949 --> 0.122361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1056557\n",
      "\tspeed: 0.0391s/iter; left time: 854.2121s\n",
      "\titers: 200, epoch: 3 | loss: 0.0986517\n",
      "\tspeed: 0.0173s/iter; left time: 375.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1074685 Vali Loss: 0.1198070 Test Loss: 0.1282619\n",
      "Validation loss decreased (0.122361 --> 0.119807).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1025510\n",
      "\tspeed: 0.0384s/iter; left time: 829.7428s\n",
      "\titers: 200, epoch: 4 | loss: 0.1046377\n",
      "\tspeed: 0.0173s/iter; left time: 371.4612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1054033 Vali Loss: 0.1191063 Test Loss: 0.1278673\n",
      "Validation loss decreased (0.119807 --> 0.119106).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1038417\n",
      "\tspeed: 0.0386s/iter; left time: 827.2036s\n",
      "\titers: 200, epoch: 5 | loss: 0.1063736\n",
      "\tspeed: 0.0173s/iter; left time: 367.9127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1040633 Vali Loss: 0.1187290 Test Loss: 0.1275928\n",
      "Validation loss decreased (0.119106 --> 0.118729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1033758\n",
      "\tspeed: 0.0389s/iter; left time: 823.8563s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998508\n",
      "\tspeed: 0.0173s/iter; left time: 363.7328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1030631 Vali Loss: 0.1175519 Test Loss: 0.1267884\n",
      "Validation loss decreased (0.118729 --> 0.117552).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0990547\n",
      "\tspeed: 0.0399s/iter; left time: 835.9221s\n",
      "\titers: 200, epoch: 7 | loss: 0.1022646\n",
      "\tspeed: 0.0178s/iter; left time: 371.5137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1023639 Vali Loss: 0.1179993 Test Loss: 0.1276480\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988650\n",
      "\tspeed: 0.0404s/iter; left time: 838.2038s\n",
      "\titers: 200, epoch: 8 | loss: 0.1039498\n",
      "\tspeed: 0.0178s/iter; left time: 367.3830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 224 | Train Loss: 0.1016782 Vali Loss: 0.1179397 Test Loss: 0.1280137\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1008036\n",
      "\tspeed: 0.0378s/iter; left time: 775.7178s\n",
      "\titers: 200, epoch: 9 | loss: 0.1005208\n",
      "\tspeed: 0.0172s/iter; left time: 351.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.1010756 Vali Loss: 0.1179529 Test Loss: 0.1277854\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0970302\n",
      "\tspeed: 0.0379s/iter; left time: 769.7351s\n",
      "\titers: 200, epoch: 10 | loss: 0.0986957\n",
      "\tspeed: 0.0172s/iter; left time: 346.6015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1004807 Vali Loss: 0.1180902 Test Loss: 0.1278614\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0994967\n",
      "\tspeed: 0.0378s/iter; left time: 759.1757s\n",
      "\titers: 200, epoch: 11 | loss: 0.1038442\n",
      "\tspeed: 0.0172s/iter; left time: 343.3497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1000124 Vali Loss: 0.1173964 Test Loss: 0.1274240\n",
      "Validation loss decreased (0.117552 --> 0.117396).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996821\n",
      "\tspeed: 0.0387s/iter; left time: 767.2454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0990979\n",
      "\tspeed: 0.0175s/iter; left time: 345.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0994957 Vali Loss: 0.1176490 Test Loss: 0.1276904\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1023465\n",
      "\tspeed: 0.0369s/iter; left time: 722.7662s\n",
      "\titers: 200, epoch: 13 | loss: 0.0957390\n",
      "\tspeed: 0.0173s/iter; left time: 336.5997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0990532 Vali Loss: 0.1175529 Test Loss: 0.1279353\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1013488\n",
      "\tspeed: 0.0372s/iter; left time: 721.3418s\n",
      "\titers: 200, epoch: 14 | loss: 0.0959193\n",
      "\tspeed: 0.0173s/iter; left time: 334.4019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0987154 Vali Loss: 0.1176766 Test Loss: 0.1277661\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0998006\n",
      "\tspeed: 0.0375s/iter; left time: 719.2125s\n",
      "\titers: 200, epoch: 15 | loss: 0.1027932\n",
      "\tspeed: 0.0175s/iter; left time: 333.8769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0982760 Vali Loss: 0.1177681 Test Loss: 0.1287941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1000815\n",
      "\tspeed: 0.0375s/iter; left time: 710.2521s\n",
      "\titers: 200, epoch: 16 | loss: 0.0991594\n",
      "\tspeed: 0.0172s/iter; left time: 323.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0979667 Vali Loss: 0.1176327 Test Loss: 0.1287536\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0959603\n",
      "\tspeed: 0.0370s/iter; left time: 692.7494s\n",
      "\titers: 200, epoch: 17 | loss: 0.1016421\n",
      "\tspeed: 0.0172s/iter; left time: 320.2107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0975804 Vali Loss: 0.1175091 Test Loss: 0.1282794\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1013617\n",
      "\tspeed: 0.0392s/iter; left time: 724.1950s\n",
      "\titers: 200, epoch: 18 | loss: 0.0994364\n",
      "\tspeed: 0.0177s/iter; left time: 326.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 224 | Train Loss: 0.0973018 Vali Loss: 0.1175007 Test Loss: 0.1285073\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0953462\n",
      "\tspeed: 0.0390s/iter; left time: 713.0421s\n",
      "\titers: 200, epoch: 19 | loss: 0.0957629\n",
      "\tspeed: 0.0173s/iter; left time: 314.8177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0970375 Vali Loss: 0.1175389 Test Loss: 0.1279578\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0936652\n",
      "\tspeed: 0.0378s/iter; left time: 681.4064s\n",
      "\titers: 200, epoch: 20 | loss: 0.0926009\n",
      "\tspeed: 0.0172s/iter; left time: 308.9761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0968163 Vali Loss: 0.1177528 Test Loss: 0.1284854\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0969211\n",
      "\tspeed: 0.0373s/iter; left time: 664.7692s\n",
      "\titers: 200, epoch: 21 | loss: 0.0923096\n",
      "\tspeed: 0.0172s/iter; left time: 304.2329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0966375 Vali Loss: 0.1174772 Test Loss: 0.1284957\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03713487833738327, rmse:0.19270412623882294, mae:0.12742400169372559, rse:0.6824042201042175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1599484\n",
      "\tspeed: 0.0195s/iter; left time: 434.6124s\n",
      "\titers: 200, epoch: 1 | loss: 0.1413557\n",
      "\tspeed: 0.0174s/iter; left time: 386.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.1595846 Vali Loss: 0.1500936 Test Loss: 0.1617615\n",
      "Validation loss decreased (inf --> 0.150094).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1118193\n",
      "\tspeed: 0.0375s/iter; left time: 828.7409s\n",
      "\titers: 200, epoch: 2 | loss: 0.1141836\n",
      "\tspeed: 0.0174s/iter; left time: 381.5234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1169193 Vali Loss: 0.1221970 Test Loss: 0.1299465\n",
      "Validation loss decreased (0.150094 --> 0.122197).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1066184\n",
      "\tspeed: 0.0373s/iter; left time: 815.3774s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091056\n",
      "\tspeed: 0.0173s/iter; left time: 377.1886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1074296 Vali Loss: 0.1202674 Test Loss: 0.1293137\n",
      "Validation loss decreased (0.122197 --> 0.120267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1087393\n",
      "\tspeed: 0.0370s/iter; left time: 799.2175s\n",
      "\titers: 200, epoch: 4 | loss: 0.1098559\n",
      "\tspeed: 0.0173s/iter; left time: 371.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1053362 Vali Loss: 0.1188938 Test Loss: 0.1283945\n",
      "Validation loss decreased (0.120267 --> 0.118894).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1036616\n",
      "\tspeed: 0.0381s/iter; left time: 814.4665s\n",
      "\titers: 200, epoch: 5 | loss: 0.0987561\n",
      "\tspeed: 0.0172s/iter; left time: 366.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.1039363 Vali Loss: 0.1182847 Test Loss: 0.1274230\n",
      "Validation loss decreased (0.118894 --> 0.118285).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0986086\n",
      "\tspeed: 0.0371s/iter; left time: 785.2355s\n",
      "\titers: 200, epoch: 6 | loss: 0.1053465\n",
      "\tspeed: 0.0172s/iter; left time: 362.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1030449 Vali Loss: 0.1180117 Test Loss: 0.1280116\n",
      "Validation loss decreased (0.118285 --> 0.118012).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1083958\n",
      "\tspeed: 0.0370s/iter; left time: 775.1451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0960573\n",
      "\tspeed: 0.0173s/iter; left time: 360.5917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.1022464 Vali Loss: 0.1186399 Test Loss: 0.1284888\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0968402\n",
      "\tspeed: 0.0366s/iter; left time: 758.6499s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033064\n",
      "\tspeed: 0.0172s/iter; left time: 354.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1016151 Vali Loss: 0.1177948 Test Loss: 0.1282516\n",
      "Validation loss decreased (0.118012 --> 0.117795).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0977746\n",
      "\tspeed: 0.0375s/iter; left time: 768.9752s\n",
      "\titers: 200, epoch: 9 | loss: 0.1025220\n",
      "\tspeed: 0.0172s/iter; left time: 351.6731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.1009432 Vali Loss: 0.1180718 Test Loss: 0.1280409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0968307\n",
      "\tspeed: 0.0385s/iter; left time: 780.4157s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003335\n",
      "\tspeed: 0.0178s/iter; left time: 359.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.1004707 Vali Loss: 0.1177588 Test Loss: 0.1275924\n",
      "Validation loss decreased (0.117795 --> 0.117759).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0964796\n",
      "\tspeed: 0.0398s/iter; left time: 798.3198s\n",
      "\titers: 200, epoch: 11 | loss: 0.0991034\n",
      "\tspeed: 0.0175s/iter; left time: 348.3281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0998950 Vali Loss: 0.1181497 Test Loss: 0.1280834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0983424\n",
      "\tspeed: 0.0371s/iter; left time: 736.0024s\n",
      "\titers: 200, epoch: 12 | loss: 0.0982117\n",
      "\tspeed: 0.0172s/iter; left time: 340.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0994486 Vali Loss: 0.1179022 Test Loss: 0.1283433\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0962082\n",
      "\tspeed: 0.0366s/iter; left time: 718.4732s\n",
      "\titers: 200, epoch: 13 | loss: 0.1015690\n",
      "\tspeed: 0.0172s/iter; left time: 336.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0989993 Vali Loss: 0.1177817 Test Loss: 0.1278238\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0975967\n",
      "\tspeed: 0.0370s/iter; left time: 718.1980s\n",
      "\titers: 200, epoch: 14 | loss: 0.0966008\n",
      "\tspeed: 0.0172s/iter; left time: 332.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0985978 Vali Loss: 0.1181463 Test Loss: 0.1287461\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0959569\n",
      "\tspeed: 0.0386s/iter; left time: 740.6719s\n",
      "\titers: 200, epoch: 15 | loss: 0.1029405\n",
      "\tspeed: 0.0178s/iter; left time: 339.5190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 224 | Train Loss: 0.0982344 Vali Loss: 0.1182312 Test Loss: 0.1291786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0989549\n",
      "\tspeed: 0.0393s/iter; left time: 744.9942s\n",
      "\titers: 200, epoch: 16 | loss: 0.0945562\n",
      "\tspeed: 0.0178s/iter; left time: 335.4520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0978905 Vali Loss: 0.1179194 Test Loss: 0.1287309\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0958547\n",
      "\tspeed: 0.0382s/iter; left time: 714.9937s\n",
      "\titers: 200, epoch: 17 | loss: 0.0940897\n",
      "\tspeed: 0.0172s/iter; left time: 320.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0976239 Vali Loss: 0.1180656 Test Loss: 0.1284651\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1004175\n",
      "\tspeed: 0.0373s/iter; left time: 690.0222s\n",
      "\titers: 200, epoch: 18 | loss: 0.1005977\n",
      "\tspeed: 0.0172s/iter; left time: 316.7888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0972825 Vali Loss: 0.1180854 Test Loss: 0.1286950\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1003960\n",
      "\tspeed: 0.0370s/iter; left time: 675.9540s\n",
      "\titers: 200, epoch: 19 | loss: 0.0981270\n",
      "\tspeed: 0.0172s/iter; left time: 312.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0971135 Vali Loss: 0.1180676 Test Loss: 0.1292992\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0947228\n",
      "\tspeed: 0.0376s/iter; left time: 679.2548s\n",
      "\titers: 200, epoch: 20 | loss: 0.0970842\n",
      "\tspeed: 0.0172s/iter; left time: 309.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0968280 Vali Loss: 0.1183526 Test Loss: 0.1293319\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03748929128050804, rmse:0.19362151622772217, mae:0.1275922954082489, rse:0.6856529116630554\n",
      "Intermediate time for DE and pred_len 96: 00h:03m:57.65s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1628355\n",
      "\tspeed: 0.0387s/iter; left time: 859.4430s\n",
      "\titers: 200, epoch: 1 | loss: 0.1461226\n",
      "\tspeed: 0.0178s/iter; left time: 393.0587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.43s\n",
      "Steps: 223 | Train Loss: 0.1605776 Vali Loss: 0.1508951 Test Loss: 0.1630175\n",
      "Validation loss decreased (inf --> 0.150895).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1295495\n",
      "\tspeed: 0.0391s/iter; left time: 858.2492s\n",
      "\titers: 200, epoch: 2 | loss: 0.1168577\n",
      "\tspeed: 0.0176s/iter; left time: 384.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1227509 Vali Loss: 0.1269903 Test Loss: 0.1363985\n",
      "Validation loss decreased (0.150895 --> 0.126990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1139878\n",
      "\tspeed: 0.0385s/iter; left time: 837.8047s\n",
      "\titers: 200, epoch: 3 | loss: 0.1160950\n",
      "\tspeed: 0.0176s/iter; left time: 381.5331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1136342 Vali Loss: 0.1248411 Test Loss: 0.1347367\n",
      "Validation loss decreased (0.126990 --> 0.124841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1093246\n",
      "\tspeed: 0.0392s/iter; left time: 843.5192s\n",
      "\titers: 200, epoch: 4 | loss: 0.1123354\n",
      "\tspeed: 0.0176s/iter; left time: 376.4795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1113418 Vali Loss: 0.1242843 Test Loss: 0.1348724\n",
      "Validation loss decreased (0.124841 --> 0.124284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1121740\n",
      "\tspeed: 0.0392s/iter; left time: 835.0787s\n",
      "\titers: 200, epoch: 5 | loss: 0.1110278\n",
      "\tspeed: 0.0176s/iter; left time: 373.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1099283 Vali Loss: 0.1237305 Test Loss: 0.1349811\n",
      "Validation loss decreased (0.124284 --> 0.123731).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1062920\n",
      "\tspeed: 0.0390s/iter; left time: 823.2866s\n",
      "\titers: 200, epoch: 6 | loss: 0.1049748\n",
      "\tspeed: 0.0177s/iter; left time: 371.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1088134 Vali Loss: 0.1234774 Test Loss: 0.1352224\n",
      "Validation loss decreased (0.123731 --> 0.123477).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1020317\n",
      "\tspeed: 0.0400s/iter; left time: 833.5150s\n",
      "\titers: 200, epoch: 7 | loss: 0.1096161\n",
      "\tspeed: 0.0176s/iter; left time: 365.1252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1079568 Vali Loss: 0.1236840 Test Loss: 0.1353464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1095021\n",
      "\tspeed: 0.0372s/iter; left time: 768.2425s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080197\n",
      "\tspeed: 0.0176s/iter; left time: 361.4129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1071359 Vali Loss: 0.1236301 Test Loss: 0.1354977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1036291\n",
      "\tspeed: 0.0385s/iter; left time: 786.8944s\n",
      "\titers: 200, epoch: 9 | loss: 0.1095203\n",
      "\tspeed: 0.0176s/iter; left time: 358.1727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1063827 Vali Loss: 0.1240077 Test Loss: 0.1362663\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034006\n",
      "\tspeed: 0.0393s/iter; left time: 793.6545s\n",
      "\titers: 200, epoch: 10 | loss: 0.1180468\n",
      "\tspeed: 0.0178s/iter; left time: 358.4844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1057231 Vali Loss: 0.1239120 Test Loss: 0.1363678\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1066202\n",
      "\tspeed: 0.0384s/iter; left time: 766.0886s\n",
      "\titers: 200, epoch: 11 | loss: 0.1106018\n",
      "\tspeed: 0.0177s/iter; left time: 350.9222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1050407 Vali Loss: 0.1239418 Test Loss: 0.1362969\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1029786\n",
      "\tspeed: 0.0382s/iter; left time: 753.9081s\n",
      "\titers: 200, epoch: 12 | loss: 0.1028491\n",
      "\tspeed: 0.0176s/iter; left time: 345.5721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.1044090 Vali Loss: 0.1241329 Test Loss: 0.1362726\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1058907\n",
      "\tspeed: 0.0385s/iter; left time: 752.2159s\n",
      "\titers: 200, epoch: 13 | loss: 0.1042866\n",
      "\tspeed: 0.0176s/iter; left time: 342.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 223 | Train Loss: 0.1038418 Vali Loss: 0.1245901 Test Loss: 0.1365954\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1026729\n",
      "\tspeed: 0.0389s/iter; left time: 751.1229s\n",
      "\titers: 200, epoch: 14 | loss: 0.1014817\n",
      "\tspeed: 0.0176s/iter; left time: 337.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1033419 Vali Loss: 0.1247212 Test Loss: 0.1368871\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0972697\n",
      "\tspeed: 0.0388s/iter; left time: 740.5257s\n",
      "\titers: 200, epoch: 15 | loss: 0.0956452\n",
      "\tspeed: 0.0176s/iter; left time: 333.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1028740 Vali Loss: 0.1247642 Test Loss: 0.1374077\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0998949\n",
      "\tspeed: 0.0385s/iter; left time: 726.7714s\n",
      "\titers: 200, epoch: 16 | loss: 0.1000571\n",
      "\tspeed: 0.0178s/iter; left time: 333.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1024888 Vali Loss: 0.1247744 Test Loss: 0.1375357\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039771974086761475, rmse:0.19942912459373474, mae:0.13522249460220337, rse:0.7063939571380615\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1614676\n",
      "\tspeed: 0.0199s/iter; left time: 440.9957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1472207\n",
      "\tspeed: 0.0178s/iter; left time: 393.2451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1615994 Vali Loss: 0.1517376 Test Loss: 0.1639812\n",
      "Validation loss decreased (inf --> 0.151738).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1190681\n",
      "\tspeed: 0.0398s/iter; left time: 874.5828s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159668\n",
      "\tspeed: 0.0178s/iter; left time: 389.6738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 223 | Train Loss: 0.1226643 Vali Loss: 0.1268927 Test Loss: 0.1364927\n",
      "Validation loss decreased (0.151738 --> 0.126893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1129499\n",
      "\tspeed: 0.0398s/iter; left time: 866.4752s\n",
      "\titers: 200, epoch: 3 | loss: 0.1098257\n",
      "\tspeed: 0.0177s/iter; left time: 382.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1135993 Vali Loss: 0.1247262 Test Loss: 0.1353878\n",
      "Validation loss decreased (0.126893 --> 0.124726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083528\n",
      "\tspeed: 0.0391s/iter; left time: 842.5083s\n",
      "\titers: 200, epoch: 4 | loss: 0.1114580\n",
      "\tspeed: 0.0177s/iter; left time: 378.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1112562 Vali Loss: 0.1239683 Test Loss: 0.1353339\n",
      "Validation loss decreased (0.124726 --> 0.123968).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1135723\n",
      "\tspeed: 0.0404s/iter; left time: 860.9361s\n",
      "\titers: 200, epoch: 5 | loss: 0.1070901\n",
      "\tspeed: 0.0177s/iter; left time: 375.9225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1097971 Vali Loss: 0.1239955 Test Loss: 0.1353594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1017848\n",
      "\tspeed: 0.0402s/iter; left time: 846.8534s\n",
      "\titers: 200, epoch: 6 | loss: 0.1038264\n",
      "\tspeed: 0.0177s/iter; left time: 370.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1087336 Vali Loss: 0.1239600 Test Loss: 0.1352128\n",
      "Validation loss decreased (0.123968 --> 0.123960).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1039184\n",
      "\tspeed: 0.0400s/iter; left time: 834.9273s\n",
      "\titers: 200, epoch: 7 | loss: 0.1078782\n",
      "\tspeed: 0.0180s/iter; left time: 373.7605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1077933 Vali Loss: 0.1239608 Test Loss: 0.1350288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1076476\n",
      "\tspeed: 0.0410s/iter; left time: 846.4543s\n",
      "\titers: 200, epoch: 8 | loss: 0.1046468\n",
      "\tspeed: 0.0177s/iter; left time: 363.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1068901 Vali Loss: 0.1239507 Test Loss: 0.1356310\n",
      "Validation loss decreased (0.123960 --> 0.123951).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1034207\n",
      "\tspeed: 0.0410s/iter; left time: 836.5789s\n",
      "\titers: 200, epoch: 9 | loss: 0.1056401\n",
      "\tspeed: 0.0175s/iter; left time: 355.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 223 | Train Loss: 0.1061190 Vali Loss: 0.1242385 Test Loss: 0.1362977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1077828\n",
      "\tspeed: 0.0400s/iter; left time: 807.6142s\n",
      "\titers: 200, epoch: 10 | loss: 0.0995826\n",
      "\tspeed: 0.0179s/iter; left time: 360.0383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 223 | Train Loss: 0.1053582 Vali Loss: 0.1240935 Test Loss: 0.1358449\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1077381\n",
      "\tspeed: 0.0401s/iter; left time: 801.1817s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030068\n",
      "\tspeed: 0.0177s/iter; left time: 350.9121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1047195 Vali Loss: 0.1246159 Test Loss: 0.1358436\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1044587\n",
      "\tspeed: 0.0395s/iter; left time: 779.1617s\n",
      "\titers: 200, epoch: 12 | loss: 0.1011329\n",
      "\tspeed: 0.0177s/iter; left time: 346.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1041107 Vali Loss: 0.1247848 Test Loss: 0.1364089\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1013795\n",
      "\tspeed: 0.0383s/iter; left time: 748.2918s\n",
      "\titers: 200, epoch: 13 | loss: 0.1016659\n",
      "\tspeed: 0.0177s/iter; left time: 343.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1035474 Vali Loss: 0.1248526 Test Loss: 0.1364463\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1000248\n",
      "\tspeed: 0.0401s/iter; left time: 774.9119s\n",
      "\titers: 200, epoch: 14 | loss: 0.1002347\n",
      "\tspeed: 0.0178s/iter; left time: 341.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1030316 Vali Loss: 0.1251890 Test Loss: 0.1370925\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1002223\n",
      "\tspeed: 0.0412s/iter; left time: 786.7110s\n",
      "\titers: 200, epoch: 15 | loss: 0.0996103\n",
      "\tspeed: 0.0178s/iter; left time: 337.8894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1025586 Vali Loss: 0.1250165 Test Loss: 0.1359998\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1048982\n",
      "\tspeed: 0.0406s/iter; left time: 766.1310s\n",
      "\titers: 200, epoch: 16 | loss: 0.1010092\n",
      "\tspeed: 0.0177s/iter; left time: 332.6317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.27s\n",
      "Steps: 223 | Train Loss: 0.1021861 Vali Loss: 0.1254149 Test Loss: 0.1366657\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1023926\n",
      "\tspeed: 0.0411s/iter; left time: 766.3792s\n",
      "\titers: 200, epoch: 17 | loss: 0.0989901\n",
      "\tspeed: 0.0178s/iter; left time: 330.0293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 223 | Train Loss: 0.1018655 Vali Loss: 0.1256411 Test Loss: 0.1365401\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0996629\n",
      "\tspeed: 0.0412s/iter; left time: 759.3628s\n",
      "\titers: 200, epoch: 18 | loss: 0.0977472\n",
      "\tspeed: 0.0179s/iter; left time: 327.7871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.1015171 Vali Loss: 0.1260166 Test Loss: 0.1366263\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04039271920919418, rmse:0.20097939670085907, mae:0.13563112914562225, rse:0.7118852138519287\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:25.91s\n",
      "Intermediate time for DE: 00h:16m:32.69s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1414340\n",
      "\tspeed: 0.0383s/iter; left time: 853.4657s\n",
      "\titers: 200, epoch: 1 | loss: 0.1221013\n",
      "\tspeed: 0.0173s/iter; left time: 383.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 224 | Train Loss: 0.1394487 Vali Loss: 0.1303349 Test Loss: 0.1521696\n",
      "Validation loss decreased (inf --> 0.130335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0840514\n",
      "\tspeed: 0.0367s/iter; left time: 810.7054s\n",
      "\titers: 200, epoch: 2 | loss: 0.0808714\n",
      "\tspeed: 0.0173s/iter; left time: 381.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0883156 Vali Loss: 0.0921759 Test Loss: 0.1036873\n",
      "Validation loss decreased (0.130335 --> 0.092176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0803500\n",
      "\tspeed: 0.0370s/iter; left time: 808.0457s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805062\n",
      "\tspeed: 0.0172s/iter; left time: 373.5376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0800184 Vali Loss: 0.0905325 Test Loss: 0.1025728\n",
      "Validation loss decreased (0.092176 --> 0.090532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0798231\n",
      "\tspeed: 0.0365s/iter; left time: 788.8720s\n",
      "\titers: 200, epoch: 4 | loss: 0.0777466\n",
      "\tspeed: 0.0172s/iter; left time: 370.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0784797 Vali Loss: 0.0899157 Test Loss: 0.1023136\n",
      "Validation loss decreased (0.090532 --> 0.089916).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0795304\n",
      "\tspeed: 0.0368s/iter; left time: 788.6294s\n",
      "\titers: 200, epoch: 5 | loss: 0.0756811\n",
      "\tspeed: 0.0174s/iter; left time: 369.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0774861 Vali Loss: 0.0895856 Test Loss: 0.1022673\n",
      "Validation loss decreased (0.089916 --> 0.089586).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0745707\n",
      "\tspeed: 0.0369s/iter; left time: 781.7138s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718807\n",
      "\tspeed: 0.0172s/iter; left time: 362.3496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0767927 Vali Loss: 0.0892474 Test Loss: 0.1016225\n",
      "Validation loss decreased (0.089586 --> 0.089247).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0763125\n",
      "\tspeed: 0.0372s/iter; left time: 778.6028s\n",
      "\titers: 200, epoch: 7 | loss: 0.0761305\n",
      "\tspeed: 0.0173s/iter; left time: 360.0436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0762174 Vali Loss: 0.0889595 Test Loss: 0.1021078\n",
      "Validation loss decreased (0.089247 --> 0.088960).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0740032\n",
      "\tspeed: 0.0365s/iter; left time: 757.2420s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748307\n",
      "\tspeed: 0.0172s/iter; left time: 355.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0758005 Vali Loss: 0.0888929 Test Loss: 0.1011652\n",
      "Validation loss decreased (0.088960 --> 0.088893).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0772215\n",
      "\tspeed: 0.0366s/iter; left time: 749.7183s\n",
      "\titers: 200, epoch: 9 | loss: 0.0779016\n",
      "\tspeed: 0.0172s/iter; left time: 351.3917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0754587 Vali Loss: 0.0887787 Test Loss: 0.1017626\n",
      "Validation loss decreased (0.088893 --> 0.088779).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0781136\n",
      "\tspeed: 0.0371s/iter; left time: 753.5873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792562\n",
      "\tspeed: 0.0174s/iter; left time: 350.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0750786 Vali Loss: 0.0883456 Test Loss: 0.1013593\n",
      "Validation loss decreased (0.088779 --> 0.088346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0763240\n",
      "\tspeed: 0.0371s/iter; left time: 744.1256s\n",
      "\titers: 200, epoch: 11 | loss: 0.0766105\n",
      "\tspeed: 0.0172s/iter; left time: 342.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0748253 Vali Loss: 0.0884376 Test Loss: 0.1009040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0720343\n",
      "\tspeed: 0.0366s/iter; left time: 725.4153s\n",
      "\titers: 200, epoch: 12 | loss: 0.0749820\n",
      "\tspeed: 0.0173s/iter; left time: 342.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0745866 Vali Loss: 0.0884318 Test Loss: 0.1014207\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0764522\n",
      "\tspeed: 0.0373s/iter; left time: 731.3310s\n",
      "\titers: 200, epoch: 13 | loss: 0.0720733\n",
      "\tspeed: 0.0172s/iter; left time: 335.8304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0743763 Vali Loss: 0.0881860 Test Loss: 0.1007518\n",
      "Validation loss decreased (0.088346 --> 0.088186).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0781043\n",
      "\tspeed: 0.0373s/iter; left time: 722.6676s\n",
      "\titers: 200, epoch: 14 | loss: 0.0749587\n",
      "\tspeed: 0.0172s/iter; left time: 332.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0742807 Vali Loss: 0.0881734 Test Loss: 0.1011914\n",
      "Validation loss decreased (0.088186 --> 0.088173).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0691805\n",
      "\tspeed: 0.0365s/iter; left time: 699.2967s\n",
      "\titers: 200, epoch: 15 | loss: 0.0790325\n",
      "\tspeed: 0.0171s/iter; left time: 326.7412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0741194 Vali Loss: 0.0882669 Test Loss: 0.1008864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0723666\n",
      "\tspeed: 0.0370s/iter; left time: 701.5384s\n",
      "\titers: 200, epoch: 16 | loss: 0.0744868\n",
      "\tspeed: 0.0171s/iter; left time: 322.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0739220 Vali Loss: 0.0880005 Test Loss: 0.1011248\n",
      "Validation loss decreased (0.088173 --> 0.088000).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0806842\n",
      "\tspeed: 0.0369s/iter; left time: 690.2079s\n",
      "\titers: 200, epoch: 17 | loss: 0.0699300\n",
      "\tspeed: 0.0173s/iter; left time: 322.9573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0737822 Vali Loss: 0.0880966 Test Loss: 0.1010500\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789800\n",
      "\tspeed: 0.0383s/iter; left time: 708.8477s\n",
      "\titers: 200, epoch: 18 | loss: 0.0703603\n",
      "\tspeed: 0.0171s/iter; left time: 314.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 224 | Train Loss: 0.0736363 Vali Loss: 0.0880285 Test Loss: 0.1005919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0718165\n",
      "\tspeed: 0.0365s/iter; left time: 666.2419s\n",
      "\titers: 200, epoch: 19 | loss: 0.0751730\n",
      "\tspeed: 0.0172s/iter; left time: 312.2814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0735602 Vali Loss: 0.0878067 Test Loss: 0.1006212\n",
      "Validation loss decreased (0.088000 --> 0.087807).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748918\n",
      "\tspeed: 0.0369s/iter; left time: 665.9881s\n",
      "\titers: 200, epoch: 20 | loss: 0.0692953\n",
      "\tspeed: 0.0173s/iter; left time: 310.4420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0734651 Vali Loss: 0.0879854 Test Loss: 0.1006300\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0713822\n",
      "\tspeed: 0.0377s/iter; left time: 672.2404s\n",
      "\titers: 200, epoch: 21 | loss: 0.0704772\n",
      "\tspeed: 0.0171s/iter; left time: 303.7340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0734279 Vali Loss: 0.0878920 Test Loss: 0.1006983\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0702952\n",
      "\tspeed: 0.0362s/iter; left time: 637.6293s\n",
      "\titers: 200, epoch: 22 | loss: 0.0716079\n",
      "\tspeed: 0.0172s/iter; left time: 300.9183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0732838 Vali Loss: 0.0879619 Test Loss: 0.1006514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0730950\n",
      "\tspeed: 0.0373s/iter; left time: 648.7056s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714289\n",
      "\tspeed: 0.0172s/iter; left time: 297.2506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0732746 Vali Loss: 0.0879373 Test Loss: 0.1007899\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0770678\n",
      "\tspeed: 0.0365s/iter; left time: 626.6239s\n",
      "\titers: 200, epoch: 24 | loss: 0.0762338\n",
      "\tspeed: 0.0172s/iter; left time: 292.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0732110 Vali Loss: 0.0878568 Test Loss: 0.1006290\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0733350\n",
      "\tspeed: 0.0369s/iter; left time: 624.4114s\n",
      "\titers: 200, epoch: 25 | loss: 0.0729042\n",
      "\tspeed: 0.0172s/iter; left time: 289.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0730880 Vali Loss: 0.0878372 Test Loss: 0.1006322\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0744758\n",
      "\tspeed: 0.0363s/iter; left time: 606.9646s\n",
      "\titers: 200, epoch: 26 | loss: 0.0729826\n",
      "\tspeed: 0.0172s/iter; left time: 286.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0730730 Vali Loss: 0.0877768 Test Loss: 0.1007827\n",
      "Validation loss decreased (0.087807 --> 0.087777).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0761941\n",
      "\tspeed: 0.0367s/iter; left time: 605.2384s\n",
      "\titers: 200, epoch: 27 | loss: 0.0774298\n",
      "\tspeed: 0.0172s/iter; left time: 281.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0730445 Vali Loss: 0.0879525 Test Loss: 0.1008523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0738741\n",
      "\tspeed: 0.0369s/iter; left time: 600.2413s\n",
      "\titers: 200, epoch: 28 | loss: 0.0736755\n",
      "\tspeed: 0.0173s/iter; left time: 278.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0729427 Vali Loss: 0.0877238 Test Loss: 0.1007436\n",
      "Validation loss decreased (0.087777 --> 0.087724).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0745023\n",
      "\tspeed: 0.0382s/iter; left time: 611.9999s\n",
      "\titers: 200, epoch: 29 | loss: 0.0714937\n",
      "\tspeed: 0.0172s/iter; left time: 274.5008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0729999 Vali Loss: 0.0879006 Test Loss: 0.1007036\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0712956\n",
      "\tspeed: 0.0365s/iter; left time: 577.1134s\n",
      "\titers: 200, epoch: 30 | loss: 0.0730343\n",
      "\tspeed: 0.0174s/iter; left time: 272.6920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0728931 Vali Loss: 0.0877871 Test Loss: 0.1007157\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0756159\n",
      "\tspeed: 0.0362s/iter; left time: 563.5415s\n",
      "\titers: 200, epoch: 31 | loss: 0.0722965\n",
      "\tspeed: 0.0172s/iter; left time: 266.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0728672 Vali Loss: 0.0878085 Test Loss: 0.1007682\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0714643\n",
      "\tspeed: 0.0371s/iter; left time: 570.4311s\n",
      "\titers: 200, epoch: 32 | loss: 0.0707066\n",
      "\tspeed: 0.0174s/iter; left time: 265.2177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0728596 Vali Loss: 0.0877316 Test Loss: 0.1006434\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0724875\n",
      "\tspeed: 0.0364s/iter; left time: 551.3463s\n",
      "\titers: 200, epoch: 33 | loss: 0.0727731\n",
      "\tspeed: 0.0172s/iter; left time: 258.2072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0728394 Vali Loss: 0.0878194 Test Loss: 0.1006887\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0725046\n",
      "\tspeed: 0.0370s/iter; left time: 551.9290s\n",
      "\titers: 200, epoch: 34 | loss: 0.0697057\n",
      "\tspeed: 0.0171s/iter; left time: 253.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0728348 Vali Loss: 0.0878913 Test Loss: 0.1006468\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0757190\n",
      "\tspeed: 0.0380s/iter; left time: 557.7409s\n",
      "\titers: 200, epoch: 35 | loss: 0.0747981\n",
      "\tspeed: 0.0175s/iter; left time: 255.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0728293 Vali Loss: 0.0878169 Test Loss: 0.1006506\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0681821\n",
      "\tspeed: 0.0381s/iter; left time: 550.9108s\n",
      "\titers: 200, epoch: 36 | loss: 0.0683805\n",
      "\tspeed: 0.0176s/iter; left time: 253.0971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0728057 Vali Loss: 0.0877465 Test Loss: 0.1006636\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0727580\n",
      "\tspeed: 0.0373s/iter; left time: 531.0372s\n",
      "\titers: 200, epoch: 37 | loss: 0.0700100\n",
      "\tspeed: 0.0175s/iter; left time: 247.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0727171 Vali Loss: 0.0877706 Test Loss: 0.1006148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0708804\n",
      "\tspeed: 0.0373s/iter; left time: 522.2345s\n",
      "\titers: 200, epoch: 38 | loss: 0.0741328\n",
      "\tspeed: 0.0175s/iter; left time: 243.7007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 224 | Train Loss: 0.0727147 Vali Loss: 0.0877684 Test Loss: 0.1006876\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025709599256515503, rmse:0.16034212708473206, mae:0.10074356198310852, rse:0.5531349182128906\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1340197\n",
      "\tspeed: 0.0190s/iter; left time: 424.7416s\n",
      "\titers: 200, epoch: 1 | loss: 0.1186601\n",
      "\tspeed: 0.0171s/iter; left time: 380.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.1332096 Vali Loss: 0.1250855 Test Loss: 0.1450315\n",
      "Validation loss decreased (inf --> 0.125086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0869524\n",
      "\tspeed: 0.0361s/iter; left time: 797.7078s\n",
      "\titers: 200, epoch: 2 | loss: 0.0819350\n",
      "\tspeed: 0.0172s/iter; left time: 378.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0874151 Vali Loss: 0.0918531 Test Loss: 0.1030672\n",
      "Validation loss decreased (0.125086 --> 0.091853).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818921\n",
      "\tspeed: 0.0367s/iter; left time: 801.6545s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800888\n",
      "\tspeed: 0.0173s/iter; left time: 377.0439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0799450 Vali Loss: 0.0906650 Test Loss: 0.1026596\n",
      "Validation loss decreased (0.091853 --> 0.090665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0747526\n",
      "\tspeed: 0.0367s/iter; left time: 793.1449s\n",
      "\titers: 200, epoch: 4 | loss: 0.0756399\n",
      "\tspeed: 0.0173s/iter; left time: 371.6693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0783222 Vali Loss: 0.0899995 Test Loss: 0.1022800\n",
      "Validation loss decreased (0.090665 --> 0.090000).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0747572\n",
      "\tspeed: 0.0367s/iter; left time: 785.8063s\n",
      "\titers: 200, epoch: 5 | loss: 0.0794002\n",
      "\tspeed: 0.0174s/iter; left time: 370.2993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0773946 Vali Loss: 0.0897476 Test Loss: 0.1018221\n",
      "Validation loss decreased (0.090000 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0733640\n",
      "\tspeed: 0.0367s/iter; left time: 776.3960s\n",
      "\titers: 200, epoch: 6 | loss: 0.0765230\n",
      "\tspeed: 0.0172s/iter; left time: 362.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0767216 Vali Loss: 0.0893016 Test Loss: 0.1022495\n",
      "Validation loss decreased (0.089748 --> 0.089302).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0722223\n",
      "\tspeed: 0.0374s/iter; left time: 782.7657s\n",
      "\titers: 200, epoch: 7 | loss: 0.0744969\n",
      "\tspeed: 0.0183s/iter; left time: 382.0580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0761975 Vali Loss: 0.0892127 Test Loss: 0.1019732\n",
      "Validation loss decreased (0.089302 --> 0.089213).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749555\n",
      "\tspeed: 0.0372s/iter; left time: 771.2873s\n",
      "\titers: 200, epoch: 8 | loss: 0.0759168\n",
      "\tspeed: 0.0172s/iter; left time: 355.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0757348 Vali Loss: 0.0890652 Test Loss: 0.1010868\n",
      "Validation loss decreased (0.089213 --> 0.089065).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0813650\n",
      "\tspeed: 0.0368s/iter; left time: 754.6814s\n",
      "\titers: 200, epoch: 9 | loss: 0.0762008\n",
      "\tspeed: 0.0172s/iter; left time: 351.7093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0753979 Vali Loss: 0.0888576 Test Loss: 0.1009978\n",
      "Validation loss decreased (0.089065 --> 0.088858).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0709221\n",
      "\tspeed: 0.0364s/iter; left time: 738.9337s\n",
      "\titers: 200, epoch: 10 | loss: 0.0800366\n",
      "\tspeed: 0.0171s/iter; left time: 346.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0750259 Vali Loss: 0.0886416 Test Loss: 0.1010157\n",
      "Validation loss decreased (0.088858 --> 0.088642).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0783893\n",
      "\tspeed: 0.0365s/iter; left time: 733.0024s\n",
      "\titers: 200, epoch: 11 | loss: 0.0746205\n",
      "\tspeed: 0.0174s/iter; left time: 347.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0748059 Vali Loss: 0.0884174 Test Loss: 0.1007122\n",
      "Validation loss decreased (0.088642 --> 0.088417).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0703763\n",
      "\tspeed: 0.0368s/iter; left time: 730.5288s\n",
      "\titers: 200, epoch: 12 | loss: 0.0713630\n",
      "\tspeed: 0.0174s/iter; left time: 342.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0745252 Vali Loss: 0.0882811 Test Loss: 0.1010922\n",
      "Validation loss decreased (0.088417 --> 0.088281).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0715097\n",
      "\tspeed: 0.0363s/iter; left time: 712.6221s\n",
      "\titers: 200, epoch: 13 | loss: 0.0759385\n",
      "\tspeed: 0.0172s/iter; left time: 334.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.04s\n",
      "Steps: 224 | Train Loss: 0.0742809 Vali Loss: 0.0886574 Test Loss: 0.1010207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0742332\n",
      "\tspeed: 0.0375s/iter; left time: 727.1920s\n",
      "\titers: 200, epoch: 14 | loss: 0.0752046\n",
      "\tspeed: 0.0172s/iter; left time: 331.5437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0740758 Vali Loss: 0.0884659 Test Loss: 0.1007764\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0692213\n",
      "\tspeed: 0.0358s/iter; left time: 686.4125s\n",
      "\titers: 200, epoch: 15 | loss: 0.0751361\n",
      "\tspeed: 0.0172s/iter; left time: 328.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0738982 Vali Loss: 0.0882612 Test Loss: 0.1004264\n",
      "Validation loss decreased (0.088281 --> 0.088261).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0718375\n",
      "\tspeed: 0.0366s/iter; left time: 693.1036s\n",
      "\titers: 200, epoch: 16 | loss: 0.0718620\n",
      "\tspeed: 0.0172s/iter; left time: 324.0769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0737685 Vali Loss: 0.0882500 Test Loss: 0.1006880\n",
      "Validation loss decreased (0.088261 --> 0.088250).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0724004\n",
      "\tspeed: 0.0365s/iter; left time: 684.0425s\n",
      "\titers: 200, epoch: 17 | loss: 0.0734418\n",
      "\tspeed: 0.0172s/iter; left time: 319.9006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0736443 Vali Loss: 0.0880385 Test Loss: 0.1004960\n",
      "Validation loss decreased (0.088250 --> 0.088038).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0816676\n",
      "\tspeed: 0.0361s/iter; left time: 668.0329s\n",
      "\titers: 200, epoch: 18 | loss: 0.0710257\n",
      "\tspeed: 0.0172s/iter; left time: 316.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0735018 Vali Loss: 0.0880099 Test Loss: 0.1006841\n",
      "Validation loss decreased (0.088038 --> 0.088010).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734205\n",
      "\tspeed: 0.0368s/iter; left time: 672.4582s\n",
      "\titers: 200, epoch: 19 | loss: 0.0737147\n",
      "\tspeed: 0.0172s/iter; left time: 313.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.09s\n",
      "Steps: 224 | Train Loss: 0.0733862 Vali Loss: 0.0881161 Test Loss: 0.1008031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0696185\n",
      "\tspeed: 0.0359s/iter; left time: 647.0878s\n",
      "\titers: 200, epoch: 20 | loss: 0.0717715\n",
      "\tspeed: 0.0172s/iter; left time: 307.9090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0733109 Vali Loss: 0.0880452 Test Loss: 0.1006649\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0772186\n",
      "\tspeed: 0.0360s/iter; left time: 641.3618s\n",
      "\titers: 200, epoch: 21 | loss: 0.0699462\n",
      "\tspeed: 0.0172s/iter; left time: 304.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0732230 Vali Loss: 0.0881920 Test Loss: 0.1006695\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0739405\n",
      "\tspeed: 0.0360s/iter; left time: 633.6522s\n",
      "\titers: 200, epoch: 22 | loss: 0.0663721\n",
      "\tspeed: 0.0172s/iter; left time: 301.7868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0731667 Vali Loss: 0.0880491 Test Loss: 0.1005262\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0633060\n",
      "\tspeed: 0.0368s/iter; left time: 639.9159s\n",
      "\titers: 200, epoch: 23 | loss: 0.0738195\n",
      "\tspeed: 0.0172s/iter; left time: 297.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0730593 Vali Loss: 0.0880977 Test Loss: 0.1007090\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0669296\n",
      "\tspeed: 0.0366s/iter; left time: 627.7858s\n",
      "\titers: 200, epoch: 24 | loss: 0.0727231\n",
      "\tspeed: 0.0175s/iter; left time: 297.8819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.0730345 Vali Loss: 0.0879509 Test Loss: 0.1005569\n",
      "Validation loss decreased (0.088010 --> 0.087951).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0751498\n",
      "\tspeed: 0.0364s/iter; left time: 615.8319s\n",
      "\titers: 200, epoch: 25 | loss: 0.0753632\n",
      "\tspeed: 0.0173s/iter; left time: 290.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0729213 Vali Loss: 0.0878470 Test Loss: 0.1005143\n",
      "Validation loss decreased (0.087951 --> 0.087847).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0715652\n",
      "\tspeed: 0.0367s/iter; left time: 612.2914s\n",
      "\titers: 200, epoch: 26 | loss: 0.0733509\n",
      "\tspeed: 0.0173s/iter; left time: 287.0222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0728528 Vali Loss: 0.0879316 Test Loss: 0.1007227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0698756\n",
      "\tspeed: 0.0365s/iter; left time: 601.4241s\n",
      "\titers: 200, epoch: 27 | loss: 0.0761078\n",
      "\tspeed: 0.0172s/iter; left time: 282.0836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.11s\n",
      "Steps: 224 | Train Loss: 0.0728290 Vali Loss: 0.0879371 Test Loss: 0.1005514\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0739709\n",
      "\tspeed: 0.0359s/iter; left time: 582.8318s\n",
      "\titers: 200, epoch: 28 | loss: 0.0731866\n",
      "\tspeed: 0.0172s/iter; left time: 277.6671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0728290 Vali Loss: 0.0880316 Test Loss: 0.1006677\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0695286\n",
      "\tspeed: 0.0361s/iter; left time: 578.2692s\n",
      "\titers: 200, epoch: 29 | loss: 0.0667043\n",
      "\tspeed: 0.0172s/iter; left time: 274.3320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 224 | Train Loss: 0.0727749 Vali Loss: 0.0879090 Test Loss: 0.1005998\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0697565\n",
      "\tspeed: 0.0366s/iter; left time: 578.0433s\n",
      "\titers: 200, epoch: 30 | loss: 0.0748501\n",
      "\tspeed: 0.0173s/iter; left time: 271.1503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0727729 Vali Loss: 0.0879277 Test Loss: 0.1007596\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0775060\n",
      "\tspeed: 0.0365s/iter; left time: 568.0746s\n",
      "\titers: 200, epoch: 31 | loss: 0.0712336\n",
      "\tspeed: 0.0172s/iter; left time: 266.5540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0726781 Vali Loss: 0.0879502 Test Loss: 0.1006403\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0763604\n",
      "\tspeed: 0.0364s/iter; left time: 559.0032s\n",
      "\titers: 200, epoch: 32 | loss: 0.0687235\n",
      "\tspeed: 0.0172s/iter; left time: 263.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 224 | Train Loss: 0.0726493 Vali Loss: 0.0878651 Test Loss: 0.1005589\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0698651\n",
      "\tspeed: 0.0362s/iter; left time: 547.9015s\n",
      "\titers: 200, epoch: 33 | loss: 0.0710001\n",
      "\tspeed: 0.0172s/iter; left time: 259.0656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0726488 Vali Loss: 0.0879200 Test Loss: 0.1006626\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0724165\n",
      "\tspeed: 0.0365s/iter; left time: 544.4970s\n",
      "\titers: 200, epoch: 34 | loss: 0.0725442\n",
      "\tspeed: 0.0172s/iter; left time: 254.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 224 | Train Loss: 0.0726266 Vali Loss: 0.0878657 Test Loss: 0.1006181\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0797121\n",
      "\tspeed: 0.0362s/iter; left time: 532.0459s\n",
      "\titers: 200, epoch: 35 | loss: 0.0701527\n",
      "\tspeed: 0.0172s/iter; left time: 250.9618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.06s\n",
      "Steps: 224 | Train Loss: 0.0726234 Vali Loss: 0.0878595 Test Loss: 0.1005977\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02563919499516487, rmse:0.16012243926525116, mae:0.1005142405629158, rse:0.5523770451545715\n",
      "Intermediate time for GB and pred_len 24: 00h:06m:44.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1466275\n",
      "\tspeed: 0.0391s/iter; left time: 871.8716s\n",
      "\titers: 200, epoch: 1 | loss: 0.1337850\n",
      "\tspeed: 0.0177s/iter; left time: 391.9264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.42s\n",
      "Steps: 224 | Train Loss: 0.1435828 Vali Loss: 0.1385492 Test Loss: 0.1633576\n",
      "Validation loss decreased (inf --> 0.138549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1104258\n",
      "\tspeed: 0.0374s/iter; left time: 825.4376s\n",
      "\titers: 200, epoch: 2 | loss: 0.1112381\n",
      "\tspeed: 0.0174s/iter; left time: 382.7788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.10s\n",
      "Steps: 224 | Train Loss: 0.1108078 Vali Loss: 0.1185432 Test Loss: 0.1400204\n",
      "Validation loss decreased (0.138549 --> 0.118543).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1055267\n",
      "\tspeed: 0.0386s/iter; left time: 842.4860s\n",
      "\titers: 200, epoch: 3 | loss: 0.1024510\n",
      "\tspeed: 0.0174s/iter; left time: 379.2553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.1047173 Vali Loss: 0.1173792 Test Loss: 0.1411833\n",
      "Validation loss decreased (0.118543 --> 0.117379).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1010584\n",
      "\tspeed: 0.0389s/iter; left time: 841.7595s\n",
      "\titers: 200, epoch: 4 | loss: 0.1023916\n",
      "\tspeed: 0.0176s/iter; left time: 379.7397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.1031035 Vali Loss: 0.1173137 Test Loss: 0.1412240\n",
      "Validation loss decreased (0.117379 --> 0.117314).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1018159\n",
      "\tspeed: 0.0400s/iter; left time: 856.9857s\n",
      "\titers: 200, epoch: 5 | loss: 0.1006902\n",
      "\tspeed: 0.0175s/iter; left time: 373.4554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.1020479 Vali Loss: 0.1172939 Test Loss: 0.1422832\n",
      "Validation loss decreased (0.117314 --> 0.117294).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1007758\n",
      "\tspeed: 0.0391s/iter; left time: 827.2096s\n",
      "\titers: 200, epoch: 6 | loss: 0.0994306\n",
      "\tspeed: 0.0175s/iter; left time: 369.6725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.1009951 Vali Loss: 0.1164035 Test Loss: 0.1401911\n",
      "Validation loss decreased (0.117294 --> 0.116403).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1036470\n",
      "\tspeed: 0.0395s/iter; left time: 827.5263s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978406\n",
      "\tspeed: 0.0176s/iter; left time: 366.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.1001050 Vali Loss: 0.1163152 Test Loss: 0.1423407\n",
      "Validation loss decreased (0.116403 --> 0.116315).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0974191\n",
      "\tspeed: 0.0392s/iter; left time: 812.0799s\n",
      "\titers: 200, epoch: 8 | loss: 0.1014476\n",
      "\tspeed: 0.0175s/iter; left time: 361.3922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.19s\n",
      "Steps: 224 | Train Loss: 0.0992137 Vali Loss: 0.1164122 Test Loss: 0.1430775\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0985387\n",
      "\tspeed: 0.0383s/iter; left time: 785.5559s\n",
      "\titers: 200, epoch: 9 | loss: 0.0965922\n",
      "\tspeed: 0.0175s/iter; left time: 357.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0984681 Vali Loss: 0.1171481 Test Loss: 0.1426953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0963279\n",
      "\tspeed: 0.0388s/iter; left time: 786.8631s\n",
      "\titers: 200, epoch: 10 | loss: 0.0998888\n",
      "\tspeed: 0.0175s/iter; left time: 354.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0978281 Vali Loss: 0.1175429 Test Loss: 0.1437618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0968340\n",
      "\tspeed: 0.0380s/iter; left time: 762.5355s\n",
      "\titers: 200, epoch: 11 | loss: 0.1017763\n",
      "\tspeed: 0.0176s/iter; left time: 350.4631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0972433 Vali Loss: 0.1171132 Test Loss: 0.1428917\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0951716\n",
      "\tspeed: 0.0388s/iter; left time: 769.4111s\n",
      "\titers: 200, epoch: 12 | loss: 0.0948278\n",
      "\tspeed: 0.0175s/iter; left time: 345.7241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0967977 Vali Loss: 0.1174284 Test Loss: 0.1440489\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0988010\n",
      "\tspeed: 0.0402s/iter; left time: 789.4187s\n",
      "\titers: 200, epoch: 13 | loss: 0.0960313\n",
      "\tspeed: 0.0175s/iter; left time: 341.5476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0963267 Vali Loss: 0.1179225 Test Loss: 0.1438781\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0950944\n",
      "\tspeed: 0.0380s/iter; left time: 735.8707s\n",
      "\titers: 200, epoch: 14 | loss: 0.0917997\n",
      "\tspeed: 0.0175s/iter; left time: 338.2515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0959337 Vali Loss: 0.1176546 Test Loss: 0.1443557\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0956033\n",
      "\tspeed: 0.0389s/iter; left time: 746.2554s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981533\n",
      "\tspeed: 0.0177s/iter; left time: 337.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0955988 Vali Loss: 0.1177327 Test Loss: 0.1449699\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0946286\n",
      "\tspeed: 0.0395s/iter; left time: 747.4375s\n",
      "\titers: 200, epoch: 16 | loss: 0.0934132\n",
      "\tspeed: 0.0176s/iter; left time: 332.4098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0952448 Vali Loss: 0.1179892 Test Loss: 0.1447331\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0967856\n",
      "\tspeed: 0.0387s/iter; left time: 723.8781s\n",
      "\titers: 200, epoch: 17 | loss: 0.0960769\n",
      "\tspeed: 0.0172s/iter; left time: 320.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.0949099 Vali Loss: 0.1181670 Test Loss: 0.1441893\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043783560395240784, rmse:0.2092452198266983, mae:0.14234068989753723, rse:0.7235991358757019\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1481112\n",
      "\tspeed: 0.0203s/iter; left time: 452.7125s\n",
      "\titers: 200, epoch: 1 | loss: 0.1335087\n",
      "\tspeed: 0.0177s/iter; left time: 392.3413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.26s\n",
      "Steps: 224 | Train Loss: 0.1449150 Vali Loss: 0.1387053 Test Loss: 0.1635620\n",
      "Validation loss decreased (inf --> 0.138705).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1131397\n",
      "\tspeed: 0.0390s/iter; left time: 861.2814s\n",
      "\titers: 200, epoch: 2 | loss: 0.1046704\n",
      "\tspeed: 0.0175s/iter; left time: 384.8104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1110582 Vali Loss: 0.1184300 Test Loss: 0.1397089\n",
      "Validation loss decreased (0.138705 --> 0.118430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071158\n",
      "\tspeed: 0.0385s/iter; left time: 841.8028s\n",
      "\titers: 200, epoch: 3 | loss: 0.1100300\n",
      "\tspeed: 0.0176s/iter; left time: 382.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.1047914 Vali Loss: 0.1177066 Test Loss: 0.1415562\n",
      "Validation loss decreased (0.118430 --> 0.117707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1067308\n",
      "\tspeed: 0.0458s/iter; left time: 990.9878s\n",
      "\titers: 200, epoch: 4 | loss: 0.1074803\n",
      "\tspeed: 0.0176s/iter; left time: 379.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.86s\n",
      "Steps: 224 | Train Loss: 0.1030597 Vali Loss: 0.1168600 Test Loss: 0.1414379\n",
      "Validation loss decreased (0.117707 --> 0.116860).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029709\n",
      "\tspeed: 0.0390s/iter; left time: 834.2450s\n",
      "\titers: 200, epoch: 5 | loss: 0.0968682\n",
      "\tspeed: 0.0175s/iter; left time: 372.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.1019301 Vali Loss: 0.1165089 Test Loss: 0.1414413\n",
      "Validation loss decreased (0.116860 --> 0.116509).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1010422\n",
      "\tspeed: 0.0384s/iter; left time: 812.3643s\n",
      "\titers: 200, epoch: 6 | loss: 0.1084577\n",
      "\tspeed: 0.0174s/iter; left time: 367.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 224 | Train Loss: 0.1008747 Vali Loss: 0.1165724 Test Loss: 0.1430360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0997258\n",
      "\tspeed: 0.0378s/iter; left time: 791.7718s\n",
      "\titers: 200, epoch: 7 | loss: 0.1066200\n",
      "\tspeed: 0.0176s/iter; left time: 366.4546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 224 | Train Loss: 0.0999447 Vali Loss: 0.1161490 Test Loss: 0.1422906\n",
      "Validation loss decreased (0.116509 --> 0.116149).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1012282\n",
      "\tspeed: 0.0393s/iter; left time: 814.0734s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019995\n",
      "\tspeed: 0.0176s/iter; left time: 363.9528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0991358 Vali Loss: 0.1163857 Test Loss: 0.1419556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1001763\n",
      "\tspeed: 0.0388s/iter; left time: 795.4770s\n",
      "\titers: 200, epoch: 9 | loss: 0.0960826\n",
      "\tspeed: 0.0176s/iter; left time: 359.0155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 224 | Train Loss: 0.0984164 Vali Loss: 0.1166470 Test Loss: 0.1425706\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0959569\n",
      "\tspeed: 0.0384s/iter; left time: 778.6761s\n",
      "\titers: 200, epoch: 10 | loss: 0.0987386\n",
      "\tspeed: 0.0178s/iter; left time: 358.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0977737 Vali Loss: 0.1167493 Test Loss: 0.1431903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1008444\n",
      "\tspeed: 0.0382s/iter; left time: 766.6603s\n",
      "\titers: 200, epoch: 11 | loss: 0.0952595\n",
      "\tspeed: 0.0177s/iter; left time: 352.8180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 224 | Train Loss: 0.0972392 Vali Loss: 0.1179862 Test Loss: 0.1449880\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0954704\n",
      "\tspeed: 0.0390s/iter; left time: 773.1921s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967767\n",
      "\tspeed: 0.0174s/iter; left time: 343.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0967055 Vali Loss: 0.1168492 Test Loss: 0.1427419\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0957815\n",
      "\tspeed: 0.0397s/iter; left time: 778.6650s\n",
      "\titers: 200, epoch: 13 | loss: 0.0956375\n",
      "\tspeed: 0.0175s/iter; left time: 340.9608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 224 | Train Loss: 0.0962845 Vali Loss: 0.1177728 Test Loss: 0.1452707\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0947317\n",
      "\tspeed: 0.0389s/iter; left time: 753.6991s\n",
      "\titers: 200, epoch: 14 | loss: 0.0960187\n",
      "\tspeed: 0.0178s/iter; left time: 343.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.23s\n",
      "Steps: 224 | Train Loss: 0.0958775 Vali Loss: 0.1178635 Test Loss: 0.1445331\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0879725\n",
      "\tspeed: 0.0385s/iter; left time: 738.5014s\n",
      "\titers: 200, epoch: 15 | loss: 0.0905229\n",
      "\tspeed: 0.0178s/iter; left time: 338.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.22s\n",
      "Steps: 224 | Train Loss: 0.0955328 Vali Loss: 0.1184353 Test Loss: 0.1450296\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0918466\n",
      "\tspeed: 0.0385s/iter; left time: 729.4512s\n",
      "\titers: 200, epoch: 16 | loss: 0.0920146\n",
      "\tspeed: 0.0173s/iter; left time: 325.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 224 | Train Loss: 0.0952483 Vali Loss: 0.1181045 Test Loss: 0.1440710\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0938620\n",
      "\tspeed: 0.0384s/iter; left time: 719.4400s\n",
      "\titers: 200, epoch: 17 | loss: 0.0983414\n",
      "\tspeed: 0.0172s/iter; left time: 320.0343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.12s\n",
      "Steps: 224 | Train Loss: 0.0948800 Vali Loss: 0.1184686 Test Loss: 0.1454143\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.043279990553855896, rmse:0.20803843438625336, mae:0.1422906368970871, rse:0.7194259166717529\n",
      "Intermediate time for GB and pred_len 96: 00h:03m:22.69s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1476450\n",
      "\tspeed: 0.0392s/iter; left time: 869.1779s\n",
      "\titers: 200, epoch: 1 | loss: 0.1322379\n",
      "\tspeed: 0.0175s/iter; left time: 387.7135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.39s\n",
      "Steps: 223 | Train Loss: 0.1446634 Vali Loss: 0.1403988 Test Loss: 0.1657538\n",
      "Validation loss decreased (inf --> 0.140399).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1181542\n",
      "\tspeed: 0.0395s/iter; left time: 867.3047s\n",
      "\titers: 200, epoch: 2 | loss: 0.1103590\n",
      "\tspeed: 0.0174s/iter; left time: 381.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1153974 Vali Loss: 0.1230213 Test Loss: 0.1469014\n",
      "Validation loss decreased (0.140399 --> 0.123021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1078933\n",
      "\tspeed: 0.0392s/iter; left time: 851.7154s\n",
      "\titers: 200, epoch: 3 | loss: 0.1094684\n",
      "\tspeed: 0.0176s/iter; left time: 380.6176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1095194 Vali Loss: 0.1215952 Test Loss: 0.1471972\n",
      "Validation loss decreased (0.123021 --> 0.121595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1068714\n",
      "\tspeed: 0.0408s/iter; left time: 877.8638s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091786\n",
      "\tspeed: 0.0175s/iter; left time: 374.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1077170 Vali Loss: 0.1219872 Test Loss: 0.1488043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1074749\n",
      "\tspeed: 0.0387s/iter; left time: 824.9724s\n",
      "\titers: 200, epoch: 5 | loss: 0.1072562\n",
      "\tspeed: 0.0175s/iter; left time: 370.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1063439 Vali Loss: 0.1214106 Test Loss: 0.1474847\n",
      "Validation loss decreased (0.121595 --> 0.121411).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1031363\n",
      "\tspeed: 0.0404s/iter; left time: 852.2875s\n",
      "\titers: 200, epoch: 6 | loss: 0.1033070\n",
      "\tspeed: 0.0175s/iter; left time: 366.7537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.17s\n",
      "Steps: 223 | Train Loss: 0.1048237 Vali Loss: 0.1214159 Test Loss: 0.1477327\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015336\n",
      "\tspeed: 0.0417s/iter; left time: 869.3591s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040114\n",
      "\tspeed: 0.1525s/iter; left time: 3167.3069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:21.68s\n",
      "Steps: 223 | Train Loss: 0.1036718 Vali Loss: 0.1211991 Test Loss: 0.1474411\n",
      "Validation loss decreased (0.121411 --> 0.121199).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045649\n",
      "\tspeed: 0.1298s/iter; left time: 2679.8212s\n",
      "\titers: 200, epoch: 8 | loss: 0.0997393\n",
      "\tspeed: 0.0178s/iter; left time: 366.5644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.30s\n",
      "Steps: 223 | Train Loss: 0.1027916 Vali Loss: 0.1215216 Test Loss: 0.1471704\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1015813\n",
      "\tspeed: 0.0399s/iter; left time: 815.1224s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016080\n",
      "\tspeed: 0.0175s/iter; left time: 355.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1020035 Vali Loss: 0.1216637 Test Loss: 0.1498252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1022068\n",
      "\tspeed: 0.0394s/iter; left time: 794.9318s\n",
      "\titers: 200, epoch: 10 | loss: 0.1057559\n",
      "\tspeed: 0.0175s/iter; left time: 352.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1014043 Vali Loss: 0.1225466 Test Loss: 0.1508662\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1012574\n",
      "\tspeed: 0.0397s/iter; left time: 793.3899s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064127\n",
      "\tspeed: 0.0176s/iter; left time: 348.7888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.1008412 Vali Loss: 0.1222213 Test Loss: 0.1478938\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0995592\n",
      "\tspeed: 0.0405s/iter; left time: 798.9544s\n",
      "\titers: 200, epoch: 12 | loss: 0.1017008\n",
      "\tspeed: 0.0513s/iter; left time: 1008.6786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 223 | Train Loss: 0.1004033 Vali Loss: 0.1223581 Test Loss: 0.1499430\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0989383\n",
      "\tspeed: 0.4601s/iter; left time: 8984.0502s\n",
      "\titers: 200, epoch: 13 | loss: 0.0984159\n",
      "\tspeed: 0.1803s/iter; left time: 3502.4383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.89s\n",
      "Steps: 223 | Train Loss: 0.0999151 Vali Loss: 0.1223459 Test Loss: 0.1497312\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1002314\n",
      "\tspeed: 0.5599s/iter; left time: 10806.3333s\n",
      "\titers: 200, epoch: 14 | loss: 0.0961447\n",
      "\tspeed: 0.1594s/iter; left time: 3060.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:36.09s\n",
      "Steps: 223 | Train Loss: 0.0995683 Vali Loss: 0.1228215 Test Loss: 0.1515283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0979909\n",
      "\tspeed: 0.6072s/iter; left time: 11585.3637s\n",
      "\titers: 200, epoch: 15 | loss: 0.0989413\n",
      "\tspeed: 0.1864s/iter; left time: 3537.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 223 | Train Loss: 0.0991421 Vali Loss: 0.1224687 Test Loss: 0.1503336\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0992032\n",
      "\tspeed: 0.5397s/iter; left time: 10176.6253s\n",
      "\titers: 200, epoch: 16 | loss: 0.0969575\n",
      "\tspeed: 0.1721s/iter; left time: 3227.8436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.38s\n",
      "Steps: 223 | Train Loss: 0.0988860 Vali Loss: 0.1225571 Test Loss: 0.1509262\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0961994\n",
      "\tspeed: 0.5721s/iter; left time: 10660.3549s\n",
      "\titers: 200, epoch: 17 | loss: 0.0982187\n",
      "\tspeed: 0.1421s/iter; left time: 2633.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:33.36s\n",
      "Steps: 223 | Train Loss: 0.0985715 Vali Loss: 0.1225072 Test Loss: 0.1499307\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04548247531056404, rmse:0.21326620876789093, mae:0.14744102954864502, rse:0.7394245862960815\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1482336\n",
      "\tspeed: 0.1888s/iter; left time: 4191.8406s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329430\n",
      "\tspeed: 0.1692s/iter; left time: 3739.5150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 223 | Train Loss: 0.1461992 Vali Loss: 0.1411567 Test Loss: 0.1666802\n",
      "Validation loss decreased (inf --> 0.141157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1129525\n",
      "\tspeed: 0.5704s/iter; left time: 12537.1494s\n",
      "\titers: 200, epoch: 2 | loss: 0.1096142\n",
      "\tspeed: 0.1758s/iter; left time: 3846.9241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.63s\n",
      "Steps: 223 | Train Loss: 0.1152861 Vali Loss: 0.1229858 Test Loss: 0.1474020\n",
      "Validation loss decreased (0.141157 --> 0.122986).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1078742\n",
      "\tspeed: 0.5912s/iter; left time: 12861.5149s\n",
      "\titers: 200, epoch: 3 | loss: 0.1125078\n",
      "\tspeed: 0.1744s/iter; left time: 3776.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 223 | Train Loss: 0.1093150 Vali Loss: 0.1221120 Test Loss: 0.1470503\n",
      "Validation loss decreased (0.122986 --> 0.122112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1082627\n",
      "\tspeed: 0.2431s/iter; left time: 5233.4711s\n",
      "\titers: 200, epoch: 4 | loss: 0.1044651\n",
      "\tspeed: 0.0196s/iter; left time: 419.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.1075973 Vali Loss: 0.1214756 Test Loss: 0.1476164\n",
      "Validation loss decreased (0.122112 --> 0.121476).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1025503\n",
      "\tspeed: 0.0508s/iter; left time: 1082.0440s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008863\n",
      "\tspeed: 0.0177s/iter; left time: 376.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.34s\n",
      "Steps: 223 | Train Loss: 0.1060826 Vali Loss: 0.1215398 Test Loss: 0.1481340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1024763\n",
      "\tspeed: 0.0420s/iter; left time: 886.1248s\n",
      "\titers: 200, epoch: 6 | loss: 0.1056562\n",
      "\tspeed: 0.0176s/iter; left time: 368.6333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.24s\n",
      "Steps: 223 | Train Loss: 0.1048202 Vali Loss: 0.1220085 Test Loss: 0.1482165\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1073380\n",
      "\tspeed: 0.0406s/iter; left time: 846.5497s\n",
      "\titers: 200, epoch: 7 | loss: 0.1033433\n",
      "\tspeed: 0.0175s/iter; left time: 363.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.21s\n",
      "Steps: 223 | Train Loss: 0.1037267 Vali Loss: 0.1217567 Test Loss: 0.1494698\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1025141\n",
      "\tspeed: 0.0403s/iter; left time: 832.1615s\n",
      "\titers: 200, epoch: 8 | loss: 0.1014851\n",
      "\tspeed: 0.0176s/iter; left time: 360.8063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.20s\n",
      "Steps: 223 | Train Loss: 0.1027552 Vali Loss: 0.1213167 Test Loss: 0.1502217\n",
      "Validation loss decreased (0.121476 --> 0.121317).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1035220\n",
      "\tspeed: 0.0404s/iter; left time: 824.2079s\n",
      "\titers: 200, epoch: 9 | loss: 0.0998949\n",
      "\tspeed: 0.0175s/iter; left time: 354.6522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1020255 Vali Loss: 0.1216063 Test Loss: 0.1508289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1041638\n",
      "\tspeed: 0.0395s/iter; left time: 798.3969s\n",
      "\titers: 200, epoch: 10 | loss: 0.1009678\n",
      "\tspeed: 0.0174s/iter; left time: 349.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.1012701 Vali Loss: 0.1218095 Test Loss: 0.1510347\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1021368\n",
      "\tspeed: 0.0390s/iter; left time: 779.7368s\n",
      "\titers: 200, epoch: 11 | loss: 0.0983129\n",
      "\tspeed: 0.0174s/iter; left time: 346.1519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.15s\n",
      "Steps: 223 | Train Loss: 0.1007042 Vali Loss: 0.1215735 Test Loss: 0.1509421\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0982807\n",
      "\tspeed: 0.0384s/iter; left time: 759.1090s\n",
      "\titers: 200, epoch: 12 | loss: 0.0970041\n",
      "\tspeed: 0.0175s/iter; left time: 343.1640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.14s\n",
      "Steps: 223 | Train Loss: 0.1001431 Vali Loss: 0.1217044 Test Loss: 0.1500687\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0993334\n",
      "\tspeed: 0.0401s/iter; left time: 782.6868s\n",
      "\titers: 200, epoch: 13 | loss: 0.0995143\n",
      "\tspeed: 0.0174s/iter; left time: 338.4589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0995548 Vali Loss: 0.1217058 Test Loss: 0.1512485\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0973570\n",
      "\tspeed: 0.0387s/iter; left time: 747.2182s\n",
      "\titers: 200, epoch: 14 | loss: 0.0990187\n",
      "\tspeed: 0.0174s/iter; left time: 334.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.16s\n",
      "Steps: 223 | Train Loss: 0.0990940 Vali Loss: 0.1220706 Test Loss: 0.1521041\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1006069\n",
      "\tspeed: 0.0387s/iter; left time: 737.5224s\n",
      "\titers: 200, epoch: 15 | loss: 0.0981848\n",
      "\tspeed: 0.0191s/iter; left time: 363.1306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.31s\n",
      "Steps: 223 | Train Loss: 0.0986910 Vali Loss: 0.1226799 Test Loss: 0.1513366\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0993160\n",
      "\tspeed: 0.0388s/iter; left time: 730.9551s\n",
      "\titers: 200, epoch: 16 | loss: 0.0979478\n",
      "\tspeed: 0.0174s/iter; left time: 326.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.13s\n",
      "Steps: 223 | Train Loss: 0.0982535 Vali Loss: 0.1225123 Test Loss: 0.1517763\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0984739\n",
      "\tspeed: 0.0390s/iter; left time: 727.1391s\n",
      "\titers: 200, epoch: 17 | loss: 0.0959666\n",
      "\tspeed: 0.0175s/iter; left time: 325.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.18s\n",
      "Steps: 223 | Train Loss: 0.0979072 Vali Loss: 0.1228554 Test Loss: 0.1526561\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0991124\n",
      "\tspeed: 0.0389s/iter; left time: 715.6767s\n",
      "\titers: 200, epoch: 18 | loss: 0.0975065\n",
      "\tspeed: 0.0354s/iter; left time: 648.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 223 | Train Loss: 0.0976403 Vali Loss: 0.1224059 Test Loss: 0.1518670\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.047296199947595596, rmse:0.21747688949108124, mae:0.15022163093090057, rse:0.7540236711502075\n",
      "Intermediate time for GB and pred_len 168: 00h:13m:16.79s\n",
      "Intermediate time for GB: 00h:23m:23.57s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1494770\n",
      "\tspeed: 0.0293s/iter; left time: 653.3356s\n",
      "\titers: 200, epoch: 1 | loss: 0.1274537\n",
      "\tspeed: 0.0114s/iter; left time: 254.0236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.1528605 Vali Loss: 0.1144877 Test Loss: 0.1285769\n",
      "Validation loss decreased (inf --> 0.114488).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0765437\n",
      "\tspeed: 0.0270s/iter; left time: 595.2536s\n",
      "\titers: 200, epoch: 2 | loss: 0.0665579\n",
      "\tspeed: 0.0112s/iter; left time: 246.7454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0811992 Vali Loss: 0.0652718 Test Loss: 0.0723863\n",
      "Validation loss decreased (0.114488 --> 0.065272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0697450\n",
      "\tspeed: 0.0268s/iter; left time: 585.2117s\n",
      "\titers: 200, epoch: 3 | loss: 0.0660162\n",
      "\tspeed: 0.0112s/iter; left time: 244.6899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0678131 Vali Loss: 0.0617073 Test Loss: 0.0685091\n",
      "Validation loss decreased (0.065272 --> 0.061707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611825\n",
      "\tspeed: 0.0265s/iter; left time: 573.4070s\n",
      "\titers: 200, epoch: 4 | loss: 0.0663184\n",
      "\tspeed: 0.0114s/iter; left time: 245.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0643569 Vali Loss: 0.0592894 Test Loss: 0.0658884\n",
      "Validation loss decreased (0.061707 --> 0.059289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620450\n",
      "\tspeed: 0.0268s/iter; left time: 574.0366s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624085\n",
      "\tspeed: 0.0114s/iter; left time: 242.5387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0622190 Vali Loss: 0.0580893 Test Loss: 0.0645561\n",
      "Validation loss decreased (0.059289 --> 0.058089).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605343\n",
      "\tspeed: 0.0269s/iter; left time: 569.7609s\n",
      "\titers: 200, epoch: 6 | loss: 0.0587551\n",
      "\tspeed: 0.0115s/iter; left time: 242.8275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0572285 Test Loss: 0.0637012\n",
      "Validation loss decreased (0.058089 --> 0.057228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0607917\n",
      "\tspeed: 0.0266s/iter; left time: 557.0231s\n",
      "\titers: 200, epoch: 7 | loss: 0.0628559\n",
      "\tspeed: 0.0116s/iter; left time: 242.5836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0597911 Vali Loss: 0.0568611 Test Loss: 0.0632574\n",
      "Validation loss decreased (0.057228 --> 0.056861).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585717\n",
      "\tspeed: 0.0273s/iter; left time: 566.1050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0590016\n",
      "\tspeed: 0.0114s/iter; left time: 234.7951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0589440 Vali Loss: 0.0562228 Test Loss: 0.0624446\n",
      "Validation loss decreased (0.056861 --> 0.056223).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0570429\n",
      "\tspeed: 0.0274s/iter; left time: 560.9366s\n",
      "\titers: 200, epoch: 9 | loss: 0.0550695\n",
      "\tspeed: 0.0114s/iter; left time: 231.7856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0582554 Vali Loss: 0.0558884 Test Loss: 0.0622871\n",
      "Validation loss decreased (0.056223 --> 0.055888).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0585720\n",
      "\tspeed: 0.0272s/iter; left time: 551.7394s\n",
      "\titers: 200, epoch: 10 | loss: 0.0569206\n",
      "\tspeed: 0.0113s/iter; left time: 228.6478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0577634 Vali Loss: 0.0553971 Test Loss: 0.0617752\n",
      "Validation loss decreased (0.055888 --> 0.055397).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0591369\n",
      "\tspeed: 0.0284s/iter; left time: 569.1511s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592699\n",
      "\tspeed: 0.0128s/iter; left time: 254.8793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0572746 Vali Loss: 0.0550906 Test Loss: 0.0615792\n",
      "Validation loss decreased (0.055397 --> 0.055091).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0612531\n",
      "\tspeed: 0.0271s/iter; left time: 537.3180s\n",
      "\titers: 200, epoch: 12 | loss: 0.0553235\n",
      "\tspeed: 0.0113s/iter; left time: 223.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0567800 Vali Loss: 0.0550882 Test Loss: 0.0614859\n",
      "Validation loss decreased (0.055091 --> 0.055088).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0574471\n",
      "\tspeed: 0.0280s/iter; left time: 548.5447s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576361\n",
      "\tspeed: 0.0113s/iter; left time: 221.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0565321 Vali Loss: 0.0548449 Test Loss: 0.0614008\n",
      "Validation loss decreased (0.055088 --> 0.054845).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0557640\n",
      "\tspeed: 0.0270s/iter; left time: 523.7064s\n",
      "\titers: 200, epoch: 14 | loss: 0.0564044\n",
      "\tspeed: 0.0113s/iter; left time: 217.8378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0562479 Vali Loss: 0.0548242 Test Loss: 0.0611537\n",
      "Validation loss decreased (0.054845 --> 0.054824).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0533020\n",
      "\tspeed: 0.0310s/iter; left time: 594.0006s\n",
      "\titers: 200, epoch: 15 | loss: 0.0543857\n",
      "\tspeed: 0.0112s/iter; left time: 214.1662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0559401 Vali Loss: 0.0545402 Test Loss: 0.0610489\n",
      "Validation loss decreased (0.054824 --> 0.054540).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0609088\n",
      "\tspeed: 0.0274s/iter; left time: 518.5474s\n",
      "\titers: 200, epoch: 16 | loss: 0.0545612\n",
      "\tspeed: 0.0112s/iter; left time: 211.6617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0558091 Vali Loss: 0.0543885 Test Loss: 0.0608586\n",
      "Validation loss decreased (0.054540 --> 0.054389).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0537297\n",
      "\tspeed: 0.0272s/iter; left time: 509.2520s\n",
      "\titers: 200, epoch: 17 | loss: 0.0562503\n",
      "\tspeed: 0.0112s/iter; left time: 208.8348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0556262 Vali Loss: 0.0542731 Test Loss: 0.0607741\n",
      "Validation loss decreased (0.054389 --> 0.054273).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0572393\n",
      "\tspeed: 0.0266s/iter; left time: 491.2420s\n",
      "\titers: 200, epoch: 18 | loss: 0.0538083\n",
      "\tspeed: 0.0112s/iter; left time: 205.9848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0553770 Vali Loss: 0.0542938 Test Loss: 0.0607562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0543686\n",
      "\tspeed: 0.0263s/iter; left time: 479.8356s\n",
      "\titers: 200, epoch: 19 | loss: 0.0553563\n",
      "\tspeed: 0.0112s/iter; left time: 203.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0552918 Vali Loss: 0.0541263 Test Loss: 0.0606835\n",
      "Validation loss decreased (0.054273 --> 0.054126).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0580385\n",
      "\tspeed: 0.0264s/iter; left time: 476.3097s\n",
      "\titers: 200, epoch: 20 | loss: 0.0506126\n",
      "\tspeed: 0.0112s/iter; left time: 201.3260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0551724 Vali Loss: 0.0539999 Test Loss: 0.0603945\n",
      "Validation loss decreased (0.054126 --> 0.054000).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0582643\n",
      "\tspeed: 0.0275s/iter; left time: 490.1626s\n",
      "\titers: 200, epoch: 21 | loss: 0.0554577\n",
      "\tspeed: 0.0112s/iter; left time: 198.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0550136 Vali Loss: 0.0540128 Test Loss: 0.0604760\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0546076\n",
      "\tspeed: 0.0260s/iter; left time: 458.2561s\n",
      "\titers: 200, epoch: 22 | loss: 0.0565411\n",
      "\tspeed: 0.0112s/iter; left time: 196.2901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0548817 Vali Loss: 0.0539749 Test Loss: 0.0604030\n",
      "Validation loss decreased (0.054000 --> 0.053975).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0554973\n",
      "\tspeed: 0.0265s/iter; left time: 460.3344s\n",
      "\titers: 200, epoch: 23 | loss: 0.0558205\n",
      "\tspeed: 0.0112s/iter; left time: 193.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0548609 Vali Loss: 0.0538946 Test Loss: 0.0603620\n",
      "Validation loss decreased (0.053975 --> 0.053895).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0533115\n",
      "\tspeed: 0.0268s/iter; left time: 459.6479s\n",
      "\titers: 200, epoch: 24 | loss: 0.0573804\n",
      "\tspeed: 0.0115s/iter; left time: 195.9391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0547190 Vali Loss: 0.0539102 Test Loss: 0.0602858\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0496125\n",
      "\tspeed: 0.0261s/iter; left time: 441.5271s\n",
      "\titers: 200, epoch: 25 | loss: 0.0556968\n",
      "\tspeed: 0.0112s/iter; left time: 188.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0547353 Vali Loss: 0.0539490 Test Loss: 0.0603437\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0583126\n",
      "\tspeed: 0.0261s/iter; left time: 436.5477s\n",
      "\titers: 200, epoch: 26 | loss: 0.0542569\n",
      "\tspeed: 0.0112s/iter; left time: 186.1359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0546250 Vali Loss: 0.0538260 Test Loss: 0.0602104\n",
      "Validation loss decreased (0.053895 --> 0.053826).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0572964\n",
      "\tspeed: 0.0266s/iter; left time: 437.5790s\n",
      "\titers: 200, epoch: 27 | loss: 0.0549415\n",
      "\tspeed: 0.0112s/iter; left time: 183.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0545951 Vali Loss: 0.0537597 Test Loss: 0.0601757\n",
      "Validation loss decreased (0.053826 --> 0.053760).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0536598\n",
      "\tspeed: 0.0270s/iter; left time: 438.2534s\n",
      "\titers: 200, epoch: 28 | loss: 0.0547956\n",
      "\tspeed: 0.0112s/iter; left time: 181.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0545621 Vali Loss: 0.0537530 Test Loss: 0.0601665\n",
      "Validation loss decreased (0.053760 --> 0.053753).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0556514\n",
      "\tspeed: 0.0260s/iter; left time: 416.8887s\n",
      "\titers: 200, epoch: 29 | loss: 0.0529170\n",
      "\tspeed: 0.0112s/iter; left time: 178.3765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 224 | Train Loss: 0.0544709 Vali Loss: 0.0538123 Test Loss: 0.0601161\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0533088\n",
      "\tspeed: 0.0268s/iter; left time: 423.4925s\n",
      "\titers: 200, epoch: 30 | loss: 0.0519441\n",
      "\tspeed: 0.0112s/iter; left time: 176.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0544302 Vali Loss: 0.0537146 Test Loss: 0.0601225\n",
      "Validation loss decreased (0.053753 --> 0.053715).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0541733\n",
      "\tspeed: 0.0274s/iter; left time: 426.2309s\n",
      "\titers: 200, epoch: 31 | loss: 0.0555571\n",
      "\tspeed: 0.0113s/iter; left time: 174.3200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0543628 Vali Loss: 0.0536728 Test Loss: 0.0600829\n",
      "Validation loss decreased (0.053715 --> 0.053673).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0529801\n",
      "\tspeed: 0.0274s/iter; left time: 420.5325s\n",
      "\titers: 200, epoch: 32 | loss: 0.0546520\n",
      "\tspeed: 0.0113s/iter; left time: 172.1194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0543544 Vali Loss: 0.0536983 Test Loss: 0.0601135\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0534263\n",
      "\tspeed: 0.0270s/iter; left time: 409.2479s\n",
      "\titers: 200, epoch: 33 | loss: 0.0562974\n",
      "\tspeed: 0.0112s/iter; left time: 168.8237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0542939 Vali Loss: 0.0537160 Test Loss: 0.0599725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0540499\n",
      "\tspeed: 0.0271s/iter; left time: 403.5567s\n",
      "\titers: 200, epoch: 34 | loss: 0.0582170\n",
      "\tspeed: 0.0112s/iter; left time: 166.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0542774 Vali Loss: 0.0536529 Test Loss: 0.0600538\n",
      "Validation loss decreased (0.053673 --> 0.053653).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0548191\n",
      "\tspeed: 0.0272s/iter; left time: 399.5021s\n",
      "\titers: 200, epoch: 35 | loss: 0.0521856\n",
      "\tspeed: 0.0114s/iter; left time: 166.1747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0542461 Vali Loss: 0.0536224 Test Loss: 0.0599819\n",
      "Validation loss decreased (0.053653 --> 0.053622).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0551268\n",
      "\tspeed: 0.0270s/iter; left time: 390.3002s\n",
      "\titers: 200, epoch: 36 | loss: 0.0511006\n",
      "\tspeed: 0.0112s/iter; left time: 160.8843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0542382 Vali Loss: 0.0536401 Test Loss: 0.0599571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0531337\n",
      "\tspeed: 0.0261s/iter; left time: 371.3320s\n",
      "\titers: 200, epoch: 37 | loss: 0.0547423\n",
      "\tspeed: 0.0112s/iter; left time: 158.8714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0542553 Vali Loss: 0.0536260 Test Loss: 0.0599756\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0535780\n",
      "\tspeed: 0.0262s/iter; left time: 367.4607s\n",
      "\titers: 200, epoch: 38 | loss: 0.0540706\n",
      "\tspeed: 0.0112s/iter; left time: 155.8161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0541586 Vali Loss: 0.0536272 Test Loss: 0.0600406\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0525786\n",
      "\tspeed: 0.0271s/iter; left time: 373.8426s\n",
      "\titers: 200, epoch: 39 | loss: 0.0523348\n",
      "\tspeed: 0.0112s/iter; left time: 153.6733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0542093 Vali Loss: 0.0535640 Test Loss: 0.0599691\n",
      "Validation loss decreased (0.053622 --> 0.053564).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0530525\n",
      "\tspeed: 0.0273s/iter; left time: 370.9006s\n",
      "\titers: 200, epoch: 40 | loss: 0.0517619\n",
      "\tspeed: 0.0112s/iter; left time: 150.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0542139 Vali Loss: 0.0535969 Test Loss: 0.0599620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0545805\n",
      "\tspeed: 0.0265s/iter; left time: 353.2663s\n",
      "\titers: 200, epoch: 41 | loss: 0.0545226\n",
      "\tspeed: 0.0112s/iter; left time: 148.6263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0541434 Vali Loss: 0.0536054 Test Loss: 0.0599443\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0536046\n",
      "\tspeed: 0.0262s/iter; left time: 343.8742s\n",
      "\titers: 200, epoch: 42 | loss: 0.0537292\n",
      "\tspeed: 0.0112s/iter; left time: 146.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0541200 Vali Loss: 0.0536159 Test Loss: 0.0599863\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0529255\n",
      "\tspeed: 0.0263s/iter; left time: 338.8629s\n",
      "\titers: 200, epoch: 43 | loss: 0.0564435\n",
      "\tspeed: 0.0115s/iter; left time: 146.6514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0541575 Vali Loss: 0.0536216 Test Loss: 0.0599966\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0581362\n",
      "\tspeed: 0.0261s/iter; left time: 330.3998s\n",
      "\titers: 200, epoch: 44 | loss: 0.0559508\n",
      "\tspeed: 0.0112s/iter; left time: 141.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0541555 Vali Loss: 0.0535124 Test Loss: 0.0600077\n",
      "Validation loss decreased (0.053564 --> 0.053512).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0564229\n",
      "\tspeed: 0.0290s/iter; left time: 361.0631s\n",
      "\titers: 200, epoch: 45 | loss: 0.0558010\n",
      "\tspeed: 0.0114s/iter; left time: 141.2485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0541609 Vali Loss: 0.0536338 Test Loss: 0.0600080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0529164\n",
      "\tspeed: 0.0276s/iter; left time: 337.2588s\n",
      "\titers: 200, epoch: 46 | loss: 0.0579805\n",
      "\tspeed: 0.0114s/iter; left time: 138.2396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0541587 Vali Loss: 0.0535361 Test Loss: 0.0599453\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0525720\n",
      "\tspeed: 0.0269s/iter; left time: 322.1557s\n",
      "\titers: 200, epoch: 47 | loss: 0.0534824\n",
      "\tspeed: 0.0115s/iter; left time: 136.7944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0541336 Vali Loss: 0.0535486 Test Loss: 0.0599519\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0558678\n",
      "\tspeed: 0.0286s/iter; left time: 336.6418s\n",
      "\titers: 200, epoch: 48 | loss: 0.0530399\n",
      "\tspeed: 0.0114s/iter; left time: 133.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0541394 Vali Loss: 0.0535392 Test Loss: 0.0599605\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0553967\n",
      "\tspeed: 0.0291s/iter; left time: 336.4127s\n",
      "\titers: 200, epoch: 49 | loss: 0.0558583\n",
      "\tspeed: 0.0113s/iter; left time: 128.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0541153 Vali Loss: 0.0535242 Test Loss: 0.0599426\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0526230\n",
      "\tspeed: 0.0277s/iter; left time: 313.1631s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539039\n",
      "\tspeed: 0.0113s/iter; left time: 127.3694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0540899 Vali Loss: 0.0535815 Test Loss: 0.0599829\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0548446\n",
      "\tspeed: 0.0281s/iter; left time: 311.4856s\n",
      "\titers: 200, epoch: 51 | loss: 0.0546494\n",
      "\tspeed: 0.0116s/iter; left time: 127.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0540314 Vali Loss: 0.0535134 Test Loss: 0.0599339\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0532394\n",
      "\tspeed: 0.0279s/iter; left time: 302.9963s\n",
      "\titers: 200, epoch: 52 | loss: 0.0547640\n",
      "\tspeed: 0.0112s/iter; left time: 121.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0540867 Vali Loss: 0.0535719 Test Loss: 0.0598737\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0551326\n",
      "\tspeed: 0.0292s/iter; left time: 311.0748s\n",
      "\titers: 200, epoch: 53 | loss: 0.0537917\n",
      "\tspeed: 0.0111s/iter; left time: 117.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0541156 Vali Loss: 0.0535578 Test Loss: 0.0599764\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0526593\n",
      "\tspeed: 0.0265s/iter; left time: 275.9986s\n",
      "\titers: 200, epoch: 54 | loss: 0.0545212\n",
      "\tspeed: 0.0113s/iter; left time: 116.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0540693 Vali Loss: 0.0536068 Test Loss: 0.0599520\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009862286038696766, rmse:0.099309042096138, mae:0.06000771373510361, rse:0.2922545075416565\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1616312\n",
      "\tspeed: 0.0135s/iter; left time: 300.5250s\n",
      "\titers: 200, epoch: 1 | loss: 0.1268028\n",
      "\tspeed: 0.0112s/iter; left time: 249.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.1587772 Vali Loss: 0.1166928 Test Loss: 0.1332514\n",
      "Validation loss decreased (inf --> 0.116693).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0775314\n",
      "\tspeed: 0.0257s/iter; left time: 567.6015s\n",
      "\titers: 200, epoch: 2 | loss: 0.0713925\n",
      "\tspeed: 0.0112s/iter; left time: 246.0237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0807692 Vali Loss: 0.0650024 Test Loss: 0.0717942\n",
      "Validation loss decreased (0.116693 --> 0.065002).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662167\n",
      "\tspeed: 0.0259s/iter; left time: 566.4843s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641782\n",
      "\tspeed: 0.0112s/iter; left time: 243.5082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0673719 Vali Loss: 0.0611292 Test Loss: 0.0678452\n",
      "Validation loss decreased (0.065002 --> 0.061129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0642227\n",
      "\tspeed: 0.0261s/iter; left time: 564.5536s\n",
      "\titers: 200, epoch: 4 | loss: 0.0637685\n",
      "\tspeed: 0.0112s/iter; left time: 241.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0640868 Vali Loss: 0.0591971 Test Loss: 0.0657261\n",
      "Validation loss decreased (0.061129 --> 0.059197).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0632296\n",
      "\tspeed: 0.0262s/iter; left time: 561.4831s\n",
      "\titers: 200, epoch: 5 | loss: 0.0592473\n",
      "\tspeed: 0.0114s/iter; left time: 243.4007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0621609 Vali Loss: 0.0580492 Test Loss: 0.0645020\n",
      "Validation loss decreased (0.059197 --> 0.058049).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0625181\n",
      "\tspeed: 0.0261s/iter; left time: 553.0885s\n",
      "\titers: 200, epoch: 6 | loss: 0.0610487\n",
      "\tspeed: 0.0112s/iter; left time: 235.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0607551 Vali Loss: 0.0576803 Test Loss: 0.0640908\n",
      "Validation loss decreased (0.058049 --> 0.057680).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0595791\n",
      "\tspeed: 0.0262s/iter; left time: 549.9119s\n",
      "\titers: 200, epoch: 7 | loss: 0.0616701\n",
      "\tspeed: 0.0113s/iter; left time: 235.0510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0597895 Vali Loss: 0.0565401 Test Loss: 0.0629565\n",
      "Validation loss decreased (0.057680 --> 0.056540).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0572647\n",
      "\tspeed: 0.0267s/iter; left time: 552.5384s\n",
      "\titers: 200, epoch: 8 | loss: 0.0550913\n",
      "\tspeed: 0.0112s/iter; left time: 231.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0589233 Vali Loss: 0.0559721 Test Loss: 0.0624422\n",
      "Validation loss decreased (0.056540 --> 0.055972).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0604779\n",
      "\tspeed: 0.0265s/iter; left time: 543.0956s\n",
      "\titers: 200, epoch: 9 | loss: 0.0584860\n",
      "\tspeed: 0.0112s/iter; left time: 228.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0582582 Vali Loss: 0.0556693 Test Loss: 0.0622265\n",
      "Validation loss decreased (0.055972 --> 0.055669).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548977\n",
      "\tspeed: 0.0259s/iter; left time: 525.2087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0598079\n",
      "\tspeed: 0.0112s/iter; left time: 226.5266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0576654 Vali Loss: 0.0554317 Test Loss: 0.0617219\n",
      "Validation loss decreased (0.055669 --> 0.055432).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559494\n",
      "\tspeed: 0.0262s/iter; left time: 525.7427s\n",
      "\titers: 200, epoch: 11 | loss: 0.0553739\n",
      "\tspeed: 0.0112s/iter; left time: 224.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0572015 Vali Loss: 0.0551642 Test Loss: 0.0615186\n",
      "Validation loss decreased (0.055432 --> 0.055164).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0560272\n",
      "\tspeed: 0.0259s/iter; left time: 514.3705s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523639\n",
      "\tspeed: 0.0112s/iter; left time: 221.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0568153 Vali Loss: 0.0549070 Test Loss: 0.0613121\n",
      "Validation loss decreased (0.055164 --> 0.054907).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0586234\n",
      "\tspeed: 0.0264s/iter; left time: 516.8581s\n",
      "\titers: 200, epoch: 13 | loss: 0.0606698\n",
      "\tspeed: 0.0112s/iter; left time: 218.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0565045 Vali Loss: 0.0545902 Test Loss: 0.0612054\n",
      "Validation loss decreased (0.054907 --> 0.054590).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0568536\n",
      "\tspeed: 0.0262s/iter; left time: 507.8143s\n",
      "\titers: 200, epoch: 14 | loss: 0.0555497\n",
      "\tspeed: 0.0112s/iter; left time: 216.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0562225 Vali Loss: 0.0544734 Test Loss: 0.0610235\n",
      "Validation loss decreased (0.054590 --> 0.054473).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0567656\n",
      "\tspeed: 0.0267s/iter; left time: 512.0280s\n",
      "\titers: 200, epoch: 15 | loss: 0.0552110\n",
      "\tspeed: 0.0114s/iter; left time: 217.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0559339 Vali Loss: 0.0544358 Test Loss: 0.0610027\n",
      "Validation loss decreased (0.054473 --> 0.054436).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0569726\n",
      "\tspeed: 0.0262s/iter; left time: 495.8150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0560292\n",
      "\tspeed: 0.0112s/iter; left time: 211.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0557953 Vali Loss: 0.0543780 Test Loss: 0.0609334\n",
      "Validation loss decreased (0.054436 --> 0.054378).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0529792\n",
      "\tspeed: 0.0262s/iter; left time: 490.2293s\n",
      "\titers: 200, epoch: 17 | loss: 0.0571565\n",
      "\tspeed: 0.0113s/iter; left time: 209.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0555849 Vali Loss: 0.0542471 Test Loss: 0.0607671\n",
      "Validation loss decreased (0.054378 --> 0.054247).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0557929\n",
      "\tspeed: 0.0260s/iter; left time: 480.7536s\n",
      "\titers: 200, epoch: 18 | loss: 0.0570705\n",
      "\tspeed: 0.0113s/iter; left time: 207.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0554244 Vali Loss: 0.0542962 Test Loss: 0.0607673\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0556748\n",
      "\tspeed: 0.0255s/iter; left time: 466.3520s\n",
      "\titers: 200, epoch: 19 | loss: 0.0566410\n",
      "\tspeed: 0.0112s/iter; left time: 203.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0553082 Vali Loss: 0.0542234 Test Loss: 0.0607002\n",
      "Validation loss decreased (0.054247 --> 0.054223).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0530097\n",
      "\tspeed: 0.0260s/iter; left time: 469.9345s\n",
      "\titers: 200, epoch: 20 | loss: 0.0574891\n",
      "\tspeed: 0.0112s/iter; left time: 201.2285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0551558 Vali Loss: 0.0539742 Test Loss: 0.0605518\n",
      "Validation loss decreased (0.054223 --> 0.053974).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0533590\n",
      "\tspeed: 0.0299s/iter; left time: 533.1636s\n",
      "\titers: 200, epoch: 21 | loss: 0.0556851\n",
      "\tspeed: 0.0112s/iter; left time: 199.2975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0549968 Vali Loss: 0.0540330 Test Loss: 0.0606103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0552667\n",
      "\tspeed: 0.0265s/iter; left time: 465.6673s\n",
      "\titers: 200, epoch: 22 | loss: 0.0588599\n",
      "\tspeed: 0.0113s/iter; left time: 196.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0549233 Vali Loss: 0.0538995 Test Loss: 0.0604213\n",
      "Validation loss decreased (0.053974 --> 0.053899).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0527139\n",
      "\tspeed: 0.0267s/iter; left time: 463.1414s\n",
      "\titers: 200, epoch: 23 | loss: 0.0536404\n",
      "\tspeed: 0.0112s/iter; left time: 194.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0548388 Vali Loss: 0.0539061 Test Loss: 0.0603897\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0566915\n",
      "\tspeed: 0.0307s/iter; left time: 526.9267s\n",
      "\titers: 200, epoch: 24 | loss: 0.0549551\n",
      "\tspeed: 0.0114s/iter; left time: 193.5202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0547820 Vali Loss: 0.0538374 Test Loss: 0.0603987\n",
      "Validation loss decreased (0.053899 --> 0.053837).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0547276\n",
      "\tspeed: 0.0264s/iter; left time: 447.2074s\n",
      "\titers: 200, epoch: 25 | loss: 0.0585644\n",
      "\tspeed: 0.0115s/iter; left time: 194.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0547840 Vali Loss: 0.0538295 Test Loss: 0.0602589\n",
      "Validation loss decreased (0.053837 --> 0.053830).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0539689\n",
      "\tspeed: 0.0264s/iter; left time: 440.9936s\n",
      "\titers: 200, epoch: 26 | loss: 0.0497977\n",
      "\tspeed: 0.0112s/iter; left time: 186.3737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0546523 Vali Loss: 0.0537706 Test Loss: 0.0603272\n",
      "Validation loss decreased (0.053830 --> 0.053771).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0553499\n",
      "\tspeed: 0.0262s/iter; left time: 431.4485s\n",
      "\titers: 200, epoch: 27 | loss: 0.0532208\n",
      "\tspeed: 0.0113s/iter; left time: 184.2898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0546224 Vali Loss: 0.0537843 Test Loss: 0.0602787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0517212\n",
      "\tspeed: 0.0266s/iter; left time: 433.0715s\n",
      "\titers: 200, epoch: 28 | loss: 0.0533430\n",
      "\tspeed: 0.0112s/iter; left time: 181.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0545121 Vali Loss: 0.0537198 Test Loss: 0.0603058\n",
      "Validation loss decreased (0.053771 --> 0.053720).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0573367\n",
      "\tspeed: 0.0280s/iter; left time: 449.2322s\n",
      "\titers: 200, epoch: 29 | loss: 0.0570211\n",
      "\tspeed: 0.0112s/iter; left time: 178.4957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0545019 Vali Loss: 0.0538381 Test Loss: 0.0602355\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0547797\n",
      "\tspeed: 0.0255s/iter; left time: 402.6885s\n",
      "\titers: 200, epoch: 30 | loss: 0.0537057\n",
      "\tspeed: 0.0112s/iter; left time: 175.6011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0544426 Vali Loss: 0.0537189 Test Loss: 0.0601404\n",
      "Validation loss decreased (0.053720 --> 0.053719).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0553422\n",
      "\tspeed: 0.0258s/iter; left time: 401.7408s\n",
      "\titers: 200, epoch: 31 | loss: 0.0539733\n",
      "\tspeed: 0.0112s/iter; left time: 173.5451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0544381 Vali Loss: 0.0537475 Test Loss: 0.0602033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0524785\n",
      "\tspeed: 0.0256s/iter; left time: 393.8323s\n",
      "\titers: 200, epoch: 32 | loss: 0.0537987\n",
      "\tspeed: 0.0112s/iter; left time: 171.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0544146 Vali Loss: 0.0537483 Test Loss: 0.0602193\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0534074\n",
      "\tspeed: 0.0258s/iter; left time: 390.4631s\n",
      "\titers: 200, epoch: 33 | loss: 0.0558754\n",
      "\tspeed: 0.0112s/iter; left time: 168.0515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0543704 Vali Loss: 0.0536938 Test Loss: 0.0601097\n",
      "Validation loss decreased (0.053719 --> 0.053694).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0550879\n",
      "\tspeed: 0.0260s/iter; left time: 387.1207s\n",
      "\titers: 200, epoch: 34 | loss: 0.0578311\n",
      "\tspeed: 0.0112s/iter; left time: 166.1602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0543395 Vali Loss: 0.0536585 Test Loss: 0.0601655\n",
      "Validation loss decreased (0.053694 --> 0.053659).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0561146\n",
      "\tspeed: 0.0262s/iter; left time: 384.9904s\n",
      "\titers: 200, epoch: 35 | loss: 0.0497176\n",
      "\tspeed: 0.0112s/iter; left time: 163.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0542746 Vali Loss: 0.0536390 Test Loss: 0.0601120\n",
      "Validation loss decreased (0.053659 --> 0.053639).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0574535\n",
      "\tspeed: 0.0264s/iter; left time: 381.7836s\n",
      "\titers: 200, epoch: 36 | loss: 0.0561297\n",
      "\tspeed: 0.0112s/iter; left time: 160.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0542984 Vali Loss: 0.0536583 Test Loss: 0.0600901\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0565096\n",
      "\tspeed: 0.0257s/iter; left time: 366.1249s\n",
      "\titers: 200, epoch: 37 | loss: 0.0537040\n",
      "\tspeed: 0.0112s/iter; left time: 158.3276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0542197 Vali Loss: 0.0536494 Test Loss: 0.0600951\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0541594\n",
      "\tspeed: 0.0256s/iter; left time: 358.7452s\n",
      "\titers: 200, epoch: 38 | loss: 0.0543582\n",
      "\tspeed: 0.0112s/iter; left time: 155.6922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.70s\n",
      "Steps: 224 | Train Loss: 0.0542173 Vali Loss: 0.0536799 Test Loss: 0.0601070\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0536897\n",
      "\tspeed: 0.0255s/iter; left time: 350.9874s\n",
      "\titers: 200, epoch: 39 | loss: 0.0549333\n",
      "\tspeed: 0.0112s/iter; left time: 153.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0542248 Vali Loss: 0.0536525 Test Loss: 0.0600947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0549562\n",
      "\tspeed: 0.0258s/iter; left time: 349.6626s\n",
      "\titers: 200, epoch: 40 | loss: 0.0511646\n",
      "\tspeed: 0.0114s/iter; left time: 153.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0542051 Vali Loss: 0.0535251 Test Loss: 0.0601042\n",
      "Validation loss decreased (0.053639 --> 0.053525).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0592025\n",
      "\tspeed: 0.0260s/iter; left time: 346.5532s\n",
      "\titers: 200, epoch: 41 | loss: 0.0546780\n",
      "\tspeed: 0.0112s/iter; left time: 148.0433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0541743 Vali Loss: 0.0536186 Test Loss: 0.0600484\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0551636\n",
      "\tspeed: 0.0259s/iter; left time: 339.6075s\n",
      "\titers: 200, epoch: 42 | loss: 0.0535085\n",
      "\tspeed: 0.0112s/iter; left time: 145.8917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0541917 Vali Loss: 0.0536826 Test Loss: 0.0601315\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0537008\n",
      "\tspeed: 0.0263s/iter; left time: 338.7609s\n",
      "\titers: 200, epoch: 43 | loss: 0.0555828\n",
      "\tspeed: 0.0114s/iter; left time: 145.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0541736 Vali Loss: 0.0536307 Test Loss: 0.0600563\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0541692\n",
      "\tspeed: 0.0269s/iter; left time: 340.7094s\n",
      "\titers: 200, epoch: 44 | loss: 0.0531680\n",
      "\tspeed: 0.0112s/iter; left time: 140.6959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0541764 Vali Loss: 0.0536253 Test Loss: 0.0601112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556184\n",
      "\tspeed: 0.0281s/iter; left time: 349.8735s\n",
      "\titers: 200, epoch: 45 | loss: 0.0536562\n",
      "\tspeed: 0.0126s/iter; left time: 155.2162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.0542042 Vali Loss: 0.0536543 Test Loss: 0.0600868\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0535693\n",
      "\tspeed: 0.0257s/iter; left time: 313.8280s\n",
      "\titers: 200, epoch: 46 | loss: 0.0522479\n",
      "\tspeed: 0.0113s/iter; left time: 136.9479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0541603 Vali Loss: 0.0535597 Test Loss: 0.0600303\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0528129\n",
      "\tspeed: 0.0259s/iter; left time: 310.8492s\n",
      "\titers: 200, epoch: 47 | loss: 0.0519045\n",
      "\tspeed: 0.0112s/iter; left time: 133.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0541718 Vali Loss: 0.0535700 Test Loss: 0.0600493\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0516170\n",
      "\tspeed: 0.0255s/iter; left time: 300.2483s\n",
      "\titers: 200, epoch: 48 | loss: 0.0534588\n",
      "\tspeed: 0.0112s/iter; left time: 130.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0541160 Vali Loss: 0.0535972 Test Loss: 0.0600190\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0544061\n",
      "\tspeed: 0.0258s/iter; left time: 297.4542s\n",
      "\titers: 200, epoch: 49 | loss: 0.0557179\n",
      "\tspeed: 0.0118s/iter; left time: 135.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0540811 Vali Loss: 0.0536488 Test Loss: 0.0600004\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0535855\n",
      "\tspeed: 0.0265s/iter; left time: 299.7916s\n",
      "\titers: 200, epoch: 50 | loss: 0.0539434\n",
      "\tspeed: 0.0112s/iter; left time: 125.7223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.71s\n",
      "Steps: 224 | Train Loss: 0.0541007 Vali Loss: 0.0536049 Test Loss: 0.0600496\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009904390200972557, rmse:0.09952080249786377, mae:0.06010424718260765, rse:0.2928776741027832\n",
      "Intermediate time for ES and pred_len 24: 00h:06m:44.34s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1600715\n",
      "\tspeed: 0.0295s/iter; left time: 657.7671s\n",
      "\titers: 200, epoch: 1 | loss: 0.1329738\n",
      "\tspeed: 0.0118s/iter; left time: 262.2289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.17s\n",
      "Steps: 224 | Train Loss: 0.1563259 Vali Loss: 0.1220047 Test Loss: 0.1377991\n",
      "Validation loss decreased (inf --> 0.122005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0986281\n",
      "\tspeed: 0.0281s/iter; left time: 620.3181s\n",
      "\titers: 200, epoch: 2 | loss: 0.0916502\n",
      "\tspeed: 0.0116s/iter; left time: 255.9049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0987325 Vali Loss: 0.0868770 Test Loss: 0.0978651\n",
      "Validation loss decreased (0.122005 --> 0.086877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0870886\n",
      "\tspeed: 0.0291s/iter; left time: 635.9196s\n",
      "\titers: 200, epoch: 3 | loss: 0.0855636\n",
      "\tspeed: 0.0120s/iter; left time: 261.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0874873 Vali Loss: 0.0815230 Test Loss: 0.0928167\n",
      "Validation loss decreased (0.086877 --> 0.081523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0859502\n",
      "\tspeed: 0.0287s/iter; left time: 621.6158s\n",
      "\titers: 200, epoch: 4 | loss: 0.0796197\n",
      "\tspeed: 0.0116s/iter; left time: 249.3421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0837237 Vali Loss: 0.0794888 Test Loss: 0.0907266\n",
      "Validation loss decreased (0.081523 --> 0.079489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0817280\n",
      "\tspeed: 0.0298s/iter; left time: 636.8645s\n",
      "\titers: 200, epoch: 5 | loss: 0.0827391\n",
      "\tspeed: 0.0116s/iter; left time: 248.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0817404 Vali Loss: 0.0787186 Test Loss: 0.0896066\n",
      "Validation loss decreased (0.079489 --> 0.078719).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0804231\n",
      "\tspeed: 0.0292s/iter; left time: 618.2093s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756826\n",
      "\tspeed: 0.0117s/iter; left time: 246.1427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0802827 Vali Loss: 0.0777990 Test Loss: 0.0888387\n",
      "Validation loss decreased (0.078719 --> 0.077799).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0785264\n",
      "\tspeed: 0.0292s/iter; left time: 611.2696s\n",
      "\titers: 200, epoch: 7 | loss: 0.0755876\n",
      "\tspeed: 0.0118s/iter; left time: 245.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0792729 Vali Loss: 0.0773480 Test Loss: 0.0884110\n",
      "Validation loss decreased (0.077799 --> 0.077348).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815148\n",
      "\tspeed: 0.0295s/iter; left time: 612.2944s\n",
      "\titers: 200, epoch: 8 | loss: 0.0805861\n",
      "\tspeed: 0.0130s/iter; left time: 268.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0784637 Vali Loss: 0.0769119 Test Loss: 0.0878655\n",
      "Validation loss decreased (0.077348 --> 0.076912).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0779870\n",
      "\tspeed: 0.0317s/iter; left time: 650.4822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0807751\n",
      "\tspeed: 0.0115s/iter; left time: 234.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0777863 Vali Loss: 0.0771217 Test Loss: 0.0875601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772136\n",
      "\tspeed: 0.0289s/iter; left time: 585.5173s\n",
      "\titers: 200, epoch: 10 | loss: 0.0758945\n",
      "\tspeed: 0.0133s/iter; left time: 268.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0772079 Vali Loss: 0.0772257 Test Loss: 0.0879205\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747496\n",
      "\tspeed: 0.0289s/iter; left time: 579.4329s\n",
      "\titers: 200, epoch: 11 | loss: 0.0791871\n",
      "\tspeed: 0.0115s/iter; left time: 230.2381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0767879 Vali Loss: 0.0771484 Test Loss: 0.0879905\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0762381\n",
      "\tspeed: 0.0285s/iter; left time: 566.2554s\n",
      "\titers: 200, epoch: 12 | loss: 0.0765716\n",
      "\tspeed: 0.0116s/iter; left time: 228.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0764095 Vali Loss: 0.0771252 Test Loss: 0.0876286\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0747886\n",
      "\tspeed: 0.0302s/iter; left time: 592.2205s\n",
      "\titers: 200, epoch: 13 | loss: 0.0747912\n",
      "\tspeed: 0.0116s/iter; left time: 225.3787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0760711 Vali Loss: 0.0773463 Test Loss: 0.0876072\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719230\n",
      "\tspeed: 0.0298s/iter; left time: 578.4748s\n",
      "\titers: 200, epoch: 14 | loss: 0.0747276\n",
      "\tspeed: 0.0116s/iter; left time: 222.9443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0758260 Vali Loss: 0.0770627 Test Loss: 0.0875556\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782677\n",
      "\tspeed: 0.0297s/iter; left time: 568.3232s\n",
      "\titers: 200, epoch: 15 | loss: 0.0764109\n",
      "\tspeed: 0.0115s/iter; left time: 219.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0754916 Vali Loss: 0.0771773 Test Loss: 0.0876015\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0736337\n",
      "\tspeed: 0.0300s/iter; left time: 567.4044s\n",
      "\titers: 200, epoch: 16 | loss: 0.0733995\n",
      "\tspeed: 0.0115s/iter; left time: 217.0574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0753228 Vali Loss: 0.0773426 Test Loss: 0.0875953\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0799747\n",
      "\tspeed: 0.0274s/iter; left time: 513.3787s\n",
      "\titers: 200, epoch: 17 | loss: 0.0749841\n",
      "\tspeed: 0.0115s/iter; left time: 213.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0750884 Vali Loss: 0.0775687 Test Loss: 0.0877661\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0765019\n",
      "\tspeed: 0.0279s/iter; left time: 516.3192s\n",
      "\titers: 200, epoch: 18 | loss: 0.0756694\n",
      "\tspeed: 0.0116s/iter; left time: 212.5229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0749176 Vali Loss: 0.0772072 Test Loss: 0.0875665\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018780911341309547, rmse:0.13704346120357513, mae:0.08786552399396896, rse:0.4025924503803253\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1601316\n",
      "\tspeed: 0.0140s/iter; left time: 311.7341s\n",
      "\titers: 200, epoch: 1 | loss: 0.1304595\n",
      "\tspeed: 0.0115s/iter; left time: 254.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.1566661 Vali Loss: 0.1233721 Test Loss: 0.1393741\n",
      "Validation loss decreased (inf --> 0.123372).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0955486\n",
      "\tspeed: 0.0278s/iter; left time: 612.9885s\n",
      "\titers: 200, epoch: 2 | loss: 0.0894783\n",
      "\tspeed: 0.0115s/iter; left time: 252.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0983929 Vali Loss: 0.0861697 Test Loss: 0.0973250\n",
      "Validation loss decreased (0.123372 --> 0.086170).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0887607\n",
      "\tspeed: 0.0281s/iter; left time: 613.8562s\n",
      "\titers: 200, epoch: 3 | loss: 0.0820354\n",
      "\tspeed: 0.0115s/iter; left time: 249.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0872108 Vali Loss: 0.0813447 Test Loss: 0.0928617\n",
      "Validation loss decreased (0.086170 --> 0.081345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0857283\n",
      "\tspeed: 0.0309s/iter; left time: 668.9262s\n",
      "\titers: 200, epoch: 4 | loss: 0.0806698\n",
      "\tspeed: 0.0115s/iter; left time: 248.0192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0836687 Vali Loss: 0.0795641 Test Loss: 0.0906829\n",
      "Validation loss decreased (0.081345 --> 0.079564).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0777771\n",
      "\tspeed: 0.0278s/iter; left time: 595.0151s\n",
      "\titers: 200, epoch: 5 | loss: 0.0843807\n",
      "\tspeed: 0.0115s/iter; left time: 246.0504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0816398 Vali Loss: 0.0783285 Test Loss: 0.0893582\n",
      "Validation loss decreased (0.079564 --> 0.078328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864370\n",
      "\tspeed: 0.0277s/iter; left time: 586.8022s\n",
      "\titers: 200, epoch: 6 | loss: 0.0826968\n",
      "\tspeed: 0.0115s/iter; left time: 242.7967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0802175 Vali Loss: 0.0777193 Test Loss: 0.0887649\n",
      "Validation loss decreased (0.078328 --> 0.077719).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0791327\n",
      "\tspeed: 0.0276s/iter; left time: 578.5842s\n",
      "\titers: 200, epoch: 7 | loss: 0.0790084\n",
      "\tspeed: 0.0115s/iter; left time: 240.4747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0792138 Vali Loss: 0.0774533 Test Loss: 0.0883232\n",
      "Validation loss decreased (0.077719 --> 0.077453).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0756879\n",
      "\tspeed: 0.0279s/iter; left time: 578.3117s\n",
      "\titers: 200, epoch: 8 | loss: 0.0778915\n",
      "\tspeed: 0.0115s/iter; left time: 237.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0784622 Vali Loss: 0.0772718 Test Loss: 0.0880733\n",
      "Validation loss decreased (0.077453 --> 0.077272).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0784498\n",
      "\tspeed: 0.0273s/iter; left time: 559.6812s\n",
      "\titers: 200, epoch: 9 | loss: 0.0788638\n",
      "\tspeed: 0.0115s/iter; left time: 235.0244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0778212 Vali Loss: 0.0771774 Test Loss: 0.0877888\n",
      "Validation loss decreased (0.077272 --> 0.077177).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777390\n",
      "\tspeed: 0.0279s/iter; left time: 565.5568s\n",
      "\titers: 200, epoch: 10 | loss: 0.0771276\n",
      "\tspeed: 0.0115s/iter; left time: 232.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0772442 Vali Loss: 0.0765630 Test Loss: 0.0875897\n",
      "Validation loss decreased (0.077177 --> 0.076563).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764690\n",
      "\tspeed: 0.0302s/iter; left time: 605.1649s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763456\n",
      "\tspeed: 0.0115s/iter; left time: 230.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 224 | Train Loss: 0.0767787 Vali Loss: 0.0766127 Test Loss: 0.0875858\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0760492\n",
      "\tspeed: 0.0276s/iter; left time: 547.2712s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778596\n",
      "\tspeed: 0.0116s/iter; left time: 229.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0763816 Vali Loss: 0.0765723 Test Loss: 0.0875484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0749779\n",
      "\tspeed: 0.0297s/iter; left time: 582.9719s\n",
      "\titers: 200, epoch: 13 | loss: 0.0725502\n",
      "\tspeed: 0.0130s/iter; left time: 253.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0760159 Vali Loss: 0.0767293 Test Loss: 0.0874934\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0722800\n",
      "\tspeed: 0.0275s/iter; left time: 532.7338s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727144\n",
      "\tspeed: 0.0115s/iter; left time: 222.3744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0756537 Vali Loss: 0.0769270 Test Loss: 0.0874659\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0742095\n",
      "\tspeed: 0.0275s/iter; left time: 526.2042s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760447\n",
      "\tspeed: 0.0115s/iter; left time: 220.1762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0754731 Vali Loss: 0.0765708 Test Loss: 0.0873497\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0725512\n",
      "\tspeed: 0.0272s/iter; left time: 515.0975s\n",
      "\titers: 200, epoch: 16 | loss: 0.0733261\n",
      "\tspeed: 0.0115s/iter; left time: 216.6209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0751407 Vali Loss: 0.0765624 Test Loss: 0.0873665\n",
      "Validation loss decreased (0.076563 --> 0.076562).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0784192\n",
      "\tspeed: 0.0281s/iter; left time: 525.0459s\n",
      "\titers: 200, epoch: 17 | loss: 0.0745179\n",
      "\tspeed: 0.0135s/iter; left time: 251.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 224 | Train Loss: 0.0749689 Vali Loss: 0.0767629 Test Loss: 0.0872535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0729170\n",
      "\tspeed: 0.0271s/iter; left time: 500.9638s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760571\n",
      "\tspeed: 0.0117s/iter; left time: 214.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0747560 Vali Loss: 0.0768380 Test Loss: 0.0873866\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0746585\n",
      "\tspeed: 0.0274s/iter; left time: 500.2297s\n",
      "\titers: 200, epoch: 19 | loss: 0.0728588\n",
      "\tspeed: 0.0114s/iter; left time: 207.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0745385 Vali Loss: 0.0772080 Test Loss: 0.0873950\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0699876\n",
      "\tspeed: 0.0272s/iter; left time: 491.5440s\n",
      "\titers: 200, epoch: 20 | loss: 0.0742279\n",
      "\tspeed: 0.0115s/iter; left time: 206.6234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0744452 Vali Loss: 0.0773498 Test Loss: 0.0873456\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0717203\n",
      "\tspeed: 0.0275s/iter; left time: 489.6316s\n",
      "\titers: 200, epoch: 21 | loss: 0.0743747\n",
      "\tspeed: 0.0115s/iter; left time: 204.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0743060 Vali Loss: 0.0770385 Test Loss: 0.0872542\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0711055\n",
      "\tspeed: 0.0275s/iter; left time: 484.4589s\n",
      "\titers: 200, epoch: 22 | loss: 0.0717142\n",
      "\tspeed: 0.0115s/iter; left time: 201.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0741545 Vali Loss: 0.0767462 Test Loss: 0.0870712\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0731803\n",
      "\tspeed: 0.0269s/iter; left time: 467.5669s\n",
      "\titers: 200, epoch: 23 | loss: 0.0755438\n",
      "\tspeed: 0.0115s/iter; left time: 198.3108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0740483 Vali Loss: 0.0770965 Test Loss: 0.0872396\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0702744\n",
      "\tspeed: 0.0282s/iter; left time: 483.7496s\n",
      "\titers: 200, epoch: 24 | loss: 0.0736694\n",
      "\tspeed: 0.0115s/iter; left time: 196.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0739292 Vali Loss: 0.0772130 Test Loss: 0.0871992\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0710596\n",
      "\tspeed: 0.0276s/iter; left time: 466.6418s\n",
      "\titers: 200, epoch: 25 | loss: 0.0755225\n",
      "\tspeed: 0.0115s/iter; left time: 194.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0738307 Vali Loss: 0.0770757 Test Loss: 0.0871310\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0728090\n",
      "\tspeed: 0.0276s/iter; left time: 461.6607s\n",
      "\titers: 200, epoch: 26 | loss: 0.0761471\n",
      "\tspeed: 0.0115s/iter; left time: 190.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0737318 Vali Loss: 0.0775357 Test Loss: 0.0872217\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018813656643033028, rmse:0.13716287910938263, mae:0.08736646920442581, rse:0.40294328331947327\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:05.43s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1587022\n",
      "\tspeed: 0.0344s/iter; left time: 763.0373s\n",
      "\titers: 200, epoch: 1 | loss: 0.1341747\n",
      "\tspeed: 0.0132s/iter; left time: 291.4998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.53s\n",
      "Steps: 223 | Train Loss: 0.1577783 Vali Loss: 0.1251705 Test Loss: 0.1401281\n",
      "Validation loss decreased (inf --> 0.125171).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1031412\n",
      "\tspeed: 0.0286s/iter; left time: 629.5006s\n",
      "\titers: 200, epoch: 2 | loss: 0.0959672\n",
      "\tspeed: 0.0114s/iter; left time: 249.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.1027157 Vali Loss: 0.0919966 Test Loss: 0.1034162\n",
      "Validation loss decreased (0.125171 --> 0.091997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0920534\n",
      "\tspeed: 0.0283s/iter; left time: 615.1348s\n",
      "\titers: 200, epoch: 3 | loss: 0.0888611\n",
      "\tspeed: 0.0114s/iter; left time: 247.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0920359 Vali Loss: 0.0870327 Test Loss: 0.0976905\n",
      "Validation loss decreased (0.091997 --> 0.087033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0895105\n",
      "\tspeed: 0.0322s/iter; left time: 693.5467s\n",
      "\titers: 200, epoch: 4 | loss: 0.0878107\n",
      "\tspeed: 0.0118s/iter; left time: 253.0771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 223 | Train Loss: 0.0884706 Vali Loss: 0.0853649 Test Loss: 0.0954801\n",
      "Validation loss decreased (0.087033 --> 0.085365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862070\n",
      "\tspeed: 0.0329s/iter; left time: 701.2742s\n",
      "\titers: 200, epoch: 5 | loss: 0.0893748\n",
      "\tspeed: 0.0116s/iter; left time: 245.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 223 | Train Loss: 0.0865734 Vali Loss: 0.0847053 Test Loss: 0.0949914\n",
      "Validation loss decreased (0.085365 --> 0.084705).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0864203\n",
      "\tspeed: 0.0330s/iter; left time: 696.0142s\n",
      "\titers: 200, epoch: 6 | loss: 0.0820089\n",
      "\tspeed: 0.0116s/iter; left time: 242.9249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 223 | Train Loss: 0.0852276 Vali Loss: 0.0837621 Test Loss: 0.0942142\n",
      "Validation loss decreased (0.084705 --> 0.083762).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0851779\n",
      "\tspeed: 0.0302s/iter; left time: 630.5794s\n",
      "\titers: 200, epoch: 7 | loss: 0.0864495\n",
      "\tspeed: 0.0115s/iter; left time: 239.4460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0841670 Vali Loss: 0.0831766 Test Loss: 0.0941424\n",
      "Validation loss decreased (0.083762 --> 0.083177).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0873072\n",
      "\tspeed: 0.0302s/iter; left time: 623.2747s\n",
      "\titers: 200, epoch: 8 | loss: 0.0819371\n",
      "\tspeed: 0.0116s/iter; left time: 239.2191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0833336 Vali Loss: 0.0830012 Test Loss: 0.0937584\n",
      "Validation loss decreased (0.083177 --> 0.083001).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0824002\n",
      "\tspeed: 0.0292s/iter; left time: 596.5058s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809036\n",
      "\tspeed: 0.0115s/iter; left time: 234.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0827256 Vali Loss: 0.0830959 Test Loss: 0.0934695\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0832733\n",
      "\tspeed: 0.0297s/iter; left time: 600.4564s\n",
      "\titers: 200, epoch: 10 | loss: 0.0845594\n",
      "\tspeed: 0.0117s/iter; left time: 235.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0820771 Vali Loss: 0.0831661 Test Loss: 0.0935841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0840108\n",
      "\tspeed: 0.0293s/iter; left time: 585.0653s\n",
      "\titers: 200, epoch: 11 | loss: 0.0846826\n",
      "\tspeed: 0.0116s/iter; left time: 230.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0816523 Vali Loss: 0.0829173 Test Loss: 0.0937325\n",
      "Validation loss decreased (0.083001 --> 0.082917).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819534\n",
      "\tspeed: 0.0290s/iter; left time: 572.7860s\n",
      "\titers: 200, epoch: 12 | loss: 0.0778076\n",
      "\tspeed: 0.0115s/iter; left time: 225.3315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0812295 Vali Loss: 0.0828364 Test Loss: 0.0937928\n",
      "Validation loss decreased (0.082917 --> 0.082836).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0812906\n",
      "\tspeed: 0.0297s/iter; left time: 580.0746s\n",
      "\titers: 200, epoch: 13 | loss: 0.0818937\n",
      "\tspeed: 0.0117s/iter; left time: 226.9359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0807780 Vali Loss: 0.0831400 Test Loss: 0.0939310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0822786\n",
      "\tspeed: 0.0291s/iter; left time: 562.6103s\n",
      "\titers: 200, epoch: 14 | loss: 0.0779815\n",
      "\tspeed: 0.0127s/iter; left time: 244.6672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 223 | Train Loss: 0.0805288 Vali Loss: 0.0833648 Test Loss: 0.0938287\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0780915\n",
      "\tspeed: 0.0290s/iter; left time: 552.6051s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791826\n",
      "\tspeed: 0.0117s/iter; left time: 222.7567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0801763 Vali Loss: 0.0833790 Test Loss: 0.0936142\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0781371\n",
      "\tspeed: 0.0337s/iter; left time: 634.5570s\n",
      "\titers: 200, epoch: 16 | loss: 0.0776101\n",
      "\tspeed: 0.0115s/iter; left time: 215.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 223 | Train Loss: 0.0799538 Vali Loss: 0.0833786 Test Loss: 0.0939362\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800811\n",
      "\tspeed: 0.0333s/iter; left time: 621.1238s\n",
      "\titers: 200, epoch: 17 | loss: 0.0839744\n",
      "\tspeed: 0.0129s/iter; left time: 239.4875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 223 | Train Loss: 0.0796631 Vali Loss: 0.0837506 Test Loss: 0.0939819\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0788040\n",
      "\tspeed: 0.0288s/iter; left time: 530.3188s\n",
      "\titers: 200, epoch: 18 | loss: 0.0789553\n",
      "\tspeed: 0.0115s/iter; left time: 210.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0794751 Vali Loss: 0.0837391 Test Loss: 0.0940982\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0783507\n",
      "\tspeed: 0.0292s/iter; left time: 530.8842s\n",
      "\titers: 200, epoch: 19 | loss: 0.0804847\n",
      "\tspeed: 0.0115s/iter; left time: 207.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0792338 Vali Loss: 0.0838487 Test Loss: 0.0941867\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0772178\n",
      "\tspeed: 0.0307s/iter; left time: 552.1777s\n",
      "\titers: 200, epoch: 20 | loss: 0.0813217\n",
      "\tspeed: 0.0127s/iter; left time: 227.4603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 223 | Train Loss: 0.0790690 Vali Loss: 0.0836823 Test Loss: 0.0938814\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0800160\n",
      "\tspeed: 0.0308s/iter; left time: 546.9624s\n",
      "\titers: 200, epoch: 21 | loss: 0.0796038\n",
      "\tspeed: 0.0119s/iter; left time: 209.6994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.11s\n",
      "Steps: 223 | Train Loss: 0.0789528 Vali Loss: 0.0837873 Test Loss: 0.0938809\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793275\n",
      "\tspeed: 0.0338s/iter; left time: 592.0021s\n",
      "\titers: 200, epoch: 22 | loss: 0.0798240\n",
      "\tspeed: 0.0115s/iter; left time: 200.3811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0787614 Vali Loss: 0.0838924 Test Loss: 0.0941008\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021249037235975266, rmse:0.14577049016952515, mae:0.09379277378320694, rse:0.42826059460639954\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1605392\n",
      "\tspeed: 0.0141s/iter; left time: 313.1761s\n",
      "\titers: 200, epoch: 1 | loss: 0.1363500\n",
      "\tspeed: 0.0115s/iter; left time: 253.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.1596482 Vali Loss: 0.1268232 Test Loss: 0.1421630\n",
      "Validation loss decreased (inf --> 0.126823).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1004310\n",
      "\tspeed: 0.0298s/iter; left time: 655.5568s\n",
      "\titers: 200, epoch: 2 | loss: 0.0955543\n",
      "\tspeed: 0.0120s/iter; left time: 262.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.1025893 Vali Loss: 0.0916167 Test Loss: 0.1032000\n",
      "Validation loss decreased (0.126823 --> 0.091617).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0914148\n",
      "\tspeed: 0.0321s/iter; left time: 698.3802s\n",
      "\titers: 200, epoch: 3 | loss: 0.0923088\n",
      "\tspeed: 0.0119s/iter; left time: 257.3482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 223 | Train Loss: 0.0920838 Vali Loss: 0.0870149 Test Loss: 0.0982181\n",
      "Validation loss decreased (0.091617 --> 0.087015).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0846778\n",
      "\tspeed: 0.0301s/iter; left time: 648.1005s\n",
      "\titers: 200, epoch: 4 | loss: 0.0861134\n",
      "\tspeed: 0.0119s/iter; left time: 255.6797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0884871 Vali Loss: 0.0852041 Test Loss: 0.0956721\n",
      "Validation loss decreased (0.087015 --> 0.085204).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0870330\n",
      "\tspeed: 0.0297s/iter; left time: 633.0270s\n",
      "\titers: 200, epoch: 5 | loss: 0.0852656\n",
      "\tspeed: 0.0115s/iter; left time: 244.5190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0865100 Vali Loss: 0.0844294 Test Loss: 0.0948228\n",
      "Validation loss decreased (0.085204 --> 0.084429).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863186\n",
      "\tspeed: 0.0297s/iter; left time: 626.6237s\n",
      "\titers: 200, epoch: 6 | loss: 0.0831458\n",
      "\tspeed: 0.0120s/iter; left time: 251.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.93s\n",
      "Steps: 223 | Train Loss: 0.0850853 Vali Loss: 0.0837917 Test Loss: 0.0940178\n",
      "Validation loss decreased (0.084429 --> 0.083792).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0876890\n",
      "\tspeed: 0.0294s/iter; left time: 614.2889s\n",
      "\titers: 200, epoch: 7 | loss: 0.0835134\n",
      "\tspeed: 0.0116s/iter; left time: 240.2457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0840338 Vali Loss: 0.0838877 Test Loss: 0.0942143\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0827855\n",
      "\tspeed: 0.0300s/iter; left time: 618.5084s\n",
      "\titers: 200, epoch: 8 | loss: 0.0853693\n",
      "\tspeed: 0.0119s/iter; left time: 244.2781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 223 | Train Loss: 0.0831374 Vali Loss: 0.0837217 Test Loss: 0.0937193\n",
      "Validation loss decreased (0.083792 --> 0.083722).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0812459\n",
      "\tspeed: 0.0340s/iter; left time: 693.5549s\n",
      "\titers: 200, epoch: 9 | loss: 0.0818766\n",
      "\tspeed: 0.0120s/iter; left time: 243.1691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.38s\n",
      "Steps: 223 | Train Loss: 0.0824538 Vali Loss: 0.0836485 Test Loss: 0.0936264\n",
      "Validation loss decreased (0.083722 --> 0.083649).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0820990\n",
      "\tspeed: 0.0321s/iter; left time: 647.4170s\n",
      "\titers: 200, epoch: 10 | loss: 0.0822195\n",
      "\tspeed: 0.0115s/iter; left time: 230.4767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 223 | Train Loss: 0.0819013 Vali Loss: 0.0840038 Test Loss: 0.0938968\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0843275\n",
      "\tspeed: 0.0305s/iter; left time: 609.3461s\n",
      "\titers: 200, epoch: 11 | loss: 0.0849570\n",
      "\tspeed: 0.0115s/iter; left time: 228.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0813265 Vali Loss: 0.0841294 Test Loss: 0.0936858\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0768876\n",
      "\tspeed: 0.0288s/iter; left time: 568.1477s\n",
      "\titers: 200, epoch: 12 | loss: 0.0830417\n",
      "\tspeed: 0.0115s/iter; left time: 226.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0808785 Vali Loss: 0.0843138 Test Loss: 0.0940610\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0833870\n",
      "\tspeed: 0.0283s/iter; left time: 553.0949s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779065\n",
      "\tspeed: 0.0120s/iter; left time: 232.5003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.0805317 Vali Loss: 0.0839325 Test Loss: 0.0937242\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0815096\n",
      "\tspeed: 0.0303s/iter; left time: 585.1730s\n",
      "\titers: 200, epoch: 14 | loss: 0.0806752\n",
      "\tspeed: 0.0130s/iter; left time: 249.8381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 223 | Train Loss: 0.0801348 Vali Loss: 0.0840338 Test Loss: 0.0938141\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0778798\n",
      "\tspeed: 0.0302s/iter; left time: 576.1190s\n",
      "\titers: 200, epoch: 15 | loss: 0.0814550\n",
      "\tspeed: 0.0117s/iter; left time: 222.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0798799 Vali Loss: 0.0843550 Test Loss: 0.0940164\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0817667\n",
      "\tspeed: 0.0290s/iter; left time: 547.4380s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845650\n",
      "\tspeed: 0.0117s/iter; left time: 218.8929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0796008 Vali Loss: 0.0839033 Test Loss: 0.0938236\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0794869\n",
      "\tspeed: 0.0300s/iter; left time: 558.5709s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802841\n",
      "\tspeed: 0.0117s/iter; left time: 217.0030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0793618 Vali Loss: 0.0846649 Test Loss: 0.0942594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0808938\n",
      "\tspeed: 0.0295s/iter; left time: 543.7092s\n",
      "\titers: 200, epoch: 18 | loss: 0.0759929\n",
      "\tspeed: 0.0116s/iter; left time: 212.5229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0791255 Vali Loss: 0.0843100 Test Loss: 0.0940207\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0767357\n",
      "\tspeed: 0.0286s/iter; left time: 519.4010s\n",
      "\titers: 200, epoch: 19 | loss: 0.0807587\n",
      "\tspeed: 0.0116s/iter; left time: 209.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0789828 Vali Loss: 0.0839456 Test Loss: 0.0939088\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020944105461239815, rmse:0.14472077786922455, mae:0.09362631291151047, rse:0.4251766502857208\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:02.42s\n",
      "Intermediate time for ES: 00h:12m:52.19s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1109400\n",
      "\tspeed: 0.0318s/iter; left time: 709.2640s\n",
      "\titers: 200, epoch: 1 | loss: 0.0880111\n",
      "\tspeed: 0.0114s/iter; left time: 252.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.1121065 Vali Loss: 0.0946012 Test Loss: 0.1039492\n",
      "Validation loss decreased (inf --> 0.094601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0538929\n",
      "\tspeed: 0.0265s/iter; left time: 585.0602s\n",
      "\titers: 200, epoch: 2 | loss: 0.0533425\n",
      "\tspeed: 0.0113s/iter; left time: 248.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0594639 Vali Loss: 0.0593115 Test Loss: 0.0626804\n",
      "Validation loss decreased (0.094601 --> 0.059311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0489332\n",
      "\tspeed: 0.0306s/iter; left time: 667.8622s\n",
      "\titers: 200, epoch: 3 | loss: 0.0485343\n",
      "\tspeed: 0.0114s/iter; left time: 247.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0507693 Vali Loss: 0.0568483 Test Loss: 0.0600760\n",
      "Validation loss decreased (0.059311 --> 0.056848).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0487404\n",
      "\tspeed: 0.0290s/iter; left time: 627.4355s\n",
      "\titers: 200, epoch: 4 | loss: 0.0477995\n",
      "\tspeed: 0.0127s/iter; left time: 273.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.05s\n",
      "Steps: 224 | Train Loss: 0.0485856 Vali Loss: 0.0556100 Test Loss: 0.0589949\n",
      "Validation loss decreased (0.056848 --> 0.055610).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0472121\n",
      "\tspeed: 0.0269s/iter; left time: 576.6738s\n",
      "\titers: 200, epoch: 5 | loss: 0.0472476\n",
      "\tspeed: 0.0114s/iter; left time: 241.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0472403 Vali Loss: 0.0546619 Test Loss: 0.0584079\n",
      "Validation loss decreased (0.055610 --> 0.054662).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473987\n",
      "\tspeed: 0.0303s/iter; left time: 641.0761s\n",
      "\titers: 200, epoch: 6 | loss: 0.0465832\n",
      "\tspeed: 0.0114s/iter; left time: 239.6599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0462808 Vali Loss: 0.0536563 Test Loss: 0.0576321\n",
      "Validation loss decreased (0.054662 --> 0.053656).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0467726\n",
      "\tspeed: 0.0269s/iter; left time: 564.4247s\n",
      "\titers: 200, epoch: 7 | loss: 0.0450430\n",
      "\tspeed: 0.0114s/iter; left time: 237.1985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0456065 Vali Loss: 0.0533683 Test Loss: 0.0574062\n",
      "Validation loss decreased (0.053656 --> 0.053368).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0468291\n",
      "\tspeed: 0.0312s/iter; left time: 647.1592s\n",
      "\titers: 200, epoch: 8 | loss: 0.0441214\n",
      "\tspeed: 0.0113s/iter; left time: 233.8212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0450418 Vali Loss: 0.0531526 Test Loss: 0.0570093\n",
      "Validation loss decreased (0.053368 --> 0.053153).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0461029\n",
      "\tspeed: 0.0270s/iter; left time: 552.9580s\n",
      "\titers: 200, epoch: 9 | loss: 0.0408064\n",
      "\tspeed: 0.0113s/iter; left time: 231.3900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0445590 Vali Loss: 0.0528589 Test Loss: 0.0570480\n",
      "Validation loss decreased (0.053153 --> 0.052859).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0465658\n",
      "\tspeed: 0.0274s/iter; left time: 556.3677s\n",
      "\titers: 200, epoch: 10 | loss: 0.0442628\n",
      "\tspeed: 0.0114s/iter; left time: 229.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0441614 Vali Loss: 0.0525321 Test Loss: 0.0567075\n",
      "Validation loss decreased (0.052859 --> 0.052532).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0423924\n",
      "\tspeed: 0.0272s/iter; left time: 545.6579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0421286\n",
      "\tspeed: 0.0114s/iter; left time: 226.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0438235 Vali Loss: 0.0523531 Test Loss: 0.0565543\n",
      "Validation loss decreased (0.052532 --> 0.052353).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0432395\n",
      "\tspeed: 0.0270s/iter; left time: 535.6725s\n",
      "\titers: 200, epoch: 12 | loss: 0.0427727\n",
      "\tspeed: 0.0114s/iter; left time: 224.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0435605 Vali Loss: 0.0522622 Test Loss: 0.0562977\n",
      "Validation loss decreased (0.052353 --> 0.052262).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0425658\n",
      "\tspeed: 0.0272s/iter; left time: 534.2567s\n",
      "\titers: 200, epoch: 13 | loss: 0.0426574\n",
      "\tspeed: 0.0114s/iter; left time: 221.9436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0433638 Vali Loss: 0.0520600 Test Loss: 0.0562625\n",
      "Validation loss decreased (0.052262 --> 0.052060).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0430053\n",
      "\tspeed: 0.0269s/iter; left time: 520.7740s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461629\n",
      "\tspeed: 0.0114s/iter; left time: 219.1459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0431846 Vali Loss: 0.0523483 Test Loss: 0.0562605\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0421305\n",
      "\tspeed: 0.0263s/iter; left time: 503.5577s\n",
      "\titers: 200, epoch: 15 | loss: 0.0412395\n",
      "\tspeed: 0.0113s/iter; left time: 216.2409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0429814 Vali Loss: 0.0519295 Test Loss: 0.0562118\n",
      "Validation loss decreased (0.052060 --> 0.051930).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0420358\n",
      "\tspeed: 0.0267s/iter; left time: 505.4618s\n",
      "\titers: 200, epoch: 16 | loss: 0.0441732\n",
      "\tspeed: 0.0114s/iter; left time: 214.1242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0428641 Vali Loss: 0.0518976 Test Loss: 0.0560167\n",
      "Validation loss decreased (0.051930 --> 0.051898).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0419349\n",
      "\tspeed: 0.0319s/iter; left time: 596.3180s\n",
      "\titers: 200, epoch: 17 | loss: 0.0407056\n",
      "\tspeed: 0.0114s/iter; left time: 212.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0426269 Vali Loss: 0.0517025 Test Loss: 0.0560059\n",
      "Validation loss decreased (0.051898 --> 0.051702).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0445126\n",
      "\tspeed: 0.0304s/iter; left time: 562.3024s\n",
      "\titers: 200, epoch: 18 | loss: 0.0424769\n",
      "\tspeed: 0.0121s/iter; left time: 222.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0425544 Vali Loss: 0.0517746 Test Loss: 0.0559971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0395071\n",
      "\tspeed: 0.0264s/iter; left time: 482.4276s\n",
      "\titers: 200, epoch: 19 | loss: 0.0431924\n",
      "\tspeed: 0.0114s/iter; left time: 206.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0424392 Vali Loss: 0.0516417 Test Loss: 0.0558206\n",
      "Validation loss decreased (0.051702 --> 0.051642).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0415440\n",
      "\tspeed: 0.0271s/iter; left time: 488.7819s\n",
      "\titers: 200, epoch: 20 | loss: 0.0394489\n",
      "\tspeed: 0.0114s/iter; left time: 203.9700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0423368 Vali Loss: 0.0516620 Test Loss: 0.0558139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0407615\n",
      "\tspeed: 0.0264s/iter; left time: 471.1409s\n",
      "\titers: 200, epoch: 21 | loss: 0.0426134\n",
      "\tspeed: 0.0114s/iter; left time: 201.2245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0423221 Vali Loss: 0.0516890 Test Loss: 0.0558509\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0417494\n",
      "\tspeed: 0.0260s/iter; left time: 457.3201s\n",
      "\titers: 200, epoch: 22 | loss: 0.0424503\n",
      "\tspeed: 0.0113s/iter; left time: 197.6824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0422042 Vali Loss: 0.0516807 Test Loss: 0.0557669\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0422069\n",
      "\tspeed: 0.0265s/iter; left time: 459.7961s\n",
      "\titers: 200, epoch: 23 | loss: 0.0421869\n",
      "\tspeed: 0.0113s/iter; left time: 195.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0421442 Vali Loss: 0.0515090 Test Loss: 0.0558012\n",
      "Validation loss decreased (0.051642 --> 0.051509).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0418931\n",
      "\tspeed: 0.0261s/iter; left time: 447.4470s\n",
      "\titers: 200, epoch: 24 | loss: 0.0408529\n",
      "\tspeed: 0.0113s/iter; left time: 192.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0420906 Vali Loss: 0.0515393 Test Loss: 0.0557616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0419490\n",
      "\tspeed: 0.0264s/iter; left time: 446.9120s\n",
      "\titers: 200, epoch: 25 | loss: 0.0443372\n",
      "\tspeed: 0.0113s/iter; left time: 189.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0420129 Vali Loss: 0.0515676 Test Loss: 0.0557406\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0415911\n",
      "\tspeed: 0.0267s/iter; left time: 446.1236s\n",
      "\titers: 200, epoch: 26 | loss: 0.0454777\n",
      "\tspeed: 0.0113s/iter; left time: 187.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0419738 Vali Loss: 0.0515209 Test Loss: 0.0556991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0439227\n",
      "\tspeed: 0.0263s/iter; left time: 433.4257s\n",
      "\titers: 200, epoch: 27 | loss: 0.0386638\n",
      "\tspeed: 0.0114s/iter; left time: 186.0390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0419349 Vali Loss: 0.0514542 Test Loss: 0.0556763\n",
      "Validation loss decreased (0.051509 --> 0.051454).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0419656\n",
      "\tspeed: 0.0273s/iter; left time: 443.4657s\n",
      "\titers: 200, epoch: 28 | loss: 0.0410749\n",
      "\tspeed: 0.0113s/iter; left time: 182.9131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0419496 Vali Loss: 0.0513850 Test Loss: 0.0556148\n",
      "Validation loss decreased (0.051454 --> 0.051385).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0419630\n",
      "\tspeed: 0.0275s/iter; left time: 440.8479s\n",
      "\titers: 200, epoch: 29 | loss: 0.0418092\n",
      "\tspeed: 0.0114s/iter; left time: 180.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0418379 Vali Loss: 0.0514334 Test Loss: 0.0555982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0409940\n",
      "\tspeed: 0.0263s/iter; left time: 415.3322s\n",
      "\titers: 200, epoch: 30 | loss: 0.0390244\n",
      "\tspeed: 0.0113s/iter; left time: 177.9363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0418288 Vali Loss: 0.0513954 Test Loss: 0.0556216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0411828\n",
      "\tspeed: 0.0266s/iter; left time: 414.3470s\n",
      "\titers: 200, epoch: 31 | loss: 0.0444561\n",
      "\tspeed: 0.0114s/iter; left time: 175.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0417868 Vali Loss: 0.0514006 Test Loss: 0.0556102\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0405125\n",
      "\tspeed: 0.0265s/iter; left time: 406.8392s\n",
      "\titers: 200, epoch: 32 | loss: 0.0414968\n",
      "\tspeed: 0.0113s/iter; left time: 172.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0417627 Vali Loss: 0.0514132 Test Loss: 0.0556035\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0407390\n",
      "\tspeed: 0.0275s/iter; left time: 415.8402s\n",
      "\titers: 200, epoch: 33 | loss: 0.0418444\n",
      "\tspeed: 0.0113s/iter; left time: 170.1466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0417871 Vali Loss: 0.0514308 Test Loss: 0.0556037\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0408377\n",
      "\tspeed: 0.0262s/iter; left time: 390.6963s\n",
      "\titers: 200, epoch: 34 | loss: 0.0403687\n",
      "\tspeed: 0.0114s/iter; left time: 168.2972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0417662 Vali Loss: 0.0513956 Test Loss: 0.0555526\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0418818\n",
      "\tspeed: 0.0267s/iter; left time: 392.4487s\n",
      "\titers: 200, epoch: 35 | loss: 0.0407693\n",
      "\tspeed: 0.0113s/iter; left time: 164.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0416525 Vali Loss: 0.0513907 Test Loss: 0.0555776\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0383531\n",
      "\tspeed: 0.0267s/iter; left time: 386.0894s\n",
      "\titers: 200, epoch: 36 | loss: 0.0394005\n",
      "\tspeed: 0.0113s/iter; left time: 162.0934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0416648 Vali Loss: 0.0514215 Test Loss: 0.0555419\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0411682\n",
      "\tspeed: 0.0273s/iter; left time: 388.5373s\n",
      "\titers: 200, epoch: 37 | loss: 0.0423041\n",
      "\tspeed: 0.0113s/iter; left time: 160.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0417005 Vali Loss: 0.0513743 Test Loss: 0.0555397\n",
      "Validation loss decreased (0.051385 --> 0.051374).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0408833\n",
      "\tspeed: 0.0269s/iter; left time: 376.8323s\n",
      "\titers: 200, epoch: 38 | loss: 0.0388810\n",
      "\tspeed: 0.0114s/iter; left time: 158.6465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0416703 Vali Loss: 0.0514368 Test Loss: 0.0555344\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0397985\n",
      "\tspeed: 0.0274s/iter; left time: 377.4818s\n",
      "\titers: 200, epoch: 39 | loss: 0.0396867\n",
      "\tspeed: 0.0113s/iter; left time: 155.2606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0416373 Vali Loss: 0.0514143 Test Loss: 0.0555408\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0412675\n",
      "\tspeed: 0.0266s/iter; left time: 360.5572s\n",
      "\titers: 200, epoch: 40 | loss: 0.0385533\n",
      "\tspeed: 0.0114s/iter; left time: 152.8771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0416844 Vali Loss: 0.0513738 Test Loss: 0.0555417\n",
      "Validation loss decreased (0.051374 --> 0.051374).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0407081\n",
      "\tspeed: 0.0267s/iter; left time: 355.7639s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402288\n",
      "\tspeed: 0.0113s/iter; left time: 149.3221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0416253 Vali Loss: 0.0514445 Test Loss: 0.0555158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0419141\n",
      "\tspeed: 0.0267s/iter; left time: 350.7288s\n",
      "\titers: 200, epoch: 42 | loss: 0.0434356\n",
      "\tspeed: 0.0113s/iter; left time: 147.2053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0416379 Vali Loss: 0.0513738 Test Loss: 0.0555247\n",
      "Validation loss decreased (0.051374 --> 0.051374).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0397124\n",
      "\tspeed: 0.0265s/iter; left time: 341.9893s\n",
      "\titers: 200, epoch: 43 | loss: 0.0440199\n",
      "\tspeed: 0.0114s/iter; left time: 145.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0416425 Vali Loss: 0.0513975 Test Loss: 0.0555227\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0452872\n",
      "\tspeed: 0.0269s/iter; left time: 340.7710s\n",
      "\titers: 200, epoch: 44 | loss: 0.0398631\n",
      "\tspeed: 0.0113s/iter; left time: 142.1585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0416148 Vali Loss: 0.0513826 Test Loss: 0.0555055\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0422358\n",
      "\tspeed: 0.0267s/iter; left time: 332.4502s\n",
      "\titers: 200, epoch: 45 | loss: 0.0448361\n",
      "\tspeed: 0.0113s/iter; left time: 139.3715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0416003 Vali Loss: 0.0513718 Test Loss: 0.0555177\n",
      "Validation loss decreased (0.051374 --> 0.051372).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0403614\n",
      "\tspeed: 0.0267s/iter; left time: 326.6583s\n",
      "\titers: 200, epoch: 46 | loss: 0.0450035\n",
      "\tspeed: 0.0113s/iter; left time: 137.2103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0416295 Vali Loss: 0.0513982 Test Loss: 0.0555105\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0404242\n",
      "\tspeed: 0.0266s/iter; left time: 319.3259s\n",
      "\titers: 200, epoch: 47 | loss: 0.0397902\n",
      "\tspeed: 0.0113s/iter; left time: 134.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0416020 Vali Loss: 0.0513915 Test Loss: 0.0555158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0421404\n",
      "\tspeed: 0.0266s/iter; left time: 312.8807s\n",
      "\titers: 200, epoch: 48 | loss: 0.0438213\n",
      "\tspeed: 0.0114s/iter; left time: 132.7442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0415688 Vali Loss: 0.0513696 Test Loss: 0.0555146\n",
      "Validation loss decreased (0.051372 --> 0.051370).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0421305\n",
      "\tspeed: 0.0266s/iter; left time: 307.7061s\n",
      "\titers: 200, epoch: 49 | loss: 0.0384293\n",
      "\tspeed: 0.0113s/iter; left time: 129.1121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0415714 Vali Loss: 0.0513273 Test Loss: 0.0555126\n",
      "Validation loss decreased (0.051370 --> 0.051327).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0433809\n",
      "\tspeed: 0.0273s/iter; left time: 308.6527s\n",
      "\titers: 200, epoch: 50 | loss: 0.0429459\n",
      "\tspeed: 0.0113s/iter; left time: 126.8861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0415727 Vali Loss: 0.0513864 Test Loss: 0.0555176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0454690\n",
      "\tspeed: 0.0267s/iter; left time: 296.7887s\n",
      "\titers: 200, epoch: 51 | loss: 0.0403795\n",
      "\tspeed: 0.0113s/iter; left time: 124.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0415888 Vali Loss: 0.0514048 Test Loss: 0.0555065\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0426668\n",
      "\tspeed: 0.0264s/iter; left time: 287.3238s\n",
      "\titers: 200, epoch: 52 | loss: 0.0446686\n",
      "\tspeed: 0.0114s/iter; left time: 122.4538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0416104 Vali Loss: 0.0513689 Test Loss: 0.0554959\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0435898\n",
      "\tspeed: 0.0267s/iter; left time: 284.9566s\n",
      "\titers: 200, epoch: 53 | loss: 0.0417512\n",
      "\tspeed: 0.0114s/iter; left time: 119.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0415594 Vali Loss: 0.0513543 Test Loss: 0.0554936\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0447290\n",
      "\tspeed: 0.0266s/iter; left time: 277.8144s\n",
      "\titers: 200, epoch: 54 | loss: 0.0445685\n",
      "\tspeed: 0.0113s/iter; left time: 116.7020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0415773 Vali Loss: 0.0514316 Test Loss: 0.0555048\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0428288\n",
      "\tspeed: 0.0270s/iter; left time: 275.5483s\n",
      "\titers: 200, epoch: 55 | loss: 0.0410732\n",
      "\tspeed: 0.0114s/iter; left time: 114.8184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0416301 Vali Loss: 0.0513627 Test Loss: 0.0555057\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0416298\n",
      "\tspeed: 0.0260s/iter; left time: 259.6532s\n",
      "\titers: 200, epoch: 56 | loss: 0.0376745\n",
      "\tspeed: 0.0113s/iter; left time: 111.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0415781 Vali Loss: 0.0514315 Test Loss: 0.0555051\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0449215\n",
      "\tspeed: 0.0264s/iter; left time: 257.9872s\n",
      "\titers: 200, epoch: 57 | loss: 0.0431855\n",
      "\tspeed: 0.0113s/iter; left time: 109.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0415654 Vali Loss: 0.0514049 Test Loss: 0.0554999\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0408680\n",
      "\tspeed: 0.0268s/iter; left time: 255.5940s\n",
      "\titers: 200, epoch: 58 | loss: 0.0406956\n",
      "\tspeed: 0.0114s/iter; left time: 107.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0415538 Vali Loss: 0.0513615 Test Loss: 0.0555021\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0433828\n",
      "\tspeed: 0.0269s/iter; left time: 250.7900s\n",
      "\titers: 200, epoch: 59 | loss: 0.0447299\n",
      "\tspeed: 0.0113s/iter; left time: 103.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0415695 Vali Loss: 0.0513497 Test Loss: 0.0555113\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010139995254576206, rmse:0.10069753974676132, mae:0.05551256611943245, rse:0.3884883224964142\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1064993\n",
      "\tspeed: 0.0134s/iter; left time: 299.1759s\n",
      "\titers: 200, epoch: 1 | loss: 0.0898978\n",
      "\tspeed: 0.0113s/iter; left time: 250.9464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.1072968 Vali Loss: 0.0922784 Test Loss: 0.1009453\n",
      "Validation loss decreased (inf --> 0.092278).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0541077\n",
      "\tspeed: 0.0264s/iter; left time: 582.1714s\n",
      "\titers: 200, epoch: 2 | loss: 0.0517863\n",
      "\tspeed: 0.0114s/iter; left time: 249.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0590329 Vali Loss: 0.0591651 Test Loss: 0.0625161\n",
      "Validation loss decreased (0.092278 --> 0.059165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0516064\n",
      "\tspeed: 0.0262s/iter; left time: 572.7445s\n",
      "\titers: 200, epoch: 3 | loss: 0.0497771\n",
      "\tspeed: 0.0114s/iter; left time: 247.8557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0506384 Vali Loss: 0.0565764 Test Loss: 0.0601657\n",
      "Validation loss decreased (0.059165 --> 0.056576).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0466088\n",
      "\tspeed: 0.0268s/iter; left time: 579.0598s\n",
      "\titers: 200, epoch: 4 | loss: 0.0451131\n",
      "\tspeed: 0.0113s/iter; left time: 244.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0484426 Vali Loss: 0.0553318 Test Loss: 0.0590868\n",
      "Validation loss decreased (0.056576 --> 0.055332).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0480724\n",
      "\tspeed: 0.0265s/iter; left time: 566.1636s\n",
      "\titers: 200, epoch: 5 | loss: 0.0474793\n",
      "\tspeed: 0.0113s/iter; left time: 240.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0470719 Vali Loss: 0.0546400 Test Loss: 0.0585360\n",
      "Validation loss decreased (0.055332 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0450504\n",
      "\tspeed: 0.0264s/iter; left time: 558.2628s\n",
      "\titers: 200, epoch: 6 | loss: 0.0451436\n",
      "\tspeed: 0.0113s/iter; left time: 238.5693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0461726 Vali Loss: 0.0537437 Test Loss: 0.0577703\n",
      "Validation loss decreased (0.054640 --> 0.053744).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0442156\n",
      "\tspeed: 0.0266s/iter; left time: 556.9486s\n",
      "\titers: 200, epoch: 7 | loss: 0.0422004\n",
      "\tspeed: 0.0114s/iter; left time: 237.2585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0454504 Vali Loss: 0.0534526 Test Loss: 0.0575519\n",
      "Validation loss decreased (0.053744 --> 0.053453).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0472451\n",
      "\tspeed: 0.0259s/iter; left time: 536.7529s\n",
      "\titers: 200, epoch: 8 | loss: 0.0453474\n",
      "\tspeed: 0.0113s/iter; left time: 233.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0448834 Vali Loss: 0.0532607 Test Loss: 0.0572170\n",
      "Validation loss decreased (0.053453 --> 0.053261).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0441168\n",
      "\tspeed: 0.0261s/iter; left time: 535.4675s\n",
      "\titers: 200, epoch: 9 | loss: 0.0439339\n",
      "\tspeed: 0.0114s/iter; left time: 231.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0443996 Vali Loss: 0.0527744 Test Loss: 0.0573015\n",
      "Validation loss decreased (0.053261 --> 0.052774).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0426141\n",
      "\tspeed: 0.0260s/iter; left time: 527.9921s\n",
      "\titers: 200, epoch: 10 | loss: 0.0423739\n",
      "\tspeed: 0.0113s/iter; left time: 228.8863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0440688 Vali Loss: 0.0526297 Test Loss: 0.0569990\n",
      "Validation loss decreased (0.052774 --> 0.052630).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0436581\n",
      "\tspeed: 0.0261s/iter; left time: 523.9617s\n",
      "\titers: 200, epoch: 11 | loss: 0.0428546\n",
      "\tspeed: 0.0114s/iter; left time: 226.7805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0437997 Vali Loss: 0.0525190 Test Loss: 0.0566387\n",
      "Validation loss decreased (0.052630 --> 0.052519).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0419358\n",
      "\tspeed: 0.0269s/iter; left time: 533.4601s\n",
      "\titers: 200, epoch: 12 | loss: 0.0408733\n",
      "\tspeed: 0.0113s/iter; left time: 223.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0434765 Vali Loss: 0.0522965 Test Loss: 0.0564813\n",
      "Validation loss decreased (0.052519 --> 0.052296).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0424740\n",
      "\tspeed: 0.0262s/iter; left time: 513.1263s\n",
      "\titers: 200, epoch: 13 | loss: 0.0448592\n",
      "\tspeed: 0.0114s/iter; left time: 222.1623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0432481 Vali Loss: 0.0519859 Test Loss: 0.0562043\n",
      "Validation loss decreased (0.052296 --> 0.051986).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0462686\n",
      "\tspeed: 0.0265s/iter; left time: 514.1028s\n",
      "\titers: 200, epoch: 14 | loss: 0.0410175\n",
      "\tspeed: 0.0114s/iter; left time: 219.0239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0430263 Vali Loss: 0.0519746 Test Loss: 0.0561616\n",
      "Validation loss decreased (0.051986 --> 0.051975).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0400170\n",
      "\tspeed: 0.0264s/iter; left time: 505.6215s\n",
      "\titers: 200, epoch: 15 | loss: 0.0417477\n",
      "\tspeed: 0.0114s/iter; left time: 216.9647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0428693 Vali Loss: 0.0518668 Test Loss: 0.0560349\n",
      "Validation loss decreased (0.051975 --> 0.051867).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0429298\n",
      "\tspeed: 0.0269s/iter; left time: 508.7103s\n",
      "\titers: 200, epoch: 16 | loss: 0.0404028\n",
      "\tspeed: 0.0114s/iter; left time: 214.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0426903 Vali Loss: 0.0518083 Test Loss: 0.0560235\n",
      "Validation loss decreased (0.051867 --> 0.051808).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0414114\n",
      "\tspeed: 0.0262s/iter; left time: 490.1766s\n",
      "\titers: 200, epoch: 17 | loss: 0.0444004\n",
      "\tspeed: 0.0114s/iter; left time: 212.8129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0425624 Vali Loss: 0.0518523 Test Loss: 0.0560078\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0408400\n",
      "\tspeed: 0.0260s/iter; left time: 480.7216s\n",
      "\titers: 200, epoch: 18 | loss: 0.0405412\n",
      "\tspeed: 0.0113s/iter; left time: 208.4179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0424842 Vali Loss: 0.0517635 Test Loss: 0.0558364\n",
      "Validation loss decreased (0.051808 --> 0.051763).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0409657\n",
      "\tspeed: 0.0260s/iter; left time: 474.4267s\n",
      "\titers: 200, epoch: 19 | loss: 0.0436802\n",
      "\tspeed: 0.0113s/iter; left time: 205.9944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0423607 Vali Loss: 0.0516174 Test Loss: 0.0558228\n",
      "Validation loss decreased (0.051763 --> 0.051617).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0431456\n",
      "\tspeed: 0.0279s/iter; left time: 503.2124s\n",
      "\titers: 200, epoch: 20 | loss: 0.0479117\n",
      "\tspeed: 0.0114s/iter; left time: 204.0084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0422403 Vali Loss: 0.0515918 Test Loss: 0.0557595\n",
      "Validation loss decreased (0.051617 --> 0.051592).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0405881\n",
      "\tspeed: 0.0260s/iter; left time: 463.1448s\n",
      "\titers: 200, epoch: 21 | loss: 0.0398511\n",
      "\tspeed: 0.0113s/iter; left time: 200.4115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0421710 Vali Loss: 0.0514938 Test Loss: 0.0557249\n",
      "Validation loss decreased (0.051592 --> 0.051494).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0410583\n",
      "\tspeed: 0.0266s/iter; left time: 467.4769s\n",
      "\titers: 200, epoch: 22 | loss: 0.0419496\n",
      "\tspeed: 0.0114s/iter; left time: 198.7533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0421269 Vali Loss: 0.0516128 Test Loss: 0.0556860\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0393955\n",
      "\tspeed: 0.0259s/iter; left time: 449.1334s\n",
      "\titers: 200, epoch: 23 | loss: 0.0389127\n",
      "\tspeed: 0.0113s/iter; left time: 194.9566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.72s\n",
      "Steps: 224 | Train Loss: 0.0420173 Vali Loss: 0.0514699 Test Loss: 0.0556844\n",
      "Validation loss decreased (0.051494 --> 0.051470).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0429449\n",
      "\tspeed: 0.0265s/iter; left time: 454.7134s\n",
      "\titers: 200, epoch: 24 | loss: 0.0411954\n",
      "\tspeed: 0.0114s/iter; left time: 193.5587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0420042 Vali Loss: 0.0514821 Test Loss: 0.0556613\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0427483\n",
      "\tspeed: 0.0257s/iter; left time: 435.2970s\n",
      "\titers: 200, epoch: 25 | loss: 0.0430793\n",
      "\tspeed: 0.0113s/iter; left time: 190.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0419427 Vali Loss: 0.0513386 Test Loss: 0.0555822\n",
      "Validation loss decreased (0.051470 --> 0.051339).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0436190\n",
      "\tspeed: 0.0260s/iter; left time: 434.5435s\n",
      "\titers: 200, epoch: 26 | loss: 0.0396242\n",
      "\tspeed: 0.0113s/iter; left time: 187.7902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0418911 Vali Loss: 0.0513915 Test Loss: 0.0555950\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0422270\n",
      "\tspeed: 0.0257s/iter; left time: 422.9728s\n",
      "\titers: 200, epoch: 27 | loss: 0.0385547\n",
      "\tspeed: 0.0113s/iter; left time: 185.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0418529 Vali Loss: 0.0513919 Test Loss: 0.0555254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0432778\n",
      "\tspeed: 0.0264s/iter; left time: 428.5953s\n",
      "\titers: 200, epoch: 28 | loss: 0.0430710\n",
      "\tspeed: 0.0113s/iter; left time: 183.2910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0418229 Vali Loss: 0.0513874 Test Loss: 0.0555705\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0448900\n",
      "\tspeed: 0.0258s/iter; left time: 413.4087s\n",
      "\titers: 200, epoch: 29 | loss: 0.0417846\n",
      "\tspeed: 0.0114s/iter; left time: 180.8886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0417814 Vali Loss: 0.0513500 Test Loss: 0.0555337\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0430666\n",
      "\tspeed: 0.0262s/iter; left time: 413.9917s\n",
      "\titers: 200, epoch: 30 | loss: 0.0393300\n",
      "\tspeed: 0.0114s/iter; left time: 178.3285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0417232 Vali Loss: 0.0513649 Test Loss: 0.0554943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0400133\n",
      "\tspeed: 0.0258s/iter; left time: 402.5267s\n",
      "\titers: 200, epoch: 31 | loss: 0.0417974\n",
      "\tspeed: 0.0113s/iter; left time: 175.4208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0417238 Vali Loss: 0.0513547 Test Loss: 0.0554955\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0402275\n",
      "\tspeed: 0.0261s/iter; left time: 401.5832s\n",
      "\titers: 200, epoch: 32 | loss: 0.0406861\n",
      "\tspeed: 0.0114s/iter; left time: 173.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0416927 Vali Loss: 0.0513156 Test Loss: 0.0555012\n",
      "Validation loss decreased (0.051339 --> 0.051316).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0431422\n",
      "\tspeed: 0.0260s/iter; left time: 394.0966s\n",
      "\titers: 200, epoch: 33 | loss: 0.0421905\n",
      "\tspeed: 0.0113s/iter; left time: 170.2625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0417212 Vali Loss: 0.0513036 Test Loss: 0.0554760\n",
      "Validation loss decreased (0.051316 --> 0.051304).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0426976\n",
      "\tspeed: 0.0262s/iter; left time: 390.1926s\n",
      "\titers: 200, epoch: 34 | loss: 0.0425665\n",
      "\tspeed: 0.0113s/iter; left time: 167.7690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0416526 Vali Loss: 0.0513469 Test Loss: 0.0554543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0403928\n",
      "\tspeed: 0.0265s/iter; left time: 388.6582s\n",
      "\titers: 200, epoch: 35 | loss: 0.0381656\n",
      "\tspeed: 0.0114s/iter; left time: 165.5504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0416932 Vali Loss: 0.0512570 Test Loss: 0.0554872\n",
      "Validation loss decreased (0.051304 --> 0.051257).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0417262\n",
      "\tspeed: 0.0262s/iter; left time: 379.2518s\n",
      "\titers: 200, epoch: 36 | loss: 0.0409358\n",
      "\tspeed: 0.0114s/iter; left time: 163.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0415752 Vali Loss: 0.0513374 Test Loss: 0.0554584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0410994\n",
      "\tspeed: 0.0259s/iter; left time: 369.1766s\n",
      "\titers: 200, epoch: 37 | loss: 0.0404155\n",
      "\tspeed: 0.0114s/iter; left time: 161.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0416342 Vali Loss: 0.0513017 Test Loss: 0.0554516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0422448\n",
      "\tspeed: 0.0260s/iter; left time: 365.0034s\n",
      "\titers: 200, epoch: 38 | loss: 0.0421917\n",
      "\tspeed: 0.0114s/iter; left time: 158.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0416186 Vali Loss: 0.0513290 Test Loss: 0.0554624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0423602\n",
      "\tspeed: 0.0259s/iter; left time: 357.6494s\n",
      "\titers: 200, epoch: 39 | loss: 0.0395699\n",
      "\tspeed: 0.0113s/iter; left time: 155.0648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0415399 Vali Loss: 0.0512565 Test Loss: 0.0554393\n",
      "Validation loss decreased (0.051257 --> 0.051256).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0409622\n",
      "\tspeed: 0.0262s/iter; left time: 354.8640s\n",
      "\titers: 200, epoch: 40 | loss: 0.0419753\n",
      "\tspeed: 0.0113s/iter; left time: 152.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0415769 Vali Loss: 0.0512582 Test Loss: 0.0554393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0404423\n",
      "\tspeed: 0.0259s/iter; left time: 345.4653s\n",
      "\titers: 200, epoch: 41 | loss: 0.0391504\n",
      "\tspeed: 0.0113s/iter; left time: 149.7891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0415408 Vali Loss: 0.0511953 Test Loss: 0.0554382\n",
      "Validation loss decreased (0.051256 --> 0.051195).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0421683\n",
      "\tspeed: 0.0261s/iter; left time: 342.6293s\n",
      "\titers: 200, epoch: 42 | loss: 0.0392771\n",
      "\tspeed: 0.0113s/iter; left time: 147.5685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0415430 Vali Loss: 0.0512018 Test Loss: 0.0554315\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0408451\n",
      "\tspeed: 0.0268s/iter; left time: 345.3384s\n",
      "\titers: 200, epoch: 43 | loss: 0.0414137\n",
      "\tspeed: 0.0114s/iter; left time: 145.5391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0415321 Vali Loss: 0.0512675 Test Loss: 0.0554436\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0420590\n",
      "\tspeed: 0.0263s/iter; left time: 333.1573s\n",
      "\titers: 200, epoch: 44 | loss: 0.0435591\n",
      "\tspeed: 0.0114s/iter; left time: 143.1402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0415375 Vali Loss: 0.0513441 Test Loss: 0.0554425\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0411132\n",
      "\tspeed: 0.0264s/iter; left time: 328.2493s\n",
      "\titers: 200, epoch: 45 | loss: 0.0444768\n",
      "\tspeed: 0.0113s/iter; left time: 139.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0415071 Vali Loss: 0.0512262 Test Loss: 0.0554158\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0399008\n",
      "\tspeed: 0.0264s/iter; left time: 322.6287s\n",
      "\titers: 200, epoch: 46 | loss: 0.0419652\n",
      "\tspeed: 0.0113s/iter; left time: 136.8841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0415763 Vali Loss: 0.0512670 Test Loss: 0.0554265\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0403989\n",
      "\tspeed: 0.0268s/iter; left time: 321.3843s\n",
      "\titers: 200, epoch: 47 | loss: 0.0408006\n",
      "\tspeed: 0.0113s/iter; left time: 134.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0415416 Vali Loss: 0.0512850 Test Loss: 0.0554061\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0421052\n",
      "\tspeed: 0.0261s/iter; left time: 307.4037s\n",
      "\titers: 200, epoch: 48 | loss: 0.0431605\n",
      "\tspeed: 0.0114s/iter; left time: 132.7738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0415406 Vali Loss: 0.0512447 Test Loss: 0.0554275\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0422548\n",
      "\tspeed: 0.0267s/iter; left time: 308.2059s\n",
      "\titers: 200, epoch: 49 | loss: 0.0428016\n",
      "\tspeed: 0.0114s/iter; left time: 130.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0415042 Vali Loss: 0.0511977 Test Loss: 0.0554122\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0432623\n",
      "\tspeed: 0.0259s/iter; left time: 293.4014s\n",
      "\titers: 200, epoch: 50 | loss: 0.0383340\n",
      "\tspeed: 0.0113s/iter; left time: 127.1646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0414821 Vali Loss: 0.0512053 Test Loss: 0.0554054\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0425686\n",
      "\tspeed: 0.0277s/iter; left time: 307.9691s\n",
      "\titers: 200, epoch: 51 | loss: 0.0439639\n",
      "\tspeed: 0.0119s/iter; left time: 131.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 224 | Train Loss: 0.0414878 Vali Loss: 0.0512469 Test Loss: 0.0554142\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010151279158890247, rmse:0.100753553211689, mae:0.05543816089630127, rse:0.38870441913604736\n",
      "Intermediate time for FR and pred_len 24: 00h:07m:08.27s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1147146\n",
      "\tspeed: 0.0300s/iter; left time: 669.1631s\n",
      "\titers: 200, epoch: 1 | loss: 0.1000472\n",
      "\tspeed: 0.0116s/iter; left time: 256.8000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.14s\n",
      "Steps: 224 | Train Loss: 0.1151350 Vali Loss: 0.1004755 Test Loss: 0.1112628\n",
      "Validation loss decreased (inf --> 0.100475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692950\n",
      "\tspeed: 0.0279s/iter; left time: 615.2192s\n",
      "\titers: 200, epoch: 2 | loss: 0.0726237\n",
      "\tspeed: 0.0114s/iter; left time: 251.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0735507 Vali Loss: 0.0766084 Test Loss: 0.0845824\n",
      "Validation loss decreased (0.100475 --> 0.076608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0612146\n",
      "\tspeed: 0.0296s/iter; left time: 646.6481s\n",
      "\titers: 200, epoch: 3 | loss: 0.0639182\n",
      "\tspeed: 0.0119s/iter; left time: 258.2957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0659023 Vali Loss: 0.0733167 Test Loss: 0.0827081\n",
      "Validation loss decreased (0.076608 --> 0.073317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0624377\n",
      "\tspeed: 0.0295s/iter; left time: 638.2792s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632359\n",
      "\tspeed: 0.0128s/iter; left time: 276.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0634114 Vali Loss: 0.0719024 Test Loss: 0.0820890\n",
      "Validation loss decreased (0.073317 --> 0.071902).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0613682\n",
      "\tspeed: 0.0290s/iter; left time: 621.1611s\n",
      "\titers: 200, epoch: 5 | loss: 0.0603765\n",
      "\tspeed: 0.0114s/iter; left time: 243.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0622096 Vali Loss: 0.0716747 Test Loss: 0.0817658\n",
      "Validation loss decreased (0.071902 --> 0.071675).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0613188\n",
      "\tspeed: 0.0292s/iter; left time: 618.5483s\n",
      "\titers: 200, epoch: 6 | loss: 0.0585596\n",
      "\tspeed: 0.0115s/iter; left time: 243.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0613992 Vali Loss: 0.0709265 Test Loss: 0.0814199\n",
      "Validation loss decreased (0.071675 --> 0.070926).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581186\n",
      "\tspeed: 0.0288s/iter; left time: 602.6529s\n",
      "\titers: 200, epoch: 7 | loss: 0.0601980\n",
      "\tspeed: 0.0114s/iter; left time: 238.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0607734 Vali Loss: 0.0705771 Test Loss: 0.0811658\n",
      "Validation loss decreased (0.070926 --> 0.070577).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0599504\n",
      "\tspeed: 0.0287s/iter; left time: 594.8931s\n",
      "\titers: 200, epoch: 8 | loss: 0.0627330\n",
      "\tspeed: 0.0114s/iter; left time: 234.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0602172 Vali Loss: 0.0707170 Test Loss: 0.0811702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0582917\n",
      "\tspeed: 0.0280s/iter; left time: 574.3010s\n",
      "\titers: 200, epoch: 9 | loss: 0.0607997\n",
      "\tspeed: 0.0114s/iter; left time: 232.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0597521 Vali Loss: 0.0708032 Test Loss: 0.0809484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0596805\n",
      "\tspeed: 0.0285s/iter; left time: 578.3936s\n",
      "\titers: 200, epoch: 10 | loss: 0.0599481\n",
      "\tspeed: 0.0114s/iter; left time: 231.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0594114 Vali Loss: 0.0709393 Test Loss: 0.0808087\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0559060\n",
      "\tspeed: 0.0286s/iter; left time: 572.8847s\n",
      "\titers: 200, epoch: 11 | loss: 0.0589835\n",
      "\tspeed: 0.0116s/iter; left time: 231.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0590685 Vali Loss: 0.0707514 Test Loss: 0.0809203\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0602128\n",
      "\tspeed: 0.0293s/iter; left time: 581.4523s\n",
      "\titers: 200, epoch: 12 | loss: 0.0592024\n",
      "\tspeed: 0.0117s/iter; left time: 229.9393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0587862 Vali Loss: 0.0708335 Test Loss: 0.0807095\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580792\n",
      "\tspeed: 0.0294s/iter; left time: 576.3357s\n",
      "\titers: 200, epoch: 13 | loss: 0.0547504\n",
      "\tspeed: 0.0115s/iter; left time: 223.4590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0584698 Vali Loss: 0.0707657 Test Loss: 0.0807335\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0601844\n",
      "\tspeed: 0.0297s/iter; left time: 576.1537s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572699\n",
      "\tspeed: 0.0119s/iter; left time: 229.1257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0582468 Vali Loss: 0.0709575 Test Loss: 0.0809022\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0584695\n",
      "\tspeed: 0.0288s/iter; left time: 552.2478s\n",
      "\titers: 200, epoch: 15 | loss: 0.0578075\n",
      "\tspeed: 0.0115s/iter; left time: 218.8193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0580251 Vali Loss: 0.0708869 Test Loss: 0.0806350\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0605491\n",
      "\tspeed: 0.0289s/iter; left time: 546.6400s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561613\n",
      "\tspeed: 0.0115s/iter; left time: 216.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0577797 Vali Loss: 0.0710255 Test Loss: 0.0806221\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0595750\n",
      "\tspeed: 0.0292s/iter; left time: 547.1611s\n",
      "\titers: 200, epoch: 17 | loss: 0.0611041\n",
      "\tspeed: 0.0115s/iter; left time: 213.6597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0576120 Vali Loss: 0.0709482 Test Loss: 0.0805590\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019104918465018272, rmse:0.13822054862976074, mae:0.08116577565670013, rse:0.534673810005188\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1202747\n",
      "\tspeed: 0.0136s/iter; left time: 304.0579s\n",
      "\titers: 200, epoch: 1 | loss: 0.0997065\n",
      "\tspeed: 0.0115s/iter; left time: 254.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.1172957 Vali Loss: 0.1020921 Test Loss: 0.1127334\n",
      "Validation loss decreased (inf --> 0.102092).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0724823\n",
      "\tspeed: 0.0326s/iter; left time: 720.8064s\n",
      "\titers: 200, epoch: 2 | loss: 0.0699062\n",
      "\tspeed: 0.0115s/iter; left time: 253.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.98s\n",
      "Steps: 224 | Train Loss: 0.0735782 Vali Loss: 0.0765092 Test Loss: 0.0841945\n",
      "Validation loss decreased (0.102092 --> 0.076509).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0662696\n",
      "\tspeed: 0.0307s/iter; left time: 671.7733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645706\n",
      "\tspeed: 0.0115s/iter; left time: 251.0375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0657694 Vali Loss: 0.0733837 Test Loss: 0.0831204\n",
      "Validation loss decreased (0.076509 --> 0.073384).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0611530\n",
      "\tspeed: 0.0287s/iter; left time: 621.3655s\n",
      "\titers: 200, epoch: 4 | loss: 0.0659544\n",
      "\tspeed: 0.0115s/iter; left time: 248.1174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0634075 Vali Loss: 0.0722505 Test Loss: 0.0823108\n",
      "Validation loss decreased (0.073384 --> 0.072250).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0658578\n",
      "\tspeed: 0.0356s/iter; left time: 762.3698s\n",
      "\titers: 200, epoch: 5 | loss: 0.0574036\n",
      "\tspeed: 0.0115s/iter; left time: 245.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0621686 Vali Loss: 0.0717408 Test Loss: 0.0818696\n",
      "Validation loss decreased (0.072250 --> 0.071741).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0610497\n",
      "\tspeed: 0.0301s/iter; left time: 638.4846s\n",
      "\titers: 200, epoch: 6 | loss: 0.0636622\n",
      "\tspeed: 0.0114s/iter; left time: 240.5407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0612845 Vali Loss: 0.0714861 Test Loss: 0.0818076\n",
      "Validation loss decreased (0.071741 --> 0.071486).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585363\n",
      "\tspeed: 0.0290s/iter; left time: 607.5532s\n",
      "\titers: 200, epoch: 7 | loss: 0.0656659\n",
      "\tspeed: 0.0115s/iter; left time: 238.8302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0606305 Vali Loss: 0.0714486 Test Loss: 0.0817776\n",
      "Validation loss decreased (0.071486 --> 0.071449).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0635940\n",
      "\tspeed: 0.0283s/iter; left time: 587.0694s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629447\n",
      "\tspeed: 0.0114s/iter; left time: 236.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0600929 Vali Loss: 0.0711712 Test Loss: 0.0811652\n",
      "Validation loss decreased (0.071449 --> 0.071171).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0600899\n",
      "\tspeed: 0.0294s/iter; left time: 603.7815s\n",
      "\titers: 200, epoch: 9 | loss: 0.0571586\n",
      "\tspeed: 0.0117s/iter; left time: 238.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 224 | Train Loss: 0.0596494 Vali Loss: 0.0711967 Test Loss: 0.0813785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0557992\n",
      "\tspeed: 0.0283s/iter; left time: 574.7597s\n",
      "\titers: 200, epoch: 10 | loss: 0.0644642\n",
      "\tspeed: 0.0115s/iter; left time: 231.5481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0592877 Vali Loss: 0.0710584 Test Loss: 0.0814269\n",
      "Validation loss decreased (0.071171 --> 0.071058).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0601218\n",
      "\tspeed: 0.0288s/iter; left time: 576.9253s\n",
      "\titers: 200, epoch: 11 | loss: 0.0572920\n",
      "\tspeed: 0.0115s/iter; left time: 229.6208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0589017 Vali Loss: 0.0709550 Test Loss: 0.0808641\n",
      "Validation loss decreased (0.071058 --> 0.070955).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0561160\n",
      "\tspeed: 0.0292s/iter; left time: 579.4172s\n",
      "\titers: 200, epoch: 12 | loss: 0.0599036\n",
      "\tspeed: 0.0115s/iter; left time: 227.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0585683 Vali Loss: 0.0708470 Test Loss: 0.0811279\n",
      "Validation loss decreased (0.070955 --> 0.070847).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0578002\n",
      "\tspeed: 0.0288s/iter; left time: 565.7638s\n",
      "\titers: 200, epoch: 13 | loss: 0.0568185\n",
      "\tspeed: 0.0115s/iter; left time: 223.4907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0583111 Vali Loss: 0.0708244 Test Loss: 0.0807075\n",
      "Validation loss decreased (0.070847 --> 0.070824).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0589670\n",
      "\tspeed: 0.0296s/iter; left time: 574.2355s\n",
      "\titers: 200, epoch: 14 | loss: 0.0602821\n",
      "\tspeed: 0.0115s/iter; left time: 222.1835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0580342 Vali Loss: 0.0709775 Test Loss: 0.0811160\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0572604\n",
      "\tspeed: 0.0283s/iter; left time: 542.2359s\n",
      "\titers: 200, epoch: 15 | loss: 0.0548296\n",
      "\tspeed: 0.0116s/iter; left time: 220.7933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0578016 Vali Loss: 0.0711745 Test Loss: 0.0809998\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0559784\n",
      "\tspeed: 0.0283s/iter; left time: 536.3527s\n",
      "\titers: 200, epoch: 16 | loss: 0.0546374\n",
      "\tspeed: 0.0115s/iter; left time: 216.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0576136 Vali Loss: 0.0709519 Test Loss: 0.0813246\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0554312\n",
      "\tspeed: 0.0282s/iter; left time: 527.8571s\n",
      "\titers: 200, epoch: 17 | loss: 0.0553518\n",
      "\tspeed: 0.0150s/iter; left time: 279.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0574008 Vali Loss: 0.0709440 Test Loss: 0.0813238\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0609418\n",
      "\tspeed: 0.0304s/iter; left time: 563.0885s\n",
      "\titers: 200, epoch: 18 | loss: 0.0602370\n",
      "\tspeed: 0.0123s/iter; left time: 226.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 224 | Train Loss: 0.0572644 Vali Loss: 0.0708922 Test Loss: 0.0807067\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0567405\n",
      "\tspeed: 0.0286s/iter; left time: 522.1297s\n",
      "\titers: 200, epoch: 19 | loss: 0.0609923\n",
      "\tspeed: 0.0115s/iter; left time: 208.2564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0570852 Vali Loss: 0.0709221 Test Loss: 0.0807636\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0577074\n",
      "\tspeed: 0.0284s/iter; left time: 513.0471s\n",
      "\titers: 200, epoch: 20 | loss: 0.0550699\n",
      "\tspeed: 0.0114s/iter; left time: 205.0719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0569364 Vali Loss: 0.0711125 Test Loss: 0.0807787\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0527635\n",
      "\tspeed: 0.0288s/iter; left time: 513.0796s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540943\n",
      "\tspeed: 0.0117s/iter; left time: 207.9627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0568357 Vali Loss: 0.0709099 Test Loss: 0.0807269\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0585099\n",
      "\tspeed: 0.0298s/iter; left time: 524.2997s\n",
      "\titers: 200, epoch: 22 | loss: 0.0544598\n",
      "\tspeed: 0.0115s/iter; left time: 201.8083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 224 | Train Loss: 0.0567021 Vali Loss: 0.0709461 Test Loss: 0.0808696\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0530666\n",
      "\tspeed: 0.0283s/iter; left time: 491.9747s\n",
      "\titers: 200, epoch: 23 | loss: 0.0548214\n",
      "\tspeed: 0.0114s/iter; left time: 197.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0566524 Vali Loss: 0.0710457 Test Loss: 0.0806964\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019121399149298668, rmse:0.13828015327453613, mae:0.08070749044418335, rse:0.534904420375824\n",
      "Intermediate time for FR and pred_len 96: 00h:02m:52.21s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1183062\n",
      "\tspeed: 0.0326s/iter; left time: 724.4086s\n",
      "\titers: 200, epoch: 1 | loss: 0.0972488\n",
      "\tspeed: 0.0118s/iter; left time: 260.2313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 223 | Train Loss: 0.1167069 Vali Loss: 0.1032240 Test Loss: 0.1129787\n",
      "Validation loss decreased (inf --> 0.103224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0826022\n",
      "\tspeed: 0.0285s/iter; left time: 625.7590s\n",
      "\titers: 200, epoch: 2 | loss: 0.0746639\n",
      "\tspeed: 0.0116s/iter; left time: 253.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0773228 Vali Loss: 0.0803081 Test Loss: 0.0886298\n",
      "Validation loss decreased (0.103224 --> 0.080308).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0714847\n",
      "\tspeed: 0.0288s/iter; left time: 627.4706s\n",
      "\titers: 200, epoch: 3 | loss: 0.0688747\n",
      "\tspeed: 0.0117s/iter; left time: 253.3312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0697671 Vali Loss: 0.0767658 Test Loss: 0.0878571\n",
      "Validation loss decreased (0.080308 --> 0.076766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0678537\n",
      "\tspeed: 0.0280s/iter; left time: 603.2707s\n",
      "\titers: 200, epoch: 4 | loss: 0.0696913\n",
      "\tspeed: 0.0116s/iter; left time: 248.3640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0672740 Vali Loss: 0.0758421 Test Loss: 0.0871055\n",
      "Validation loss decreased (0.076766 --> 0.075842).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0679309\n",
      "\tspeed: 0.0285s/iter; left time: 608.1568s\n",
      "\titers: 200, epoch: 5 | loss: 0.0694386\n",
      "\tspeed: 0.0117s/iter; left time: 247.1678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0661240 Vali Loss: 0.0754434 Test Loss: 0.0868867\n",
      "Validation loss decreased (0.075842 --> 0.075443).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640229\n",
      "\tspeed: 0.0278s/iter; left time: 585.6359s\n",
      "\titers: 200, epoch: 6 | loss: 0.0638434\n",
      "\tspeed: 0.0116s/iter; left time: 243.8989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0653081 Vali Loss: 0.0750301 Test Loss: 0.0866583\n",
      "Validation loss decreased (0.075443 --> 0.075030).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0656921\n",
      "\tspeed: 0.0286s/iter; left time: 597.1817s\n",
      "\titers: 200, epoch: 7 | loss: 0.0664725\n",
      "\tspeed: 0.0116s/iter; left time: 241.8808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0647015 Vali Loss: 0.0748772 Test Loss: 0.0860748\n",
      "Validation loss decreased (0.075030 --> 0.074877).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0677239\n",
      "\tspeed: 0.0285s/iter; left time: 587.6998s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618351\n",
      "\tspeed: 0.0116s/iter; left time: 237.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0641984 Vali Loss: 0.0750208 Test Loss: 0.0871818\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0654734\n",
      "\tspeed: 0.0284s/iter; left time: 579.5016s\n",
      "\titers: 200, epoch: 9 | loss: 0.0638321\n",
      "\tspeed: 0.0116s/iter; left time: 235.3208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0637861 Vali Loss: 0.0750694 Test Loss: 0.0867115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0613091\n",
      "\tspeed: 0.0297s/iter; left time: 598.8851s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665837\n",
      "\tspeed: 0.0118s/iter; left time: 236.1645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0634266 Vali Loss: 0.0752134 Test Loss: 0.0868901\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0667932\n",
      "\tspeed: 0.0289s/iter; left time: 576.4643s\n",
      "\titers: 200, epoch: 11 | loss: 0.0656480\n",
      "\tspeed: 0.0116s/iter; left time: 230.3746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0631315 Vali Loss: 0.0750217 Test Loss: 0.0868845\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0645292\n",
      "\tspeed: 0.0286s/iter; left time: 564.1102s\n",
      "\titers: 200, epoch: 12 | loss: 0.0635025\n",
      "\tspeed: 0.0116s/iter; left time: 228.3957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0628285 Vali Loss: 0.0754389 Test Loss: 0.0868052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0657857\n",
      "\tspeed: 0.0289s/iter; left time: 565.1541s\n",
      "\titers: 200, epoch: 13 | loss: 0.0647771\n",
      "\tspeed: 0.0117s/iter; left time: 226.6661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0625321 Vali Loss: 0.0755434 Test Loss: 0.0868018\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0628145\n",
      "\tspeed: 0.0311s/iter; left time: 600.1700s\n",
      "\titers: 200, epoch: 14 | loss: 0.0610082\n",
      "\tspeed: 0.0116s/iter; left time: 222.3763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 223 | Train Loss: 0.0623218 Vali Loss: 0.0754087 Test Loss: 0.0867675\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0582129\n",
      "\tspeed: 0.0278s/iter; left time: 530.0444s\n",
      "\titers: 200, epoch: 15 | loss: 0.0592832\n",
      "\tspeed: 0.0116s/iter; left time: 220.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0620963 Vali Loss: 0.0754471 Test Loss: 0.0867860\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0637070\n",
      "\tspeed: 0.0276s/iter; left time: 520.5158s\n",
      "\titers: 200, epoch: 16 | loss: 0.0591998\n",
      "\tspeed: 0.0118s/iter; left time: 221.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0618833 Vali Loss: 0.0753342 Test Loss: 0.0865934\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0607357\n",
      "\tspeed: 0.0280s/iter; left time: 520.8164s\n",
      "\titers: 200, epoch: 17 | loss: 0.0623769\n",
      "\tspeed: 0.0116s/iter; left time: 215.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0616434 Vali Loss: 0.0755258 Test Loss: 0.0866825\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02051929198205471, rmse:0.14324556291103363, mae:0.08607485145330429, rse:0.5548036694526672\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1196070\n",
      "\tspeed: 0.0139s/iter; left time: 309.6872s\n",
      "\titers: 200, epoch: 1 | loss: 0.0991641\n",
      "\tspeed: 0.0118s/iter; left time: 261.1475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 223 | Train Loss: 0.1187108 Vali Loss: 0.1047201 Test Loss: 0.1147742\n",
      "Validation loss decreased (inf --> 0.104720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0759056\n",
      "\tspeed: 0.0288s/iter; left time: 633.0486s\n",
      "\titers: 200, epoch: 2 | loss: 0.0740525\n",
      "\tspeed: 0.0116s/iter; left time: 254.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0777051 Vali Loss: 0.0807842 Test Loss: 0.0889279\n",
      "Validation loss decreased (0.104720 --> 0.080784).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0715236\n",
      "\tspeed: 0.0284s/iter; left time: 617.0570s\n",
      "\titers: 200, epoch: 3 | loss: 0.0709061\n",
      "\tspeed: 0.0119s/iter; left time: 257.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0699242 Vali Loss: 0.0770965 Test Loss: 0.0878408\n",
      "Validation loss decreased (0.080784 --> 0.077096).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0693474\n",
      "\tspeed: 0.0349s/iter; left time: 751.5702s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656085\n",
      "\tspeed: 0.0121s/iter; left time: 259.0919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.54s\n",
      "Steps: 223 | Train Loss: 0.0672657 Vali Loss: 0.0760175 Test Loss: 0.0872544\n",
      "Validation loss decreased (0.077096 --> 0.076018).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0642087\n",
      "\tspeed: 0.0301s/iter; left time: 640.6915s\n",
      "\titers: 200, epoch: 5 | loss: 0.0657723\n",
      "\tspeed: 0.0116s/iter; left time: 246.9897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0660367 Vali Loss: 0.0757802 Test Loss: 0.0867391\n",
      "Validation loss decreased (0.076018 --> 0.075780).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0622980\n",
      "\tspeed: 0.0301s/iter; left time: 634.9351s\n",
      "\titers: 200, epoch: 6 | loss: 0.0686944\n",
      "\tspeed: 0.0118s/iter; left time: 247.1987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0652520 Vali Loss: 0.0753642 Test Loss: 0.0869520\n",
      "Validation loss decreased (0.075780 --> 0.075364).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0659844\n",
      "\tspeed: 0.0288s/iter; left time: 601.7811s\n",
      "\titers: 200, epoch: 7 | loss: 0.0639728\n",
      "\tspeed: 0.0117s/iter; left time: 241.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0645989 Vali Loss: 0.0751798 Test Loss: 0.0866093\n",
      "Validation loss decreased (0.075364 --> 0.075180).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0660233\n",
      "\tspeed: 0.0288s/iter; left time: 595.4611s\n",
      "\titers: 200, epoch: 8 | loss: 0.0654770\n",
      "\tspeed: 0.0117s/iter; left time: 239.6755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0641456 Vali Loss: 0.0750786 Test Loss: 0.0873281\n",
      "Validation loss decreased (0.075180 --> 0.075079).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0617195\n",
      "\tspeed: 0.0318s/iter; left time: 649.1786s\n",
      "\titers: 200, epoch: 9 | loss: 0.0641228\n",
      "\tspeed: 0.0117s/iter; left time: 237.5595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.96s\n",
      "Steps: 223 | Train Loss: 0.0637072 Vali Loss: 0.0752936 Test Loss: 0.0870615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0672789\n",
      "\tspeed: 0.0316s/iter; left time: 638.3741s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623632\n",
      "\tspeed: 0.0116s/iter; left time: 233.8740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.15s\n",
      "Steps: 223 | Train Loss: 0.0633528 Vali Loss: 0.0750333 Test Loss: 0.0871743\n",
      "Validation loss decreased (0.075079 --> 0.075033).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0610288\n",
      "\tspeed: 0.0284s/iter; left time: 567.1154s\n",
      "\titers: 200, epoch: 11 | loss: 0.0639119\n",
      "\tspeed: 0.0116s/iter; left time: 229.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0629256 Vali Loss: 0.0754412 Test Loss: 0.0874779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0596511\n",
      "\tspeed: 0.0277s/iter; left time: 547.4653s\n",
      "\titers: 200, epoch: 12 | loss: 0.0594631\n",
      "\tspeed: 0.0116s/iter; left time: 227.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0626853 Vali Loss: 0.0752531 Test Loss: 0.0873468\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0607190\n",
      "\tspeed: 0.0279s/iter; left time: 544.9899s\n",
      "\titers: 200, epoch: 13 | loss: 0.0616579\n",
      "\tspeed: 0.0116s/iter; left time: 225.6662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0624312 Vali Loss: 0.0754905 Test Loss: 0.0876238\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0630206\n",
      "\tspeed: 0.0283s/iter; left time: 546.7674s\n",
      "\titers: 200, epoch: 14 | loss: 0.0584795\n",
      "\tspeed: 0.0116s/iter; left time: 222.6197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0621537 Vali Loss: 0.0753516 Test Loss: 0.0876249\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0633316\n",
      "\tspeed: 0.0277s/iter; left time: 528.1290s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631492\n",
      "\tspeed: 0.0116s/iter; left time: 219.2963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0619284 Vali Loss: 0.0754504 Test Loss: 0.0878295\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0618166\n",
      "\tspeed: 0.0275s/iter; left time: 519.0067s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622232\n",
      "\tspeed: 0.0116s/iter; left time: 217.5415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0616984 Vali Loss: 0.0755137 Test Loss: 0.0876411\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0604809\n",
      "\tspeed: 0.0300s/iter; left time: 559.7905s\n",
      "\titers: 200, epoch: 17 | loss: 0.0627067\n",
      "\tspeed: 0.0121s/iter; left time: 224.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.00s\n",
      "Steps: 223 | Train Loss: 0.0615459 Vali Loss: 0.0756106 Test Loss: 0.0875299\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0609364\n",
      "\tspeed: 0.0304s/iter; left time: 559.1458s\n",
      "\titers: 200, epoch: 18 | loss: 0.0597911\n",
      "\tspeed: 0.0121s/iter; left time: 220.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.01s\n",
      "Steps: 223 | Train Loss: 0.0613814 Vali Loss: 0.0755966 Test Loss: 0.0874698\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657953\n",
      "\tspeed: 0.0311s/iter; left time: 565.0986s\n",
      "\titers: 200, epoch: 19 | loss: 0.0604367\n",
      "\tspeed: 0.0121s/iter; left time: 219.3691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 223 | Train Loss: 0.0612321 Vali Loss: 0.0755664 Test Loss: 0.0874581\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0591604\n",
      "\tspeed: 0.0289s/iter; left time: 519.8660s\n",
      "\titers: 200, epoch: 20 | loss: 0.0602056\n",
      "\tspeed: 0.0121s/iter; left time: 216.4813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.0610781 Vali Loss: 0.0758279 Test Loss: 0.0878313\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021033791825175285, rmse:0.14503031969070435, mae:0.08717425912618637, rse:0.5617161393165588\n",
      "Intermediate time for FR and pred_len 168: 00h:02m:40.87s\n",
      "Intermediate time for FR: 00h:12m:41.35s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1628962\n",
      "\tspeed: 0.0323s/iter; left time: 721.0037s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291237\n",
      "\tspeed: 0.0113s/iter; left time: 250.9960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.1621927 Vali Loss: 0.1139153 Test Loss: 0.1173210\n",
      "Validation loss decreased (inf --> 0.113915).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784920\n",
      "\tspeed: 0.0270s/iter; left time: 595.6097s\n",
      "\titers: 200, epoch: 2 | loss: 0.0711628\n",
      "\tspeed: 0.0113s/iter; left time: 248.5811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.08s\n",
      "Steps: 224 | Train Loss: 0.0831000 Vali Loss: 0.0642116 Test Loss: 0.0672076\n",
      "Validation loss decreased (0.113915 --> 0.064212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0703022\n",
      "\tspeed: 0.0309s/iter; left time: 675.7827s\n",
      "\titers: 200, epoch: 3 | loss: 0.0671893\n",
      "\tspeed: 0.0115s/iter; left time: 250.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0678163 Vali Loss: 0.0607519 Test Loss: 0.0635062\n",
      "Validation loss decreased (0.064212 --> 0.060752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0609002\n",
      "\tspeed: 0.0278s/iter; left time: 600.5293s\n",
      "\titers: 200, epoch: 4 | loss: 0.0623605\n",
      "\tspeed: 0.0114s/iter; left time: 245.8828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0644234 Vali Loss: 0.0591367 Test Loss: 0.0617633\n",
      "Validation loss decreased (0.060752 --> 0.059137).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0633016\n",
      "\tspeed: 0.0271s/iter; left time: 580.4390s\n",
      "\titers: 200, epoch: 5 | loss: 0.0651986\n",
      "\tspeed: 0.0115s/iter; left time: 245.9528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0625412 Vali Loss: 0.0581853 Test Loss: 0.0606249\n",
      "Validation loss decreased (0.059137 --> 0.058185).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0649286\n",
      "\tspeed: 0.0271s/iter; left time: 573.4416s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616859\n",
      "\tspeed: 0.0114s/iter; left time: 240.4960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0611915 Vali Loss: 0.0574970 Test Loss: 0.0600334\n",
      "Validation loss decreased (0.058185 --> 0.057497).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0590814\n",
      "\tspeed: 0.0274s/iter; left time: 574.7981s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585640\n",
      "\tspeed: 0.0113s/iter; left time: 236.4215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0602745 Vali Loss: 0.0569347 Test Loss: 0.0594827\n",
      "Validation loss decreased (0.057497 --> 0.056935).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0607947\n",
      "\tspeed: 0.0271s/iter; left time: 562.2889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0553050\n",
      "\tspeed: 0.0113s/iter; left time: 232.1241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0595292 Vali Loss: 0.0563626 Test Loss: 0.0592692\n",
      "Validation loss decreased (0.056935 --> 0.056363).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550640\n",
      "\tspeed: 0.0275s/iter; left time: 563.4513s\n",
      "\titers: 200, epoch: 9 | loss: 0.0581901\n",
      "\tspeed: 0.0113s/iter; left time: 230.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0589363 Vali Loss: 0.0561472 Test Loss: 0.0590204\n",
      "Validation loss decreased (0.056363 --> 0.056147).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0586622\n",
      "\tspeed: 0.0274s/iter; left time: 555.3161s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589459\n",
      "\tspeed: 0.0115s/iter; left time: 232.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0584518 Vali Loss: 0.0559549 Test Loss: 0.0588039\n",
      "Validation loss decreased (0.056147 --> 0.055955).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0604423\n",
      "\tspeed: 0.0289s/iter; left time: 580.5415s\n",
      "\titers: 200, epoch: 11 | loss: 0.0600132\n",
      "\tspeed: 0.0115s/iter; left time: 230.0747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 224 | Train Loss: 0.0579917 Vali Loss: 0.0557425 Test Loss: 0.0584588\n",
      "Validation loss decreased (0.055955 --> 0.055742).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0585862\n",
      "\tspeed: 0.0295s/iter; left time: 585.3972s\n",
      "\titers: 200, epoch: 12 | loss: 0.0565248\n",
      "\tspeed: 0.0116s/iter; left time: 229.5513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0575839 Vali Loss: 0.0553778 Test Loss: 0.0581512\n",
      "Validation loss decreased (0.055742 --> 0.055378).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0592767\n",
      "\tspeed: 0.0275s/iter; left time: 539.6379s\n",
      "\titers: 200, epoch: 13 | loss: 0.0601190\n",
      "\tspeed: 0.0112s/iter; left time: 218.7717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0572631 Vali Loss: 0.0554036 Test Loss: 0.0582940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0584438\n",
      "\tspeed: 0.0265s/iter; left time: 514.4744s\n",
      "\titers: 200, epoch: 14 | loss: 0.0597098\n",
      "\tspeed: 0.0112s/iter; left time: 216.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0570509 Vali Loss: 0.0552208 Test Loss: 0.0581448\n",
      "Validation loss decreased (0.055378 --> 0.055221).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0570238\n",
      "\tspeed: 0.0280s/iter; left time: 536.2910s\n",
      "\titers: 200, epoch: 15 | loss: 0.0546779\n",
      "\tspeed: 0.0113s/iter; left time: 215.5787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0568364 Vali Loss: 0.0549905 Test Loss: 0.0578448\n",
      "Validation loss decreased (0.055221 --> 0.054990).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0585651\n",
      "\tspeed: 0.0305s/iter; left time: 578.5716s\n",
      "\titers: 200, epoch: 16 | loss: 0.0602605\n",
      "\tspeed: 0.0113s/iter; left time: 212.4132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0566376 Vali Loss: 0.0548767 Test Loss: 0.0577145\n",
      "Validation loss decreased (0.054990 --> 0.054877).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632500\n",
      "\tspeed: 0.0271s/iter; left time: 508.0807s\n",
      "\titers: 200, epoch: 17 | loss: 0.0582883\n",
      "\tspeed: 0.0114s/iter; left time: 212.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0564069 Vali Loss: 0.0548520 Test Loss: 0.0575403\n",
      "Validation loss decreased (0.054877 --> 0.054852).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549437\n",
      "\tspeed: 0.0269s/iter; left time: 496.7988s\n",
      "\titers: 200, epoch: 18 | loss: 0.0606063\n",
      "\tspeed: 0.0113s/iter; left time: 207.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0563488 Vali Loss: 0.0549136 Test Loss: 0.0575645\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0539349\n",
      "\tspeed: 0.0267s/iter; left time: 487.6266s\n",
      "\titers: 200, epoch: 19 | loss: 0.0541664\n",
      "\tspeed: 0.0115s/iter; left time: 208.1700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0561536 Vali Loss: 0.0546398 Test Loss: 0.0574950\n",
      "Validation loss decreased (0.054852 --> 0.054640).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0571351\n",
      "\tspeed: 0.0273s/iter; left time: 492.1096s\n",
      "\titers: 200, epoch: 20 | loss: 0.0553324\n",
      "\tspeed: 0.0113s/iter; left time: 202.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0560287 Vali Loss: 0.0546072 Test Loss: 0.0573911\n",
      "Validation loss decreased (0.054640 --> 0.054607).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0551183\n",
      "\tspeed: 0.0275s/iter; left time: 489.4356s\n",
      "\titers: 200, epoch: 21 | loss: 0.0564215\n",
      "\tspeed: 0.0113s/iter; left time: 200.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0559125 Vali Loss: 0.0546022 Test Loss: 0.0573388\n",
      "Validation loss decreased (0.054607 --> 0.054602).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0550485\n",
      "\tspeed: 0.0280s/iter; left time: 493.3136s\n",
      "\titers: 200, epoch: 22 | loss: 0.0549185\n",
      "\tspeed: 0.0113s/iter; left time: 196.9036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0557625 Vali Loss: 0.0545448 Test Loss: 0.0572780\n",
      "Validation loss decreased (0.054602 --> 0.054545).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0529031\n",
      "\tspeed: 0.0271s/iter; left time: 471.4999s\n",
      "\titers: 200, epoch: 23 | loss: 0.0559061\n",
      "\tspeed: 0.0112s/iter; left time: 194.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0556667 Vali Loss: 0.0544226 Test Loss: 0.0574013\n",
      "Validation loss decreased (0.054545 --> 0.054423).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0553906\n",
      "\tspeed: 0.0269s/iter; left time: 462.1144s\n",
      "\titers: 200, epoch: 24 | loss: 0.0569743\n",
      "\tspeed: 0.0112s/iter; left time: 191.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0555913 Vali Loss: 0.0544965 Test Loss: 0.0573184\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0558775\n",
      "\tspeed: 0.0314s/iter; left time: 532.2548s\n",
      "\titers: 200, epoch: 25 | loss: 0.0584561\n",
      "\tspeed: 0.0117s/iter; left time: 196.5459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0555889 Vali Loss: 0.0544424 Test Loss: 0.0573293\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0535390\n",
      "\tspeed: 0.0273s/iter; left time: 455.8555s\n",
      "\titers: 200, epoch: 26 | loss: 0.0533086\n",
      "\tspeed: 0.0113s/iter; left time: 187.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0554472 Vali Loss: 0.0545179 Test Loss: 0.0572531\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0575048\n",
      "\tspeed: 0.0267s/iter; left time: 439.8597s\n",
      "\titers: 200, epoch: 27 | loss: 0.0554067\n",
      "\tspeed: 0.0114s/iter; left time: 187.3833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0553966 Vali Loss: 0.0544062 Test Loss: 0.0572583\n",
      "Validation loss decreased (0.054423 --> 0.054406).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0545062\n",
      "\tspeed: 0.0285s/iter; left time: 462.7635s\n",
      "\titers: 200, epoch: 28 | loss: 0.0578673\n",
      "\tspeed: 0.0115s/iter; left time: 186.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0554085 Vali Loss: 0.0543560 Test Loss: 0.0571799\n",
      "Validation loss decreased (0.054406 --> 0.054356).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0581800\n",
      "\tspeed: 0.0293s/iter; left time: 470.3190s\n",
      "\titers: 200, epoch: 29 | loss: 0.0543779\n",
      "\tspeed: 0.0114s/iter; left time: 181.0275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0553138 Vali Loss: 0.0543542 Test Loss: 0.0571868\n",
      "Validation loss decreased (0.054356 --> 0.054354).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0574906\n",
      "\tspeed: 0.0277s/iter; left time: 437.3962s\n",
      "\titers: 200, epoch: 30 | loss: 0.0527260\n",
      "\tspeed: 0.0113s/iter; left time: 177.0714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0553084 Vali Loss: 0.0542786 Test Loss: 0.0571788\n",
      "Validation loss decreased (0.054354 --> 0.054279).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0565198\n",
      "\tspeed: 0.0292s/iter; left time: 455.0387s\n",
      "\titers: 200, epoch: 31 | loss: 0.0544182\n",
      "\tspeed: 0.0114s/iter; left time: 177.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0552864 Vali Loss: 0.0543370 Test Loss: 0.0572038\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0568051\n",
      "\tspeed: 0.0271s/iter; left time: 415.6273s\n",
      "\titers: 200, epoch: 32 | loss: 0.0526484\n",
      "\tspeed: 0.0115s/iter; left time: 175.6289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0552234 Vali Loss: 0.0543966 Test Loss: 0.0571805\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0555857\n",
      "\tspeed: 0.0275s/iter; left time: 415.8895s\n",
      "\titers: 200, epoch: 33 | loss: 0.0554315\n",
      "\tspeed: 0.0115s/iter; left time: 172.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0552089 Vali Loss: 0.0542539 Test Loss: 0.0571902\n",
      "Validation loss decreased (0.054279 --> 0.054254).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0574522\n",
      "\tspeed: 0.0281s/iter; left time: 419.4321s\n",
      "\titers: 200, epoch: 34 | loss: 0.0497811\n",
      "\tspeed: 0.0116s/iter; left time: 171.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0551789 Vali Loss: 0.0542441 Test Loss: 0.0570834\n",
      "Validation loss decreased (0.054254 --> 0.054244).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0546958\n",
      "\tspeed: 0.0278s/iter; left time: 408.2895s\n",
      "\titers: 200, epoch: 35 | loss: 0.0585201\n",
      "\tspeed: 0.0117s/iter; left time: 170.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0551142 Vali Loss: 0.0541776 Test Loss: 0.0570566\n",
      "Validation loss decreased (0.054244 --> 0.054178).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0530606\n",
      "\tspeed: 0.0280s/iter; left time: 404.2961s\n",
      "\titers: 200, epoch: 36 | loss: 0.0561301\n",
      "\tspeed: 0.0113s/iter; left time: 161.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0551285 Vali Loss: 0.0542435 Test Loss: 0.0570634\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0564692\n",
      "\tspeed: 0.0270s/iter; left time: 384.2674s\n",
      "\titers: 200, epoch: 37 | loss: 0.0554068\n",
      "\tspeed: 0.0116s/iter; left time: 163.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0550264 Vali Loss: 0.0542894 Test Loss: 0.0570607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0552474\n",
      "\tspeed: 0.0312s/iter; left time: 436.6144s\n",
      "\titers: 200, epoch: 38 | loss: 0.0548336\n",
      "\tspeed: 0.0132s/iter; left time: 183.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.16s\n",
      "Steps: 224 | Train Loss: 0.0550615 Vali Loss: 0.0542020 Test Loss: 0.0570730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0538463\n",
      "\tspeed: 0.0279s/iter; left time: 384.4913s\n",
      "\titers: 200, epoch: 39 | loss: 0.0539861\n",
      "\tspeed: 0.0125s/iter; left time: 171.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.97s\n",
      "Steps: 224 | Train Loss: 0.0550491 Vali Loss: 0.0542294 Test Loss: 0.0570961\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0536759\n",
      "\tspeed: 0.0275s/iter; left time: 373.6331s\n",
      "\titers: 200, epoch: 40 | loss: 0.0483431\n",
      "\tspeed: 0.0115s/iter; left time: 154.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0550534 Vali Loss: 0.0541880 Test Loss: 0.0570852\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0547417\n",
      "\tspeed: 0.0287s/iter; left time: 383.0984s\n",
      "\titers: 200, epoch: 41 | loss: 0.0567900\n",
      "\tspeed: 0.0119s/iter; left time: 156.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.94s\n",
      "Steps: 224 | Train Loss: 0.0550166 Vali Loss: 0.0542468 Test Loss: 0.0570635\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0524154\n",
      "\tspeed: 0.0298s/iter; left time: 390.3533s\n",
      "\titers: 200, epoch: 42 | loss: 0.0557357\n",
      "\tspeed: 0.0113s/iter; left time: 146.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0550991 Vali Loss: 0.0541964 Test Loss: 0.0570450\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0544907\n",
      "\tspeed: 0.0285s/iter; left time: 367.6974s\n",
      "\titers: 200, epoch: 43 | loss: 0.0554809\n",
      "\tspeed: 0.0113s/iter; left time: 143.9898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0550477 Vali Loss: 0.0541649 Test Loss: 0.0570568\n",
      "Validation loss decreased (0.054178 --> 0.054165).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0572955\n",
      "\tspeed: 0.0278s/iter; left time: 351.9928s\n",
      "\titers: 200, epoch: 44 | loss: 0.0526229\n",
      "\tspeed: 0.0112s/iter; left time: 140.7375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0549734 Vali Loss: 0.0542250 Test Loss: 0.0570648\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0560282\n",
      "\tspeed: 0.0277s/iter; left time: 344.9527s\n",
      "\titers: 200, epoch: 45 | loss: 0.0536372\n",
      "\tspeed: 0.0115s/iter; left time: 141.9752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0550630 Vali Loss: 0.0542448 Test Loss: 0.0570366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0532626\n",
      "\tspeed: 0.0276s/iter; left time: 337.7153s\n",
      "\titers: 200, epoch: 46 | loss: 0.0588370\n",
      "\tspeed: 0.0112s/iter; left time: 135.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0549567 Vali Loss: 0.0542052 Test Loss: 0.0570502\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0532381\n",
      "\tspeed: 0.0271s/iter; left time: 324.7239s\n",
      "\titers: 200, epoch: 47 | loss: 0.0513831\n",
      "\tspeed: 0.0113s/iter; left time: 134.7957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0549874 Vali Loss: 0.0541965 Test Loss: 0.0570381\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0571143\n",
      "\tspeed: 0.0265s/iter; left time: 311.7603s\n",
      "\titers: 200, epoch: 48 | loss: 0.0567212\n",
      "\tspeed: 0.0112s/iter; left time: 130.3367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0549965 Vali Loss: 0.0542004 Test Loss: 0.0570543\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0525883\n",
      "\tspeed: 0.0264s/iter; left time: 305.1824s\n",
      "\titers: 200, epoch: 49 | loss: 0.0572507\n",
      "\tspeed: 0.0111s/iter; left time: 127.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.73s\n",
      "Steps: 224 | Train Loss: 0.0549131 Vali Loss: 0.0542011 Test Loss: 0.0570366\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0527183\n",
      "\tspeed: 0.0267s/iter; left time: 302.8233s\n",
      "\titers: 200, epoch: 50 | loss: 0.0552614\n",
      "\tspeed: 0.0114s/iter; left time: 127.8290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0549383 Vali Loss: 0.0542075 Test Loss: 0.0570340\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0565664\n",
      "\tspeed: 0.0263s/iter; left time: 292.3398s\n",
      "\titers: 200, epoch: 51 | loss: 0.0550123\n",
      "\tspeed: 0.0112s/iter; left time: 123.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.74s\n",
      "Steps: 224 | Train Loss: 0.0549761 Vali Loss: 0.0542216 Test Loss: 0.0570201\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0504080\n",
      "\tspeed: 0.0281s/iter; left time: 305.2802s\n",
      "\titers: 200, epoch: 52 | loss: 0.0563526\n",
      "\tspeed: 0.0112s/iter; left time: 120.5466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0549533 Vali Loss: 0.0541924 Test Loss: 0.0570153\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0578286\n",
      "\tspeed: 0.0281s/iter; left time: 299.0739s\n",
      "\titers: 200, epoch: 53 | loss: 0.0552493\n",
      "\tspeed: 0.0115s/iter; left time: 121.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0549942 Vali Loss: 0.0542160 Test Loss: 0.0570226\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010152997449040413, rmse:0.10076208412647247, mae:0.057056769728660583, rse:0.3807302713394165\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1605621\n",
      "\tspeed: 0.0139s/iter; left time: 310.7146s\n",
      "\titers: 200, epoch: 1 | loss: 0.1277546\n",
      "\tspeed: 0.0121s/iter; left time: 269.2542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.1583883 Vali Loss: 0.1113111 Test Loss: 0.1149016\n",
      "Validation loss decreased (inf --> 0.111311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0784654\n",
      "\tspeed: 0.0322s/iter; left time: 710.7869s\n",
      "\titers: 200, epoch: 2 | loss: 0.0696674\n",
      "\tspeed: 0.0133s/iter; left time: 292.3066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.27s\n",
      "Steps: 224 | Train Loss: 0.0819967 Vali Loss: 0.0645653 Test Loss: 0.0670399\n",
      "Validation loss decreased (0.111311 --> 0.064565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0724749\n",
      "\tspeed: 0.0307s/iter; left time: 671.3496s\n",
      "\titers: 200, epoch: 3 | loss: 0.0655474\n",
      "\tspeed: 0.0118s/iter; left time: 257.3611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.0676228 Vali Loss: 0.0606859 Test Loss: 0.0636061\n",
      "Validation loss decreased (0.064565 --> 0.060686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0672720\n",
      "\tspeed: 0.0276s/iter; left time: 596.2171s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656013\n",
      "\tspeed: 0.0118s/iter; left time: 254.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0642937 Vali Loss: 0.0590674 Test Loss: 0.0617162\n",
      "Validation loss decreased (0.060686 --> 0.059067).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0671563\n",
      "\tspeed: 0.0283s/iter; left time: 606.2383s\n",
      "\titers: 200, epoch: 5 | loss: 0.0664653\n",
      "\tspeed: 0.0119s/iter; left time: 253.4723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 224 | Train Loss: 0.0623796 Vali Loss: 0.0583224 Test Loss: 0.0606356\n",
      "Validation loss decreased (0.059067 --> 0.058322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0592326\n",
      "\tspeed: 0.0274s/iter; left time: 579.9400s\n",
      "\titers: 200, epoch: 6 | loss: 0.0618616\n",
      "\tspeed: 0.0118s/iter; left time: 248.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0611293 Vali Loss: 0.0573525 Test Loss: 0.0598334\n",
      "Validation loss decreased (0.058322 --> 0.057352).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0600818\n",
      "\tspeed: 0.0278s/iter; left time: 582.9605s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580605\n",
      "\tspeed: 0.0117s/iter; left time: 244.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0602744 Vali Loss: 0.0567742 Test Loss: 0.0595076\n",
      "Validation loss decreased (0.057352 --> 0.056774).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0571698\n",
      "\tspeed: 0.0276s/iter; left time: 571.9020s\n",
      "\titers: 200, epoch: 8 | loss: 0.0626226\n",
      "\tspeed: 0.0119s/iter; left time: 244.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0595094 Vali Loss: 0.0565310 Test Loss: 0.0589904\n",
      "Validation loss decreased (0.056774 --> 0.056531).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0601980\n",
      "\tspeed: 0.0266s/iter; left time: 545.4291s\n",
      "\titers: 200, epoch: 9 | loss: 0.0589777\n",
      "\tspeed: 0.0116s/iter; left time: 236.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0588105 Vali Loss: 0.0561032 Test Loss: 0.0588676\n",
      "Validation loss decreased (0.056531 --> 0.056103).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0554767\n",
      "\tspeed: 0.0275s/iter; left time: 558.7342s\n",
      "\titers: 200, epoch: 10 | loss: 0.0581255\n",
      "\tspeed: 0.0116s/iter; left time: 233.7596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0583527 Vali Loss: 0.0557523 Test Loss: 0.0584703\n",
      "Validation loss decreased (0.056103 --> 0.055752).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0558105\n",
      "\tspeed: 0.0276s/iter; left time: 554.1329s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585610\n",
      "\tspeed: 0.0117s/iter; left time: 233.7251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0579508 Vali Loss: 0.0554798 Test Loss: 0.0581610\n",
      "Validation loss decreased (0.055752 --> 0.055480).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0572418\n",
      "\tspeed: 0.0315s/iter; left time: 624.5238s\n",
      "\titers: 200, epoch: 12 | loss: 0.0564060\n",
      "\tspeed: 0.0137s/iter; left time: 270.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.33s\n",
      "Steps: 224 | Train Loss: 0.0575335 Vali Loss: 0.0554393 Test Loss: 0.0582057\n",
      "Validation loss decreased (0.055480 --> 0.055439).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559255\n",
      "\tspeed: 0.0287s/iter; left time: 563.2884s\n",
      "\titers: 200, epoch: 13 | loss: 0.0550545\n",
      "\tspeed: 0.0119s/iter; left time: 231.7240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0572026 Vali Loss: 0.0552020 Test Loss: 0.0578507\n",
      "Validation loss decreased (0.055439 --> 0.055202).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0563882\n",
      "\tspeed: 0.0272s/iter; left time: 527.8939s\n",
      "\titers: 200, epoch: 14 | loss: 0.0568423\n",
      "\tspeed: 0.0129s/iter; left time: 249.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0569021 Vali Loss: 0.0550165 Test Loss: 0.0578939\n",
      "Validation loss decreased (0.055202 --> 0.055016).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0557181\n",
      "\tspeed: 0.0302s/iter; left time: 579.1033s\n",
      "\titers: 200, epoch: 15 | loss: 0.0559319\n",
      "\tspeed: 0.0126s/iter; left time: 239.8200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.07s\n",
      "Steps: 224 | Train Loss: 0.0567267 Vali Loss: 0.0551258 Test Loss: 0.0579501\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0579334\n",
      "\tspeed: 0.0283s/iter; left time: 535.5347s\n",
      "\titers: 200, epoch: 16 | loss: 0.0582633\n",
      "\tspeed: 0.0118s/iter; left time: 223.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0565439 Vali Loss: 0.0548023 Test Loss: 0.0576225\n",
      "Validation loss decreased (0.055016 --> 0.054802).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0582140\n",
      "\tspeed: 0.0304s/iter; left time: 568.9095s\n",
      "\titers: 200, epoch: 17 | loss: 0.0583653\n",
      "\tspeed: 0.0119s/iter; left time: 220.6902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.13s\n",
      "Steps: 224 | Train Loss: 0.0563758 Vali Loss: 0.0548058 Test Loss: 0.0576926\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0535941\n",
      "\tspeed: 0.0285s/iter; left time: 526.9105s\n",
      "\titers: 200, epoch: 18 | loss: 0.0551172\n",
      "\tspeed: 0.0121s/iter; left time: 221.7088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0561761 Vali Loss: 0.0547211 Test Loss: 0.0575616\n",
      "Validation loss decreased (0.054802 --> 0.054721).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0594391\n",
      "\tspeed: 0.0278s/iter; left time: 508.4978s\n",
      "\titers: 200, epoch: 19 | loss: 0.0593594\n",
      "\tspeed: 0.0113s/iter; left time: 205.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0560246 Vali Loss: 0.0546523 Test Loss: 0.0574649\n",
      "Validation loss decreased (0.054721 --> 0.054652).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0548958\n",
      "\tspeed: 0.0277s/iter; left time: 499.8326s\n",
      "\titers: 200, epoch: 20 | loss: 0.0564744\n",
      "\tspeed: 0.0118s/iter; left time: 212.0954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0558867 Vali Loss: 0.0545992 Test Loss: 0.0572896\n",
      "Validation loss decreased (0.054652 --> 0.054599).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0615348\n",
      "\tspeed: 0.0278s/iter; left time: 494.7885s\n",
      "\titers: 200, epoch: 21 | loss: 0.0555285\n",
      "\tspeed: 0.0119s/iter; left time: 210.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0557557 Vali Loss: 0.0544675 Test Loss: 0.0573285\n",
      "Validation loss decreased (0.054599 --> 0.054467).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0559522\n",
      "\tspeed: 0.0282s/iter; left time: 495.5958s\n",
      "\titers: 200, epoch: 22 | loss: 0.0538334\n",
      "\tspeed: 0.0118s/iter; left time: 206.5512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0556659 Vali Loss: 0.0545536 Test Loss: 0.0573763\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0521547\n",
      "\tspeed: 0.0275s/iter; left time: 476.9829s\n",
      "\titers: 200, epoch: 23 | loss: 0.0547898\n",
      "\tspeed: 0.0118s/iter; left time: 203.5943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0555916 Vali Loss: 0.0544927 Test Loss: 0.0573701\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0534792\n",
      "\tspeed: 0.0288s/iter; left time: 494.6008s\n",
      "\titers: 200, epoch: 24 | loss: 0.0510001\n",
      "\tspeed: 0.0112s/iter; left time: 190.8441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.99s\n",
      "Steps: 224 | Train Loss: 0.0555200 Vali Loss: 0.0543616 Test Loss: 0.0572560\n",
      "Validation loss decreased (0.054467 --> 0.054362).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0515216\n",
      "\tspeed: 0.0294s/iter; left time: 497.7619s\n",
      "\titers: 200, epoch: 25 | loss: 0.0548689\n",
      "\tspeed: 0.0113s/iter; left time: 190.1731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0554690 Vali Loss: 0.0544049 Test Loss: 0.0572021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0552053\n",
      "\tspeed: 0.0267s/iter; left time: 446.7463s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594390\n",
      "\tspeed: 0.0117s/iter; left time: 194.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0553917 Vali Loss: 0.0543500 Test Loss: 0.0571922\n",
      "Validation loss decreased (0.054362 --> 0.054350).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0531707\n",
      "\tspeed: 0.0269s/iter; left time: 443.2774s\n",
      "\titers: 200, epoch: 27 | loss: 0.0506523\n",
      "\tspeed: 0.0118s/iter; left time: 192.6172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0553233 Vali Loss: 0.0543847 Test Loss: 0.0571362\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0538581\n",
      "\tspeed: 0.0270s/iter; left time: 438.2847s\n",
      "\titers: 200, epoch: 28 | loss: 0.0528567\n",
      "\tspeed: 0.0115s/iter; left time: 186.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0552988 Vali Loss: 0.0542971 Test Loss: 0.0571445\n",
      "Validation loss decreased (0.054350 --> 0.054297).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0533245\n",
      "\tspeed: 0.0276s/iter; left time: 442.9230s\n",
      "\titers: 200, epoch: 29 | loss: 0.0573412\n",
      "\tspeed: 0.0118s/iter; left time: 187.3363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0552292 Vali Loss: 0.0542585 Test Loss: 0.0570797\n",
      "Validation loss decreased (0.054297 --> 0.054258).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0564296\n",
      "\tspeed: 0.0269s/iter; left time: 425.3829s\n",
      "\titers: 200, epoch: 30 | loss: 0.0546442\n",
      "\tspeed: 0.0118s/iter; left time: 184.5344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0551725 Vali Loss: 0.0542428 Test Loss: 0.0570961\n",
      "Validation loss decreased (0.054258 --> 0.054243).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0547516\n",
      "\tspeed: 0.0268s/iter; left time: 416.8993s\n",
      "\titers: 200, epoch: 31 | loss: 0.0557207\n",
      "\tspeed: 0.0117s/iter; left time: 181.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0551921 Vali Loss: 0.0542338 Test Loss: 0.0570701\n",
      "Validation loss decreased (0.054243 --> 0.054234).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0571046\n",
      "\tspeed: 0.0268s/iter; left time: 411.4310s\n",
      "\titers: 200, epoch: 32 | loss: 0.0524746\n",
      "\tspeed: 0.0118s/iter; left time: 179.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0551418 Vali Loss: 0.0542316 Test Loss: 0.0571051\n",
      "Validation loss decreased (0.054234 --> 0.054232).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0530029\n",
      "\tspeed: 0.0267s/iter; left time: 404.5389s\n",
      "\titers: 200, epoch: 33 | loss: 0.0561184\n",
      "\tspeed: 0.0117s/iter; left time: 175.3483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0550747 Vali Loss: 0.0542553 Test Loss: 0.0570916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0533805\n",
      "\tspeed: 0.0265s/iter; left time: 395.7287s\n",
      "\titers: 200, epoch: 34 | loss: 0.0595358\n",
      "\tspeed: 0.0117s/iter; left time: 173.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0550723 Vali Loss: 0.0542519 Test Loss: 0.0570667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0538516\n",
      "\tspeed: 0.0259s/iter; left time: 380.8967s\n",
      "\titers: 200, epoch: 35 | loss: 0.0572209\n",
      "\tspeed: 0.0117s/iter; left time: 170.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0550484 Vali Loss: 0.0541936 Test Loss: 0.0570322\n",
      "Validation loss decreased (0.054232 --> 0.054194).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0566533\n",
      "\tspeed: 0.0270s/iter; left time: 390.6761s\n",
      "\titers: 200, epoch: 36 | loss: 0.0547452\n",
      "\tspeed: 0.0118s/iter; left time: 168.9210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0549787 Vali Loss: 0.0542229 Test Loss: 0.0570512\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0545657\n",
      "\tspeed: 0.0267s/iter; left time: 380.0018s\n",
      "\titers: 200, epoch: 37 | loss: 0.0573439\n",
      "\tspeed: 0.0118s/iter; left time: 166.1121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0550004 Vali Loss: 0.0542229 Test Loss: 0.0570312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0545918\n",
      "\tspeed: 0.0268s/iter; left time: 376.1701s\n",
      "\titers: 200, epoch: 38 | loss: 0.0589319\n",
      "\tspeed: 0.0118s/iter; left time: 164.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0549896 Vali Loss: 0.0542240 Test Loss: 0.0569882\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0550792\n",
      "\tspeed: 0.0267s/iter; left time: 368.0015s\n",
      "\titers: 200, epoch: 39 | loss: 0.0575929\n",
      "\tspeed: 0.0118s/iter; left time: 161.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0549082 Vali Loss: 0.0542438 Test Loss: 0.0570050\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0542045\n",
      "\tspeed: 0.0263s/iter; left time: 357.2767s\n",
      "\titers: 200, epoch: 40 | loss: 0.0582263\n",
      "\tspeed: 0.0117s/iter; left time: 157.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0549337 Vali Loss: 0.0542268 Test Loss: 0.0570121\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0582473\n",
      "\tspeed: 0.0263s/iter; left time: 351.4756s\n",
      "\titers: 200, epoch: 41 | loss: 0.0592045\n",
      "\tspeed: 0.0118s/iter; left time: 155.9074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0549499 Vali Loss: 0.0541086 Test Loss: 0.0569787\n",
      "Validation loss decreased (0.054194 --> 0.054109).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0569339\n",
      "\tspeed: 0.0283s/iter; left time: 370.8830s\n",
      "\titers: 200, epoch: 42 | loss: 0.0567299\n",
      "\tspeed: 0.0118s/iter; left time: 153.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0548798 Vali Loss: 0.0541921 Test Loss: 0.0570024\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0541601\n",
      "\tspeed: 0.0263s/iter; left time: 338.7494s\n",
      "\titers: 200, epoch: 43 | loss: 0.0539927\n",
      "\tspeed: 0.0117s/iter; left time: 150.0646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0549144 Vali Loss: 0.0542290 Test Loss: 0.0570001\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0597521\n",
      "\tspeed: 0.0263s/iter; left time: 333.0911s\n",
      "\titers: 200, epoch: 44 | loss: 0.0580675\n",
      "\tspeed: 0.0119s/iter; left time: 148.9465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0549672 Vali Loss: 0.0542355 Test Loss: 0.0569880\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0546702\n",
      "\tspeed: 0.0265s/iter; left time: 329.4833s\n",
      "\titers: 200, epoch: 45 | loss: 0.0565795\n",
      "\tspeed: 0.0118s/iter; left time: 145.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0549019 Vali Loss: 0.0541005 Test Loss: 0.0569835\n",
      "Validation loss decreased (0.054109 --> 0.054100).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0615396\n",
      "\tspeed: 0.0273s/iter; left time: 333.9331s\n",
      "\titers: 200, epoch: 46 | loss: 0.0559273\n",
      "\tspeed: 0.0118s/iter; left time: 142.6691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0549304 Vali Loss: 0.0542243 Test Loss: 0.0569948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0512865\n",
      "\tspeed: 0.0266s/iter; left time: 318.5824s\n",
      "\titers: 200, epoch: 47 | loss: 0.0558294\n",
      "\tspeed: 0.0118s/iter; left time: 139.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0548753 Vali Loss: 0.0541317 Test Loss: 0.0569961\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0518156\n",
      "\tspeed: 0.0270s/iter; left time: 318.0940s\n",
      "\titers: 200, epoch: 48 | loss: 0.0515242\n",
      "\tspeed: 0.0117s/iter; left time: 136.9020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.89s\n",
      "Steps: 224 | Train Loss: 0.0548384 Vali Loss: 0.0541103 Test Loss: 0.0569903\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0555870\n",
      "\tspeed: 0.0262s/iter; left time: 302.8634s\n",
      "\titers: 200, epoch: 49 | loss: 0.0527874\n",
      "\tspeed: 0.0113s/iter; left time: 129.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0548961 Vali Loss: 0.0541889 Test Loss: 0.0569676\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0531016\n",
      "\tspeed: 0.0268s/iter; left time: 303.5216s\n",
      "\titers: 200, epoch: 50 | loss: 0.0537063\n",
      "\tspeed: 0.0118s/iter; left time: 132.0744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0548514 Vali Loss: 0.0541905 Test Loss: 0.0569833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0520405\n",
      "\tspeed: 0.0269s/iter; left time: 298.8005s\n",
      "\titers: 200, epoch: 51 | loss: 0.0544461\n",
      "\tspeed: 0.0119s/iter; left time: 130.6866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0548792 Vali Loss: 0.0541448 Test Loss: 0.0569629\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0524752\n",
      "\tspeed: 0.0266s/iter; left time: 289.2492s\n",
      "\titers: 200, epoch: 52 | loss: 0.0541668\n",
      "\tspeed: 0.0118s/iter; left time: 127.2657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0549195 Vali Loss: 0.0541121 Test Loss: 0.0569540\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0527233\n",
      "\tspeed: 0.0261s/iter; left time: 277.5454s\n",
      "\titers: 200, epoch: 53 | loss: 0.0577899\n",
      "\tspeed: 0.0118s/iter; left time: 124.5365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0548472 Vali Loss: 0.0541791 Test Loss: 0.0569548\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0581326\n",
      "\tspeed: 0.0264s/iter; left time: 275.1314s\n",
      "\titers: 200, epoch: 54 | loss: 0.0555698\n",
      "\tspeed: 0.0118s/iter; left time: 121.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0548653 Vali Loss: 0.0541360 Test Loss: 0.0569727\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0543647\n",
      "\tspeed: 0.0266s/iter; left time: 271.4036s\n",
      "\titers: 200, epoch: 55 | loss: 0.0537153\n",
      "\tspeed: 0.0117s/iter; left time: 118.3270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0547929 Vali Loss: 0.0540976 Test Loss: 0.0569606\n",
      "Validation loss decreased (0.054100 --> 0.054098).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0539444\n",
      "\tspeed: 0.0266s/iter; left time: 265.5683s\n",
      "\titers: 200, epoch: 56 | loss: 0.0527476\n",
      "\tspeed: 0.0112s/iter; left time: 110.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0548682 Vali Loss: 0.0541907 Test Loss: 0.0569763\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0544273\n",
      "\tspeed: 0.0275s/iter; left time: 268.3658s\n",
      "\titers: 200, epoch: 57 | loss: 0.0565439\n",
      "\tspeed: 0.0118s/iter; left time: 113.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0547818 Vali Loss: 0.0541853 Test Loss: 0.0569743\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0535162\n",
      "\tspeed: 0.0268s/iter; left time: 255.4129s\n",
      "\titers: 200, epoch: 58 | loss: 0.0555304\n",
      "\tspeed: 0.0117s/iter; left time: 110.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0548299 Vali Loss: 0.0542178 Test Loss: 0.0569990\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0567955\n",
      "\tspeed: 0.0265s/iter; left time: 246.7884s\n",
      "\titers: 200, epoch: 59 | loss: 0.0582845\n",
      "\tspeed: 0.0118s/iter; left time: 108.5598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 224 | Train Loss: 0.0548251 Vali Loss: 0.0541437 Test Loss: 0.0569695\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0539164\n",
      "\tspeed: 0.0269s/iter; left time: 244.7437s\n",
      "\titers: 200, epoch: 60 | loss: 0.0565272\n",
      "\tspeed: 0.0118s/iter; left time: 106.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0548208 Vali Loss: 0.0541874 Test Loss: 0.0569704\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0533571\n",
      "\tspeed: 0.0269s/iter; left time: 238.0921s\n",
      "\titers: 200, epoch: 61 | loss: 0.0547494\n",
      "\tspeed: 0.0118s/iter; left time: 103.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0548509 Vali Loss: 0.0541735 Test Loss: 0.0569532\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0555343\n",
      "\tspeed: 0.0277s/iter; left time: 239.2078s\n",
      "\titers: 200, epoch: 62 | loss: 0.0572369\n",
      "\tspeed: 0.0117s/iter; left time: 100.2675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0548262 Vali Loss: 0.0540871 Test Loss: 0.0569609\n",
      "Validation loss decreased (0.054098 --> 0.054087).  Saving model ...\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0628280\n",
      "\tspeed: 0.0270s/iter; left time: 227.3805s\n",
      "\titers: 200, epoch: 63 | loss: 0.0520442\n",
      "\tspeed: 0.0117s/iter; left time: 97.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0548190 Vali Loss: 0.0542160 Test Loss: 0.0569625\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0542583\n",
      "\tspeed: 0.0266s/iter; left time: 217.6376s\n",
      "\titers: 200, epoch: 64 | loss: 0.0583994\n",
      "\tspeed: 0.0118s/iter; left time: 95.8110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0547535 Vali Loss: 0.0541568 Test Loss: 0.0569588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0548410\n",
      "\tspeed: 0.0268s/iter; left time: 213.3141s\n",
      "\titers: 200, epoch: 65 | loss: 0.0514859\n",
      "\tspeed: 0.0117s/iter; left time: 91.7981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0548672 Vali Loss: 0.0541761 Test Loss: 0.0569939\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0605304\n",
      "\tspeed: 0.0264s/iter; left time: 204.0920s\n",
      "\titers: 200, epoch: 66 | loss: 0.0560733\n",
      "\tspeed: 0.0117s/iter; left time: 89.3808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0548604 Vali Loss: 0.0541933 Test Loss: 0.0569784\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0542767\n",
      "\tspeed: 0.0265s/iter; left time: 199.2573s\n",
      "\titers: 200, epoch: 67 | loss: 0.0579931\n",
      "\tspeed: 0.0118s/iter; left time: 87.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0547553 Vali Loss: 0.0541071 Test Loss: 0.0569728\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0567268\n",
      "\tspeed: 0.0263s/iter; left time: 191.6266s\n",
      "\titers: 200, epoch: 68 | loss: 0.0589817\n",
      "\tspeed: 0.0117s/iter; left time: 84.3505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0548024 Vali Loss: 0.0541435 Test Loss: 0.0569757\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0563229\n",
      "\tspeed: 0.0268s/iter; left time: 189.2476s\n",
      "\titers: 200, epoch: 69 | loss: 0.0527551\n",
      "\tspeed: 0.0117s/iter; left time: 81.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0548119 Vali Loss: 0.0541982 Test Loss: 0.0569595\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0558584\n",
      "\tspeed: 0.0262s/iter; left time: 179.2689s\n",
      "\titers: 200, epoch: 70 | loss: 0.0526695\n",
      "\tspeed: 0.0119s/iter; left time: 79.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0547833 Vali Loss: 0.0541309 Test Loss: 0.0569778\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0545375\n",
      "\tspeed: 0.0272s/iter; left time: 180.4012s\n",
      "\titers: 200, epoch: 71 | loss: 0.0557902\n",
      "\tspeed: 0.0122s/iter; left time: 79.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:02.95s\n",
      "Steps: 224 | Train Loss: 0.0547751 Vali Loss: 0.0541751 Test Loss: 0.0569706\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0504974\n",
      "\tspeed: 0.0273s/iter; left time: 174.9522s\n",
      "\titers: 200, epoch: 72 | loss: 0.0534382\n",
      "\tspeed: 0.0126s/iter; left time: 79.5194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.02s\n",
      "Steps: 224 | Train Loss: 0.0547698 Vali Loss: 0.0542158 Test Loss: 0.0569667\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010109943337738514, rmse:0.10054821521043777, mae:0.05696091800928116, rse:0.37992221117019653\n",
      "Intermediate time for IT and pred_len 24: 00h:08m:20.15s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1694137\n",
      "\tspeed: 0.0325s/iter; left time: 725.1251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1422566\n",
      "\tspeed: 0.0114s/iter; left time: 253.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.04s\n",
      "Steps: 224 | Train Loss: 0.1661313 Vali Loss: 0.1205659 Test Loss: 0.1253998\n",
      "Validation loss decreased (inf --> 0.120566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0982611\n",
      "\tspeed: 0.0282s/iter; left time: 623.1833s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932958\n",
      "\tspeed: 0.0114s/iter; left time: 250.9489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.1010618 Vali Loss: 0.0828836 Test Loss: 0.0877833\n",
      "Validation loss decreased (0.120566 --> 0.082884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0864613\n",
      "\tspeed: 0.0286s/iter; left time: 624.9140s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823260\n",
      "\tspeed: 0.0115s/iter; left time: 250.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0868094 Vali Loss: 0.0794397 Test Loss: 0.0843617\n",
      "Validation loss decreased (0.082884 --> 0.079440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0839486\n",
      "\tspeed: 0.0287s/iter; left time: 621.5527s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801206\n",
      "\tspeed: 0.0115s/iter; left time: 246.5889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0835503 Vali Loss: 0.0782552 Test Loss: 0.0835699\n",
      "Validation loss decreased (0.079440 --> 0.078255).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815459\n",
      "\tspeed: 0.0287s/iter; left time: 613.5673s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828756\n",
      "\tspeed: 0.0114s/iter; left time: 243.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0818222 Vali Loss: 0.0776317 Test Loss: 0.0827362\n",
      "Validation loss decreased (0.078255 --> 0.077632).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0834187\n",
      "\tspeed: 0.0285s/iter; left time: 603.7846s\n",
      "\titers: 200, epoch: 6 | loss: 0.0795873\n",
      "\tspeed: 0.0115s/iter; left time: 242.1023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0805658 Vali Loss: 0.0772948 Test Loss: 0.0826314\n",
      "Validation loss decreased (0.077632 --> 0.077295).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0768925\n",
      "\tspeed: 0.0286s/iter; left time: 598.5931s\n",
      "\titers: 200, epoch: 7 | loss: 0.0789800\n",
      "\tspeed: 0.0114s/iter; left time: 238.6284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0796422 Vali Loss: 0.0770975 Test Loss: 0.0823685\n",
      "Validation loss decreased (0.077295 --> 0.077098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801099\n",
      "\tspeed: 0.0284s/iter; left time: 589.8238s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806852\n",
      "\tspeed: 0.0114s/iter; left time: 234.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0789244 Vali Loss: 0.0767069 Test Loss: 0.0817630\n",
      "Validation loss decreased (0.077098 --> 0.076707).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0756710\n",
      "\tspeed: 0.0287s/iter; left time: 589.2486s\n",
      "\titers: 200, epoch: 9 | loss: 0.0760978\n",
      "\tspeed: 0.0114s/iter; left time: 232.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 224 | Train Loss: 0.0782492 Vali Loss: 0.0765156 Test Loss: 0.0816814\n",
      "Validation loss decreased (0.076707 --> 0.076516).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0783817\n",
      "\tspeed: 0.0277s/iter; left time: 562.6149s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794710\n",
      "\tspeed: 0.0114s/iter; left time: 230.7776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0776505 Vali Loss: 0.0763667 Test Loss: 0.0815143\n",
      "Validation loss decreased (0.076516 --> 0.076367).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0764569\n",
      "\tspeed: 0.0285s/iter; left time: 571.8080s\n",
      "\titers: 200, epoch: 11 | loss: 0.0764720\n",
      "\tspeed: 0.0114s/iter; left time: 227.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0772299 Vali Loss: 0.0762668 Test Loss: 0.0814972\n",
      "Validation loss decreased (0.076367 --> 0.076267).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0755686\n",
      "\tspeed: 0.0285s/iter; left time: 565.1787s\n",
      "\titers: 200, epoch: 12 | loss: 0.0748391\n",
      "\tspeed: 0.0114s/iter; left time: 224.4130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0767714 Vali Loss: 0.0761280 Test Loss: 0.0812074\n",
      "Validation loss decreased (0.076267 --> 0.076128).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782008\n",
      "\tspeed: 0.0289s/iter; left time: 567.1693s\n",
      "\titers: 200, epoch: 13 | loss: 0.0751148\n",
      "\tspeed: 0.0113s/iter; left time: 221.2914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0763727 Vali Loss: 0.0763362 Test Loss: 0.0812979\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0707611\n",
      "\tspeed: 0.0276s/iter; left time: 535.5235s\n",
      "\titers: 200, epoch: 14 | loss: 0.0763229\n",
      "\tspeed: 0.0114s/iter; left time: 219.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0760496 Vali Loss: 0.0761597 Test Loss: 0.0812481\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798078\n",
      "\tspeed: 0.0281s/iter; left time: 539.1770s\n",
      "\titers: 200, epoch: 15 | loss: 0.0711448\n",
      "\tspeed: 0.0114s/iter; left time: 216.4107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0757627 Vali Loss: 0.0761455 Test Loss: 0.0810610\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0709446\n",
      "\tspeed: 0.0281s/iter; left time: 533.0554s\n",
      "\titers: 200, epoch: 16 | loss: 0.0774027\n",
      "\tspeed: 0.0114s/iter; left time: 214.7278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0754142 Vali Loss: 0.0760802 Test Loss: 0.0811172\n",
      "Validation loss decreased (0.076128 --> 0.076080).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0734147\n",
      "\tspeed: 0.0280s/iter; left time: 523.7629s\n",
      "\titers: 200, epoch: 17 | loss: 0.0760152\n",
      "\tspeed: 0.0114s/iter; left time: 211.5375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0751861 Vali Loss: 0.0760274 Test Loss: 0.0810721\n",
      "Validation loss decreased (0.076080 --> 0.076027).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0773675\n",
      "\tspeed: 0.0284s/iter; left time: 524.7861s\n",
      "\titers: 200, epoch: 18 | loss: 0.0752099\n",
      "\tspeed: 0.0114s/iter; left time: 209.9314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0749369 Vali Loss: 0.0759469 Test Loss: 0.0809807\n",
      "Validation loss decreased (0.076027 --> 0.075947).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0726778\n",
      "\tspeed: 0.0285s/iter; left time: 519.9827s\n",
      "\titers: 200, epoch: 19 | loss: 0.0723060\n",
      "\tspeed: 0.0113s/iter; left time: 205.8358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0747569 Vali Loss: 0.0760007 Test Loss: 0.0810970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0714997\n",
      "\tspeed: 0.0281s/iter; left time: 507.6659s\n",
      "\titers: 200, epoch: 20 | loss: 0.0753793\n",
      "\tspeed: 0.0113s/iter; left time: 203.4115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0746135 Vali Loss: 0.0759967 Test Loss: 0.0809578\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0696135\n",
      "\tspeed: 0.0272s/iter; left time: 484.9637s\n",
      "\titers: 200, epoch: 21 | loss: 0.0735055\n",
      "\tspeed: 0.0114s/iter; left time: 201.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0745242 Vali Loss: 0.0758767 Test Loss: 0.0809995\n",
      "Validation loss decreased (0.075947 --> 0.075877).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0795342\n",
      "\tspeed: 0.0283s/iter; left time: 498.5791s\n",
      "\titers: 200, epoch: 22 | loss: 0.0737265\n",
      "\tspeed: 0.0114s/iter; left time: 200.2014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0742978 Vali Loss: 0.0759324 Test Loss: 0.0809838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0735683\n",
      "\tspeed: 0.0280s/iter; left time: 486.3591s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740643\n",
      "\tspeed: 0.0114s/iter; left time: 197.7379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0742559 Vali Loss: 0.0759024 Test Loss: 0.0808765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0736660\n",
      "\tspeed: 0.0276s/iter; left time: 472.6825s\n",
      "\titers: 200, epoch: 24 | loss: 0.0706203\n",
      "\tspeed: 0.0113s/iter; left time: 192.8802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0740981 Vali Loss: 0.0758817 Test Loss: 0.0809375\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0745623\n",
      "\tspeed: 0.0277s/iter; left time: 468.4126s\n",
      "\titers: 200, epoch: 25 | loss: 0.0754423\n",
      "\tspeed: 0.0114s/iter; left time: 190.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0740124 Vali Loss: 0.0758972 Test Loss: 0.0809807\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0739561\n",
      "\tspeed: 0.0278s/iter; left time: 463.7543s\n",
      "\titers: 200, epoch: 26 | loss: 0.0790843\n",
      "\tspeed: 0.0113s/iter; left time: 188.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0739364 Vali Loss: 0.0758976 Test Loss: 0.0809296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0748592\n",
      "\tspeed: 0.0275s/iter; left time: 453.5724s\n",
      "\titers: 200, epoch: 27 | loss: 0.0733538\n",
      "\tspeed: 0.0113s/iter; left time: 185.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0738535 Vali Loss: 0.0758461 Test Loss: 0.0809156\n",
      "Validation loss decreased (0.075877 --> 0.075846).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0707953\n",
      "\tspeed: 0.0295s/iter; left time: 479.2105s\n",
      "\titers: 200, epoch: 28 | loss: 0.0718219\n",
      "\tspeed: 0.0114s/iter; left time: 183.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0738460 Vali Loss: 0.0758895 Test Loss: 0.0809272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0759644\n",
      "\tspeed: 0.0273s/iter; left time: 437.8310s\n",
      "\titers: 200, epoch: 29 | loss: 0.0731046\n",
      "\tspeed: 0.0114s/iter; left time: 182.2836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0737928 Vali Loss: 0.0759445 Test Loss: 0.0808905\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0741763\n",
      "\tspeed: 0.0276s/iter; left time: 435.4679s\n",
      "\titers: 200, epoch: 30 | loss: 0.0737658\n",
      "\tspeed: 0.0114s/iter; left time: 178.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0736904 Vali Loss: 0.0758659 Test Loss: 0.0808305\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0780312\n",
      "\tspeed: 0.0280s/iter; left time: 436.1830s\n",
      "\titers: 200, epoch: 31 | loss: 0.0734351\n",
      "\tspeed: 0.0114s/iter; left time: 176.7983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0736653 Vali Loss: 0.0758382 Test Loss: 0.0809552\n",
      "Validation loss decreased (0.075846 --> 0.075838).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0727245\n",
      "\tspeed: 0.0289s/iter; left time: 444.4571s\n",
      "\titers: 200, epoch: 32 | loss: 0.0770981\n",
      "\tspeed: 0.0113s/iter; left time: 173.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0735915 Vali Loss: 0.0758470 Test Loss: 0.0809043\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0772691\n",
      "\tspeed: 0.0272s/iter; left time: 411.4725s\n",
      "\titers: 200, epoch: 33 | loss: 0.0733989\n",
      "\tspeed: 0.0113s/iter; left time: 170.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0735036 Vali Loss: 0.0758045 Test Loss: 0.0808835\n",
      "Validation loss decreased (0.075838 --> 0.075804).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0742405\n",
      "\tspeed: 0.0289s/iter; left time: 431.3346s\n",
      "\titers: 200, epoch: 34 | loss: 0.0751152\n",
      "\tspeed: 0.0113s/iter; left time: 167.8353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0735163 Vali Loss: 0.0758490 Test Loss: 0.0808849\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0731973\n",
      "\tspeed: 0.0281s/iter; left time: 412.1783s\n",
      "\titers: 200, epoch: 35 | loss: 0.0730760\n",
      "\tspeed: 0.0114s/iter; left time: 166.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0734627 Vali Loss: 0.0758339 Test Loss: 0.0808541\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0735193\n",
      "\tspeed: 0.0273s/iter; left time: 394.2807s\n",
      "\titers: 200, epoch: 36 | loss: 0.0707832\n",
      "\tspeed: 0.0113s/iter; left time: 162.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0734177 Vali Loss: 0.0758410 Test Loss: 0.0809039\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0718613\n",
      "\tspeed: 0.0278s/iter; left time: 396.2776s\n",
      "\titers: 200, epoch: 37 | loss: 0.0729318\n",
      "\tspeed: 0.0114s/iter; left time: 161.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0734717 Vali Loss: 0.0758469 Test Loss: 0.0808782\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0704699\n",
      "\tspeed: 0.0276s/iter; left time: 386.1884s\n",
      "\titers: 200, epoch: 38 | loss: 0.0743951\n",
      "\tspeed: 0.0113s/iter; left time: 157.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0733746 Vali Loss: 0.0757807 Test Loss: 0.0808620\n",
      "Validation loss decreased (0.075804 --> 0.075781).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0737617\n",
      "\tspeed: 0.0292s/iter; left time: 402.6085s\n",
      "\titers: 200, epoch: 39 | loss: 0.0724559\n",
      "\tspeed: 0.0113s/iter; left time: 155.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0734003 Vali Loss: 0.0758021 Test Loss: 0.0808819\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0746022\n",
      "\tspeed: 0.0283s/iter; left time: 384.2416s\n",
      "\titers: 200, epoch: 40 | loss: 0.0715293\n",
      "\tspeed: 0.0114s/iter; left time: 153.3292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0733724 Vali Loss: 0.0758284 Test Loss: 0.0808730\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0721853\n",
      "\tspeed: 0.0277s/iter; left time: 369.3662s\n",
      "\titers: 200, epoch: 41 | loss: 0.0718565\n",
      "\tspeed: 0.0114s/iter; left time: 151.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0733212 Vali Loss: 0.0758413 Test Loss: 0.0808912\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0720106\n",
      "\tspeed: 0.0270s/iter; left time: 354.2514s\n",
      "\titers: 200, epoch: 42 | loss: 0.0772543\n",
      "\tspeed: 0.0114s/iter; left time: 148.0746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0733566 Vali Loss: 0.0758298 Test Loss: 0.0808564\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0740069\n",
      "\tspeed: 0.0277s/iter; left time: 356.8043s\n",
      "\titers: 200, epoch: 43 | loss: 0.0731490\n",
      "\tspeed: 0.0113s/iter; left time: 145.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0733458 Vali Loss: 0.0757772 Test Loss: 0.0808347\n",
      "Validation loss decreased (0.075781 --> 0.075777).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0715052\n",
      "\tspeed: 0.0280s/iter; left time: 354.3739s\n",
      "\titers: 200, epoch: 44 | loss: 0.0747850\n",
      "\tspeed: 0.0113s/iter; left time: 142.3174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0733016 Vali Loss: 0.0757796 Test Loss: 0.0808205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0719475\n",
      "\tspeed: 0.0283s/iter; left time: 352.8106s\n",
      "\titers: 200, epoch: 45 | loss: 0.0713744\n",
      "\tspeed: 0.0114s/iter; left time: 140.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0732650 Vali Loss: 0.0757780 Test Loss: 0.0808208\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0726385\n",
      "\tspeed: 0.0278s/iter; left time: 339.9831s\n",
      "\titers: 200, epoch: 46 | loss: 0.0706786\n",
      "\tspeed: 0.0113s/iter; left time: 137.5239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0732982 Vali Loss: 0.0758178 Test Loss: 0.0808473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0707147\n",
      "\tspeed: 0.0274s/iter; left time: 328.3518s\n",
      "\titers: 200, epoch: 47 | loss: 0.0752718\n",
      "\tspeed: 0.0114s/iter; left time: 135.8286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0732292 Vali Loss: 0.0757686 Test Loss: 0.0808429\n",
      "Validation loss decreased (0.075777 --> 0.075769).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0734363\n",
      "\tspeed: 0.0284s/iter; left time: 333.8829s\n",
      "\titers: 200, epoch: 48 | loss: 0.0722561\n",
      "\tspeed: 0.0114s/iter; left time: 132.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0732187 Vali Loss: 0.0757897 Test Loss: 0.0808505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0739431\n",
      "\tspeed: 0.0282s/iter; left time: 325.4908s\n",
      "\titers: 200, epoch: 49 | loss: 0.0703347\n",
      "\tspeed: 0.0118s/iter; left time: 135.5259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 224 | Train Loss: 0.0732267 Vali Loss: 0.0758007 Test Loss: 0.0808499\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0730786\n",
      "\tspeed: 0.0290s/iter; left time: 328.7960s\n",
      "\titers: 200, epoch: 50 | loss: 0.0715853\n",
      "\tspeed: 0.0115s/iter; left time: 128.8348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 224 | Train Loss: 0.0732164 Vali Loss: 0.0757983 Test Loss: 0.0808601\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0706862\n",
      "\tspeed: 0.0276s/iter; left time: 306.5934s\n",
      "\titers: 200, epoch: 51 | loss: 0.0755018\n",
      "\tspeed: 0.0114s/iter; left time: 125.4169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0731927 Vali Loss: 0.0757994 Test Loss: 0.0808404\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0699867\n",
      "\tspeed: 0.0273s/iter; left time: 297.1849s\n",
      "\titers: 200, epoch: 52 | loss: 0.0745428\n",
      "\tspeed: 0.0114s/iter; left time: 122.7882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0732258 Vali Loss: 0.0757754 Test Loss: 0.0808408\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0736577\n",
      "\tspeed: 0.0276s/iter; left time: 293.5661s\n",
      "\titers: 200, epoch: 53 | loss: 0.0773339\n",
      "\tspeed: 0.0114s/iter; left time: 120.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 224 | Train Loss: 0.0732240 Vali Loss: 0.0757863 Test Loss: 0.0808232\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0711451\n",
      "\tspeed: 0.0280s/iter; left time: 291.7007s\n",
      "\titers: 200, epoch: 54 | loss: 0.0727071\n",
      "\tspeed: 0.0114s/iter; left time: 117.6635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0732478 Vali Loss: 0.0757839 Test Loss: 0.0808262\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0717013\n",
      "\tspeed: 0.0276s/iter; left time: 281.3858s\n",
      "\titers: 200, epoch: 55 | loss: 0.0737597\n",
      "\tspeed: 0.0113s/iter; left time: 114.6684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0732223 Vali Loss: 0.0757855 Test Loss: 0.0808341\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0753467\n",
      "\tspeed: 0.0274s/iter; left time: 273.6281s\n",
      "\titers: 200, epoch: 56 | loss: 0.0763780\n",
      "\tspeed: 0.0114s/iter; left time: 112.8303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0732472 Vali Loss: 0.0757797 Test Loss: 0.0808185\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0750451\n",
      "\tspeed: 0.0272s/iter; left time: 265.0569s\n",
      "\titers: 200, epoch: 57 | loss: 0.0715232\n",
      "\tspeed: 0.0114s/iter; left time: 110.3265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0731629 Vali Loss: 0.0757890 Test Loss: 0.0808226\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018440978601574898, rmse:0.13579756021499634, mae:0.08084290474653244, rse:0.5134652256965637\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1654511\n",
      "\tspeed: 0.0137s/iter; left time: 306.4412s\n",
      "\titers: 200, epoch: 1 | loss: 0.1383132\n",
      "\tspeed: 0.0114s/iter; left time: 254.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.1662379 Vali Loss: 0.1215407 Test Loss: 0.1261214\n",
      "Validation loss decreased (inf --> 0.121541).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0995385\n",
      "\tspeed: 0.0279s/iter; left time: 615.4672s\n",
      "\titers: 200, epoch: 2 | loss: 0.0913172\n",
      "\tspeed: 0.0114s/iter; left time: 250.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.1009662 Vali Loss: 0.0827438 Test Loss: 0.0877970\n",
      "Validation loss decreased (0.121541 --> 0.082744).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829328\n",
      "\tspeed: 0.0281s/iter; left time: 613.7918s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806222\n",
      "\tspeed: 0.0113s/iter; left time: 246.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0866257 Vali Loss: 0.0795557 Test Loss: 0.0842887\n",
      "Validation loss decreased (0.082744 --> 0.079556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0841553\n",
      "\tspeed: 0.0278s/iter; left time: 601.7192s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792951\n",
      "\tspeed: 0.0114s/iter; left time: 244.7480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0833798 Vali Loss: 0.0784393 Test Loss: 0.0835730\n",
      "Validation loss decreased (0.079556 --> 0.078439).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0883140\n",
      "\tspeed: 0.0275s/iter; left time: 588.2093s\n",
      "\titers: 200, epoch: 5 | loss: 0.0801233\n",
      "\tspeed: 0.0113s/iter; left time: 241.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0816572 Vali Loss: 0.0775846 Test Loss: 0.0825094\n",
      "Validation loss decreased (0.078439 --> 0.077585).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0777037\n",
      "\tspeed: 0.0270s/iter; left time: 570.9248s\n",
      "\titers: 200, epoch: 6 | loss: 0.0794889\n",
      "\tspeed: 0.0114s/iter; left time: 239.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0803276 Vali Loss: 0.0771481 Test Loss: 0.0821213\n",
      "Validation loss decreased (0.077585 --> 0.077148).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0787307\n",
      "\tspeed: 0.0274s/iter; left time: 574.3894s\n",
      "\titers: 200, epoch: 7 | loss: 0.0747271\n",
      "\tspeed: 0.0113s/iter; left time: 236.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0793485 Vali Loss: 0.0769263 Test Loss: 0.0818814\n",
      "Validation loss decreased (0.077148 --> 0.076926).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0776170\n",
      "\tspeed: 0.0274s/iter; left time: 567.3671s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762532\n",
      "\tspeed: 0.0114s/iter; left time: 234.8011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0785638 Vali Loss: 0.0765866 Test Loss: 0.0818779\n",
      "Validation loss decreased (0.076926 --> 0.076587).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769413\n",
      "\tspeed: 0.0272s/iter; left time: 558.3170s\n",
      "\titers: 200, epoch: 9 | loss: 0.0772685\n",
      "\tspeed: 0.0114s/iter; left time: 233.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0779302 Vali Loss: 0.0763406 Test Loss: 0.0816626\n",
      "Validation loss decreased (0.076587 --> 0.076341).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0775558\n",
      "\tspeed: 0.0272s/iter; left time: 552.4014s\n",
      "\titers: 200, epoch: 10 | loss: 0.0765286\n",
      "\tspeed: 0.0114s/iter; left time: 229.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0773178 Vali Loss: 0.0764101 Test Loss: 0.0813802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767124\n",
      "\tspeed: 0.0277s/iter; left time: 555.2070s\n",
      "\titers: 200, epoch: 11 | loss: 0.0785199\n",
      "\tspeed: 0.0114s/iter; left time: 226.7510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 224 | Train Loss: 0.0768960 Vali Loss: 0.0763734 Test Loss: 0.0813544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0767896\n",
      "\tspeed: 0.0276s/iter; left time: 547.4304s\n",
      "\titers: 200, epoch: 12 | loss: 0.0791036\n",
      "\tspeed: 0.0114s/iter; left time: 224.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 224 | Train Loss: 0.0764688 Vali Loss: 0.0762276 Test Loss: 0.0811897\n",
      "Validation loss decreased (0.076341 --> 0.076228).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738119\n",
      "\tspeed: 0.0274s/iter; left time: 537.4785s\n",
      "\titers: 200, epoch: 13 | loss: 0.0769699\n",
      "\tspeed: 0.0114s/iter; left time: 222.3488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0760621 Vali Loss: 0.0764672 Test Loss: 0.0810951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0757548\n",
      "\tspeed: 0.0273s/iter; left time: 529.4412s\n",
      "\titers: 200, epoch: 14 | loss: 0.0715871\n",
      "\tspeed: 0.0113s/iter; left time: 218.4471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 224 | Train Loss: 0.0757244 Vali Loss: 0.0762775 Test Loss: 0.0808579\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0750708\n",
      "\tspeed: 0.0266s/iter; left time: 510.0298s\n",
      "\titers: 200, epoch: 15 | loss: 0.0744994\n",
      "\tspeed: 0.0114s/iter; left time: 216.8947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0753486 Vali Loss: 0.0762104 Test Loss: 0.0812013\n",
      "Validation loss decreased (0.076228 --> 0.076210).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0724380\n",
      "\tspeed: 0.0273s/iter; left time: 517.4602s\n",
      "\titers: 200, epoch: 16 | loss: 0.0794296\n",
      "\tspeed: 0.0113s/iter; left time: 213.4255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0752060 Vali Loss: 0.0763183 Test Loss: 0.0809916\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0782663\n",
      "\tspeed: 0.0271s/iter; left time: 507.6059s\n",
      "\titers: 200, epoch: 17 | loss: 0.0745338\n",
      "\tspeed: 0.0114s/iter; left time: 211.5495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0749128 Vali Loss: 0.0763458 Test Loss: 0.0808894\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725660\n",
      "\tspeed: 0.0265s/iter; left time: 490.6997s\n",
      "\titers: 200, epoch: 18 | loss: 0.0751752\n",
      "\tspeed: 0.0113s/iter; left time: 208.3247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.75s\n",
      "Steps: 224 | Train Loss: 0.0747663 Vali Loss: 0.0762609 Test Loss: 0.0808101\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0717330\n",
      "\tspeed: 0.0268s/iter; left time: 488.9044s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709173\n",
      "\tspeed: 0.0113s/iter; left time: 206.0055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0745690 Vali Loss: 0.0762782 Test Loss: 0.0809971\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0723821\n",
      "\tspeed: 0.0272s/iter; left time: 491.4401s\n",
      "\titers: 200, epoch: 20 | loss: 0.0756970\n",
      "\tspeed: 0.0113s/iter; left time: 203.3568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 224 | Train Loss: 0.0744083 Vali Loss: 0.0762866 Test Loss: 0.0809529\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0715602\n",
      "\tspeed: 0.0281s/iter; left time: 500.4292s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750736\n",
      "\tspeed: 0.0113s/iter; left time: 200.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0741704 Vali Loss: 0.0762854 Test Loss: 0.0811020\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0772781\n",
      "\tspeed: 0.0266s/iter; left time: 468.8106s\n",
      "\titers: 200, epoch: 22 | loss: 0.0735219\n",
      "\tspeed: 0.0114s/iter; left time: 199.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.76s\n",
      "Steps: 224 | Train Loss: 0.0740332 Vali Loss: 0.0764265 Test Loss: 0.0810173\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0756811\n",
      "\tspeed: 0.0272s/iter; left time: 472.4493s\n",
      "\titers: 200, epoch: 23 | loss: 0.0719638\n",
      "\tspeed: 0.0113s/iter; left time: 195.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 224 | Train Loss: 0.0739304 Vali Loss: 0.0764976 Test Loss: 0.0810180\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0730596\n",
      "\tspeed: 0.0279s/iter; left time: 478.1583s\n",
      "\titers: 200, epoch: 24 | loss: 0.0714086\n",
      "\tspeed: 0.0114s/iter; left time: 193.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 224 | Train Loss: 0.0738633 Vali Loss: 0.0763677 Test Loss: 0.0809491\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0742244\n",
      "\tspeed: 0.0278s/iter; left time: 470.8063s\n",
      "\titers: 200, epoch: 25 | loss: 0.0683572\n",
      "\tspeed: 0.0114s/iter; left time: 191.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 224 | Train Loss: 0.0737765 Vali Loss: 0.0764349 Test Loss: 0.0809759\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018602589145302773, rmse:0.1363913118839264, mae:0.08120128512382507, rse:0.5157102346420288\n",
      "Intermediate time for IT and pred_len 96: 00h:05m:31.44s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1690010\n",
      "\tspeed: 0.0337s/iter; left time: 747.7490s\n",
      "\titers: 200, epoch: 1 | loss: 0.1379525\n",
      "\tspeed: 0.0117s/iter; left time: 257.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.12s\n",
      "Steps: 223 | Train Loss: 0.1674818 Vali Loss: 0.1228408 Test Loss: 0.1272520\n",
      "Validation loss decreased (inf --> 0.122841).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1055019\n",
      "\tspeed: 0.0286s/iter; left time: 627.9144s\n",
      "\titers: 200, epoch: 2 | loss: 0.0947789\n",
      "\tspeed: 0.0115s/iter; left time: 251.1924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.77s\n",
      "Steps: 223 | Train Loss: 0.1046888 Vali Loss: 0.0870983 Test Loss: 0.0914740\n",
      "Validation loss decreased (0.122841 --> 0.087098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945887\n",
      "\tspeed: 0.0288s/iter; left time: 625.7159s\n",
      "\titers: 200, epoch: 3 | loss: 0.0912248\n",
      "\tspeed: 0.0115s/iter; left time: 249.9853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0910463 Vali Loss: 0.0845167 Test Loss: 0.0886465\n",
      "Validation loss decreased (0.087098 --> 0.084517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0890638\n",
      "\tspeed: 0.0293s/iter; left time: 631.5802s\n",
      "\titers: 200, epoch: 4 | loss: 0.0876659\n",
      "\tspeed: 0.0115s/iter; left time: 246.4034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0876957 Vali Loss: 0.0838203 Test Loss: 0.0880159\n",
      "Validation loss decreased (0.084517 --> 0.083820).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888273\n",
      "\tspeed: 0.0292s/iter; left time: 622.8987s\n",
      "\titers: 200, epoch: 5 | loss: 0.0901279\n",
      "\tspeed: 0.0115s/iter; left time: 244.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0858796 Vali Loss: 0.0827751 Test Loss: 0.0877248\n",
      "Validation loss decreased (0.083820 --> 0.082775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0843554\n",
      "\tspeed: 0.0294s/iter; left time: 619.5769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0846031\n",
      "\tspeed: 0.0116s/iter; left time: 242.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0846602 Vali Loss: 0.0825831 Test Loss: 0.0875698\n",
      "Validation loss decreased (0.082775 --> 0.082583).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839404\n",
      "\tspeed: 0.0291s/iter; left time: 606.2427s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820961\n",
      "\tspeed: 0.0115s/iter; left time: 239.3955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0836598 Vali Loss: 0.0826961 Test Loss: 0.0873808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0833263\n",
      "\tspeed: 0.0287s/iter; left time: 591.5697s\n",
      "\titers: 200, epoch: 8 | loss: 0.0827962\n",
      "\tspeed: 0.0116s/iter; left time: 237.9351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0828944 Vali Loss: 0.0821371 Test Loss: 0.0873078\n",
      "Validation loss decreased (0.082583 --> 0.082137).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822694\n",
      "\tspeed: 0.0292s/iter; left time: 596.0908s\n",
      "\titers: 200, epoch: 9 | loss: 0.0826395\n",
      "\tspeed: 0.0116s/iter; left time: 235.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0822426 Vali Loss: 0.0819558 Test Loss: 0.0873221\n",
      "Validation loss decreased (0.082137 --> 0.081956).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0777007\n",
      "\tspeed: 0.0289s/iter; left time: 582.8070s\n",
      "\titers: 200, epoch: 10 | loss: 0.0856002\n",
      "\tspeed: 0.0115s/iter; left time: 231.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0817157 Vali Loss: 0.0821818 Test Loss: 0.0874224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795958\n",
      "\tspeed: 0.0285s/iter; left time: 568.9284s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828160\n",
      "\tspeed: 0.0116s/iter; left time: 231.3582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0812583 Vali Loss: 0.0822034 Test Loss: 0.0871338\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0838655\n",
      "\tspeed: 0.0287s/iter; left time: 566.5138s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794579\n",
      "\tspeed: 0.0116s/iter; left time: 227.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0807852 Vali Loss: 0.0821391 Test Loss: 0.0870446\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816532\n",
      "\tspeed: 0.0286s/iter; left time: 558.7311s\n",
      "\titers: 200, epoch: 13 | loss: 0.0783536\n",
      "\tspeed: 0.0118s/iter; left time: 228.5680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0804130 Vali Loss: 0.0822525 Test Loss: 0.0869995\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0825000\n",
      "\tspeed: 0.0289s/iter; left time: 557.4355s\n",
      "\titers: 200, epoch: 14 | loss: 0.0804190\n",
      "\tspeed: 0.0116s/iter; left time: 222.8643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0800701 Vali Loss: 0.0822010 Test Loss: 0.0872152\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0798860\n",
      "\tspeed: 0.0286s/iter; left time: 545.8201s\n",
      "\titers: 200, epoch: 15 | loss: 0.0772282\n",
      "\tspeed: 0.0117s/iter; left time: 221.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0797681 Vali Loss: 0.0820332 Test Loss: 0.0871188\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789592\n",
      "\tspeed: 0.0290s/iter; left time: 546.1761s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760670\n",
      "\tspeed: 0.0116s/iter; left time: 218.2349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0794996 Vali Loss: 0.0819667 Test Loss: 0.0869654\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0803436\n",
      "\tspeed: 0.0282s/iter; left time: 525.7667s\n",
      "\titers: 200, epoch: 17 | loss: 0.0807260\n",
      "\tspeed: 0.0116s/iter; left time: 214.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.83s\n",
      "Steps: 223 | Train Loss: 0.0792149 Vali Loss: 0.0822786 Test Loss: 0.0871658\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0795373\n",
      "\tspeed: 0.0281s/iter; left time: 516.5814s\n",
      "\titers: 200, epoch: 18 | loss: 0.0793326\n",
      "\tspeed: 0.0115s/iter; left time: 210.8240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0789781 Vali Loss: 0.0821574 Test Loss: 0.0869839\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0807548\n",
      "\tspeed: 0.0288s/iter; left time: 523.5767s\n",
      "\titers: 200, epoch: 19 | loss: 0.0787308\n",
      "\tspeed: 0.0116s/iter; left time: 209.0134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0788001 Vali Loss: 0.0820995 Test Loss: 0.0871633\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020744217559695244, rmse:0.14402852952480316, mae:0.08732207864522934, rse:0.5450934767723083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1731510\n",
      "\tspeed: 0.0140s/iter; left time: 309.9864s\n",
      "\titers: 200, epoch: 1 | loss: 0.1460505\n",
      "\tspeed: 0.0115s/iter; left time: 253.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.1702867 Vali Loss: 0.1252616 Test Loss: 0.1300249\n",
      "Validation loss decreased (inf --> 0.125262).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1006787\n",
      "\tspeed: 0.0346s/iter; left time: 760.4885s\n",
      "\titers: 200, epoch: 2 | loss: 0.0925735\n",
      "\tspeed: 0.0118s/iter; left time: 258.9855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:02.90s\n",
      "Steps: 223 | Train Loss: 0.1043730 Vali Loss: 0.0868681 Test Loss: 0.0915102\n",
      "Validation loss decreased (0.125262 --> 0.086868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0896123\n",
      "\tspeed: 0.0295s/iter; left time: 641.1101s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917352\n",
      "\tspeed: 0.0118s/iter; left time: 256.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:02.88s\n",
      "Steps: 223 | Train Loss: 0.0906214 Vali Loss: 0.0847884 Test Loss: 0.0887608\n",
      "Validation loss decreased (0.086868 --> 0.084788).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0894315\n",
      "\tspeed: 0.0291s/iter; left time: 627.1317s\n",
      "\titers: 200, epoch: 4 | loss: 0.0910589\n",
      "\tspeed: 0.0115s/iter; left time: 246.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0874065 Vali Loss: 0.0838679 Test Loss: 0.0884103\n",
      "Validation loss decreased (0.084788 --> 0.083868).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0853082\n",
      "\tspeed: 0.0290s/iter; left time: 618.9656s\n",
      "\titers: 200, epoch: 5 | loss: 0.0824562\n",
      "\tspeed: 0.0115s/iter; left time: 244.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0856309 Vali Loss: 0.0826546 Test Loss: 0.0881909\n",
      "Validation loss decreased (0.083868 --> 0.082655).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0822363\n",
      "\tspeed: 0.0286s/iter; left time: 602.9352s\n",
      "\titers: 200, epoch: 6 | loss: 0.0844333\n",
      "\tspeed: 0.0116s/iter; left time: 242.4594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0844192 Vali Loss: 0.0825971 Test Loss: 0.0878325\n",
      "Validation loss decreased (0.082655 --> 0.082597).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0793967\n",
      "\tspeed: 0.0302s/iter; left time: 629.3590s\n",
      "\titers: 200, epoch: 7 | loss: 0.0814577\n",
      "\tspeed: 0.0117s/iter; left time: 241.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:02.91s\n",
      "Steps: 223 | Train Loss: 0.0834429 Vali Loss: 0.0826814 Test Loss: 0.0876921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863563\n",
      "\tspeed: 0.0288s/iter; left time: 593.4502s\n",
      "\titers: 200, epoch: 8 | loss: 0.0811406\n",
      "\tspeed: 0.0120s/iter; left time: 247.3058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:02.92s\n",
      "Steps: 223 | Train Loss: 0.0827214 Vali Loss: 0.0824002 Test Loss: 0.0874007\n",
      "Validation loss decreased (0.082597 --> 0.082400).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0846347\n",
      "\tspeed: 0.0287s/iter; left time: 586.7538s\n",
      "\titers: 200, epoch: 9 | loss: 0.0826154\n",
      "\tspeed: 0.0115s/iter; left time: 233.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0820304 Vali Loss: 0.0822703 Test Loss: 0.0877020\n",
      "Validation loss decreased (0.082400 --> 0.082270).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811306\n",
      "\tspeed: 0.0293s/iter; left time: 591.4219s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803987\n",
      "\tspeed: 0.0116s/iter; left time: 232.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0814892 Vali Loss: 0.0820680 Test Loss: 0.0875858\n",
      "Validation loss decreased (0.082270 --> 0.082068).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0805208\n",
      "\tspeed: 0.0287s/iter; left time: 573.9877s\n",
      "\titers: 200, epoch: 11 | loss: 0.0806047\n",
      "\tspeed: 0.0115s/iter; left time: 227.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0809552 Vali Loss: 0.0823256 Test Loss: 0.0875782\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0811700\n",
      "\tspeed: 0.0294s/iter; left time: 581.3593s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788328\n",
      "\tspeed: 0.0115s/iter; left time: 225.5356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:02.87s\n",
      "Steps: 223 | Train Loss: 0.0804924 Vali Loss: 0.0821931 Test Loss: 0.0872803\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0810962\n",
      "\tspeed: 0.0289s/iter; left time: 563.8224s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851066\n",
      "\tspeed: 0.0116s/iter; left time: 224.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0801009 Vali Loss: 0.0823623 Test Loss: 0.0874463\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0843502\n",
      "\tspeed: 0.0286s/iter; left time: 551.9693s\n",
      "\titers: 200, epoch: 14 | loss: 0.0819275\n",
      "\tspeed: 0.0116s/iter; left time: 222.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:02.82s\n",
      "Steps: 223 | Train Loss: 0.0796707 Vali Loss: 0.0822738 Test Loss: 0.0873173\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0775695\n",
      "\tspeed: 0.0284s/iter; left time: 541.7929s\n",
      "\titers: 200, epoch: 15 | loss: 0.0791050\n",
      "\tspeed: 0.0115s/iter; left time: 218.7691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0793568 Vali Loss: 0.0821303 Test Loss: 0.0875209\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0817669\n",
      "\tspeed: 0.0290s/iter; left time: 547.5653s\n",
      "\titers: 200, epoch: 16 | loss: 0.0806475\n",
      "\tspeed: 0.0118s/iter; left time: 221.2348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0791216 Vali Loss: 0.0824217 Test Loss: 0.0874984\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0810358\n",
      "\tspeed: 0.0279s/iter; left time: 520.4720s\n",
      "\titers: 200, epoch: 17 | loss: 0.0766317\n",
      "\tspeed: 0.0115s/iter; left time: 212.7404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:02.78s\n",
      "Steps: 223 | Train Loss: 0.0788214 Vali Loss: 0.0820436 Test Loss: 0.0874990\n",
      "Validation loss decreased (0.082068 --> 0.082044).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0796176\n",
      "\tspeed: 0.0284s/iter; left time: 523.0539s\n",
      "\titers: 200, epoch: 18 | loss: 0.0814136\n",
      "\tspeed: 0.0116s/iter; left time: 211.8490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:02.84s\n",
      "Steps: 223 | Train Loss: 0.0785753 Vali Loss: 0.0823171 Test Loss: 0.0875437\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0756481\n",
      "\tspeed: 0.0283s/iter; left time: 515.1531s\n",
      "\titers: 200, epoch: 19 | loss: 0.0773865\n",
      "\tspeed: 0.0117s/iter; left time: 212.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:02.85s\n",
      "Steps: 223 | Train Loss: 0.0784159 Vali Loss: 0.0820838 Test Loss: 0.0873722\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0784695\n",
      "\tspeed: 0.0287s/iter; left time: 515.6963s\n",
      "\titers: 200, epoch: 20 | loss: 0.0800799\n",
      "\tspeed: 0.0116s/iter; left time: 206.4229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:02.86s\n",
      "Steps: 223 | Train Loss: 0.0782511 Vali Loss: 0.0821813 Test Loss: 0.0873397\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0795840\n",
      "\tspeed: 0.0284s/iter; left time: 503.9215s\n",
      "\titers: 200, epoch: 21 | loss: 0.0790068\n",
      "\tspeed: 0.0115s/iter; left time: 202.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0780187 Vali Loss: 0.0824653 Test Loss: 0.0874262\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0794330\n",
      "\tspeed: 0.0288s/iter; left time: 504.4616s\n",
      "\titers: 200, epoch: 22 | loss: 0.0792243\n",
      "\tspeed: 0.0115s/iter; left time: 199.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0778995 Vali Loss: 0.0821711 Test Loss: 0.0874371\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0763422\n",
      "\tspeed: 0.0281s/iter; left time: 486.2385s\n",
      "\titers: 200, epoch: 23 | loss: 0.0769411\n",
      "\tspeed: 0.0115s/iter; left time: 197.8810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0777498 Vali Loss: 0.0823708 Test Loss: 0.0875190\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0733960\n",
      "\tspeed: 0.0281s/iter; left time: 479.9942s\n",
      "\titers: 200, epoch: 24 | loss: 0.0779446\n",
      "\tspeed: 0.0115s/iter; left time: 195.7942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0776919 Vali Loss: 0.0822278 Test Loss: 0.0874607\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0755023\n",
      "\tspeed: 0.0286s/iter; left time: 482.6462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0749521\n",
      "\tspeed: 0.0116s/iter; left time: 193.8699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:02.81s\n",
      "Steps: 223 | Train Loss: 0.0775821 Vali Loss: 0.0822642 Test Loss: 0.0875200\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0821081\n",
      "\tspeed: 0.0276s/iter; left time: 459.1871s\n",
      "\titers: 200, epoch: 26 | loss: 0.0818980\n",
      "\tspeed: 0.0115s/iter; left time: 190.1066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:02.79s\n",
      "Steps: 223 | Train Loss: 0.0774814 Vali Loss: 0.0823392 Test Loss: 0.0875374\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0760011\n",
      "\tspeed: 0.0277s/iter; left time: 454.8665s\n",
      "\titers: 200, epoch: 27 | loss: 0.0782952\n",
      "\tspeed: 0.0115s/iter; left time: 188.1419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:02.80s\n",
      "Steps: 223 | Train Loss: 0.0773704 Vali Loss: 0.0823611 Test Loss: 0.0875950\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0206182599067688, rmse:0.14359059929847717, mae:0.08749900013208389, rse:0.5434360504150391\n",
      "Intermediate time for IT and pred_len 168: 00h:03m:16.16s\n",
      "Intermediate time for IT: 00h:17m:07.74s\n",
      "Total time: 01h:22m:37.55s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/42</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.0866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>0.1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/42                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0210  0.1450  0.0879\n",
       "        96            0.0373  0.1932  0.1275\n",
       "        168           0.0401  0.2002  0.1354\n",
       "ES      24            0.0099  0.0994  0.0601\n",
       "        96            0.0188  0.1371  0.0876\n",
       "        168           0.0211  0.1452  0.0937\n",
       "FR      24            0.0101  0.1007  0.0555\n",
       "        96            0.0191  0.1383  0.0809\n",
       "        168           0.0208  0.1441  0.0866\n",
       "GB      24            0.0257  0.1602  0.1006\n",
       "        96            0.0435  0.2086  0.1423\n",
       "        168           0.0464  0.2154  0.1488\n",
       "IT      24            0.0101  0.1007  0.0570\n",
       "        96            0.0185  0.1361  0.0810\n",
       "        168           0.0207  0.1438  0.0874"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/42'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_128.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PatchTST 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 512\n",
    "model = \"PatchTST\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "patch_len = 32\n",
    "stride = 16\n",
    "batch_size = 128 \n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1373355\n",
      "\tspeed: 0.0467s/iter; left time: 1036.2882s\n",
      "\titers: 200, epoch: 1 | loss: 0.1334118\n",
      "\tspeed: 0.0251s/iter; left time: 554.0842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.04s\n",
      "Steps: 223 | Train Loss: 0.1453993 Vali Loss: 0.1329783 Test Loss: 0.1404441\n",
      "Validation loss decreased (inf --> 0.132978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0888796\n",
      "\tspeed: 0.0489s/iter; left time: 1073.8007s\n",
      "\titers: 200, epoch: 2 | loss: 0.0831336\n",
      "\tspeed: 0.0251s/iter; left time: 548.1945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0907415 Vali Loss: 0.0933192 Test Loss: 0.0952993\n",
      "Validation loss decreased (0.132978 --> 0.093319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0792083\n",
      "\tspeed: 0.0491s/iter; left time: 1067.2618s\n",
      "\titers: 200, epoch: 3 | loss: 0.0782485\n",
      "\tspeed: 0.0250s/iter; left time: 540.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0800919 Vali Loss: 0.0906347 Test Loss: 0.0927831\n",
      "Validation loss decreased (0.093319 --> 0.090635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0760983\n",
      "\tspeed: 0.0487s/iter; left time: 1049.4122s\n",
      "\titers: 200, epoch: 4 | loss: 0.0804803\n",
      "\tspeed: 0.0249s/iter; left time: 533.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0776514 Vali Loss: 0.0891426 Test Loss: 0.0911534\n",
      "Validation loss decreased (0.090635 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0731426\n",
      "\tspeed: 0.0494s/iter; left time: 1052.2743s\n",
      "\titers: 200, epoch: 5 | loss: 0.0730842\n",
      "\tspeed: 0.0250s/iter; left time: 529.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0762323 Vali Loss: 0.0887006 Test Loss: 0.0911575\n",
      "Validation loss decreased (0.089143 --> 0.088701).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770437\n",
      "\tspeed: 0.0493s/iter; left time: 1038.5192s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688699\n",
      "\tspeed: 0.0251s/iter; left time: 526.3873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0752050 Vali Loss: 0.0875822 Test Loss: 0.0899144\n",
      "Validation loss decreased (0.088701 --> 0.087582).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0776841\n",
      "\tspeed: 0.0495s/iter; left time: 1032.2646s\n",
      "\titers: 200, epoch: 7 | loss: 0.0760563\n",
      "\tspeed: 0.0250s/iter; left time: 518.7276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0744924 Vali Loss: 0.0878255 Test Loss: 0.0900309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0724099\n",
      "\tspeed: 0.0492s/iter; left time: 1015.7683s\n",
      "\titers: 200, epoch: 8 | loss: 0.0770502\n",
      "\tspeed: 0.0250s/iter; left time: 512.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0739047 Vali Loss: 0.0875601 Test Loss: 0.0895829\n",
      "Validation loss decreased (0.087582 --> 0.087560).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0735691\n",
      "\tspeed: 0.0489s/iter; left time: 997.5167s\n",
      "\titers: 200, epoch: 9 | loss: 0.0746017\n",
      "\tspeed: 0.0250s/iter; left time: 507.1823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0733632 Vali Loss: 0.0873396 Test Loss: 0.0894276\n",
      "Validation loss decreased (0.087560 --> 0.087340).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712517\n",
      "\tspeed: 0.0502s/iter; left time: 1013.8873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0719973\n",
      "\tspeed: 0.0250s/iter; left time: 502.8393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0730056 Vali Loss: 0.0871200 Test Loss: 0.0890380\n",
      "Validation loss decreased (0.087340 --> 0.087120).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0736760\n",
      "\tspeed: 0.0490s/iter; left time: 978.0451s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749013\n",
      "\tspeed: 0.0249s/iter; left time: 495.6530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0726510 Vali Loss: 0.0867601 Test Loss: 0.0890658\n",
      "Validation loss decreased (0.087120 --> 0.086760).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0733816\n",
      "\tspeed: 0.0494s/iter; left time: 975.7801s\n",
      "\titers: 200, epoch: 12 | loss: 0.0710724\n",
      "\tspeed: 0.0251s/iter; left time: 493.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0723448 Vali Loss: 0.0869641 Test Loss: 0.0890288\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775656\n",
      "\tspeed: 0.0484s/iter; left time: 945.8760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0687345\n",
      "\tspeed: 0.0249s/iter; left time: 484.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0720741 Vali Loss: 0.0867219 Test Loss: 0.0888413\n",
      "Validation loss decreased (0.086760 --> 0.086722).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752403\n",
      "\tspeed: 0.0493s/iter; left time: 952.2490s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746249\n",
      "\tspeed: 0.0250s/iter; left time: 479.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0718593 Vali Loss: 0.0864101 Test Loss: 0.0884662\n",
      "Validation loss decreased (0.086722 --> 0.086410).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0715580\n",
      "\tspeed: 0.0489s/iter; left time: 932.4592s\n",
      "\titers: 200, epoch: 15 | loss: 0.0659076\n",
      "\tspeed: 0.0250s/iter; left time: 474.1515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0717240 Vali Loss: 0.0864764 Test Loss: 0.0888205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0784111\n",
      "\tspeed: 0.0484s/iter; left time: 912.3637s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652250\n",
      "\tspeed: 0.0251s/iter; left time: 470.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0714541 Vali Loss: 0.0865088 Test Loss: 0.0888026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695369\n",
      "\tspeed: 0.0492s/iter; left time: 917.6422s\n",
      "\titers: 200, epoch: 17 | loss: 0.0679761\n",
      "\tspeed: 0.0251s/iter; left time: 464.4644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0713016 Vali Loss: 0.0866600 Test Loss: 0.0888405\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0707704\n",
      "\tspeed: 0.0495s/iter; left time: 911.2658s\n",
      "\titers: 200, epoch: 18 | loss: 0.0674867\n",
      "\tspeed: 0.0251s/iter; left time: 460.1183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0711602 Vali Loss: 0.0860936 Test Loss: 0.0882517\n",
      "Validation loss decreased (0.086410 --> 0.086094).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0734340\n",
      "\tspeed: 0.0494s/iter; left time: 897.8843s\n",
      "\titers: 200, epoch: 19 | loss: 0.0713441\n",
      "\tspeed: 0.0250s/iter; left time: 452.0258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0710292 Vali Loss: 0.0862774 Test Loss: 0.0884907\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0644633\n",
      "\tspeed: 0.0485s/iter; left time: 870.8627s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701132\n",
      "\tspeed: 0.0249s/iter; left time: 445.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0709714 Vali Loss: 0.0861165 Test Loss: 0.0884363\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0698224\n",
      "\tspeed: 0.0488s/iter; left time: 865.1906s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750680\n",
      "\tspeed: 0.0250s/iter; left time: 441.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0708266 Vali Loss: 0.0863780 Test Loss: 0.0886958\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0714958\n",
      "\tspeed: 0.0485s/iter; left time: 849.5065s\n",
      "\titers: 200, epoch: 22 | loss: 0.0686006\n",
      "\tspeed: 0.0250s/iter; left time: 435.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0707735 Vali Loss: 0.0862078 Test Loss: 0.0884660\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0711541\n",
      "\tspeed: 0.0491s/iter; left time: 848.6861s\n",
      "\titers: 200, epoch: 23 | loss: 0.0663720\n",
      "\tspeed: 0.0250s/iter; left time: 430.0908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0706522 Vali Loss: 0.0860660 Test Loss: 0.0883843\n",
      "Validation loss decreased (0.086094 --> 0.086066).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0725636\n",
      "\tspeed: 0.0497s/iter; left time: 848.4616s\n",
      "\titers: 200, epoch: 24 | loss: 0.0740665\n",
      "\tspeed: 0.0251s/iter; left time: 425.7504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0705760 Vali Loss: 0.0859706 Test Loss: 0.0883283\n",
      "Validation loss decreased (0.086066 --> 0.085971).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0739742\n",
      "\tspeed: 0.0498s/iter; left time: 839.0826s\n",
      "\titers: 200, epoch: 25 | loss: 0.0699692\n",
      "\tspeed: 0.0250s/iter; left time: 419.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0705116 Vali Loss: 0.0861167 Test Loss: 0.0883272\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763717\n",
      "\tspeed: 0.0490s/iter; left time: 813.8539s\n",
      "\titers: 200, epoch: 26 | loss: 0.0682417\n",
      "\tspeed: 0.0249s/iter; left time: 412.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0704680 Vali Loss: 0.0861149 Test Loss: 0.0883842\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0696202\n",
      "\tspeed: 0.0490s/iter; left time: 803.3934s\n",
      "\titers: 200, epoch: 27 | loss: 0.0716152\n",
      "\tspeed: 0.0250s/iter; left time: 407.6705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0703974 Vali Loss: 0.0860153 Test Loss: 0.0883578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0724538\n",
      "\tspeed: 0.0484s/iter; left time: 783.6797s\n",
      "\titers: 200, epoch: 28 | loss: 0.0679542\n",
      "\tspeed: 0.0250s/iter; left time: 401.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0703348 Vali Loss: 0.0859652 Test Loss: 0.0882799\n",
      "Validation loss decreased (0.085971 --> 0.085965).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0681855\n",
      "\tspeed: 0.0486s/iter; left time: 776.1752s\n",
      "\titers: 200, epoch: 29 | loss: 0.0691818\n",
      "\tspeed: 0.0250s/iter; left time: 395.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0703257 Vali Loss: 0.0858717 Test Loss: 0.0883005\n",
      "Validation loss decreased (0.085965 --> 0.085872).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0666259\n",
      "\tspeed: 0.0496s/iter; left time: 780.1239s\n",
      "\titers: 200, epoch: 30 | loss: 0.0629813\n",
      "\tspeed: 0.0250s/iter; left time: 390.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0702629 Vali Loss: 0.0859850 Test Loss: 0.0883057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0721415\n",
      "\tspeed: 0.0491s/iter; left time: 762.3581s\n",
      "\titers: 200, epoch: 31 | loss: 0.0739303\n",
      "\tspeed: 0.0250s/iter; left time: 384.7333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0702183 Vali Loss: 0.0859044 Test Loss: 0.0883667\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0736202\n",
      "\tspeed: 0.0493s/iter; left time: 753.7578s\n",
      "\titers: 200, epoch: 32 | loss: 0.0738355\n",
      "\tspeed: 0.0250s/iter; left time: 379.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0702222 Vali Loss: 0.0859894 Test Loss: 0.0882834\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0702697\n",
      "\tspeed: 0.0492s/iter; left time: 740.5228s\n",
      "\titers: 200, epoch: 33 | loss: 0.0743087\n",
      "\tspeed: 0.0250s/iter; left time: 373.9456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0701913 Vali Loss: 0.0858794 Test Loss: 0.0882766\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697325\n",
      "\tspeed: 0.0493s/iter; left time: 731.2036s\n",
      "\titers: 200, epoch: 34 | loss: 0.0680488\n",
      "\tspeed: 0.0250s/iter; left time: 368.9693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0701571 Vali Loss: 0.0859209 Test Loss: 0.0882831\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0736714\n",
      "\tspeed: 0.0486s/iter; left time: 709.9743s\n",
      "\titers: 200, epoch: 35 | loss: 0.0691608\n",
      "\tspeed: 0.0251s/iter; left time: 363.7075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0701614 Vali Loss: 0.0858921 Test Loss: 0.0882636\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0691657\n",
      "\tspeed: 0.0494s/iter; left time: 710.7232s\n",
      "\titers: 200, epoch: 36 | loss: 0.0744323\n",
      "\tspeed: 0.0250s/iter; left time: 357.1718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0701179 Vali Loss: 0.0858365 Test Loss: 0.0882528\n",
      "Validation loss decreased (0.085872 --> 0.085837).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0688654\n",
      "\tspeed: 0.0493s/iter; left time: 698.1900s\n",
      "\titers: 200, epoch: 37 | loss: 0.0680846\n",
      "\tspeed: 0.0250s/iter; left time: 351.5321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0700891 Vali Loss: 0.0857107 Test Loss: 0.0882761\n",
      "Validation loss decreased (0.085837 --> 0.085711).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0651810\n",
      "\tspeed: 0.0494s/iter; left time: 689.4462s\n",
      "\titers: 200, epoch: 38 | loss: 0.0707111\n",
      "\tspeed: 0.0250s/iter; left time: 345.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0701103 Vali Loss: 0.0858999 Test Loss: 0.0882970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0684334\n",
      "\tspeed: 0.0483s/iter; left time: 662.9341s\n",
      "\titers: 200, epoch: 39 | loss: 0.0744249\n",
      "\tspeed: 0.0250s/iter; left time: 340.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0701173 Vali Loss: 0.0859022 Test Loss: 0.0883074\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0754938\n",
      "\tspeed: 0.0489s/iter; left time: 660.5450s\n",
      "\titers: 200, epoch: 40 | loss: 0.0740024\n",
      "\tspeed: 0.0250s/iter; left time: 335.7481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0700733 Vali Loss: 0.0858663 Test Loss: 0.0882624\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0698133\n",
      "\tspeed: 0.0485s/iter; left time: 643.7275s\n",
      "\titers: 200, epoch: 41 | loss: 0.0750550\n",
      "\tspeed: 0.0250s/iter; left time: 329.2958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0701352 Vali Loss: 0.0858977 Test Loss: 0.0883255\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0642483\n",
      "\tspeed: 0.0490s/iter; left time: 640.1226s\n",
      "\titers: 200, epoch: 42 | loss: 0.0671091\n",
      "\tspeed: 0.0250s/iter; left time: 323.5948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0700657 Vali Loss: 0.0859332 Test Loss: 0.0882965\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0735642\n",
      "\tspeed: 0.0497s/iter; left time: 637.8632s\n",
      "\titers: 200, epoch: 43 | loss: 0.0729568\n",
      "\tspeed: 0.0251s/iter; left time: 319.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0700165 Vali Loss: 0.0858927 Test Loss: 0.0883076\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0734636\n",
      "\tspeed: 0.0489s/iter; left time: 616.4362s\n",
      "\titers: 200, epoch: 44 | loss: 0.0690300\n",
      "\tspeed: 0.0251s/iter; left time: 313.7022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0700028 Vali Loss: 0.0858704 Test Loss: 0.0883119\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0671917\n",
      "\tspeed: 0.0493s/iter; left time: 610.5114s\n",
      "\titers: 200, epoch: 45 | loss: 0.0709053\n",
      "\tspeed: 0.0251s/iter; left time: 308.2087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0700380 Vali Loss: 0.0858327 Test Loss: 0.0882856\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0700764\n",
      "\tspeed: 0.0491s/iter; left time: 597.5878s\n",
      "\titers: 200, epoch: 46 | loss: 0.0692285\n",
      "\tspeed: 0.0251s/iter; left time: 302.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0699673 Vali Loss: 0.0858734 Test Loss: 0.0882937\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0695581\n",
      "\tspeed: 0.0492s/iter; left time: 587.7611s\n",
      "\titers: 200, epoch: 47 | loss: 0.0699299\n",
      "\tspeed: 0.0252s/iter; left time: 297.8902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0699852 Vali Loss: 0.0858123 Test Loss: 0.0882996\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021149860695004463, rmse:0.14542992413043976, mae:0.08827611804008484, rse:0.5132423043251038\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1461521\n",
      "\tspeed: 0.0273s/iter; left time: 605.2890s\n",
      "\titers: 200, epoch: 1 | loss: 0.1256195\n",
      "\tspeed: 0.0253s/iter; left time: 558.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.1449411 Vali Loss: 0.1321355 Test Loss: 0.1399244\n",
      "Validation loss decreased (inf --> 0.132135).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0943744\n",
      "\tspeed: 0.0505s/iter; left time: 1109.6407s\n",
      "\titers: 200, epoch: 2 | loss: 0.0835938\n",
      "\tspeed: 0.0249s/iter; left time: 545.3180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0905361 Vali Loss: 0.0936815 Test Loss: 0.0959489\n",
      "Validation loss decreased (0.132135 --> 0.093681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807325\n",
      "\tspeed: 0.0503s/iter; left time: 1093.1913s\n",
      "\titers: 200, epoch: 3 | loss: 0.0788035\n",
      "\tspeed: 0.0250s/iter; left time: 541.3907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0803357 Vali Loss: 0.0912253 Test Loss: 0.0936213\n",
      "Validation loss decreased (0.093681 --> 0.091225).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0775517\n",
      "\tspeed: 0.0494s/iter; left time: 1063.4861s\n",
      "\titers: 200, epoch: 4 | loss: 0.0801532\n",
      "\tspeed: 0.0250s/iter; left time: 535.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0778353 Vali Loss: 0.0896708 Test Loss: 0.0920883\n",
      "Validation loss decreased (0.091225 --> 0.089671).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0770165\n",
      "\tspeed: 0.0503s/iter; left time: 1071.8791s\n",
      "\titers: 200, epoch: 5 | loss: 0.0742212\n",
      "\tspeed: 0.0252s/iter; left time: 535.3145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0763774 Vali Loss: 0.0885667 Test Loss: 0.0912962\n",
      "Validation loss decreased (0.089671 --> 0.088567).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0766403\n",
      "\tspeed: 0.0505s/iter; left time: 1064.3044s\n",
      "\titers: 200, epoch: 6 | loss: 0.0741429\n",
      "\tspeed: 0.0251s/iter; left time: 526.8090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0753661 Vali Loss: 0.0882574 Test Loss: 0.0904761\n",
      "Validation loss decreased (0.088567 --> 0.088257).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0710612\n",
      "\tspeed: 0.0503s/iter; left time: 1049.4469s\n",
      "\titers: 200, epoch: 7 | loss: 0.0729467\n",
      "\tspeed: 0.0253s/iter; left time: 524.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0745057 Vali Loss: 0.0876982 Test Loss: 0.0900299\n",
      "Validation loss decreased (0.088257 --> 0.087698).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0691563\n",
      "\tspeed: 0.0503s/iter; left time: 1037.6588s\n",
      "\titers: 200, epoch: 8 | loss: 0.0710967\n",
      "\tspeed: 0.0252s/iter; left time: 517.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0739504 Vali Loss: 0.0872957 Test Loss: 0.0897937\n",
      "Validation loss decreased (0.087698 --> 0.087296).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0754087\n",
      "\tspeed: 0.0512s/iter; left time: 1044.7231s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683555\n",
      "\tspeed: 0.0251s/iter; left time: 509.4061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0734790 Vali Loss: 0.0872478 Test Loss: 0.0893918\n",
      "Validation loss decreased (0.087296 --> 0.087248).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0738951\n",
      "\tspeed: 0.0504s/iter; left time: 1018.6099s\n",
      "\titers: 200, epoch: 10 | loss: 0.0741360\n",
      "\tspeed: 0.0252s/iter; left time: 506.3416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0730453 Vali Loss: 0.0869284 Test Loss: 0.0893832\n",
      "Validation loss decreased (0.087248 --> 0.086928).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0699757\n",
      "\tspeed: 0.0503s/iter; left time: 1005.5212s\n",
      "\titers: 200, epoch: 11 | loss: 0.0705246\n",
      "\tspeed: 0.0252s/iter; left time: 499.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0727183 Vali Loss: 0.0868291 Test Loss: 0.0892654\n",
      "Validation loss decreased (0.086928 --> 0.086829).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0716523\n",
      "\tspeed: 0.0503s/iter; left time: 993.5282s\n",
      "\titers: 200, epoch: 12 | loss: 0.0713905\n",
      "\tspeed: 0.0252s/iter; left time: 494.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0723991 Vali Loss: 0.0866124 Test Loss: 0.0887663\n",
      "Validation loss decreased (0.086829 --> 0.086612).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0747705\n",
      "\tspeed: 0.0503s/iter; left time: 981.8418s\n",
      "\titers: 200, epoch: 13 | loss: 0.0731174\n",
      "\tspeed: 0.0253s/iter; left time: 490.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0721448 Vali Loss: 0.0868194 Test Loss: 0.0889366\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0745159\n",
      "\tspeed: 0.0497s/iter; left time: 959.7948s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712438\n",
      "\tspeed: 0.0252s/iter; left time: 483.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0718804 Vali Loss: 0.0863543 Test Loss: 0.0887567\n",
      "Validation loss decreased (0.086612 --> 0.086354).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0660448\n",
      "\tspeed: 0.0499s/iter; left time: 952.8093s\n",
      "\titers: 200, epoch: 15 | loss: 0.0721473\n",
      "\tspeed: 0.0252s/iter; left time: 478.2798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0716332 Vali Loss: 0.0865717 Test Loss: 0.0889983\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0734475\n",
      "\tspeed: 0.0496s/iter; left time: 935.3598s\n",
      "\titers: 200, epoch: 16 | loss: 0.0788704\n",
      "\tspeed: 0.0252s/iter; left time: 472.5505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0714888 Vali Loss: 0.0860736 Test Loss: 0.0887922\n",
      "Validation loss decreased (0.086354 --> 0.086074).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0709178\n",
      "\tspeed: 0.0509s/iter; left time: 948.5201s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727869\n",
      "\tspeed: 0.0252s/iter; left time: 466.3907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0713614 Vali Loss: 0.0862941 Test Loss: 0.0887875\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0707612\n",
      "\tspeed: 0.0500s/iter; left time: 920.3128s\n",
      "\titers: 200, epoch: 18 | loss: 0.0675346\n",
      "\tspeed: 0.0252s/iter; left time: 461.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0712447 Vali Loss: 0.0863197 Test Loss: 0.0886446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0749099\n",
      "\tspeed: 0.0498s/iter; left time: 905.3634s\n",
      "\titers: 200, epoch: 19 | loss: 0.0760307\n",
      "\tspeed: 0.0252s/iter; left time: 456.2595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0710522 Vali Loss: 0.0861925 Test Loss: 0.0885754\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0713197\n",
      "\tspeed: 0.0495s/iter; left time: 888.5623s\n",
      "\titers: 200, epoch: 20 | loss: 0.0713801\n",
      "\tspeed: 0.0252s/iter; left time: 449.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0709942 Vali Loss: 0.0862382 Test Loss: 0.0884672\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0677657\n",
      "\tspeed: 0.0498s/iter; left time: 883.7393s\n",
      "\titers: 200, epoch: 21 | loss: 0.0750154\n",
      "\tspeed: 0.0253s/iter; left time: 445.5551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0709194 Vali Loss: 0.0861991 Test Loss: 0.0886265\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0765982\n",
      "\tspeed: 0.0494s/iter; left time: 865.7867s\n",
      "\titers: 200, epoch: 22 | loss: 0.0738702\n",
      "\tspeed: 0.0252s/iter; left time: 438.6139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0707416 Vali Loss: 0.0861124 Test Loss: 0.0885178\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0749518\n",
      "\tspeed: 0.0497s/iter; left time: 859.9355s\n",
      "\titers: 200, epoch: 23 | loss: 0.0742371\n",
      "\tspeed: 0.0251s/iter; left time: 432.3646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0707409 Vali Loss: 0.0860502 Test Loss: 0.0884793\n",
      "Validation loss decreased (0.086074 --> 0.086050).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0701658\n",
      "\tspeed: 0.0501s/iter; left time: 855.4253s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680811\n",
      "\tspeed: 0.0252s/iter; left time: 427.7203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0706613 Vali Loss: 0.0860249 Test Loss: 0.0884572\n",
      "Validation loss decreased (0.086050 --> 0.086025).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0741741\n",
      "\tspeed: 0.0495s/iter; left time: 834.6949s\n",
      "\titers: 200, epoch: 25 | loss: 0.0710448\n",
      "\tspeed: 0.0251s/iter; left time: 420.5787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0705670 Vali Loss: 0.0860716 Test Loss: 0.0884207\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0692869\n",
      "\tspeed: 0.0492s/iter; left time: 817.8658s\n",
      "\titers: 200, epoch: 26 | loss: 0.0719596\n",
      "\tspeed: 0.0250s/iter; left time: 413.2438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 223 | Train Loss: 0.0705181 Vali Loss: 0.0859137 Test Loss: 0.0884775\n",
      "Validation loss decreased (0.086025 --> 0.085914).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0714520\n",
      "\tspeed: 0.0500s/iter; left time: 819.9517s\n",
      "\titers: 200, epoch: 27 | loss: 0.0711289\n",
      "\tspeed: 0.0253s/iter; left time: 413.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0704750 Vali Loss: 0.0858923 Test Loss: 0.0884893\n",
      "Validation loss decreased (0.085914 --> 0.085892).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0684908\n",
      "\tspeed: 0.0503s/iter; left time: 813.7036s\n",
      "\titers: 200, epoch: 28 | loss: 0.0662225\n",
      "\tspeed: 0.0252s/iter; left time: 405.3777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0704305 Vali Loss: 0.0859367 Test Loss: 0.0884536\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0741826\n",
      "\tspeed: 0.0498s/iter; left time: 794.0071s\n",
      "\titers: 200, epoch: 29 | loss: 0.0643841\n",
      "\tspeed: 0.0253s/iter; left time: 400.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0704128 Vali Loss: 0.0859557 Test Loss: 0.0884671\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0662789\n",
      "\tspeed: 0.0500s/iter; left time: 787.0195s\n",
      "\titers: 200, epoch: 30 | loss: 0.0743379\n",
      "\tspeed: 0.0252s/iter; left time: 393.6180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0703725 Vali Loss: 0.0860384 Test Loss: 0.0884674\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0758048\n",
      "\tspeed: 0.0503s/iter; left time: 780.7842s\n",
      "\titers: 200, epoch: 31 | loss: 0.0694733\n",
      "\tspeed: 0.0252s/iter; left time: 388.8904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0703420 Vali Loss: 0.0858800 Test Loss: 0.0884109\n",
      "Validation loss decreased (0.085892 --> 0.085880).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0680420\n",
      "\tspeed: 0.0504s/iter; left time: 770.7524s\n",
      "\titers: 200, epoch: 32 | loss: 0.0721457\n",
      "\tspeed: 0.0252s/iter; left time: 382.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0702696 Vali Loss: 0.0858180 Test Loss: 0.0883795\n",
      "Validation loss decreased (0.085880 --> 0.085818).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0736050\n",
      "\tspeed: 0.0501s/iter; left time: 755.3946s\n",
      "\titers: 200, epoch: 33 | loss: 0.0732561\n",
      "\tspeed: 0.0253s/iter; left time: 378.8344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0702501 Vali Loss: 0.0859268 Test Loss: 0.0884040\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0664225\n",
      "\tspeed: 0.0497s/iter; left time: 737.9105s\n",
      "\titers: 200, epoch: 34 | loss: 0.0657699\n",
      "\tspeed: 0.0252s/iter; left time: 372.2071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0701816 Vali Loss: 0.0859034 Test Loss: 0.0884167\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0711937\n",
      "\tspeed: 0.0496s/iter; left time: 724.9860s\n",
      "\titers: 200, epoch: 35 | loss: 0.0674408\n",
      "\tspeed: 0.0252s/iter; left time: 366.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0702510 Vali Loss: 0.0859230 Test Loss: 0.0883771\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0688262\n",
      "\tspeed: 0.0503s/iter; left time: 724.0122s\n",
      "\titers: 200, epoch: 36 | loss: 0.0726821\n",
      "\tspeed: 0.0252s/iter; left time: 359.9777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0702085 Vali Loss: 0.0859269 Test Loss: 0.0884174\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0670818\n",
      "\tspeed: 0.0496s/iter; left time: 702.5609s\n",
      "\titers: 200, epoch: 37 | loss: 0.0682757\n",
      "\tspeed: 0.0250s/iter; left time: 352.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0701719 Vali Loss: 0.0858489 Test Loss: 0.0884043\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0647335\n",
      "\tspeed: 0.0492s/iter; left time: 685.9853s\n",
      "\titers: 200, epoch: 38 | loss: 0.0728789\n",
      "\tspeed: 0.0251s/iter; left time: 347.1172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 223 | Train Loss: 0.0701648 Vali Loss: 0.0858962 Test Loss: 0.0883968\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0719848\n",
      "\tspeed: 0.0494s/iter; left time: 678.4394s\n",
      "\titers: 200, epoch: 39 | loss: 0.0708576\n",
      "\tspeed: 0.0251s/iter; left time: 341.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0701664 Vali Loss: 0.0858619 Test Loss: 0.0884096\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0697842\n",
      "\tspeed: 0.0498s/iter; left time: 672.2935s\n",
      "\titers: 200, epoch: 40 | loss: 0.0673004\n",
      "\tspeed: 0.0252s/iter; left time: 338.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0701322 Vali Loss: 0.0858025 Test Loss: 0.0884263\n",
      "Validation loss decreased (0.085818 --> 0.085802).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0685517\n",
      "\tspeed: 0.0500s/iter; left time: 663.9413s\n",
      "\titers: 200, epoch: 41 | loss: 0.0612718\n",
      "\tspeed: 0.0252s/iter; left time: 331.8283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0701332 Vali Loss: 0.0858518 Test Loss: 0.0883753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0725074\n",
      "\tspeed: 0.0497s/iter; left time: 649.3800s\n",
      "\titers: 200, epoch: 42 | loss: 0.0705593\n",
      "\tspeed: 0.0252s/iter; left time: 326.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0701421 Vali Loss: 0.0859170 Test Loss: 0.0883983\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0671079\n",
      "\tspeed: 0.0495s/iter; left time: 635.3529s\n",
      "\titers: 200, epoch: 43 | loss: 0.0747133\n",
      "\tspeed: 0.0253s/iter; left time: 321.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0701364 Vali Loss: 0.0858429 Test Loss: 0.0884035\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0690709\n",
      "\tspeed: 0.0498s/iter; left time: 628.4700s\n",
      "\titers: 200, epoch: 44 | loss: 0.0713201\n",
      "\tspeed: 0.0252s/iter; left time: 315.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0701425 Vali Loss: 0.0858843 Test Loss: 0.0883987\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0729482\n",
      "\tspeed: 0.0500s/iter; left time: 619.2055s\n",
      "\titers: 200, epoch: 45 | loss: 0.0685356\n",
      "\tspeed: 0.0252s/iter; left time: 309.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0700901 Vali Loss: 0.0858915 Test Loss: 0.0883627\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0745746\n",
      "\tspeed: 0.0509s/iter; left time: 619.5363s\n",
      "\titers: 200, epoch: 46 | loss: 0.0733909\n",
      "\tspeed: 0.0252s/iter; left time: 304.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0700691 Vali Loss: 0.0858574 Test Loss: 0.0883694\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0738314\n",
      "\tspeed: 0.0506s/iter; left time: 604.4592s\n",
      "\titers: 200, epoch: 47 | loss: 0.0721386\n",
      "\tspeed: 0.0251s/iter; left time: 297.1163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0700754 Vali Loss: 0.0857232 Test Loss: 0.0883822\n",
      "Validation loss decreased (0.085802 --> 0.085723).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0734515\n",
      "\tspeed: 0.0506s/iter; left time: 593.1187s\n",
      "\titers: 200, epoch: 48 | loss: 0.0707952\n",
      "\tspeed: 0.0251s/iter; left time: 291.5494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 223 | Train Loss: 0.0700326 Vali Loss: 0.0858113 Test Loss: 0.0883937\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0672538\n",
      "\tspeed: 0.0498s/iter; left time: 573.0198s\n",
      "\titers: 200, epoch: 49 | loss: 0.0684050\n",
      "\tspeed: 0.0249s/iter; left time: 283.7655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0700494 Vali Loss: 0.0859423 Test Loss: 0.0884089\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0679383\n",
      "\tspeed: 0.0494s/iter; left time: 557.4072s\n",
      "\titers: 200, epoch: 50 | loss: 0.0695522\n",
      "\tspeed: 0.0249s/iter; left time: 278.5374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0700723 Vali Loss: 0.0858360 Test Loss: 0.0883867\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0660272\n",
      "\tspeed: 0.0500s/iter; left time: 552.5143s\n",
      "\titers: 200, epoch: 51 | loss: 0.0655665\n",
      "\tspeed: 0.0254s/iter; left time: 278.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0700694 Vali Loss: 0.0858147 Test Loss: 0.0883880\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0654098\n",
      "\tspeed: 0.0500s/iter; left time: 541.2277s\n",
      "\titers: 200, epoch: 52 | loss: 0.0682493\n",
      "\tspeed: 0.0254s/iter; left time: 273.0137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0700595 Vali Loss: 0.0858020 Test Loss: 0.0884007\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0666298\n",
      "\tspeed: 0.0500s/iter; left time: 530.6993s\n",
      "\titers: 200, epoch: 53 | loss: 0.0689680\n",
      "\tspeed: 0.0254s/iter; left time: 267.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0700380 Vali Loss: 0.0858293 Test Loss: 0.0883959\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0716464\n",
      "\tspeed: 0.0497s/iter; left time: 515.8620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0708857\n",
      "\tspeed: 0.0253s/iter; left time: 259.9821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0700914 Vali Loss: 0.0858054 Test Loss: 0.0884004\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0652516\n",
      "\tspeed: 0.0500s/iter; left time: 507.6338s\n",
      "\titers: 200, epoch: 55 | loss: 0.0698527\n",
      "\tspeed: 0.0253s/iter; left time: 254.8265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0700917 Vali Loss: 0.0857407 Test Loss: 0.0883828\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0777036\n",
      "\tspeed: 0.0500s/iter; left time: 496.6173s\n",
      "\titers: 200, epoch: 56 | loss: 0.0713831\n",
      "\tspeed: 0.0254s/iter; left time: 249.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0700006 Vali Loss: 0.0857836 Test Loss: 0.0883884\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0754892\n",
      "\tspeed: 0.0506s/iter; left time: 491.1177s\n",
      "\titers: 200, epoch: 57 | loss: 0.0658672\n",
      "\tspeed: 0.0254s/iter; left time: 243.7383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0700489 Vali Loss: 0.0858200 Test Loss: 0.0883929\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_DE_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021160440519452095, rmse:0.14546628296375275, mae:0.08838219940662384, rse:0.5133706331253052\n",
      "Intermediate time for DE and pred_len 24: 00h:13m:07.29s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1524197\n",
      "\tspeed: 0.0456s/iter; left time: 1007.5414s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375952\n",
      "\tspeed: 0.0251s/iter; left time: 553.1671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 222 | Train Loss: 0.1509252 Vali Loss: 0.1419280 Test Loss: 0.1509789\n",
      "Validation loss decreased (inf --> 0.141928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1138061\n",
      "\tspeed: 0.0508s/iter; left time: 1110.4214s\n",
      "\titers: 200, epoch: 2 | loss: 0.1108992\n",
      "\tspeed: 0.0252s/iter; left time: 548.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.1142543 Vali Loss: 0.1206686 Test Loss: 0.1282206\n",
      "Validation loss decreased (0.141928 --> 0.120669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1041095\n",
      "\tspeed: 0.0517s/iter; left time: 1119.6362s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048442\n",
      "\tspeed: 0.0252s/iter; left time: 543.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.1059201 Vali Loss: 0.1185557 Test Loss: 0.1270821\n",
      "Validation loss decreased (0.120669 --> 0.118556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1051723\n",
      "\tspeed: 0.0523s/iter; left time: 1120.8748s\n",
      "\titers: 200, epoch: 4 | loss: 0.1051609\n",
      "\tspeed: 0.0252s/iter; left time: 537.7496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1039714 Vali Loss: 0.1180957 Test Loss: 0.1273423\n",
      "Validation loss decreased (0.118556 --> 0.118096).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1021679\n",
      "\tspeed: 0.0526s/iter; left time: 1115.7147s\n",
      "\titers: 200, epoch: 5 | loss: 0.0999732\n",
      "\tspeed: 0.0252s/iter; left time: 531.9331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1025546 Vali Loss: 0.1181811 Test Loss: 0.1268808\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1011426\n",
      "\tspeed: 0.0512s/iter; left time: 1075.1138s\n",
      "\titers: 200, epoch: 6 | loss: 0.0999946\n",
      "\tspeed: 0.0255s/iter; left time: 532.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1014402 Vali Loss: 0.1177357 Test Loss: 0.1269181\n",
      "Validation loss decreased (0.118096 --> 0.117736).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1005419\n",
      "\tspeed: 0.0517s/iter; left time: 1074.5997s\n",
      "\titers: 200, epoch: 7 | loss: 0.0978059\n",
      "\tspeed: 0.0254s/iter; left time: 525.9493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1004559 Vali Loss: 0.1176819 Test Loss: 0.1281645\n",
      "Validation loss decreased (0.117736 --> 0.117682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985050\n",
      "\tspeed: 0.0521s/iter; left time: 1069.5200s\n",
      "\titers: 200, epoch: 8 | loss: 0.1038893\n",
      "\tspeed: 0.0255s/iter; left time: 521.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0995783 Vali Loss: 0.1171959 Test Loss: 0.1264225\n",
      "Validation loss decreased (0.117682 --> 0.117196).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0951688\n",
      "\tspeed: 0.0512s/iter; left time: 1041.4285s\n",
      "\titers: 200, epoch: 9 | loss: 0.0956111\n",
      "\tspeed: 0.0254s/iter; left time: 514.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0988268 Vali Loss: 0.1174052 Test Loss: 0.1277224\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954819\n",
      "\tspeed: 0.0509s/iter; left time: 1023.3904s\n",
      "\titers: 200, epoch: 10 | loss: 0.1034079\n",
      "\tspeed: 0.0254s/iter; left time: 508.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0981092 Vali Loss: 0.1172850 Test Loss: 0.1271868\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1022108\n",
      "\tspeed: 0.0507s/iter; left time: 1008.8438s\n",
      "\titers: 200, epoch: 11 | loss: 0.0883767\n",
      "\tspeed: 0.0255s/iter; left time: 504.1633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0974056 Vali Loss: 0.1178961 Test Loss: 0.1278977\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1006592\n",
      "\tspeed: 0.0517s/iter; left time: 1015.5895s\n",
      "\titers: 200, epoch: 12 | loss: 0.0967516\n",
      "\tspeed: 0.0254s/iter; left time: 497.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0967342 Vali Loss: 0.1180168 Test Loss: 0.1285491\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0893896\n",
      "\tspeed: 0.0513s/iter; left time: 997.1997s\n",
      "\titers: 200, epoch: 13 | loss: 0.1023085\n",
      "\tspeed: 0.0254s/iter; left time: 490.8524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0962980 Vali Loss: 0.1178484 Test Loss: 0.1280199\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0966621\n",
      "\tspeed: 0.0512s/iter; left time: 984.2322s\n",
      "\titers: 200, epoch: 14 | loss: 0.0981322\n",
      "\tspeed: 0.0255s/iter; left time: 486.5458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0957736 Vali Loss: 0.1181080 Test Loss: 0.1278495\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1028325\n",
      "\tspeed: 0.0507s/iter; left time: 963.5776s\n",
      "\titers: 200, epoch: 15 | loss: 0.0946158\n",
      "\tspeed: 0.0255s/iter; left time: 481.0436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0953171 Vali Loss: 0.1185629 Test Loss: 0.1278412\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0918257\n",
      "\tspeed: 0.0517s/iter; left time: 969.9707s\n",
      "\titers: 200, epoch: 16 | loss: 0.0940629\n",
      "\tspeed: 0.0256s/iter; left time: 477.2058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 222 | Train Loss: 0.0949627 Vali Loss: 0.1188230 Test Loss: 0.1280066\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0924636\n",
      "\tspeed: 0.0521s/iter; left time: 967.1558s\n",
      "\titers: 200, epoch: 17 | loss: 0.0977937\n",
      "\tspeed: 0.0254s/iter; left time: 468.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.0945861 Vali Loss: 0.1190186 Test Loss: 0.1285008\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0980287\n",
      "\tspeed: 0.0510s/iter; left time: 934.0348s\n",
      "\titers: 200, epoch: 18 | loss: 0.0947321\n",
      "\tspeed: 0.0254s/iter; left time: 463.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0942736 Vali Loss: 0.1191351 Test Loss: 0.1282264\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03628804534673691, rmse:0.19049420952796936, mae:0.12642250955104828, rse:0.6745785474777222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1495005\n",
      "\tspeed: 0.0279s/iter; left time: 615.6964s\n",
      "\titers: 200, epoch: 1 | loss: 0.1483644\n",
      "\tspeed: 0.0254s/iter; left time: 559.1199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1538858 Vali Loss: 0.1434507 Test Loss: 0.1525832\n",
      "Validation loss decreased (inf --> 0.143451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1093789\n",
      "\tspeed: 0.0517s/iter; left time: 1130.5557s\n",
      "\titers: 200, epoch: 2 | loss: 0.1060983\n",
      "\tspeed: 0.0255s/iter; left time: 556.2733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1145388 Vali Loss: 0.1205670 Test Loss: 0.1277450\n",
      "Validation loss decreased (0.143451 --> 0.120567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1053650\n",
      "\tspeed: 0.0557s/iter; left time: 1206.9195s\n",
      "\titers: 200, epoch: 3 | loss: 0.1052486\n",
      "\tspeed: 0.0253s/iter; left time: 546.4493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1059764 Vali Loss: 0.1189504 Test Loss: 0.1264854\n",
      "Validation loss decreased (0.120567 --> 0.118950).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032582\n",
      "\tspeed: 0.0511s/iter; left time: 1095.2144s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007004\n",
      "\tspeed: 0.0255s/iter; left time: 544.0990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1036641 Vali Loss: 0.1181136 Test Loss: 0.1268559\n",
      "Validation loss decreased (0.118950 --> 0.118114).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0987287\n",
      "\tspeed: 0.0507s/iter; left time: 1076.3586s\n",
      "\titers: 200, epoch: 5 | loss: 0.1038093\n",
      "\tspeed: 0.0254s/iter; left time: 536.7854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1022074 Vali Loss: 0.1173323 Test Loss: 0.1264772\n",
      "Validation loss decreased (0.118114 --> 0.117332).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0989035\n",
      "\tspeed: 0.0518s/iter; left time: 1087.7913s\n",
      "\titers: 200, epoch: 6 | loss: 0.0998063\n",
      "\tspeed: 0.0255s/iter; left time: 533.7056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.1010978 Vali Loss: 0.1166770 Test Loss: 0.1269804\n",
      "Validation loss decreased (0.117332 --> 0.116677).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1015427\n",
      "\tspeed: 0.0518s/iter; left time: 1076.0430s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027738\n",
      "\tspeed: 0.0255s/iter; left time: 526.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.1000916 Vali Loss: 0.1172437 Test Loss: 0.1277861\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1011881\n",
      "\tspeed: 0.0518s/iter; left time: 1065.0841s\n",
      "\titers: 200, epoch: 8 | loss: 0.1011126\n",
      "\tspeed: 0.0255s/iter; left time: 521.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0992966 Vali Loss: 0.1172458 Test Loss: 0.1268532\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0969131\n",
      "\tspeed: 0.0518s/iter; left time: 1053.8025s\n",
      "\titers: 200, epoch: 9 | loss: 0.1006673\n",
      "\tspeed: 0.0256s/iter; left time: 516.7623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0985443 Vali Loss: 0.1170602 Test Loss: 0.1277052\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0992040\n",
      "\tspeed: 0.0515s/iter; left time: 1035.2037s\n",
      "\titers: 200, epoch: 10 | loss: 0.0947819\n",
      "\tspeed: 0.0254s/iter; left time: 509.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.0978525 Vali Loss: 0.1170986 Test Loss: 0.1273471\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0918789\n",
      "\tspeed: 0.0513s/iter; left time: 1020.3248s\n",
      "\titers: 200, epoch: 11 | loss: 0.0924916\n",
      "\tspeed: 0.0255s/iter; left time: 503.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0972131 Vali Loss: 0.1172122 Test Loss: 0.1279654\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0906690\n",
      "\tspeed: 0.0506s/iter; left time: 993.8415s\n",
      "\titers: 200, epoch: 12 | loss: 0.0971802\n",
      "\tspeed: 0.0255s/iter; left time: 497.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0965657 Vali Loss: 0.1173786 Test Loss: 0.1278468\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1020299\n",
      "\tspeed: 0.0506s/iter; left time: 982.8033s\n",
      "\titers: 200, epoch: 13 | loss: 0.0981012\n",
      "\tspeed: 0.0254s/iter; left time: 491.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.0961574 Vali Loss: 0.1177682 Test Loss: 0.1272987\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0930351\n",
      "\tspeed: 0.0514s/iter; left time: 987.6919s\n",
      "\titers: 200, epoch: 14 | loss: 0.0943429\n",
      "\tspeed: 0.0254s/iter; left time: 485.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0956286 Vali Loss: 0.1182583 Test Loss: 0.1283219\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0971190\n",
      "\tspeed: 0.0510s/iter; left time: 968.4833s\n",
      "\titers: 200, epoch: 15 | loss: 0.0957469\n",
      "\tspeed: 0.0255s/iter; left time: 481.7441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0951772 Vali Loss: 0.1182584 Test Loss: 0.1283540\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0929601\n",
      "\tspeed: 0.0509s/iter; left time: 955.7018s\n",
      "\titers: 200, epoch: 16 | loss: 0.0904809\n",
      "\tspeed: 0.0255s/iter; left time: 475.6678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0947826 Vali Loss: 0.1184066 Test Loss: 0.1285332\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_DE_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03634176030755043, rmse:0.19063514471054077, mae:0.12698037922382355, rse:0.6750776171684265\n",
      "Intermediate time for DE and pred_len 96: 00h:04m:32.04s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1490380\n",
      "\tspeed: 0.0466s/iter; left time: 1029.1702s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348439\n",
      "\tspeed: 0.0255s/iter; left time: 560.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.09s\n",
      "Steps: 222 | Train Loss: 0.1536819 Vali Loss: 0.1435488 Test Loss: 0.1536387\n",
      "Validation loss decreased (inf --> 0.143549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1156273\n",
      "\tspeed: 0.0514s/iter; left time: 1124.9093s\n",
      "\titers: 200, epoch: 2 | loss: 0.1153742\n",
      "\tspeed: 0.0255s/iter; left time: 555.3105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1194604 Vali Loss: 0.1243052 Test Loss: 0.1335621\n",
      "Validation loss decreased (0.143549 --> 0.124305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091914\n",
      "\tspeed: 0.0516s/iter; left time: 1116.5229s\n",
      "\titers: 200, epoch: 3 | loss: 0.1107274\n",
      "\tspeed: 0.0255s/iter; left time: 549.2186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1114915 Vali Loss: 0.1228457 Test Loss: 0.1317932\n",
      "Validation loss decreased (0.124305 --> 0.122846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1125002\n",
      "\tspeed: 0.0512s/iter; left time: 1096.7362s\n",
      "\titers: 200, epoch: 4 | loss: 0.1050300\n",
      "\tspeed: 0.0256s/iter; left time: 545.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1093076 Vali Loss: 0.1216234 Test Loss: 0.1328400\n",
      "Validation loss decreased (0.122846 --> 0.121623).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1088410\n",
      "\tspeed: 0.0525s/iter; left time: 1113.9772s\n",
      "\titers: 200, epoch: 5 | loss: 0.1082159\n",
      "\tspeed: 0.0256s/iter; left time: 540.6266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.1076152 Vali Loss: 0.1219271 Test Loss: 0.1323917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080438\n",
      "\tspeed: 0.0519s/iter; left time: 1089.1529s\n",
      "\titers: 200, epoch: 6 | loss: 0.1060845\n",
      "\tspeed: 0.0256s/iter; left time: 535.0526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1063124 Vali Loss: 0.1223658 Test Loss: 0.1331617\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1041891\n",
      "\tspeed: 0.0516s/iter; left time: 1071.8863s\n",
      "\titers: 200, epoch: 7 | loss: 0.1084695\n",
      "\tspeed: 0.0256s/iter; left time: 529.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1050821 Vali Loss: 0.1230205 Test Loss: 0.1332460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1057436\n",
      "\tspeed: 0.0513s/iter; left time: 1053.6532s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041152\n",
      "\tspeed: 0.0256s/iter; left time: 522.4783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1038863 Vali Loss: 0.1226599 Test Loss: 0.1340252\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1044045\n",
      "\tspeed: 0.0511s/iter; left time: 1037.7588s\n",
      "\titers: 200, epoch: 9 | loss: 0.1016497\n",
      "\tspeed: 0.0255s/iter; left time: 516.7142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1028623 Vali Loss: 0.1233028 Test Loss: 0.1341052\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1005499\n",
      "\tspeed: 0.0524s/iter; left time: 1052.9043s\n",
      "\titers: 200, epoch: 10 | loss: 0.1009529\n",
      "\tspeed: 0.0256s/iter; left time: 511.5196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1019990 Vali Loss: 0.1234747 Test Loss: 0.1343502\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1020088\n",
      "\tspeed: 0.0523s/iter; left time: 1039.0064s\n",
      "\titers: 200, epoch: 11 | loss: 0.1041425\n",
      "\tspeed: 0.0256s/iter; left time: 506.4536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1011726 Vali Loss: 0.1239517 Test Loss: 0.1350030\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1044545\n",
      "\tspeed: 0.0529s/iter; left time: 1040.5043s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023122\n",
      "\tspeed: 0.0256s/iter; left time: 500.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1004230 Vali Loss: 0.1238782 Test Loss: 0.1346552\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0961498\n",
      "\tspeed: 0.0531s/iter; left time: 1033.0765s\n",
      "\titers: 200, epoch: 13 | loss: 0.0913712\n",
      "\tspeed: 0.0256s/iter; left time: 495.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.0997918 Vali Loss: 0.1246168 Test Loss: 0.1347854\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0991515\n",
      "\tspeed: 0.0536s/iter; left time: 1030.3442s\n",
      "\titers: 200, epoch: 14 | loss: 0.1034397\n",
      "\tspeed: 0.0256s/iter; left time: 488.9143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.0992378 Vali Loss: 0.1244980 Test Loss: 0.1352518\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03833557665348053, rmse:0.1957947313785553, mae:0.13283993303775787, rse:0.6935206651687622\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1543029\n",
      "\tspeed: 0.0281s/iter; left time: 620.1876s\n",
      "\titers: 200, epoch: 1 | loss: 0.1435044\n",
      "\tspeed: 0.0256s/iter; left time: 563.8414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 222 | Train Loss: 0.1547431 Vali Loss: 0.1446874 Test Loss: 0.1549106\n",
      "Validation loss decreased (inf --> 0.144687).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1210449\n",
      "\tspeed: 0.0531s/iter; left time: 1161.3309s\n",
      "\titers: 200, epoch: 2 | loss: 0.1119168\n",
      "\tspeed: 0.0256s/iter; left time: 557.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.1194619 Vali Loss: 0.1244446 Test Loss: 0.1335501\n",
      "Validation loss decreased (0.144687 --> 0.124445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108734\n",
      "\tspeed: 0.0565s/iter; left time: 1222.7998s\n",
      "\titers: 200, epoch: 3 | loss: 0.1088899\n",
      "\tspeed: 0.0256s/iter; left time: 552.7539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.1115335 Vali Loss: 0.1223524 Test Loss: 0.1330087\n",
      "Validation loss decreased (0.124445 --> 0.122352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1085154\n",
      "\tspeed: 0.0536s/iter; left time: 1149.4773s\n",
      "\titers: 200, epoch: 4 | loss: 0.1110478\n",
      "\tspeed: 0.0256s/iter; left time: 546.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1093102 Vali Loss: 0.1214626 Test Loss: 0.1330683\n",
      "Validation loss decreased (0.122352 --> 0.121463).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106680\n",
      "\tspeed: 0.0537s/iter; left time: 1138.7320s\n",
      "\titers: 200, epoch: 5 | loss: 0.1070109\n",
      "\tspeed: 0.0256s/iter; left time: 540.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.1077559 Vali Loss: 0.1214304 Test Loss: 0.1337442\n",
      "Validation loss decreased (0.121463 --> 0.121430).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1029641\n",
      "\tspeed: 0.0530s/iter; left time: 1112.2664s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036105\n",
      "\tspeed: 0.0256s/iter; left time: 535.4062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1064275 Vali Loss: 0.1215250 Test Loss: 0.1326394\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1049076\n",
      "\tspeed: 0.0523s/iter; left time: 1086.2031s\n",
      "\titers: 200, epoch: 7 | loss: 0.1039453\n",
      "\tspeed: 0.0256s/iter; left time: 528.6024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1052114 Vali Loss: 0.1226436 Test Loss: 0.1345214\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1050609\n",
      "\tspeed: 0.0518s/iter; left time: 1065.0336s\n",
      "\titers: 200, epoch: 8 | loss: 0.1080089\n",
      "\tspeed: 0.0256s/iter; left time: 523.0863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1041170 Vali Loss: 0.1224953 Test Loss: 0.1334585\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1030256\n",
      "\tspeed: 0.0523s/iter; left time: 1062.0085s\n",
      "\titers: 200, epoch: 9 | loss: 0.1049656\n",
      "\tspeed: 0.0256s/iter; left time: 517.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1030426 Vali Loss: 0.1231798 Test Loss: 0.1348209\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1027530\n",
      "\tspeed: 0.0519s/iter; left time: 1044.3300s\n",
      "\titers: 200, epoch: 10 | loss: 0.0984921\n",
      "\tspeed: 0.0256s/iter; left time: 512.4535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.1021722 Vali Loss: 0.1231913 Test Loss: 0.1343626\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1038189\n",
      "\tspeed: 0.0516s/iter; left time: 1026.1127s\n",
      "\titers: 200, epoch: 11 | loss: 0.0992023\n",
      "\tspeed: 0.0256s/iter; left time: 506.4142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1012704 Vali Loss: 0.1232842 Test Loss: 0.1349792\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0977994\n",
      "\tspeed: 0.0522s/iter; left time: 1026.4805s\n",
      "\titers: 200, epoch: 12 | loss: 0.1018422\n",
      "\tspeed: 0.0255s/iter; left time: 499.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.1005818 Vali Loss: 0.1236513 Test Loss: 0.1347542\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0984675\n",
      "\tspeed: 0.0521s/iter; left time: 1013.2955s\n",
      "\titers: 200, epoch: 13 | loss: 0.1010876\n",
      "\tspeed: 0.0257s/iter; left time: 496.6222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.0999027 Vali Loss: 0.1240007 Test Loss: 0.1342938\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0995590\n",
      "\tspeed: 0.0527s/iter; left time: 1013.0638s\n",
      "\titers: 200, epoch: 14 | loss: 0.1007741\n",
      "\tspeed: 0.0256s/iter; left time: 489.7658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.0993070 Vali Loss: 0.1239844 Test Loss: 0.1345304\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1017895\n",
      "\tspeed: 0.0523s/iter; left time: 993.1866s\n",
      "\titers: 200, epoch: 15 | loss: 0.0955664\n",
      "\tspeed: 0.0256s/iter; left time: 483.9907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.0987165 Vali Loss: 0.1246377 Test Loss: 0.1349451\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_DE_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038744036108255386, rmse:0.19683504104614258, mae:0.1337442696094513, rse:0.6972056031227112\n",
      "Intermediate time for DE and pred_len 168: 00h:03m:57.90s\n",
      "Intermediate time for DE: 00h:21m:37.22s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1248104\n",
      "\tspeed: 0.0456s/iter; left time: 1013.0756s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189683\n",
      "\tspeed: 0.0250s/iter; left time: 552.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 223 | Train Loss: 0.1320080 Vali Loss: 0.1245858 Test Loss: 0.1461386\n",
      "Validation loss decreased (inf --> 0.124586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871835\n",
      "\tspeed: 0.0492s/iter; left time: 1080.7499s\n",
      "\titers: 200, epoch: 2 | loss: 0.0825444\n",
      "\tspeed: 0.0249s/iter; left time: 545.3207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0873957 Vali Loss: 0.0911867 Test Loss: 0.1036528\n",
      "Validation loss decreased (0.124586 --> 0.091187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0829440\n",
      "\tspeed: 0.0486s/iter; left time: 1056.3517s\n",
      "\titers: 200, epoch: 3 | loss: 0.0811696\n",
      "\tspeed: 0.0250s/iter; left time: 541.1446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0794493 Vali Loss: 0.0906464 Test Loss: 0.1034824\n",
      "Validation loss decreased (0.091187 --> 0.090646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736907\n",
      "\tspeed: 0.0484s/iter; left time: 1041.6584s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760392\n",
      "\tspeed: 0.0249s/iter; left time: 533.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0779166 Vali Loss: 0.0895404 Test Loss: 0.1021740\n",
      "Validation loss decreased (0.090646 --> 0.089540).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0748423\n",
      "\tspeed: 0.0492s/iter; left time: 1047.6181s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785504\n",
      "\tspeed: 0.0249s/iter; left time: 529.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0768613 Vali Loss: 0.0893269 Test Loss: 0.1015313\n",
      "Validation loss decreased (0.089540 --> 0.089327).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0773457\n",
      "\tspeed: 0.0489s/iter; left time: 1031.2186s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689240\n",
      "\tspeed: 0.0250s/iter; left time: 523.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0760901 Vali Loss: 0.0886091 Test Loss: 0.1013818\n",
      "Validation loss decreased (0.089327 --> 0.088609).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797589\n",
      "\tspeed: 0.0485s/iter; left time: 1011.0934s\n",
      "\titers: 200, epoch: 7 | loss: 0.0784155\n",
      "\tspeed: 0.0249s/iter; left time: 516.4686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0755444 Vali Loss: 0.0884675 Test Loss: 0.1010676\n",
      "Validation loss decreased (0.088609 --> 0.088467).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0801681\n",
      "\tspeed: 0.0488s/iter; left time: 1006.3214s\n",
      "\titers: 200, epoch: 8 | loss: 0.0736745\n",
      "\tspeed: 0.0249s/iter; left time: 511.7652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0749900 Vali Loss: 0.0884748 Test Loss: 0.1007913\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.0481s/iter; left time: 982.8480s\n",
      "\titers: 200, epoch: 9 | loss: 0.0762836\n",
      "\tspeed: 0.0249s/iter; left time: 505.5755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0746327 Vali Loss: 0.0882159 Test Loss: 0.1009664\n",
      "Validation loss decreased (0.088467 --> 0.088216).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0769711\n",
      "\tspeed: 0.0484s/iter; left time: 978.1709s\n",
      "\titers: 200, epoch: 10 | loss: 0.0704211\n",
      "\tspeed: 0.0249s/iter; left time: 500.2281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0743007 Vali Loss: 0.0878040 Test Loss: 0.1006743\n",
      "Validation loss decreased (0.088216 --> 0.087804).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0712703\n",
      "\tspeed: 0.0484s/iter; left time: 967.5832s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745102\n",
      "\tspeed: 0.0249s/iter; left time: 495.0294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0739317 Vali Loss: 0.0876703 Test Loss: 0.1006999\n",
      "Validation loss decreased (0.087804 --> 0.087670).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0710412\n",
      "\tspeed: 0.0486s/iter; left time: 959.5855s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782618\n",
      "\tspeed: 0.0249s/iter; left time: 489.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 223 | Train Loss: 0.0736354 Vali Loss: 0.0876544 Test Loss: 0.1004437\n",
      "Validation loss decreased (0.087670 --> 0.087654).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783196\n",
      "\tspeed: 0.0478s/iter; left time: 933.3550s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716469\n",
      "\tspeed: 0.0249s/iter; left time: 483.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 223 | Train Loss: 0.0734116 Vali Loss: 0.0879656 Test Loss: 0.1002505\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0729655\n",
      "\tspeed: 0.0491s/iter; left time: 948.2735s\n",
      "\titers: 200, epoch: 14 | loss: 0.0741272\n",
      "\tspeed: 0.0249s/iter; left time: 478.8751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 223 | Train Loss: 0.0731876 Vali Loss: 0.0877671 Test Loss: 0.1007679\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0784120\n",
      "\tspeed: 0.0483s/iter; left time: 921.8843s\n",
      "\titers: 200, epoch: 15 | loss: 0.0713894\n",
      "\tspeed: 0.0250s/iter; left time: 473.5409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0730301 Vali Loss: 0.0874009 Test Loss: 0.1004193\n",
      "Validation loss decreased (0.087654 --> 0.087401).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0752648\n",
      "\tspeed: 0.0490s/iter; left time: 924.3291s\n",
      "\titers: 200, epoch: 16 | loss: 0.0692569\n",
      "\tspeed: 0.0249s/iter; left time: 467.7986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0728606 Vali Loss: 0.0875206 Test Loss: 0.0998576\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0696480\n",
      "\tspeed: 0.0483s/iter; left time: 899.3966s\n",
      "\titers: 200, epoch: 17 | loss: 0.0696990\n",
      "\tspeed: 0.0250s/iter; left time: 462.6908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0727070 Vali Loss: 0.0874191 Test Loss: 0.1002236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680822\n",
      "\tspeed: 0.0484s/iter; left time: 891.6223s\n",
      "\titers: 200, epoch: 18 | loss: 0.0788060\n",
      "\tspeed: 0.0250s/iter; left time: 458.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0725290 Vali Loss: 0.0875011 Test Loss: 0.1004622\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0758588\n",
      "\tspeed: 0.0504s/iter; left time: 915.8557s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707837\n",
      "\tspeed: 0.0249s/iter; left time: 450.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0724507 Vali Loss: 0.0874077 Test Loss: 0.1003668\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0709867\n",
      "\tspeed: 0.0487s/iter; left time: 875.2528s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729043\n",
      "\tspeed: 0.0249s/iter; left time: 445.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0723412 Vali Loss: 0.0872065 Test Loss: 0.0999682\n",
      "Validation loss decreased (0.087401 --> 0.087207).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0778060\n",
      "\tspeed: 0.0496s/iter; left time: 879.3697s\n",
      "\titers: 200, epoch: 21 | loss: 0.0670025\n",
      "\tspeed: 0.0248s/iter; left time: 437.8072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0722158 Vali Loss: 0.0873711 Test Loss: 0.1000982\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0729466\n",
      "\tspeed: 0.0481s/iter; left time: 841.7661s\n",
      "\titers: 200, epoch: 22 | loss: 0.0700531\n",
      "\tspeed: 0.0249s/iter; left time: 433.2143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0720897 Vali Loss: 0.0874786 Test Loss: 0.1000748\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0726483\n",
      "\tspeed: 0.0488s/iter; left time: 844.3330s\n",
      "\titers: 200, epoch: 23 | loss: 0.0730122\n",
      "\tspeed: 0.0249s/iter; left time: 428.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0720368 Vali Loss: 0.0873162 Test Loss: 0.1000200\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0696376\n",
      "\tspeed: 0.0483s/iter; left time: 823.9977s\n",
      "\titers: 200, epoch: 24 | loss: 0.0693120\n",
      "\tspeed: 0.0249s/iter; left time: 422.5034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0720012 Vali Loss: 0.0873478 Test Loss: 0.0998815\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0735212\n",
      "\tspeed: 0.0478s/iter; left time: 805.7458s\n",
      "\titers: 200, epoch: 25 | loss: 0.0706571\n",
      "\tspeed: 0.0249s/iter; left time: 417.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 223 | Train Loss: 0.0718782 Vali Loss: 0.0875282 Test Loss: 0.0999747\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0723889\n",
      "\tspeed: 0.0481s/iter; left time: 798.9622s\n",
      "\titers: 200, epoch: 26 | loss: 0.0746940\n",
      "\tspeed: 0.0252s/iter; left time: 416.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0718173 Vali Loss: 0.0872865 Test Loss: 0.1001369\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0697213\n",
      "\tspeed: 0.0499s/iter; left time: 818.1169s\n",
      "\titers: 200, epoch: 27 | loss: 0.0763196\n",
      "\tspeed: 0.0252s/iter; left time: 411.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0717980 Vali Loss: 0.0873656 Test Loss: 0.1000675\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0663531\n",
      "\tspeed: 0.0501s/iter; left time: 811.1703s\n",
      "\titers: 200, epoch: 28 | loss: 0.0710246\n",
      "\tspeed: 0.0251s/iter; left time: 403.6916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0717659 Vali Loss: 0.0874845 Test Loss: 0.0999915\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0710578\n",
      "\tspeed: 0.0484s/iter; left time: 772.1985s\n",
      "\titers: 200, epoch: 29 | loss: 0.0703827\n",
      "\tspeed: 0.0249s/iter; left time: 394.9517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 223 | Train Loss: 0.0716918 Vali Loss: 0.0875549 Test Loss: 0.1000763\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0700337\n",
      "\tspeed: 0.0489s/iter; left time: 768.6804s\n",
      "\titers: 200, epoch: 30 | loss: 0.0695842\n",
      "\tspeed: 0.0250s/iter; left time: 390.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 223 | Train Loss: 0.0716595 Vali Loss: 0.0874843 Test Loss: 0.0999994\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02504582144320011, rmse:0.15825872123241425, mae:0.09996816515922546, rse:0.5459477305412292\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1323163\n",
      "\tspeed: 0.0276s/iter; left time: 611.9415s\n",
      "\titers: 200, epoch: 1 | loss: 0.1189228\n",
      "\tspeed: 0.0253s/iter; left time: 559.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.1318476 Vali Loss: 0.1257551 Test Loss: 0.1473570\n",
      "Validation loss decreased (inf --> 0.125755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0798685\n",
      "\tspeed: 0.0501s/iter; left time: 1101.4439s\n",
      "\titers: 200, epoch: 2 | loss: 0.0845883\n",
      "\tspeed: 0.0253s/iter; left time: 554.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0872557 Vali Loss: 0.0915369 Test Loss: 0.1030957\n",
      "Validation loss decreased (0.125755 --> 0.091537).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0800503\n",
      "\tspeed: 0.0507s/iter; left time: 1103.7914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0787766\n",
      "\tspeed: 0.0253s/iter; left time: 548.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0795310 Vali Loss: 0.0903285 Test Loss: 0.1020660\n",
      "Validation loss decreased (0.091537 --> 0.090328).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0773197\n",
      "\tspeed: 0.0509s/iter; left time: 1096.3777s\n",
      "\titers: 200, epoch: 4 | loss: 0.0830111\n",
      "\tspeed: 0.0253s/iter; left time: 542.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0780791 Vali Loss: 0.0899431 Test Loss: 0.1017878\n",
      "Validation loss decreased (0.090328 --> 0.089943).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0744771\n",
      "\tspeed: 0.0514s/iter; left time: 1094.8789s\n",
      "\titers: 200, epoch: 5 | loss: 0.0765711\n",
      "\tspeed: 0.0253s/iter; left time: 536.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 223 | Train Loss: 0.0770148 Vali Loss: 0.0889636 Test Loss: 0.1018415\n",
      "Validation loss decreased (0.089943 --> 0.088964).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713009\n",
      "\tspeed: 0.0507s/iter; left time: 1068.3663s\n",
      "\titers: 200, epoch: 6 | loss: 0.0817048\n",
      "\tspeed: 0.0252s/iter; left time: 529.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0761595 Vali Loss: 0.0886923 Test Loss: 0.1008152\n",
      "Validation loss decreased (0.088964 --> 0.088692).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745291\n",
      "\tspeed: 0.0506s/iter; left time: 1055.8602s\n",
      "\titers: 200, epoch: 7 | loss: 0.0710425\n",
      "\tspeed: 0.0254s/iter; left time: 527.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0755859 Vali Loss: 0.0886602 Test Loss: 0.1013759\n",
      "Validation loss decreased (0.088692 --> 0.088660).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0698976\n",
      "\tspeed: 0.0503s/iter; left time: 1039.1293s\n",
      "\titers: 200, epoch: 8 | loss: 0.0723516\n",
      "\tspeed: 0.0253s/iter; left time: 518.9462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0751700 Vali Loss: 0.0883549 Test Loss: 0.1006763\n",
      "Validation loss decreased (0.088660 --> 0.088355).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730734\n",
      "\tspeed: 0.0507s/iter; left time: 1035.3710s\n",
      "\titers: 200, epoch: 9 | loss: 0.0750179\n",
      "\tspeed: 0.0254s/iter; left time: 515.8586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0747537 Vali Loss: 0.0881169 Test Loss: 0.1011833\n",
      "Validation loss decreased (0.088355 --> 0.088117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0722550\n",
      "\tspeed: 0.0501s/iter; left time: 1010.9259s\n",
      "\titers: 200, epoch: 10 | loss: 0.0722195\n",
      "\tspeed: 0.0253s/iter; left time: 508.3206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0743964 Vali Loss: 0.0881602 Test Loss: 0.1006756\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0740176\n",
      "\tspeed: 0.0503s/iter; left time: 1004.4579s\n",
      "\titers: 200, epoch: 11 | loss: 0.0699266\n",
      "\tspeed: 0.0253s/iter; left time: 502.3798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0740340 Vali Loss: 0.0882749 Test Loss: 0.1005724\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0748533\n",
      "\tspeed: 0.0501s/iter; left time: 989.0475s\n",
      "\titers: 200, epoch: 12 | loss: 0.0782913\n",
      "\tspeed: 0.0254s/iter; left time: 499.6394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0737781 Vali Loss: 0.0881477 Test Loss: 0.1009226\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0745476\n",
      "\tspeed: 0.0501s/iter; left time: 977.6201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714304\n",
      "\tspeed: 0.0253s/iter; left time: 490.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0735746 Vali Loss: 0.0881314 Test Loss: 0.1003296\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732854\n",
      "\tspeed: 0.0505s/iter; left time: 975.5433s\n",
      "\titers: 200, epoch: 14 | loss: 0.0765176\n",
      "\tspeed: 0.0253s/iter; left time: 485.4839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 223 | Train Loss: 0.0733631 Vali Loss: 0.0880418 Test Loss: 0.1006267\n",
      "Validation loss decreased (0.088117 --> 0.088042).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0686045\n",
      "\tspeed: 0.0510s/iter; left time: 972.5719s\n",
      "\titers: 200, epoch: 15 | loss: 0.0738218\n",
      "\tspeed: 0.0249s/iter; left time: 472.6525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0731731 Vali Loss: 0.0877948 Test Loss: 0.1004807\n",
      "Validation loss decreased (0.088042 --> 0.087795).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0774363\n",
      "\tspeed: 0.0505s/iter; left time: 951.9306s\n",
      "\titers: 200, epoch: 16 | loss: 0.0685417\n",
      "\tspeed: 0.0250s/iter; left time: 468.1213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0729970 Vali Loss: 0.0878974 Test Loss: 0.1002158\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0694770\n",
      "\tspeed: 0.0493s/iter; left time: 917.9258s\n",
      "\titers: 200, epoch: 17 | loss: 0.0728208\n",
      "\tspeed: 0.0253s/iter; left time: 468.4760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0728009 Vali Loss: 0.0877508 Test Loss: 0.1001492\n",
      "Validation loss decreased (0.087795 --> 0.087751).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0753803\n",
      "\tspeed: 0.0506s/iter; left time: 932.2731s\n",
      "\titers: 200, epoch: 18 | loss: 0.0674711\n",
      "\tspeed: 0.0254s/iter; left time: 464.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 223 | Train Loss: 0.0726956 Vali Loss: 0.0878319 Test Loss: 0.1002021\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733524\n",
      "\tspeed: 0.0501s/iter; left time: 911.6387s\n",
      "\titers: 200, epoch: 19 | loss: 0.0708202\n",
      "\tspeed: 0.0253s/iter; left time: 457.4903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0725880 Vali Loss: 0.0878186 Test Loss: 0.1000890\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0762931\n",
      "\tspeed: 0.0511s/iter; left time: 917.6981s\n",
      "\titers: 200, epoch: 20 | loss: 0.0742078\n",
      "\tspeed: 0.0253s/iter; left time: 452.7912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0724748 Vali Loss: 0.0875500 Test Loss: 0.0999164\n",
      "Validation loss decreased (0.087751 --> 0.087550).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0688657\n",
      "\tspeed: 0.0510s/iter; left time: 904.9608s\n",
      "\titers: 200, epoch: 21 | loss: 0.0728711\n",
      "\tspeed: 0.0253s/iter; left time: 446.7633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 223 | Train Loss: 0.0723021 Vali Loss: 0.0877870 Test Loss: 0.1000556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0736826\n",
      "\tspeed: 0.0501s/iter; left time: 878.0198s\n",
      "\titers: 200, epoch: 22 | loss: 0.0708404\n",
      "\tspeed: 0.0253s/iter; left time: 440.6858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0722708 Vali Loss: 0.0878466 Test Loss: 0.1002947\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0716160\n",
      "\tspeed: 0.0499s/iter; left time: 862.5070s\n",
      "\titers: 200, epoch: 23 | loss: 0.0733281\n",
      "\tspeed: 0.0252s/iter; left time: 433.7357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0722087 Vali Loss: 0.0877250 Test Loss: 0.0998263\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0726692\n",
      "\tspeed: 0.0496s/iter; left time: 847.3922s\n",
      "\titers: 200, epoch: 24 | loss: 0.0717799\n",
      "\tspeed: 0.0254s/iter; left time: 431.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 223 | Train Loss: 0.0721054 Vali Loss: 0.0876443 Test Loss: 0.1000359\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0738992\n",
      "\tspeed: 0.0498s/iter; left time: 839.5298s\n",
      "\titers: 200, epoch: 25 | loss: 0.0750774\n",
      "\tspeed: 0.0253s/iter; left time: 423.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0720436 Vali Loss: 0.0876506 Test Loss: 0.1001287\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0770335\n",
      "\tspeed: 0.0497s/iter; left time: 826.9164s\n",
      "\titers: 200, epoch: 26 | loss: 0.0682387\n",
      "\tspeed: 0.0252s/iter; left time: 415.7719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0719946 Vali Loss: 0.0877581 Test Loss: 0.1002319\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0703107\n",
      "\tspeed: 0.0497s/iter; left time: 814.8929s\n",
      "\titers: 200, epoch: 27 | loss: 0.0738228\n",
      "\tspeed: 0.0253s/iter; left time: 411.9677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0719626 Vali Loss: 0.0878458 Test Loss: 0.1001381\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0668318\n",
      "\tspeed: 0.0503s/iter; left time: 814.4864s\n",
      "\titers: 200, epoch: 28 | loss: 0.0739143\n",
      "\tspeed: 0.0255s/iter; left time: 409.2462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 223 | Train Loss: 0.0718852 Vali Loss: 0.0876029 Test Loss: 0.1000922\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0680094\n",
      "\tspeed: 0.0497s/iter; left time: 793.8416s\n",
      "\titers: 200, epoch: 29 | loss: 0.0744305\n",
      "\tspeed: 0.0250s/iter; left time: 396.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0719436 Vali Loss: 0.0877404 Test Loss: 0.1001255\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0759910\n",
      "\tspeed: 0.0497s/iter; left time: 781.7658s\n",
      "\titers: 200, epoch: 30 | loss: 0.0703826\n",
      "\tspeed: 0.0253s/iter; left time: 395.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 223 | Train Loss: 0.0718248 Vali Loss: 0.0877080 Test Loss: 0.1000241\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_24_GB_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025234097614884377, rmse:0.1588524430990219, mae:0.09991640597581863, rse:0.5479958653450012\n",
      "Intermediate time for GB and pred_len 24: 00h:07m:37.98s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1394340\n",
      "\tspeed: 0.0453s/iter; left time: 1001.2559s\n",
      "\titers: 200, epoch: 1 | loss: 0.1290265\n",
      "\tspeed: 0.0253s/iter; left time: 555.7881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.03s\n",
      "Steps: 222 | Train Loss: 0.1366888 Vali Loss: 0.1331916 Test Loss: 0.1571194\n",
      "Validation loss decreased (inf --> 0.133192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1068254\n",
      "\tspeed: 0.0501s/iter; left time: 1096.9919s\n",
      "\titers: 200, epoch: 2 | loss: 0.1038789\n",
      "\tspeed: 0.0252s/iter; left time: 549.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1089743 Vali Loss: 0.1170851 Test Loss: 0.1377481\n",
      "Validation loss decreased (0.133192 --> 0.117085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039727\n",
      "\tspeed: 0.0500s/iter; left time: 1083.5320s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007207\n",
      "\tspeed: 0.0253s/iter; left time: 544.5012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.1035166 Vali Loss: 0.1159595 Test Loss: 0.1386739\n",
      "Validation loss decreased (0.117085 --> 0.115960).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1032024\n",
      "\tspeed: 0.0497s/iter; left time: 1065.7862s\n",
      "\titers: 200, epoch: 4 | loss: 0.1009170\n",
      "\tspeed: 0.0252s/iter; left time: 538.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.1019685 Vali Loss: 0.1150414 Test Loss: 0.1387783\n",
      "Validation loss decreased (0.115960 --> 0.115041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1023183\n",
      "\tspeed: 0.0523s/iter; left time: 1110.2566s\n",
      "\titers: 200, epoch: 5 | loss: 0.0971835\n",
      "\tspeed: 0.0257s/iter; left time: 541.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 222 | Train Loss: 0.1006222 Vali Loss: 0.1144552 Test Loss: 0.1380308\n",
      "Validation loss decreased (0.115041 --> 0.114455).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0979462\n",
      "\tspeed: 0.0506s/iter; left time: 1062.9952s\n",
      "\titers: 200, epoch: 6 | loss: 0.0962899\n",
      "\tspeed: 0.0254s/iter; left time: 530.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.0993785 Vali Loss: 0.1143939 Test Loss: 0.1384692\n",
      "Validation loss decreased (0.114455 --> 0.114394).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0957437\n",
      "\tspeed: 0.0512s/iter; left time: 1062.3679s\n",
      "\titers: 200, epoch: 7 | loss: 0.0956334\n",
      "\tspeed: 0.0256s/iter; left time: 528.5298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.0984068 Vali Loss: 0.1152558 Test Loss: 0.1409329\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0985388\n",
      "\tspeed: 0.0507s/iter; left time: 1041.9183s\n",
      "\titers: 200, epoch: 8 | loss: 0.0979370\n",
      "\tspeed: 0.0253s/iter; left time: 516.7270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 222 | Train Loss: 0.0974339 Vali Loss: 0.1146337 Test Loss: 0.1407919\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0960061\n",
      "\tspeed: 0.0503s/iter; left time: 1021.8452s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977183\n",
      "\tspeed: 0.0253s/iter; left time: 512.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0965533 Vali Loss: 0.1147367 Test Loss: 0.1410791\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983268\n",
      "\tspeed: 0.0498s/iter; left time: 1001.7614s\n",
      "\titers: 200, epoch: 10 | loss: 0.0971290\n",
      "\tspeed: 0.0253s/iter; left time: 506.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0957947 Vali Loss: 0.1152980 Test Loss: 0.1419808\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0965237\n",
      "\tspeed: 0.0502s/iter; left time: 997.8964s\n",
      "\titers: 200, epoch: 11 | loss: 0.0888941\n",
      "\tspeed: 0.0252s/iter; left time: 499.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.80s\n",
      "Steps: 222 | Train Loss: 0.0951090 Vali Loss: 0.1158843 Test Loss: 0.1428171\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0924156\n",
      "\tspeed: 0.0506s/iter; left time: 993.9725s\n",
      "\titers: 200, epoch: 12 | loss: 0.0951459\n",
      "\tspeed: 0.0252s/iter; left time: 493.7560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.0944358 Vali Loss: 0.1160919 Test Loss: 0.1423847\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0906801\n",
      "\tspeed: 0.0502s/iter; left time: 976.3992s\n",
      "\titers: 200, epoch: 13 | loss: 0.0945358\n",
      "\tspeed: 0.0253s/iter; left time: 489.7337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.85s\n",
      "Steps: 222 | Train Loss: 0.0939192 Vali Loss: 0.1160532 Test Loss: 0.1428135\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0922736\n",
      "\tspeed: 0.0501s/iter; left time: 962.7509s\n",
      "\titers: 200, epoch: 14 | loss: 0.1017823\n",
      "\tspeed: 0.0250s/iter; left time: 477.2029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 222 | Train Loss: 0.0934323 Vali Loss: 0.1166288 Test Loss: 0.1422593\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0974771\n",
      "\tspeed: 0.0501s/iter; left time: 952.0617s\n",
      "\titers: 200, epoch: 15 | loss: 0.0921112\n",
      "\tspeed: 0.0253s/iter; left time: 477.5541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.0928999 Vali Loss: 0.1167778 Test Loss: 0.1436719\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0920093\n",
      "\tspeed: 0.0510s/iter; left time: 958.0473s\n",
      "\titers: 200, epoch: 16 | loss: 0.0894551\n",
      "\tspeed: 0.0254s/iter; left time: 474.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.0925493 Vali Loss: 0.1169045 Test Loss: 0.1445190\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04119270667433739, rmse:0.20295986533164978, mae:0.13846930861473083, rse:0.7018635272979736\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1430690\n",
      "\tspeed: 0.0277s/iter; left time: 611.9711s\n",
      "\titers: 200, epoch: 1 | loss: 0.1275259\n",
      "\tspeed: 0.0253s/iter; left time: 557.0928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1375757 Vali Loss: 0.1335484 Test Loss: 0.1576532\n",
      "Validation loss decreased (inf --> 0.133548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1136771\n",
      "\tspeed: 0.0511s/iter; left time: 1118.4060s\n",
      "\titers: 200, epoch: 2 | loss: 0.1101739\n",
      "\tspeed: 0.0253s/iter; left time: 550.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1089530 Vali Loss: 0.1170144 Test Loss: 0.1385832\n",
      "Validation loss decreased (0.133548 --> 0.117014).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1007280\n",
      "\tspeed: 0.0519s/iter; left time: 1123.5449s\n",
      "\titers: 200, epoch: 3 | loss: 0.1076406\n",
      "\tspeed: 0.0253s/iter; left time: 545.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.1034623 Vali Loss: 0.1154502 Test Loss: 0.1380389\n",
      "Validation loss decreased (0.117014 --> 0.115450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1036936\n",
      "\tspeed: 0.0512s/iter; left time: 1097.0386s\n",
      "\titers: 200, epoch: 4 | loss: 0.1024783\n",
      "\tspeed: 0.0252s/iter; left time: 538.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.1020140 Vali Loss: 0.1151202 Test Loss: 0.1389594\n",
      "Validation loss decreased (0.115450 --> 0.115120).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0969818\n",
      "\tspeed: 0.0516s/iter; left time: 1095.4411s\n",
      "\titers: 200, epoch: 5 | loss: 0.0966104\n",
      "\tspeed: 0.0253s/iter; left time: 534.7440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1007545 Vali Loss: 0.1149426 Test Loss: 0.1381298\n",
      "Validation loss decreased (0.115120 --> 0.114943).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1006539\n",
      "\tspeed: 0.0531s/iter; left time: 1114.8611s\n",
      "\titers: 200, epoch: 6 | loss: 0.1000434\n",
      "\tspeed: 0.0253s/iter; left time: 528.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0995366 Vali Loss: 0.1148471 Test Loss: 0.1398015\n",
      "Validation loss decreased (0.114943 --> 0.114847).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0947145\n",
      "\tspeed: 0.0512s/iter; left time: 1063.8846s\n",
      "\titers: 200, epoch: 7 | loss: 0.0983384\n",
      "\tspeed: 0.0253s/iter; left time: 523.6688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0983988 Vali Loss: 0.1144975 Test Loss: 0.1389094\n",
      "Validation loss decreased (0.114847 --> 0.114497).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0982471\n",
      "\tspeed: 0.0521s/iter; left time: 1071.3099s\n",
      "\titers: 200, epoch: 8 | loss: 0.0984341\n",
      "\tspeed: 0.0253s/iter; left time: 516.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0973721 Vali Loss: 0.1153436 Test Loss: 0.1403963\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0977281\n",
      "\tspeed: 0.0516s/iter; left time: 1049.0329s\n",
      "\titers: 200, epoch: 9 | loss: 0.1021109\n",
      "\tspeed: 0.0254s/iter; left time: 514.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0964842 Vali Loss: 0.1152684 Test Loss: 0.1403659\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1011215\n",
      "\tspeed: 0.0522s/iter; left time: 1049.2459s\n",
      "\titers: 200, epoch: 10 | loss: 0.0951523\n",
      "\tspeed: 0.0254s/iter; left time: 509.0028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 222 | Train Loss: 0.0956798 Vali Loss: 0.1152389 Test Loss: 0.1411659\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0978804\n",
      "\tspeed: 0.0512s/iter; left time: 1018.8591s\n",
      "\titers: 200, epoch: 11 | loss: 0.0953086\n",
      "\tspeed: 0.0253s/iter; left time: 500.4367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0949506 Vali Loss: 0.1154193 Test Loss: 0.1404475\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0929117\n",
      "\tspeed: 0.0506s/iter; left time: 995.3684s\n",
      "\titers: 200, epoch: 12 | loss: 0.0936474\n",
      "\tspeed: 0.0255s/iter; left time: 497.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0942768 Vali Loss: 0.1156795 Test Loss: 0.1401807\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0894259\n",
      "\tspeed: 0.0518s/iter; left time: 1006.5478s\n",
      "\titers: 200, epoch: 13 | loss: 0.0967165\n",
      "\tspeed: 0.0254s/iter; left time: 491.2548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0936254 Vali Loss: 0.1155844 Test Loss: 0.1414489\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0955940\n",
      "\tspeed: 0.0523s/iter; left time: 1005.1129s\n",
      "\titers: 200, epoch: 14 | loss: 0.0979259\n",
      "\tspeed: 0.0253s/iter; left time: 483.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0930738 Vali Loss: 0.1156601 Test Loss: 0.1417124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0949226\n",
      "\tspeed: 0.0519s/iter; left time: 985.8470s\n",
      "\titers: 200, epoch: 15 | loss: 0.0942575\n",
      "\tspeed: 0.0255s/iter; left time: 482.1344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 222 | Train Loss: 0.0926891 Vali Loss: 0.1158257 Test Loss: 0.1421594\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0902436\n",
      "\tspeed: 0.0508s/iter; left time: 953.4994s\n",
      "\titers: 200, epoch: 16 | loss: 0.0915645\n",
      "\tspeed: 0.0253s/iter; left time: 472.3373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 222 | Train Loss: 0.0922145 Vali Loss: 0.1160959 Test Loss: 0.1423633\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0928457\n",
      "\tspeed: 0.0506s/iter; left time: 937.7163s\n",
      "\titers: 200, epoch: 17 | loss: 0.0961502\n",
      "\tspeed: 0.0253s/iter; left time: 466.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.0917279 Vali Loss: 0.1162622 Test Loss: 0.1419429\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_96_GB_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0415174700319767, rmse:0.2037583589553833, mae:0.13890935480594635, rse:0.7046248316764832\n",
      "Intermediate time for GB and pred_len 96: 00h:04m:22.64s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_512_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1374336\n",
      "\tspeed: 0.0464s/iter; left time: 1024.7686s\n",
      "\titers: 200, epoch: 1 | loss: 0.1251440\n",
      "\tspeed: 0.0254s/iter; left time: 559.5163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:06.10s\n",
      "Steps: 222 | Train Loss: 0.1389109 Vali Loss: 0.1349851 Test Loss: 0.1598008\n",
      "Validation loss decreased (inf --> 0.134985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122300\n",
      "\tspeed: 0.0507s/iter; left time: 1109.2660s\n",
      "\titers: 200, epoch: 2 | loss: 0.1079164\n",
      "\tspeed: 0.0255s/iter; left time: 554.4236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 222 | Train Loss: 0.1132026 Vali Loss: 0.1214197 Test Loss: 0.1451650\n",
      "Validation loss decreased (0.134985 --> 0.121420).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1036352\n",
      "\tspeed: 0.0514s/iter; left time: 1113.2177s\n",
      "\titers: 200, epoch: 3 | loss: 0.1043559\n",
      "\tspeed: 0.0255s/iter; left time: 549.1922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1080314 Vali Loss: 0.1201407 Test Loss: 0.1442623\n",
      "Validation loss decreased (0.121420 --> 0.120141).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1083568\n",
      "\tspeed: 0.0511s/iter; left time: 1094.2993s\n",
      "\titers: 200, epoch: 4 | loss: 0.1068884\n",
      "\tspeed: 0.0254s/iter; left time: 542.8628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.88s\n",
      "Steps: 222 | Train Loss: 0.1063734 Vali Loss: 0.1194321 Test Loss: 0.1463639\n",
      "Validation loss decreased (0.120141 --> 0.119432).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1059435\n",
      "\tspeed: 0.0520s/iter; left time: 1102.6808s\n",
      "\titers: 200, epoch: 5 | loss: 0.1046826\n",
      "\tspeed: 0.0255s/iter; left time: 537.3862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1048385 Vali Loss: 0.1198237 Test Loss: 0.1464768\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1037265\n",
      "\tspeed: 0.0517s/iter; left time: 1085.7939s\n",
      "\titers: 200, epoch: 6 | loss: 0.1038950\n",
      "\tspeed: 0.0257s/iter; left time: 536.3222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.1033754 Vali Loss: 0.1201003 Test Loss: 0.1470414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1040469\n",
      "\tspeed: 0.0518s/iter; left time: 1076.3714s\n",
      "\titers: 200, epoch: 7 | loss: 0.1053304\n",
      "\tspeed: 0.0256s/iter; left time: 529.2961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.1021183 Vali Loss: 0.1202404 Test Loss: 0.1469195\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1039958\n",
      "\tspeed: 0.0529s/iter; left time: 1086.5747s\n",
      "\titers: 200, epoch: 8 | loss: 0.1013930\n",
      "\tspeed: 0.0257s/iter; left time: 525.6122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.1009759 Vali Loss: 0.1207501 Test Loss: 0.1468556\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0994803\n",
      "\tspeed: 0.0531s/iter; left time: 1079.1375s\n",
      "\titers: 200, epoch: 9 | loss: 0.0979783\n",
      "\tspeed: 0.0256s/iter; left time: 517.3971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 222 | Train Loss: 0.0998242 Vali Loss: 0.1210882 Test Loss: 0.1469089\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0995152\n",
      "\tspeed: 0.0523s/iter; left time: 1051.0664s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934824\n",
      "\tspeed: 0.0256s/iter; left time: 511.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.97s\n",
      "Steps: 222 | Train Loss: 0.0988383 Vali Loss: 0.1216525 Test Loss: 0.1474309\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0981456\n",
      "\tspeed: 0.0533s/iter; left time: 1059.6871s\n",
      "\titers: 200, epoch: 11 | loss: 0.1016490\n",
      "\tspeed: 0.0256s/iter; left time: 506.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 222 | Train Loss: 0.0979763 Vali Loss: 0.1217374 Test Loss: 0.1472979\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0996736\n",
      "\tspeed: 0.0522s/iter; left time: 1025.7067s\n",
      "\titers: 200, epoch: 12 | loss: 0.0996886\n",
      "\tspeed: 0.0257s/iter; left time: 502.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 222 | Train Loss: 0.0972306 Vali Loss: 0.1215846 Test Loss: 0.1476726\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0932190\n",
      "\tspeed: 0.0517s/iter; left time: 1004.4353s\n",
      "\titers: 200, epoch: 13 | loss: 0.0925781\n",
      "\tspeed: 0.0257s/iter; left time: 497.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 222 | Train Loss: 0.0965848 Vali Loss: 0.1225467 Test Loss: 0.1480687\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0947959\n",
      "\tspeed: 0.0517s/iter; left time: 994.1211s\n",
      "\titers: 200, epoch: 14 | loss: 0.0977212\n",
      "\tspeed: 0.0256s/iter; left time: 489.5313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.0959841 Vali Loss: 0.1223132 Test Loss: 0.1484276\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04480735957622528, rmse:0.21167749166488647, mae:0.14636394381523132, rse:0.7339162826538086\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1396508\n",
      "\tspeed: 0.0281s/iter; left time: 620.0299s\n",
      "\titers: 200, epoch: 1 | loss: 0.1307749\n",
      "\tspeed: 0.0255s/iter; left time: 561.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 222 | Train Loss: 0.1400538 Vali Loss: 0.1358964 Test Loss: 0.1608582\n",
      "Validation loss decreased (inf --> 0.135896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1127824\n",
      "\tspeed: 0.0523s/iter; left time: 1144.3960s\n",
      "\titers: 200, epoch: 2 | loss: 0.1061968\n",
      "\tspeed: 0.0255s/iter; left time: 554.8333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1132773 Vali Loss: 0.1212811 Test Loss: 0.1449151\n",
      "Validation loss decreased (0.135896 --> 0.121281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1071511\n",
      "\tspeed: 0.0556s/iter; left time: 1204.6563s\n",
      "\titers: 200, epoch: 3 | loss: 0.1027253\n",
      "\tspeed: 0.0255s/iter; left time: 549.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1080624 Vali Loss: 0.1203866 Test Loss: 0.1448053\n",
      "Validation loss decreased (0.121281 --> 0.120387).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1035581\n",
      "\tspeed: 0.0521s/iter; left time: 1117.2976s\n",
      "\titers: 200, epoch: 4 | loss: 0.1055970\n",
      "\tspeed: 0.0255s/iter; left time: 544.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1063175 Vali Loss: 0.1201248 Test Loss: 0.1456940\n",
      "Validation loss decreased (0.120387 --> 0.120125).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1069989\n",
      "\tspeed: 0.0519s/iter; left time: 1101.1076s\n",
      "\titers: 200, epoch: 5 | loss: 0.1046950\n",
      "\tspeed: 0.0255s/iter; left time: 539.2159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 222 | Train Loss: 0.1047623 Vali Loss: 0.1203996 Test Loss: 0.1467559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1008141\n",
      "\tspeed: 0.0517s/iter; left time: 1084.7960s\n",
      "\titers: 200, epoch: 6 | loss: 0.1024363\n",
      "\tspeed: 0.0255s/iter; left time: 532.4825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1033632 Vali Loss: 0.1209063 Test Loss: 0.1470580\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028267\n",
      "\tspeed: 0.0521s/iter; left time: 1081.7134s\n",
      "\titers: 200, epoch: 7 | loss: 0.1020889\n",
      "\tspeed: 0.0255s/iter; left time: 527.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 222 | Train Loss: 0.1019508 Vali Loss: 0.1216134 Test Loss: 0.1470931\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0988903\n",
      "\tspeed: 0.0512s/iter; left time: 1051.3945s\n",
      "\titers: 200, epoch: 8 | loss: 0.1025722\n",
      "\tspeed: 0.0255s/iter; left time: 521.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.1007434 Vali Loss: 0.1214628 Test Loss: 0.1464817\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0973133\n",
      "\tspeed: 0.0516s/iter; left time: 1049.7674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0978820\n",
      "\tspeed: 0.0255s/iter; left time: 515.8546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0995585 Vali Loss: 0.1221120 Test Loss: 0.1456643\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0989086\n",
      "\tspeed: 0.0515s/iter; left time: 1035.1670s\n",
      "\titers: 200, epoch: 10 | loss: 0.0941991\n",
      "\tspeed: 0.0255s/iter; left time: 510.4202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0985036 Vali Loss: 0.1223060 Test Loss: 0.1466020\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0981043\n",
      "\tspeed: 0.0514s/iter; left time: 1021.7070s\n",
      "\titers: 200, epoch: 11 | loss: 0.0956146\n",
      "\tspeed: 0.0255s/iter; left time: 504.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 222 | Train Loss: 0.0975236 Vali Loss: 0.1228690 Test Loss: 0.1478358\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0967339\n",
      "\tspeed: 0.0512s/iter; left time: 1006.0039s\n",
      "\titers: 200, epoch: 12 | loss: 0.0983998\n",
      "\tspeed: 0.0255s/iter; left time: 498.3879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0967355 Vali Loss: 0.1234979 Test Loss: 0.1485324\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0949580\n",
      "\tspeed: 0.0511s/iter; left time: 993.1264s\n",
      "\titers: 200, epoch: 13 | loss: 0.0979866\n",
      "\tspeed: 0.0255s/iter; left time: 492.7208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0960046 Vali Loss: 0.1233077 Test Loss: 0.1484443\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0979299\n",
      "\tspeed: 0.0512s/iter; left time: 984.7332s\n",
      "\titers: 200, epoch: 14 | loss: 0.0952646\n",
      "\tspeed: 0.0255s/iter; left time: 487.5131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 222 | Train Loss: 0.0954114 Vali Loss: 0.1239719 Test Loss: 0.1494929\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_512_168_GB_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043718528002500534, rmse:0.2090897560119629, mae:0.14569395780563354, rse:0.7249442338943481\n",
      "Intermediate time for GB and pred_len 168: 00h:03m:49.02s\n",
      "Intermediate time for GB: 00h:15m:49.65s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1329129\n",
      "\tspeed: 0.0386s/iter; left time: 856.1197s\n",
      "\titers: 200, epoch: 1 | loss: 0.1140730\n",
      "\tspeed: 0.0159s/iter; left time: 352.1040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 223 | Train Loss: 0.1388291 Vali Loss: 0.1031739 Test Loss: 0.1167768\n",
      "Validation loss decreased (inf --> 0.103174).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0760406\n",
      "\tspeed: 0.0361s/iter; left time: 792.3856s\n",
      "\titers: 200, epoch: 2 | loss: 0.0709279\n",
      "\tspeed: 0.0157s/iter; left time: 344.5583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0782182 Vali Loss: 0.0637507 Test Loss: 0.0713524\n",
      "Validation loss decreased (0.103174 --> 0.063751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0656441\n",
      "\tspeed: 0.0346s/iter; left time: 751.6355s\n",
      "\titers: 200, epoch: 3 | loss: 0.0637093\n",
      "\tspeed: 0.0157s/iter; left time: 339.2093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0659534 Vali Loss: 0.0600094 Test Loss: 0.0667960\n",
      "Validation loss decreased (0.063751 --> 0.060009).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0627606\n",
      "\tspeed: 0.0338s/iter; left time: 728.0941s\n",
      "\titers: 200, epoch: 4 | loss: 0.0611268\n",
      "\tspeed: 0.0156s/iter; left time: 335.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0627434 Vali Loss: 0.0586569 Test Loss: 0.0652340\n",
      "Validation loss decreased (0.060009 --> 0.058657).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0597999\n",
      "\tspeed: 0.0341s/iter; left time: 726.8197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0628164\n",
      "\tspeed: 0.0157s/iter; left time: 332.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0608250 Vali Loss: 0.0571451 Test Loss: 0.0638910\n",
      "Validation loss decreased (0.058657 --> 0.057145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0588184\n",
      "\tspeed: 0.0345s/iter; left time: 727.3789s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603673\n",
      "\tspeed: 0.0157s/iter; left time: 328.7543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0595142 Vali Loss: 0.0563593 Test Loss: 0.0631915\n",
      "Validation loss decreased (0.057145 --> 0.056359).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0571423\n",
      "\tspeed: 0.0344s/iter; left time: 718.5314s\n",
      "\titers: 200, epoch: 7 | loss: 0.0634167\n",
      "\tspeed: 0.0157s/iter; left time: 325.1303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0586404 Vali Loss: 0.0558892 Test Loss: 0.0628020\n",
      "Validation loss decreased (0.056359 --> 0.055889).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0587911\n",
      "\tspeed: 0.0342s/iter; left time: 706.3646s\n",
      "\titers: 200, epoch: 8 | loss: 0.0589734\n",
      "\tspeed: 0.0158s/iter; left time: 324.1934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0579511 Vali Loss: 0.0554596 Test Loss: 0.0625661\n",
      "Validation loss decreased (0.055889 --> 0.055460).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0562014\n",
      "\tspeed: 0.0344s/iter; left time: 701.8674s\n",
      "\titers: 200, epoch: 9 | loss: 0.0573063\n",
      "\tspeed: 0.0156s/iter; left time: 317.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0573422 Vali Loss: 0.0551464 Test Loss: 0.0621672\n",
      "Validation loss decreased (0.055460 --> 0.055146).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0563526\n",
      "\tspeed: 0.0343s/iter; left time: 692.1398s\n",
      "\titers: 200, epoch: 10 | loss: 0.0558840\n",
      "\tspeed: 0.0157s/iter; left time: 314.5322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0568031 Vali Loss: 0.0549321 Test Loss: 0.0619139\n",
      "Validation loss decreased (0.055146 --> 0.054932).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561171\n",
      "\tspeed: 0.0341s/iter; left time: 681.0513s\n",
      "\titers: 200, epoch: 11 | loss: 0.0546085\n",
      "\tspeed: 0.0157s/iter; left time: 311.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0563940 Vali Loss: 0.0546079 Test Loss: 0.0616910\n",
      "Validation loss decreased (0.054932 --> 0.054608).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0553174\n",
      "\tspeed: 0.0342s/iter; left time: 675.4763s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555087\n",
      "\tspeed: 0.0157s/iter; left time: 307.6573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0560539 Vali Loss: 0.0541861 Test Loss: 0.0612447\n",
      "Validation loss decreased (0.054608 --> 0.054186).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0536061\n",
      "\tspeed: 0.0352s/iter; left time: 686.8177s\n",
      "\titers: 200, epoch: 13 | loss: 0.0512201\n",
      "\tspeed: 0.0159s/iter; left time: 308.1545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0556423 Vali Loss: 0.0539564 Test Loss: 0.0611355\n",
      "Validation loss decreased (0.054186 --> 0.053956).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0582338\n",
      "\tspeed: 0.0348s/iter; left time: 671.2097s\n",
      "\titers: 200, epoch: 14 | loss: 0.0572633\n",
      "\tspeed: 0.0156s/iter; left time: 300.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0554266 Vali Loss: 0.0539151 Test Loss: 0.0609410\n",
      "Validation loss decreased (0.053956 --> 0.053915).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0551506\n",
      "\tspeed: 0.0347s/iter; left time: 662.6052s\n",
      "\titers: 200, epoch: 15 | loss: 0.0490729\n",
      "\tspeed: 0.0156s/iter; left time: 296.1321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0551881 Vali Loss: 0.0538702 Test Loss: 0.0607723\n",
      "Validation loss decreased (0.053915 --> 0.053870).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0550896\n",
      "\tspeed: 0.0342s/iter; left time: 644.2733s\n",
      "\titers: 200, epoch: 16 | loss: 0.0553330\n",
      "\tspeed: 0.0159s/iter; left time: 297.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0549647 Vali Loss: 0.0537893 Test Loss: 0.0606530\n",
      "Validation loss decreased (0.053870 --> 0.053789).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0518273\n",
      "\tspeed: 0.0355s/iter; left time: 660.5734s\n",
      "\titers: 200, epoch: 17 | loss: 0.0541851\n",
      "\tspeed: 0.0156s/iter; left time: 289.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0548265 Vali Loss: 0.0535404 Test Loss: 0.0606558\n",
      "Validation loss decreased (0.053789 --> 0.053540).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0561151\n",
      "\tspeed: 0.0342s/iter; left time: 629.1472s\n",
      "\titers: 200, epoch: 18 | loss: 0.0536424\n",
      "\tspeed: 0.0158s/iter; left time: 289.2172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0545902 Vali Loss: 0.0535757 Test Loss: 0.0607545\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0576345\n",
      "\tspeed: 0.0349s/iter; left time: 634.2062s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547254\n",
      "\tspeed: 0.0157s/iter; left time: 283.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0545236 Vali Loss: 0.0534763 Test Loss: 0.0604636\n",
      "Validation loss decreased (0.053540 --> 0.053476).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0522795\n",
      "\tspeed: 0.0352s/iter; left time: 631.5587s\n",
      "\titers: 200, epoch: 20 | loss: 0.0537029\n",
      "\tspeed: 0.0158s/iter; left time: 281.8349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0544254 Vali Loss: 0.0533704 Test Loss: 0.0604521\n",
      "Validation loss decreased (0.053476 --> 0.053370).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0568015\n",
      "\tspeed: 0.0348s/iter; left time: 617.2793s\n",
      "\titers: 200, epoch: 21 | loss: 0.0540952\n",
      "\tspeed: 0.0157s/iter; left time: 277.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0542280 Vali Loss: 0.0533390 Test Loss: 0.0604639\n",
      "Validation loss decreased (0.053370 --> 0.053339).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0557625\n",
      "\tspeed: 0.0346s/iter; left time: 606.7391s\n",
      "\titers: 200, epoch: 22 | loss: 0.0572797\n",
      "\tspeed: 0.0157s/iter; left time: 273.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0541607 Vali Loss: 0.0531715 Test Loss: 0.0602939\n",
      "Validation loss decreased (0.053339 --> 0.053171).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0539247\n",
      "\tspeed: 0.0350s/iter; left time: 605.2073s\n",
      "\titers: 200, epoch: 23 | loss: 0.0530932\n",
      "\tspeed: 0.0156s/iter; left time: 268.9413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0540009 Vali Loss: 0.0531151 Test Loss: 0.0603079\n",
      "Validation loss decreased (0.053171 --> 0.053115).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0546650\n",
      "\tspeed: 0.0350s/iter; left time: 597.8093s\n",
      "\titers: 200, epoch: 24 | loss: 0.0528670\n",
      "\tspeed: 0.0158s/iter; left time: 268.6958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0539860 Vali Loss: 0.0530908 Test Loss: 0.0602066\n",
      "Validation loss decreased (0.053115 --> 0.053091).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0552615\n",
      "\tspeed: 0.0348s/iter; left time: 586.8733s\n",
      "\titers: 200, epoch: 25 | loss: 0.0521157\n",
      "\tspeed: 0.0157s/iter; left time: 262.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0538393 Vali Loss: 0.0531449 Test Loss: 0.0602618\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0532421\n",
      "\tspeed: 0.0346s/iter; left time: 575.1477s\n",
      "\titers: 200, epoch: 26 | loss: 0.0526556\n",
      "\tspeed: 0.0158s/iter; left time: 261.7941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0537998 Vali Loss: 0.0530610 Test Loss: 0.0602070\n",
      "Validation loss decreased (0.053091 --> 0.053061).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0526167\n",
      "\tspeed: 0.0350s/iter; left time: 574.6943s\n",
      "\titers: 200, epoch: 27 | loss: 0.0537283\n",
      "\tspeed: 0.0156s/iter; left time: 254.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0537199 Vali Loss: 0.0530816 Test Loss: 0.0602919\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0532675\n",
      "\tspeed: 0.0338s/iter; left time: 546.6604s\n",
      "\titers: 200, epoch: 28 | loss: 0.0559333\n",
      "\tspeed: 0.0158s/iter; left time: 254.3834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0536376 Vali Loss: 0.0529987 Test Loss: 0.0601239\n",
      "Validation loss decreased (0.053061 --> 0.052999).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0531704\n",
      "\tspeed: 0.0349s/iter; left time: 556.4606s\n",
      "\titers: 200, epoch: 29 | loss: 0.0544962\n",
      "\tspeed: 0.0156s/iter; left time: 247.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0536452 Vali Loss: 0.0529070 Test Loss: 0.0600837\n",
      "Validation loss decreased (0.052999 --> 0.052907).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0560164\n",
      "\tspeed: 0.0341s/iter; left time: 537.0657s\n",
      "\titers: 200, epoch: 30 | loss: 0.0548248\n",
      "\tspeed: 0.0158s/iter; left time: 246.2597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0535822 Vali Loss: 0.0529105 Test Loss: 0.0600305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0554323\n",
      "\tspeed: 0.0341s/iter; left time: 529.4402s\n",
      "\titers: 200, epoch: 31 | loss: 0.0533037\n",
      "\tspeed: 0.0157s/iter; left time: 241.3758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0535717 Vali Loss: 0.0528396 Test Loss: 0.0600280\n",
      "Validation loss decreased (0.052907 --> 0.052840).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0501680\n",
      "\tspeed: 0.0347s/iter; left time: 531.1910s\n",
      "\titers: 200, epoch: 32 | loss: 0.0541464\n",
      "\tspeed: 0.0157s/iter; left time: 238.5651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0535378 Vali Loss: 0.0528682 Test Loss: 0.0599837\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0534413\n",
      "\tspeed: 0.0340s/iter; left time: 512.4142s\n",
      "\titers: 200, epoch: 33 | loss: 0.0573865\n",
      "\tspeed: 0.0157s/iter; left time: 235.0796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0535355 Vali Loss: 0.0529223 Test Loss: 0.0599426\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0541659\n",
      "\tspeed: 0.0341s/iter; left time: 505.9514s\n",
      "\titers: 200, epoch: 34 | loss: 0.0524720\n",
      "\tspeed: 0.0157s/iter; left time: 231.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0535342 Vali Loss: 0.0529159 Test Loss: 0.0600252\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572794\n",
      "\tspeed: 0.0335s/iter; left time: 489.5618s\n",
      "\titers: 200, epoch: 35 | loss: 0.0539988\n",
      "\tspeed: 0.0157s/iter; left time: 227.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0534211 Vali Loss: 0.0528558 Test Loss: 0.0599309\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0542360\n",
      "\tspeed: 0.0342s/iter; left time: 491.9979s\n",
      "\titers: 200, epoch: 36 | loss: 0.0543825\n",
      "\tspeed: 0.0159s/iter; left time: 227.7196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0534362 Vali Loss: 0.0527856 Test Loss: 0.0599428\n",
      "Validation loss decreased (0.052840 --> 0.052786).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0533227\n",
      "\tspeed: 0.0349s/iter; left time: 494.7699s\n",
      "\titers: 200, epoch: 37 | loss: 0.0557657\n",
      "\tspeed: 0.0159s/iter; left time: 223.4360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0534365 Vali Loss: 0.0528243 Test Loss: 0.0600305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0498835\n",
      "\tspeed: 0.0348s/iter; left time: 485.2727s\n",
      "\titers: 200, epoch: 38 | loss: 0.0568389\n",
      "\tspeed: 0.0159s/iter; left time: 220.1208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0533594 Vali Loss: 0.0527874 Test Loss: 0.0599263\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0564888\n",
      "\tspeed: 0.0339s/iter; left time: 465.9185s\n",
      "\titers: 200, epoch: 39 | loss: 0.0550414\n",
      "\tspeed: 0.0156s/iter; left time: 213.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0533975 Vali Loss: 0.0528350 Test Loss: 0.0599182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0584605\n",
      "\tspeed: 0.0345s/iter; left time: 466.0402s\n",
      "\titers: 200, epoch: 40 | loss: 0.0531241\n",
      "\tspeed: 0.0157s/iter; left time: 209.9590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0533569 Vali Loss: 0.0527965 Test Loss: 0.0599171\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0512958\n",
      "\tspeed: 0.0349s/iter; left time: 463.4722s\n",
      "\titers: 200, epoch: 41 | loss: 0.0537981\n",
      "\tspeed: 0.0159s/iter; left time: 209.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0533515 Vali Loss: 0.0528236 Test Loss: 0.0599311\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0544218\n",
      "\tspeed: 0.0348s/iter; left time: 454.5705s\n",
      "\titers: 200, epoch: 42 | loss: 0.0513351\n",
      "\tspeed: 0.0157s/iter; left time: 203.3838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0533229 Vali Loss: 0.0527975 Test Loss: 0.0599152\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0541592\n",
      "\tspeed: 0.0348s/iter; left time: 446.8337s\n",
      "\titers: 200, epoch: 43 | loss: 0.0536271\n",
      "\tspeed: 0.0157s/iter; left time: 200.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0533137 Vali Loss: 0.0528115 Test Loss: 0.0599268\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0510992\n",
      "\tspeed: 0.0337s/iter; left time: 425.0769s\n",
      "\titers: 200, epoch: 44 | loss: 0.0535229\n",
      "\tspeed: 0.0157s/iter; left time: 196.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0533160 Vali Loss: 0.0527789 Test Loss: 0.0599260\n",
      "Validation loss decreased (0.052786 --> 0.052779).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0554727\n",
      "\tspeed: 0.0339s/iter; left time: 419.8520s\n",
      "\titers: 200, epoch: 45 | loss: 0.0590581\n",
      "\tspeed: 0.0157s/iter; left time: 192.3757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0532693 Vali Loss: 0.0527663 Test Loss: 0.0598969\n",
      "Validation loss decreased (0.052779 --> 0.052766).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0542788\n",
      "\tspeed: 0.0341s/iter; left time: 415.2516s\n",
      "\titers: 200, epoch: 46 | loss: 0.0510488\n",
      "\tspeed: 0.0157s/iter; left time: 189.5968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0533092 Vali Loss: 0.0527689 Test Loss: 0.0598986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0569829\n",
      "\tspeed: 0.0339s/iter; left time: 405.3267s\n",
      "\titers: 200, epoch: 47 | loss: 0.0538657\n",
      "\tspeed: 0.0157s/iter; left time: 185.4840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0532299 Vali Loss: 0.0527729 Test Loss: 0.0599283\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0518508\n",
      "\tspeed: 0.0337s/iter; left time: 394.8696s\n",
      "\titers: 200, epoch: 48 | loss: 0.0523402\n",
      "\tspeed: 0.0158s/iter; left time: 184.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0532980 Vali Loss: 0.0527913 Test Loss: 0.0599101\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0554262\n",
      "\tspeed: 0.0338s/iter; left time: 388.5312s\n",
      "\titers: 200, epoch: 49 | loss: 0.0535938\n",
      "\tspeed: 0.0157s/iter; left time: 178.5224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0532604 Vali Loss: 0.0528364 Test Loss: 0.0599107\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0551420\n",
      "\tspeed: 0.0348s/iter; left time: 392.4079s\n",
      "\titers: 200, epoch: 50 | loss: 0.0547235\n",
      "\tspeed: 0.0157s/iter; left time: 175.1718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0532606 Vali Loss: 0.0527633 Test Loss: 0.0598679\n",
      "Validation loss decreased (0.052766 --> 0.052763).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0509627\n",
      "\tspeed: 0.0337s/iter; left time: 372.2067s\n",
      "\titers: 200, epoch: 51 | loss: 0.0502183\n",
      "\tspeed: 0.0157s/iter; left time: 171.8105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0532658 Vali Loss: 0.0527999 Test Loss: 0.0599409\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0514866\n",
      "\tspeed: 0.0341s/iter; left time: 369.3851s\n",
      "\titers: 200, epoch: 52 | loss: 0.0525713\n",
      "\tspeed: 0.0158s/iter; left time: 169.6616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0532414 Vali Loss: 0.0527631 Test Loss: 0.0598883\n",
      "Validation loss decreased (0.052763 --> 0.052763).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0519205\n",
      "\tspeed: 0.0349s/iter; left time: 369.6916s\n",
      "\titers: 200, epoch: 53 | loss: 0.0510750\n",
      "\tspeed: 0.0159s/iter; left time: 167.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0532204 Vali Loss: 0.0527729 Test Loss: 0.0598521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0533466\n",
      "\tspeed: 0.0340s/iter; left time: 352.8475s\n",
      "\titers: 200, epoch: 54 | loss: 0.0526112\n",
      "\tspeed: 0.0157s/iter; left time: 161.8187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0532364 Vali Loss: 0.0527110 Test Loss: 0.0598682\n",
      "Validation loss decreased (0.052763 --> 0.052711).  Saving model ...\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0524288\n",
      "\tspeed: 0.0354s/iter; left time: 359.3468s\n",
      "\titers: 200, epoch: 55 | loss: 0.0535417\n",
      "\tspeed: 0.0159s/iter; left time: 159.7683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0532377 Vali Loss: 0.0527158 Test Loss: 0.0598616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0546501\n",
      "\tspeed: 0.0352s/iter; left time: 349.7409s\n",
      "\titers: 200, epoch: 56 | loss: 0.0530430\n",
      "\tspeed: 0.0159s/iter; left time: 156.5648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0532673 Vali Loss: 0.0527476 Test Loss: 0.0599032\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0515294\n",
      "\tspeed: 0.0340s/iter; left time: 330.4523s\n",
      "\titers: 200, epoch: 57 | loss: 0.0518301\n",
      "\tspeed: 0.0157s/iter; left time: 150.9372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0532686 Vali Loss: 0.0527835 Test Loss: 0.0598942\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0544063\n",
      "\tspeed: 0.0352s/iter; left time: 334.0520s\n",
      "\titers: 200, epoch: 58 | loss: 0.0550527\n",
      "\tspeed: 0.0157s/iter; left time: 147.1011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0532884 Vali Loss: 0.0527583 Test Loss: 0.0598403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0532435\n",
      "\tspeed: 0.0342s/iter; left time: 316.8564s\n",
      "\titers: 200, epoch: 59 | loss: 0.0506730\n",
      "\tspeed: 0.0156s/iter; left time: 143.3689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0532472 Vali Loss: 0.0527307 Test Loss: 0.0598696\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0551703\n",
      "\tspeed: 0.0340s/iter; left time: 307.1385s\n",
      "\titers: 200, epoch: 60 | loss: 0.0516307\n",
      "\tspeed: 0.0156s/iter; left time: 139.5237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.0532293 Vali Loss: 0.0527420 Test Loss: 0.0598754\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0528135\n",
      "\tspeed: 0.0363s/iter; left time: 320.2780s\n",
      "\titers: 200, epoch: 61 | loss: 0.0507391\n",
      "\tspeed: 0.0157s/iter; left time: 136.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0532160 Vali Loss: 0.0527358 Test Loss: 0.0598852\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0534176\n",
      "\tspeed: 0.0361s/iter; left time: 310.6124s\n",
      "\titers: 200, epoch: 62 | loss: 0.0554196\n",
      "\tspeed: 0.0162s/iter; left time: 137.6047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0532175 Vali Loss: 0.0527649 Test Loss: 0.0598998\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0564644\n",
      "\tspeed: 0.0358s/iter; left time: 300.1855s\n",
      "\titers: 200, epoch: 63 | loss: 0.0529435\n",
      "\tspeed: 0.0159s/iter; left time: 131.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0531984 Vali Loss: 0.0526922 Test Loss: 0.0598829\n",
      "Validation loss decreased (0.052711 --> 0.052692).  Saving model ...\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0525410\n",
      "\tspeed: 0.0347s/iter; left time: 283.2132s\n",
      "\titers: 200, epoch: 64 | loss: 0.0489705\n",
      "\tspeed: 0.0156s/iter; left time: 125.7513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0532384 Vali Loss: 0.0526983 Test Loss: 0.0598414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0493640\n",
      "\tspeed: 0.0337s/iter; left time: 266.8474s\n",
      "\titers: 200, epoch: 65 | loss: 0.0519918\n",
      "\tspeed: 0.0157s/iter; left time: 122.5361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0532434 Vali Loss: 0.0526632 Test Loss: 0.0598366\n",
      "Validation loss decreased (0.052692 --> 0.052663).  Saving model ...\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0546427\n",
      "\tspeed: 0.0344s/iter; left time: 264.7357s\n",
      "\titers: 200, epoch: 66 | loss: 0.0539316\n",
      "\tspeed: 0.0159s/iter; left time: 120.5559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0532743 Vali Loss: 0.0527569 Test Loss: 0.0598504\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0507975\n",
      "\tspeed: 0.0343s/iter; left time: 256.6103s\n",
      "\titers: 200, epoch: 67 | loss: 0.0515427\n",
      "\tspeed: 0.0159s/iter; left time: 117.4389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0532349 Vali Loss: 0.0527584 Test Loss: 0.0598787\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0497267\n",
      "\tspeed: 0.0352s/iter; left time: 255.7231s\n",
      "\titers: 200, epoch: 68 | loss: 0.0487397\n",
      "\tspeed: 0.0157s/iter; left time: 112.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0532526 Vali Loss: 0.0527889 Test Loss: 0.0598642\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0567136\n",
      "\tspeed: 0.0343s/iter; left time: 241.1610s\n",
      "\titers: 200, epoch: 69 | loss: 0.0533746\n",
      "\tspeed: 0.0158s/iter; left time: 109.6291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0532380 Vali Loss: 0.0527150 Test Loss: 0.0598760\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0545710\n",
      "\tspeed: 0.0343s/iter; left time: 233.5843s\n",
      "\titers: 200, epoch: 70 | loss: 0.0528616\n",
      "\tspeed: 0.0159s/iter; left time: 106.5839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0532030 Vali Loss: 0.0526979 Test Loss: 0.0598560\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0518418\n",
      "\tspeed: 0.0354s/iter; left time: 233.0940s\n",
      "\titers: 200, epoch: 71 | loss: 0.0526090\n",
      "\tspeed: 0.0161s/iter; left time: 104.3250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0532116 Vali Loss: 0.0527602 Test Loss: 0.0598751\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0519524\n",
      "\tspeed: 0.0352s/iter; left time: 224.3890s\n",
      "\titers: 200, epoch: 72 | loss: 0.0523574\n",
      "\tspeed: 0.0158s/iter; left time: 99.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0532906 Vali Loss: 0.0527295 Test Loss: 0.0598628\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0518238\n",
      "\tspeed: 0.0345s/iter; left time: 211.7797s\n",
      "\titers: 200, epoch: 73 | loss: 0.0515795\n",
      "\tspeed: 0.0158s/iter; left time: 95.7268s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0532802 Vali Loss: 0.0527398 Test Loss: 0.0598585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0503394\n",
      "\tspeed: 0.0346s/iter; left time: 205.1673s\n",
      "\titers: 200, epoch: 74 | loss: 0.0543157\n",
      "\tspeed: 0.0157s/iter; left time: 91.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0532771 Vali Loss: 0.0527615 Test Loss: 0.0598402\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0579608\n",
      "\tspeed: 0.0340s/iter; left time: 193.9189s\n",
      "\titers: 200, epoch: 75 | loss: 0.0514695\n",
      "\tspeed: 0.0157s/iter; left time: 87.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0532435 Vali Loss: 0.0528124 Test Loss: 0.0598727\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.00981216412037611, rmse:0.09905637055635452, mae:0.059836581349372864, rse:0.2915109097957611\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1466417\n",
      "\tspeed: 0.0178s/iter; left time: 394.5764s\n",
      "\titers: 200, epoch: 1 | loss: 0.1180566\n",
      "\tspeed: 0.0157s/iter; left time: 346.8940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.1441261 Vali Loss: 0.1056981 Test Loss: 0.1193211\n",
      "Validation loss decreased (inf --> 0.105698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0758713\n",
      "\tspeed: 0.0341s/iter; left time: 750.0193s\n",
      "\titers: 200, epoch: 2 | loss: 0.0706378\n",
      "\tspeed: 0.0158s/iter; left time: 345.8670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0783395 Vali Loss: 0.0629406 Test Loss: 0.0706034\n",
      "Validation loss decreased (0.105698 --> 0.062941).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0638876\n",
      "\tspeed: 0.0344s/iter; left time: 747.4593s\n",
      "\titers: 200, epoch: 3 | loss: 0.0640308\n",
      "\tspeed: 0.0156s/iter; left time: 338.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0658042 Vali Loss: 0.0598624 Test Loss: 0.0668053\n",
      "Validation loss decreased (0.062941 --> 0.059862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657810\n",
      "\tspeed: 0.0347s/iter; left time: 746.7612s\n",
      "\titers: 200, epoch: 4 | loss: 0.0655616\n",
      "\tspeed: 0.0158s/iter; left time: 339.0581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0625775 Vali Loss: 0.0585873 Test Loss: 0.0653232\n",
      "Validation loss decreased (0.059862 --> 0.058587).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0628328\n",
      "\tspeed: 0.0348s/iter; left time: 742.4377s\n",
      "\titers: 200, epoch: 5 | loss: 0.0600066\n",
      "\tspeed: 0.0156s/iter; left time: 331.5336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0607326 Vali Loss: 0.0572481 Test Loss: 0.0642461\n",
      "Validation loss decreased (0.058587 --> 0.057248).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0594159\n",
      "\tspeed: 0.0352s/iter; left time: 742.1466s\n",
      "\titers: 200, epoch: 6 | loss: 0.0622299\n",
      "\tspeed: 0.0157s/iter; left time: 328.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0595198 Vali Loss: 0.0565737 Test Loss: 0.0636952\n",
      "Validation loss decreased (0.057248 --> 0.056574).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0585973\n",
      "\tspeed: 0.0346s/iter; left time: 721.0837s\n",
      "\titers: 200, epoch: 7 | loss: 0.0575892\n",
      "\tspeed: 0.0157s/iter; left time: 325.1193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0586035 Vali Loss: 0.0561017 Test Loss: 0.0629540\n",
      "Validation loss decreased (0.056574 --> 0.056102).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0556866\n",
      "\tspeed: 0.0341s/iter; left time: 703.4211s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560880\n",
      "\tspeed: 0.0157s/iter; left time: 322.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0578915 Vali Loss: 0.0554318 Test Loss: 0.0623090\n",
      "Validation loss decreased (0.056102 --> 0.055432).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0597855\n",
      "\tspeed: 0.0339s/iter; left time: 691.4599s\n",
      "\titers: 200, epoch: 9 | loss: 0.0556837\n",
      "\tspeed: 0.0156s/iter; left time: 317.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0573444 Vali Loss: 0.0549995 Test Loss: 0.0618753\n",
      "Validation loss decreased (0.055432 --> 0.054999).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0590797\n",
      "\tspeed: 0.0335s/iter; left time: 676.8856s\n",
      "\titers: 200, epoch: 10 | loss: 0.0557223\n",
      "\tspeed: 0.0157s/iter; left time: 315.4766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0568249 Vali Loss: 0.0548584 Test Loss: 0.0616890\n",
      "Validation loss decreased (0.054999 --> 0.054858).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561026\n",
      "\tspeed: 0.0337s/iter; left time: 673.0335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585357\n",
      "\tspeed: 0.0157s/iter; left time: 311.0231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0564232 Vali Loss: 0.0546378 Test Loss: 0.0616500\n",
      "Validation loss decreased (0.054858 --> 0.054638).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0558916\n",
      "\tspeed: 0.0334s/iter; left time: 659.2483s\n",
      "\titers: 200, epoch: 12 | loss: 0.0566510\n",
      "\tspeed: 0.0156s/iter; left time: 307.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.0560662 Vali Loss: 0.0546260 Test Loss: 0.0615494\n",
      "Validation loss decreased (0.054638 --> 0.054626).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0569320\n",
      "\tspeed: 0.0337s/iter; left time: 657.8020s\n",
      "\titers: 200, epoch: 13 | loss: 0.0572126\n",
      "\tspeed: 0.0156s/iter; left time: 303.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.68s\n",
      "Steps: 223 | Train Loss: 0.0556781 Vali Loss: 0.0540884 Test Loss: 0.0609491\n",
      "Validation loss decreased (0.054626 --> 0.054088).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0538806\n",
      "\tspeed: 0.0335s/iter; left time: 646.9365s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576553\n",
      "\tspeed: 0.0157s/iter; left time: 301.0323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0554483 Vali Loss: 0.0541653 Test Loss: 0.0610347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0553492\n",
      "\tspeed: 0.0339s/iter; left time: 646.2741s\n",
      "\titers: 200, epoch: 15 | loss: 0.0535342\n",
      "\tspeed: 0.0157s/iter; left time: 297.7160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0552008 Vali Loss: 0.0536823 Test Loss: 0.0607922\n",
      "Validation loss decreased (0.054088 --> 0.053682).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0565477\n",
      "\tspeed: 0.0338s/iter; left time: 636.3917s\n",
      "\titers: 200, epoch: 16 | loss: 0.0576115\n",
      "\tspeed: 0.0156s/iter; left time: 293.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0550428 Vali Loss: 0.0537006 Test Loss: 0.0608407\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0562572\n",
      "\tspeed: 0.0337s/iter; left time: 628.7302s\n",
      "\titers: 200, epoch: 17 | loss: 0.0517175\n",
      "\tspeed: 0.0157s/iter; left time: 290.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0547894 Vali Loss: 0.0536728 Test Loss: 0.0604892\n",
      "Validation loss decreased (0.053682 --> 0.053673).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0553935\n",
      "\tspeed: 0.0339s/iter; left time: 624.6156s\n",
      "\titers: 200, epoch: 18 | loss: 0.0554292\n",
      "\tspeed: 0.0159s/iter; left time: 290.5992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0545941 Vali Loss: 0.0534926 Test Loss: 0.0605976\n",
      "Validation loss decreased (0.053673 --> 0.053493).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0538022\n",
      "\tspeed: 0.0335s/iter; left time: 610.0744s\n",
      "\titers: 200, epoch: 19 | loss: 0.0544681\n",
      "\tspeed: 0.0157s/iter; left time: 283.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0545015 Vali Loss: 0.0534522 Test Loss: 0.0605146\n",
      "Validation loss decreased (0.053493 --> 0.053452).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0524562\n",
      "\tspeed: 0.0334s/iter; left time: 600.6760s\n",
      "\titers: 200, epoch: 20 | loss: 0.0563905\n",
      "\tspeed: 0.0157s/iter; left time: 280.0334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0543636 Vali Loss: 0.0532615 Test Loss: 0.0602106\n",
      "Validation loss decreased (0.053452 --> 0.053262).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0505455\n",
      "\tspeed: 0.0335s/iter; left time: 594.1087s\n",
      "\titers: 200, epoch: 21 | loss: 0.0527814\n",
      "\tspeed: 0.0157s/iter; left time: 277.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0542359 Vali Loss: 0.0532801 Test Loss: 0.0603404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0503393\n",
      "\tspeed: 0.0335s/iter; left time: 586.3625s\n",
      "\titers: 200, epoch: 22 | loss: 0.0562435\n",
      "\tspeed: 0.0156s/iter; left time: 272.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0541370 Vali Loss: 0.0531477 Test Loss: 0.0602857\n",
      "Validation loss decreased (0.053262 --> 0.053148).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0570451\n",
      "\tspeed: 0.0338s/iter; left time: 584.9694s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524014\n",
      "\tspeed: 0.0157s/iter; left time: 269.3751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0540593 Vali Loss: 0.0532202 Test Loss: 0.0601717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0559748\n",
      "\tspeed: 0.0335s/iter; left time: 571.0659s\n",
      "\titers: 200, epoch: 24 | loss: 0.0517910\n",
      "\tspeed: 0.0157s/iter; left time: 266.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0539460 Vali Loss: 0.0532085 Test Loss: 0.0602040\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0498675\n",
      "\tspeed: 0.0333s/iter; left time: 561.6974s\n",
      "\titers: 200, epoch: 25 | loss: 0.0544898\n",
      "\tspeed: 0.0157s/iter; left time: 262.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0538836 Vali Loss: 0.0532143 Test Loss: 0.0601980\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0524655\n",
      "\tspeed: 0.0335s/iter; left time: 557.5375s\n",
      "\titers: 200, epoch: 26 | loss: 0.0515837\n",
      "\tspeed: 0.0157s/iter; left time: 259.0849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0538454 Vali Loss: 0.0530224 Test Loss: 0.0600790\n",
      "Validation loss decreased (0.053148 --> 0.053022).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0547678\n",
      "\tspeed: 0.0338s/iter; left time: 554.9851s\n",
      "\titers: 200, epoch: 27 | loss: 0.0534155\n",
      "\tspeed: 0.0156s/iter; left time: 254.8684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0538159 Vali Loss: 0.0530498 Test Loss: 0.0601092\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0537902\n",
      "\tspeed: 0.0338s/iter; left time: 546.9295s\n",
      "\titers: 200, epoch: 28 | loss: 0.0558576\n",
      "\tspeed: 0.0156s/iter; left time: 251.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0537517 Vali Loss: 0.0528752 Test Loss: 0.0600939\n",
      "Validation loss decreased (0.053022 --> 0.052875).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0535152\n",
      "\tspeed: 0.0337s/iter; left time: 536.9992s\n",
      "\titers: 200, epoch: 29 | loss: 0.0604828\n",
      "\tspeed: 0.0156s/iter; left time: 248.0212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0536101 Vali Loss: 0.0529713 Test Loss: 0.0599872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0508151\n",
      "\tspeed: 0.0330s/iter; left time: 519.7384s\n",
      "\titers: 200, epoch: 30 | loss: 0.0545918\n",
      "\tspeed: 0.0157s/iter; left time: 244.6760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.0536600 Vali Loss: 0.0529191 Test Loss: 0.0600255\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0573995\n",
      "\tspeed: 0.0331s/iter; left time: 512.8102s\n",
      "\titers: 200, epoch: 31 | loss: 0.0547190\n",
      "\tspeed: 0.0156s/iter; left time: 240.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.0536297 Vali Loss: 0.0528685 Test Loss: 0.0600883\n",
      "Validation loss decreased (0.052875 --> 0.052868).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0566322\n",
      "\tspeed: 0.0333s/iter; left time: 508.8799s\n",
      "\titers: 200, epoch: 32 | loss: 0.0561644\n",
      "\tspeed: 0.0156s/iter; left time: 237.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.69s\n",
      "Steps: 223 | Train Loss: 0.0535747 Vali Loss: 0.0529492 Test Loss: 0.0599952\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0541256\n",
      "\tspeed: 0.0333s/iter; left time: 501.0213s\n",
      "\titers: 200, epoch: 33 | loss: 0.0542545\n",
      "\tspeed: 0.0157s/iter; left time: 234.5140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0535112 Vali Loss: 0.0529153 Test Loss: 0.0599485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0514983\n",
      "\tspeed: 0.0336s/iter; left time: 498.0498s\n",
      "\titers: 200, epoch: 34 | loss: 0.0519383\n",
      "\tspeed: 0.0158s/iter; left time: 232.6535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0534532 Vali Loss: 0.0528856 Test Loss: 0.0599772\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0521322\n",
      "\tspeed: 0.0336s/iter; left time: 490.6969s\n",
      "\titers: 200, epoch: 35 | loss: 0.0555844\n",
      "\tspeed: 0.0158s/iter; left time: 229.2352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0534954 Vali Loss: 0.0528585 Test Loss: 0.0599386\n",
      "Validation loss decreased (0.052868 --> 0.052858).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0558157\n",
      "\tspeed: 0.0338s/iter; left time: 487.2419s\n",
      "\titers: 200, epoch: 36 | loss: 0.0551492\n",
      "\tspeed: 0.0157s/iter; left time: 223.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0534211 Vali Loss: 0.0528269 Test Loss: 0.0599109\n",
      "Validation loss decreased (0.052858 --> 0.052827).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0531007\n",
      "\tspeed: 0.0335s/iter; left time: 474.1778s\n",
      "\titers: 200, epoch: 37 | loss: 0.0533124\n",
      "\tspeed: 0.0157s/iter; left time: 220.5746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0534156 Vali Loss: 0.0528403 Test Loss: 0.0599353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0529477\n",
      "\tspeed: 0.0341s/iter; left time: 476.2467s\n",
      "\titers: 200, epoch: 38 | loss: 0.0505175\n",
      "\tspeed: 0.0161s/iter; left time: 222.5795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0534417 Vali Loss: 0.0528283 Test Loss: 0.0599188\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0537945\n",
      "\tspeed: 0.0340s/iter; left time: 466.0685s\n",
      "\titers: 200, epoch: 39 | loss: 0.0519727\n",
      "\tspeed: 0.0160s/iter; left time: 218.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0534414 Vali Loss: 0.0528408 Test Loss: 0.0599295\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0549834\n",
      "\tspeed: 0.0339s/iter; left time: 457.7062s\n",
      "\titers: 200, epoch: 40 | loss: 0.0527561\n",
      "\tspeed: 0.0160s/iter; left time: 214.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0533297 Vali Loss: 0.0527750 Test Loss: 0.0599160\n",
      "Validation loss decreased (0.052827 --> 0.052775).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0530107\n",
      "\tspeed: 0.0339s/iter; left time: 450.7689s\n",
      "\titers: 200, epoch: 41 | loss: 0.0512906\n",
      "\tspeed: 0.0158s/iter; left time: 208.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0534438 Vali Loss: 0.0528400 Test Loss: 0.0598943\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0548615\n",
      "\tspeed: 0.0334s/iter; left time: 436.2235s\n",
      "\titers: 200, epoch: 42 | loss: 0.0517692\n",
      "\tspeed: 0.0158s/iter; left time: 204.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0533682 Vali Loss: 0.0527767 Test Loss: 0.0599782\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0568761\n",
      "\tspeed: 0.0332s/iter; left time: 426.0999s\n",
      "\titers: 200, epoch: 43 | loss: 0.0537487\n",
      "\tspeed: 0.0159s/iter; left time: 202.1218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0533370 Vali Loss: 0.0527511 Test Loss: 0.0598640\n",
      "Validation loss decreased (0.052775 --> 0.052751).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0518278\n",
      "\tspeed: 0.0335s/iter; left time: 421.9967s\n",
      "\titers: 200, epoch: 44 | loss: 0.0541499\n",
      "\tspeed: 0.0157s/iter; left time: 196.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0533398 Vali Loss: 0.0528490 Test Loss: 0.0598922\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0545956\n",
      "\tspeed: 0.0331s/iter; left time: 409.8749s\n",
      "\titers: 200, epoch: 45 | loss: 0.0548810\n",
      "\tspeed: 0.0158s/iter; left time: 194.0881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0533313 Vali Loss: 0.0528048 Test Loss: 0.0598589\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0524439\n",
      "\tspeed: 0.0334s/iter; left time: 406.9498s\n",
      "\titers: 200, epoch: 46 | loss: 0.0551395\n",
      "\tspeed: 0.0158s/iter; left time: 190.9805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0533605 Vali Loss: 0.0528271 Test Loss: 0.0598727\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0529228\n",
      "\tspeed: 0.0335s/iter; left time: 400.2973s\n",
      "\titers: 200, epoch: 47 | loss: 0.0536647\n",
      "\tspeed: 0.0159s/iter; left time: 188.2691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0533144 Vali Loss: 0.0528189 Test Loss: 0.0599236\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0500809\n",
      "\tspeed: 0.0333s/iter; left time: 389.8731s\n",
      "\titers: 200, epoch: 48 | loss: 0.0522239\n",
      "\tspeed: 0.0157s/iter; left time: 181.9984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0533118 Vali Loss: 0.0527360 Test Loss: 0.0598047\n",
      "Validation loss decreased (0.052751 --> 0.052736).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0530612\n",
      "\tspeed: 0.0336s/iter; left time: 386.2993s\n",
      "\titers: 200, epoch: 49 | loss: 0.0528583\n",
      "\tspeed: 0.0158s/iter; left time: 180.6087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0533719 Vali Loss: 0.0528013 Test Loss: 0.0598424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0526910\n",
      "\tspeed: 0.0334s/iter; left time: 376.9527s\n",
      "\titers: 200, epoch: 50 | loss: 0.0508897\n",
      "\tspeed: 0.0157s/iter; left time: 175.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0532920 Vali Loss: 0.0527309 Test Loss: 0.0598208\n",
      "Validation loss decreased (0.052736 --> 0.052731).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0555241\n",
      "\tspeed: 0.0340s/iter; left time: 376.1526s\n",
      "\titers: 200, epoch: 51 | loss: 0.0515032\n",
      "\tspeed: 0.0157s/iter; left time: 171.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0533077 Vali Loss: 0.0528050 Test Loss: 0.0598917\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0504222\n",
      "\tspeed: 0.0344s/iter; left time: 372.3197s\n",
      "\titers: 200, epoch: 52 | loss: 0.0511422\n",
      "\tspeed: 0.0157s/iter; left time: 168.1458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0533192 Vali Loss: 0.0527871 Test Loss: 0.0598772\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0523588\n",
      "\tspeed: 0.0335s/iter; left time: 355.2282s\n",
      "\titers: 200, epoch: 53 | loss: 0.0520532\n",
      "\tspeed: 0.0157s/iter; left time: 164.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0532792 Vali Loss: 0.0527758 Test Loss: 0.0598355\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0552782\n",
      "\tspeed: 0.0334s/iter; left time: 347.0704s\n",
      "\titers: 200, epoch: 54 | loss: 0.0514998\n",
      "\tspeed: 0.0157s/iter; left time: 161.7392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0532762 Vali Loss: 0.0527533 Test Loss: 0.0598804\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0508366\n",
      "\tspeed: 0.0336s/iter; left time: 341.0711s\n",
      "\titers: 200, epoch: 55 | loss: 0.0515189\n",
      "\tspeed: 0.0159s/iter; left time: 160.0266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0533144 Vali Loss: 0.0527656 Test Loss: 0.0598407\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0558456\n",
      "\tspeed: 0.0342s/iter; left time: 340.1604s\n",
      "\titers: 200, epoch: 56 | loss: 0.0555344\n",
      "\tspeed: 0.0158s/iter; left time: 155.8123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0532639 Vali Loss: 0.0527695 Test Loss: 0.0598857\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0504367\n",
      "\tspeed: 0.0336s/iter; left time: 326.4069s\n",
      "\titers: 200, epoch: 57 | loss: 0.0523928\n",
      "\tspeed: 0.0158s/iter; left time: 151.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0532876 Vali Loss: 0.0527460 Test Loss: 0.0598777\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0559266\n",
      "\tspeed: 0.0335s/iter; left time: 317.4801s\n",
      "\titers: 200, epoch: 58 | loss: 0.0553270\n",
      "\tspeed: 0.0157s/iter; left time: 147.0756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0532810 Vali Loss: 0.0528159 Test Loss: 0.0598513\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0536265\n",
      "\tspeed: 0.0334s/iter; left time: 309.5548s\n",
      "\titers: 200, epoch: 59 | loss: 0.0533814\n",
      "\tspeed: 0.0157s/iter; left time: 143.6645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.70s\n",
      "Steps: 223 | Train Loss: 0.0533104 Vali Loss: 0.0527790 Test Loss: 0.0599007\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0525546\n",
      "\tspeed: 0.0337s/iter; left time: 304.9595s\n",
      "\titers: 200, epoch: 60 | loss: 0.0488285\n",
      "\tspeed: 0.0159s/iter; left time: 142.3277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0533224 Vali Loss: 0.0527687 Test Loss: 0.0598176\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_24_ES_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.009826576337218285, rmse:0.0991290882229805, mae:0.05982082709670067, rse:0.29172492027282715\n",
      "Intermediate time for ES and pred_len 24: 00h:11m:23.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1382145\n",
      "\tspeed: 0.0380s/iter; left time: 840.4046s\n",
      "\titers: 200, epoch: 1 | loss: 0.1181780\n",
      "\tspeed: 0.0162s/iter; left time: 356.7242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.1422870 Vali Loss: 0.1110726 Test Loss: 0.1262145\n",
      "Validation loss decreased (inf --> 0.111073).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934740\n",
      "\tspeed: 0.0358s/iter; left time: 784.2887s\n",
      "\titers: 200, epoch: 2 | loss: 0.0868728\n",
      "\tspeed: 0.0160s/iter; left time: 348.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0946656 Vali Loss: 0.0840059 Test Loss: 0.0971048\n",
      "Validation loss decreased (0.111073 --> 0.084006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0818275\n",
      "\tspeed: 0.0358s/iter; left time: 774.3505s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815208\n",
      "\tspeed: 0.0162s/iter; left time: 348.9050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0849752 Vali Loss: 0.0803390 Test Loss: 0.0920883\n",
      "Validation loss decreased (0.084006 --> 0.080339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0843434\n",
      "\tspeed: 0.0369s/iter; left time: 791.1018s\n",
      "\titers: 200, epoch: 4 | loss: 0.0803908\n",
      "\tspeed: 0.0160s/iter; left time: 340.7915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0819896 Vali Loss: 0.0789692 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.080339 --> 0.078969).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0778120\n",
      "\tspeed: 0.0374s/iter; left time: 793.6584s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792906\n",
      "\tspeed: 0.0163s/iter; left time: 344.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0802503 Vali Loss: 0.0777747 Test Loss: 0.0894107\n",
      "Validation loss decreased (0.078969 --> 0.077775).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0807522\n",
      "\tspeed: 0.0381s/iter; left time: 799.6434s\n",
      "\titers: 200, epoch: 6 | loss: 0.0769921\n",
      "\tspeed: 0.0162s/iter; left time: 338.5042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0790549 Vali Loss: 0.0774048 Test Loss: 0.0887209\n",
      "Validation loss decreased (0.077775 --> 0.077405).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823921\n",
      "\tspeed: 0.0361s/iter; left time: 750.1166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0769773\n",
      "\tspeed: 0.0162s/iter; left time: 335.2452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0780271 Vali Loss: 0.0765681 Test Loss: 0.0888416\n",
      "Validation loss decreased (0.077405 --> 0.076568).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0805103\n",
      "\tspeed: 0.0367s/iter; left time: 754.0216s\n",
      "\titers: 200, epoch: 8 | loss: 0.0825891\n",
      "\tspeed: 0.0162s/iter; left time: 331.0952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0772853 Vali Loss: 0.0766558 Test Loss: 0.0883564\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0758953\n",
      "\tspeed: 0.0369s/iter; left time: 750.8006s\n",
      "\titers: 200, epoch: 9 | loss: 0.0758411\n",
      "\tspeed: 0.0161s/iter; left time: 326.4429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0766971 Vali Loss: 0.0760411 Test Loss: 0.0879879\n",
      "Validation loss decreased (0.076568 --> 0.076041).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0772159\n",
      "\tspeed: 0.0365s/iter; left time: 732.8555s\n",
      "\titers: 200, epoch: 10 | loss: 0.0762513\n",
      "\tspeed: 0.0162s/iter; left time: 324.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0761602 Vali Loss: 0.0759706 Test Loss: 0.0880720\n",
      "Validation loss decreased (0.076041 --> 0.075971).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0755076\n",
      "\tspeed: 0.0366s/iter; left time: 726.8926s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763734\n",
      "\tspeed: 0.0162s/iter; left time: 320.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0756422 Vali Loss: 0.0762044 Test Loss: 0.0878475\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0748532\n",
      "\tspeed: 0.0354s/iter; left time: 695.4020s\n",
      "\titers: 200, epoch: 12 | loss: 0.0741075\n",
      "\tspeed: 0.0162s/iter; left time: 316.7426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0751778 Vali Loss: 0.0761833 Test Loss: 0.0877756\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0756494\n",
      "\tspeed: 0.0362s/iter; left time: 703.3238s\n",
      "\titers: 200, epoch: 13 | loss: 0.0696331\n",
      "\tspeed: 0.0162s/iter; left time: 313.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0747903 Vali Loss: 0.0759777 Test Loss: 0.0875898\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0709691\n",
      "\tspeed: 0.0354s/iter; left time: 680.9828s\n",
      "\titers: 200, epoch: 14 | loss: 0.0781972\n",
      "\tspeed: 0.0163s/iter; left time: 311.9916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0744701 Vali Loss: 0.0760754 Test Loss: 0.0878949\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0766354\n",
      "\tspeed: 0.0362s/iter; left time: 686.6905s\n",
      "\titers: 200, epoch: 15 | loss: 0.0760197\n",
      "\tspeed: 0.0163s/iter; left time: 307.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0741755 Vali Loss: 0.0762521 Test Loss: 0.0875846\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0728517\n",
      "\tspeed: 0.0363s/iter; left time: 681.3254s\n",
      "\titers: 200, epoch: 16 | loss: 0.0739293\n",
      "\tspeed: 0.0163s/iter; left time: 303.4218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0739151 Vali Loss: 0.0765721 Test Loss: 0.0876145\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0729643\n",
      "\tspeed: 0.0359s/iter; left time: 665.8752s\n",
      "\titers: 200, epoch: 17 | loss: 0.0719611\n",
      "\tspeed: 0.0162s/iter; left time: 298.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0736111 Vali Loss: 0.0764372 Test Loss: 0.0878238\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0713653\n",
      "\tspeed: 0.0363s/iter; left time: 665.5871s\n",
      "\titers: 200, epoch: 18 | loss: 0.0706139\n",
      "\tspeed: 0.0162s/iter; left time: 295.6097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0733448 Vali Loss: 0.0764247 Test Loss: 0.0877773\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0710176\n",
      "\tspeed: 0.0359s/iter; left time: 649.3804s\n",
      "\titers: 200, epoch: 19 | loss: 0.0718137\n",
      "\tspeed: 0.0162s/iter; left time: 292.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0732027 Vali Loss: 0.0767154 Test Loss: 0.0876804\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0710302\n",
      "\tspeed: 0.0362s/iter; left time: 647.3301s\n",
      "\titers: 200, epoch: 20 | loss: 0.0708285\n",
      "\tspeed: 0.0163s/iter; left time: 289.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0730290 Vali Loss: 0.0766685 Test Loss: 0.0878887\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01861393451690674, rmse:0.13643290102481842, mae:0.08807197213172913, rse:0.4007987976074219\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1392002\n",
      "\tspeed: 0.0186s/iter; left time: 410.3116s\n",
      "\titers: 200, epoch: 1 | loss: 0.1213997\n",
      "\tspeed: 0.0162s/iter; left time: 356.5772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.1457149 Vali Loss: 0.1121324 Test Loss: 0.1275801\n",
      "Validation loss decreased (inf --> 0.112132).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0916661\n",
      "\tspeed: 0.0363s/iter; left time: 794.1812s\n",
      "\titers: 200, epoch: 2 | loss: 0.0882165\n",
      "\tspeed: 0.0162s/iter; left time: 352.1816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0948816 Vali Loss: 0.0847211 Test Loss: 0.0971129\n",
      "Validation loss decreased (0.112132 --> 0.084721).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0838655\n",
      "\tspeed: 0.0367s/iter; left time: 794.4595s\n",
      "\titers: 200, epoch: 3 | loss: 0.0821575\n",
      "\tspeed: 0.0162s/iter; left time: 348.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0853048 Vali Loss: 0.0805378 Test Loss: 0.0925466\n",
      "Validation loss decreased (0.084721 --> 0.080538).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0814954\n",
      "\tspeed: 0.0378s/iter; left time: 810.5241s\n",
      "\titers: 200, epoch: 4 | loss: 0.0799669\n",
      "\tspeed: 0.0162s/iter; left time: 346.2689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0822200 Vali Loss: 0.0790645 Test Loss: 0.0904507\n",
      "Validation loss decreased (0.080538 --> 0.079065).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0827645\n",
      "\tspeed: 0.0364s/iter; left time: 773.1853s\n",
      "\titers: 200, epoch: 5 | loss: 0.0784648\n",
      "\tspeed: 0.0163s/iter; left time: 344.4453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0803891 Vali Loss: 0.0776014 Test Loss: 0.0900914\n",
      "Validation loss decreased (0.079065 --> 0.077601).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0819158\n",
      "\tspeed: 0.0365s/iter; left time: 765.3124s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812780\n",
      "\tspeed: 0.0161s/iter; left time: 337.0083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0791297 Vali Loss: 0.0769471 Test Loss: 0.0889320\n",
      "Validation loss decreased (0.077601 --> 0.076947).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0790335\n",
      "\tspeed: 0.0362s/iter; left time: 751.2864s\n",
      "\titers: 200, epoch: 7 | loss: 0.0776521\n",
      "\tspeed: 0.0162s/iter; left time: 335.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0781040 Vali Loss: 0.0764812 Test Loss: 0.0890434\n",
      "Validation loss decreased (0.076947 --> 0.076481).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0781007\n",
      "\tspeed: 0.0366s/iter; left time: 750.9956s\n",
      "\titers: 200, epoch: 8 | loss: 0.0739211\n",
      "\tspeed: 0.0159s/iter; left time: 325.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0773688 Vali Loss: 0.0761299 Test Loss: 0.0885875\n",
      "Validation loss decreased (0.076481 --> 0.076130).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0748803\n",
      "\tspeed: 0.0363s/iter; left time: 737.3732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0766237\n",
      "\tspeed: 0.0159s/iter; left time: 320.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0766422 Vali Loss: 0.0759516 Test Loss: 0.0882437\n",
      "Validation loss decreased (0.076130 --> 0.075952).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0768858\n",
      "\tspeed: 0.0365s/iter; left time: 734.3978s\n",
      "\titers: 200, epoch: 10 | loss: 0.0776741\n",
      "\tspeed: 0.0161s/iter; left time: 321.8361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0759568 Vali Loss: 0.0758801 Test Loss: 0.0881058\n",
      "Validation loss decreased (0.075952 --> 0.075880).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0730904\n",
      "\tspeed: 0.0368s/iter; left time: 732.1395s\n",
      "\titers: 200, epoch: 11 | loss: 0.0754524\n",
      "\tspeed: 0.0162s/iter; left time: 319.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0755087 Vali Loss: 0.0756813 Test Loss: 0.0882308\n",
      "Validation loss decreased (0.075880 --> 0.075681).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0759275\n",
      "\tspeed: 0.0358s/iter; left time: 703.8034s\n",
      "\titers: 200, epoch: 12 | loss: 0.0746774\n",
      "\tspeed: 0.0160s/iter; left time: 313.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0750229 Vali Loss: 0.0760648 Test Loss: 0.0884734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0772028\n",
      "\tspeed: 0.0350s/iter; left time: 679.4565s\n",
      "\titers: 200, epoch: 13 | loss: 0.0717757\n",
      "\tspeed: 0.0162s/iter; left time: 312.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0746180 Vali Loss: 0.0763635 Test Loss: 0.0886167\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0730422\n",
      "\tspeed: 0.0358s/iter; left time: 687.3162s\n",
      "\titers: 200, epoch: 14 | loss: 0.0736753\n",
      "\tspeed: 0.0160s/iter; left time: 305.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0742349 Vali Loss: 0.0757813 Test Loss: 0.0882573\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0747367\n",
      "\tspeed: 0.0349s/iter; left time: 662.9744s\n",
      "\titers: 200, epoch: 15 | loss: 0.0743688\n",
      "\tspeed: 0.0161s/iter; left time: 303.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0739294 Vali Loss: 0.0763437 Test Loss: 0.0882667\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0708626\n",
      "\tspeed: 0.0347s/iter; left time: 651.5734s\n",
      "\titers: 200, epoch: 16 | loss: 0.0729118\n",
      "\tspeed: 0.0161s/iter; left time: 301.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0736520 Vali Loss: 0.0763455 Test Loss: 0.0881919\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0769467\n",
      "\tspeed: 0.0349s/iter; left time: 646.9496s\n",
      "\titers: 200, epoch: 17 | loss: 0.0711830\n",
      "\tspeed: 0.0160s/iter; left time: 294.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0733108 Vali Loss: 0.0764271 Test Loss: 0.0883007\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0737789\n",
      "\tspeed: 0.0347s/iter; left time: 636.6097s\n",
      "\titers: 200, epoch: 18 | loss: 0.0739083\n",
      "\tspeed: 0.0160s/iter; left time: 292.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0731830 Vali Loss: 0.0764392 Test Loss: 0.0881364\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0710725\n",
      "\tspeed: 0.0355s/iter; left time: 643.2561s\n",
      "\titers: 200, epoch: 19 | loss: 0.0745345\n",
      "\tspeed: 0.0162s/iter; left time: 291.4193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0729455 Vali Loss: 0.0765167 Test Loss: 0.0883839\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0727747\n",
      "\tspeed: 0.0353s/iter; left time: 631.5753s\n",
      "\titers: 200, epoch: 20 | loss: 0.0709504\n",
      "\tspeed: 0.0160s/iter; left time: 284.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0727968 Vali Loss: 0.0766446 Test Loss: 0.0882663\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0744427\n",
      "\tspeed: 0.0356s/iter; left time: 629.6061s\n",
      "\titers: 200, epoch: 21 | loss: 0.0721747\n",
      "\tspeed: 0.0162s/iter; left time: 285.2050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0725545 Vali Loss: 0.0766247 Test Loss: 0.0882425\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_96_ES_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01882493495941162, rmse:0.13720399141311646, mae:0.08823078870773315, rse:0.4030640125274658\n",
      "Intermediate time for ES and pred_len 96: 00h:03m:44.48s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_512_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1420207\n",
      "\tspeed: 0.0376s/iter; left time: 831.5251s\n",
      "\titers: 200, epoch: 1 | loss: 0.1220062\n",
      "\tspeed: 0.0162s/iter; left time: 355.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.03s\n",
      "Steps: 222 | Train Loss: 0.1459882 Vali Loss: 0.1142418 Test Loss: 0.1288368\n",
      "Validation loss decreased (inf --> 0.114242).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0938779\n",
      "\tspeed: 0.0355s/iter; left time: 776.7881s\n",
      "\titers: 200, epoch: 2 | loss: 0.0906986\n",
      "\tspeed: 0.0162s/iter; left time: 351.7682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0986648 Vali Loss: 0.0893049 Test Loss: 0.1028076\n",
      "Validation loss decreased (0.114242 --> 0.089305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886885\n",
      "\tspeed: 0.0360s/iter; left time: 780.4533s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865253\n",
      "\tspeed: 0.0162s/iter; left time: 348.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0898190 Vali Loss: 0.0859340 Test Loss: 0.0980160\n",
      "Validation loss decreased (0.089305 --> 0.085934).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0852806\n",
      "\tspeed: 0.0356s/iter; left time: 763.6336s\n",
      "\titers: 200, epoch: 4 | loss: 0.0859492\n",
      "\tspeed: 0.0162s/iter; left time: 345.0431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0869044 Vali Loss: 0.0841650 Test Loss: 0.0958709\n",
      "Validation loss decreased (0.085934 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0888405\n",
      "\tspeed: 0.0367s/iter; left time: 777.5233s\n",
      "\titers: 200, epoch: 5 | loss: 0.0867904\n",
      "\tspeed: 0.0162s/iter; left time: 341.1597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0850048 Vali Loss: 0.0835832 Test Loss: 0.0956103\n",
      "Validation loss decreased (0.084165 --> 0.083583).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844916\n",
      "\tspeed: 0.0359s/iter; left time: 754.5196s\n",
      "\titers: 200, epoch: 6 | loss: 0.0805309\n",
      "\tspeed: 0.0164s/iter; left time: 341.7623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0836529 Vali Loss: 0.0832231 Test Loss: 0.0952673\n",
      "Validation loss decreased (0.083583 --> 0.083223).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0847475\n",
      "\tspeed: 0.0367s/iter; left time: 762.7029s\n",
      "\titers: 200, epoch: 7 | loss: 0.0842363\n",
      "\tspeed: 0.0161s/iter; left time: 333.7478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0825565 Vali Loss: 0.0831752 Test Loss: 0.0948034\n",
      "Validation loss decreased (0.083223 --> 0.083175).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815429\n",
      "\tspeed: 0.0376s/iter; left time: 772.5074s\n",
      "\titers: 200, epoch: 8 | loss: 0.0795956\n",
      "\tspeed: 0.0164s/iter; left time: 334.9864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0816194 Vali Loss: 0.0834158 Test Loss: 0.0945200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0805828\n",
      "\tspeed: 0.0354s/iter; left time: 719.2672s\n",
      "\titers: 200, epoch: 9 | loss: 0.0785723\n",
      "\tspeed: 0.0161s/iter; left time: 325.7341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0808371 Vali Loss: 0.0834359 Test Loss: 0.0951119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0788970\n",
      "\tspeed: 0.0362s/iter; left time: 726.7427s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791808\n",
      "\tspeed: 0.0161s/iter; left time: 322.2730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0801603 Vali Loss: 0.0837579 Test Loss: 0.0949604\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0781882\n",
      "\tspeed: 0.0361s/iter; left time: 718.6465s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749253\n",
      "\tspeed: 0.0163s/iter; left time: 323.3025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0795041 Vali Loss: 0.0836973 Test Loss: 0.0950555\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0820172\n",
      "\tspeed: 0.0354s/iter; left time: 695.1612s\n",
      "\titers: 200, epoch: 12 | loss: 0.0827949\n",
      "\tspeed: 0.0163s/iter; left time: 318.8511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0790387 Vali Loss: 0.0843834 Test Loss: 0.0948036\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0767224\n",
      "\tspeed: 0.0347s/iter; left time: 674.8942s\n",
      "\titers: 200, epoch: 13 | loss: 0.0767669\n",
      "\tspeed: 0.0163s/iter; left time: 315.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0785595 Vali Loss: 0.0837799 Test Loss: 0.0946348\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0776364\n",
      "\tspeed: 0.0363s/iter; left time: 698.4501s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788151\n",
      "\tspeed: 0.0163s/iter; left time: 310.9653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0781529 Vali Loss: 0.0840986 Test Loss: 0.0948527\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0782898\n",
      "\tspeed: 0.0366s/iter; left time: 695.6588s\n",
      "\titers: 200, epoch: 15 | loss: 0.0772800\n",
      "\tspeed: 0.0162s/iter; left time: 306.0996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0777862 Vali Loss: 0.0843334 Test Loss: 0.0949395\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0794309\n",
      "\tspeed: 0.0358s/iter; left time: 671.2904s\n",
      "\titers: 200, epoch: 16 | loss: 0.0761538\n",
      "\tspeed: 0.0162s/iter; left time: 302.1532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0774798 Vali Loss: 0.0843783 Test Loss: 0.0947229\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0744821\n",
      "\tspeed: 0.0357s/iter; left time: 662.6103s\n",
      "\titers: 200, epoch: 17 | loss: 0.0786856\n",
      "\tspeed: 0.0161s/iter; left time: 297.0746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0771468 Vali Loss: 0.0845008 Test Loss: 0.0948383\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02094191126525402, rmse:0.14471320807933807, mae:0.09480340778827667, rse:0.4251543879508972\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1481263\n",
      "\tspeed: 0.0185s/iter; left time: 408.4627s\n",
      "\titers: 200, epoch: 1 | loss: 0.1227052\n",
      "\tspeed: 0.0163s/iter; left time: 359.0196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.1500091 Vali Loss: 0.1163593 Test Loss: 0.1314223\n",
      "Validation loss decreased (inf --> 0.116359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0965327\n",
      "\tspeed: 0.0361s/iter; left time: 790.2943s\n",
      "\titers: 200, epoch: 2 | loss: 0.0956875\n",
      "\tspeed: 0.0162s/iter; left time: 351.8786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0985138 Vali Loss: 0.0893222 Test Loss: 0.1023705\n",
      "Validation loss decreased (0.116359 --> 0.089322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888230\n",
      "\tspeed: 0.0358s/iter; left time: 776.2399s\n",
      "\titers: 200, epoch: 3 | loss: 0.0875622\n",
      "\tspeed: 0.0162s/iter; left time: 348.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0895779 Vali Loss: 0.0861177 Test Loss: 0.0976926\n",
      "Validation loss decreased (0.089322 --> 0.086118).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853538\n",
      "\tspeed: 0.0403s/iter; left time: 864.0450s\n",
      "\titers: 200, epoch: 4 | loss: 0.0864567\n",
      "\tspeed: 0.0164s/iter; left time: 349.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0867516 Vali Loss: 0.0849476 Test Loss: 0.0962479\n",
      "Validation loss decreased (0.086118 --> 0.084948).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882230\n",
      "\tspeed: 0.0361s/iter; left time: 766.0562s\n",
      "\titers: 200, epoch: 5 | loss: 0.0861160\n",
      "\tspeed: 0.0162s/iter; left time: 342.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0849158 Vali Loss: 0.0841899 Test Loss: 0.0946461\n",
      "Validation loss decreased (0.084948 --> 0.084190).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0801568\n",
      "\tspeed: 0.0368s/iter; left time: 773.0360s\n",
      "\titers: 200, epoch: 6 | loss: 0.0808399\n",
      "\tspeed: 0.0161s/iter; left time: 336.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0834968 Vali Loss: 0.0833415 Test Loss: 0.0945159\n",
      "Validation loss decreased (0.084190 --> 0.083341).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0854605\n",
      "\tspeed: 0.0362s/iter; left time: 751.1907s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811665\n",
      "\tspeed: 0.0164s/iter; left time: 338.2093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0824433 Vali Loss: 0.0836033 Test Loss: 0.0946325\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0825000\n",
      "\tspeed: 0.0357s/iter; left time: 733.7108s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831890\n",
      "\tspeed: 0.0162s/iter; left time: 330.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0815026 Vali Loss: 0.0839171 Test Loss: 0.0946808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0826100\n",
      "\tspeed: 0.0352s/iter; left time: 715.8732s\n",
      "\titers: 200, epoch: 9 | loss: 0.0817555\n",
      "\tspeed: 0.0161s/iter; left time: 326.4287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0808106 Vali Loss: 0.0837482 Test Loss: 0.0951947\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0815277\n",
      "\tspeed: 0.0353s/iter; left time: 708.6773s\n",
      "\titers: 200, epoch: 10 | loss: 0.0787754\n",
      "\tspeed: 0.0162s/iter; left time: 323.7823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0801576 Vali Loss: 0.0838155 Test Loss: 0.0950207\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0795944\n",
      "\tspeed: 0.0355s/iter; left time: 704.9431s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797635\n",
      "\tspeed: 0.0162s/iter; left time: 320.0405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0796641 Vali Loss: 0.0838913 Test Loss: 0.0950335\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0790174\n",
      "\tspeed: 0.0356s/iter; left time: 700.0254s\n",
      "\titers: 200, epoch: 12 | loss: 0.0773009\n",
      "\tspeed: 0.0163s/iter; left time: 318.6285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0790822 Vali Loss: 0.0836509 Test Loss: 0.0951440\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0794942\n",
      "\tspeed: 0.0357s/iter; left time: 693.4349s\n",
      "\titers: 200, epoch: 13 | loss: 0.0796114\n",
      "\tspeed: 0.0162s/iter; left time: 312.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0787112 Vali Loss: 0.0838853 Test Loss: 0.0950327\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0771335\n",
      "\tspeed: 0.0352s/iter; left time: 676.5767s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793738\n",
      "\tspeed: 0.0161s/iter; left time: 308.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0783208 Vali Loss: 0.0840787 Test Loss: 0.0951204\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0753011\n",
      "\tspeed: 0.0353s/iter; left time: 669.9384s\n",
      "\titers: 200, epoch: 15 | loss: 0.0783717\n",
      "\tspeed: 0.0162s/iter; left time: 305.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0779966 Vali Loss: 0.0835997 Test Loss: 0.0954129\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0776929\n",
      "\tspeed: 0.0350s/iter; left time: 657.4335s\n",
      "\titers: 200, epoch: 16 | loss: 0.0769748\n",
      "\tspeed: 0.0162s/iter; left time: 301.9083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0776513 Vali Loss: 0.0835594 Test Loss: 0.0950344\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_512_168_ES_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021092932671308517, rmse:0.14523406326770782, mae:0.09451582282781601, rse:0.42668458819389343\n",
      "Intermediate time for ES and pred_len 168: 00h:03m:02.56s\n",
      "Intermediate time for ES: 00h:18m:10.82s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975797\n",
      "\tspeed: 0.0363s/iter; left time: 806.1243s\n",
      "\titers: 200, epoch: 1 | loss: 0.0836335\n",
      "\tspeed: 0.0159s/iter; left time: 351.1256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.00s\n",
      "Steps: 223 | Train Loss: 0.1024391 Vali Loss: 0.0872047 Test Loss: 0.0960801\n",
      "Validation loss decreased (inf --> 0.087205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0558590\n",
      "\tspeed: 0.0346s/iter; left time: 761.1099s\n",
      "\titers: 200, epoch: 2 | loss: 0.0529639\n",
      "\tspeed: 0.0158s/iter; left time: 346.4807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0578774 Vali Loss: 0.0587300 Test Loss: 0.0621037\n",
      "Validation loss decreased (0.087205 --> 0.058730).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0464267\n",
      "\tspeed: 0.0343s/iter; left time: 746.7955s\n",
      "\titers: 200, epoch: 3 | loss: 0.0519227\n",
      "\tspeed: 0.0158s/iter; left time: 342.9458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0499244 Vali Loss: 0.0564306 Test Loss: 0.0598956\n",
      "Validation loss decreased (0.058730 --> 0.056431).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0491055\n",
      "\tspeed: 0.0343s/iter; left time: 739.6120s\n",
      "\titers: 200, epoch: 4 | loss: 0.0485278\n",
      "\tspeed: 0.0158s/iter; left time: 339.5102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0479141 Vali Loss: 0.0552515 Test Loss: 0.0584848\n",
      "Validation loss decreased (0.056431 --> 0.055251).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0461720\n",
      "\tspeed: 0.0340s/iter; left time: 725.4197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0457155\n",
      "\tspeed: 0.0158s/iter; left time: 335.6504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0465824 Vali Loss: 0.0546872 Test Loss: 0.0577522\n",
      "Validation loss decreased (0.055251 --> 0.054687).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0473171\n",
      "\tspeed: 0.0342s/iter; left time: 721.7797s\n",
      "\titers: 200, epoch: 6 | loss: 0.0413529\n",
      "\tspeed: 0.0158s/iter; left time: 330.8000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0456244 Vali Loss: 0.0540799 Test Loss: 0.0576998\n",
      "Validation loss decreased (0.054687 --> 0.054080).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0445942\n",
      "\tspeed: 0.0343s/iter; left time: 715.6181s\n",
      "\titers: 200, epoch: 7 | loss: 0.0474015\n",
      "\tspeed: 0.0158s/iter; left time: 329.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0449627 Vali Loss: 0.0533268 Test Loss: 0.0570868\n",
      "Validation loss decreased (0.054080 --> 0.053327).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0458883\n",
      "\tspeed: 0.0342s/iter; left time: 705.5631s\n",
      "\titers: 200, epoch: 8 | loss: 0.0440469\n",
      "\tspeed: 0.0159s/iter; left time: 325.5987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0443844 Vali Loss: 0.0530725 Test Loss: 0.0570844\n",
      "Validation loss decreased (0.053327 --> 0.053073).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0468748\n",
      "\tspeed: 0.0346s/iter; left time: 706.2290s\n",
      "\titers: 200, epoch: 9 | loss: 0.0448973\n",
      "\tspeed: 0.0158s/iter; left time: 320.4230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0439861 Vali Loss: 0.0528239 Test Loss: 0.0568019\n",
      "Validation loss decreased (0.053073 --> 0.052824).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0420790\n",
      "\tspeed: 0.0344s/iter; left time: 693.7823s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407695\n",
      "\tspeed: 0.0158s/iter; left time: 318.1299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0435386 Vali Loss: 0.0526597 Test Loss: 0.0562937\n",
      "Validation loss decreased (0.052824 --> 0.052660).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0412320\n",
      "\tspeed: 0.0342s/iter; left time: 683.3778s\n",
      "\titers: 200, epoch: 11 | loss: 0.0465333\n",
      "\tspeed: 0.0158s/iter; left time: 314.6612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0433083 Vali Loss: 0.0523613 Test Loss: 0.0560849\n",
      "Validation loss decreased (0.052660 --> 0.052361).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0417468\n",
      "\tspeed: 0.0343s/iter; left time: 677.9932s\n",
      "\titers: 200, epoch: 12 | loss: 0.0436344\n",
      "\tspeed: 0.0158s/iter; left time: 310.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0430509 Vali Loss: 0.0523960 Test Loss: 0.0563496\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0463760\n",
      "\tspeed: 0.0339s/iter; left time: 661.1903s\n",
      "\titers: 200, epoch: 13 | loss: 0.0398072\n",
      "\tspeed: 0.0158s/iter; left time: 306.6887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0427942 Vali Loss: 0.0523807 Test Loss: 0.0562546\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0441464\n",
      "\tspeed: 0.0335s/iter; left time: 646.2027s\n",
      "\titers: 200, epoch: 14 | loss: 0.0437662\n",
      "\tspeed: 0.0158s/iter; left time: 304.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0426049 Vali Loss: 0.0519577 Test Loss: 0.0558820\n",
      "Validation loss decreased (0.052361 --> 0.051958).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0397336\n",
      "\tspeed: 0.0348s/iter; left time: 663.5882s\n",
      "\titers: 200, epoch: 15 | loss: 0.0388149\n",
      "\tspeed: 0.0158s/iter; left time: 299.8178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0424205 Vali Loss: 0.0520772 Test Loss: 0.0560981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0439926\n",
      "\tspeed: 0.0343s/iter; left time: 647.5421s\n",
      "\titers: 200, epoch: 16 | loss: 0.0399195\n",
      "\tspeed: 0.0158s/iter; left time: 297.0679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0422887 Vali Loss: 0.0519859 Test Loss: 0.0558941\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0427168\n",
      "\tspeed: 0.0337s/iter; left time: 628.1599s\n",
      "\titers: 200, epoch: 17 | loss: 0.0386291\n",
      "\tspeed: 0.0158s/iter; left time: 293.0007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0421217 Vali Loss: 0.0517315 Test Loss: 0.0557642\n",
      "Validation loss decreased (0.051958 --> 0.051731).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0424594\n",
      "\tspeed: 0.0349s/iter; left time: 642.4447s\n",
      "\titers: 200, epoch: 18 | loss: 0.0416625\n",
      "\tspeed: 0.0158s/iter; left time: 289.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0419993 Vali Loss: 0.0518133 Test Loss: 0.0558669\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0458638\n",
      "\tspeed: 0.0337s/iter; left time: 613.1663s\n",
      "\titers: 200, epoch: 19 | loss: 0.0417649\n",
      "\tspeed: 0.0159s/iter; left time: 286.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0419249 Vali Loss: 0.0517524 Test Loss: 0.0559174\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0395100\n",
      "\tspeed: 0.0347s/iter; left time: 622.5059s\n",
      "\titers: 200, epoch: 20 | loss: 0.0389466\n",
      "\tspeed: 0.0159s/iter; left time: 283.3438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0418182 Vali Loss: 0.0516136 Test Loss: 0.0558284\n",
      "Validation loss decreased (0.051731 --> 0.051614).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0428368\n",
      "\tspeed: 0.0344s/iter; left time: 611.1412s\n",
      "\titers: 200, epoch: 21 | loss: 0.0405450\n",
      "\tspeed: 0.0158s/iter; left time: 278.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0417006 Vali Loss: 0.0515338 Test Loss: 0.0558885\n",
      "Validation loss decreased (0.051614 --> 0.051534).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0440898\n",
      "\tspeed: 0.0350s/iter; left time: 612.2902s\n",
      "\titers: 200, epoch: 22 | loss: 0.0420497\n",
      "\tspeed: 0.0158s/iter; left time: 275.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0416685 Vali Loss: 0.0514476 Test Loss: 0.0557991\n",
      "Validation loss decreased (0.051534 --> 0.051448).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0430937\n",
      "\tspeed: 0.0344s/iter; left time: 595.6494s\n",
      "\titers: 200, epoch: 23 | loss: 0.0398813\n",
      "\tspeed: 0.0158s/iter; left time: 271.4851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0416005 Vali Loss: 0.0515074 Test Loss: 0.0557361\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0419602\n",
      "\tspeed: 0.0354s/iter; left time: 604.6607s\n",
      "\titers: 200, epoch: 24 | loss: 0.0430597\n",
      "\tspeed: 0.0161s/iter; left time: 272.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0415662 Vali Loss: 0.0514777 Test Loss: 0.0557597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0399645\n",
      "\tspeed: 0.0357s/iter; left time: 601.0967s\n",
      "\titers: 200, epoch: 25 | loss: 0.0416431\n",
      "\tspeed: 0.0161s/iter; left time: 270.4881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0414937 Vali Loss: 0.0513363 Test Loss: 0.0557811\n",
      "Validation loss decreased (0.051448 --> 0.051336).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0426611\n",
      "\tspeed: 0.0378s/iter; left time: 628.9728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0409105\n",
      "\tspeed: 0.0161s/iter; left time: 265.5778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0414068 Vali Loss: 0.0513394 Test Loss: 0.0555850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0399409\n",
      "\tspeed: 0.0359s/iter; left time: 588.5061s\n",
      "\titers: 200, epoch: 27 | loss: 0.0433905\n",
      "\tspeed: 0.0161s/iter; left time: 262.1090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0413773 Vali Loss: 0.0513904 Test Loss: 0.0555711\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0399843\n",
      "\tspeed: 0.0350s/iter; left time: 566.2767s\n",
      "\titers: 200, epoch: 28 | loss: 0.0413728\n",
      "\tspeed: 0.0158s/iter; left time: 254.4915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0413183 Vali Loss: 0.0513504 Test Loss: 0.0556318\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0373408\n",
      "\tspeed: 0.0358s/iter; left time: 570.7609s\n",
      "\titers: 200, epoch: 29 | loss: 0.0431454\n",
      "\tspeed: 0.0158s/iter; left time: 250.7462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0412993 Vali Loss: 0.0513449 Test Loss: 0.0556754\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0397304\n",
      "\tspeed: 0.0351s/iter; left time: 551.7345s\n",
      "\titers: 200, epoch: 30 | loss: 0.0421205\n",
      "\tspeed: 0.0159s/iter; left time: 248.0189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0412880 Vali Loss: 0.0513688 Test Loss: 0.0555943\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0424835\n",
      "\tspeed: 0.0342s/iter; left time: 529.8174s\n",
      "\titers: 200, epoch: 31 | loss: 0.0425456\n",
      "\tspeed: 0.0158s/iter; left time: 244.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0412180 Vali Loss: 0.0513311 Test Loss: 0.0556133\n",
      "Validation loss decreased (0.051336 --> 0.051331).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0392999\n",
      "\tspeed: 0.0352s/iter; left time: 538.4016s\n",
      "\titers: 200, epoch: 32 | loss: 0.0432906\n",
      "\tspeed: 0.0158s/iter; left time: 239.5334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0412256 Vali Loss: 0.0513189 Test Loss: 0.0556509\n",
      "Validation loss decreased (0.051331 --> 0.051319).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0396141\n",
      "\tspeed: 0.0355s/iter; left time: 534.6185s\n",
      "\titers: 200, epoch: 33 | loss: 0.0428274\n",
      "\tspeed: 0.0158s/iter; left time: 236.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0412205 Vali Loss: 0.0512656 Test Loss: 0.0556395\n",
      "Validation loss decreased (0.051319 --> 0.051266).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0427225\n",
      "\tspeed: 0.0347s/iter; left time: 515.2942s\n",
      "\titers: 200, epoch: 34 | loss: 0.0381919\n",
      "\tspeed: 0.0161s/iter; left time: 237.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0411833 Vali Loss: 0.0513350 Test Loss: 0.0555940\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0443468\n",
      "\tspeed: 0.0343s/iter; left time: 500.7464s\n",
      "\titers: 200, epoch: 35 | loss: 0.0399947\n",
      "\tspeed: 0.0160s/iter; left time: 232.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0411878 Vali Loss: 0.0512880 Test Loss: 0.0556060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0449015\n",
      "\tspeed: 0.0349s/iter; left time: 503.0693s\n",
      "\titers: 200, epoch: 36 | loss: 0.0396455\n",
      "\tspeed: 0.0160s/iter; left time: 228.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0411217 Vali Loss: 0.0512513 Test Loss: 0.0556292\n",
      "Validation loss decreased (0.051266 --> 0.051251).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0443964\n",
      "\tspeed: 0.0356s/iter; left time: 504.2648s\n",
      "\titers: 200, epoch: 37 | loss: 0.0443292\n",
      "\tspeed: 0.0159s/iter; left time: 223.2491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0411408 Vali Loss: 0.0512115 Test Loss: 0.0555857\n",
      "Validation loss decreased (0.051251 --> 0.051211).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0391081\n",
      "\tspeed: 0.0356s/iter; left time: 495.9838s\n",
      "\titers: 200, epoch: 38 | loss: 0.0423499\n",
      "\tspeed: 0.0160s/iter; left time: 221.4728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 223 | Train Loss: 0.0411390 Vali Loss: 0.0512668 Test Loss: 0.0555924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0414787\n",
      "\tspeed: 0.0340s/iter; left time: 467.2193s\n",
      "\titers: 200, epoch: 39 | loss: 0.0435088\n",
      "\tspeed: 0.0158s/iter; left time: 215.0318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0411038 Vali Loss: 0.0512767 Test Loss: 0.0556082\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0434515\n",
      "\tspeed: 0.0344s/iter; left time: 464.2158s\n",
      "\titers: 200, epoch: 40 | loss: 0.0433120\n",
      "\tspeed: 0.0158s/iter; left time: 211.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0410821 Vali Loss: 0.0512964 Test Loss: 0.0555965\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0401907\n",
      "\tspeed: 0.0340s/iter; left time: 451.3104s\n",
      "\titers: 200, epoch: 41 | loss: 0.0402709\n",
      "\tspeed: 0.0158s/iter; left time: 207.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0410773 Vali Loss: 0.0512676 Test Loss: 0.0555823\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0413380\n",
      "\tspeed: 0.0336s/iter; left time: 438.3759s\n",
      "\titers: 200, epoch: 42 | loss: 0.0405632\n",
      "\tspeed: 0.0158s/iter; left time: 204.3648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0410806 Vali Loss: 0.0512996 Test Loss: 0.0555771\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0421932\n",
      "\tspeed: 0.0339s/iter; left time: 435.1602s\n",
      "\titers: 200, epoch: 43 | loss: 0.0386680\n",
      "\tspeed: 0.0158s/iter; left time: 201.2535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0410676 Vali Loss: 0.0512338 Test Loss: 0.0555654\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0420944\n",
      "\tspeed: 0.0338s/iter; left time: 426.2970s\n",
      "\titers: 200, epoch: 44 | loss: 0.0432655\n",
      "\tspeed: 0.0158s/iter; left time: 197.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0410823 Vali Loss: 0.0512685 Test Loss: 0.0555896\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0414064\n",
      "\tspeed: 0.0338s/iter; left time: 418.1352s\n",
      "\titers: 200, epoch: 45 | loss: 0.0418664\n",
      "\tspeed: 0.0158s/iter; left time: 193.7247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0410319 Vali Loss: 0.0513147 Test Loss: 0.0555856\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0381398\n",
      "\tspeed: 0.0345s/iter; left time: 419.1364s\n",
      "\titers: 200, epoch: 46 | loss: 0.0429963\n",
      "\tspeed: 0.0158s/iter; left time: 190.2647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0410216 Vali Loss: 0.0512298 Test Loss: 0.0555440\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0405284\n",
      "\tspeed: 0.0338s/iter; left time: 403.1904s\n",
      "\titers: 200, epoch: 47 | loss: 0.0465864\n",
      "\tspeed: 0.0158s/iter; left time: 187.0217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0410256 Vali Loss: 0.0511851 Test Loss: 0.0555695\n",
      "Validation loss decreased (0.051211 --> 0.051185).  Saving model ...\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0402459\n",
      "\tspeed: 0.0344s/iter; left time: 403.0601s\n",
      "\titers: 200, epoch: 48 | loss: 0.0374434\n",
      "\tspeed: 0.0158s/iter; left time: 184.0109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0410395 Vali Loss: 0.0512317 Test Loss: 0.0555677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0404923\n",
      "\tspeed: 0.0343s/iter; left time: 394.6795s\n",
      "\titers: 200, epoch: 49 | loss: 0.0433474\n",
      "\tspeed: 0.0158s/iter; left time: 180.0456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0410361 Vali Loss: 0.0512816 Test Loss: 0.0555622\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0415060\n",
      "\tspeed: 0.0342s/iter; left time: 386.1175s\n",
      "\titers: 200, epoch: 50 | loss: 0.0437148\n",
      "\tspeed: 0.0158s/iter; left time: 176.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0410606 Vali Loss: 0.0512042 Test Loss: 0.0555580\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0386717\n",
      "\tspeed: 0.0339s/iter; left time: 374.8241s\n",
      "\titers: 200, epoch: 51 | loss: 0.0425169\n",
      "\tspeed: 0.0158s/iter; left time: 172.4887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409971 Vali Loss: 0.0512497 Test Loss: 0.0555757\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0410338\n",
      "\tspeed: 0.0341s/iter; left time: 368.9091s\n",
      "\titers: 200, epoch: 52 | loss: 0.0391278\n",
      "\tspeed: 0.0159s/iter; left time: 170.1103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0410260 Vali Loss: 0.0512679 Test Loss: 0.0555562\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0408258\n",
      "\tspeed: 0.0341s/iter; left time: 361.1217s\n",
      "\titers: 200, epoch: 53 | loss: 0.0424527\n",
      "\tspeed: 0.0158s/iter; left time: 165.6909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0410108 Vali Loss: 0.0512564 Test Loss: 0.0555663\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0419571\n",
      "\tspeed: 0.0345s/iter; left time: 358.1452s\n",
      "\titers: 200, epoch: 54 | loss: 0.0428220\n",
      "\tspeed: 0.0158s/iter; left time: 162.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0410593 Vali Loss: 0.0511923 Test Loss: 0.0555763\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0421002\n",
      "\tspeed: 0.0345s/iter; left time: 349.9992s\n",
      "\titers: 200, epoch: 55 | loss: 0.0409684\n",
      "\tspeed: 0.0158s/iter; left time: 159.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0409952 Vali Loss: 0.0512294 Test Loss: 0.0555645\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0405906\n",
      "\tspeed: 0.0335s/iter; left time: 333.1904s\n",
      "\titers: 200, epoch: 56 | loss: 0.0427134\n",
      "\tspeed: 0.0158s/iter; left time: 155.8220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0410246 Vali Loss: 0.0512592 Test Loss: 0.0555599\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0386466\n",
      "\tspeed: 0.0341s/iter; left time: 331.3065s\n",
      "\titers: 200, epoch: 57 | loss: 0.0416110\n",
      "\tspeed: 0.0159s/iter; left time: 152.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0410470 Vali Loss: 0.0512369 Test Loss: 0.0555557\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010117452591657639, rmse:0.10058555006980896, mae:0.055569473654031754, rse:0.3880562484264374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1016255\n",
      "\tspeed: 0.0177s/iter; left time: 393.3920s\n",
      "\titers: 200, epoch: 1 | loss: 0.0838352\n",
      "\tspeed: 0.0158s/iter; left time: 350.1349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.1038986 Vali Loss: 0.0882190 Test Loss: 0.0965883\n",
      "Validation loss decreased (inf --> 0.088219).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0533356\n",
      "\tspeed: 0.0352s/iter; left time: 773.4714s\n",
      "\titers: 200, epoch: 2 | loss: 0.0519655\n",
      "\tspeed: 0.0158s/iter; left time: 346.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0579388 Vali Loss: 0.0591754 Test Loss: 0.0621324\n",
      "Validation loss decreased (0.088219 --> 0.059175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0509850\n",
      "\tspeed: 0.0337s/iter; left time: 732.7664s\n",
      "\titers: 200, epoch: 3 | loss: 0.0481615\n",
      "\tspeed: 0.0158s/iter; left time: 342.5198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0500037 Vali Loss: 0.0570332 Test Loss: 0.0598633\n",
      "Validation loss decreased (0.059175 --> 0.057033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0487975\n",
      "\tspeed: 0.0345s/iter; left time: 743.6273s\n",
      "\titers: 200, epoch: 4 | loss: 0.0490044\n",
      "\tspeed: 0.0158s/iter; left time: 338.4444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0479605 Vali Loss: 0.0555148 Test Loss: 0.0589177\n",
      "Validation loss decreased (0.057033 --> 0.055515).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0455757\n",
      "\tspeed: 0.0353s/iter; left time: 752.5601s\n",
      "\titers: 200, epoch: 5 | loss: 0.0503848\n",
      "\tspeed: 0.0162s/iter; left time: 343.9861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0465132 Vali Loss: 0.0544305 Test Loss: 0.0581779\n",
      "Validation loss decreased (0.055515 --> 0.054431).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0418130\n",
      "\tspeed: 0.0362s/iter; left time: 762.7391s\n",
      "\titers: 200, epoch: 6 | loss: 0.0498182\n",
      "\tspeed: 0.0163s/iter; left time: 342.6332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 223 | Train Loss: 0.0455063 Vali Loss: 0.0538291 Test Loss: 0.0575790\n",
      "Validation loss decreased (0.054431 --> 0.053829).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0449642\n",
      "\tspeed: 0.0348s/iter; left time: 725.2953s\n",
      "\titers: 200, epoch: 7 | loss: 0.0444704\n",
      "\tspeed: 0.0158s/iter; left time: 328.2545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0448453 Vali Loss: 0.0536959 Test Loss: 0.0576604\n",
      "Validation loss decreased (0.053829 --> 0.053696).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433090\n",
      "\tspeed: 0.0338s/iter; left time: 698.4587s\n",
      "\titers: 200, epoch: 8 | loss: 0.0400839\n",
      "\tspeed: 0.0158s/iter; left time: 325.4762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0442233 Vali Loss: 0.0530859 Test Loss: 0.0570014\n",
      "Validation loss decreased (0.053696 --> 0.053086).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0434766\n",
      "\tspeed: 0.0338s/iter; left time: 690.6845s\n",
      "\titers: 200, epoch: 9 | loss: 0.0468716\n",
      "\tspeed: 0.0159s/iter; left time: 322.1088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0437940 Vali Loss: 0.0527717 Test Loss: 0.0569588\n",
      "Validation loss decreased (0.053086 --> 0.052772).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0439353\n",
      "\tspeed: 0.0336s/iter; left time: 678.8567s\n",
      "\titers: 200, epoch: 10 | loss: 0.0435405\n",
      "\tspeed: 0.0158s/iter; left time: 316.9108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0434302 Vali Loss: 0.0524914 Test Loss: 0.0565410\n",
      "Validation loss decreased (0.052772 --> 0.052491).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0430079\n",
      "\tspeed: 0.0343s/iter; left time: 685.5431s\n",
      "\titers: 200, epoch: 11 | loss: 0.0469641\n",
      "\tspeed: 0.0158s/iter; left time: 314.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0431631 Vali Loss: 0.0524883 Test Loss: 0.0567408\n",
      "Validation loss decreased (0.052491 --> 0.052488).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0426147\n",
      "\tspeed: 0.0350s/iter; left time: 691.2089s\n",
      "\titers: 200, epoch: 12 | loss: 0.0439647\n",
      "\tspeed: 0.0159s/iter; left time: 311.9145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0429642 Vali Loss: 0.0521677 Test Loss: 0.0561768\n",
      "Validation loss decreased (0.052488 --> 0.052168).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0438134\n",
      "\tspeed: 0.0337s/iter; left time: 658.9541s\n",
      "\titers: 200, epoch: 13 | loss: 0.0434642\n",
      "\tspeed: 0.0158s/iter; left time: 306.7574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0426851 Vali Loss: 0.0521223 Test Loss: 0.0565209\n",
      "Validation loss decreased (0.052168 --> 0.052122).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0422469\n",
      "\tspeed: 0.0337s/iter; left time: 650.9205s\n",
      "\titers: 200, epoch: 14 | loss: 0.0429672\n",
      "\tspeed: 0.0158s/iter; left time: 303.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0425556 Vali Loss: 0.0519145 Test Loss: 0.0562044\n",
      "Validation loss decreased (0.052122 --> 0.051914).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0404917\n",
      "\tspeed: 0.0336s/iter; left time: 640.6860s\n",
      "\titers: 200, epoch: 15 | loss: 0.0406948\n",
      "\tspeed: 0.0158s/iter; left time: 300.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0423611 Vali Loss: 0.0519287 Test Loss: 0.0562382\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0445466\n",
      "\tspeed: 0.0333s/iter; left time: 628.2264s\n",
      "\titers: 200, epoch: 16 | loss: 0.0451075\n",
      "\tspeed: 0.0158s/iter; left time: 296.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0421966 Vali Loss: 0.0516925 Test Loss: 0.0560583\n",
      "Validation loss decreased (0.051914 --> 0.051693).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0428128\n",
      "\tspeed: 0.0336s/iter; left time: 625.5479s\n",
      "\titers: 200, epoch: 17 | loss: 0.0419480\n",
      "\tspeed: 0.0158s/iter; left time: 292.8390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0419945 Vali Loss: 0.0518120 Test Loss: 0.0561096\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0418663\n",
      "\tspeed: 0.0334s/iter; left time: 615.7434s\n",
      "\titers: 200, epoch: 18 | loss: 0.0446099\n",
      "\tspeed: 0.0158s/iter; left time: 289.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0419429 Vali Loss: 0.0516119 Test Loss: 0.0560771\n",
      "Validation loss decreased (0.051693 --> 0.051612).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0460792\n",
      "\tspeed: 0.0341s/iter; left time: 620.3301s\n",
      "\titers: 200, epoch: 19 | loss: 0.0394440\n",
      "\tspeed: 0.0159s/iter; left time: 286.7734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0418446 Vali Loss: 0.0516175 Test Loss: 0.0559939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0407458\n",
      "\tspeed: 0.0333s/iter; left time: 599.0941s\n",
      "\titers: 200, epoch: 20 | loss: 0.0417658\n",
      "\tspeed: 0.0159s/iter; left time: 283.4599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0416996 Vali Loss: 0.0517122 Test Loss: 0.0558792\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0426546\n",
      "\tspeed: 0.0334s/iter; left time: 593.1339s\n",
      "\titers: 200, epoch: 21 | loss: 0.0427783\n",
      "\tspeed: 0.0158s/iter; left time: 279.4939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0416690 Vali Loss: 0.0516044 Test Loss: 0.0557602\n",
      "Validation loss decreased (0.051612 --> 0.051604).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0430880\n",
      "\tspeed: 0.0339s/iter; left time: 593.3296s\n",
      "\titers: 200, epoch: 22 | loss: 0.0419164\n",
      "\tspeed: 0.0158s/iter; left time: 275.5173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0415451 Vali Loss: 0.0514597 Test Loss: 0.0559783\n",
      "Validation loss decreased (0.051604 --> 0.051460).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0438980\n",
      "\tspeed: 0.0339s/iter; left time: 586.7398s\n",
      "\titers: 200, epoch: 23 | loss: 0.0398928\n",
      "\tspeed: 0.0158s/iter; left time: 272.1952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0414963 Vali Loss: 0.0514372 Test Loss: 0.0557630\n",
      "Validation loss decreased (0.051460 --> 0.051437).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0402959\n",
      "\tspeed: 0.0339s/iter; left time: 578.9162s\n",
      "\titers: 200, epoch: 24 | loss: 0.0451689\n",
      "\tspeed: 0.0158s/iter; left time: 268.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0414606 Vali Loss: 0.0514894 Test Loss: 0.0556908\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0401783\n",
      "\tspeed: 0.0341s/iter; left time: 574.7419s\n",
      "\titers: 200, epoch: 25 | loss: 0.0403398\n",
      "\tspeed: 0.0159s/iter; left time: 265.8841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0414147 Vali Loss: 0.0514340 Test Loss: 0.0556621\n",
      "Validation loss decreased (0.051437 --> 0.051434).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0396113\n",
      "\tspeed: 0.0338s/iter; left time: 561.7029s\n",
      "\titers: 200, epoch: 26 | loss: 0.0400556\n",
      "\tspeed: 0.0158s/iter; left time: 261.1763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0413243 Vali Loss: 0.0513320 Test Loss: 0.0555667\n",
      "Validation loss decreased (0.051434 --> 0.051332).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0419835\n",
      "\tspeed: 0.0337s/iter; left time: 553.2738s\n",
      "\titers: 200, epoch: 27 | loss: 0.0400179\n",
      "\tspeed: 0.0158s/iter; left time: 257.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0413216 Vali Loss: 0.0513787 Test Loss: 0.0556238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0416513\n",
      "\tspeed: 0.0338s/iter; left time: 546.5657s\n",
      "\titers: 200, epoch: 28 | loss: 0.0426979\n",
      "\tspeed: 0.0158s/iter; left time: 253.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0412329 Vali Loss: 0.0514208 Test Loss: 0.0556222\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0391097\n",
      "\tspeed: 0.0353s/iter; left time: 563.2866s\n",
      "\titers: 200, epoch: 29 | loss: 0.0410694\n",
      "\tspeed: 0.0158s/iter; left time: 250.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0412458 Vali Loss: 0.0512832 Test Loss: 0.0556637\n",
      "Validation loss decreased (0.051332 --> 0.051283).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0409140\n",
      "\tspeed: 0.0348s/iter; left time: 547.0549s\n",
      "\titers: 200, epoch: 30 | loss: 0.0394320\n",
      "\tspeed: 0.0158s/iter; left time: 246.4470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0411853 Vali Loss: 0.0513306 Test Loss: 0.0556755\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0430662\n",
      "\tspeed: 0.0347s/iter; left time: 537.9685s\n",
      "\titers: 200, epoch: 31 | loss: 0.0422118\n",
      "\tspeed: 0.0158s/iter; left time: 243.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0411678 Vali Loss: 0.0513212 Test Loss: 0.0555797\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0418563\n",
      "\tspeed: 0.0333s/iter; left time: 509.6844s\n",
      "\titers: 200, epoch: 32 | loss: 0.0418435\n",
      "\tspeed: 0.0158s/iter; left time: 239.9345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0411544 Vali Loss: 0.0513621 Test Loss: 0.0556410\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0407957\n",
      "\tspeed: 0.0334s/iter; left time: 503.2511s\n",
      "\titers: 200, epoch: 33 | loss: 0.0400570\n",
      "\tspeed: 0.0158s/iter; left time: 236.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0411219 Vali Loss: 0.0512870 Test Loss: 0.0555747\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0394739\n",
      "\tspeed: 0.0335s/iter; left time: 497.1166s\n",
      "\titers: 200, epoch: 34 | loss: 0.0402601\n",
      "\tspeed: 0.0159s/iter; left time: 233.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0411078 Vali Loss: 0.0512565 Test Loss: 0.0555929\n",
      "Validation loss decreased (0.051283 --> 0.051256).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0384507\n",
      "\tspeed: 0.0336s/iter; left time: 490.5310s\n",
      "\titers: 200, epoch: 35 | loss: 0.0391426\n",
      "\tspeed: 0.0158s/iter; left time: 229.3029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0410747 Vali Loss: 0.0513052 Test Loss: 0.0555846\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0407484\n",
      "\tspeed: 0.0334s/iter; left time: 480.7977s\n",
      "\titers: 200, epoch: 36 | loss: 0.0422202\n",
      "\tspeed: 0.0158s/iter; left time: 226.4038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0410390 Vali Loss: 0.0512695 Test Loss: 0.0555414\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0403228\n",
      "\tspeed: 0.0333s/iter; left time: 472.4181s\n",
      "\titers: 200, epoch: 37 | loss: 0.0391431\n",
      "\tspeed: 0.0158s/iter; left time: 222.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0410311 Vali Loss: 0.0512405 Test Loss: 0.0555319\n",
      "Validation loss decreased (0.051256 --> 0.051241).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0412446\n",
      "\tspeed: 0.0336s/iter; left time: 469.3091s\n",
      "\titers: 200, epoch: 38 | loss: 0.0439908\n",
      "\tspeed: 0.0159s/iter; left time: 219.6239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0410129 Vali Loss: 0.0512428 Test Loss: 0.0555413\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0375529\n",
      "\tspeed: 0.0332s/iter; left time: 455.8844s\n",
      "\titers: 200, epoch: 39 | loss: 0.0408200\n",
      "\tspeed: 0.0158s/iter; left time: 214.8730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0410009 Vali Loss: 0.0512831 Test Loss: 0.0556086\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0377521\n",
      "\tspeed: 0.0342s/iter; left time: 462.2790s\n",
      "\titers: 200, epoch: 40 | loss: 0.0406466\n",
      "\tspeed: 0.0158s/iter; left time: 212.1581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0410451 Vali Loss: 0.0512533 Test Loss: 0.0555394\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0423588\n",
      "\tspeed: 0.0332s/iter; left time: 441.1370s\n",
      "\titers: 200, epoch: 41 | loss: 0.0378717\n",
      "\tspeed: 0.0158s/iter; left time: 208.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409878 Vali Loss: 0.0513038 Test Loss: 0.0555176\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0394336\n",
      "\tspeed: 0.0332s/iter; left time: 433.7289s\n",
      "\titers: 200, epoch: 42 | loss: 0.0395236\n",
      "\tspeed: 0.0158s/iter; left time: 204.8999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409494 Vali Loss: 0.0512754 Test Loss: 0.0555517\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0394683\n",
      "\tspeed: 0.0333s/iter; left time: 426.9560s\n",
      "\titers: 200, epoch: 43 | loss: 0.0377219\n",
      "\tspeed: 0.0158s/iter; left time: 201.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409939 Vali Loss: 0.0512398 Test Loss: 0.0555495\n",
      "Validation loss decreased (0.051241 --> 0.051240).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0417308\n",
      "\tspeed: 0.0340s/iter; left time: 429.0376s\n",
      "\titers: 200, epoch: 44 | loss: 0.0415252\n",
      "\tspeed: 0.0158s/iter; left time: 197.9043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409804 Vali Loss: 0.0512563 Test Loss: 0.0555381\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0413126\n",
      "\tspeed: 0.0334s/iter; left time: 413.9782s\n",
      "\titers: 200, epoch: 45 | loss: 0.0408744\n",
      "\tspeed: 0.0158s/iter; left time: 194.1230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409424 Vali Loss: 0.0512181 Test Loss: 0.0555134\n",
      "Validation loss decreased (0.051240 --> 0.051218).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0388747\n",
      "\tspeed: 0.0341s/iter; left time: 415.0836s\n",
      "\titers: 200, epoch: 46 | loss: 0.0410515\n",
      "\tspeed: 0.0159s/iter; left time: 191.2588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409544 Vali Loss: 0.0512244 Test Loss: 0.0555258\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0413459\n",
      "\tspeed: 0.0332s/iter; left time: 396.7968s\n",
      "\titers: 200, epoch: 47 | loss: 0.0423692\n",
      "\tspeed: 0.0158s/iter; left time: 187.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409373 Vali Loss: 0.0512903 Test Loss: 0.0555143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0440530\n",
      "\tspeed: 0.0335s/iter; left time: 392.5492s\n",
      "\titers: 200, epoch: 48 | loss: 0.0391196\n",
      "\tspeed: 0.0158s/iter; left time: 183.3345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409770 Vali Loss: 0.0512277 Test Loss: 0.0555383\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0406355\n",
      "\tspeed: 0.0332s/iter; left time: 382.0337s\n",
      "\titers: 200, epoch: 49 | loss: 0.0435964\n",
      "\tspeed: 0.0158s/iter; left time: 179.6923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409814 Vali Loss: 0.0512162 Test Loss: 0.0555290\n",
      "Validation loss decreased (0.051218 --> 0.051216).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0420103\n",
      "\tspeed: 0.0335s/iter; left time: 378.1353s\n",
      "\titers: 200, epoch: 50 | loss: 0.0437940\n",
      "\tspeed: 0.0158s/iter; left time: 176.8136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409543 Vali Loss: 0.0512655 Test Loss: 0.0555116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0370449\n",
      "\tspeed: 0.0346s/iter; left time: 382.7895s\n",
      "\titers: 200, epoch: 51 | loss: 0.0424271\n",
      "\tspeed: 0.0163s/iter; left time: 178.5876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 223 | Train Loss: 0.0409507 Vali Loss: 0.0512297 Test Loss: 0.0555262\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0378710\n",
      "\tspeed: 0.0351s/iter; left time: 379.9565s\n",
      "\titers: 200, epoch: 52 | loss: 0.0394271\n",
      "\tspeed: 0.0160s/iter; left time: 171.8656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0408929 Vali Loss: 0.0512688 Test Loss: 0.0555152\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0418024\n",
      "\tspeed: 0.0350s/iter; left time: 371.1398s\n",
      "\titers: 200, epoch: 53 | loss: 0.0423576\n",
      "\tspeed: 0.0158s/iter; left time: 165.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0409118 Vali Loss: 0.0511948 Test Loss: 0.0555222\n",
      "Validation loss decreased (0.051216 --> 0.051195).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0429354\n",
      "\tspeed: 0.0340s/iter; left time: 352.8537s\n",
      "\titers: 200, epoch: 54 | loss: 0.0409159\n",
      "\tspeed: 0.0159s/iter; left time: 163.2883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0409544 Vali Loss: 0.0512326 Test Loss: 0.0555248\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0415118\n",
      "\tspeed: 0.0338s/iter; left time: 343.7516s\n",
      "\titers: 200, epoch: 55 | loss: 0.0423684\n",
      "\tspeed: 0.0159s/iter; left time: 159.6166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0409551 Vali Loss: 0.0512283 Test Loss: 0.0555104\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0414411\n",
      "\tspeed: 0.0334s/iter; left time: 331.8384s\n",
      "\titers: 200, epoch: 56 | loss: 0.0409673\n",
      "\tspeed: 0.0158s/iter; left time: 155.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0409518 Vali Loss: 0.0512707 Test Loss: 0.0555068\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0393366\n",
      "\tspeed: 0.0332s/iter; left time: 322.2119s\n",
      "\titers: 200, epoch: 57 | loss: 0.0385716\n",
      "\tspeed: 0.0158s/iter; left time: 151.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409637 Vali Loss: 0.0512726 Test Loss: 0.0555079\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0430532\n",
      "\tspeed: 0.0347s/iter; left time: 329.7363s\n",
      "\titers: 200, epoch: 58 | loss: 0.0420994\n",
      "\tspeed: 0.0159s/iter; left time: 148.9987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0409240 Vali Loss: 0.0512268 Test Loss: 0.0554990\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0426919\n",
      "\tspeed: 0.0337s/iter; left time: 311.8533s\n",
      "\titers: 200, epoch: 59 | loss: 0.0391602\n",
      "\tspeed: 0.0159s/iter; left time: 145.3445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0409162 Vali Loss: 0.0512607 Test Loss: 0.0555028\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0411180\n",
      "\tspeed: 0.0333s/iter; left time: 300.9269s\n",
      "\titers: 200, epoch: 60 | loss: 0.0371820\n",
      "\tspeed: 0.0158s/iter; left time: 141.1910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409325 Vali Loss: 0.0511890 Test Loss: 0.0555132\n",
      "Validation loss decreased (0.051195 --> 0.051189).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0423414\n",
      "\tspeed: 0.0336s/iter; left time: 296.6302s\n",
      "\titers: 200, epoch: 61 | loss: 0.0424808\n",
      "\tspeed: 0.0158s/iter; left time: 137.8965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409312 Vali Loss: 0.0511977 Test Loss: 0.0555149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0410725\n",
      "\tspeed: 0.0332s/iter; left time: 285.2412s\n",
      "\titers: 200, epoch: 62 | loss: 0.0416605\n",
      "\tspeed: 0.0158s/iter; left time: 134.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409479 Vali Loss: 0.0512809 Test Loss: 0.0555132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0413201\n",
      "\tspeed: 0.0332s/iter; left time: 277.6383s\n",
      "\titers: 200, epoch: 63 | loss: 0.0452777\n",
      "\tspeed: 0.0158s/iter; left time: 130.6497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409039 Vali Loss: 0.0513105 Test Loss: 0.0555127\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0417753\n",
      "\tspeed: 0.0335s/iter; left time: 272.7699s\n",
      "\titers: 200, epoch: 64 | loss: 0.0391523\n",
      "\tspeed: 0.0159s/iter; left time: 127.7121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0408937 Vali Loss: 0.0512243 Test Loss: 0.0555111\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0389973\n",
      "\tspeed: 0.0333s/iter; left time: 263.7321s\n",
      "\titers: 200, epoch: 65 | loss: 0.0408901\n",
      "\tspeed: 0.0158s/iter; left time: 123.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409149 Vali Loss: 0.0512483 Test Loss: 0.0555184\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0414115\n",
      "\tspeed: 0.0333s/iter; left time: 256.6409s\n",
      "\titers: 200, epoch: 66 | loss: 0.0405998\n",
      "\tspeed: 0.0158s/iter; left time: 119.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409546 Vali Loss: 0.0511339 Test Loss: 0.0555134\n",
      "Validation loss decreased (0.051189 --> 0.051134).  Saving model ...\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0387884\n",
      "\tspeed: 0.0334s/iter; left time: 250.3008s\n",
      "\titers: 200, epoch: 67 | loss: 0.0416901\n",
      "\tspeed: 0.0158s/iter; left time: 116.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0408856 Vali Loss: 0.0512888 Test Loss: 0.0555100\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0417796\n",
      "\tspeed: 0.0331s/iter; left time: 240.0694s\n",
      "\titers: 200, epoch: 68 | loss: 0.0401028\n",
      "\tspeed: 0.0158s/iter; left time: 112.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409174 Vali Loss: 0.0512354 Test Loss: 0.0555087\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0425693\n",
      "\tspeed: 0.0333s/iter; left time: 234.3284s\n",
      "\titers: 200, epoch: 69 | loss: 0.0399520\n",
      "\tspeed: 0.0158s/iter; left time: 109.9394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0408981 Vali Loss: 0.0512228 Test Loss: 0.0555117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0394891\n",
      "\tspeed: 0.0334s/iter; left time: 227.8457s\n",
      "\titers: 200, epoch: 70 | loss: 0.0415780\n",
      "\tspeed: 0.0158s/iter; left time: 106.2675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409041 Vali Loss: 0.0511617 Test Loss: 0.0555145\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0431448\n",
      "\tspeed: 0.0336s/iter; left time: 221.2188s\n",
      "\titers: 200, epoch: 71 | loss: 0.0398277\n",
      "\tspeed: 0.0158s/iter; left time: 102.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0409084 Vali Loss: 0.0511817 Test Loss: 0.0554925\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.735540101454298e-08\n",
      "\titers: 100, epoch: 72 | loss: 0.0407875\n",
      "\tspeed: 0.0334s/iter; left time: 212.8616s\n",
      "\titers: 200, epoch: 72 | loss: 0.0396075\n",
      "\tspeed: 0.0158s/iter; left time: 98.9802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 72\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0409291 Vali Loss: 0.0512321 Test Loss: 0.0555127\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.961986091308869e-08\n",
      "\titers: 100, epoch: 73 | loss: 0.0437903\n",
      "\tspeed: 0.0335s/iter; left time: 205.6572s\n",
      "\titers: 200, epoch: 73 | loss: 0.0409102\n",
      "\tspeed: 0.0158s/iter; left time: 95.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 73\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409257 Vali Loss: 0.0512419 Test Loss: 0.0555183\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.265787482177981e-08\n",
      "\titers: 100, epoch: 74 | loss: 0.0458577\n",
      "\tspeed: 0.0331s/iter; left time: 196.1170s\n",
      "\titers: 200, epoch: 74 | loss: 0.0408866\n",
      "\tspeed: 0.0158s/iter; left time: 91.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 74\n",
      "Cost time: 00h:00m:03.71s\n",
      "Steps: 223 | Train Loss: 0.0409089 Vali Loss: 0.0512293 Test Loss: 0.0555160\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.639208733960184e-08\n",
      "\titers: 100, epoch: 75 | loss: 0.0417416\n",
      "\tspeed: 0.0335s/iter; left time: 190.7443s\n",
      "\titers: 200, epoch: 75 | loss: 0.0402629\n",
      "\tspeed: 0.0158s/iter; left time: 88.6717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 75\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0409208 Vali Loss: 0.0512512 Test Loss: 0.0555153\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.075287860564165e-08\n",
      "\titers: 100, epoch: 76 | loss: 0.0412015\n",
      "\tspeed: 0.0336s/iter; left time: 183.9870s\n",
      "\titers: 200, epoch: 76 | loss: 0.0413445\n",
      "\tspeed: 0.0158s/iter; left time: 84.9933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 76\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0408446 Vali Loss: 0.0512477 Test Loss: 0.0555011\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_24_FR_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010079373605549335, rmse:0.10039608180522919, mae:0.055513396859169006, rse:0.38732531666755676\n",
      "Intermediate time for FR and pred_len 24: 00h:11m:13.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1062729\n",
      "\tspeed: 0.0365s/iter; left time: 806.8732s\n",
      "\titers: 200, epoch: 1 | loss: 0.0912535\n",
      "\tspeed: 0.0160s/iter; left time: 351.6495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.1059553 Vali Loss: 0.0940188 Test Loss: 0.1034623\n",
      "Validation loss decreased (inf --> 0.094019).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0692657\n",
      "\tspeed: 0.0351s/iter; left time: 768.7067s\n",
      "\titers: 200, epoch: 2 | loss: 0.0679127\n",
      "\tspeed: 0.0159s/iter; left time: 347.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0712136 Vali Loss: 0.0755337 Test Loss: 0.0831639\n",
      "Validation loss decreased (0.094019 --> 0.075534).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0644198\n",
      "\tspeed: 0.0352s/iter; left time: 763.3401s\n",
      "\titers: 200, epoch: 3 | loss: 0.0641778\n",
      "\tspeed: 0.0160s/iter; left time: 344.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0641186 Vali Loss: 0.0729066 Test Loss: 0.0819365\n",
      "Validation loss decreased (0.075534 --> 0.072907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0631415\n",
      "\tspeed: 0.0353s/iter; left time: 755.9159s\n",
      "\titers: 200, epoch: 4 | loss: 0.0631826\n",
      "\tspeed: 0.0160s/iter; left time: 341.9250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0622656 Vali Loss: 0.0719733 Test Loss: 0.0818505\n",
      "Validation loss decreased (0.072907 --> 0.071973).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0571297\n",
      "\tspeed: 0.0350s/iter; left time: 742.6608s\n",
      "\titers: 200, epoch: 5 | loss: 0.0588143\n",
      "\tspeed: 0.0160s/iter; left time: 338.6782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0612333 Vali Loss: 0.0714952 Test Loss: 0.0811877\n",
      "Validation loss decreased (0.071973 --> 0.071495).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595467\n",
      "\tspeed: 0.0357s/iter; left time: 748.3316s\n",
      "\titers: 200, epoch: 6 | loss: 0.0609350\n",
      "\tspeed: 0.0160s/iter; left time: 335.1316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0604214 Vali Loss: 0.0708795 Test Loss: 0.0811347\n",
      "Validation loss decreased (0.071495 --> 0.070879).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608792\n",
      "\tspeed: 0.0357s/iter; left time: 740.7598s\n",
      "\titers: 200, epoch: 7 | loss: 0.0585211\n",
      "\tspeed: 0.0161s/iter; left time: 332.0287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0597737 Vali Loss: 0.0705817 Test Loss: 0.0810214\n",
      "Validation loss decreased (0.070879 --> 0.070582).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0610314\n",
      "\tspeed: 0.0356s/iter; left time: 731.3735s\n",
      "\titers: 200, epoch: 8 | loss: 0.0618555\n",
      "\tspeed: 0.0160s/iter; left time: 327.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0592500 Vali Loss: 0.0704232 Test Loss: 0.0813442\n",
      "Validation loss decreased (0.070582 --> 0.070423).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0571530\n",
      "\tspeed: 0.0368s/iter; left time: 748.0885s\n",
      "\titers: 200, epoch: 9 | loss: 0.0578120\n",
      "\tspeed: 0.0161s/iter; left time: 324.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0587209 Vali Loss: 0.0699692 Test Loss: 0.0809877\n",
      "Validation loss decreased (0.070423 --> 0.069969).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548690\n",
      "\tspeed: 0.0349s/iter; left time: 701.5960s\n",
      "\titers: 200, epoch: 10 | loss: 0.0623343\n",
      "\tspeed: 0.0160s/iter; left time: 320.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0583109 Vali Loss: 0.0701566 Test Loss: 0.0808541\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0622497\n",
      "\tspeed: 0.0348s/iter; left time: 691.6101s\n",
      "\titers: 200, epoch: 11 | loss: 0.0519874\n",
      "\tspeed: 0.0160s/iter; left time: 316.9649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0579716 Vali Loss: 0.0699671 Test Loss: 0.0806739\n",
      "Validation loss decreased (0.069969 --> 0.069967).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0575550\n",
      "\tspeed: 0.0351s/iter; left time: 690.6728s\n",
      "\titers: 200, epoch: 12 | loss: 0.0585573\n",
      "\tspeed: 0.0160s/iter; left time: 313.5495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0576525 Vali Loss: 0.0699727 Test Loss: 0.0805810\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0560351\n",
      "\tspeed: 0.0358s/iter; left time: 696.3795s\n",
      "\titers: 200, epoch: 13 | loss: 0.0602073\n",
      "\tspeed: 0.0160s/iter; left time: 309.7755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0573944 Vali Loss: 0.0700975 Test Loss: 0.0805544\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0595173\n",
      "\tspeed: 0.0349s/iter; left time: 670.6117s\n",
      "\titers: 200, epoch: 14 | loss: 0.0593522\n",
      "\tspeed: 0.0161s/iter; left time: 307.1356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0570652 Vali Loss: 0.0699457 Test Loss: 0.0812258\n",
      "Validation loss decreased (0.069967 --> 0.069946).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574924\n",
      "\tspeed: 0.0352s/iter; left time: 668.7082s\n",
      "\titers: 200, epoch: 15 | loss: 0.0550430\n",
      "\tspeed: 0.0160s/iter; left time: 302.2274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0568423 Vali Loss: 0.0700274 Test Loss: 0.0809713\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0535070\n",
      "\tspeed: 0.0351s/iter; left time: 658.4929s\n",
      "\titers: 200, epoch: 16 | loss: 0.0542754\n",
      "\tspeed: 0.0160s/iter; left time: 299.4746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0566337 Vali Loss: 0.0701664 Test Loss: 0.0816400\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0580005\n",
      "\tspeed: 0.0349s/iter; left time: 647.2946s\n",
      "\titers: 200, epoch: 17 | loss: 0.0568877\n",
      "\tspeed: 0.0160s/iter; left time: 294.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0564597 Vali Loss: 0.0703682 Test Loss: 0.0816390\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0549882\n",
      "\tspeed: 0.0349s/iter; left time: 639.0717s\n",
      "\titers: 200, epoch: 18 | loss: 0.0590507\n",
      "\tspeed: 0.0160s/iter; left time: 292.4638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0562345 Vali Loss: 0.0703658 Test Loss: 0.0810546\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550113\n",
      "\tspeed: 0.0347s/iter; left time: 628.4493s\n",
      "\titers: 200, epoch: 19 | loss: 0.0547352\n",
      "\tspeed: 0.0161s/iter; left time: 288.9976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0560780 Vali Loss: 0.0702507 Test Loss: 0.0813001\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0533842\n",
      "\tspeed: 0.0351s/iter; left time: 627.7226s\n",
      "\titers: 200, epoch: 20 | loss: 0.0574151\n",
      "\tspeed: 0.0160s/iter; left time: 283.8915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0559371 Vali Loss: 0.0704959 Test Loss: 0.0815710\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0555232\n",
      "\tspeed: 0.0348s/iter; left time: 615.2357s\n",
      "\titers: 200, epoch: 21 | loss: 0.0537505\n",
      "\tspeed: 0.0160s/iter; left time: 281.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0557673 Vali Loss: 0.0703999 Test Loss: 0.0813136\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0557698\n",
      "\tspeed: 0.0351s/iter; left time: 612.0855s\n",
      "\titers: 200, epoch: 22 | loss: 0.0531113\n",
      "\tspeed: 0.0160s/iter; left time: 278.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0556477 Vali Loss: 0.0705612 Test Loss: 0.0815532\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0550038\n",
      "\tspeed: 0.0347s/iter; left time: 597.8174s\n",
      "\titers: 200, epoch: 23 | loss: 0.0560861\n",
      "\tspeed: 0.0160s/iter; left time: 274.1707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0555682 Vali Loss: 0.0705549 Test Loss: 0.0812347\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0558360\n",
      "\tspeed: 0.0347s/iter; left time: 590.5458s\n",
      "\titers: 200, epoch: 24 | loss: 0.0585479\n",
      "\tspeed: 0.0160s/iter; left time: 270.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0554437 Vali Loss: 0.0707379 Test Loss: 0.0815306\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01962335966527462, rmse:0.1400834023952484, mae:0.08122573792934418, rse:0.5418798327445984\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1122292\n",
      "\tspeed: 0.0181s/iter; left time: 399.1893s\n",
      "\titers: 200, epoch: 1 | loss: 0.0946616\n",
      "\tspeed: 0.0160s/iter; left time: 353.1094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.1112033 Vali Loss: 0.0965449 Test Loss: 0.1060960\n",
      "Validation loss decreased (inf --> 0.096545).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0716812\n",
      "\tspeed: 0.0348s/iter; left time: 762.1809s\n",
      "\titers: 200, epoch: 2 | loss: 0.0678015\n",
      "\tspeed: 0.0160s/iter; left time: 349.3139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0718552 Vali Loss: 0.0762111 Test Loss: 0.0835712\n",
      "Validation loss decreased (0.096545 --> 0.076211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0646288\n",
      "\tspeed: 0.0348s/iter; left time: 754.1339s\n",
      "\titers: 200, epoch: 3 | loss: 0.0646458\n",
      "\tspeed: 0.0160s/iter; left time: 345.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0646718 Vali Loss: 0.0732805 Test Loss: 0.0822283\n",
      "Validation loss decreased (0.076211 --> 0.073281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0640724\n",
      "\tspeed: 0.0357s/iter; left time: 765.2887s\n",
      "\titers: 200, epoch: 4 | loss: 0.0588711\n",
      "\tspeed: 0.0160s/iter; left time: 341.2069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0624607 Vali Loss: 0.0727846 Test Loss: 0.0814630\n",
      "Validation loss decreased (0.073281 --> 0.072785).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0624945\n",
      "\tspeed: 0.0353s/iter; left time: 749.4405s\n",
      "\titers: 200, epoch: 5 | loss: 0.0596167\n",
      "\tspeed: 0.0160s/iter; left time: 338.7523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0612830 Vali Loss: 0.0714983 Test Loss: 0.0808075\n",
      "Validation loss decreased (0.072785 --> 0.071498).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0595007\n",
      "\tspeed: 0.0350s/iter; left time: 734.0820s\n",
      "\titers: 200, epoch: 6 | loss: 0.0618312\n",
      "\tspeed: 0.0160s/iter; left time: 335.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0604304 Vali Loss: 0.0709713 Test Loss: 0.0807888\n",
      "Validation loss decreased (0.071498 --> 0.070971).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0616037\n",
      "\tspeed: 0.0348s/iter; left time: 722.1387s\n",
      "\titers: 200, epoch: 7 | loss: 0.0620479\n",
      "\tspeed: 0.0160s/iter; left time: 330.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0597976 Vali Loss: 0.0706447 Test Loss: 0.0805795\n",
      "Validation loss decreased (0.070971 --> 0.070645).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0609257\n",
      "\tspeed: 0.0348s/iter; left time: 715.7887s\n",
      "\titers: 200, epoch: 8 | loss: 0.0603080\n",
      "\tspeed: 0.0161s/iter; left time: 328.5238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0592158 Vali Loss: 0.0704229 Test Loss: 0.0809683\n",
      "Validation loss decreased (0.070645 --> 0.070423).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0557252\n",
      "\tspeed: 0.0353s/iter; left time: 718.0947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0630149\n",
      "\tspeed: 0.0160s/iter; left time: 324.5274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0587712 Vali Loss: 0.0702808 Test Loss: 0.0807810\n",
      "Validation loss decreased (0.070423 --> 0.070281).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0599275\n",
      "\tspeed: 0.0348s/iter; left time: 699.2417s\n",
      "\titers: 200, epoch: 10 | loss: 0.0553082\n",
      "\tspeed: 0.0160s/iter; left time: 320.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0584179 Vali Loss: 0.0699955 Test Loss: 0.0802009\n",
      "Validation loss decreased (0.070281 --> 0.069995).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0578092\n",
      "\tspeed: 0.0349s/iter; left time: 693.6055s\n",
      "\titers: 200, epoch: 11 | loss: 0.0525841\n",
      "\tspeed: 0.0160s/iter; left time: 316.5516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0579987 Vali Loss: 0.0698137 Test Loss: 0.0806228\n",
      "Validation loss decreased (0.069995 --> 0.069814).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0572381\n",
      "\tspeed: 0.0348s/iter; left time: 683.8187s\n",
      "\titers: 200, epoch: 12 | loss: 0.0555238\n",
      "\tspeed: 0.0160s/iter; left time: 312.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0576806 Vali Loss: 0.0701003 Test Loss: 0.0802513\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0560792\n",
      "\tspeed: 0.0345s/iter; left time: 670.2258s\n",
      "\titers: 200, epoch: 13 | loss: 0.0574737\n",
      "\tspeed: 0.0160s/iter; left time: 309.6218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0574025 Vali Loss: 0.0700787 Test Loss: 0.0806821\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0577715\n",
      "\tspeed: 0.0349s/iter; left time: 671.3173s\n",
      "\titers: 200, epoch: 14 | loss: 0.0561642\n",
      "\tspeed: 0.0160s/iter; left time: 306.1015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0571215 Vali Loss: 0.0701057 Test Loss: 0.0807799\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0555706\n",
      "\tspeed: 0.0342s/iter; left time: 648.6584s\n",
      "\titers: 200, epoch: 15 | loss: 0.0565401\n",
      "\tspeed: 0.0160s/iter; left time: 301.5858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0568968 Vali Loss: 0.0700795 Test Loss: 0.0803867\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0565411\n",
      "\tspeed: 0.0346s/iter; left time: 649.0108s\n",
      "\titers: 200, epoch: 16 | loss: 0.0561443\n",
      "\tspeed: 0.0160s/iter; left time: 298.7292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0567084 Vali Loss: 0.0701772 Test Loss: 0.0807520\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0608105\n",
      "\tspeed: 0.0347s/iter; left time: 642.8904s\n",
      "\titers: 200, epoch: 17 | loss: 0.0540559\n",
      "\tspeed: 0.0160s/iter; left time: 295.4696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0564278 Vali Loss: 0.0701747 Test Loss: 0.0809684\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0556518\n",
      "\tspeed: 0.0345s/iter; left time: 631.7513s\n",
      "\titers: 200, epoch: 18 | loss: 0.0570807\n",
      "\tspeed: 0.0161s/iter; left time: 292.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0563473 Vali Loss: 0.0703987 Test Loss: 0.0810388\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0550060\n",
      "\tspeed: 0.0346s/iter; left time: 625.8752s\n",
      "\titers: 200, epoch: 19 | loss: 0.0567594\n",
      "\tspeed: 0.0161s/iter; left time: 289.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0560786 Vali Loss: 0.0702187 Test Loss: 0.0806400\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0527730\n",
      "\tspeed: 0.0346s/iter; left time: 619.5913s\n",
      "\titers: 200, epoch: 20 | loss: 0.0554634\n",
      "\tspeed: 0.0160s/iter; left time: 285.0719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0559585 Vali Loss: 0.0705468 Test Loss: 0.0810551\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0532757\n",
      "\tspeed: 0.0348s/iter; left time: 615.4116s\n",
      "\titers: 200, epoch: 21 | loss: 0.0547482\n",
      "\tspeed: 0.0160s/iter; left time: 280.5938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0557980 Vali Loss: 0.0704501 Test Loss: 0.0807355\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_96_FR_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018970314413309097, rmse:0.13773275911808014, mae:0.08062282204627991, rse:0.5327869653701782\n",
      "Intermediate time for FR and pred_len 96: 00h:03m:59.31s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_512_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1038085\n",
      "\tspeed: 0.0374s/iter; left time: 826.9664s\n",
      "\titers: 200, epoch: 1 | loss: 0.0886158\n",
      "\tspeed: 0.0162s/iter; left time: 356.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.07s\n",
      "Steps: 222 | Train Loss: 0.1091605 Vali Loss: 0.0966437 Test Loss: 0.1046350\n",
      "Validation loss decreased (inf --> 0.096644).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0697438\n",
      "\tspeed: 0.0359s/iter; left time: 785.4012s\n",
      "\titers: 200, epoch: 2 | loss: 0.0691064\n",
      "\tspeed: 0.0162s/iter; left time: 352.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 222 | Train Loss: 0.0750519 Vali Loss: 0.0789187 Test Loss: 0.0872487\n",
      "Validation loss decreased (0.096644 --> 0.078919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0678330\n",
      "\tspeed: 0.0357s/iter; left time: 773.0231s\n",
      "\titers: 200, epoch: 3 | loss: 0.0678092\n",
      "\tspeed: 0.0162s/iter; left time: 349.7243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0678947 Vali Loss: 0.0768626 Test Loss: 0.0861012\n",
      "Validation loss decreased (0.078919 --> 0.076863).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0657281\n",
      "\tspeed: 0.0367s/iter; left time: 787.1896s\n",
      "\titers: 200, epoch: 4 | loss: 0.0660678\n",
      "\tspeed: 0.0162s/iter; left time: 344.7157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0660797 Vali Loss: 0.0759090 Test Loss: 0.0861572\n",
      "Validation loss decreased (0.076863 --> 0.075909).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0692789\n",
      "\tspeed: 0.0371s/iter; left time: 788.0369s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646435\n",
      "\tspeed: 0.0164s/iter; left time: 346.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0650898 Vali Loss: 0.0755803 Test Loss: 0.0858476\n",
      "Validation loss decreased (0.075909 --> 0.075580).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0632229\n",
      "\tspeed: 0.0371s/iter; left time: 779.7562s\n",
      "\titers: 200, epoch: 6 | loss: 0.0647839\n",
      "\tspeed: 0.0165s/iter; left time: 343.8618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0642895 Vali Loss: 0.0752362 Test Loss: 0.0858734\n",
      "Validation loss decreased (0.075580 --> 0.075236).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0630247\n",
      "\tspeed: 0.0368s/iter; left time: 765.2420s\n",
      "\titers: 200, epoch: 7 | loss: 0.0642375\n",
      "\tspeed: 0.0162s/iter; left time: 335.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0636251 Vali Loss: 0.0747174 Test Loss: 0.0859729\n",
      "Validation loss decreased (0.075236 --> 0.074717).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0634076\n",
      "\tspeed: 0.0374s/iter; left time: 768.5287s\n",
      "\titers: 200, epoch: 8 | loss: 0.0629932\n",
      "\tspeed: 0.0164s/iter; left time: 334.6601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0630702 Vali Loss: 0.0744353 Test Loss: 0.0859410\n",
      "Validation loss decreased (0.074717 --> 0.074435).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0623881\n",
      "\tspeed: 0.0375s/iter; left time: 762.3529s\n",
      "\titers: 200, epoch: 9 | loss: 0.0627867\n",
      "\tspeed: 0.0165s/iter; left time: 333.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0625488 Vali Loss: 0.0742188 Test Loss: 0.0858460\n",
      "Validation loss decreased (0.074435 --> 0.074219).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0612790\n",
      "\tspeed: 0.0380s/iter; left time: 763.6621s\n",
      "\titers: 200, epoch: 10 | loss: 0.0607237\n",
      "\tspeed: 0.0164s/iter; left time: 327.2811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0621399 Vali Loss: 0.0741986 Test Loss: 0.0865132\n",
      "Validation loss decreased (0.074219 --> 0.074199).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0644236\n",
      "\tspeed: 0.0378s/iter; left time: 751.2786s\n",
      "\titers: 200, epoch: 11 | loss: 0.0592703\n",
      "\tspeed: 0.0164s/iter; left time: 323.4660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0617343 Vali Loss: 0.0741677 Test Loss: 0.0863853\n",
      "Validation loss decreased (0.074199 --> 0.074168).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0644370\n",
      "\tspeed: 0.0375s/iter; left time: 737.1975s\n",
      "\titers: 200, epoch: 12 | loss: 0.0639723\n",
      "\tspeed: 0.0164s/iter; left time: 320.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0613191 Vali Loss: 0.0743162 Test Loss: 0.0861957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0559229\n",
      "\tspeed: 0.0367s/iter; left time: 713.2013s\n",
      "\titers: 200, epoch: 13 | loss: 0.0556470\n",
      "\tspeed: 0.0164s/iter; left time: 317.7820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0609983 Vali Loss: 0.0742826 Test Loss: 0.0860600\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0603098\n",
      "\tspeed: 0.0360s/iter; left time: 692.0505s\n",
      "\titers: 200, epoch: 14 | loss: 0.0619693\n",
      "\tspeed: 0.0164s/iter; left time: 312.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0607090 Vali Loss: 0.0742746 Test Loss: 0.0869348\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0594293\n",
      "\tspeed: 0.0361s/iter; left time: 685.7998s\n",
      "\titers: 200, epoch: 15 | loss: 0.0618856\n",
      "\tspeed: 0.0164s/iter; left time: 308.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0604436 Vali Loss: 0.0745566 Test Loss: 0.0866983\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0625551\n",
      "\tspeed: 0.0367s/iter; left time: 689.8120s\n",
      "\titers: 200, epoch: 16 | loss: 0.0558443\n",
      "\tspeed: 0.0167s/iter; left time: 311.3004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0601866 Vali Loss: 0.0745793 Test Loss: 0.0866429\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0592577\n",
      "\tspeed: 0.0366s/iter; left time: 679.3046s\n",
      "\titers: 200, epoch: 17 | loss: 0.0594727\n",
      "\tspeed: 0.0164s/iter; left time: 302.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0599500 Vali Loss: 0.0747081 Test Loss: 0.0870583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0593972\n",
      "\tspeed: 0.0373s/iter; left time: 682.8863s\n",
      "\titers: 200, epoch: 18 | loss: 0.0601947\n",
      "\tspeed: 0.0164s/iter; left time: 299.4890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0597595 Vali Loss: 0.0745586 Test Loss: 0.0867914\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0631380\n",
      "\tspeed: 0.0365s/iter; left time: 661.4521s\n",
      "\titers: 200, epoch: 19 | loss: 0.0602810\n",
      "\tspeed: 0.0164s/iter; left time: 296.0505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0595620 Vali Loss: 0.0747368 Test Loss: 0.0867407\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0594467\n",
      "\tspeed: 0.0369s/iter; left time: 659.4922s\n",
      "\titers: 200, epoch: 20 | loss: 0.0574901\n",
      "\tspeed: 0.0166s/iter; left time: 295.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0594130 Vali Loss: 0.0749151 Test Loss: 0.0871659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0606618\n",
      "\tspeed: 0.0374s/iter; left time: 660.3072s\n",
      "\titers: 200, epoch: 21 | loss: 0.0589134\n",
      "\tspeed: 0.0165s/iter; left time: 290.3220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0592656 Vali Loss: 0.0748669 Test Loss: 0.0867058\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021192140877246857, rmse:0.14557521045207977, mae:0.08638525754213333, rse:0.5638265609741211\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1101471\n",
      "\tspeed: 0.0190s/iter; left time: 420.7233s\n",
      "\titers: 200, epoch: 1 | loss: 0.1027616\n",
      "\tspeed: 0.0166s/iter; left time: 364.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.1114776 Vali Loss: 0.0981760 Test Loss: 0.1063650\n",
      "Validation loss decreased (inf --> 0.098176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0739392\n",
      "\tspeed: 0.0376s/iter; left time: 821.8009s\n",
      "\titers: 200, epoch: 2 | loss: 0.0721243\n",
      "\tspeed: 0.0164s/iter; left time: 357.2290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0752453 Vali Loss: 0.0792993 Test Loss: 0.0873241\n",
      "Validation loss decreased (0.098176 --> 0.079299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0698516\n",
      "\tspeed: 0.0372s/iter; left time: 805.5797s\n",
      "\titers: 200, epoch: 3 | loss: 0.0652524\n",
      "\tspeed: 0.0162s/iter; left time: 349.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0679834 Vali Loss: 0.0769513 Test Loss: 0.0858087\n",
      "Validation loss decreased (0.079299 --> 0.076951).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0649683\n",
      "\tspeed: 0.0420s/iter; left time: 900.0097s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638714\n",
      "\tspeed: 0.0160s/iter; left time: 342.1874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0659432 Vali Loss: 0.0760446 Test Loss: 0.0856320\n",
      "Validation loss decreased (0.076951 --> 0.076045).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0652397\n",
      "\tspeed: 0.0374s/iter; left time: 793.2662s\n",
      "\titers: 200, epoch: 5 | loss: 0.0678086\n",
      "\tspeed: 0.0160s/iter; left time: 337.8420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0648318 Vali Loss: 0.0757291 Test Loss: 0.0858723\n",
      "Validation loss decreased (0.076045 --> 0.075729).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0640183\n",
      "\tspeed: 0.0382s/iter; left time: 801.7771s\n",
      "\titers: 200, epoch: 6 | loss: 0.0646850\n",
      "\tspeed: 0.0165s/iter; left time: 345.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0639992 Vali Loss: 0.0749830 Test Loss: 0.0854967\n",
      "Validation loss decreased (0.075729 --> 0.074983).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0655322\n",
      "\tspeed: 0.0373s/iter; left time: 774.7943s\n",
      "\titers: 200, epoch: 7 | loss: 0.0627624\n",
      "\tspeed: 0.0163s/iter; left time: 337.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0633765 Vali Loss: 0.0748275 Test Loss: 0.0857529\n",
      "Validation loss decreased (0.074983 --> 0.074828).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0604581\n",
      "\tspeed: 0.0378s/iter; left time: 776.3545s\n",
      "\titers: 200, epoch: 8 | loss: 0.0625577\n",
      "\tspeed: 0.0164s/iter; left time: 335.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0627193 Vali Loss: 0.0747458 Test Loss: 0.0866586\n",
      "Validation loss decreased (0.074828 --> 0.074746).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0615152\n",
      "\tspeed: 0.0371s/iter; left time: 754.6724s\n",
      "\titers: 200, epoch: 9 | loss: 0.0628731\n",
      "\tspeed: 0.0166s/iter; left time: 335.9681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0621836 Vali Loss: 0.0750587 Test Loss: 0.0860134\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0606103\n",
      "\tspeed: 0.0370s/iter; left time: 742.8652s\n",
      "\titers: 200, epoch: 10 | loss: 0.0654614\n",
      "\tspeed: 0.0165s/iter; left time: 329.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0616607 Vali Loss: 0.0747478 Test Loss: 0.0866064\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0598038\n",
      "\tspeed: 0.0369s/iter; left time: 733.5527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0602280\n",
      "\tspeed: 0.0165s/iter; left time: 325.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0612040 Vali Loss: 0.0746229 Test Loss: 0.0866348\n",
      "Validation loss decreased (0.074746 --> 0.074623).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0593534\n",
      "\tspeed: 0.0371s/iter; left time: 730.2731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0592141\n",
      "\tspeed: 0.0164s/iter; left time: 320.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0607798 Vali Loss: 0.0750477 Test Loss: 0.0867689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0580138\n",
      "\tspeed: 0.0376s/iter; left time: 731.5409s\n",
      "\titers: 200, epoch: 13 | loss: 0.0600558\n",
      "\tspeed: 0.0164s/iter; left time: 316.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0604337 Vali Loss: 0.0748355 Test Loss: 0.0861653\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0592027\n",
      "\tspeed: 0.0374s/iter; left time: 718.5061s\n",
      "\titers: 200, epoch: 14 | loss: 0.0613107\n",
      "\tspeed: 0.0161s/iter; left time: 307.0695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0600727 Vali Loss: 0.0750052 Test Loss: 0.0862515\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0615001\n",
      "\tspeed: 0.0371s/iter; left time: 705.5147s\n",
      "\titers: 200, epoch: 15 | loss: 0.0582078\n",
      "\tspeed: 0.0165s/iter; left time: 311.9274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0597914 Vali Loss: 0.0750886 Test Loss: 0.0864182\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0587654\n",
      "\tspeed: 0.0375s/iter; left time: 704.5028s\n",
      "\titers: 200, epoch: 16 | loss: 0.0619198\n",
      "\tspeed: 0.0161s/iter; left time: 300.3499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0595052 Vali Loss: 0.0751519 Test Loss: 0.0864571\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0565387\n",
      "\tspeed: 0.0369s/iter; left time: 684.0616s\n",
      "\titers: 200, epoch: 17 | loss: 0.0555177\n",
      "\tspeed: 0.0164s/iter; left time: 302.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0591903 Vali Loss: 0.0751499 Test Loss: 0.0864117\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0547446\n",
      "\tspeed: 0.0373s/iter; left time: 683.8636s\n",
      "\titers: 200, epoch: 18 | loss: 0.0563592\n",
      "\tspeed: 0.0165s/iter; left time: 300.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0590196 Vali Loss: 0.0750642 Test Loss: 0.0861926\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0586830\n",
      "\tspeed: 0.0364s/iter; left time: 658.5836s\n",
      "\titers: 200, epoch: 19 | loss: 0.0613574\n",
      "\tspeed: 0.0164s/iter; left time: 295.7564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0588265 Vali Loss: 0.0755887 Test Loss: 0.0867060\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0549258\n",
      "\tspeed: 0.0362s/iter; left time: 648.0272s\n",
      "\titers: 200, epoch: 20 | loss: 0.0571486\n",
      "\tspeed: 0.0164s/iter; left time: 291.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0586307 Vali Loss: 0.0755013 Test Loss: 0.0867498\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0581642\n",
      "\tspeed: 0.0383s/iter; left time: 676.5090s\n",
      "\titers: 200, epoch: 21 | loss: 0.0579601\n",
      "\tspeed: 0.0163s/iter; left time: 285.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0584874 Vali Loss: 0.0754130 Test Loss: 0.0866517\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_512_168_FR_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021292829886078835, rmse:0.14592063426971436, mae:0.0866347998380661, rse:0.5651643872261047\n",
      "Intermediate time for FR and pred_len 168: 00h:03m:55.10s\n",
      "Intermediate time for FR: 00h:19m:08.24s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1427019\n",
      "\tspeed: 0.0375s/iter; left time: 832.0050s\n",
      "\titers: 200, epoch: 1 | loss: 0.1210744\n",
      "\tspeed: 0.0161s/iter; left time: 356.3788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.05s\n",
      "Steps: 223 | Train Loss: 0.1474612 Vali Loss: 0.1040003 Test Loss: 0.1061004\n",
      "Validation loss decreased (inf --> 0.104000).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0786053\n",
      "\tspeed: 0.0344s/iter; left time: 755.2396s\n",
      "\titers: 200, epoch: 2 | loss: 0.0688016\n",
      "\tspeed: 0.0160s/iter; left time: 349.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0795060 Vali Loss: 0.0627535 Test Loss: 0.0660522\n",
      "Validation loss decreased (0.104000 --> 0.062754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0712326\n",
      "\tspeed: 0.0360s/iter; left time: 784.2130s\n",
      "\titers: 200, epoch: 3 | loss: 0.0645262\n",
      "\tspeed: 0.0161s/iter; left time: 348.3141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0662299 Vali Loss: 0.0600951 Test Loss: 0.0631527\n",
      "Validation loss decreased (0.062754 --> 0.060095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637566\n",
      "\tspeed: 0.0347s/iter; left time: 748.0045s\n",
      "\titers: 200, epoch: 4 | loss: 0.0638368\n",
      "\tspeed: 0.0161s/iter; left time: 344.4379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0632282 Vali Loss: 0.0587887 Test Loss: 0.0614277\n",
      "Validation loss decreased (0.060095 --> 0.058789).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0593576\n",
      "\tspeed: 0.0343s/iter; left time: 730.3160s\n",
      "\titers: 200, epoch: 5 | loss: 0.0606443\n",
      "\tspeed: 0.0159s/iter; left time: 337.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0614621 Vali Loss: 0.0578707 Test Loss: 0.0606217\n",
      "Validation loss decreased (0.058789 --> 0.057871).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0630265\n",
      "\tspeed: 0.0338s/iter; left time: 713.4095s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619991\n",
      "\tspeed: 0.0160s/iter; left time: 335.2304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0602812 Vali Loss: 0.0573779 Test Loss: 0.0601057\n",
      "Validation loss decreased (0.057871 --> 0.057378).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0639013\n",
      "\tspeed: 0.0349s/iter; left time: 728.6127s\n",
      "\titers: 200, epoch: 7 | loss: 0.0623509\n",
      "\tspeed: 0.0159s/iter; left time: 330.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0593809 Vali Loss: 0.0566655 Test Loss: 0.0593408\n",
      "Validation loss decreased (0.057378 --> 0.056665).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0575579\n",
      "\tspeed: 0.0347s/iter; left time: 717.0577s\n",
      "\titers: 200, epoch: 8 | loss: 0.0638874\n",
      "\tspeed: 0.0160s/iter; left time: 328.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0586741 Vali Loss: 0.0564011 Test Loss: 0.0590913\n",
      "Validation loss decreased (0.056665 --> 0.056401).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0573168\n",
      "\tspeed: 0.0344s/iter; left time: 703.1396s\n",
      "\titers: 200, epoch: 9 | loss: 0.0594589\n",
      "\tspeed: 0.0160s/iter; left time: 324.1879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0580785 Vali Loss: 0.0563285 Test Loss: 0.0593507\n",
      "Validation loss decreased (0.056401 --> 0.056329).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577093\n",
      "\tspeed: 0.0348s/iter; left time: 703.5950s\n",
      "\titers: 200, epoch: 10 | loss: 0.0602368\n",
      "\tspeed: 0.0160s/iter; left time: 320.5224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0576331 Vali Loss: 0.0557669 Test Loss: 0.0586965\n",
      "Validation loss decreased (0.056329 --> 0.055767).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0583503\n",
      "\tspeed: 0.0351s/iter; left time: 701.5500s\n",
      "\titers: 200, epoch: 11 | loss: 0.0567511\n",
      "\tspeed: 0.0160s/iter; left time: 318.4936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0572207 Vali Loss: 0.0557464 Test Loss: 0.0586863\n",
      "Validation loss decreased (0.055767 --> 0.055746).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0557410\n",
      "\tspeed: 0.0350s/iter; left time: 691.4246s\n",
      "\titers: 200, epoch: 12 | loss: 0.0559181\n",
      "\tspeed: 0.0159s/iter; left time: 312.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0568358 Vali Loss: 0.0554589 Test Loss: 0.0583942\n",
      "Validation loss decreased (0.055746 --> 0.055459).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0571601\n",
      "\tspeed: 0.0344s/iter; left time: 672.4040s\n",
      "\titers: 200, epoch: 13 | loss: 0.0576887\n",
      "\tspeed: 0.0161s/iter; left time: 313.5443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0564875 Vali Loss: 0.0554860 Test Loss: 0.0581893\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0531539\n",
      "\tspeed: 0.0340s/iter; left time: 655.3441s\n",
      "\titers: 200, epoch: 14 | loss: 0.0590748\n",
      "\tspeed: 0.0159s/iter; left time: 304.4316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0563151 Vali Loss: 0.0553224 Test Loss: 0.0581858\n",
      "Validation loss decreased (0.055459 --> 0.055322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0506413\n",
      "\tspeed: 0.0341s/iter; left time: 651.1924s\n",
      "\titers: 200, epoch: 15 | loss: 0.0539879\n",
      "\tspeed: 0.0158s/iter; left time: 300.4438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0560368 Vali Loss: 0.0551295 Test Loss: 0.0582475\n",
      "Validation loss decreased (0.055322 --> 0.055130).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0581412\n",
      "\tspeed: 0.0339s/iter; left time: 639.8529s\n",
      "\titers: 200, epoch: 16 | loss: 0.0519915\n",
      "\tspeed: 0.0158s/iter; left time: 296.9041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0557948 Vali Loss: 0.0549986 Test Loss: 0.0579295\n",
      "Validation loss decreased (0.055130 --> 0.054999).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0555389\n",
      "\tspeed: 0.0349s/iter; left time: 650.2338s\n",
      "\titers: 200, epoch: 17 | loss: 0.0499771\n",
      "\tspeed: 0.0160s/iter; left time: 295.6444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0556709 Vali Loss: 0.0548981 Test Loss: 0.0580050\n",
      "Validation loss decreased (0.054999 --> 0.054898).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0559821\n",
      "\tspeed: 0.0348s/iter; left time: 639.8755s\n",
      "\titers: 200, epoch: 18 | loss: 0.0539320\n",
      "\tspeed: 0.0160s/iter; left time: 292.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0554450 Vali Loss: 0.0548618 Test Loss: 0.0578751\n",
      "Validation loss decreased (0.054898 --> 0.054862).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0516250\n",
      "\tspeed: 0.0349s/iter; left time: 635.4021s\n",
      "\titers: 200, epoch: 19 | loss: 0.0590425\n",
      "\tspeed: 0.0161s/iter; left time: 290.6298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0553374 Vali Loss: 0.0548607 Test Loss: 0.0577288\n",
      "Validation loss decreased (0.054862 --> 0.054861).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0521452\n",
      "\tspeed: 0.0342s/iter; left time: 614.8249s\n",
      "\titers: 200, epoch: 20 | loss: 0.0546899\n",
      "\tspeed: 0.0160s/iter; left time: 286.5182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0552047 Vali Loss: 0.0547884 Test Loss: 0.0577962\n",
      "Validation loss decreased (0.054861 --> 0.054788).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0575326\n",
      "\tspeed: 0.0345s/iter; left time: 612.4496s\n",
      "\titers: 200, epoch: 21 | loss: 0.0596603\n",
      "\tspeed: 0.0160s/iter; left time: 282.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0550960 Vali Loss: 0.0548155 Test Loss: 0.0576586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0548494\n",
      "\tspeed: 0.0346s/iter; left time: 606.1109s\n",
      "\titers: 200, epoch: 22 | loss: 0.0557587\n",
      "\tspeed: 0.0160s/iter; left time: 278.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0549943 Vali Loss: 0.0546323 Test Loss: 0.0576324\n",
      "Validation loss decreased (0.054788 --> 0.054632).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0520775\n",
      "\tspeed: 0.0346s/iter; left time: 599.0772s\n",
      "\titers: 200, epoch: 23 | loss: 0.0523562\n",
      "\tspeed: 0.0159s/iter; left time: 274.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0549227 Vali Loss: 0.0545992 Test Loss: 0.0575449\n",
      "Validation loss decreased (0.054632 --> 0.054599).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0551701\n",
      "\tspeed: 0.0345s/iter; left time: 589.4322s\n",
      "\titers: 200, epoch: 24 | loss: 0.0565630\n",
      "\tspeed: 0.0159s/iter; left time: 270.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0548284 Vali Loss: 0.0546200 Test Loss: 0.0576595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0537986\n",
      "\tspeed: 0.0341s/iter; left time: 575.3762s\n",
      "\titers: 200, epoch: 25 | loss: 0.0557100\n",
      "\tspeed: 0.0160s/iter; left time: 267.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0547565 Vali Loss: 0.0545856 Test Loss: 0.0575511\n",
      "Validation loss decreased (0.054599 --> 0.054586).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0557428\n",
      "\tspeed: 0.0351s/iter; left time: 583.1866s\n",
      "\titers: 200, epoch: 26 | loss: 0.0518505\n",
      "\tspeed: 0.0158s/iter; left time: 261.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0546297 Vali Loss: 0.0546757 Test Loss: 0.0575367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0490851\n",
      "\tspeed: 0.0338s/iter; left time: 555.0323s\n",
      "\titers: 200, epoch: 27 | loss: 0.0549791\n",
      "\tspeed: 0.0160s/iter; left time: 261.1510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0546483 Vali Loss: 0.0545224 Test Loss: 0.0574979\n",
      "Validation loss decreased (0.054586 --> 0.054522).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0540850\n",
      "\tspeed: 0.0356s/iter; left time: 575.6120s\n",
      "\titers: 200, epoch: 28 | loss: 0.0537625\n",
      "\tspeed: 0.0158s/iter; left time: 254.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0544892 Vali Loss: 0.0546254 Test Loss: 0.0575262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0558160\n",
      "\tspeed: 0.0352s/iter; left time: 561.5500s\n",
      "\titers: 200, epoch: 29 | loss: 0.0561940\n",
      "\tspeed: 0.0160s/iter; left time: 253.2509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0545047 Vali Loss: 0.0545289 Test Loss: 0.0574216\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0521401\n",
      "\tspeed: 0.0350s/iter; left time: 550.2645s\n",
      "\titers: 200, epoch: 30 | loss: 0.0562083\n",
      "\tspeed: 0.0160s/iter; left time: 250.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0545059 Vali Loss: 0.0545895 Test Loss: 0.0574229\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0551878\n",
      "\tspeed: 0.0343s/iter; left time: 532.6448s\n",
      "\titers: 200, epoch: 31 | loss: 0.0548581\n",
      "\tspeed: 0.0159s/iter; left time: 244.8807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0544665 Vali Loss: 0.0544737 Test Loss: 0.0574892\n",
      "Validation loss decreased (0.054522 --> 0.054474).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0542025\n",
      "\tspeed: 0.0344s/iter; left time: 526.4956s\n",
      "\titers: 200, epoch: 32 | loss: 0.0572710\n",
      "\tspeed: 0.0160s/iter; left time: 242.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0544115 Vali Loss: 0.0545342 Test Loss: 0.0574461\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0535640\n",
      "\tspeed: 0.0343s/iter; left time: 517.1064s\n",
      "\titers: 200, epoch: 33 | loss: 0.0569752\n",
      "\tspeed: 0.0161s/iter; left time: 240.2397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0544246 Vali Loss: 0.0544580 Test Loss: 0.0573837\n",
      "Validation loss decreased (0.054474 --> 0.054458).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0605599\n",
      "\tspeed: 0.0352s/iter; left time: 522.8040s\n",
      "\titers: 200, epoch: 34 | loss: 0.0472958\n",
      "\tspeed: 0.0161s/iter; left time: 236.6915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0543542 Vali Loss: 0.0545168 Test Loss: 0.0574080\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0564097\n",
      "\tspeed: 0.0350s/iter; left time: 512.3211s\n",
      "\titers: 200, epoch: 35 | loss: 0.0553258\n",
      "\tspeed: 0.0160s/iter; left time: 232.3637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0543401 Vali Loss: 0.0545226 Test Loss: 0.0574246\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0550940\n",
      "\tspeed: 0.0344s/iter; left time: 494.5909s\n",
      "\titers: 200, epoch: 36 | loss: 0.0552749\n",
      "\tspeed: 0.0160s/iter; left time: 229.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0542743 Vali Loss: 0.0544873 Test Loss: 0.0573703\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0490394\n",
      "\tspeed: 0.0341s/iter; left time: 483.8383s\n",
      "\titers: 200, epoch: 37 | loss: 0.0553193\n",
      "\tspeed: 0.0160s/iter; left time: 225.6181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0542710 Vali Loss: 0.0544739 Test Loss: 0.0573537\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0526361\n",
      "\tspeed: 0.0348s/iter; left time: 486.1514s\n",
      "\titers: 200, epoch: 38 | loss: 0.0504732\n",
      "\tspeed: 0.0160s/iter; left time: 221.2352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0542628 Vali Loss: 0.0544524 Test Loss: 0.0573422\n",
      "Validation loss decreased (0.054458 --> 0.054452).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0559285\n",
      "\tspeed: 0.0350s/iter; left time: 480.0643s\n",
      "\titers: 200, epoch: 39 | loss: 0.0555603\n",
      "\tspeed: 0.0159s/iter; left time: 216.5884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0542550 Vali Loss: 0.0544331 Test Loss: 0.0573323\n",
      "Validation loss decreased (0.054452 --> 0.054433).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0579910\n",
      "\tspeed: 0.0341s/iter; left time: 460.7299s\n",
      "\titers: 200, epoch: 40 | loss: 0.0548393\n",
      "\tspeed: 0.0159s/iter; left time: 213.2186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0541701 Vali Loss: 0.0544750 Test Loss: 0.0573672\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0517201\n",
      "\tspeed: 0.0341s/iter; left time: 452.7832s\n",
      "\titers: 200, epoch: 41 | loss: 0.0538156\n",
      "\tspeed: 0.0161s/iter; left time: 211.8607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0542072 Vali Loss: 0.0544891 Test Loss: 0.0573259\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0515476\n",
      "\tspeed: 0.0349s/iter; left time: 455.5990s\n",
      "\titers: 200, epoch: 42 | loss: 0.0563213\n",
      "\tspeed: 0.0158s/iter; left time: 204.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0542154 Vali Loss: 0.0544153 Test Loss: 0.0573448\n",
      "Validation loss decreased (0.054433 --> 0.054415).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0552305\n",
      "\tspeed: 0.0346s/iter; left time: 444.4076s\n",
      "\titers: 200, epoch: 43 | loss: 0.0489174\n",
      "\tspeed: 0.0158s/iter; left time: 201.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0541136 Vali Loss: 0.0544915 Test Loss: 0.0573413\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0554321\n",
      "\tspeed: 0.0334s/iter; left time: 421.2308s\n",
      "\titers: 200, epoch: 44 | loss: 0.0550841\n",
      "\tspeed: 0.0158s/iter; left time: 198.2006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.72s\n",
      "Steps: 223 | Train Loss: 0.0541974 Vali Loss: 0.0544485 Test Loss: 0.0573440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0556461\n",
      "\tspeed: 0.0341s/iter; left time: 422.0379s\n",
      "\titers: 200, epoch: 45 | loss: 0.0582484\n",
      "\tspeed: 0.0160s/iter; left time: 197.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0542326 Vali Loss: 0.0544156 Test Loss: 0.0573400\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0518712\n",
      "\tspeed: 0.0345s/iter; left time: 419.4795s\n",
      "\titers: 200, epoch: 46 | loss: 0.0530871\n",
      "\tspeed: 0.0160s/iter; left time: 192.8966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0542202 Vali Loss: 0.0544276 Test Loss: 0.0573249\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0570431\n",
      "\tspeed: 0.0344s/iter; left time: 410.9057s\n",
      "\titers: 200, epoch: 47 | loss: 0.0589256\n",
      "\tspeed: 0.0159s/iter; left time: 187.9922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0541914 Vali Loss: 0.0544385 Test Loss: 0.0573448\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0530827\n",
      "\tspeed: 0.0341s/iter; left time: 399.1827s\n",
      "\titers: 200, epoch: 48 | loss: 0.0537200\n",
      "\tspeed: 0.0161s/iter; left time: 187.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0541314 Vali Loss: 0.0544282 Test Loss: 0.0573157\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0541340\n",
      "\tspeed: 0.0342s/iter; left time: 392.8101s\n",
      "\titers: 200, epoch: 49 | loss: 0.0526849\n",
      "\tspeed: 0.0160s/iter; left time: 181.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0541437 Vali Loss: 0.0545368 Test Loss: 0.0573278\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0592180\n",
      "\tspeed: 0.0347s/iter; left time: 390.7957s\n",
      "\titers: 200, epoch: 50 | loss: 0.0563472\n",
      "\tspeed: 0.0160s/iter; left time: 178.3339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0541242 Vali Loss: 0.0543747 Test Loss: 0.0573191\n",
      "Validation loss decreased (0.054415 --> 0.054375).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0525011\n",
      "\tspeed: 0.0351s/iter; left time: 387.6635s\n",
      "\titers: 200, epoch: 51 | loss: 0.0538566\n",
      "\tspeed: 0.0159s/iter; left time: 174.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0541166 Vali Loss: 0.0544819 Test Loss: 0.0573347\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0536968\n",
      "\tspeed: 0.0347s/iter; left time: 375.9349s\n",
      "\titers: 200, epoch: 52 | loss: 0.0525365\n",
      "\tspeed: 0.0160s/iter; left time: 171.1398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0541408 Vali Loss: 0.0544048 Test Loss: 0.0573146\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0528640\n",
      "\tspeed: 0.0341s/iter; left time: 361.9083s\n",
      "\titers: 200, epoch: 53 | loss: 0.0538888\n",
      "\tspeed: 0.0159s/iter; left time: 167.3859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0540383 Vali Loss: 0.0543453 Test Loss: 0.0573166\n",
      "Validation loss decreased (0.054375 --> 0.054345).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0566848\n",
      "\tspeed: 0.0345s/iter; left time: 358.2394s\n",
      "\titers: 200, epoch: 54 | loss: 0.0535414\n",
      "\tspeed: 0.0161s/iter; left time: 165.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0541614 Vali Loss: 0.0543865 Test Loss: 0.0573139\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0516741\n",
      "\tspeed: 0.0344s/iter; left time: 349.3242s\n",
      "\titers: 200, epoch: 55 | loss: 0.0552716\n",
      "\tspeed: 0.0160s/iter; left time: 161.3449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0541209 Vali Loss: 0.0544638 Test Loss: 0.0573122\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0526690\n",
      "\tspeed: 0.0340s/iter; left time: 337.4450s\n",
      "\titers: 200, epoch: 56 | loss: 0.0548634\n",
      "\tspeed: 0.0159s/iter; left time: 156.3507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0541260 Vali Loss: 0.0543685 Test Loss: 0.0573111\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0524065\n",
      "\tspeed: 0.0345s/iter; left time: 335.2163s\n",
      "\titers: 200, epoch: 57 | loss: 0.0489925\n",
      "\tspeed: 0.0159s/iter; left time: 152.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0541340 Vali Loss: 0.0544913 Test Loss: 0.0573359\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0536880\n",
      "\tspeed: 0.0350s/iter; left time: 332.0043s\n",
      "\titers: 200, epoch: 58 | loss: 0.0531165\n",
      "\tspeed: 0.0162s/iter; left time: 151.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 223 | Train Loss: 0.0541110 Vali Loss: 0.0544186 Test Loss: 0.0573093\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0540935\n",
      "\tspeed: 0.0349s/iter; left time: 323.6043s\n",
      "\titers: 200, epoch: 59 | loss: 0.0515974\n",
      "\tspeed: 0.0159s/iter; left time: 145.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0540857 Vali Loss: 0.0544005 Test Loss: 0.0573207\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0542790\n",
      "\tspeed: 0.0346s/iter; left time: 313.2182s\n",
      "\titers: 200, epoch: 60 | loss: 0.0533910\n",
      "\tspeed: 0.0161s/iter; left time: 143.6579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0540731 Vali Loss: 0.0544256 Test Loss: 0.0573097\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0529101\n",
      "\tspeed: 0.0344s/iter; left time: 303.6967s\n",
      "\titers: 200, epoch: 61 | loss: 0.0518097\n",
      "\tspeed: 0.0160s/iter; left time: 139.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0540157 Vali Loss: 0.0543952 Test Loss: 0.0572920\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0523179\n",
      "\tspeed: 0.0344s/iter; left time: 295.4702s\n",
      "\titers: 200, epoch: 62 | loss: 0.0563427\n",
      "\tspeed: 0.0159s/iter; left time: 135.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0541533 Vali Loss: 0.0543900 Test Loss: 0.0573175\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0530872\n",
      "\tspeed: 0.0342s/iter; left time: 286.5650s\n",
      "\titers: 200, epoch: 63 | loss: 0.0575467\n",
      "\tspeed: 0.0159s/iter; left time: 131.8436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0540531 Vali Loss: 0.0544257 Test Loss: 0.0573183\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010042445734143257, rmse:0.10021200031042099, mae:0.05731664597988129, rse:0.37865182757377625\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1437376\n",
      "\tspeed: 0.0179s/iter; left time: 398.4899s\n",
      "\titers: 200, epoch: 1 | loss: 0.1218088\n",
      "\tspeed: 0.0159s/iter; left time: 350.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.1459537 Vali Loss: 0.1040123 Test Loss: 0.1059128\n",
      "Validation loss decreased (inf --> 0.104012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0734974\n",
      "\tspeed: 0.0350s/iter; left time: 769.9706s\n",
      "\titers: 200, epoch: 2 | loss: 0.0681576\n",
      "\tspeed: 0.0160s/iter; left time: 349.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0788160 Vali Loss: 0.0632393 Test Loss: 0.0662010\n",
      "Validation loss decreased (0.104012 --> 0.063239).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0615088\n",
      "\tspeed: 0.0354s/iter; left time: 769.4324s\n",
      "\titers: 200, epoch: 3 | loss: 0.0651769\n",
      "\tspeed: 0.0158s/iter; left time: 342.1837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0659581 Vali Loss: 0.0599105 Test Loss: 0.0627305\n",
      "Validation loss decreased (0.063239 --> 0.059911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0566885\n",
      "\tspeed: 0.0343s/iter; left time: 739.2755s\n",
      "\titers: 200, epoch: 4 | loss: 0.0625224\n",
      "\tspeed: 0.0158s/iter; left time: 339.6461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0629574 Vali Loss: 0.0586193 Test Loss: 0.0615723\n",
      "Validation loss decreased (0.059911 --> 0.058619).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0626815\n",
      "\tspeed: 0.0344s/iter; left time: 733.3117s\n",
      "\titers: 200, epoch: 5 | loss: 0.0557751\n",
      "\tspeed: 0.0159s/iter; left time: 338.1939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0612096 Vali Loss: 0.0576986 Test Loss: 0.0605876\n",
      "Validation loss decreased (0.058619 --> 0.057699).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0600710\n",
      "\tspeed: 0.0348s/iter; left time: 733.4879s\n",
      "\titers: 200, epoch: 6 | loss: 0.0616770\n",
      "\tspeed: 0.0158s/iter; left time: 332.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0600082 Vali Loss: 0.0573011 Test Loss: 0.0603055\n",
      "Validation loss decreased (0.057699 --> 0.057301).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621134\n",
      "\tspeed: 0.0346s/iter; left time: 720.8724s\n",
      "\titers: 200, epoch: 7 | loss: 0.0567575\n",
      "\tspeed: 0.0158s/iter; left time: 328.3635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0591977 Vali Loss: 0.0565639 Test Loss: 0.0593693\n",
      "Validation loss decreased (0.057301 --> 0.056564).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570501\n",
      "\tspeed: 0.0343s/iter; left time: 707.4024s\n",
      "\titers: 200, epoch: 8 | loss: 0.0534457\n",
      "\tspeed: 0.0158s/iter; left time: 324.3977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0584375 Vali Loss: 0.0563807 Test Loss: 0.0593228\n",
      "Validation loss decreased (0.056564 --> 0.056381).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0550565\n",
      "\tspeed: 0.0346s/iter; left time: 706.5261s\n",
      "\titers: 200, epoch: 9 | loss: 0.0540454\n",
      "\tspeed: 0.0158s/iter; left time: 321.5994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0578834 Vali Loss: 0.0560455 Test Loss: 0.0590278\n",
      "Validation loss decreased (0.056381 --> 0.056045).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0577517\n",
      "\tspeed: 0.0350s/iter; left time: 707.1288s\n",
      "\titers: 200, epoch: 10 | loss: 0.0583597\n",
      "\tspeed: 0.0158s/iter; left time: 317.4321s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0574364 Vali Loss: 0.0558651 Test Loss: 0.0588139\n",
      "Validation loss decreased (0.056045 --> 0.055865).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0545390\n",
      "\tspeed: 0.0340s/iter; left time: 679.7341s\n",
      "\titers: 200, epoch: 11 | loss: 0.0585475\n",
      "\tspeed: 0.0159s/iter; left time: 315.4992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0571123 Vali Loss: 0.0556779 Test Loss: 0.0584315\n",
      "Validation loss decreased (0.055865 --> 0.055678).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0539109\n",
      "\tspeed: 0.0343s/iter; left time: 676.9433s\n",
      "\titers: 200, epoch: 12 | loss: 0.0540821\n",
      "\tspeed: 0.0159s/iter; left time: 311.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0566812 Vali Loss: 0.0554154 Test Loss: 0.0584952\n",
      "Validation loss decreased (0.055678 --> 0.055415).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0585509\n",
      "\tspeed: 0.0347s/iter; left time: 678.2293s\n",
      "\titers: 200, epoch: 13 | loss: 0.0568328\n",
      "\tspeed: 0.0162s/iter; left time: 314.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 223 | Train Loss: 0.0563619 Vali Loss: 0.0551742 Test Loss: 0.0581848\n",
      "Validation loss decreased (0.055415 --> 0.055174).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0529384\n",
      "\tspeed: 0.0357s/iter; left time: 690.0011s\n",
      "\titers: 200, epoch: 14 | loss: 0.0569521\n",
      "\tspeed: 0.0159s/iter; left time: 305.8315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0561004 Vali Loss: 0.0550201 Test Loss: 0.0582083\n",
      "Validation loss decreased (0.055174 --> 0.055020).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0574702\n",
      "\tspeed: 0.0344s/iter; left time: 656.5835s\n",
      "\titers: 200, epoch: 15 | loss: 0.0554621\n",
      "\tspeed: 0.0160s/iter; left time: 304.0439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0558923 Vali Loss: 0.0549680 Test Loss: 0.0579567\n",
      "Validation loss decreased (0.055020 --> 0.054968).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0561865\n",
      "\tspeed: 0.0347s/iter; left time: 654.1133s\n",
      "\titers: 200, epoch: 16 | loss: 0.0586759\n",
      "\tspeed: 0.0159s/iter; left time: 297.7919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0556617 Vali Loss: 0.0548728 Test Loss: 0.0580167\n",
      "Validation loss decreased (0.054968 --> 0.054873).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0569220\n",
      "\tspeed: 0.0343s/iter; left time: 638.4917s\n",
      "\titers: 200, epoch: 17 | loss: 0.0556935\n",
      "\tspeed: 0.0159s/iter; left time: 294.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0554824 Vali Loss: 0.0547731 Test Loss: 0.0578745\n",
      "Validation loss decreased (0.054873 --> 0.054773).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0521001\n",
      "\tspeed: 0.0342s/iter; left time: 629.2710s\n",
      "\titers: 200, epoch: 18 | loss: 0.0569415\n",
      "\tspeed: 0.0160s/iter; left time: 292.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0553238 Vali Loss: 0.0548064 Test Loss: 0.0577388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0509532\n",
      "\tspeed: 0.0337s/iter; left time: 613.4193s\n",
      "\titers: 200, epoch: 19 | loss: 0.0549318\n",
      "\tspeed: 0.0159s/iter; left time: 287.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0551692 Vali Loss: 0.0547886 Test Loss: 0.0577580\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0542093\n",
      "\tspeed: 0.0338s/iter; left time: 607.4727s\n",
      "\titers: 200, epoch: 20 | loss: 0.0539864\n",
      "\tspeed: 0.0159s/iter; left time: 284.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0551054 Vali Loss: 0.0545684 Test Loss: 0.0576752\n",
      "Validation loss decreased (0.054773 --> 0.054568).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0570287\n",
      "\tspeed: 0.0354s/iter; left time: 627.3411s\n",
      "\titers: 200, epoch: 21 | loss: 0.0536542\n",
      "\tspeed: 0.0159s/iter; left time: 279.9261s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0549805 Vali Loss: 0.0547029 Test Loss: 0.0577845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0513130\n",
      "\tspeed: 0.0353s/iter; left time: 619.1957s\n",
      "\titers: 200, epoch: 22 | loss: 0.0539055\n",
      "\tspeed: 0.0160s/iter; left time: 278.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.82s\n",
      "Steps: 223 | Train Loss: 0.0548726 Vali Loss: 0.0545246 Test Loss: 0.0575976\n",
      "Validation loss decreased (0.054568 --> 0.054525).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0546211\n",
      "\tspeed: 0.0348s/iter; left time: 601.9265s\n",
      "\titers: 200, epoch: 23 | loss: 0.0518262\n",
      "\tspeed: 0.0160s/iter; left time: 275.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0547239 Vali Loss: 0.0544865 Test Loss: 0.0576013\n",
      "Validation loss decreased (0.054525 --> 0.054486).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0565210\n",
      "\tspeed: 0.0349s/iter; left time: 595.8325s\n",
      "\titers: 200, epoch: 24 | loss: 0.0530960\n",
      "\tspeed: 0.0158s/iter; left time: 267.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0546909 Vali Loss: 0.0544991 Test Loss: 0.0577168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0572857\n",
      "\tspeed: 0.0339s/iter; left time: 571.4837s\n",
      "\titers: 200, epoch: 25 | loss: 0.0572679\n",
      "\tspeed: 0.0158s/iter; left time: 265.3899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0545974 Vali Loss: 0.0544958 Test Loss: 0.0575073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0505562\n",
      "\tspeed: 0.0341s/iter; left time: 566.1329s\n",
      "\titers: 200, epoch: 26 | loss: 0.0509735\n",
      "\tspeed: 0.0158s/iter; left time: 260.5649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0545359 Vali Loss: 0.0544772 Test Loss: 0.0575183\n",
      "Validation loss decreased (0.054486 --> 0.054477).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0550611\n",
      "\tspeed: 0.0342s/iter; left time: 561.7949s\n",
      "\titers: 200, epoch: 27 | loss: 0.0506625\n",
      "\tspeed: 0.0158s/iter; left time: 258.2214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0544718 Vali Loss: 0.0543655 Test Loss: 0.0575012\n",
      "Validation loss decreased (0.054477 --> 0.054365).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0524747\n",
      "\tspeed: 0.0348s/iter; left time: 562.6658s\n",
      "\titers: 200, epoch: 28 | loss: 0.0541451\n",
      "\tspeed: 0.0158s/iter; left time: 254.7158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 223 | Train Loss: 0.0544397 Vali Loss: 0.0543907 Test Loss: 0.0574795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0610372\n",
      "\tspeed: 0.0345s/iter; left time: 549.8447s\n",
      "\titers: 200, epoch: 29 | loss: 0.0488619\n",
      "\tspeed: 0.0158s/iter; left time: 249.7985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0543997 Vali Loss: 0.0544548 Test Loss: 0.0574493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0520118\n",
      "\tspeed: 0.0336s/iter; left time: 529.1967s\n",
      "\titers: 200, epoch: 30 | loss: 0.0576182\n",
      "\tspeed: 0.0158s/iter; left time: 246.6020s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0543466 Vali Loss: 0.0543716 Test Loss: 0.0574473\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0549162\n",
      "\tspeed: 0.0346s/iter; left time: 536.3651s\n",
      "\titers: 200, epoch: 31 | loss: 0.0518339\n",
      "\tspeed: 0.0159s/iter; left time: 244.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0543057 Vali Loss: 0.0543546 Test Loss: 0.0574099\n",
      "Validation loss decreased (0.054365 --> 0.054355).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0550131\n",
      "\tspeed: 0.0348s/iter; left time: 531.8229s\n",
      "\titers: 200, epoch: 32 | loss: 0.0551643\n",
      "\tspeed: 0.0158s/iter; left time: 239.6524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0542746 Vali Loss: 0.0543607 Test Loss: 0.0574468\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0510239\n",
      "\tspeed: 0.0342s/iter; left time: 515.4534s\n",
      "\titers: 200, epoch: 33 | loss: 0.0563661\n",
      "\tspeed: 0.0158s/iter; left time: 235.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0542900 Vali Loss: 0.0542929 Test Loss: 0.0574407\n",
      "Validation loss decreased (0.054355 --> 0.054293).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0518789\n",
      "\tspeed: 0.0343s/iter; left time: 509.6326s\n",
      "\titers: 200, epoch: 34 | loss: 0.0508898\n",
      "\tspeed: 0.0159s/iter; left time: 233.7112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0541548 Vali Loss: 0.0543167 Test Loss: 0.0573864\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0535522\n",
      "\tspeed: 0.0337s/iter; left time: 492.8914s\n",
      "\titers: 200, epoch: 35 | loss: 0.0541271\n",
      "\tspeed: 0.0158s/iter; left time: 229.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0542357 Vali Loss: 0.0542606 Test Loss: 0.0573678\n",
      "Validation loss decreased (0.054293 --> 0.054261).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0527551\n",
      "\tspeed: 0.0341s/iter; left time: 490.8590s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486183\n",
      "\tspeed: 0.0158s/iter; left time: 226.5362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0541346 Vali Loss: 0.0542899 Test Loss: 0.0573781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0559723\n",
      "\tspeed: 0.0337s/iter; left time: 477.8557s\n",
      "\titers: 200, epoch: 37 | loss: 0.0569861\n",
      "\tspeed: 0.0158s/iter; left time: 221.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0541087 Vali Loss: 0.0543084 Test Loss: 0.0573659\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0551543\n",
      "\tspeed: 0.0337s/iter; left time: 470.1934s\n",
      "\titers: 200, epoch: 38 | loss: 0.0536958\n",
      "\tspeed: 0.0158s/iter; left time: 219.2939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0541737 Vali Loss: 0.0542291 Test Loss: 0.0573913\n",
      "Validation loss decreased (0.054261 --> 0.054229).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0543118\n",
      "\tspeed: 0.0340s/iter; left time: 467.3230s\n",
      "\titers: 200, epoch: 39 | loss: 0.0527666\n",
      "\tspeed: 0.0159s/iter; left time: 217.0861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0540488 Vali Loss: 0.0542493 Test Loss: 0.0574019\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0543259\n",
      "\tspeed: 0.0337s/iter; left time: 455.3499s\n",
      "\titers: 200, epoch: 40 | loss: 0.0579327\n",
      "\tspeed: 0.0159s/iter; left time: 213.7665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 223 | Train Loss: 0.0540642 Vali Loss: 0.0543219 Test Loss: 0.0573815\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0537464\n",
      "\tspeed: 0.0338s/iter; left time: 449.0923s\n",
      "\titers: 200, epoch: 41 | loss: 0.0553150\n",
      "\tspeed: 0.0158s/iter; left time: 208.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 223 | Train Loss: 0.0540945 Vali Loss: 0.0542109 Test Loss: 0.0573602\n",
      "Validation loss decreased (0.054229 --> 0.054211).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0542094\n",
      "\tspeed: 0.0347s/iter; left time: 452.5382s\n",
      "\titers: 200, epoch: 42 | loss: 0.0538296\n",
      "\tspeed: 0.0159s/iter; left time: 206.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0541527 Vali Loss: 0.0542404 Test Loss: 0.0573753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0496452\n",
      "\tspeed: 0.0344s/iter; left time: 441.7018s\n",
      "\titers: 200, epoch: 43 | loss: 0.0559051\n",
      "\tspeed: 0.0159s/iter; left time: 201.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0540728 Vali Loss: 0.0542064 Test Loss: 0.0573421\n",
      "Validation loss decreased (0.054211 --> 0.054206).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0540601\n",
      "\tspeed: 0.0350s/iter; left time: 440.8513s\n",
      "\titers: 200, epoch: 44 | loss: 0.0521746\n",
      "\tspeed: 0.0159s/iter; left time: 198.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0540135 Vali Loss: 0.0542180 Test Loss: 0.0573422\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0563909\n",
      "\tspeed: 0.0341s/iter; left time: 422.5100s\n",
      "\titers: 200, epoch: 45 | loss: 0.0520319\n",
      "\tspeed: 0.0160s/iter; left time: 196.6146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0540294 Vali Loss: 0.0542403 Test Loss: 0.0573742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0503368\n",
      "\tspeed: 0.0338s/iter; left time: 410.6712s\n",
      "\titers: 200, epoch: 46 | loss: 0.0564675\n",
      "\tspeed: 0.0158s/iter; left time: 190.7697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0540314 Vali Loss: 0.0542415 Test Loss: 0.0573479\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0521331\n",
      "\tspeed: 0.0345s/iter; left time: 412.4184s\n",
      "\titers: 200, epoch: 47 | loss: 0.0564413\n",
      "\tspeed: 0.0158s/iter; left time: 186.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0539900 Vali Loss: 0.0542255 Test Loss: 0.0573726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0523032\n",
      "\tspeed: 0.0347s/iter; left time: 406.2370s\n",
      "\titers: 200, epoch: 48 | loss: 0.0552092\n",
      "\tspeed: 0.0160s/iter; left time: 185.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 223 | Train Loss: 0.0540442 Vali Loss: 0.0542793 Test Loss: 0.0573596\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0549094\n",
      "\tspeed: 0.0353s/iter; left time: 405.6372s\n",
      "\titers: 200, epoch: 49 | loss: 0.0553518\n",
      "\tspeed: 0.0160s/iter; left time: 182.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 223 | Train Loss: 0.0540319 Vali Loss: 0.0542665 Test Loss: 0.0573428\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0528407\n",
      "\tspeed: 0.0340s/iter; left time: 383.3247s\n",
      "\titers: 200, epoch: 50 | loss: 0.0519125\n",
      "\tspeed: 0.0159s/iter; left time: 177.2620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 223 | Train Loss: 0.0539984 Vali Loss: 0.0541995 Test Loss: 0.0573373\n",
      "Validation loss decreased (0.054206 --> 0.054199).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0556440\n",
      "\tspeed: 0.0343s/iter; left time: 378.7051s\n",
      "\titers: 200, epoch: 51 | loss: 0.0513425\n",
      "\tspeed: 0.0160s/iter; left time: 175.4815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0539772 Vali Loss: 0.0542637 Test Loss: 0.0573530\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0555834\n",
      "\tspeed: 0.0338s/iter; left time: 366.3641s\n",
      "\titers: 200, epoch: 52 | loss: 0.0514550\n",
      "\tspeed: 0.0160s/iter; left time: 172.1759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 223 | Train Loss: 0.0540019 Vali Loss: 0.0542435 Test Loss: 0.0573402\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0542054\n",
      "\tspeed: 0.0345s/iter; left time: 365.4268s\n",
      "\titers: 200, epoch: 53 | loss: 0.0515398\n",
      "\tspeed: 0.0157s/iter; left time: 165.3309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0539925 Vali Loss: 0.0542621 Test Loss: 0.0573415\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0520108\n",
      "\tspeed: 0.0336s/iter; left time: 349.0547s\n",
      "\titers: 200, epoch: 54 | loss: 0.0545530\n",
      "\tspeed: 0.0158s/iter; left time: 162.1345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0539694 Vali Loss: 0.0542016 Test Loss: 0.0573542\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0578185\n",
      "\tspeed: 0.0339s/iter; left time: 344.6737s\n",
      "\titers: 200, epoch: 55 | loss: 0.0543417\n",
      "\tspeed: 0.0158s/iter; left time: 159.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0540142 Vali Loss: 0.0542875 Test Loss: 0.0573427\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0559313\n",
      "\tspeed: 0.0337s/iter; left time: 335.1495s\n",
      "\titers: 200, epoch: 56 | loss: 0.0529022\n",
      "\tspeed: 0.0158s/iter; left time: 155.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 223 | Train Loss: 0.0540126 Vali Loss: 0.0542788 Test Loss: 0.0573249\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0527710\n",
      "\tspeed: 0.0342s/iter; left time: 332.1599s\n",
      "\titers: 200, epoch: 57 | loss: 0.0580449\n",
      "\tspeed: 0.0159s/iter; left time: 152.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 223 | Train Loss: 0.0540016 Vali Loss: 0.0542580 Test Loss: 0.0573280\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0520843\n",
      "\tspeed: 0.0343s/iter; left time: 325.4857s\n",
      "\titers: 200, epoch: 58 | loss: 0.0531525\n",
      "\tspeed: 0.0160s/iter; left time: 149.8106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0539654 Vali Loss: 0.0542225 Test Loss: 0.0573418\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0533918\n",
      "\tspeed: 0.0349s/iter; left time: 323.6474s\n",
      "\titers: 200, epoch: 59 | loss: 0.0501421\n",
      "\tspeed: 0.0158s/iter; left time: 144.9004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 223 | Train Loss: 0.0539878 Vali Loss: 0.0542799 Test Loss: 0.0573421\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0541033\n",
      "\tspeed: 0.0352s/iter; left time: 317.9306s\n",
      "\titers: 200, epoch: 60 | loss: 0.0571955\n",
      "\tspeed: 0.0158s/iter; left time: 141.6231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 223 | Train Loss: 0.0539509 Vali Loss: 0.0542057 Test Loss: 0.0573444\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_IT_PatchTST_custom_ftM_sl512_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010105514898896217, rmse:0.10052619129419327, mae:0.05733725056052208, rse:0.3798389732837677\n",
      "Intermediate time for IT and pred_len 24: 00h:10m:29.66s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1480092\n",
      "\tspeed: 0.0380s/iter; left time: 840.1612s\n",
      "\titers: 200, epoch: 1 | loss: 0.1285040\n",
      "\tspeed: 0.0160s/iter; left time: 352.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.01s\n",
      "Steps: 222 | Train Loss: 0.1509507 Vali Loss: 0.1113291 Test Loss: 0.1137491\n",
      "Validation loss decreased (inf --> 0.111329).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0946910\n",
      "\tspeed: 0.0361s/iter; left time: 788.9349s\n",
      "\titers: 200, epoch: 2 | loss: 0.0880413\n",
      "\tspeed: 0.0158s/iter; left time: 343.3632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.74s\n",
      "Steps: 222 | Train Loss: 0.0966951 Vali Loss: 0.0821402 Test Loss: 0.0859240\n",
      "Validation loss decreased (0.111329 --> 0.082140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0857038\n",
      "\tspeed: 0.0363s/iter; left time: 785.3421s\n",
      "\titers: 200, epoch: 3 | loss: 0.0834037\n",
      "\tspeed: 0.0158s/iter; left time: 341.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0849271 Vali Loss: 0.0798710 Test Loss: 0.0837083\n",
      "Validation loss decreased (0.082140 --> 0.079871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0806999\n",
      "\tspeed: 0.0347s/iter; left time: 744.7689s\n",
      "\titers: 200, epoch: 4 | loss: 0.0802332\n",
      "\tspeed: 0.0159s/iter; left time: 338.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0820312 Vali Loss: 0.0793059 Test Loss: 0.0828319\n",
      "Validation loss decreased (0.079871 --> 0.079306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0756191\n",
      "\tspeed: 0.0357s/iter; left time: 757.2364s\n",
      "\titers: 200, epoch: 5 | loss: 0.0793900\n",
      "\tspeed: 0.0160s/iter; left time: 337.7678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0802160 Vali Loss: 0.0782365 Test Loss: 0.0818849\n",
      "Validation loss decreased (0.079306 --> 0.078237).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0778672\n",
      "\tspeed: 0.0371s/iter; left time: 778.5071s\n",
      "\titers: 200, epoch: 6 | loss: 0.0811385\n",
      "\tspeed: 0.0164s/iter; left time: 342.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0789857 Vali Loss: 0.0778599 Test Loss: 0.0823483\n",
      "Validation loss decreased (0.078237 --> 0.077860).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0805226\n",
      "\tspeed: 0.0368s/iter; left time: 764.2622s\n",
      "\titers: 200, epoch: 7 | loss: 0.0763721\n",
      "\tspeed: 0.0164s/iter; left time: 339.6007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0780315 Vali Loss: 0.0776080 Test Loss: 0.0814997\n",
      "Validation loss decreased (0.077860 --> 0.077608).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0774337\n",
      "\tspeed: 0.0366s/iter; left time: 752.5304s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790309\n",
      "\tspeed: 0.0160s/iter; left time: 327.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0772947 Vali Loss: 0.0778682 Test Loss: 0.0816363\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0766557\n",
      "\tspeed: 0.0354s/iter; left time: 719.6739s\n",
      "\titers: 200, epoch: 9 | loss: 0.0757727\n",
      "\tspeed: 0.0158s/iter; left time: 318.6162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0766040 Vali Loss: 0.0773319 Test Loss: 0.0813767\n",
      "Validation loss decreased (0.077608 --> 0.077332).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0735397\n",
      "\tspeed: 0.0369s/iter; left time: 740.8621s\n",
      "\titers: 200, epoch: 10 | loss: 0.0794665\n",
      "\tspeed: 0.0164s/iter; left time: 328.3716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0760296 Vali Loss: 0.0770209 Test Loss: 0.0814560\n",
      "Validation loss decreased (0.077332 --> 0.077021).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0747499\n",
      "\tspeed: 0.0370s/iter; left time: 735.2754s\n",
      "\titers: 200, epoch: 11 | loss: 0.0756375\n",
      "\tspeed: 0.0165s/iter; left time: 325.7696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0754948 Vali Loss: 0.0773987 Test Loss: 0.0817112\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0736938\n",
      "\tspeed: 0.0367s/iter; left time: 721.3324s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756246\n",
      "\tspeed: 0.0164s/iter; left time: 321.5687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0751052 Vali Loss: 0.0768902 Test Loss: 0.0815840\n",
      "Validation loss decreased (0.077021 --> 0.076890).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766086\n",
      "\tspeed: 0.0368s/iter; left time: 714.8905s\n",
      "\titers: 200, epoch: 13 | loss: 0.0705611\n",
      "\tspeed: 0.0165s/iter; left time: 319.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0746385 Vali Loss: 0.0769166 Test Loss: 0.0817023\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0752744\n",
      "\tspeed: 0.0358s/iter; left time: 688.5627s\n",
      "\titers: 200, epoch: 14 | loss: 0.0727744\n",
      "\tspeed: 0.0164s/iter; left time: 313.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0742598 Vali Loss: 0.0771264 Test Loss: 0.0818628\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0718330\n",
      "\tspeed: 0.0362s/iter; left time: 687.1020s\n",
      "\titers: 200, epoch: 15 | loss: 0.0762048\n",
      "\tspeed: 0.0165s/iter; left time: 311.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0739807 Vali Loss: 0.0771396 Test Loss: 0.0821665\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0717527\n",
      "\tspeed: 0.0357s/iter; left time: 670.9901s\n",
      "\titers: 200, epoch: 16 | loss: 0.0717268\n",
      "\tspeed: 0.0164s/iter; left time: 307.0880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0736803 Vali Loss: 0.0769131 Test Loss: 0.0820079\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0754391\n",
      "\tspeed: 0.0358s/iter; left time: 664.4454s\n",
      "\titers: 200, epoch: 17 | loss: 0.0759702\n",
      "\tspeed: 0.0164s/iter; left time: 302.9243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0734304 Vali Loss: 0.0771116 Test Loss: 0.0819217\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0734905\n",
      "\tspeed: 0.0361s/iter; left time: 661.7668s\n",
      "\titers: 200, epoch: 18 | loss: 0.0709522\n",
      "\tspeed: 0.0165s/iter; left time: 299.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0731816 Vali Loss: 0.0769015 Test Loss: 0.0822031\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0715518\n",
      "\tspeed: 0.0368s/iter; left time: 665.9818s\n",
      "\titers: 200, epoch: 19 | loss: 0.0747448\n",
      "\tspeed: 0.0165s/iter; left time: 296.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0729965 Vali Loss: 0.0771511 Test Loss: 0.0821523\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0736236\n",
      "\tspeed: 0.0371s/iter; left time: 662.7975s\n",
      "\titers: 200, epoch: 20 | loss: 0.0729047\n",
      "\tspeed: 0.0164s/iter; left time: 291.6173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0728174 Vali Loss: 0.0772877 Test Loss: 0.0821367\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0751020\n",
      "\tspeed: 0.0346s/iter; left time: 610.5431s\n",
      "\titers: 200, epoch: 21 | loss: 0.0710079\n",
      "\tspeed: 0.0158s/iter; left time: 277.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.0725626 Vali Loss: 0.0770003 Test Loss: 0.0822969\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0741920\n",
      "\tspeed: 0.0359s/iter; left time: 626.7563s\n",
      "\titers: 200, epoch: 22 | loss: 0.0669616\n",
      "\tspeed: 0.0158s/iter; left time: 274.7855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0725037 Vali Loss: 0.0770790 Test Loss: 0.0823455\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01853265054523945, rmse:0.13613468408584595, mae:0.08158402144908905, rse:0.5147398710250854\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1555070\n",
      "\tspeed: 0.0188s/iter; left time: 415.4164s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291604\n",
      "\tspeed: 0.0165s/iter; left time: 363.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.1573724 Vali Loss: 0.1145640 Test Loss: 0.1174751\n",
      "Validation loss decreased (inf --> 0.114564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0941553\n",
      "\tspeed: 0.0375s/iter; left time: 820.3077s\n",
      "\titers: 200, epoch: 2 | loss: 0.0865144\n",
      "\tspeed: 0.0166s/iter; left time: 360.7934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0970681 Vali Loss: 0.0823746 Test Loss: 0.0858983\n",
      "Validation loss decreased (0.114564 --> 0.082375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0863378\n",
      "\tspeed: 0.0433s/iter; left time: 936.8382s\n",
      "\titers: 200, epoch: 3 | loss: 0.0803839\n",
      "\tspeed: 0.0165s/iter; left time: 356.0279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.97s\n",
      "Steps: 222 | Train Loss: 0.0852200 Vali Loss: 0.0797426 Test Loss: 0.0836973\n",
      "Validation loss decreased (0.082375 --> 0.079743).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0865159\n",
      "\tspeed: 0.0367s/iter; left time: 787.5020s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848909\n",
      "\tspeed: 0.0166s/iter; left time: 353.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0822031 Vali Loss: 0.0791175 Test Loss: 0.0827647\n",
      "Validation loss decreased (0.079743 --> 0.079117).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0796207\n",
      "\tspeed: 0.0371s/iter; left time: 787.0930s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791748\n",
      "\tspeed: 0.0166s/iter; left time: 349.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0803477 Vali Loss: 0.0786148 Test Loss: 0.0820616\n",
      "Validation loss decreased (0.079117 --> 0.078615).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0757173\n",
      "\tspeed: 0.0360s/iter; left time: 756.3029s\n",
      "\titers: 200, epoch: 6 | loss: 0.0754393\n",
      "\tspeed: 0.0160s/iter; left time: 334.1996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0790370 Vali Loss: 0.0781819 Test Loss: 0.0819740\n",
      "Validation loss decreased (0.078615 --> 0.078182).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0745518\n",
      "\tspeed: 0.0365s/iter; left time: 758.0714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756573\n",
      "\tspeed: 0.0161s/iter; left time: 333.1330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0780410 Vali Loss: 0.0776998 Test Loss: 0.0820251\n",
      "Validation loss decreased (0.078182 --> 0.077700).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0742693\n",
      "\tspeed: 0.0364s/iter; left time: 748.2809s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745044\n",
      "\tspeed: 0.0161s/iter; left time: 328.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0772031 Vali Loss: 0.0774395 Test Loss: 0.0818786\n",
      "Validation loss decreased (0.077700 --> 0.077440).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0742239\n",
      "\tspeed: 0.0355s/iter; left time: 720.6571s\n",
      "\titers: 200, epoch: 9 | loss: 0.0791291\n",
      "\tspeed: 0.0159s/iter; left time: 322.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.80s\n",
      "Steps: 222 | Train Loss: 0.0764999 Vali Loss: 0.0772092 Test Loss: 0.0817916\n",
      "Validation loss decreased (0.077440 --> 0.077209).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0737181\n",
      "\tspeed: 0.0365s/iter; left time: 733.2958s\n",
      "\titers: 200, epoch: 10 | loss: 0.0773580\n",
      "\tspeed: 0.0165s/iter; left time: 329.2441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0758682 Vali Loss: 0.0770861 Test Loss: 0.0817229\n",
      "Validation loss decreased (0.077209 --> 0.077086).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0770987\n",
      "\tspeed: 0.0370s/iter; left time: 735.6306s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737798\n",
      "\tspeed: 0.0164s/iter; left time: 324.7676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0753195 Vali Loss: 0.0769910 Test Loss: 0.0821812\n",
      "Validation loss decreased (0.077086 --> 0.076991).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0734271\n",
      "\tspeed: 0.0359s/iter; left time: 704.8145s\n",
      "\titers: 200, epoch: 12 | loss: 0.0721675\n",
      "\tspeed: 0.0158s/iter; left time: 308.3146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.77s\n",
      "Steps: 222 | Train Loss: 0.0747707 Vali Loss: 0.0769323 Test Loss: 0.0819397\n",
      "Validation loss decreased (0.076991 --> 0.076932).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0738018\n",
      "\tspeed: 0.0355s/iter; left time: 689.2617s\n",
      "\titers: 200, epoch: 13 | loss: 0.0714348\n",
      "\tspeed: 0.0158s/iter; left time: 306.2562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.75s\n",
      "Steps: 222 | Train Loss: 0.0743572 Vali Loss: 0.0772886 Test Loss: 0.0821857\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0731976\n",
      "\tspeed: 0.0350s/iter; left time: 671.9581s\n",
      "\titers: 200, epoch: 14 | loss: 0.0656593\n",
      "\tspeed: 0.0160s/iter; left time: 305.0419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.79s\n",
      "Steps: 222 | Train Loss: 0.0740338 Vali Loss: 0.0775655 Test Loss: 0.0819620\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0748007\n",
      "\tspeed: 0.0347s/iter; left time: 659.7460s\n",
      "\titers: 200, epoch: 15 | loss: 0.0750588\n",
      "\tspeed: 0.0158s/iter; left time: 298.2025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.73s\n",
      "Steps: 222 | Train Loss: 0.0736843 Vali Loss: 0.0771802 Test Loss: 0.0821792\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0737958\n",
      "\tspeed: 0.0348s/iter; left time: 652.7509s\n",
      "\titers: 200, epoch: 16 | loss: 0.0730467\n",
      "\tspeed: 0.0160s/iter; left time: 297.8047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.76s\n",
      "Steps: 222 | Train Loss: 0.0734211 Vali Loss: 0.0773003 Test Loss: 0.0820249\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0751593\n",
      "\tspeed: 0.0351s/iter; left time: 650.7276s\n",
      "\titers: 200, epoch: 17 | loss: 0.0694198\n",
      "\tspeed: 0.0164s/iter; left time: 302.4092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0731247 Vali Loss: 0.0769491 Test Loss: 0.0822842\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0696459\n",
      "\tspeed: 0.0368s/iter; left time: 674.7969s\n",
      "\titers: 200, epoch: 18 | loss: 0.0696081\n",
      "\tspeed: 0.0164s/iter; left time: 298.3630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0728680 Vali Loss: 0.0769823 Test Loss: 0.0821469\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0720809\n",
      "\tspeed: 0.0361s/iter; left time: 654.0462s\n",
      "\titers: 200, epoch: 19 | loss: 0.0725739\n",
      "\tspeed: 0.0164s/iter; left time: 295.6848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0726815 Vali Loss: 0.0770691 Test Loss: 0.0823159\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0681402\n",
      "\tspeed: 0.0360s/iter; left time: 643.0192s\n",
      "\titers: 200, epoch: 20 | loss: 0.0728310\n",
      "\tspeed: 0.0161s/iter; left time: 285.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0724979 Vali Loss: 0.0772694 Test Loss: 0.0823961\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737853\n",
      "\tspeed: 0.0357s/iter; left time: 630.7733s\n",
      "\titers: 200, epoch: 21 | loss: 0.0738573\n",
      "\tspeed: 0.0159s/iter; left time: 279.8313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.78s\n",
      "Steps: 222 | Train Loss: 0.0723262 Vali Loss: 0.0771167 Test Loss: 0.0822710\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0723389\n",
      "\tspeed: 0.0365s/iter; left time: 637.0000s\n",
      "\titers: 200, epoch: 22 | loss: 0.0719887\n",
      "\tspeed: 0.0164s/iter; left time: 283.6821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0721758 Vali Loss: 0.0773189 Test Loss: 0.0822954\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_IT_PatchTST_custom_ftM_sl512_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01885984279215336, rmse:0.13733114302158356, mae:0.08193979412317276, rse:0.5192638635635376\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:01.00s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=512, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1507905\n",
      "\tspeed: 0.0382s/iter; left time: 844.1761s\n",
      "\titers: 200, epoch: 1 | loss: 0.1282871\n",
      "\tspeed: 0.0164s/iter; left time: 360.5312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.08s\n",
      "Steps: 222 | Train Loss: 0.1545451 Vali Loss: 0.1136977 Test Loss: 0.1152371\n",
      "Validation loss decreased (inf --> 0.113698).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0970599\n",
      "\tspeed: 0.0370s/iter; left time: 809.2103s\n",
      "\titers: 200, epoch: 2 | loss: 0.0932366\n",
      "\tspeed: 0.0164s/iter; left time: 356.5207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.1000816 Vali Loss: 0.0867449 Test Loss: 0.0896152\n",
      "Validation loss decreased (0.113698 --> 0.086745).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0901877\n",
      "\tspeed: 0.0367s/iter; left time: 794.7552s\n",
      "\titers: 200, epoch: 3 | loss: 0.0865992\n",
      "\tspeed: 0.0164s/iter; left time: 353.6602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0889035 Vali Loss: 0.0849238 Test Loss: 0.0875093\n",
      "Validation loss decreased (0.086745 --> 0.084924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0845438\n",
      "\tspeed: 0.0371s/iter; left time: 794.9844s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829936\n",
      "\tspeed: 0.0162s/iter; left time: 346.4339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0859813 Vali Loss: 0.0839607 Test Loss: 0.0871231\n",
      "Validation loss decreased (0.084924 --> 0.083961).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0876910\n",
      "\tspeed: 0.0370s/iter; left time: 784.0312s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828706\n",
      "\tspeed: 0.0164s/iter; left time: 345.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0842898 Vali Loss: 0.0835059 Test Loss: 0.0865171\n",
      "Validation loss decreased (0.083961 --> 0.083506).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0829766\n",
      "\tspeed: 0.0378s/iter; left time: 793.6593s\n",
      "\titers: 200, epoch: 6 | loss: 0.0801894\n",
      "\tspeed: 0.0162s/iter; left time: 338.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0830918 Vali Loss: 0.0831982 Test Loss: 0.0865383\n",
      "Validation loss decreased (0.083506 --> 0.083198).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0817649\n",
      "\tspeed: 0.0364s/iter; left time: 755.7306s\n",
      "\titers: 200, epoch: 7 | loss: 0.0810547\n",
      "\tspeed: 0.0162s/iter; left time: 334.3479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.85s\n",
      "Steps: 222 | Train Loss: 0.0820679 Vali Loss: 0.0825729 Test Loss: 0.0865927\n",
      "Validation loss decreased (0.083198 --> 0.082573).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0778579\n",
      "\tspeed: 0.0370s/iter; left time: 759.4925s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810552\n",
      "\tspeed: 0.0163s/iter; left time: 333.1333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0811687 Vali Loss: 0.0825304 Test Loss: 0.0868129\n",
      "Validation loss decreased (0.082573 --> 0.082530).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791721\n",
      "\tspeed: 0.0401s/iter; left time: 814.8277s\n",
      "\titers: 200, epoch: 9 | loss: 0.0805860\n",
      "\tspeed: 0.0163s/iter; left time: 329.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0804634 Vali Loss: 0.0822290 Test Loss: 0.0871206\n",
      "Validation loss decreased (0.082530 --> 0.082229).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0794385\n",
      "\tspeed: 0.0367s/iter; left time: 737.3827s\n",
      "\titers: 200, epoch: 10 | loss: 0.0797314\n",
      "\tspeed: 0.0163s/iter; left time: 326.1925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0798415 Vali Loss: 0.0824751 Test Loss: 0.0871971\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0778659\n",
      "\tspeed: 0.0357s/iter; left time: 709.6463s\n",
      "\titers: 200, epoch: 11 | loss: 0.0769867\n",
      "\tspeed: 0.0163s/iter; left time: 321.7505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0792664 Vali Loss: 0.0825735 Test Loss: 0.0874378\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0774243\n",
      "\tspeed: 0.0366s/iter; left time: 719.9115s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788503\n",
      "\tspeed: 0.0163s/iter; left time: 319.3774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0787563 Vali Loss: 0.0823296 Test Loss: 0.0874938\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0766882\n",
      "\tspeed: 0.0362s/iter; left time: 703.6906s\n",
      "\titers: 200, epoch: 13 | loss: 0.0737316\n",
      "\tspeed: 0.0162s/iter; left time: 313.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0782796 Vali Loss: 0.0822701 Test Loss: 0.0875234\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0788106\n",
      "\tspeed: 0.0351s/iter; left time: 674.3287s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772315\n",
      "\tspeed: 0.0163s/iter; left time: 311.1276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0779511 Vali Loss: 0.0826971 Test Loss: 0.0877752\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790197\n",
      "\tspeed: 0.0368s/iter; left time: 698.6869s\n",
      "\titers: 200, epoch: 15 | loss: 0.0752131\n",
      "\tspeed: 0.0163s/iter; left time: 307.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0775710 Vali Loss: 0.0821810 Test Loss: 0.0878082\n",
      "Validation loss decreased (0.082229 --> 0.082181).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0786629\n",
      "\tspeed: 0.0370s/iter; left time: 694.8623s\n",
      "\titers: 200, epoch: 16 | loss: 0.0768897\n",
      "\tspeed: 0.0163s/iter; left time: 303.6119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0772676 Vali Loss: 0.0823011 Test Loss: 0.0877939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0767586\n",
      "\tspeed: 0.0361s/iter; left time: 669.9302s\n",
      "\titers: 200, epoch: 17 | loss: 0.0751727\n",
      "\tspeed: 0.0164s/iter; left time: 302.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0769386 Vali Loss: 0.0821689 Test Loss: 0.0880645\n",
      "Validation loss decreased (0.082181 --> 0.082169).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0767126\n",
      "\tspeed: 0.0380s/iter; left time: 695.9389s\n",
      "\titers: 200, epoch: 18 | loss: 0.0760278\n",
      "\tspeed: 0.0163s/iter; left time: 297.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0767086 Vali Loss: 0.0820294 Test Loss: 0.0878732\n",
      "Validation loss decreased (0.082169 --> 0.082029).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0766538\n",
      "\tspeed: 0.0377s/iter; left time: 683.0824s\n",
      "\titers: 200, epoch: 19 | loss: 0.0754637\n",
      "\tspeed: 0.0162s/iter; left time: 291.2174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.94s\n",
      "Steps: 222 | Train Loss: 0.0764047 Vali Loss: 0.0825537 Test Loss: 0.0882137\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0749426\n",
      "\tspeed: 0.0370s/iter; left time: 661.5998s\n",
      "\titers: 200, epoch: 20 | loss: 0.0740511\n",
      "\tspeed: 0.0159s/iter; left time: 283.3205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.83s\n",
      "Steps: 222 | Train Loss: 0.0762095 Vali Loss: 0.0826038 Test Loss: 0.0883427\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0775036\n",
      "\tspeed: 0.0362s/iter; left time: 640.1150s\n",
      "\titers: 200, epoch: 21 | loss: 0.0772584\n",
      "\tspeed: 0.0159s/iter; left time: 279.9591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.81s\n",
      "Steps: 222 | Train Loss: 0.0760702 Vali Loss: 0.0821933 Test Loss: 0.0881386\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0763429\n",
      "\tspeed: 0.0374s/iter; left time: 651.8201s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750307\n",
      "\tspeed: 0.0164s/iter; left time: 284.2562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.99s\n",
      "Steps: 222 | Train Loss: 0.0758558 Vali Loss: 0.0824308 Test Loss: 0.0883022\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0729752\n",
      "\tspeed: 0.0377s/iter; left time: 649.1111s\n",
      "\titers: 200, epoch: 23 | loss: 0.0740452\n",
      "\tspeed: 0.0165s/iter; left time: 283.1583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0757018 Vali Loss: 0.0825302 Test Loss: 0.0882507\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0720513\n",
      "\tspeed: 0.0367s/iter; left time: 623.7802s\n",
      "\titers: 200, epoch: 24 | loss: 0.0763470\n",
      "\tspeed: 0.0164s/iter; left time: 277.9157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0756011 Vali Loss: 0.0824944 Test Loss: 0.0883199\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0745154\n",
      "\tspeed: 0.0360s/iter; left time: 604.1818s\n",
      "\titers: 200, epoch: 25 | loss: 0.0729336\n",
      "\tspeed: 0.0165s/iter; left time: 275.7945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0754408 Vali Loss: 0.0824659 Test Loss: 0.0882696\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0767272\n",
      "\tspeed: 0.0370s/iter; left time: 613.0106s\n",
      "\titers: 200, epoch: 26 | loss: 0.0745950\n",
      "\tspeed: 0.0165s/iter; left time: 271.4127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:03.96s\n",
      "Steps: 222 | Train Loss: 0.0753240 Vali Loss: 0.0825830 Test Loss: 0.0882900\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0760082\n",
      "\tspeed: 0.0364s/iter; left time: 594.7633s\n",
      "\titers: 200, epoch: 27 | loss: 0.0752839\n",
      "\tspeed: 0.0165s/iter; left time: 267.5580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0751577 Vali Loss: 0.0826097 Test Loss: 0.0884141\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0759595\n",
      "\tspeed: 0.0368s/iter; left time: 593.5219s\n",
      "\titers: 200, epoch: 28 | loss: 0.0739208\n",
      "\tspeed: 0.0165s/iter; left time: 263.5797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0751573 Vali Loss: 0.0824285 Test Loss: 0.0884090\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02078671008348465, rmse:0.14417597651481628, mae:0.08787322044372559, rse:0.5456514358520508\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1588684\n",
      "\tspeed: 0.0188s/iter; left time: 415.6308s\n",
      "\titers: 200, epoch: 1 | loss: 0.1307499\n",
      "\tspeed: 0.0164s/iter; left time: 360.7968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.1593690 Vali Loss: 0.1162165 Test Loss: 0.1180349\n",
      "Validation loss decreased (inf --> 0.116216).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1008547\n",
      "\tspeed: 0.0375s/iter; left time: 821.3231s\n",
      "\titers: 200, epoch: 2 | loss: 0.0937861\n",
      "\tspeed: 0.0163s/iter; left time: 354.5465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.1003901 Vali Loss: 0.0868620 Test Loss: 0.0896006\n",
      "Validation loss decreased (0.116216 --> 0.086862).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888271\n",
      "\tspeed: 0.0374s/iter; left time: 810.1001s\n",
      "\titers: 200, epoch: 3 | loss: 0.0911564\n",
      "\tspeed: 0.0165s/iter; left time: 356.0754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:03.98s\n",
      "Steps: 222 | Train Loss: 0.0890265 Vali Loss: 0.0849301 Test Loss: 0.0880268\n",
      "Validation loss decreased (0.086862 --> 0.084930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0843602\n",
      "\tspeed: 0.0390s/iter; left time: 835.2337s\n",
      "\titers: 200, epoch: 4 | loss: 0.0838501\n",
      "\tspeed: 0.0164s/iter; left time: 349.2994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0860878 Vali Loss: 0.0843046 Test Loss: 0.0873117\n",
      "Validation loss decreased (0.084930 --> 0.084305).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0835603\n",
      "\tspeed: 0.0367s/iter; left time: 779.2895s\n",
      "\titers: 200, epoch: 5 | loss: 0.0828689\n",
      "\tspeed: 0.0165s/iter; left time: 347.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0842355 Vali Loss: 0.0835095 Test Loss: 0.0871982\n",
      "Validation loss decreased (0.084305 --> 0.083509).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0835187\n",
      "\tspeed: 0.0369s/iter; left time: 774.1946s\n",
      "\titers: 200, epoch: 6 | loss: 0.0786849\n",
      "\tspeed: 0.0164s/iter; left time: 341.9909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:03.92s\n",
      "Steps: 222 | Train Loss: 0.0829455 Vali Loss: 0.0835323 Test Loss: 0.0873093\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830474\n",
      "\tspeed: 0.0369s/iter; left time: 766.7769s\n",
      "\titers: 200, epoch: 7 | loss: 0.0812496\n",
      "\tspeed: 0.0164s/iter; left time: 339.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:03.95s\n",
      "Steps: 222 | Train Loss: 0.0819120 Vali Loss: 0.0830870 Test Loss: 0.0872568\n",
      "Validation loss decreased (0.083509 --> 0.083087).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0838625\n",
      "\tspeed: 0.0372s/iter; left time: 764.7108s\n",
      "\titers: 200, epoch: 8 | loss: 0.0784900\n",
      "\tspeed: 0.0164s/iter; left time: 334.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0810798 Vali Loss: 0.0831313 Test Loss: 0.0880330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0791416\n",
      "\tspeed: 0.0371s/iter; left time: 754.8257s\n",
      "\titers: 200, epoch: 9 | loss: 0.0808412\n",
      "\tspeed: 0.0164s/iter; left time: 330.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0802783 Vali Loss: 0.0830388 Test Loss: 0.0879317\n",
      "Validation loss decreased (0.083087 --> 0.083039).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0792002\n",
      "\tspeed: 0.0374s/iter; left time: 752.6241s\n",
      "\titers: 200, epoch: 10 | loss: 0.0773338\n",
      "\tspeed: 0.0163s/iter; left time: 326.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0795180 Vali Loss: 0.0834733 Test Loss: 0.0879787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0762878\n",
      "\tspeed: 0.0371s/iter; left time: 737.1915s\n",
      "\titers: 200, epoch: 11 | loss: 0.0782936\n",
      "\tspeed: 0.0162s/iter; left time: 321.1985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:03.90s\n",
      "Steps: 222 | Train Loss: 0.0788952 Vali Loss: 0.0829030 Test Loss: 0.0884762\n",
      "Validation loss decreased (0.083039 --> 0.082903).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0787625\n",
      "\tspeed: 0.0376s/iter; left time: 738.3572s\n",
      "\titers: 200, epoch: 12 | loss: 0.0816671\n",
      "\tspeed: 0.0164s/iter; left time: 320.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:03.93s\n",
      "Steps: 222 | Train Loss: 0.0782911 Vali Loss: 0.0827228 Test Loss: 0.0883598\n",
      "Validation loss decreased (0.082903 --> 0.082723).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0740193\n",
      "\tspeed: 0.0370s/iter; left time: 719.3062s\n",
      "\titers: 200, epoch: 13 | loss: 0.0803092\n",
      "\tspeed: 0.0163s/iter; left time: 314.6077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0777800 Vali Loss: 0.0827499 Test Loss: 0.0887310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0779402\n",
      "\tspeed: 0.0362s/iter; left time: 695.9827s\n",
      "\titers: 200, epoch: 14 | loss: 0.0750769\n",
      "\tspeed: 0.0163s/iter; left time: 311.5593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:03.87s\n",
      "Steps: 222 | Train Loss: 0.0773386 Vali Loss: 0.0829793 Test Loss: 0.0888920\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0790265\n",
      "\tspeed: 0.0357s/iter; left time: 678.3548s\n",
      "\titers: 200, epoch: 15 | loss: 0.0794962\n",
      "\tspeed: 0.0163s/iter; left time: 307.8987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0769541 Vali Loss: 0.0830877 Test Loss: 0.0888542\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0767698\n",
      "\tspeed: 0.0355s/iter; left time: 666.9624s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772384\n",
      "\tspeed: 0.0162s/iter; left time: 302.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:03.84s\n",
      "Steps: 222 | Train Loss: 0.0765659 Vali Loss: 0.0831581 Test Loss: 0.0890574\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0771411\n",
      "\tspeed: 0.0373s/iter; left time: 691.6071s\n",
      "\titers: 200, epoch: 17 | loss: 0.0769504\n",
      "\tspeed: 0.0162s/iter; left time: 299.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:03.91s\n",
      "Steps: 222 | Train Loss: 0.0762588 Vali Loss: 0.0831008 Test Loss: 0.0889786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0769279\n",
      "\tspeed: 0.0370s/iter; left time: 677.9868s\n",
      "\titers: 200, epoch: 18 | loss: 0.0737021\n",
      "\tspeed: 0.0163s/iter; left time: 297.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0759188 Vali Loss: 0.0831228 Test Loss: 0.0892668\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0785338\n",
      "\tspeed: 0.0367s/iter; left time: 664.0649s\n",
      "\titers: 200, epoch: 19 | loss: 0.0728545\n",
      "\tspeed: 0.0164s/iter; left time: 294.5972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:03.89s\n",
      "Steps: 222 | Train Loss: 0.0756867 Vali Loss: 0.0835317 Test Loss: 0.0894047\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0749899\n",
      "\tspeed: 0.0359s/iter; left time: 642.1878s\n",
      "\titers: 200, epoch: 20 | loss: 0.0766533\n",
      "\tspeed: 0.0163s/iter; left time: 290.0206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0754356 Vali Loss: 0.0833911 Test Loss: 0.0893575\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0747033\n",
      "\tspeed: 0.0364s/iter; left time: 642.0154s\n",
      "\titers: 200, epoch: 21 | loss: 0.0747439\n",
      "\tspeed: 0.0162s/iter; left time: 284.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:03.86s\n",
      "Steps: 222 | Train Loss: 0.0752699 Vali Loss: 0.0832443 Test Loss: 0.0893365\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0735475\n",
      "\tspeed: 0.0360s/iter; left time: 627.7970s\n",
      "\titers: 200, epoch: 22 | loss: 0.0784438\n",
      "\tspeed: 0.0163s/iter; left time: 283.0251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:03.88s\n",
      "Steps: 222 | Train Loss: 0.0750556 Vali Loss: 0.0834173 Test Loss: 0.0895010\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_IT_PatchTST_custom_ftM_sl512_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021248484030365944, rmse:0.14576859772205353, mae:0.0883597806096077, rse:0.5516789555549622\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:36.52s\n",
      "Intermediate time for IT: 00h:19m:07.18s\n",
      "Total time: 01h:33m:53.12s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PatchTST/64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.1906</td>\n",
       "      <td>0.1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.0555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.0999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>0.1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.0881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            PatchTST/64                \n",
       "Metrics                  MSE    RMSE     MAE\n",
       "Country Pred_len                            \n",
       "DE      24            0.0212  0.1454  0.0883\n",
       "        96            0.0363  0.1906  0.1267\n",
       "        168           0.0385  0.1963  0.1333\n",
       "ES      24            0.0098  0.0991  0.0598\n",
       "        96            0.0187  0.1368  0.0882\n",
       "        168           0.0210  0.1450  0.0947\n",
       "FR      24            0.0101  0.1005  0.0555\n",
       "        96            0.0193  0.1389  0.0809\n",
       "        168           0.0212  0.1457  0.0865\n",
       "GB      24            0.0251  0.1586  0.0999\n",
       "        96            0.0414  0.2034  0.1387\n",
       "        168           0.0443  0.2104  0.1460\n",
       "IT      24            0.0101  0.1004  0.0573\n",
       "        96            0.0187  0.1367  0.0818\n",
       "        168           0.0210  0.1450  0.0881"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['PatchTST/64'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_bs128_pl512.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
