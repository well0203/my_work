{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax Scaler Informer](#3-minmax-scaler-informer)\n",
    "- [4. MinMax Scaler PatchTST](#4-minmax-scaler-patchtst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on **Germany** dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. \n",
    "\n",
    "**For Standard Scaler and MinMax we tried learning rates: 0.0001, 0.00001, 0.000001.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9104970\n",
      "\tspeed: 0.0792s/iter; left time: 1427.5213s\n",
      "\titers: 200, epoch: 1 | loss: 0.8711158\n",
      "\tspeed: 0.0487s/iter; left time: 872.9434s\n",
      "\titers: 300, epoch: 1 | loss: 0.8038976\n",
      "\tspeed: 0.0488s/iter; left time: 869.5116s\n",
      "\titers: 400, epoch: 1 | loss: 0.7513130\n",
      "\tspeed: 0.0490s/iter; left time: 868.6074s\n",
      "\titers: 500, epoch: 1 | loss: 0.6295568\n",
      "\tspeed: 0.0488s/iter; left time: 859.2839s\n",
      "\titers: 600, epoch: 1 | loss: 0.5829157\n",
      "\tspeed: 0.0487s/iter; left time: 853.8880s\n",
      "\titers: 700, epoch: 1 | loss: 0.7766658\n",
      "\tspeed: 0.0489s/iter; left time: 852.2430s\n",
      "\titers: 800, epoch: 1 | loss: 0.5712127\n",
      "\tspeed: 0.0487s/iter; left time: 844.3359s\n",
      "\titers: 900, epoch: 1 | loss: 0.4657794\n",
      "\tspeed: 0.0486s/iter; left time: 836.9512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 906 | Train Loss: 0.7501092 Vali Loss: 0.6983547 Test Loss: 0.8220211\n",
      "Validation loss decreased (inf --> 0.698355).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3802336\n",
      "\tspeed: 0.1148s/iter; left time: 1964.4605s\n",
      "\titers: 200, epoch: 2 | loss: 0.6111795\n",
      "\tspeed: 0.0459s/iter; left time: 780.9971s\n",
      "\titers: 300, epoch: 2 | loss: 0.4284708\n",
      "\tspeed: 0.0457s/iter; left time: 772.8035s\n",
      "\titers: 400, epoch: 2 | loss: 0.3482813\n",
      "\tspeed: 0.0458s/iter; left time: 770.2304s\n",
      "\titers: 500, epoch: 2 | loss: 0.3832674\n",
      "\tspeed: 0.0458s/iter; left time: 765.0921s\n",
      "\titers: 600, epoch: 2 | loss: 0.3144601\n",
      "\tspeed: 0.0457s/iter; left time: 759.5749s\n",
      "\titers: 700, epoch: 2 | loss: 0.3589360\n",
      "\tspeed: 0.0457s/iter; left time: 754.2164s\n",
      "\titers: 800, epoch: 2 | loss: 0.3370725\n",
      "\tspeed: 0.0460s/iter; left time: 755.1841s\n",
      "\titers: 900, epoch: 2 | loss: 0.2957594\n",
      "\tspeed: 0.0458s/iter; left time: 747.8194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 906 | Train Loss: 0.3711995 Vali Loss: 0.4807511 Test Loss: 0.5183359\n",
      "Validation loss decreased (0.698355 --> 0.480751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3875117\n",
      "\tspeed: 0.1115s/iter; left time: 1807.1758s\n",
      "\titers: 200, epoch: 3 | loss: 0.3094494\n",
      "\tspeed: 0.0452s/iter; left time: 728.1003s\n",
      "\titers: 300, epoch: 3 | loss: 0.2973114\n",
      "\tspeed: 0.0462s/iter; left time: 738.9822s\n",
      "\titers: 400, epoch: 3 | loss: 0.2883330\n",
      "\tspeed: 0.0461s/iter; left time: 733.9347s\n",
      "\titers: 500, epoch: 3 | loss: 0.2615284\n",
      "\tspeed: 0.0460s/iter; left time: 727.1989s\n",
      "\titers: 600, epoch: 3 | loss: 0.2627238\n",
      "\tspeed: 0.0458s/iter; left time: 719.3086s\n",
      "\titers: 700, epoch: 3 | loss: 0.2122257\n",
      "\tspeed: 0.0457s/iter; left time: 713.6532s\n",
      "\titers: 800, epoch: 3 | loss: 0.3070318\n",
      "\tspeed: 0.0457s/iter; left time: 708.4092s\n",
      "\titers: 900, epoch: 3 | loss: 0.2688614\n",
      "\tspeed: 0.0455s/iter; left time: 701.7491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.2904149 Vali Loss: 0.4616562 Test Loss: 0.5247303\n",
      "Validation loss decreased (0.480751 --> 0.461656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2526511\n",
      "\tspeed: 0.1112s/iter; left time: 1702.0198s\n",
      "\titers: 200, epoch: 4 | loss: 0.3215090\n",
      "\tspeed: 0.0458s/iter; left time: 696.8022s\n",
      "\titers: 300, epoch: 4 | loss: 0.2669591\n",
      "\tspeed: 0.0456s/iter; left time: 688.2762s\n",
      "\titers: 400, epoch: 4 | loss: 0.2451770\n",
      "\tspeed: 0.0455s/iter; left time: 682.3172s\n",
      "\titers: 500, epoch: 4 | loss: 0.2993646\n",
      "\tspeed: 0.0455s/iter; left time: 677.9239s\n",
      "\titers: 600, epoch: 4 | loss: 0.3083833\n",
      "\tspeed: 0.0458s/iter; left time: 677.7311s\n",
      "\titers: 700, epoch: 4 | loss: 0.2911207\n",
      "\tspeed: 0.0456s/iter; left time: 669.7236s\n",
      "\titers: 800, epoch: 4 | loss: 0.2631357\n",
      "\tspeed: 0.0456s/iter; left time: 666.1386s\n",
      "\titers: 900, epoch: 4 | loss: 0.1568320\n",
      "\tspeed: 0.0455s/iter; left time: 659.3494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.52s\n",
      "Steps: 906 | Train Loss: 0.2592014 Vali Loss: 0.4736970 Test Loss: 0.4936007\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2179513\n",
      "\tspeed: 0.1090s/iter; left time: 1569.1942s\n",
      "\titers: 200, epoch: 5 | loss: 0.1931886\n",
      "\tspeed: 0.0462s/iter; left time: 660.3731s\n",
      "\titers: 300, epoch: 5 | loss: 0.2392450\n",
      "\tspeed: 0.0464s/iter; left time: 658.0756s\n",
      "\titers: 400, epoch: 5 | loss: 0.2803777\n",
      "\tspeed: 0.0461s/iter; left time: 649.4182s\n",
      "\titers: 500, epoch: 5 | loss: 0.2224879\n",
      "\tspeed: 0.0462s/iter; left time: 646.8812s\n",
      "\titers: 600, epoch: 5 | loss: 0.2797216\n",
      "\tspeed: 0.0462s/iter; left time: 641.7033s\n",
      "\titers: 700, epoch: 5 | loss: 0.2974651\n",
      "\tspeed: 0.0462s/iter; left time: 638.0257s\n",
      "\titers: 800, epoch: 5 | loss: 0.2284474\n",
      "\tspeed: 0.0461s/iter; left time: 631.1829s\n",
      "\titers: 900, epoch: 5 | loss: 0.2488129\n",
      "\tspeed: 0.0462s/iter; left time: 628.8411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 906 | Train Loss: 0.2277873 Vali Loss: 0.4834140 Test Loss: 0.5247088\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1752480\n",
      "\tspeed: 0.1087s/iter; left time: 1465.9322s\n",
      "\titers: 200, epoch: 6 | loss: 0.1714603\n",
      "\tspeed: 0.0458s/iter; left time: 613.1119s\n",
      "\titers: 300, epoch: 6 | loss: 0.2042173\n",
      "\tspeed: 0.0458s/iter; left time: 608.3553s\n",
      "\titers: 400, epoch: 6 | loss: 0.2316877\n",
      "\tspeed: 0.0460s/iter; left time: 606.9190s\n",
      "\titers: 500, epoch: 6 | loss: 0.2160948\n",
      "\tspeed: 0.0452s/iter; left time: 591.6857s\n",
      "\titers: 600, epoch: 6 | loss: 0.1734637\n",
      "\tspeed: 0.0457s/iter; left time: 594.2602s\n",
      "\titers: 700, epoch: 6 | loss: 0.1899715\n",
      "\tspeed: 0.0457s/iter; left time: 588.8867s\n",
      "\titers: 800, epoch: 6 | loss: 0.1790908\n",
      "\tspeed: 0.0457s/iter; left time: 585.1742s\n",
      "\titers: 900, epoch: 6 | loss: 0.1842958\n",
      "\tspeed: 0.0457s/iter; left time: 580.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.65s\n",
      "Steps: 906 | Train Loss: 0.2010258 Vali Loss: 0.4921048 Test Loss: 0.5407787\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1823340\n",
      "\tspeed: 0.1084s/iter; left time: 1364.4684s\n",
      "\titers: 200, epoch: 7 | loss: 0.1805010\n",
      "\tspeed: 0.0460s/iter; left time: 574.7701s\n",
      "\titers: 300, epoch: 7 | loss: 0.1972598\n",
      "\tspeed: 0.0457s/iter; left time: 565.8883s\n",
      "\titers: 400, epoch: 7 | loss: 0.1803806\n",
      "\tspeed: 0.0456s/iter; left time: 560.0734s\n",
      "\titers: 500, epoch: 7 | loss: 0.2101067\n",
      "\tspeed: 0.0456s/iter; left time: 555.9064s\n",
      "\titers: 600, epoch: 7 | loss: 0.1571381\n",
      "\tspeed: 0.0460s/iter; left time: 555.6014s\n",
      "\titers: 700, epoch: 7 | loss: 0.1744555\n",
      "\tspeed: 0.0458s/iter; left time: 549.4652s\n",
      "\titers: 800, epoch: 7 | loss: 0.1387538\n",
      "\tspeed: 0.0458s/iter; left time: 543.9854s\n",
      "\titers: 900, epoch: 7 | loss: 0.1815638\n",
      "\tspeed: 0.0459s/iter; left time: 540.6930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.1769158 Vali Loss: 0.4869587 Test Loss: 0.5433283\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1460735\n",
      "\tspeed: 0.1110s/iter; left time: 1296.0177s\n",
      "\titers: 200, epoch: 8 | loss: 0.2011652\n",
      "\tspeed: 0.0459s/iter; left time: 531.8630s\n",
      "\titers: 300, epoch: 8 | loss: 0.1611235\n",
      "\tspeed: 0.0459s/iter; left time: 527.3853s\n",
      "\titers: 400, epoch: 8 | loss: 0.1481988\n",
      "\tspeed: 0.0457s/iter; left time: 520.2557s\n",
      "\titers: 500, epoch: 8 | loss: 0.1455447\n",
      "\tspeed: 0.0460s/iter; left time: 518.5952s\n",
      "\titers: 600, epoch: 8 | loss: 0.1820050\n",
      "\tspeed: 0.0459s/iter; left time: 513.2983s\n",
      "\titers: 700, epoch: 8 | loss: 0.1521713\n",
      "\tspeed: 0.0458s/iter; left time: 507.0675s\n",
      "\titers: 800, epoch: 8 | loss: 0.1509119\n",
      "\tspeed: 0.0459s/iter; left time: 504.3253s\n",
      "\titers: 900, epoch: 8 | loss: 0.1970310\n",
      "\tspeed: 0.0459s/iter; left time: 499.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.1576567 Vali Loss: 0.5108601 Test Loss: 0.5493667\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5247083902359009, rmse:0.7243675589561462, mae:0.5114242434501648, rse:0.5732911825180054\n",
      "Original data scale mse:21980930.0, rmse:4688.38232421875, mae:3161.35595703125, rse:0.23311582207679749\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0628076\n",
      "\tspeed: 0.0514s/iter; left time: 925.5416s\n",
      "\titers: 200, epoch: 1 | loss: 0.9605696\n",
      "\tspeed: 0.0490s/iter; left time: 877.8913s\n",
      "\titers: 300, epoch: 1 | loss: 0.6938849\n",
      "\tspeed: 0.0493s/iter; left time: 879.2426s\n",
      "\titers: 400, epoch: 1 | loss: 0.7792652\n",
      "\tspeed: 0.0494s/iter; left time: 875.4997s\n",
      "\titers: 500, epoch: 1 | loss: 0.6813926\n",
      "\tspeed: 0.0491s/iter; left time: 865.7961s\n",
      "\titers: 600, epoch: 1 | loss: 0.6067265\n",
      "\tspeed: 0.0474s/iter; left time: 830.5685s\n",
      "\titers: 700, epoch: 1 | loss: 0.5843720\n",
      "\tspeed: 0.0492s/iter; left time: 856.6144s\n",
      "\titers: 800, epoch: 1 | loss: 0.5290220\n",
      "\tspeed: 0.0492s/iter; left time: 851.5320s\n",
      "\titers: 900, epoch: 1 | loss: 0.5730929\n",
      "\tspeed: 0.0492s/iter; left time: 847.7634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.69s\n",
      "Steps: 906 | Train Loss: 0.7625438 Vali Loss: 0.7239302 Test Loss: 0.8687614\n",
      "Validation loss decreased (inf --> 0.723930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3758424\n",
      "\tspeed: 0.1147s/iter; left time: 1963.4642s\n",
      "\titers: 200, epoch: 2 | loss: 0.3646194\n",
      "\tspeed: 0.0456s/iter; left time: 776.6227s\n",
      "\titers: 300, epoch: 2 | loss: 0.3095314\n",
      "\tspeed: 0.0459s/iter; left time: 776.5302s\n",
      "\titers: 400, epoch: 2 | loss: 0.2982154\n",
      "\tspeed: 0.0460s/iter; left time: 773.8835s\n",
      "\titers: 500, epoch: 2 | loss: 0.3897021\n",
      "\tspeed: 0.0459s/iter; left time: 766.5600s\n",
      "\titers: 600, epoch: 2 | loss: 0.3662042\n",
      "\tspeed: 0.0460s/iter; left time: 764.2310s\n",
      "\titers: 700, epoch: 2 | loss: 0.2544575\n",
      "\tspeed: 0.0457s/iter; left time: 755.3873s\n",
      "\titers: 800, epoch: 2 | loss: 0.3526127\n",
      "\tspeed: 0.0458s/iter; left time: 752.2014s\n",
      "\titers: 900, epoch: 2 | loss: 0.3756969\n",
      "\tspeed: 0.0458s/iter; left time: 747.0253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 906 | Train Loss: 0.3695670 Vali Loss: 0.4820793 Test Loss: 0.5092894\n",
      "Validation loss decreased (0.723930 --> 0.482079).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4251068\n",
      "\tspeed: 0.1130s/iter; left time: 1831.6968s\n",
      "\titers: 200, epoch: 3 | loss: 0.3247374\n",
      "\tspeed: 0.0461s/iter; left time: 741.9228s\n",
      "\titers: 300, epoch: 3 | loss: 0.2736883\n",
      "\tspeed: 0.0459s/iter; left time: 735.3097s\n",
      "\titers: 400, epoch: 3 | loss: 0.2713743\n",
      "\tspeed: 0.0457s/iter; left time: 727.4596s\n",
      "\titers: 500, epoch: 3 | loss: 0.2933823\n",
      "\tspeed: 0.0457s/iter; left time: 722.1898s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180786\n",
      "\tspeed: 0.0459s/iter; left time: 720.3403s\n",
      "\titers: 700, epoch: 3 | loss: 0.2748957\n",
      "\tspeed: 0.0458s/iter; left time: 714.2289s\n",
      "\titers: 800, epoch: 3 | loss: 0.2574829\n",
      "\tspeed: 0.0459s/iter; left time: 711.5463s\n",
      "\titers: 900, epoch: 3 | loss: 0.3379675\n",
      "\tspeed: 0.0459s/iter; left time: 706.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.85s\n",
      "Steps: 906 | Train Loss: 0.2899146 Vali Loss: 0.4790719 Test Loss: 0.5009371\n",
      "Validation loss decreased (0.482079 --> 0.479072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2945890\n",
      "\tspeed: 0.1148s/iter; left time: 1756.2287s\n",
      "\titers: 200, epoch: 4 | loss: 0.2658485\n",
      "\tspeed: 0.0454s/iter; left time: 690.6557s\n",
      "\titers: 300, epoch: 4 | loss: 0.2636538\n",
      "\tspeed: 0.0456s/iter; left time: 688.3107s\n",
      "\titers: 400, epoch: 4 | loss: 0.2693836\n",
      "\tspeed: 0.0458s/iter; left time: 686.3942s\n",
      "\titers: 500, epoch: 4 | loss: 0.2935839\n",
      "\tspeed: 0.0457s/iter; left time: 680.5723s\n",
      "\titers: 600, epoch: 4 | loss: 0.2882493\n",
      "\tspeed: 0.0457s/iter; left time: 676.0903s\n",
      "\titers: 700, epoch: 4 | loss: 0.2030391\n",
      "\tspeed: 0.0456s/iter; left time: 670.0559s\n",
      "\titers: 800, epoch: 4 | loss: 0.2573617\n",
      "\tspeed: 0.0457s/iter; left time: 666.6776s\n",
      "\titers: 900, epoch: 4 | loss: 0.2048668\n",
      "\tspeed: 0.0455s/iter; left time: 659.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 906 | Train Loss: 0.2561839 Vali Loss: 0.5148459 Test Loss: 0.5233349\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2761251\n",
      "\tspeed: 0.1111s/iter; left time: 1600.2144s\n",
      "\titers: 200, epoch: 5 | loss: 0.2843397\n",
      "\tspeed: 0.0458s/iter; left time: 654.2708s\n",
      "\titers: 300, epoch: 5 | loss: 0.2273894\n",
      "\tspeed: 0.0457s/iter; left time: 649.2466s\n",
      "\titers: 400, epoch: 5 | loss: 0.2643791\n",
      "\tspeed: 0.0457s/iter; left time: 643.7730s\n",
      "\titers: 500, epoch: 5 | loss: 0.2837206\n",
      "\tspeed: 0.0456s/iter; left time: 638.2886s\n",
      "\titers: 600, epoch: 5 | loss: 0.2163835\n",
      "\tspeed: 0.0454s/iter; left time: 631.0433s\n",
      "\titers: 700, epoch: 5 | loss: 0.2504148\n",
      "\tspeed: 0.0457s/iter; left time: 630.8576s\n",
      "\titers: 800, epoch: 5 | loss: 0.2377587\n",
      "\tspeed: 0.0457s/iter; left time: 626.1601s\n",
      "\titers: 900, epoch: 5 | loss: 0.1449706\n",
      "\tspeed: 0.0457s/iter; left time: 621.3623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 906 | Train Loss: 0.2284436 Vali Loss: 0.4867030 Test Loss: 0.5015737\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1904681\n",
      "\tspeed: 0.1106s/iter; left time: 1491.7101s\n",
      "\titers: 200, epoch: 6 | loss: 0.2041081\n",
      "\tspeed: 0.0460s/iter; left time: 616.6309s\n",
      "\titers: 300, epoch: 6 | loss: 0.1515250\n",
      "\tspeed: 0.0460s/iter; left time: 611.2216s\n",
      "\titers: 400, epoch: 6 | loss: 0.2396197\n",
      "\tspeed: 0.0460s/iter; left time: 606.3233s\n",
      "\titers: 500, epoch: 6 | loss: 0.1940728\n",
      "\tspeed: 0.0460s/iter; left time: 602.7864s\n",
      "\titers: 600, epoch: 6 | loss: 0.2022454\n",
      "\tspeed: 0.0461s/iter; left time: 599.1084s\n",
      "\titers: 700, epoch: 6 | loss: 0.2515428\n",
      "\tspeed: 0.0461s/iter; left time: 594.0410s\n",
      "\titers: 800, epoch: 6 | loss: 0.1635727\n",
      "\tspeed: 0.0456s/iter; left time: 583.8898s\n",
      "\titers: 900, epoch: 6 | loss: 0.1909400\n",
      "\tspeed: 0.0460s/iter; left time: 583.9198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.00s\n",
      "Steps: 906 | Train Loss: 0.2017562 Vali Loss: 0.4742086 Test Loss: 0.5111247\n",
      "Validation loss decreased (0.479072 --> 0.474209).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1812528\n",
      "\tspeed: 0.1162s/iter; left time: 1462.2838s\n",
      "\titers: 200, epoch: 7 | loss: 0.1536006\n",
      "\tspeed: 0.0462s/iter; left time: 576.2597s\n",
      "\titers: 300, epoch: 7 | loss: 0.1356485\n",
      "\tspeed: 0.0460s/iter; left time: 569.6998s\n",
      "\titers: 400, epoch: 7 | loss: 0.1863169\n",
      "\tspeed: 0.0460s/iter; left time: 564.9274s\n",
      "\titers: 500, epoch: 7 | loss: 0.1905580\n",
      "\tspeed: 0.0461s/iter; left time: 561.4784s\n",
      "\titers: 600, epoch: 7 | loss: 0.1704247\n",
      "\tspeed: 0.0462s/iter; left time: 558.1484s\n",
      "\titers: 700, epoch: 7 | loss: 0.1717562\n",
      "\tspeed: 0.0459s/iter; left time: 550.2751s\n",
      "\titers: 800, epoch: 7 | loss: 0.1808064\n",
      "\tspeed: 0.0460s/iter; left time: 546.9784s\n",
      "\titers: 900, epoch: 7 | loss: 0.1531990\n",
      "\tspeed: 0.0460s/iter; left time: 542.2766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 906 | Train Loss: 0.1798702 Vali Loss: 0.5021562 Test Loss: 0.5403028\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1431093\n",
      "\tspeed: 0.1093s/iter; left time: 1276.9727s\n",
      "\titers: 200, epoch: 8 | loss: 0.1501391\n",
      "\tspeed: 0.0457s/iter; left time: 529.3514s\n",
      "\titers: 300, epoch: 8 | loss: 0.1256026\n",
      "\tspeed: 0.0457s/iter; left time: 524.9075s\n",
      "\titers: 400, epoch: 8 | loss: 0.1316871\n",
      "\tspeed: 0.0458s/iter; left time: 521.7095s\n",
      "\titers: 500, epoch: 8 | loss: 0.1367774\n",
      "\tspeed: 0.0458s/iter; left time: 516.5860s\n",
      "\titers: 600, epoch: 8 | loss: 0.1498744\n",
      "\tspeed: 0.0458s/iter; left time: 511.8350s\n",
      "\titers: 700, epoch: 8 | loss: 0.1640657\n",
      "\tspeed: 0.0459s/iter; left time: 508.8996s\n",
      "\titers: 800, epoch: 8 | loss: 0.1520273\n",
      "\tspeed: 0.0458s/iter; left time: 502.3900s\n",
      "\titers: 900, epoch: 8 | loss: 0.1758567\n",
      "\tspeed: 0.0460s/iter; left time: 500.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 906 | Train Loss: 0.1603928 Vali Loss: 0.4732493 Test Loss: 0.5329067\n",
      "Validation loss decreased (0.474209 --> 0.473249).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1046355\n",
      "\tspeed: 0.1125s/iter; left time: 1211.9408s\n",
      "\titers: 200, epoch: 9 | loss: 0.1708581\n",
      "\tspeed: 0.0458s/iter; left time: 488.8051s\n",
      "\titers: 300, epoch: 9 | loss: 0.1738368\n",
      "\tspeed: 0.0453s/iter; left time: 479.1347s\n",
      "\titers: 400, epoch: 9 | loss: 0.1384565\n",
      "\tspeed: 0.0460s/iter; left time: 481.4394s\n",
      "\titers: 500, epoch: 9 | loss: 0.1524522\n",
      "\tspeed: 0.0458s/iter; left time: 474.5670s\n",
      "\titers: 600, epoch: 9 | loss: 0.1455010\n",
      "\tspeed: 0.0459s/iter; left time: 471.4267s\n",
      "\titers: 700, epoch: 9 | loss: 0.1273396\n",
      "\tspeed: 0.0460s/iter; left time: 467.4862s\n",
      "\titers: 800, epoch: 9 | loss: 0.1605159\n",
      "\tspeed: 0.0457s/iter; left time: 459.8614s\n",
      "\titers: 900, epoch: 9 | loss: 0.1334071\n",
      "\tspeed: 0.0457s/iter; left time: 455.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.79s\n",
      "Steps: 906 | Train Loss: 0.1450858 Vali Loss: 0.4914211 Test Loss: 0.5519576\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1320078\n",
      "\tspeed: 0.1098s/iter; left time: 1083.5158s\n",
      "\titers: 200, epoch: 10 | loss: 0.1295727\n",
      "\tspeed: 0.0460s/iter; left time: 449.7361s\n",
      "\titers: 300, epoch: 10 | loss: 0.1423758\n",
      "\tspeed: 0.0457s/iter; left time: 441.4002s\n",
      "\titers: 400, epoch: 10 | loss: 0.1804732\n",
      "\tspeed: 0.0460s/iter; left time: 439.9050s\n",
      "\titers: 500, epoch: 10 | loss: 0.1264879\n",
      "\tspeed: 0.0460s/iter; left time: 435.0673s\n",
      "\titers: 600, epoch: 10 | loss: 0.1378343\n",
      "\tspeed: 0.0460s/iter; left time: 430.4744s\n",
      "\titers: 700, epoch: 10 | loss: 0.1379522\n",
      "\tspeed: 0.0460s/iter; left time: 426.5130s\n",
      "\titers: 800, epoch: 10 | loss: 0.1365237\n",
      "\tspeed: 0.0458s/iter; left time: 419.9052s\n",
      "\titers: 900, epoch: 10 | loss: 0.1149044\n",
      "\tspeed: 0.0461s/iter; left time: 417.6132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 906 | Train Loss: 0.1308894 Vali Loss: 0.5051424 Test Loss: 0.5509188\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1301663\n",
      "\tspeed: 0.1091s/iter; left time: 977.7966s\n",
      "\titers: 200, epoch: 11 | loss: 0.1064578\n",
      "\tspeed: 0.0460s/iter; left time: 407.2990s\n",
      "\titers: 300, epoch: 11 | loss: 0.1046797\n",
      "\tspeed: 0.0460s/iter; left time: 402.5884s\n",
      "\titers: 400, epoch: 11 | loss: 0.1079707\n",
      "\tspeed: 0.0460s/iter; left time: 398.0252s\n",
      "\titers: 500, epoch: 11 | loss: 0.1248002\n",
      "\tspeed: 0.0460s/iter; left time: 393.5568s\n",
      "\titers: 600, epoch: 11 | loss: 0.1074882\n",
      "\tspeed: 0.0461s/iter; left time: 389.9688s\n",
      "\titers: 700, epoch: 11 | loss: 0.0967922\n",
      "\tspeed: 0.0456s/iter; left time: 381.4221s\n",
      "\titers: 800, epoch: 11 | loss: 0.1486352\n",
      "\tspeed: 0.0459s/iter; left time: 379.0184s\n",
      "\titers: 900, epoch: 11 | loss: 0.1042361\n",
      "\tspeed: 0.0459s/iter; left time: 374.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 906 | Train Loss: 0.1185289 Vali Loss: 0.5039625 Test Loss: 0.5429449\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1150860\n",
      "\tspeed: 0.1115s/iter; left time: 898.3661s\n",
      "\titers: 200, epoch: 12 | loss: 0.1053290\n",
      "\tspeed: 0.0459s/iter; left time: 364.9104s\n",
      "\titers: 300, epoch: 12 | loss: 0.0935528\n",
      "\tspeed: 0.0460s/iter; left time: 361.3904s\n",
      "\titers: 400, epoch: 12 | loss: 0.1060606\n",
      "\tspeed: 0.0461s/iter; left time: 357.5391s\n",
      "\titers: 500, epoch: 12 | loss: 0.1272249\n",
      "\tspeed: 0.0460s/iter; left time: 352.3177s\n",
      "\titers: 600, epoch: 12 | loss: 0.0866550\n",
      "\tspeed: 0.0461s/iter; left time: 348.3534s\n",
      "\titers: 700, epoch: 12 | loss: 0.1187673\n",
      "\tspeed: 0.0459s/iter; left time: 342.3775s\n",
      "\titers: 800, epoch: 12 | loss: 0.1234600\n",
      "\tspeed: 0.0460s/iter; left time: 338.5190s\n",
      "\titers: 900, epoch: 12 | loss: 0.1036495\n",
      "\tspeed: 0.0460s/iter; left time: 334.0559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 906 | Train Loss: 0.1097063 Vali Loss: 0.5004998 Test Loss: 0.5600593\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0971159\n",
      "\tspeed: 0.1130s/iter; left time: 807.8110s\n",
      "\titers: 200, epoch: 13 | loss: 0.0817538\n",
      "\tspeed: 0.0490s/iter; left time: 345.5125s\n",
      "\titers: 300, epoch: 13 | loss: 0.0950478\n",
      "\tspeed: 0.0487s/iter; left time: 338.5457s\n",
      "\titers: 400, epoch: 13 | loss: 0.1127713\n",
      "\tspeed: 0.0490s/iter; left time: 335.3742s\n",
      "\titers: 500, epoch: 13 | loss: 0.0893352\n",
      "\tspeed: 0.0477s/iter; left time: 322.1628s\n",
      "\titers: 600, epoch: 13 | loss: 0.0883289\n",
      "\tspeed: 0.0489s/iter; left time: 324.9232s\n",
      "\titers: 700, epoch: 13 | loss: 0.1186316\n",
      "\tspeed: 0.0487s/iter; left time: 318.6254s\n",
      "\titers: 800, epoch: 13 | loss: 0.0967449\n",
      "\tspeed: 0.0487s/iter; left time: 314.1747s\n",
      "\titers: 900, epoch: 13 | loss: 0.0927760\n",
      "\tspeed: 0.0488s/iter; left time: 310.1396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:44.45s\n",
      "Steps: 906 | Train Loss: 0.1015858 Vali Loss: 0.4902031 Test Loss: 0.5311362\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.533747136592865, rmse:0.7305799722671509, mae:0.47780337929725647, rse:0.5782079696655273\n",
      "Original data scale mse:21397382.0, rmse:4625.73046875, mae:2871.884765625, rse:0.23000064492225647\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0605805\n",
      "\tspeed: 0.0811s/iter; left time: 1459.0334s\n",
      "\titers: 200, epoch: 1 | loss: 0.9717692\n",
      "\tspeed: 0.0506s/iter; left time: 905.5071s\n",
      "\titers: 300, epoch: 1 | loss: 0.9617305\n",
      "\tspeed: 0.0506s/iter; left time: 899.4591s\n",
      "\titers: 400, epoch: 1 | loss: 0.8473159\n",
      "\tspeed: 0.0504s/iter; left time: 891.9999s\n",
      "\titers: 500, epoch: 1 | loss: 0.8435406\n",
      "\tspeed: 0.0505s/iter; left time: 887.5127s\n",
      "\titers: 600, epoch: 1 | loss: 0.7733423\n",
      "\tspeed: 0.0504s/iter; left time: 881.5736s\n",
      "\titers: 700, epoch: 1 | loss: 0.7525464\n",
      "\tspeed: 0.0506s/iter; left time: 878.7372s\n",
      "\titers: 800, epoch: 1 | loss: 0.7953976\n",
      "\tspeed: 0.0505s/iter; left time: 873.2243s\n",
      "\titers: 900, epoch: 1 | loss: 0.7578309\n",
      "\tspeed: 0.0506s/iter; left time: 868.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 904 | Train Loss: 0.8820779 Vali Loss: 0.9884527 Test Loss: 1.2501144\n",
      "Validation loss decreased (inf --> 0.988453).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6872817\n",
      "\tspeed: 0.1262s/iter; left time: 2155.3554s\n",
      "\titers: 200, epoch: 2 | loss: 0.6318825\n",
      "\tspeed: 0.0505s/iter; left time: 857.4179s\n",
      "\titers: 300, epoch: 2 | loss: 0.6118687\n",
      "\tspeed: 0.0506s/iter; left time: 853.6628s\n",
      "\titers: 400, epoch: 2 | loss: 0.6720122\n",
      "\tspeed: 0.0506s/iter; left time: 849.2790s\n",
      "\titers: 500, epoch: 2 | loss: 0.6069590\n",
      "\tspeed: 0.0506s/iter; left time: 843.1052s\n",
      "\titers: 600, epoch: 2 | loss: 0.5220518\n",
      "\tspeed: 0.0506s/iter; left time: 838.5550s\n",
      "\titers: 700, epoch: 2 | loss: 0.4842487\n",
      "\tspeed: 0.0505s/iter; left time: 832.7784s\n",
      "\titers: 800, epoch: 2 | loss: 0.5168561\n",
      "\tspeed: 0.0505s/iter; left time: 827.5697s\n",
      "\titers: 900, epoch: 2 | loss: 0.5635256\n",
      "\tspeed: 0.0505s/iter; left time: 822.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.5985550 Vali Loss: 0.7319562 Test Loss: 0.8385763\n",
      "Validation loss decreased (0.988453 --> 0.731956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5183938\n",
      "\tspeed: 0.1269s/iter; left time: 2051.8177s\n",
      "\titers: 200, epoch: 3 | loss: 0.3872420\n",
      "\tspeed: 0.0506s/iter; left time: 812.7171s\n",
      "\titers: 300, epoch: 3 | loss: 0.4710692\n",
      "\tspeed: 0.0506s/iter; left time: 808.3773s\n",
      "\titers: 400, epoch: 3 | loss: 0.3772839\n",
      "\tspeed: 0.0506s/iter; left time: 802.9303s\n",
      "\titers: 500, epoch: 3 | loss: 0.4210662\n",
      "\tspeed: 0.0506s/iter; left time: 798.0422s\n",
      "\titers: 600, epoch: 3 | loss: 0.4137359\n",
      "\tspeed: 0.0506s/iter; left time: 792.6912s\n",
      "\titers: 700, epoch: 3 | loss: 0.5522777\n",
      "\tspeed: 0.0505s/iter; left time: 786.6136s\n",
      "\titers: 800, epoch: 3 | loss: 0.4163330\n",
      "\tspeed: 0.0505s/iter; left time: 781.1759s\n",
      "\titers: 900, epoch: 3 | loss: 0.5194146\n",
      "\tspeed: 0.0505s/iter; left time: 776.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.4396906 Vali Loss: 0.7048147 Test Loss: 0.8681936\n",
      "Validation loss decreased (0.731956 --> 0.704815).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5076982\n",
      "\tspeed: 0.1265s/iter; left time: 1931.1676s\n",
      "\titers: 200, epoch: 4 | loss: 0.3931543\n",
      "\tspeed: 0.0506s/iter; left time: 767.8393s\n",
      "\titers: 300, epoch: 4 | loss: 0.4137790\n",
      "\tspeed: 0.0506s/iter; left time: 762.1234s\n",
      "\titers: 400, epoch: 4 | loss: 0.3570974\n",
      "\tspeed: 0.0504s/iter; left time: 755.1777s\n",
      "\titers: 500, epoch: 4 | loss: 0.3723400\n",
      "\tspeed: 0.0505s/iter; left time: 750.9245s\n",
      "\titers: 600, epoch: 4 | loss: 0.3875241\n",
      "\tspeed: 0.0505s/iter; left time: 745.4882s\n",
      "\titers: 700, epoch: 4 | loss: 0.3502263\n",
      "\tspeed: 0.0505s/iter; left time: 741.0356s\n",
      "\titers: 800, epoch: 4 | loss: 0.3241617\n",
      "\tspeed: 0.0505s/iter; left time: 735.6654s\n",
      "\titers: 900, epoch: 4 | loss: 0.3349272\n",
      "\tspeed: 0.0505s/iter; left time: 730.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.3749704 Vali Loss: 0.7238701 Test Loss: 0.9088898\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3075674\n",
      "\tspeed: 0.1229s/iter; left time: 1765.2616s\n",
      "\titers: 200, epoch: 5 | loss: 0.3223272\n",
      "\tspeed: 0.0505s/iter; left time: 720.7620s\n",
      "\titers: 300, epoch: 5 | loss: 0.3427497\n",
      "\tspeed: 0.0506s/iter; left time: 716.3198s\n",
      "\titers: 400, epoch: 5 | loss: 0.3543960\n",
      "\tspeed: 0.0504s/iter; left time: 709.2068s\n",
      "\titers: 500, epoch: 5 | loss: 0.2539738\n",
      "\tspeed: 0.0505s/iter; left time: 705.5056s\n",
      "\titers: 600, epoch: 5 | loss: 0.3751425\n",
      "\tspeed: 0.0505s/iter; left time: 699.9271s\n",
      "\titers: 700, epoch: 5 | loss: 0.3742727\n",
      "\tspeed: 0.0505s/iter; left time: 695.2077s\n",
      "\titers: 800, epoch: 5 | loss: 0.2891563\n",
      "\tspeed: 0.0506s/iter; left time: 690.9636s\n",
      "\titers: 900, epoch: 5 | loss: 0.2785223\n",
      "\tspeed: 0.0506s/iter; left time: 686.7543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.3253914 Vali Loss: 0.7610592 Test Loss: 0.9426096\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2712336\n",
      "\tspeed: 0.1229s/iter; left time: 1654.1472s\n",
      "\titers: 200, epoch: 6 | loss: 0.2623831\n",
      "\tspeed: 0.0502s/iter; left time: 671.2241s\n",
      "\titers: 300, epoch: 6 | loss: 0.2686088\n",
      "\tspeed: 0.0505s/iter; left time: 670.0248s\n",
      "\titers: 400, epoch: 6 | loss: 0.3030204\n",
      "\tspeed: 0.0505s/iter; left time: 664.8030s\n",
      "\titers: 500, epoch: 6 | loss: 0.2974093\n",
      "\tspeed: 0.0504s/iter; left time: 658.7104s\n",
      "\titers: 600, epoch: 6 | loss: 0.2694578\n",
      "\tspeed: 0.0505s/iter; left time: 653.9482s\n",
      "\titers: 700, epoch: 6 | loss: 0.2545598\n",
      "\tspeed: 0.0506s/iter; left time: 650.3078s\n",
      "\titers: 800, epoch: 6 | loss: 0.2556204\n",
      "\tspeed: 0.0505s/iter; left time: 644.5318s\n",
      "\titers: 900, epoch: 6 | loss: 0.2435222\n",
      "\tspeed: 0.0503s/iter; left time: 636.9929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.83s\n",
      "Steps: 904 | Train Loss: 0.2822100 Vali Loss: 0.7438261 Test Loss: 0.9381113\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2645974\n",
      "\tspeed: 0.1231s/iter; left time: 1545.4387s\n",
      "\titers: 200, epoch: 7 | loss: 0.2486003\n",
      "\tspeed: 0.0505s/iter; left time: 629.0784s\n",
      "\titers: 300, epoch: 7 | loss: 0.2439299\n",
      "\tspeed: 0.0505s/iter; left time: 624.0170s\n",
      "\titers: 400, epoch: 7 | loss: 0.2740248\n",
      "\tspeed: 0.0505s/iter; left time: 618.9795s\n",
      "\titers: 500, epoch: 7 | loss: 0.2410460\n",
      "\tspeed: 0.0505s/iter; left time: 614.3222s\n",
      "\titers: 600, epoch: 7 | loss: 0.2446578\n",
      "\tspeed: 0.0505s/iter; left time: 609.1845s\n",
      "\titers: 700, epoch: 7 | loss: 0.2826106\n",
      "\tspeed: 0.0506s/iter; left time: 604.4541s\n",
      "\titers: 800, epoch: 7 | loss: 0.2300957\n",
      "\tspeed: 0.0505s/iter; left time: 599.1747s\n",
      "\titers: 900, epoch: 7 | loss: 0.2321821\n",
      "\tspeed: 0.0505s/iter; left time: 593.7519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.2479378 Vali Loss: 0.7488794 Test Loss: 0.9623802\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2140537\n",
      "\tspeed: 0.1242s/iter; left time: 1447.1619s\n",
      "\titers: 200, epoch: 8 | loss: 0.2113641\n",
      "\tspeed: 0.0506s/iter; left time: 584.7237s\n",
      "\titers: 300, epoch: 8 | loss: 0.2192861\n",
      "\tspeed: 0.0506s/iter; left time: 579.8110s\n",
      "\titers: 400, epoch: 8 | loss: 0.1996561\n",
      "\tspeed: 0.0505s/iter; left time: 573.3295s\n",
      "\titers: 500, epoch: 8 | loss: 0.2208516\n",
      "\tspeed: 0.0505s/iter; left time: 568.3661s\n",
      "\titers: 600, epoch: 8 | loss: 0.2630434\n",
      "\tspeed: 0.0505s/iter; left time: 563.1423s\n",
      "\titers: 700, epoch: 8 | loss: 0.2323789\n",
      "\tspeed: 0.0507s/iter; left time: 559.8773s\n",
      "\titers: 800, epoch: 8 | loss: 0.1922609\n",
      "\tspeed: 0.0506s/iter; left time: 553.8595s\n",
      "\titers: 900, epoch: 8 | loss: 0.2017849\n",
      "\tspeed: 0.0504s/iter; left time: 547.3951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.2202499 Vali Loss: 0.7663458 Test Loss: 0.9763528\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8677544593811035, rmse:0.9315333962440491, mae:0.6915313601493835, rse:0.7388207912445068\n",
      "Original data scale mse:38906908.0, rmse:6237.5400390625, mae:4300.837890625, rse:0.31063172221183777\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8655462\n",
      "\tspeed: 0.0538s/iter; left time: 967.4135s\n",
      "\titers: 200, epoch: 1 | loss: 0.8117222\n",
      "\tspeed: 0.0507s/iter; left time: 906.2410s\n",
      "\titers: 300, epoch: 1 | loss: 0.9148418\n",
      "\tspeed: 0.0505s/iter; left time: 898.7424s\n",
      "\titers: 400, epoch: 1 | loss: 0.9095563\n",
      "\tspeed: 0.0505s/iter; left time: 893.1099s\n",
      "\titers: 500, epoch: 1 | loss: 0.9828821\n",
      "\tspeed: 0.0505s/iter; left time: 887.6539s\n",
      "\titers: 600, epoch: 1 | loss: 0.9020529\n",
      "\tspeed: 0.0505s/iter; left time: 882.1808s\n",
      "\titers: 700, epoch: 1 | loss: 0.8114009\n",
      "\tspeed: 0.0505s/iter; left time: 877.7008s\n",
      "\titers: 800, epoch: 1 | loss: 0.8094805\n",
      "\tspeed: 0.0505s/iter; left time: 872.9838s\n",
      "\titers: 900, epoch: 1 | loss: 0.8074092\n",
      "\tspeed: 0.0505s/iter; left time: 868.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.10s\n",
      "Steps: 904 | Train Loss: 0.8857616 Vali Loss: 0.9797246 Test Loss: 1.2443970\n",
      "Validation loss decreased (inf --> 0.979725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8031266\n",
      "\tspeed: 0.1277s/iter; left time: 2180.1528s\n",
      "\titers: 200, epoch: 2 | loss: 0.5845723\n",
      "\tspeed: 0.0505s/iter; left time: 856.5481s\n",
      "\titers: 300, epoch: 2 | loss: 0.7320786\n",
      "\tspeed: 0.0504s/iter; left time: 850.7646s\n",
      "\titers: 400, epoch: 2 | loss: 0.6130444\n",
      "\tspeed: 0.0504s/iter; left time: 846.2498s\n",
      "\titers: 500, epoch: 2 | loss: 0.5989880\n",
      "\tspeed: 0.0504s/iter; left time: 840.7654s\n",
      "\titers: 600, epoch: 2 | loss: 0.4955609\n",
      "\tspeed: 0.0505s/iter; left time: 836.5293s\n",
      "\titers: 700, epoch: 2 | loss: 0.4557247\n",
      "\tspeed: 0.0505s/iter; left time: 832.3626s\n",
      "\titers: 800, epoch: 2 | loss: 0.5100004\n",
      "\tspeed: 0.0506s/iter; left time: 827.9904s\n",
      "\titers: 900, epoch: 2 | loss: 0.4214234\n",
      "\tspeed: 0.0505s/iter; left time: 822.4087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.5992010 Vali Loss: 0.7207685 Test Loss: 0.8747638\n",
      "Validation loss decreased (0.979725 --> 0.720768).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4248578\n",
      "\tspeed: 0.1157s/iter; left time: 1870.8274s\n",
      "\titers: 200, epoch: 3 | loss: 0.3937776\n",
      "\tspeed: 0.0390s/iter; left time: 627.5336s\n",
      "\titers: 300, epoch: 3 | loss: 0.5102718\n",
      "\tspeed: 0.0459s/iter; left time: 733.8750s\n",
      "\titers: 400, epoch: 3 | loss: 0.4688219\n",
      "\tspeed: 0.0509s/iter; left time: 807.9559s\n",
      "\titers: 500, epoch: 3 | loss: 0.4196325\n",
      "\tspeed: 0.0509s/iter; left time: 802.4365s\n",
      "\titers: 600, epoch: 3 | loss: 0.5358827\n",
      "\tspeed: 0.0506s/iter; left time: 792.4568s\n",
      "\titers: 700, epoch: 3 | loss: 0.4935442\n",
      "\tspeed: 0.0505s/iter; left time: 786.4926s\n",
      "\titers: 800, epoch: 3 | loss: 0.3448799\n",
      "\tspeed: 0.0505s/iter; left time: 782.0172s\n",
      "\titers: 900, epoch: 3 | loss: 0.4266475\n",
      "\tspeed: 0.0505s/iter; left time: 776.1804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.41s\n",
      "Steps: 904 | Train Loss: 0.4389693 Vali Loss: 0.6927793 Test Loss: 0.9070653\n",
      "Validation loss decreased (0.720768 --> 0.692779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4022974\n",
      "\tspeed: 0.1296s/iter; left time: 1979.4088s\n",
      "\titers: 200, epoch: 4 | loss: 0.3787035\n",
      "\tspeed: 0.0506s/iter; left time: 767.0210s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054031\n",
      "\tspeed: 0.0505s/iter; left time: 761.5424s\n",
      "\titers: 400, epoch: 4 | loss: 0.3918075\n",
      "\tspeed: 0.0506s/iter; left time: 757.6274s\n",
      "\titers: 500, epoch: 4 | loss: 0.3248608\n",
      "\tspeed: 0.0505s/iter; left time: 751.2394s\n",
      "\titers: 600, epoch: 4 | loss: 0.3436697\n",
      "\tspeed: 0.0505s/iter; left time: 746.1768s\n",
      "\titers: 700, epoch: 4 | loss: 0.3732203\n",
      "\tspeed: 0.0505s/iter; left time: 741.1972s\n",
      "\titers: 800, epoch: 4 | loss: 0.3666429\n",
      "\tspeed: 0.0505s/iter; left time: 736.3377s\n",
      "\titers: 900, epoch: 4 | loss: 0.3113438\n",
      "\tspeed: 0.0505s/iter; left time: 731.0495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.3677405 Vali Loss: 0.7129097 Test Loss: 0.8917966\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2832287\n",
      "\tspeed: 0.1246s/iter; left time: 1789.8197s\n",
      "\titers: 200, epoch: 5 | loss: 0.3404443\n",
      "\tspeed: 0.0504s/iter; left time: 718.9045s\n",
      "\titers: 300, epoch: 5 | loss: 0.3949805\n",
      "\tspeed: 0.0502s/iter; left time: 711.7438s\n",
      "\titers: 400, epoch: 5 | loss: 0.3035242\n",
      "\tspeed: 0.0502s/iter; left time: 706.4141s\n",
      "\titers: 500, epoch: 5 | loss: 0.3047126\n",
      "\tspeed: 0.0503s/iter; left time: 702.3242s\n",
      "\titers: 600, epoch: 5 | loss: 0.2923572\n",
      "\tspeed: 0.0506s/iter; left time: 701.1085s\n",
      "\titers: 700, epoch: 5 | loss: 0.2676851\n",
      "\tspeed: 0.0505s/iter; left time: 695.1639s\n",
      "\titers: 800, epoch: 5 | loss: 0.2733913\n",
      "\tspeed: 0.0503s/iter; left time: 687.8272s\n",
      "\titers: 900, epoch: 5 | loss: 0.3001047\n",
      "\tspeed: 0.0503s/iter; left time: 682.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.81s\n",
      "Steps: 904 | Train Loss: 0.3145329 Vali Loss: 0.7336422 Test Loss: 0.9191062\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3194776\n",
      "\tspeed: 0.1247s/iter; left time: 1678.6421s\n",
      "\titers: 200, epoch: 6 | loss: 0.2521819\n",
      "\tspeed: 0.0506s/iter; left time: 675.4103s\n",
      "\titers: 300, epoch: 6 | loss: 0.2802464\n",
      "\tspeed: 0.0505s/iter; left time: 669.9667s\n",
      "\titers: 400, epoch: 6 | loss: 0.2593033\n",
      "\tspeed: 0.0505s/iter; left time: 665.1493s\n",
      "\titers: 500, epoch: 6 | loss: 0.2882525\n",
      "\tspeed: 0.0504s/iter; left time: 658.2145s\n",
      "\titers: 600, epoch: 6 | loss: 0.2597700\n",
      "\tspeed: 0.0390s/iter; left time: 505.3984s\n",
      "\titers: 700, epoch: 6 | loss: 0.2467932\n",
      "\tspeed: 0.0390s/iter; left time: 501.5065s\n",
      "\titers: 800, epoch: 6 | loss: 0.2609795\n",
      "\tspeed: 0.0390s/iter; left time: 497.5962s\n",
      "\titers: 900, epoch: 6 | loss: 0.2892472\n",
      "\tspeed: 0.0390s/iter; left time: 493.4095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.30s\n",
      "Steps: 904 | Train Loss: 0.2720444 Vali Loss: 0.7490230 Test Loss: 1.0089771\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2539870\n",
      "\tspeed: 0.1255s/iter; left time: 1576.5210s\n",
      "\titers: 200, epoch: 7 | loss: 0.2427886\n",
      "\tspeed: 0.0505s/iter; left time: 629.3962s\n",
      "\titers: 300, epoch: 7 | loss: 0.2798741\n",
      "\tspeed: 0.0506s/iter; left time: 625.6062s\n",
      "\titers: 400, epoch: 7 | loss: 0.2688481\n",
      "\tspeed: 0.0506s/iter; left time: 619.8120s\n",
      "\titers: 500, epoch: 7 | loss: 0.2188558\n",
      "\tspeed: 0.0505s/iter; left time: 614.4707s\n",
      "\titers: 600, epoch: 7 | loss: 0.2524507\n",
      "\tspeed: 0.0507s/iter; left time: 611.8506s\n",
      "\titers: 700, epoch: 7 | loss: 0.2382094\n",
      "\tspeed: 0.0507s/iter; left time: 606.0065s\n",
      "\titers: 800, epoch: 7 | loss: 0.2274452\n",
      "\tspeed: 0.0503s/iter; left time: 596.0968s\n",
      "\titers: 900, epoch: 7 | loss: 0.2534213\n",
      "\tspeed: 0.0505s/iter; left time: 593.9648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.2406148 Vali Loss: 0.7714815 Test Loss: 1.0171771\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2008600\n",
      "\tspeed: 0.1236s/iter; left time: 1440.3414s\n",
      "\titers: 200, epoch: 8 | loss: 0.2281130\n",
      "\tspeed: 0.0505s/iter; left time: 583.7189s\n",
      "\titers: 300, epoch: 8 | loss: 0.2223569\n",
      "\tspeed: 0.0505s/iter; left time: 578.9428s\n",
      "\titers: 400, epoch: 8 | loss: 0.2730049\n",
      "\tspeed: 0.0507s/iter; left time: 575.0679s\n",
      "\titers: 500, epoch: 8 | loss: 0.2278657\n",
      "\tspeed: 0.0505s/iter; left time: 568.7225s\n",
      "\titers: 600, epoch: 8 | loss: 0.1980424\n",
      "\tspeed: 0.0505s/iter; left time: 563.3057s\n",
      "\titers: 700, epoch: 8 | loss: 0.1892312\n",
      "\tspeed: 0.0505s/iter; left time: 558.3779s\n",
      "\titers: 800, epoch: 8 | loss: 0.2074329\n",
      "\tspeed: 0.0506s/iter; left time: 554.0304s\n",
      "\titers: 900, epoch: 8 | loss: 0.2052583\n",
      "\tspeed: 0.0504s/iter; left time: 546.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.92s\n",
      "Steps: 904 | Train Loss: 0.2129988 Vali Loss: 0.7965338 Test Loss: 1.0072703\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9062726497650146, rmse:0.9519835114479065, mae:0.6853876113891602, rse:0.7550402879714966\n",
      "Original data scale mse:40021996.0, rmse:6326.2939453125, mae:4212.20361328125, rse:0.31505170464515686\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9249804\n",
      "\tspeed: 0.0829s/iter; left time: 1486.7637s\n",
      "\titers: 200, epoch: 1 | loss: 1.0187807\n",
      "\tspeed: 0.0518s/iter; left time: 924.4632s\n",
      "\titers: 300, epoch: 1 | loss: 0.8977410\n",
      "\tspeed: 0.0518s/iter; left time: 918.2543s\n",
      "\titers: 400, epoch: 1 | loss: 0.9024578\n",
      "\tspeed: 0.0517s/iter; left time: 911.4139s\n",
      "\titers: 500, epoch: 1 | loss: 0.8629702\n",
      "\tspeed: 0.0516s/iter; left time: 904.6342s\n",
      "\titers: 600, epoch: 1 | loss: 0.9282914\n",
      "\tspeed: 0.0519s/iter; left time: 904.7074s\n",
      "\titers: 700, epoch: 1 | loss: 0.8626103\n",
      "\tspeed: 0.0517s/iter; left time: 896.3277s\n",
      "\titers: 800, epoch: 1 | loss: 0.8041627\n",
      "\tspeed: 0.0525s/iter; left time: 905.1659s\n",
      "\titers: 900, epoch: 1 | loss: 0.8967922\n",
      "\tspeed: 0.0515s/iter; left time: 883.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.55s\n",
      "Steps: 902 | Train Loss: 0.9077419 Vali Loss: 1.0301040 Test Loss: 1.3215446\n",
      "Validation loss decreased (inf --> 1.030104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8136090\n",
      "\tspeed: 0.1375s/iter; left time: 2342.2842s\n",
      "\titers: 200, epoch: 2 | loss: 0.6843329\n",
      "\tspeed: 0.0469s/iter; left time: 793.8616s\n",
      "\titers: 300, epoch: 2 | loss: 0.7661862\n",
      "\tspeed: 0.0470s/iter; left time: 790.9620s\n",
      "\titers: 400, epoch: 2 | loss: 0.7764358\n",
      "\tspeed: 0.0469s/iter; left time: 784.9864s\n",
      "\titers: 500, epoch: 2 | loss: 0.6428636\n",
      "\tspeed: 0.0486s/iter; left time: 809.2819s\n",
      "\titers: 600, epoch: 2 | loss: 0.5915630\n",
      "\tspeed: 0.0513s/iter; left time: 847.7022s\n",
      "\titers: 700, epoch: 2 | loss: 0.5726713\n",
      "\tspeed: 0.0540s/iter; left time: 887.7111s\n",
      "\titers: 800, epoch: 2 | loss: 0.6239541\n",
      "\tspeed: 0.0540s/iter; left time: 882.8933s\n",
      "\titers: 900, epoch: 2 | loss: 0.5038958\n",
      "\tspeed: 0.0544s/iter; left time: 884.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.46s\n",
      "Steps: 902 | Train Loss: 0.6982916 Vali Loss: 0.7979439 Test Loss: 0.9655151\n",
      "Validation loss decreased (1.030104 --> 0.797944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5253241\n",
      "\tspeed: 0.1462s/iter; left time: 2359.9799s\n",
      "\titers: 200, epoch: 3 | loss: 0.5125729\n",
      "\tspeed: 0.0541s/iter; left time: 867.8261s\n",
      "\titers: 300, epoch: 3 | loss: 0.4666479\n",
      "\tspeed: 0.0542s/iter; left time: 863.4040s\n",
      "\titers: 400, epoch: 3 | loss: 0.5136193\n",
      "\tspeed: 0.0544s/iter; left time: 860.9377s\n",
      "\titers: 500, epoch: 3 | loss: 0.4608695\n",
      "\tspeed: 0.0523s/iter; left time: 823.3883s\n",
      "\titers: 600, epoch: 3 | loss: 0.4557330\n",
      "\tspeed: 0.0506s/iter; left time: 790.5292s\n",
      "\titers: 700, epoch: 3 | loss: 0.4320635\n",
      "\tspeed: 0.0527s/iter; left time: 819.5399s\n",
      "\titers: 800, epoch: 3 | loss: 0.4418385\n",
      "\tspeed: 0.0538s/iter; left time: 830.7816s\n",
      "\titers: 900, epoch: 3 | loss: 0.4422487\n",
      "\tspeed: 0.0538s/iter; left time: 825.0824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.4802823 Vali Loss: 0.7410014 Test Loss: 0.9479406\n",
      "Validation loss decreased (0.797944 --> 0.741001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4545560\n",
      "\tspeed: 0.1459s/iter; left time: 2222.9844s\n",
      "\titers: 200, epoch: 4 | loss: 0.3579492\n",
      "\tspeed: 0.0491s/iter; left time: 743.5792s\n",
      "\titers: 300, epoch: 4 | loss: 0.3576623\n",
      "\tspeed: 0.0469s/iter; left time: 705.1590s\n",
      "\titers: 400, epoch: 4 | loss: 0.4258225\n",
      "\tspeed: 0.0469s/iter; left time: 700.9854s\n",
      "\titers: 500, epoch: 4 | loss: 0.3702534\n",
      "\tspeed: 0.0521s/iter; left time: 773.1523s\n",
      "\titers: 600, epoch: 4 | loss: 0.3901100\n",
      "\tspeed: 0.0587s/iter; left time: 865.5419s\n",
      "\titers: 700, epoch: 4 | loss: 0.3546235\n",
      "\tspeed: 0.0584s/iter; left time: 854.1796s\n",
      "\titers: 800, epoch: 4 | loss: 0.3677294\n",
      "\tspeed: 0.0585s/iter; left time: 850.7299s\n",
      "\titers: 900, epoch: 4 | loss: 0.3524360\n",
      "\tspeed: 0.0588s/iter; left time: 848.9906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.3958655 Vali Loss: 0.7785021 Test Loss: 0.9596282\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3119120\n",
      "\tspeed: 0.1473s/iter; left time: 2111.6816s\n",
      "\titers: 200, epoch: 5 | loss: 0.3249052\n",
      "\tspeed: 0.0567s/iter; left time: 807.0336s\n",
      "\titers: 300, epoch: 5 | loss: 0.3422277\n",
      "\tspeed: 0.0569s/iter; left time: 804.3699s\n",
      "\titers: 400, epoch: 5 | loss: 0.3809371\n",
      "\tspeed: 0.0573s/iter; left time: 804.5357s\n",
      "\titers: 500, epoch: 5 | loss: 0.3334263\n",
      "\tspeed: 0.0558s/iter; left time: 777.1423s\n",
      "\titers: 600, epoch: 5 | loss: 0.2895035\n",
      "\tspeed: 0.0539s/iter; left time: 745.2634s\n",
      "\titers: 700, epoch: 5 | loss: 0.3007365\n",
      "\tspeed: 0.0550s/iter; left time: 755.0230s\n",
      "\titers: 800, epoch: 5 | loss: 0.3595013\n",
      "\tspeed: 0.0564s/iter; left time: 768.7760s\n",
      "\titers: 900, epoch: 5 | loss: 0.3141673\n",
      "\tspeed: 0.0567s/iter; left time: 767.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.03s\n",
      "Steps: 902 | Train Loss: 0.3387007 Vali Loss: 0.7871937 Test Loss: 1.0502307\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3407153\n",
      "\tspeed: 0.1493s/iter; left time: 2005.8915s\n",
      "\titers: 200, epoch: 6 | loss: 0.3292459\n",
      "\tspeed: 0.0572s/iter; left time: 762.5507s\n",
      "\titers: 300, epoch: 6 | loss: 0.3082098\n",
      "\tspeed: 0.0578s/iter; left time: 765.4047s\n",
      "\titers: 400, epoch: 6 | loss: 0.3325780\n",
      "\tspeed: 0.0570s/iter; left time: 748.1529s\n",
      "\titers: 500, epoch: 6 | loss: 0.3094540\n",
      "\tspeed: 0.0575s/iter; left time: 749.3837s\n",
      "\titers: 600, epoch: 6 | loss: 0.3041326\n",
      "\tspeed: 0.0567s/iter; left time: 733.4441s\n",
      "\titers: 700, epoch: 6 | loss: 0.2445558\n",
      "\tspeed: 0.0565s/iter; left time: 724.3640s\n",
      "\titers: 800, epoch: 6 | loss: 0.2930852\n",
      "\tspeed: 0.0567s/iter; left time: 721.3465s\n",
      "\titers: 900, epoch: 6 | loss: 0.2950725\n",
      "\tspeed: 0.0570s/iter; left time: 720.2454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:51.94s\n",
      "Steps: 902 | Train Loss: 0.2933663 Vali Loss: 0.8230544 Test Loss: 1.0240233\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2559663\n",
      "\tspeed: 0.1441s/iter; left time: 1805.7640s\n",
      "\titers: 200, epoch: 7 | loss: 0.2564496\n",
      "\tspeed: 0.0563s/iter; left time: 699.4069s\n",
      "\titers: 300, epoch: 7 | loss: 0.2817649\n",
      "\tspeed: 0.0568s/iter; left time: 700.6636s\n",
      "\titers: 400, epoch: 7 | loss: 0.2319174\n",
      "\tspeed: 0.0569s/iter; left time: 695.2978s\n",
      "\titers: 500, epoch: 7 | loss: 0.2938950\n",
      "\tspeed: 0.0569s/iter; left time: 690.2255s\n",
      "\titers: 600, epoch: 7 | loss: 0.2227882\n",
      "\tspeed: 0.0568s/iter; left time: 683.1200s\n",
      "\titers: 700, epoch: 7 | loss: 0.2492258\n",
      "\tspeed: 0.0569s/iter; left time: 678.7941s\n",
      "\titers: 800, epoch: 7 | loss: 0.2563336\n",
      "\tspeed: 0.0573s/iter; left time: 677.3673s\n",
      "\titers: 900, epoch: 7 | loss: 0.2831274\n",
      "\tspeed: 0.0570s/iter; left time: 668.0162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.42s\n",
      "Steps: 902 | Train Loss: 0.2576248 Vali Loss: 0.8632520 Test Loss: 1.0802224\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2274672\n",
      "\tspeed: 0.1484s/iter; left time: 1725.5550s\n",
      "\titers: 200, epoch: 8 | loss: 0.2633924\n",
      "\tspeed: 0.0569s/iter; left time: 656.3418s\n",
      "\titers: 300, epoch: 8 | loss: 0.2460687\n",
      "\tspeed: 0.0566s/iter; left time: 646.5728s\n",
      "\titers: 400, epoch: 8 | loss: 0.2168300\n",
      "\tspeed: 0.0571s/iter; left time: 646.2565s\n",
      "\titers: 500, epoch: 8 | loss: 0.2437734\n",
      "\tspeed: 0.0573s/iter; left time: 643.4754s\n",
      "\titers: 600, epoch: 8 | loss: 0.2184790\n",
      "\tspeed: 0.0574s/iter; left time: 639.1809s\n",
      "\titers: 700, epoch: 8 | loss: 0.2262592\n",
      "\tspeed: 0.0571s/iter; left time: 629.1044s\n",
      "\titers: 800, epoch: 8 | loss: 0.2085545\n",
      "\tspeed: 0.0566s/iter; left time: 618.6836s\n",
      "\titers: 900, epoch: 8 | loss: 0.2030646\n",
      "\tspeed: 0.0569s/iter; left time: 616.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.08s\n",
      "Steps: 902 | Train Loss: 0.2298824 Vali Loss: 0.8887161 Test Loss: 1.1002785\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9472817778587341, rmse:0.9732840061187744, mae:0.7124764323234558, rse:0.7710132598876953\n",
      "Original data scale mse:42061940.0, rmse:6485.517578125, mae:4402.36328125, rse:0.32313963770866394\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9210395\n",
      "\tspeed: 0.0609s/iter; left time: 1093.2687s\n",
      "\titers: 200, epoch: 1 | loss: 0.9834211\n",
      "\tspeed: 0.0565s/iter; left time: 1007.1489s\n",
      "\titers: 300, epoch: 1 | loss: 0.8619046\n",
      "\tspeed: 0.0565s/iter; left time: 1003.0994s\n",
      "\titers: 400, epoch: 1 | loss: 0.8711451\n",
      "\tspeed: 0.0568s/iter; left time: 1002.5304s\n",
      "\titers: 500, epoch: 1 | loss: 0.8419620\n",
      "\tspeed: 0.0569s/iter; left time: 998.8744s\n",
      "\titers: 600, epoch: 1 | loss: 0.8505155\n",
      "\tspeed: 0.0571s/iter; left time: 996.6477s\n",
      "\titers: 700, epoch: 1 | loss: 0.8742189\n",
      "\tspeed: 0.0569s/iter; left time: 987.4196s\n",
      "\titers: 800, epoch: 1 | loss: 0.8644887\n",
      "\tspeed: 0.0588s/iter; left time: 1013.8852s\n",
      "\titers: 900, epoch: 1 | loss: 0.8549273\n",
      "\tspeed: 0.0595s/iter; left time: 1019.1867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:52.21s\n",
      "Steps: 902 | Train Loss: 0.9011081 Vali Loss: 1.0184302 Test Loss: 1.3099544\n",
      "Validation loss decreased (inf --> 1.018430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7189375\n",
      "\tspeed: 0.1512s/iter; left time: 2577.1379s\n",
      "\titers: 200, epoch: 2 | loss: 0.8307059\n",
      "\tspeed: 0.0572s/iter; left time: 968.2719s\n",
      "\titers: 300, epoch: 2 | loss: 0.6453809\n",
      "\tspeed: 0.0585s/iter; left time: 984.3115s\n",
      "\titers: 400, epoch: 2 | loss: 0.7505229\n",
      "\tspeed: 0.0572s/iter; left time: 957.6496s\n",
      "\titers: 500, epoch: 2 | loss: 0.6881771\n",
      "\tspeed: 0.0571s/iter; left time: 949.7068s\n",
      "\titers: 600, epoch: 2 | loss: 0.6804773\n",
      "\tspeed: 0.0572s/iter; left time: 945.4207s\n",
      "\titers: 700, epoch: 2 | loss: 0.7914818\n",
      "\tspeed: 0.0571s/iter; left time: 938.6204s\n",
      "\titers: 800, epoch: 2 | loss: 0.6105145\n",
      "\tspeed: 0.0580s/iter; left time: 948.1939s\n",
      "\titers: 900, epoch: 2 | loss: 0.6353539\n",
      "\tspeed: 0.0579s/iter; left time: 939.7360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:52.20s\n",
      "Steps: 902 | Train Loss: 0.6960781 Vali Loss: 0.8315557 Test Loss: 0.9746289\n",
      "Validation loss decreased (1.018430 --> 0.831556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4801841\n",
      "\tspeed: 0.1545s/iter; left time: 2492.8929s\n",
      "\titers: 200, epoch: 3 | loss: 0.5101814\n",
      "\tspeed: 0.0578s/iter; left time: 927.6038s\n",
      "\titers: 300, epoch: 3 | loss: 0.4520097\n",
      "\tspeed: 0.0576s/iter; left time: 917.2233s\n",
      "\titers: 400, epoch: 3 | loss: 0.4670836\n",
      "\tspeed: 0.0568s/iter; left time: 899.1925s\n",
      "\titers: 500, epoch: 3 | loss: 0.4784423\n",
      "\tspeed: 0.0568s/iter; left time: 893.1897s\n",
      "\titers: 600, epoch: 3 | loss: 0.4340152\n",
      "\tspeed: 0.0572s/iter; left time: 894.5035s\n",
      "\titers: 700, epoch: 3 | loss: 0.5075357\n",
      "\tspeed: 0.0567s/iter; left time: 881.2858s\n",
      "\titers: 800, epoch: 3 | loss: 0.5209229\n",
      "\tspeed: 0.0568s/iter; left time: 877.4324s\n",
      "\titers: 900, epoch: 3 | loss: 0.4143427\n",
      "\tspeed: 0.0591s/iter; left time: 906.6582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.32s\n",
      "Steps: 902 | Train Loss: 0.4832804 Vali Loss: 0.7737732 Test Loss: 1.0146445\n",
      "Validation loss decreased (0.831556 --> 0.773773).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4131553\n",
      "\tspeed: 0.1512s/iter; left time: 2302.9651s\n",
      "\titers: 200, epoch: 4 | loss: 0.4176673\n",
      "\tspeed: 0.0574s/iter; left time: 869.3808s\n",
      "\titers: 300, epoch: 4 | loss: 0.3764858\n",
      "\tspeed: 0.0572s/iter; left time: 860.0822s\n",
      "\titers: 400, epoch: 4 | loss: 0.3802186\n",
      "\tspeed: 0.0575s/iter; left time: 858.0267s\n",
      "\titers: 500, epoch: 4 | loss: 0.4112308\n",
      "\tspeed: 0.0577s/iter; left time: 855.5037s\n",
      "\titers: 600, epoch: 4 | loss: 0.3926941\n",
      "\tspeed: 0.0583s/iter; left time: 859.4938s\n",
      "\titers: 700, epoch: 4 | loss: 0.4169737\n",
      "\tspeed: 0.0580s/iter; left time: 848.8222s\n",
      "\titers: 800, epoch: 4 | loss: 0.3227324\n",
      "\tspeed: 0.0557s/iter; left time: 810.3107s\n",
      "\titers: 900, epoch: 4 | loss: 0.3506757\n",
      "\tspeed: 0.0556s/iter; left time: 803.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.11s\n",
      "Steps: 902 | Train Loss: 0.3937879 Vali Loss: 0.8260080 Test Loss: 1.0416869\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3304536\n",
      "\tspeed: 0.1479s/iter; left time: 2119.3265s\n",
      "\titers: 200, epoch: 5 | loss: 0.3184014\n",
      "\tspeed: 0.0588s/iter; left time: 837.2252s\n",
      "\titers: 300, epoch: 5 | loss: 0.3555612\n",
      "\tspeed: 0.0593s/iter; left time: 837.7982s\n",
      "\titers: 400, epoch: 5 | loss: 0.3572490\n",
      "\tspeed: 0.0577s/iter; left time: 809.3851s\n",
      "\titers: 500, epoch: 5 | loss: 0.3280550\n",
      "\tspeed: 0.0578s/iter; left time: 804.8147s\n",
      "\titers: 600, epoch: 5 | loss: 0.3335946\n",
      "\tspeed: 0.0570s/iter; left time: 788.2164s\n",
      "\titers: 700, epoch: 5 | loss: 0.3498349\n",
      "\tspeed: 0.0570s/iter; left time: 782.7105s\n",
      "\titers: 800, epoch: 5 | loss: 0.3253716\n",
      "\tspeed: 0.0593s/iter; left time: 808.5150s\n",
      "\titers: 900, epoch: 5 | loss: 0.3137490\n",
      "\tspeed: 0.0598s/iter; left time: 809.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:53.00s\n",
      "Steps: 902 | Train Loss: 0.3329470 Vali Loss: 0.7891561 Test Loss: 1.0794852\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2744029\n",
      "\tspeed: 0.1470s/iter; left time: 1974.4759s\n",
      "\titers: 200, epoch: 6 | loss: 0.3378651\n",
      "\tspeed: 0.0579s/iter; left time: 772.4021s\n",
      "\titers: 300, epoch: 6 | loss: 0.2829464\n",
      "\tspeed: 0.0595s/iter; left time: 787.5301s\n",
      "\titers: 400, epoch: 6 | loss: 0.3061607\n",
      "\tspeed: 0.0556s/iter; left time: 729.9237s\n",
      "\titers: 500, epoch: 6 | loss: 0.2653995\n",
      "\tspeed: 0.0543s/iter; left time: 707.7886s\n",
      "\titers: 600, epoch: 6 | loss: 0.2856255\n",
      "\tspeed: 0.0513s/iter; left time: 663.8861s\n",
      "\titers: 700, epoch: 6 | loss: 0.2722273\n",
      "\tspeed: 0.0516s/iter; left time: 661.4880s\n",
      "\titers: 800, epoch: 6 | loss: 0.2684691\n",
      "\tspeed: 0.0510s/iter; left time: 649.0418s\n",
      "\titers: 900, epoch: 6 | loss: 0.2581324\n",
      "\tspeed: 0.0507s/iter; left time: 640.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.43s\n",
      "Steps: 902 | Train Loss: 0.2875729 Vali Loss: 0.8499842 Test Loss: 1.0635883\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2429992\n",
      "\tspeed: 0.1427s/iter; left time: 1787.8859s\n",
      "\titers: 200, epoch: 7 | loss: 0.2651882\n",
      "\tspeed: 0.0537s/iter; left time: 667.4026s\n",
      "\titers: 300, epoch: 7 | loss: 0.2573965\n",
      "\tspeed: 0.0523s/iter; left time: 645.3753s\n",
      "\titers: 400, epoch: 7 | loss: 0.2575588\n",
      "\tspeed: 0.0513s/iter; left time: 627.3914s\n",
      "\titers: 500, epoch: 7 | loss: 0.2546336\n",
      "\tspeed: 0.0522s/iter; left time: 633.5392s\n",
      "\titers: 600, epoch: 7 | loss: 0.2654642\n",
      "\tspeed: 0.0524s/iter; left time: 630.1168s\n",
      "\titers: 700, epoch: 7 | loss: 0.2585121\n",
      "\tspeed: 0.0546s/iter; left time: 651.1402s\n",
      "\titers: 800, epoch: 7 | loss: 0.2705836\n",
      "\tspeed: 0.0534s/iter; left time: 631.4042s\n",
      "\titers: 900, epoch: 7 | loss: 0.2281063\n",
      "\tspeed: 0.0525s/iter; left time: 616.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.2527888 Vali Loss: 0.8783796 Test Loss: 1.0878887\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2692444\n",
      "\tspeed: 0.1404s/iter; left time: 1632.5995s\n",
      "\titers: 200, epoch: 8 | loss: 0.2336604\n",
      "\tspeed: 0.0531s/iter; left time: 611.9438s\n",
      "\titers: 300, epoch: 8 | loss: 0.2238678\n",
      "\tspeed: 0.0520s/iter; left time: 593.9406s\n",
      "\titers: 400, epoch: 8 | loss: 0.2300956\n",
      "\tspeed: 0.0517s/iter; left time: 585.5127s\n",
      "\titers: 500, epoch: 8 | loss: 0.2071926\n",
      "\tspeed: 0.0539s/iter; left time: 605.4789s\n",
      "\titers: 600, epoch: 8 | loss: 0.2156269\n",
      "\tspeed: 0.0520s/iter; left time: 578.9687s\n",
      "\titers: 700, epoch: 8 | loss: 0.2172709\n",
      "\tspeed: 0.0551s/iter; left time: 607.4423s\n",
      "\titers: 800, epoch: 8 | loss: 0.2191840\n",
      "\tspeed: 0.0558s/iter; left time: 609.7105s\n",
      "\titers: 900, epoch: 8 | loss: 0.2099798\n",
      "\tspeed: 0.0531s/iter; left time: 574.6075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.28s\n",
      "Steps: 902 | Train Loss: 0.2250717 Vali Loss: 0.8714702 Test Loss: 1.0807112\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0134246349334717, rmse:1.0066899061203003, mae:0.741763174533844, rse:0.7974767088890076\n",
      "Original data scale mse:45914860.0, rmse:6776.05029296875, mae:4621.64697265625, rse:0.33761537075042725\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7418611\n",
      "\tspeed: 0.0795s/iter; left time: 1432.5795s\n",
      "\titers: 200, epoch: 1 | loss: 0.7367070\n",
      "\tspeed: 0.0490s/iter; left time: 877.6310s\n",
      "\titers: 300, epoch: 1 | loss: 0.7049600\n",
      "\tspeed: 0.0488s/iter; left time: 869.7738s\n",
      "\titers: 400, epoch: 1 | loss: 0.6860753\n",
      "\tspeed: 0.0488s/iter; left time: 864.5463s\n",
      "\titers: 500, epoch: 1 | loss: 0.6370769\n",
      "\tspeed: 0.0486s/iter; left time: 856.4106s\n",
      "\titers: 600, epoch: 1 | loss: 0.6102574\n",
      "\tspeed: 0.0485s/iter; left time: 850.6347s\n",
      "\titers: 700, epoch: 1 | loss: 0.7115066\n",
      "\tspeed: 0.0481s/iter; left time: 837.0983s\n",
      "\titers: 800, epoch: 1 | loss: 0.5816745\n",
      "\tspeed: 0.0459s/iter; left time: 794.6745s\n",
      "\titers: 900, epoch: 1 | loss: 0.5285000\n",
      "\tspeed: 0.0440s/iter; left time: 757.4016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.11s\n",
      "Steps: 906 | Train Loss: 0.6784745 Vali Loss: 0.6455176 Test Loss: 0.7010428\n",
      "Validation loss decreased (inf --> 0.645518).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4602826\n",
      "\tspeed: 0.1118s/iter; left time: 1913.3464s\n",
      "\titers: 200, epoch: 2 | loss: 0.5297759\n",
      "\tspeed: 0.0459s/iter; left time: 780.1407s\n",
      "\titers: 300, epoch: 2 | loss: 0.4563934\n",
      "\tspeed: 0.0458s/iter; left time: 775.1726s\n",
      "\titers: 400, epoch: 2 | loss: 0.4170901\n",
      "\tspeed: 0.0458s/iter; left time: 770.3618s\n",
      "\titers: 500, epoch: 2 | loss: 0.4135004\n",
      "\tspeed: 0.0457s/iter; left time: 763.8898s\n",
      "\titers: 600, epoch: 2 | loss: 0.3520459\n",
      "\tspeed: 0.0459s/iter; left time: 762.2162s\n",
      "\titers: 700, epoch: 2 | loss: 0.4087490\n",
      "\tspeed: 0.0458s/iter; left time: 756.7833s\n",
      "\titers: 800, epoch: 2 | loss: 0.3784128\n",
      "\tspeed: 0.0458s/iter; left time: 751.4150s\n",
      "\titers: 900, epoch: 2 | loss: 0.3681543\n",
      "\tspeed: 0.0457s/iter; left time: 745.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.4308069 Vali Loss: 0.4752153 Test Loss: 0.4891419\n",
      "Validation loss decreased (0.645518 --> 0.475215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4363078\n",
      "\tspeed: 0.1116s/iter; left time: 1809.1891s\n",
      "\titers: 200, epoch: 3 | loss: 0.3645507\n",
      "\tspeed: 0.0336s/iter; left time: 541.2445s\n",
      "\titers: 300, epoch: 3 | loss: 0.3612276\n",
      "\tspeed: 0.0329s/iter; left time: 527.2126s\n",
      "\titers: 400, epoch: 3 | loss: 0.3654458\n",
      "\tspeed: 0.0330s/iter; left time: 524.3171s\n",
      "\titers: 500, epoch: 3 | loss: 0.3556231\n",
      "\tspeed: 0.0329s/iter; left time: 520.5671s\n",
      "\titers: 600, epoch: 3 | loss: 0.3688257\n",
      "\tspeed: 0.0329s/iter; left time: 517.1756s\n",
      "\titers: 700, epoch: 3 | loss: 0.3405989\n",
      "\tspeed: 0.0329s/iter; left time: 514.2756s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645940\n",
      "\tspeed: 0.0329s/iter; left time: 510.6942s\n",
      "\titers: 900, epoch: 3 | loss: 0.3503218\n",
      "\tspeed: 0.0329s/iter; left time: 507.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:31.46s\n",
      "Steps: 906 | Train Loss: 0.3667270 Vali Loss: 0.4566939 Test Loss: 0.4674495\n",
      "Validation loss decreased (0.475215 --> 0.456694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3382163\n",
      "\tspeed: 0.1128s/iter; left time: 1725.5060s\n",
      "\titers: 200, epoch: 4 | loss: 0.3756458\n",
      "\tspeed: 0.0456s/iter; left time: 692.8537s\n",
      "\titers: 300, epoch: 4 | loss: 0.3435951\n",
      "\tspeed: 0.0457s/iter; left time: 690.0136s\n",
      "\titers: 400, epoch: 4 | loss: 0.3439455\n",
      "\tspeed: 0.0458s/iter; left time: 686.5390s\n",
      "\titers: 500, epoch: 4 | loss: 0.3780990\n",
      "\tspeed: 0.0460s/iter; left time: 685.1639s\n",
      "\titers: 600, epoch: 4 | loss: 0.3607699\n",
      "\tspeed: 0.0461s/iter; left time: 681.7321s\n",
      "\titers: 700, epoch: 4 | loss: 0.3559942\n",
      "\tspeed: 0.0460s/iter; left time: 675.8345s\n",
      "\titers: 800, epoch: 4 | loss: 0.3529063\n",
      "\tspeed: 0.0461s/iter; left time: 673.2372s\n",
      "\titers: 900, epoch: 4 | loss: 0.2754554\n",
      "\tspeed: 0.0460s/iter; left time: 667.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 906 | Train Loss: 0.3434595 Vali Loss: 0.4530770 Test Loss: 0.4626109\n",
      "Validation loss decreased (0.456694 --> 0.453077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3127272\n",
      "\tspeed: 0.1150s/iter; left time: 1655.2525s\n",
      "\titers: 200, epoch: 5 | loss: 0.3090605\n",
      "\tspeed: 0.0459s/iter; left time: 655.8329s\n",
      "\titers: 300, epoch: 5 | loss: 0.3299609\n",
      "\tspeed: 0.0461s/iter; left time: 654.5303s\n",
      "\titers: 400, epoch: 5 | loss: 0.3544933\n",
      "\tspeed: 0.0460s/iter; left time: 648.7452s\n",
      "\titers: 500, epoch: 5 | loss: 0.3029163\n",
      "\tspeed: 0.0460s/iter; left time: 643.3206s\n",
      "\titers: 600, epoch: 5 | loss: 0.3803566\n",
      "\tspeed: 0.0460s/iter; left time: 639.8657s\n",
      "\titers: 700, epoch: 5 | loss: 0.3536870\n",
      "\tspeed: 0.0459s/iter; left time: 632.6780s\n",
      "\titers: 800, epoch: 5 | loss: 0.3251951\n",
      "\tspeed: 0.0458s/iter; left time: 627.9121s\n",
      "\titers: 900, epoch: 5 | loss: 0.3574745\n",
      "\tspeed: 0.0459s/iter; left time: 624.1927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.88s\n",
      "Steps: 906 | Train Loss: 0.3234064 Vali Loss: 0.4433658 Test Loss: 0.4738460\n",
      "Validation loss decreased (0.453077 --> 0.443366).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3080733\n",
      "\tspeed: 0.1112s/iter; left time: 1500.2914s\n",
      "\titers: 200, epoch: 6 | loss: 0.2912736\n",
      "\tspeed: 0.0455s/iter; left time: 609.8271s\n",
      "\titers: 300, epoch: 6 | loss: 0.3020111\n",
      "\tspeed: 0.0353s/iter; left time: 469.0896s\n",
      "\titers: 400, epoch: 6 | loss: 0.3237649\n",
      "\tspeed: 0.0330s/iter; left time: 435.0725s\n",
      "\titers: 500, epoch: 6 | loss: 0.3070419\n",
      "\tspeed: 0.0330s/iter; left time: 431.6830s\n",
      "\titers: 600, epoch: 6 | loss: 0.2748387\n",
      "\tspeed: 0.0330s/iter; left time: 428.2420s\n",
      "\titers: 700, epoch: 6 | loss: 0.2903692\n",
      "\tspeed: 0.0330s/iter; left time: 424.8600s\n",
      "\titers: 800, epoch: 6 | loss: 0.3136680\n",
      "\tspeed: 0.0330s/iter; left time: 421.5784s\n",
      "\titers: 900, epoch: 6 | loss: 0.2780750\n",
      "\tspeed: 0.0329s/iter; left time: 418.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:32.87s\n",
      "Steps: 906 | Train Loss: 0.3044916 Vali Loss: 0.4442986 Test Loss: 0.4804077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3047175\n",
      "\tspeed: 0.1117s/iter; left time: 1405.8319s\n",
      "\titers: 200, epoch: 7 | loss: 0.2794079\n",
      "\tspeed: 0.0458s/iter; left time: 571.7939s\n",
      "\titers: 300, epoch: 7 | loss: 0.3188211\n",
      "\tspeed: 0.0459s/iter; left time: 568.4350s\n",
      "\titers: 400, epoch: 7 | loss: 0.3151511\n",
      "\tspeed: 0.0458s/iter; left time: 563.0994s\n",
      "\titers: 500, epoch: 7 | loss: 0.3078192\n",
      "\tspeed: 0.0459s/iter; left time: 559.8036s\n",
      "\titers: 600, epoch: 7 | loss: 0.2738682\n",
      "\tspeed: 0.0459s/iter; left time: 554.8378s\n",
      "\titers: 700, epoch: 7 | loss: 0.3107827\n",
      "\tspeed: 0.0459s/iter; left time: 550.5172s\n",
      "\titers: 800, epoch: 7 | loss: 0.2477971\n",
      "\tspeed: 0.0456s/iter; left time: 541.9086s\n",
      "\titers: 900, epoch: 7 | loss: 0.2745183\n",
      "\tspeed: 0.0486s/iter; left time: 573.2714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 906 | Train Loss: 0.2874747 Vali Loss: 0.4404407 Test Loss: 0.4710884\n",
      "Validation loss decreased (0.443366 --> 0.440441).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2584272\n",
      "\tspeed: 0.1114s/iter; left time: 1301.6220s\n",
      "\titers: 200, epoch: 8 | loss: 0.3347048\n",
      "\tspeed: 0.0461s/iter; left time: 533.3657s\n",
      "\titers: 300, epoch: 8 | loss: 0.2449328\n",
      "\tspeed: 0.0457s/iter; left time: 524.3603s\n",
      "\titers: 400, epoch: 8 | loss: 0.2584884\n",
      "\tspeed: 0.0458s/iter; left time: 521.4731s\n",
      "\titers: 500, epoch: 8 | loss: 0.2710293\n",
      "\tspeed: 0.0458s/iter; left time: 516.3988s\n",
      "\titers: 600, epoch: 8 | loss: 0.3047492\n",
      "\tspeed: 0.0457s/iter; left time: 511.2426s\n",
      "\titers: 700, epoch: 8 | loss: 0.2657906\n",
      "\tspeed: 0.0458s/iter; left time: 507.1230s\n",
      "\titers: 800, epoch: 8 | loss: 0.2687883\n",
      "\tspeed: 0.0459s/iter; left time: 504.3303s\n",
      "\titers: 900, epoch: 8 | loss: 0.2849250\n",
      "\tspeed: 0.0458s/iter; left time: 497.9839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.76s\n",
      "Steps: 906 | Train Loss: 0.2716525 Vali Loss: 0.4477741 Test Loss: 0.4733999\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2697747\n",
      "\tspeed: 0.1089s/iter; left time: 1173.6514s\n",
      "\titers: 200, epoch: 9 | loss: 0.2652064\n",
      "\tspeed: 0.0462s/iter; left time: 493.1939s\n",
      "\titers: 300, epoch: 9 | loss: 0.2436751\n",
      "\tspeed: 0.0462s/iter; left time: 487.9477s\n",
      "\titers: 400, epoch: 9 | loss: 0.3048666\n",
      "\tspeed: 0.0463s/iter; left time: 485.2261s\n",
      "\titers: 500, epoch: 9 | loss: 0.2555520\n",
      "\tspeed: 0.0462s/iter; left time: 478.9571s\n",
      "\titers: 600, epoch: 9 | loss: 0.2660410\n",
      "\tspeed: 0.0461s/iter; left time: 473.2962s\n",
      "\titers: 700, epoch: 9 | loss: 0.2620555\n",
      "\tspeed: 0.0461s/iter; left time: 469.1677s\n",
      "\titers: 800, epoch: 9 | loss: 0.2636246\n",
      "\tspeed: 0.0462s/iter; left time: 464.8745s\n",
      "\titers: 900, epoch: 9 | loss: 0.2319689\n",
      "\tspeed: 0.0460s/iter; left time: 459.2347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 906 | Train Loss: 0.2589175 Vali Loss: 0.4508602 Test Loss: 0.4751743\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2590968\n",
      "\tspeed: 0.1080s/iter; left time: 1066.0422s\n",
      "\titers: 200, epoch: 10 | loss: 0.2616624\n",
      "\tspeed: 0.0463s/iter; left time: 451.8139s\n",
      "\titers: 300, epoch: 10 | loss: 0.2496757\n",
      "\tspeed: 0.0462s/iter; left time: 446.5292s\n",
      "\titers: 400, epoch: 10 | loss: 0.2814045\n",
      "\tspeed: 0.0464s/iter; left time: 444.0684s\n",
      "\titers: 500, epoch: 10 | loss: 0.2536940\n",
      "\tspeed: 0.0464s/iter; left time: 438.8554s\n",
      "\titers: 600, epoch: 10 | loss: 0.2385211\n",
      "\tspeed: 0.0463s/iter; left time: 433.7281s\n",
      "\titers: 700, epoch: 10 | loss: 0.2462176\n",
      "\tspeed: 0.0464s/iter; left time: 430.1225s\n",
      "\titers: 800, epoch: 10 | loss: 0.2437600\n",
      "\tspeed: 0.0461s/iter; left time: 422.7087s\n",
      "\titers: 900, epoch: 10 | loss: 0.2239989\n",
      "\tspeed: 0.0463s/iter; left time: 419.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 906 | Train Loss: 0.2480650 Vali Loss: 0.4478072 Test Loss: 0.4738463\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2234533\n",
      "\tspeed: 0.1079s/iter; left time: 966.8342s\n",
      "\titers: 200, epoch: 11 | loss: 0.2425222\n",
      "\tspeed: 0.0460s/iter; left time: 407.3417s\n",
      "\titers: 300, epoch: 11 | loss: 0.2304610\n",
      "\tspeed: 0.0459s/iter; left time: 402.1742s\n",
      "\titers: 400, epoch: 11 | loss: 0.2297867\n",
      "\tspeed: 0.0459s/iter; left time: 397.1422s\n",
      "\titers: 500, epoch: 11 | loss: 0.2814640\n",
      "\tspeed: 0.0457s/iter; left time: 391.6354s\n",
      "\titers: 600, epoch: 11 | loss: 0.2705878\n",
      "\tspeed: 0.0457s/iter; left time: 387.0670s\n",
      "\titers: 700, epoch: 11 | loss: 0.2261574\n",
      "\tspeed: 0.0458s/iter; left time: 383.3086s\n",
      "\titers: 800, epoch: 11 | loss: 0.2075110\n",
      "\tspeed: 0.0458s/iter; left time: 378.2704s\n",
      "\titers: 900, epoch: 11 | loss: 0.2062140\n",
      "\tspeed: 0.0458s/iter; left time: 373.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 906 | Train Loss: 0.2389492 Vali Loss: 0.4499737 Test Loss: 0.4815345\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2299732\n",
      "\tspeed: 0.1097s/iter; left time: 883.9790s\n",
      "\titers: 200, epoch: 12 | loss: 0.2212492\n",
      "\tspeed: 0.0463s/iter; left time: 368.6895s\n",
      "\titers: 300, epoch: 12 | loss: 0.2141170\n",
      "\tspeed: 0.0464s/iter; left time: 364.0883s\n",
      "\titers: 400, epoch: 12 | loss: 0.2253383\n",
      "\tspeed: 0.0465s/iter; left time: 360.9394s\n",
      "\titers: 500, epoch: 12 | loss: 0.2291011\n",
      "\tspeed: 0.0462s/iter; left time: 353.2987s\n",
      "\titers: 600, epoch: 12 | loss: 0.2251816\n",
      "\tspeed: 0.0464s/iter; left time: 350.8135s\n",
      "\titers: 700, epoch: 12 | loss: 0.2215950\n",
      "\tspeed: 0.0463s/iter; left time: 345.4591s\n",
      "\titers: 800, epoch: 12 | loss: 0.1915206\n",
      "\tspeed: 0.0462s/iter; left time: 340.0250s\n",
      "\titers: 900, epoch: 12 | loss: 0.2362119\n",
      "\tspeed: 0.0462s/iter; left time: 335.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.17s\n",
      "Steps: 906 | Train Loss: 0.2290419 Vali Loss: 0.4544228 Test Loss: 0.4865534\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5389456748962402, rmse:0.7341291904449463, mae:0.47187572717666626, rse:0.5810168385505676\n",
      "Original data scale mse:21871782.0, rmse:4676.7275390625, mae:2841.9736328125, rse:0.23253633081912994\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7441173\n",
      "\tspeed: 0.0516s/iter; left time: 930.7254s\n",
      "\titers: 200, epoch: 1 | loss: 0.7540241\n",
      "\tspeed: 0.0492s/iter; left time: 881.6872s\n",
      "\titers: 300, epoch: 1 | loss: 0.6945181\n",
      "\tspeed: 0.0493s/iter; left time: 879.2786s\n",
      "\titers: 400, epoch: 1 | loss: 0.6682664\n",
      "\tspeed: 0.0495s/iter; left time: 877.7733s\n",
      "\titers: 500, epoch: 1 | loss: 0.6609266\n",
      "\tspeed: 0.0494s/iter; left time: 871.1857s\n",
      "\titers: 600, epoch: 1 | loss: 0.6405426\n",
      "\tspeed: 0.0495s/iter; left time: 866.5684s\n",
      "\titers: 700, epoch: 1 | loss: 0.6038924\n",
      "\tspeed: 0.0491s/iter; left time: 855.2118s\n",
      "\titers: 800, epoch: 1 | loss: 0.6264359\n",
      "\tspeed: 0.0473s/iter; left time: 819.6048s\n",
      "\titers: 900, epoch: 1 | loss: 0.5550255\n",
      "\tspeed: 0.0462s/iter; left time: 796.2528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.48s\n",
      "Steps: 906 | Train Loss: 0.6848281 Vali Loss: 0.6588677 Test Loss: 0.7167252\n",
      "Validation loss decreased (inf --> 0.658868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4873689\n",
      "\tspeed: 0.1139s/iter; left time: 1949.5019s\n",
      "\titers: 200, epoch: 2 | loss: 0.4576486\n",
      "\tspeed: 0.0463s/iter; left time: 787.9414s\n",
      "\titers: 300, epoch: 2 | loss: 0.3933029\n",
      "\tspeed: 0.0461s/iter; left time: 780.2566s\n",
      "\titers: 400, epoch: 2 | loss: 0.4467748\n",
      "\tspeed: 0.0461s/iter; left time: 775.2020s\n",
      "\titers: 500, epoch: 2 | loss: 0.4394394\n",
      "\tspeed: 0.0454s/iter; left time: 758.6447s\n",
      "\titers: 600, epoch: 2 | loss: 0.3892457\n",
      "\tspeed: 0.0463s/iter; left time: 769.2380s\n",
      "\titers: 700, epoch: 2 | loss: 0.4428514\n",
      "\tspeed: 0.0462s/iter; left time: 762.3062s\n",
      "\titers: 800, epoch: 2 | loss: 0.3399780\n",
      "\tspeed: 0.0461s/iter; left time: 757.2457s\n",
      "\titers: 900, epoch: 2 | loss: 0.4383927\n",
      "\tspeed: 0.0461s/iter; left time: 751.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.07s\n",
      "Steps: 906 | Train Loss: 0.4365257 Vali Loss: 0.4639782 Test Loss: 0.4901719\n",
      "Validation loss decreased (0.658868 --> 0.463978).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3893672\n",
      "\tspeed: 0.1125s/iter; left time: 1824.0324s\n",
      "\titers: 200, epoch: 3 | loss: 0.3483378\n",
      "\tspeed: 0.0462s/iter; left time: 744.1495s\n",
      "\titers: 300, epoch: 3 | loss: 0.3298485\n",
      "\tspeed: 0.0462s/iter; left time: 739.1247s\n",
      "\titers: 400, epoch: 3 | loss: 0.3802936\n",
      "\tspeed: 0.0461s/iter; left time: 733.3064s\n",
      "\titers: 500, epoch: 3 | loss: 0.3986654\n",
      "\tspeed: 0.0462s/iter; left time: 730.4594s\n",
      "\titers: 600, epoch: 3 | loss: 0.3451155\n",
      "\tspeed: 0.0463s/iter; left time: 726.5771s\n",
      "\titers: 700, epoch: 3 | loss: 0.3537111\n",
      "\tspeed: 0.0460s/iter; left time: 718.7639s\n",
      "\titers: 800, epoch: 3 | loss: 0.3694519\n",
      "\tspeed: 0.0462s/iter; left time: 716.5491s\n",
      "\titers: 900, epoch: 3 | loss: 0.3612202\n",
      "\tspeed: 0.0461s/iter; left time: 710.9572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 906 | Train Loss: 0.3662567 Vali Loss: 0.4634551 Test Loss: 0.4857825\n",
      "Validation loss decreased (0.463978 --> 0.463455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3287792\n",
      "\tspeed: 0.1112s/iter; left time: 1702.3453s\n",
      "\titers: 200, epoch: 4 | loss: 0.3369122\n",
      "\tspeed: 0.0457s/iter; left time: 694.2064s\n",
      "\titers: 300, epoch: 4 | loss: 0.3325499\n",
      "\tspeed: 0.0457s/iter; left time: 690.2461s\n",
      "\titers: 400, epoch: 4 | loss: 0.3695143\n",
      "\tspeed: 0.0457s/iter; left time: 685.9660s\n",
      "\titers: 500, epoch: 4 | loss: 0.3073331\n",
      "\tspeed: 0.0457s/iter; left time: 681.3222s\n",
      "\titers: 600, epoch: 4 | loss: 0.3146611\n",
      "\tspeed: 0.0456s/iter; left time: 674.5518s\n",
      "\titers: 700, epoch: 4 | loss: 0.3185983\n",
      "\tspeed: 0.0457s/iter; left time: 671.6846s\n",
      "\titers: 800, epoch: 4 | loss: 0.3454877\n",
      "\tspeed: 0.0457s/iter; left time: 667.1861s\n",
      "\titers: 900, epoch: 4 | loss: 0.3546220\n",
      "\tspeed: 0.0458s/iter; left time: 664.5591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 906 | Train Loss: 0.3428350 Vali Loss: 0.4461609 Test Loss: 0.4551203\n",
      "Validation loss decreased (0.463455 --> 0.446161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2849411\n",
      "\tspeed: 0.1157s/iter; left time: 1665.2418s\n",
      "\titers: 200, epoch: 5 | loss: 0.3281790\n",
      "\tspeed: 0.0489s/iter; left time: 699.3313s\n",
      "\titers: 300, epoch: 5 | loss: 0.3331194\n",
      "\tspeed: 0.0489s/iter; left time: 693.8585s\n",
      "\titers: 400, epoch: 5 | loss: 0.3072594\n",
      "\tspeed: 0.0489s/iter; left time: 689.9426s\n",
      "\titers: 500, epoch: 5 | loss: 0.3405737\n",
      "\tspeed: 0.0487s/iter; left time: 681.6513s\n",
      "\titers: 600, epoch: 5 | loss: 0.2845627\n",
      "\tspeed: 0.0488s/iter; left time: 678.4832s\n",
      "\titers: 700, epoch: 5 | loss: 0.3236956\n",
      "\tspeed: 0.0487s/iter; left time: 671.6604s\n",
      "\titers: 800, epoch: 5 | loss: 0.3074664\n",
      "\tspeed: 0.0487s/iter; left time: 666.4425s\n",
      "\titers: 900, epoch: 5 | loss: 0.2941036\n",
      "\tspeed: 0.0477s/iter; left time: 648.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.37s\n",
      "Steps: 906 | Train Loss: 0.3230570 Vali Loss: 0.4407859 Test Loss: 0.4652851\n",
      "Validation loss decreased (0.446161 --> 0.440786).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3027448\n",
      "\tspeed: 0.1138s/iter; left time: 1535.7509s\n",
      "\titers: 200, epoch: 6 | loss: 0.2742180\n",
      "\tspeed: 0.0464s/iter; left time: 620.8897s\n",
      "\titers: 300, epoch: 6 | loss: 0.3233389\n",
      "\tspeed: 0.0463s/iter; left time: 614.9434s\n",
      "\titers: 400, epoch: 6 | loss: 0.3180093\n",
      "\tspeed: 0.0461s/iter; left time: 607.5248s\n",
      "\titers: 500, epoch: 6 | loss: 0.3220596\n",
      "\tspeed: 0.0461s/iter; left time: 603.0020s\n",
      "\titers: 600, epoch: 6 | loss: 0.3075038\n",
      "\tspeed: 0.0460s/iter; left time: 597.7322s\n",
      "\titers: 700, epoch: 6 | loss: 0.2889935\n",
      "\tspeed: 0.0462s/iter; left time: 595.6592s\n",
      "\titers: 800, epoch: 6 | loss: 0.2977264\n",
      "\tspeed: 0.0462s/iter; left time: 590.8514s\n",
      "\titers: 900, epoch: 6 | loss: 0.2870785\n",
      "\tspeed: 0.0462s/iter; left time: 586.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 906 | Train Loss: 0.3041236 Vali Loss: 0.4526628 Test Loss: 0.4668238\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2866482\n",
      "\tspeed: 0.1112s/iter; left time: 1399.3337s\n",
      "\titers: 200, epoch: 7 | loss: 0.2587057\n",
      "\tspeed: 0.0462s/iter; left time: 576.2322s\n",
      "\titers: 300, epoch: 7 | loss: 0.2779284\n",
      "\tspeed: 0.0461s/iter; left time: 570.7804s\n",
      "\titers: 400, epoch: 7 | loss: 0.3092663\n",
      "\tspeed: 0.0462s/iter; left time: 568.0396s\n",
      "\titers: 500, epoch: 7 | loss: 0.2959416\n",
      "\tspeed: 0.0459s/iter; left time: 559.7447s\n",
      "\titers: 600, epoch: 7 | loss: 0.3067658\n",
      "\tspeed: 0.0462s/iter; left time: 558.6200s\n",
      "\titers: 700, epoch: 7 | loss: 0.2564319\n",
      "\tspeed: 0.0464s/iter; left time: 556.1077s\n",
      "\titers: 800, epoch: 7 | loss: 0.3004796\n",
      "\tspeed: 0.0463s/iter; left time: 549.8215s\n",
      "\titers: 900, epoch: 7 | loss: 0.2376298\n",
      "\tspeed: 0.0459s/iter; left time: 541.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 906 | Train Loss: 0.2875856 Vali Loss: 0.4512243 Test Loss: 0.4804226\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2543750\n",
      "\tspeed: 0.1124s/iter; left time: 1312.9287s\n",
      "\titers: 200, epoch: 8 | loss: 0.2622992\n",
      "\tspeed: 0.0488s/iter; left time: 565.5419s\n",
      "\titers: 300, epoch: 8 | loss: 0.2679873\n",
      "\tspeed: 0.0489s/iter; left time: 561.8825s\n",
      "\titers: 400, epoch: 8 | loss: 0.2743196\n",
      "\tspeed: 0.0487s/iter; left time: 553.6469s\n",
      "\titers: 500, epoch: 8 | loss: 0.3272017\n",
      "\tspeed: 0.0488s/iter; left time: 550.8323s\n",
      "\titers: 600, epoch: 8 | loss: 0.2610323\n",
      "\tspeed: 0.0488s/iter; left time: 546.0594s\n",
      "\titers: 700, epoch: 8 | loss: 0.2805443\n",
      "\tspeed: 0.0488s/iter; left time: 540.6007s\n",
      "\titers: 800, epoch: 8 | loss: 0.2851423\n",
      "\tspeed: 0.0488s/iter; left time: 535.3567s\n",
      "\titers: 900, epoch: 8 | loss: 0.2399363\n",
      "\tspeed: 0.0490s/iter; left time: 533.1815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.52s\n",
      "Steps: 906 | Train Loss: 0.2718003 Vali Loss: 0.4447736 Test Loss: 0.4770514\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2530470\n",
      "\tspeed: 0.1091s/iter; left time: 1175.3373s\n",
      "\titers: 200, epoch: 9 | loss: 0.2198261\n",
      "\tspeed: 0.0460s/iter; left time: 490.7898s\n",
      "\titers: 300, epoch: 9 | loss: 0.2442634\n",
      "\tspeed: 0.0462s/iter; left time: 488.1140s\n",
      "\titers: 400, epoch: 9 | loss: 0.2585247\n",
      "\tspeed: 0.0461s/iter; left time: 482.4922s\n",
      "\titers: 500, epoch: 9 | loss: 0.2671536\n",
      "\tspeed: 0.0461s/iter; left time: 477.8528s\n",
      "\titers: 600, epoch: 9 | loss: 0.2298654\n",
      "\tspeed: 0.0458s/iter; left time: 470.2717s\n",
      "\titers: 700, epoch: 9 | loss: 0.2758046\n",
      "\tspeed: 0.0462s/iter; left time: 470.1522s\n",
      "\titers: 800, epoch: 9 | loss: 0.2609636\n",
      "\tspeed: 0.0463s/iter; left time: 466.5992s\n",
      "\titers: 900, epoch: 9 | loss: 0.2493378\n",
      "\tspeed: 0.0459s/iter; left time: 458.0753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.95s\n",
      "Steps: 906 | Train Loss: 0.2597978 Vali Loss: 0.4491738 Test Loss: 0.4730969\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2639883\n",
      "\tspeed: 0.1102s/iter; left time: 1087.2967s\n",
      "\titers: 200, epoch: 10 | loss: 0.2324534\n",
      "\tspeed: 0.0462s/iter; left time: 451.3987s\n",
      "\titers: 300, epoch: 10 | loss: 0.2371592\n",
      "\tspeed: 0.0463s/iter; left time: 447.8107s\n",
      "\titers: 400, epoch: 10 | loss: 0.2711227\n",
      "\tspeed: 0.0462s/iter; left time: 441.7610s\n",
      "\titers: 500, epoch: 10 | loss: 0.2696366\n",
      "\tspeed: 0.0460s/iter; left time: 435.9094s\n",
      "\titers: 600, epoch: 10 | loss: 0.2511064\n",
      "\tspeed: 0.0460s/iter; left time: 430.6096s\n",
      "\titers: 700, epoch: 10 | loss: 0.2485189\n",
      "\tspeed: 0.0461s/iter; left time: 427.3750s\n",
      "\titers: 800, epoch: 10 | loss: 0.2334890\n",
      "\tspeed: 0.0462s/iter; left time: 423.4128s\n",
      "\titers: 900, epoch: 10 | loss: 0.2508550\n",
      "\tspeed: 0.0460s/iter; left time: 416.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.05s\n",
      "Steps: 906 | Train Loss: 0.2487377 Vali Loss: 0.4398437 Test Loss: 0.4752933\n",
      "Validation loss decreased (0.440786 --> 0.439844).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2483284\n",
      "\tspeed: 0.1140s/iter; left time: 1021.2957s\n",
      "\titers: 200, epoch: 11 | loss: 0.2412300\n",
      "\tspeed: 0.0459s/iter; left time: 406.6676s\n",
      "\titers: 300, epoch: 11 | loss: 0.2354616\n",
      "\tspeed: 0.0460s/iter; left time: 402.6551s\n",
      "\titers: 400, epoch: 11 | loss: 0.2349726\n",
      "\tspeed: 0.0459s/iter; left time: 397.5126s\n",
      "\titers: 500, epoch: 11 | loss: 0.2356248\n",
      "\tspeed: 0.0457s/iter; left time: 391.4805s\n",
      "\titers: 600, epoch: 11 | loss: 0.2396688\n",
      "\tspeed: 0.0458s/iter; left time: 387.2773s\n",
      "\titers: 700, epoch: 11 | loss: 0.2229913\n",
      "\tspeed: 0.0458s/iter; left time: 383.0634s\n",
      "\titers: 800, epoch: 11 | loss: 0.2506939\n",
      "\tspeed: 0.0458s/iter; left time: 378.7323s\n",
      "\titers: 900, epoch: 11 | loss: 0.2343062\n",
      "\tspeed: 0.0457s/iter; left time: 372.9033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.83s\n",
      "Steps: 906 | Train Loss: 0.2388878 Vali Loss: 0.4477290 Test Loss: 0.4869021\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2648202\n",
      "\tspeed: 0.1144s/iter; left time: 921.6483s\n",
      "\titers: 200, epoch: 12 | loss: 0.2186224\n",
      "\tspeed: 0.0466s/iter; left time: 370.9429s\n",
      "\titers: 300, epoch: 12 | loss: 0.2411895\n",
      "\tspeed: 0.0469s/iter; left time: 368.5556s\n",
      "\titers: 400, epoch: 12 | loss: 0.2073684\n",
      "\tspeed: 0.0492s/iter; left time: 381.5037s\n",
      "\titers: 500, epoch: 12 | loss: 0.2281721\n",
      "\tspeed: 0.0494s/iter; left time: 378.3955s\n",
      "\titers: 600, epoch: 12 | loss: 0.2271247\n",
      "\tspeed: 0.0475s/iter; left time: 358.9623s\n",
      "\titers: 700, epoch: 12 | loss: 0.2232826\n",
      "\tspeed: 0.0461s/iter; left time: 343.3358s\n",
      "\titers: 800, epoch: 12 | loss: 0.2236091\n",
      "\tspeed: 0.0460s/iter; left time: 338.2932s\n",
      "\titers: 900, epoch: 12 | loss: 0.2269458\n",
      "\tspeed: 0.0459s/iter; left time: 333.1782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 906 | Train Loss: 0.2303001 Vali Loss: 0.4500311 Test Loss: 0.4804274\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2327175\n",
      "\tspeed: 0.1095s/iter; left time: 782.5118s\n",
      "\titers: 200, epoch: 13 | loss: 0.2072760\n",
      "\tspeed: 0.0462s/iter; left time: 325.3641s\n",
      "\titers: 300, epoch: 13 | loss: 0.2410574\n",
      "\tspeed: 0.0461s/iter; left time: 320.0960s\n",
      "\titers: 400, epoch: 13 | loss: 0.2100880\n",
      "\tspeed: 0.0459s/iter; left time: 314.7057s\n",
      "\titers: 500, epoch: 13 | loss: 0.2192658\n",
      "\tspeed: 0.0461s/iter; left time: 311.0244s\n",
      "\titers: 600, epoch: 13 | loss: 0.1931813\n",
      "\tspeed: 0.0461s/iter; left time: 306.5803s\n",
      "\titers: 700, epoch: 13 | loss: 0.2249931\n",
      "\tspeed: 0.0460s/iter; left time: 300.9915s\n",
      "\titers: 800, epoch: 13 | loss: 0.2392221\n",
      "\tspeed: 0.0459s/iter; left time: 296.2742s\n",
      "\titers: 900, epoch: 13 | loss: 0.2353158\n",
      "\tspeed: 0.0459s/iter; left time: 291.4042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.93s\n",
      "Steps: 906 | Train Loss: 0.2227224 Vali Loss: 0.4478437 Test Loss: 0.4801006\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2234046\n",
      "\tspeed: 0.1132s/iter; left time: 706.8598s\n",
      "\titers: 200, epoch: 14 | loss: 0.2040748\n",
      "\tspeed: 0.0464s/iter; left time: 285.0256s\n",
      "\titers: 300, epoch: 14 | loss: 0.1914598\n",
      "\tspeed: 0.0462s/iter; left time: 279.0036s\n",
      "\titers: 400, epoch: 14 | loss: 0.1965951\n",
      "\tspeed: 0.0463s/iter; left time: 275.0387s\n",
      "\titers: 500, epoch: 14 | loss: 0.2237271\n",
      "\tspeed: 0.0462s/iter; left time: 270.1114s\n",
      "\titers: 600, epoch: 14 | loss: 0.1804668\n",
      "\tspeed: 0.0464s/iter; left time: 266.3801s\n",
      "\titers: 700, epoch: 14 | loss: 0.2022136\n",
      "\tspeed: 0.0462s/iter; left time: 260.4950s\n",
      "\titers: 800, epoch: 14 | loss: 0.2155167\n",
      "\tspeed: 0.0462s/iter; left time: 255.9296s\n",
      "\titers: 900, epoch: 14 | loss: 0.2577982\n",
      "\tspeed: 0.0461s/iter; left time: 250.7069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:42.48s\n",
      "Steps: 906 | Train Loss: 0.2149612 Vali Loss: 0.4583798 Test Loss: 0.4939843\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2069962\n",
      "\tspeed: 0.1101s/iter; left time: 587.6511s\n",
      "\titers: 200, epoch: 15 | loss: 0.1955848\n",
      "\tspeed: 0.0463s/iter; left time: 242.2139s\n",
      "\titers: 300, epoch: 15 | loss: 0.1993499\n",
      "\tspeed: 0.0461s/iter; left time: 237.0349s\n",
      "\titers: 400, epoch: 15 | loss: 0.2187162\n",
      "\tspeed: 0.0462s/iter; left time: 232.5884s\n",
      "\titers: 500, epoch: 15 | loss: 0.2224089\n",
      "\tspeed: 0.0462s/iter; left time: 228.0202s\n",
      "\titers: 600, epoch: 15 | loss: 0.2264391\n",
      "\tspeed: 0.0458s/iter; left time: 221.4082s\n",
      "\titers: 700, epoch: 15 | loss: 0.1959372\n",
      "\tspeed: 0.0460s/iter; left time: 218.0459s\n",
      "\titers: 800, epoch: 15 | loss: 0.2109219\n",
      "\tspeed: 0.0459s/iter; left time: 212.9665s\n",
      "\titers: 900, epoch: 15 | loss: 0.1919999\n",
      "\tspeed: 0.0459s/iter; left time: 208.2331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.99s\n",
      "Steps: 906 | Train Loss: 0.2098694 Vali Loss: 0.4438037 Test Loss: 0.4851448\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5458264946937561, rmse:0.7388007044792175, mae:0.47608011960983276, rse:0.5847140550613403\n",
      "Original data scale mse:22062046.0, rmse:4697.025390625, mae:2876.52880859375, rse:0.23354555666446686\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8083389\n",
      "\tspeed: 0.0814s/iter; left time: 1464.0891s\n",
      "\titers: 200, epoch: 1 | loss: 0.7762032\n",
      "\tspeed: 0.0514s/iter; left time: 918.9831s\n",
      "\titers: 300, epoch: 1 | loss: 0.7710360\n",
      "\tspeed: 0.0511s/iter; left time: 907.8856s\n",
      "\titers: 400, epoch: 1 | loss: 0.7354710\n",
      "\tspeed: 0.0513s/iter; left time: 906.2460s\n",
      "\titers: 500, epoch: 1 | loss: 0.7307639\n",
      "\tspeed: 0.0510s/iter; left time: 896.5941s\n",
      "\titers: 600, epoch: 1 | loss: 0.6837030\n",
      "\tspeed: 0.0507s/iter; left time: 886.7580s\n",
      "\titers: 700, epoch: 1 | loss: 0.6817888\n",
      "\tspeed: 0.0505s/iter; left time: 878.5734s\n",
      "\titers: 800, epoch: 1 | loss: 0.7013466\n",
      "\tspeed: 0.0506s/iter; left time: 874.0149s\n",
      "\titers: 900, epoch: 1 | loss: 0.6884587\n",
      "\tspeed: 0.0507s/iter; left time: 870.3009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.75s\n",
      "Steps: 904 | Train Loss: 0.7398650 Vali Loss: 0.7844293 Test Loss: 0.8870571\n",
      "Validation loss decreased (inf --> 0.784429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6448670\n",
      "\tspeed: 0.1258s/iter; left time: 2147.6330s\n",
      "\titers: 200, epoch: 2 | loss: 0.6071983\n",
      "\tspeed: 0.0505s/iter; left time: 857.3225s\n",
      "\titers: 300, epoch: 2 | loss: 0.5985939\n",
      "\tspeed: 0.0505s/iter; left time: 852.9632s\n",
      "\titers: 400, epoch: 2 | loss: 0.6202882\n",
      "\tspeed: 0.0506s/iter; left time: 849.5656s\n",
      "\titers: 500, epoch: 2 | loss: 0.5629240\n",
      "\tspeed: 0.0506s/iter; left time: 843.4742s\n",
      "\titers: 600, epoch: 2 | loss: 0.5173069\n",
      "\tspeed: 0.0506s/iter; left time: 838.1104s\n",
      "\titers: 700, epoch: 2 | loss: 0.5096536\n",
      "\tspeed: 0.0505s/iter; left time: 832.7618s\n",
      "\titers: 800, epoch: 2 | loss: 0.5183834\n",
      "\tspeed: 0.0506s/iter; left time: 828.1983s\n",
      "\titers: 900, epoch: 2 | loss: 0.5503351\n",
      "\tspeed: 0.0505s/iter; left time: 822.7909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.5715098 Vali Loss: 0.5919201 Test Loss: 0.6620699\n",
      "Validation loss decreased (0.784429 --> 0.591920).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5061057\n",
      "\tspeed: 0.1278s/iter; left time: 2066.7241s\n",
      "\titers: 200, epoch: 3 | loss: 0.4623602\n",
      "\tspeed: 0.0509s/iter; left time: 818.6128s\n",
      "\titers: 300, epoch: 3 | loss: 0.4874446\n",
      "\tspeed: 0.0506s/iter; left time: 808.7119s\n",
      "\titers: 400, epoch: 3 | loss: 0.4430297\n",
      "\tspeed: 0.0507s/iter; left time: 804.8771s\n",
      "\titers: 500, epoch: 3 | loss: 0.4522687\n",
      "\tspeed: 0.0506s/iter; left time: 797.7602s\n",
      "\titers: 600, epoch: 3 | loss: 0.4617664\n",
      "\tspeed: 0.0506s/iter; left time: 793.7326s\n",
      "\titers: 700, epoch: 3 | loss: 0.4871444\n",
      "\tspeed: 0.0507s/iter; left time: 789.0043s\n",
      "\titers: 800, epoch: 3 | loss: 0.4312721\n",
      "\tspeed: 0.0506s/iter; left time: 782.5717s\n",
      "\titers: 900, epoch: 3 | loss: 0.5109760\n",
      "\tspeed: 0.0507s/iter; left time: 779.4154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.13s\n",
      "Steps: 904 | Train Loss: 0.4682859 Vali Loss: 0.5909439 Test Loss: 0.6689174\n",
      "Validation loss decreased (0.591920 --> 0.590944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5077047\n",
      "\tspeed: 0.1272s/iter; left time: 1942.5411s\n",
      "\titers: 200, epoch: 4 | loss: 0.4546500\n",
      "\tspeed: 0.0505s/iter; left time: 766.6719s\n",
      "\titers: 300, epoch: 4 | loss: 0.4627667\n",
      "\tspeed: 0.0507s/iter; left time: 763.6814s\n",
      "\titers: 400, epoch: 4 | loss: 0.4304535\n",
      "\tspeed: 0.0506s/iter; left time: 757.5633s\n",
      "\titers: 500, epoch: 4 | loss: 0.4356422\n",
      "\tspeed: 0.0506s/iter; left time: 752.2821s\n",
      "\titers: 600, epoch: 4 | loss: 0.4391145\n",
      "\tspeed: 0.0505s/iter; left time: 746.5003s\n",
      "\titers: 700, epoch: 4 | loss: 0.4287909\n",
      "\tspeed: 0.0505s/iter; left time: 741.3487s\n",
      "\titers: 800, epoch: 4 | loss: 0.4073527\n",
      "\tspeed: 0.0506s/iter; left time: 736.4709s\n",
      "\titers: 900, epoch: 4 | loss: 0.4028690\n",
      "\tspeed: 0.0508s/iter; left time: 734.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.4294002 Vali Loss: 0.5883614 Test Loss: 0.6436937\n",
      "Validation loss decreased (0.590944 --> 0.588361).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4035151\n",
      "\tspeed: 0.1284s/iter; left time: 1844.3888s\n",
      "\titers: 200, epoch: 5 | loss: 0.3867815\n",
      "\tspeed: 0.0518s/iter; left time: 738.5643s\n",
      "\titers: 300, epoch: 5 | loss: 0.3976009\n",
      "\tspeed: 0.0514s/iter; left time: 728.6386s\n",
      "\titers: 400, epoch: 5 | loss: 0.4168909\n",
      "\tspeed: 0.0518s/iter; left time: 728.1491s\n",
      "\titers: 500, epoch: 5 | loss: 0.3427106\n",
      "\tspeed: 0.0519s/iter; left time: 724.6745s\n",
      "\titers: 600, epoch: 5 | loss: 0.4083869\n",
      "\tspeed: 0.0520s/iter; left time: 720.4522s\n",
      "\titers: 700, epoch: 5 | loss: 0.4223669\n",
      "\tspeed: 0.0514s/iter; left time: 707.9359s\n",
      "\titers: 800, epoch: 5 | loss: 0.3915015\n",
      "\tspeed: 0.0514s/iter; left time: 702.8049s\n",
      "\titers: 900, epoch: 5 | loss: 0.3739165\n",
      "\tspeed: 0.0512s/iter; left time: 693.9603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.97s\n",
      "Steps: 904 | Train Loss: 0.3977392 Vali Loss: 0.5924602 Test Loss: 0.6606631\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3515815\n",
      "\tspeed: 0.1240s/iter; left time: 1669.1223s\n",
      "\titers: 200, epoch: 6 | loss: 0.3590550\n",
      "\tspeed: 0.0506s/iter; left time: 675.4983s\n",
      "\titers: 300, epoch: 6 | loss: 0.3627992\n",
      "\tspeed: 0.0505s/iter; left time: 669.2725s\n",
      "\titers: 400, epoch: 6 | loss: 0.3884658\n",
      "\tspeed: 0.0505s/iter; left time: 664.7379s\n",
      "\titers: 500, epoch: 6 | loss: 0.3807147\n",
      "\tspeed: 0.0505s/iter; left time: 659.8549s\n",
      "\titers: 600, epoch: 6 | loss: 0.3394528\n",
      "\tspeed: 0.0504s/iter; left time: 653.4809s\n",
      "\titers: 700, epoch: 6 | loss: 0.3374536\n",
      "\tspeed: 0.0504s/iter; left time: 648.6301s\n",
      "\titers: 800, epoch: 6 | loss: 0.3611831\n",
      "\tspeed: 0.0504s/iter; left time: 643.5342s\n",
      "\titers: 900, epoch: 6 | loss: 0.3592309\n",
      "\tspeed: 0.0505s/iter; left time: 639.6910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.3710448 Vali Loss: 0.5886969 Test Loss: 0.6598161\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3420539\n",
      "\tspeed: 0.1118s/iter; left time: 1403.8026s\n",
      "\titers: 200, epoch: 7 | loss: 0.3555740\n",
      "\tspeed: 0.0391s/iter; left time: 486.7777s\n",
      "\titers: 300, epoch: 7 | loss: 0.3519598\n",
      "\tspeed: 0.0391s/iter; left time: 483.2095s\n",
      "\titers: 400, epoch: 7 | loss: 0.3552835\n",
      "\tspeed: 0.0391s/iter; left time: 479.0892s\n",
      "\titers: 500, epoch: 7 | loss: 0.3309539\n",
      "\tspeed: 0.0391s/iter; left time: 474.9370s\n",
      "\titers: 600, epoch: 7 | loss: 0.3498957\n",
      "\tspeed: 0.0391s/iter; left time: 471.1366s\n",
      "\titers: 700, epoch: 7 | loss: 0.3530918\n",
      "\tspeed: 0.0391s/iter; left time: 467.3169s\n",
      "\titers: 800, epoch: 7 | loss: 0.3501790\n",
      "\tspeed: 0.0391s/iter; left time: 463.6383s\n",
      "\titers: 900, epoch: 7 | loss: 0.3461764\n",
      "\tspeed: 0.0391s/iter; left time: 459.3710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.59s\n",
      "Steps: 904 | Train Loss: 0.3486189 Vali Loss: 0.6054208 Test Loss: 0.6860948\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3216172\n",
      "\tspeed: 0.1233s/iter; left time: 1436.8843s\n",
      "\titers: 200, epoch: 8 | loss: 0.3182230\n",
      "\tspeed: 0.0514s/iter; left time: 593.2916s\n",
      "\titers: 300, epoch: 8 | loss: 0.3361388\n",
      "\tspeed: 0.0508s/iter; left time: 581.4861s\n",
      "\titers: 400, epoch: 8 | loss: 0.3264883\n",
      "\tspeed: 0.0506s/iter; left time: 574.9484s\n",
      "\titers: 500, epoch: 8 | loss: 0.3454481\n",
      "\tspeed: 0.0505s/iter; left time: 568.7132s\n",
      "\titers: 600, epoch: 8 | loss: 0.3418908\n",
      "\tspeed: 0.0509s/iter; left time: 567.2378s\n",
      "\titers: 700, epoch: 8 | loss: 0.3396862\n",
      "\tspeed: 0.0510s/iter; left time: 563.2572s\n",
      "\titers: 800, epoch: 8 | loss: 0.3051411\n",
      "\tspeed: 0.0507s/iter; left time: 555.5349s\n",
      "\titers: 900, epoch: 8 | loss: 0.3242508\n",
      "\tspeed: 0.0509s/iter; left time: 552.5627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.29s\n",
      "Steps: 904 | Train Loss: 0.3291857 Vali Loss: 0.5961954 Test Loss: 0.6698303\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3323874\n",
      "\tspeed: 0.1242s/iter; left time: 1334.9396s\n",
      "\titers: 200, epoch: 9 | loss: 0.3205502\n",
      "\tspeed: 0.0506s/iter; left time: 538.9896s\n",
      "\titers: 300, epoch: 9 | loss: 0.3077804\n",
      "\tspeed: 0.0506s/iter; left time: 533.7169s\n",
      "\titers: 400, epoch: 9 | loss: 0.3230237\n",
      "\tspeed: 0.0505s/iter; left time: 527.7588s\n",
      "\titers: 500, epoch: 9 | loss: 0.2938048\n",
      "\tspeed: 0.0505s/iter; left time: 522.9072s\n",
      "\titers: 600, epoch: 9 | loss: 0.3315416\n",
      "\tspeed: 0.0505s/iter; left time: 517.9774s\n",
      "\titers: 700, epoch: 9 | loss: 0.3092000\n",
      "\tspeed: 0.0506s/iter; left time: 513.5171s\n",
      "\titers: 800, epoch: 9 | loss: 0.2952563\n",
      "\tspeed: 0.0505s/iter; left time: 507.6393s\n",
      "\titers: 900, epoch: 9 | loss: 0.3070341\n",
      "\tspeed: 0.0506s/iter; left time: 503.7826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.99s\n",
      "Steps: 904 | Train Loss: 0.3129122 Vali Loss: 0.6064560 Test Loss: 0.6798185\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9010437726974487, rmse:0.9492332339286804, mae:0.6440913081169128, rse:0.7528589963912964\n",
      "Original data scale mse:37380548.0, rmse:6113.96337890625, mae:3884.0576171875, rse:0.3044775724411011\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8107427\n",
      "\tspeed: 0.0544s/iter; left time: 979.0645s\n",
      "\titers: 200, epoch: 1 | loss: 0.7104257\n",
      "\tspeed: 0.0506s/iter; left time: 904.6200s\n",
      "\titers: 300, epoch: 1 | loss: 0.7939939\n",
      "\tspeed: 0.0514s/iter; left time: 914.4122s\n",
      "\titers: 400, epoch: 1 | loss: 0.7371382\n",
      "\tspeed: 0.0514s/iter; left time: 907.9328s\n",
      "\titers: 500, epoch: 1 | loss: 0.7476736\n",
      "\tspeed: 0.0513s/iter; left time: 902.7182s\n",
      "\titers: 600, epoch: 1 | loss: 0.6738091\n",
      "\tspeed: 0.0509s/iter; left time: 889.4264s\n",
      "\titers: 700, epoch: 1 | loss: 0.7436720\n",
      "\tspeed: 0.0514s/iter; left time: 894.2352s\n",
      "\titers: 800, epoch: 1 | loss: 0.7125391\n",
      "\tspeed: 0.0512s/iter; left time: 884.3106s\n",
      "\titers: 900, epoch: 1 | loss: 0.7167732\n",
      "\tspeed: 0.0510s/iter; left time: 875.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.63s\n",
      "Steps: 904 | Train Loss: 0.7386421 Vali Loss: 0.7821450 Test Loss: 0.8881980\n",
      "Validation loss decreased (inf --> 0.782145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6382442\n",
      "\tspeed: 0.1268s/iter; left time: 2164.8341s\n",
      "\titers: 200, epoch: 2 | loss: 0.5628038\n",
      "\tspeed: 0.0505s/iter; left time: 857.4181s\n",
      "\titers: 300, epoch: 2 | loss: 0.6191453\n",
      "\tspeed: 0.0505s/iter; left time: 852.1261s\n",
      "\titers: 400, epoch: 2 | loss: 0.5944245\n",
      "\tspeed: 0.0505s/iter; left time: 847.4058s\n",
      "\titers: 500, epoch: 2 | loss: 0.5634186\n",
      "\tspeed: 0.0506s/iter; left time: 844.0713s\n",
      "\titers: 600, epoch: 2 | loss: 0.6088452\n",
      "\tspeed: 0.0506s/iter; left time: 838.7521s\n",
      "\titers: 700, epoch: 2 | loss: 0.6043390\n",
      "\tspeed: 0.0505s/iter; left time: 832.7680s\n",
      "\titers: 800, epoch: 2 | loss: 0.4830890\n",
      "\tspeed: 0.0505s/iter; left time: 826.4973s\n",
      "\titers: 900, epoch: 2 | loss: 0.5283688\n",
      "\tspeed: 0.0505s/iter; left time: 821.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.5764273 Vali Loss: 0.6016672 Test Loss: 0.6713770\n",
      "Validation loss decreased (0.782145 --> 0.601667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4889890\n",
      "\tspeed: 0.1284s/iter; left time: 2076.7342s\n",
      "\titers: 200, epoch: 3 | loss: 0.4493022\n",
      "\tspeed: 0.0505s/iter; left time: 811.8577s\n",
      "\titers: 300, epoch: 3 | loss: 0.4923941\n",
      "\tspeed: 0.0505s/iter; left time: 806.7414s\n",
      "\titers: 400, epoch: 3 | loss: 0.4741258\n",
      "\tspeed: 0.0504s/iter; left time: 800.3186s\n",
      "\titers: 500, epoch: 3 | loss: 0.4118632\n",
      "\tspeed: 0.0506s/iter; left time: 797.6694s\n",
      "\titers: 600, epoch: 3 | loss: 0.4616055\n",
      "\tspeed: 0.0506s/iter; left time: 793.3434s\n",
      "\titers: 700, epoch: 3 | loss: 0.5104001\n",
      "\tspeed: 0.0506s/iter; left time: 787.5033s\n",
      "\titers: 800, epoch: 3 | loss: 0.4490139\n",
      "\tspeed: 0.0506s/iter; left time: 782.3524s\n",
      "\titers: 900, epoch: 3 | loss: 0.4402315\n",
      "\tspeed: 0.0506s/iter; left time: 777.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.4685280 Vali Loss: 0.5965286 Test Loss: 0.6537550\n",
      "Validation loss decreased (0.601667 --> 0.596529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4171317\n",
      "\tspeed: 0.1276s/iter; left time: 1947.5875s\n",
      "\titers: 200, epoch: 4 | loss: 0.4321315\n",
      "\tspeed: 0.0505s/iter; left time: 766.6810s\n",
      "\titers: 300, epoch: 4 | loss: 0.4444336\n",
      "\tspeed: 0.0506s/iter; left time: 763.0630s\n",
      "\titers: 400, epoch: 4 | loss: 0.4156060\n",
      "\tspeed: 0.0504s/iter; left time: 754.5255s\n",
      "\titers: 500, epoch: 4 | loss: 0.4270163\n",
      "\tspeed: 0.0505s/iter; left time: 750.8958s\n",
      "\titers: 600, epoch: 4 | loss: 0.4017754\n",
      "\tspeed: 0.0512s/iter; left time: 756.3208s\n",
      "\titers: 700, epoch: 4 | loss: 0.4091924\n",
      "\tspeed: 0.0518s/iter; left time: 759.5338s\n",
      "\titers: 800, epoch: 4 | loss: 0.3736674\n",
      "\tspeed: 0.0518s/iter; left time: 754.0197s\n",
      "\titers: 900, epoch: 4 | loss: 0.4383425\n",
      "\tspeed: 0.0515s/iter; left time: 744.6566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.47s\n",
      "Steps: 904 | Train Loss: 0.4264898 Vali Loss: 0.5863400 Test Loss: 0.6746189\n",
      "Validation loss decreased (0.596529 --> 0.586340).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4380546\n",
      "\tspeed: 0.1283s/iter; left time: 1843.7311s\n",
      "\titers: 200, epoch: 5 | loss: 0.3786272\n",
      "\tspeed: 0.0507s/iter; left time: 722.9651s\n",
      "\titers: 300, epoch: 5 | loss: 0.3845729\n",
      "\tspeed: 0.0506s/iter; left time: 716.7786s\n",
      "\titers: 400, epoch: 5 | loss: 0.3903257\n",
      "\tspeed: 0.0505s/iter; left time: 710.7151s\n",
      "\titers: 500, epoch: 5 | loss: 0.4108859\n",
      "\tspeed: 0.0505s/iter; left time: 705.5865s\n",
      "\titers: 600, epoch: 5 | loss: 0.3920711\n",
      "\tspeed: 0.0507s/iter; left time: 702.3394s\n",
      "\titers: 700, epoch: 5 | loss: 0.3872411\n",
      "\tspeed: 0.0506s/iter; left time: 695.9606s\n",
      "\titers: 800, epoch: 5 | loss: 0.3835167\n",
      "\tspeed: 0.0505s/iter; left time: 690.5308s\n",
      "\titers: 900, epoch: 5 | loss: 0.4056975\n",
      "\tspeed: 0.0505s/iter; left time: 685.5617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.3938155 Vali Loss: 0.5748616 Test Loss: 0.6778134\n",
      "Validation loss decreased (0.586340 --> 0.574862).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3808792\n",
      "\tspeed: 0.1277s/iter; left time: 1719.6359s\n",
      "\titers: 200, epoch: 6 | loss: 0.3757925\n",
      "\tspeed: 0.0507s/iter; left time: 676.9002s\n",
      "\titers: 300, epoch: 6 | loss: 0.3708539\n",
      "\tspeed: 0.0504s/iter; left time: 668.9631s\n",
      "\titers: 400, epoch: 6 | loss: 0.3627008\n",
      "\tspeed: 0.0506s/iter; left time: 665.3832s\n",
      "\titers: 500, epoch: 6 | loss: 0.3402184\n",
      "\tspeed: 0.0506s/iter; left time: 661.2765s\n",
      "\titers: 600, epoch: 6 | loss: 0.3686820\n",
      "\tspeed: 0.0505s/iter; left time: 654.9425s\n",
      "\titers: 700, epoch: 6 | loss: 0.3519151\n",
      "\tspeed: 0.0506s/iter; left time: 650.7615s\n",
      "\titers: 800, epoch: 6 | loss: 0.3548285\n",
      "\tspeed: 0.0505s/iter; left time: 644.6761s\n",
      "\titers: 900, epoch: 6 | loss: 0.3850189\n",
      "\tspeed: 0.0505s/iter; left time: 639.8082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.07s\n",
      "Steps: 904 | Train Loss: 0.3677132 Vali Loss: 0.5947747 Test Loss: 0.6886828\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3463676\n",
      "\tspeed: 0.1245s/iter; left time: 1563.2075s\n",
      "\titers: 200, epoch: 7 | loss: 0.3400016\n",
      "\tspeed: 0.0506s/iter; left time: 629.9380s\n",
      "\titers: 300, epoch: 7 | loss: 0.3575536\n",
      "\tspeed: 0.0506s/iter; left time: 625.5046s\n",
      "\titers: 400, epoch: 7 | loss: 0.4025400\n",
      "\tspeed: 0.0506s/iter; left time: 620.6450s\n",
      "\titers: 500, epoch: 7 | loss: 0.3394673\n",
      "\tspeed: 0.0506s/iter; left time: 615.1142s\n",
      "\titers: 600, epoch: 7 | loss: 0.3409742\n",
      "\tspeed: 0.0505s/iter; left time: 609.3671s\n",
      "\titers: 700, epoch: 7 | loss: 0.3138832\n",
      "\tspeed: 0.0505s/iter; left time: 604.1610s\n",
      "\titers: 800, epoch: 7 | loss: 0.3443280\n",
      "\tspeed: 0.0506s/iter; left time: 600.4805s\n",
      "\titers: 900, epoch: 7 | loss: 0.3238070\n",
      "\tspeed: 0.0505s/iter; left time: 593.9279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 904 | Train Loss: 0.3443287 Vali Loss: 0.5946581 Test Loss: 0.6816165\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3201239\n",
      "\tspeed: 0.1246s/iter; left time: 1452.1387s\n",
      "\titers: 200, epoch: 8 | loss: 0.3326735\n",
      "\tspeed: 0.0506s/iter; left time: 584.0414s\n",
      "\titers: 300, epoch: 8 | loss: 0.3073162\n",
      "\tspeed: 0.0506s/iter; left time: 579.0812s\n",
      "\titers: 400, epoch: 8 | loss: 0.2982529\n",
      "\tspeed: 0.0506s/iter; left time: 574.4191s\n",
      "\titers: 500, epoch: 8 | loss: 0.3410628\n",
      "\tspeed: 0.0506s/iter; left time: 568.9437s\n",
      "\titers: 600, epoch: 8 | loss: 0.3355615\n",
      "\tspeed: 0.0505s/iter; left time: 563.4639s\n",
      "\titers: 700, epoch: 8 | loss: 0.3237234\n",
      "\tspeed: 0.0505s/iter; left time: 558.2798s\n",
      "\titers: 800, epoch: 8 | loss: 0.3035448\n",
      "\tspeed: 0.0505s/iter; left time: 553.2820s\n",
      "\titers: 900, epoch: 8 | loss: 0.2986849\n",
      "\tspeed: 0.0505s/iter; left time: 548.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.3244647 Vali Loss: 0.6039708 Test Loss: 0.7007060\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3092264\n",
      "\tspeed: 0.1246s/iter; left time: 1339.7507s\n",
      "\titers: 200, epoch: 9 | loss: 0.3259971\n",
      "\tspeed: 0.0505s/iter; left time: 537.2659s\n",
      "\titers: 300, epoch: 9 | loss: 0.3080572\n",
      "\tspeed: 0.0505s/iter; left time: 532.6116s\n",
      "\titers: 400, epoch: 9 | loss: 0.3010917\n",
      "\tspeed: 0.0505s/iter; left time: 528.0011s\n",
      "\titers: 500, epoch: 9 | loss: 0.3011563\n",
      "\tspeed: 0.0505s/iter; left time: 522.9476s\n",
      "\titers: 600, epoch: 9 | loss: 0.3149443\n",
      "\tspeed: 0.0505s/iter; left time: 517.6138s\n",
      "\titers: 700, epoch: 9 | loss: 0.2977964\n",
      "\tspeed: 0.0507s/iter; left time: 514.0877s\n",
      "\titers: 800, epoch: 9 | loss: 0.2991881\n",
      "\tspeed: 0.0505s/iter; left time: 507.7223s\n",
      "\titers: 900, epoch: 9 | loss: 0.2938460\n",
      "\tspeed: 0.0505s/iter; left time: 502.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.96s\n",
      "Steps: 904 | Train Loss: 0.3074869 Vali Loss: 0.6058674 Test Loss: 0.7088839\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2844678\n",
      "\tspeed: 0.1247s/iter; left time: 1227.9536s\n",
      "\titers: 200, epoch: 10 | loss: 0.2967182\n",
      "\tspeed: 0.0505s/iter; left time: 491.9046s\n",
      "\titers: 300, epoch: 10 | loss: 0.2989474\n",
      "\tspeed: 0.0505s/iter; left time: 487.2493s\n",
      "\titers: 400, epoch: 10 | loss: 0.2930623\n",
      "\tspeed: 0.0504s/iter; left time: 480.7629s\n",
      "\titers: 500, epoch: 10 | loss: 0.3129691\n",
      "\tspeed: 0.0505s/iter; left time: 476.9375s\n",
      "\titers: 600, epoch: 10 | loss: 0.2832736\n",
      "\tspeed: 0.0505s/iter; left time: 471.9706s\n",
      "\titers: 700, epoch: 10 | loss: 0.2915496\n",
      "\tspeed: 0.0505s/iter; left time: 467.3284s\n",
      "\titers: 800, epoch: 10 | loss: 0.2873734\n",
      "\tspeed: 0.0505s/iter; left time: 461.9647s\n",
      "\titers: 900, epoch: 10 | loss: 0.3021165\n",
      "\tspeed: 0.0506s/iter; left time: 458.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.2928202 Vali Loss: 0.6086782 Test Loss: 0.7061489\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0009963512420654, rmse:1.0004980564117432, mae:0.6779704689979553, rse:0.7935182452201843\n",
      "Original data scale mse:42881912.0, rmse:6548.42822265625, mae:4106.74853515625, rse:0.32611405849456787\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7542604\n",
      "\tspeed: 0.0845s/iter; left time: 1515.2761s\n",
      "\titers: 200, epoch: 1 | loss: 0.8099632\n",
      "\tspeed: 0.0541s/iter; left time: 964.5054s\n",
      "\titers: 300, epoch: 1 | loss: 0.7450835\n",
      "\tspeed: 0.0548s/iter; left time: 972.2909s\n",
      "\titers: 400, epoch: 1 | loss: 0.7453328\n",
      "\tspeed: 0.0545s/iter; left time: 961.3568s\n",
      "\titers: 500, epoch: 1 | loss: 0.7258010\n",
      "\tspeed: 0.0517s/iter; left time: 907.5427s\n",
      "\titers: 600, epoch: 1 | loss: 0.7584674\n",
      "\tspeed: 0.0515s/iter; left time: 897.5123s\n",
      "\titers: 700, epoch: 1 | loss: 0.7225047\n",
      "\tspeed: 0.0513s/iter; left time: 889.4918s\n",
      "\titers: 800, epoch: 1 | loss: 0.6947637\n",
      "\tspeed: 0.0517s/iter; left time: 890.6749s\n",
      "\titers: 900, epoch: 1 | loss: 0.7315311\n",
      "\tspeed: 0.0518s/iter; left time: 888.2868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.7491452 Vali Loss: 0.7987818 Test Loss: 0.9089959\n",
      "Validation loss decreased (inf --> 0.798782).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7151219\n",
      "\tspeed: 0.1500s/iter; left time: 2556.4074s\n",
      "\titers: 200, epoch: 2 | loss: 0.6309003\n",
      "\tspeed: 0.0577s/iter; left time: 977.8299s\n",
      "\titers: 300, epoch: 2 | loss: 0.6691379\n",
      "\tspeed: 0.0601s/iter; left time: 1012.8041s\n",
      "\titers: 400, epoch: 2 | loss: 0.6681862\n",
      "\tspeed: 0.0586s/iter; left time: 981.6425s\n",
      "\titers: 500, epoch: 2 | loss: 0.5925270\n",
      "\tspeed: 0.0583s/iter; left time: 969.7900s\n",
      "\titers: 600, epoch: 2 | loss: 0.5656459\n",
      "\tspeed: 0.0593s/iter; left time: 981.3002s\n",
      "\titers: 700, epoch: 2 | loss: 0.5531321\n",
      "\tspeed: 0.0596s/iter; left time: 979.1281s\n",
      "\titers: 800, epoch: 2 | loss: 0.5738384\n",
      "\tspeed: 0.0589s/iter; left time: 962.9955s\n",
      "\titers: 900, epoch: 2 | loss: 0.5239612\n",
      "\tspeed: 0.0567s/iter; left time: 920.4348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:53.25s\n",
      "Steps: 902 | Train Loss: 0.6308303 Vali Loss: 0.6581421 Test Loss: 0.7211633\n",
      "Validation loss decreased (0.798782 --> 0.658142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5373316\n",
      "\tspeed: 0.1494s/iter; left time: 2410.2467s\n",
      "\titers: 200, epoch: 3 | loss: 0.5101069\n",
      "\tspeed: 0.0567s/iter; left time: 908.9031s\n",
      "\titers: 300, epoch: 3 | loss: 0.5119216\n",
      "\tspeed: 0.0568s/iter; left time: 905.0880s\n",
      "\titers: 400, epoch: 3 | loss: 0.5264343\n",
      "\tspeed: 0.0571s/iter; left time: 904.0070s\n",
      "\titers: 500, epoch: 3 | loss: 0.5060073\n",
      "\tspeed: 0.0575s/iter; left time: 905.0786s\n",
      "\titers: 600, epoch: 3 | loss: 0.4974110\n",
      "\tspeed: 0.0573s/iter; left time: 895.7671s\n",
      "\titers: 700, epoch: 3 | loss: 0.4670866\n",
      "\tspeed: 0.0572s/iter; left time: 889.4771s\n",
      "\titers: 800, epoch: 3 | loss: 0.4862985\n",
      "\tspeed: 0.0579s/iter; left time: 893.3658s\n",
      "\titers: 900, epoch: 3 | loss: 0.4794837\n",
      "\tspeed: 0.0568s/iter; left time: 871.7890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.90s\n",
      "Steps: 902 | Train Loss: 0.5033834 Vali Loss: 0.6109629 Test Loss: 0.7097297\n",
      "Validation loss decreased (0.658142 --> 0.610963).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4931632\n",
      "\tspeed: 0.1478s/iter; left time: 2251.1934s\n",
      "\titers: 200, epoch: 4 | loss: 0.4330042\n",
      "\tspeed: 0.0571s/iter; left time: 864.4825s\n",
      "\titers: 300, epoch: 4 | loss: 0.4217555\n",
      "\tspeed: 0.0566s/iter; left time: 851.6794s\n",
      "\titers: 400, epoch: 4 | loss: 0.4518916\n",
      "\tspeed: 0.0570s/iter; left time: 850.7419s\n",
      "\titers: 500, epoch: 4 | loss: 0.4188436\n",
      "\tspeed: 0.0570s/iter; left time: 845.2609s\n",
      "\titers: 600, epoch: 4 | loss: 0.4538426\n",
      "\tspeed: 0.0569s/iter; left time: 838.4006s\n",
      "\titers: 700, epoch: 4 | loss: 0.4245886\n",
      "\tspeed: 0.0568s/iter; left time: 831.9787s\n",
      "\titers: 800, epoch: 4 | loss: 0.4392833\n",
      "\tspeed: 0.0568s/iter; left time: 825.5324s\n",
      "\titers: 900, epoch: 4 | loss: 0.4206003\n",
      "\tspeed: 0.0573s/iter; left time: 827.6597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:51.77s\n",
      "Steps: 902 | Train Loss: 0.4504049 Vali Loss: 0.6429544 Test Loss: 0.6921412\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3927313\n",
      "\tspeed: 0.1404s/iter; left time: 2012.3591s\n",
      "\titers: 200, epoch: 5 | loss: 0.4230795\n",
      "\tspeed: 0.0557s/iter; left time: 792.6263s\n",
      "\titers: 300, epoch: 5 | loss: 0.4259765\n",
      "\tspeed: 0.0569s/iter; left time: 803.6563s\n",
      "\titers: 400, epoch: 5 | loss: 0.4164893\n",
      "\tspeed: 0.0588s/iter; left time: 825.2649s\n",
      "\titers: 500, epoch: 5 | loss: 0.3959365\n",
      "\tspeed: 0.0572s/iter; left time: 796.3772s\n",
      "\titers: 600, epoch: 5 | loss: 0.3893040\n",
      "\tspeed: 0.0573s/iter; left time: 792.7911s\n",
      "\titers: 700, epoch: 5 | loss: 0.3820198\n",
      "\tspeed: 0.0574s/iter; left time: 788.6656s\n",
      "\titers: 800, epoch: 5 | loss: 0.4239312\n",
      "\tspeed: 0.0576s/iter; left time: 785.6474s\n",
      "\titers: 900, epoch: 5 | loss: 0.4105830\n",
      "\tspeed: 0.0579s/iter; left time: 782.9538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.70s\n",
      "Steps: 902 | Train Loss: 0.4145141 Vali Loss: 0.6323253 Test Loss: 0.6984363\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4068128\n",
      "\tspeed: 0.1434s/iter; left time: 1925.5229s\n",
      "\titers: 200, epoch: 6 | loss: 0.4144781\n",
      "\tspeed: 0.0525s/iter; left time: 700.2625s\n",
      "\titers: 300, epoch: 6 | loss: 0.3922909\n",
      "\tspeed: 0.0556s/iter; left time: 735.2838s\n",
      "\titers: 400, epoch: 6 | loss: 0.4189376\n",
      "\tspeed: 0.0577s/iter; left time: 757.4811s\n",
      "\titers: 500, epoch: 6 | loss: 0.4263025\n",
      "\tspeed: 0.0570s/iter; left time: 743.2547s\n",
      "\titers: 600, epoch: 6 | loss: 0.3839116\n",
      "\tspeed: 0.0574s/iter; left time: 741.7811s\n",
      "\titers: 700, epoch: 6 | loss: 0.3470266\n",
      "\tspeed: 0.0571s/iter; left time: 732.3400s\n",
      "\titers: 800, epoch: 6 | loss: 0.3833730\n",
      "\tspeed: 0.0574s/iter; left time: 730.4373s\n",
      "\titers: 900, epoch: 6 | loss: 0.3837367\n",
      "\tspeed: 0.0567s/iter; left time: 716.4651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:51.09s\n",
      "Steps: 902 | Train Loss: 0.3861443 Vali Loss: 0.6383668 Test Loss: 0.7027848\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3687515\n",
      "\tspeed: 0.1447s/iter; left time: 1813.0817s\n",
      "\titers: 200, epoch: 7 | loss: 0.3478732\n",
      "\tspeed: 0.0575s/iter; left time: 714.4247s\n",
      "\titers: 300, epoch: 7 | loss: 0.3721578\n",
      "\tspeed: 0.0568s/iter; left time: 700.0008s\n",
      "\titers: 400, epoch: 7 | loss: 0.3521626\n",
      "\tspeed: 0.0571s/iter; left time: 698.1674s\n",
      "\titers: 500, epoch: 7 | loss: 0.3737085\n",
      "\tspeed: 0.0570s/iter; left time: 690.7701s\n",
      "\titers: 600, epoch: 7 | loss: 0.3399463\n",
      "\tspeed: 0.0572s/iter; left time: 688.0472s\n",
      "\titers: 700, epoch: 7 | loss: 0.3613079\n",
      "\tspeed: 0.0573s/iter; left time: 683.9609s\n",
      "\titers: 800, epoch: 7 | loss: 0.3696672\n",
      "\tspeed: 0.0576s/iter; left time: 680.8256s\n",
      "\titers: 900, epoch: 7 | loss: 0.3796199\n",
      "\tspeed: 0.0569s/iter; left time: 667.4585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:51.95s\n",
      "Steps: 902 | Train Loss: 0.3609722 Vali Loss: 0.6373274 Test Loss: 0.7003163\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3441382\n",
      "\tspeed: 0.1444s/iter; left time: 1678.9325s\n",
      "\titers: 200, epoch: 8 | loss: 0.3604532\n",
      "\tspeed: 0.0575s/iter; left time: 662.9700s\n",
      "\titers: 300, epoch: 8 | loss: 0.3547716\n",
      "\tspeed: 0.0573s/iter; left time: 655.2529s\n",
      "\titers: 400, epoch: 8 | loss: 0.3323881\n",
      "\tspeed: 0.0577s/iter; left time: 653.7508s\n",
      "\titers: 500, epoch: 8 | loss: 0.3493576\n",
      "\tspeed: 0.0589s/iter; left time: 661.1666s\n",
      "\titers: 600, epoch: 8 | loss: 0.3295687\n",
      "\tspeed: 0.0579s/iter; left time: 644.6940s\n",
      "\titers: 700, epoch: 8 | loss: 0.3348298\n",
      "\tspeed: 0.0589s/iter; left time: 649.5816s\n",
      "\titers: 800, epoch: 8 | loss: 0.3224255\n",
      "\tspeed: 0.0602s/iter; left time: 657.5579s\n",
      "\titers: 900, epoch: 8 | loss: 0.3111054\n",
      "\tspeed: 0.0584s/iter; left time: 632.2807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.85s\n",
      "Steps: 902 | Train Loss: 0.3402787 Vali Loss: 0.6429237 Test Loss: 0.7192777\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9855568408966064, rmse:0.9927521347999573, mae:0.709299623966217, rse:0.7864354848861694\n",
      "Original data scale mse:43904392.0, rmse:6626.0390625, mae:4388.93603515625, rse:0.3301410675048828\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7547288\n",
      "\tspeed: 0.0570s/iter; left time: 1021.9853s\n",
      "\titers: 200, epoch: 1 | loss: 0.7843223\n",
      "\tspeed: 0.0527s/iter; left time: 939.9867s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319835\n",
      "\tspeed: 0.0520s/iter; left time: 922.8425s\n",
      "\titers: 400, epoch: 1 | loss: 0.7372767\n",
      "\tspeed: 0.0528s/iter; left time: 932.1789s\n",
      "\titers: 500, epoch: 1 | loss: 0.7149239\n",
      "\tspeed: 0.0575s/iter; left time: 1007.7394s\n",
      "\titers: 600, epoch: 1 | loss: 0.7230899\n",
      "\tspeed: 0.0569s/iter; left time: 992.2192s\n",
      "\titers: 700, epoch: 1 | loss: 0.7227523\n",
      "\tspeed: 0.0597s/iter; left time: 1035.9077s\n",
      "\titers: 800, epoch: 1 | loss: 0.7226050\n",
      "\tspeed: 0.0585s/iter; left time: 1009.0898s\n",
      "\titers: 900, epoch: 1 | loss: 0.7184904\n",
      "\tspeed: 0.0602s/iter; left time: 1032.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.95s\n",
      "Steps: 902 | Train Loss: 0.7441726 Vali Loss: 0.7939668 Test Loss: 0.9019395\n",
      "Validation loss decreased (inf --> 0.793967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6438110\n",
      "\tspeed: 0.1531s/iter; left time: 2608.5977s\n",
      "\titers: 200, epoch: 2 | loss: 0.6883102\n",
      "\tspeed: 0.0574s/iter; left time: 972.6572s\n",
      "\titers: 300, epoch: 2 | loss: 0.6108803\n",
      "\tspeed: 0.0599s/iter; left time: 1008.9702s\n",
      "\titers: 400, epoch: 2 | loss: 0.6653609\n",
      "\tspeed: 0.0576s/iter; left time: 964.1950s\n",
      "\titers: 500, epoch: 2 | loss: 0.6344115\n",
      "\tspeed: 0.0574s/iter; left time: 954.6057s\n",
      "\titers: 600, epoch: 2 | loss: 0.6105129\n",
      "\tspeed: 0.0582s/iter; left time: 962.8625s\n",
      "\titers: 700, epoch: 2 | loss: 0.6666594\n",
      "\tspeed: 0.0602s/iter; left time: 989.2814s\n",
      "\titers: 800, epoch: 2 | loss: 0.5665607\n",
      "\tspeed: 0.0592s/iter; left time: 967.6589s\n",
      "\titers: 900, epoch: 2 | loss: 0.5825232\n",
      "\tspeed: 0.0578s/iter; left time: 938.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:53.02s\n",
      "Steps: 902 | Train Loss: 0.6258646 Vali Loss: 0.6618105 Test Loss: 0.7169125\n",
      "Validation loss decreased (0.793967 --> 0.661811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5025635\n",
      "\tspeed: 0.1486s/iter; left time: 2398.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.5309112\n",
      "\tspeed: 0.0586s/iter; left time: 940.2842s\n",
      "\titers: 300, epoch: 3 | loss: 0.4864776\n",
      "\tspeed: 0.0572s/iter; left time: 910.9777s\n",
      "\titers: 400, epoch: 3 | loss: 0.5012859\n",
      "\tspeed: 0.0577s/iter; left time: 913.6291s\n",
      "\titers: 500, epoch: 3 | loss: 0.4956519\n",
      "\tspeed: 0.0604s/iter; left time: 950.6147s\n",
      "\titers: 600, epoch: 3 | loss: 0.4785950\n",
      "\tspeed: 0.0619s/iter; left time: 967.2026s\n",
      "\titers: 700, epoch: 3 | loss: 0.5214430\n",
      "\tspeed: 0.0611s/iter; left time: 949.7001s\n",
      "\titers: 800, epoch: 3 | loss: 0.4975451\n",
      "\tspeed: 0.0582s/iter; left time: 898.9549s\n",
      "\titers: 900, epoch: 3 | loss: 0.4950312\n",
      "\tspeed: 0.0578s/iter; left time: 886.0429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.68s\n",
      "Steps: 902 | Train Loss: 0.5029869 Vali Loss: 0.6305442 Test Loss: 0.7116168\n",
      "Validation loss decreased (0.661811 --> 0.630544).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4719218\n",
      "\tspeed: 0.1481s/iter; left time: 2256.0046s\n",
      "\titers: 200, epoch: 4 | loss: 0.4557660\n",
      "\tspeed: 0.0575s/iter; left time: 870.9760s\n",
      "\titers: 300, epoch: 4 | loss: 0.4393392\n",
      "\tspeed: 0.0597s/iter; left time: 898.1886s\n",
      "\titers: 400, epoch: 4 | loss: 0.4325653\n",
      "\tspeed: 0.0588s/iter; left time: 877.7165s\n",
      "\titers: 500, epoch: 4 | loss: 0.4576900\n",
      "\tspeed: 0.0577s/iter; left time: 855.6239s\n",
      "\titers: 600, epoch: 4 | loss: 0.4421293\n",
      "\tspeed: 0.0571s/iter; left time: 841.8002s\n",
      "\titers: 700, epoch: 4 | loss: 0.4626732\n",
      "\tspeed: 0.0574s/iter; left time: 840.5507s\n",
      "\titers: 800, epoch: 4 | loss: 0.4210347\n",
      "\tspeed: 0.0593s/iter; left time: 861.2282s\n",
      "\titers: 900, epoch: 4 | loss: 0.4233600\n",
      "\tspeed: 0.0590s/iter; left time: 851.9908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.84s\n",
      "Steps: 902 | Train Loss: 0.4496966 Vali Loss: 0.6173054 Test Loss: 0.7038510\n",
      "Validation loss decreased (0.630544 --> 0.617305).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4077258\n",
      "\tspeed: 0.1506s/iter; left time: 2158.1170s\n",
      "\titers: 200, epoch: 5 | loss: 0.4132836\n",
      "\tspeed: 0.0567s/iter; left time: 806.4309s\n",
      "\titers: 300, epoch: 5 | loss: 0.4357475\n",
      "\tspeed: 0.0569s/iter; left time: 804.1370s\n",
      "\titers: 400, epoch: 5 | loss: 0.4270459\n",
      "\tspeed: 0.0569s/iter; left time: 797.8092s\n",
      "\titers: 500, epoch: 5 | loss: 0.4093657\n",
      "\tspeed: 0.0572s/iter; left time: 796.3897s\n",
      "\titers: 600, epoch: 5 | loss: 0.4180741\n",
      "\tspeed: 0.0575s/iter; left time: 795.2361s\n",
      "\titers: 700, epoch: 5 | loss: 0.4304321\n",
      "\tspeed: 0.0572s/iter; left time: 784.9649s\n",
      "\titers: 800, epoch: 5 | loss: 0.4058852\n",
      "\tspeed: 0.0580s/iter; left time: 790.5436s\n",
      "\titers: 900, epoch: 5 | loss: 0.3912589\n",
      "\tspeed: 0.0576s/iter; left time: 778.9064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.96s\n",
      "Steps: 902 | Train Loss: 0.4109815 Vali Loss: 0.6226115 Test Loss: 0.7067994\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3736904\n",
      "\tspeed: 0.1463s/iter; left time: 1965.5668s\n",
      "\titers: 200, epoch: 6 | loss: 0.4063546\n",
      "\tspeed: 0.0586s/iter; left time: 780.9628s\n",
      "\titers: 300, epoch: 6 | loss: 0.4072610\n",
      "\tspeed: 0.0582s/iter; left time: 770.0347s\n",
      "\titers: 400, epoch: 6 | loss: 0.3981712\n",
      "\tspeed: 0.0593s/iter; left time: 778.5698s\n",
      "\titers: 500, epoch: 6 | loss: 0.3582872\n",
      "\tspeed: 0.0601s/iter; left time: 782.9505s\n",
      "\titers: 600, epoch: 6 | loss: 0.3897237\n",
      "\tspeed: 0.0605s/iter; left time: 782.3154s\n",
      "\titers: 700, epoch: 6 | loss: 0.3717340\n",
      "\tspeed: 0.0594s/iter; left time: 761.9022s\n",
      "\titers: 800, epoch: 6 | loss: 0.3714317\n",
      "\tspeed: 0.0574s/iter; left time: 731.3466s\n",
      "\titers: 900, epoch: 6 | loss: 0.3605894\n",
      "\tspeed: 0.0572s/iter; left time: 722.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.27s\n",
      "Steps: 902 | Train Loss: 0.3819308 Vali Loss: 0.6257321 Test Loss: 0.7225763\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3409602\n",
      "\tspeed: 0.1465s/iter; left time: 1835.0858s\n",
      "\titers: 200, epoch: 7 | loss: 0.3829959\n",
      "\tspeed: 0.0598s/iter; left time: 743.2404s\n",
      "\titers: 300, epoch: 7 | loss: 0.3455449\n",
      "\tspeed: 0.0598s/iter; left time: 737.5197s\n",
      "\titers: 400, epoch: 7 | loss: 0.3713112\n",
      "\tspeed: 0.0601s/iter; left time: 735.5049s\n",
      "\titers: 500, epoch: 7 | loss: 0.3563232\n",
      "\tspeed: 0.0598s/iter; left time: 724.7787s\n",
      "\titers: 600, epoch: 7 | loss: 0.3682913\n",
      "\tspeed: 0.0591s/iter; left time: 710.3440s\n",
      "\titers: 700, epoch: 7 | loss: 0.3661709\n",
      "\tspeed: 0.0527s/iter; left time: 628.2047s\n",
      "\titers: 800, epoch: 7 | loss: 0.3564461\n",
      "\tspeed: 0.0534s/iter; left time: 631.3296s\n",
      "\titers: 900, epoch: 7 | loss: 0.3330379\n",
      "\tspeed: 0.0542s/iter; left time: 635.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.21s\n",
      "Steps: 902 | Train Loss: 0.3572680 Vali Loss: 0.6332866 Test Loss: 0.7300028\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3669146\n",
      "\tspeed: 0.1424s/iter; left time: 1656.2543s\n",
      "\titers: 200, epoch: 8 | loss: 0.3443349\n",
      "\tspeed: 0.0580s/iter; left time: 669.0808s\n",
      "\titers: 300, epoch: 8 | loss: 0.3302985\n",
      "\tspeed: 0.0575s/iter; left time: 656.4952s\n",
      "\titers: 400, epoch: 8 | loss: 0.3363123\n",
      "\tspeed: 0.0576s/iter; left time: 652.4751s\n",
      "\titers: 500, epoch: 8 | loss: 0.3030025\n",
      "\tspeed: 0.0568s/iter; left time: 637.7798s\n",
      "\titers: 600, epoch: 8 | loss: 0.3542161\n",
      "\tspeed: 0.0569s/iter; left time: 632.9479s\n",
      "\titers: 700, epoch: 8 | loss: 0.3296228\n",
      "\tspeed: 0.0576s/iter; left time: 635.4861s\n",
      "\titers: 800, epoch: 8 | loss: 0.3296688\n",
      "\tspeed: 0.0584s/iter; left time: 638.3147s\n",
      "\titers: 900, epoch: 8 | loss: 0.3222977\n",
      "\tspeed: 0.0567s/iter; left time: 614.2531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:52.03s\n",
      "Steps: 902 | Train Loss: 0.3358185 Vali Loss: 0.6332167 Test Loss: 0.7396336\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3275861\n",
      "\tspeed: 0.1442s/iter; left time: 1546.2305s\n",
      "\titers: 200, epoch: 9 | loss: 0.3080933\n",
      "\tspeed: 0.0573s/iter; left time: 608.5403s\n",
      "\titers: 300, epoch: 9 | loss: 0.3156401\n",
      "\tspeed: 0.0572s/iter; left time: 602.3181s\n",
      "\titers: 400, epoch: 9 | loss: 0.3250451\n",
      "\tspeed: 0.0576s/iter; left time: 600.6187s\n",
      "\titers: 500, epoch: 9 | loss: 0.3089396\n",
      "\tspeed: 0.0577s/iter; left time: 596.0741s\n",
      "\titers: 600, epoch: 9 | loss: 0.3190619\n",
      "\tspeed: 0.0568s/iter; left time: 580.6152s\n",
      "\titers: 700, epoch: 9 | loss: 0.3033944\n",
      "\tspeed: 0.0567s/iter; left time: 574.2385s\n",
      "\titers: 800, epoch: 9 | loss: 0.3166314\n",
      "\tspeed: 0.0570s/iter; left time: 571.2421s\n",
      "\titers: 900, epoch: 9 | loss: 0.3289872\n",
      "\tspeed: 0.0567s/iter; left time: 562.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:51.85s\n",
      "Steps: 902 | Train Loss: 0.3190240 Vali Loss: 0.6347582 Test Loss: 0.7447671\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0407408475875854, rmse:1.0201671123504639, mae:0.7039265036582947, rse:0.8081529140472412\n",
      "Original data scale mse:45537116.0, rmse:6748.11962890625, mae:4292.68115234375, rse:0.3362237215042114\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>0.5114</td>\n",
       "      <td>0.5733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.7306</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.5782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.7388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0134</td>\n",
       "      <td>1.0067</td>\n",
       "      <td>0.7418</td>\n",
       "      <td>0.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5389</td>\n",
       "      <td>0.7341</td>\n",
       "      <td>0.4719</td>\n",
       "      <td>0.5810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5458</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.4761</td>\n",
       "      <td>0.5847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.7529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0010</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>0.6780</td>\n",
       "      <td>0.7935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9856</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>0.7093</td>\n",
       "      <td>0.7864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0407</td>\n",
       "      <td>1.0202</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>0.8082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5247  0.7244  0.5114  0.5733\n",
       "              2         24        0.5337  0.7306  0.4778  0.5782\n",
       "              1         96        0.8678  0.9315  0.6915  0.7388\n",
       "              2         96        0.9063  0.9520  0.6854  0.7550\n",
       "              1         168       0.9473  0.9733  0.7125  0.7710\n",
       "              2         168       1.0134  1.0067  0.7418  0.7975\n",
       "MAE           1         24        0.5389  0.7341  0.4719  0.5810\n",
       "              2         24        0.5458  0.7388  0.4761  0.5847\n",
       "              1         96        0.9010  0.9492  0.6441  0.7529\n",
       "              2         96        1.0010  1.0005  0.6780  0.7935\n",
       "              1         168       0.9856  0.9928  0.7093  0.7864\n",
       "              2         168       1.0407  1.0202  0.7039  0.8082"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)\n",
    "\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_default.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_default.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21980930.0</td>\n",
       "      <td>4688.3823</td>\n",
       "      <td>3161.3560</td>\n",
       "      <td>0.2331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>21397382.0</td>\n",
       "      <td>4625.7305</td>\n",
       "      <td>2871.8848</td>\n",
       "      <td>0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38906908.0</td>\n",
       "      <td>6237.5400</td>\n",
       "      <td>4300.8379</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>40021996.0</td>\n",
       "      <td>6326.2939</td>\n",
       "      <td>4212.2036</td>\n",
       "      <td>0.3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>42061940.0</td>\n",
       "      <td>6485.5176</td>\n",
       "      <td>4402.3633</td>\n",
       "      <td>0.3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45914860.0</td>\n",
       "      <td>6776.0503</td>\n",
       "      <td>4621.6470</td>\n",
       "      <td>0.3376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21871782.0</td>\n",
       "      <td>4676.7275</td>\n",
       "      <td>2841.9736</td>\n",
       "      <td>0.2325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>22062046.0</td>\n",
       "      <td>4697.0254</td>\n",
       "      <td>2876.5288</td>\n",
       "      <td>0.2335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37380548.0</td>\n",
       "      <td>6113.9634</td>\n",
       "      <td>3884.0576</td>\n",
       "      <td>0.3045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>42881912.0</td>\n",
       "      <td>6548.4282</td>\n",
       "      <td>4106.7485</td>\n",
       "      <td>0.3261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>43904392.0</td>\n",
       "      <td>6626.0391</td>\n",
       "      <td>4388.9360</td>\n",
       "      <td>0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45537116.0</td>\n",
       "      <td>6748.1196</td>\n",
       "      <td>4292.6812</td>\n",
       "      <td>0.3362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        21980930.0  4688.3823  3161.3560  0.2331\n",
       "              2         24        21397382.0  4625.7305  2871.8848  0.2300\n",
       "              1         96        38906908.0  6237.5400  4300.8379  0.3106\n",
       "              2         96        40021996.0  6326.2939  4212.2036  0.3151\n",
       "              1         168       42061940.0  6485.5176  4402.3633  0.3231\n",
       "              2         168       45914860.0  6776.0503  4621.6470  0.3376\n",
       "MAE           1         24        21871782.0  4676.7275  2841.9736  0.2325\n",
       "              2         24        22062046.0  4697.0254  2876.5288  0.2335\n",
       "              1         96        37380548.0  6113.9634  3884.0576  0.3045\n",
       "              2         96        42881912.0  6548.4282  4106.7485  0.3261\n",
       "              1         168       43904392.0  6626.0391  4388.9360  0.3301\n",
       "              2         168       45537116.0  6748.1196  4292.6812  0.3362"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.5829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.5757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9418</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.0131</td>\n",
       "      <td>1.0065</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.7842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5424  0.7365  0.4740  0.5829\n",
       "         MSE            0.5292  0.7275  0.4946  0.5757\n",
       "96       MAE            0.9510  0.9749  0.6610  0.7732\n",
       "         MSE            0.8870  0.9418  0.6885  0.7469\n",
       "168      MAE            1.0131  1.0065  0.7066  0.7973\n",
       "         MSE            0.9804  0.9900  0.7271  0.7842"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>21966914.0</td>\n",
       "      <td>4686.8765</td>\n",
       "      <td>2859.2512</td>\n",
       "      <td>0.2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>21689156.0</td>\n",
       "      <td>4657.0564</td>\n",
       "      <td>3016.6204</td>\n",
       "      <td>0.2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40131230.0</td>\n",
       "      <td>6331.1958</td>\n",
       "      <td>3995.4031</td>\n",
       "      <td>0.3153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39464452.0</td>\n",
       "      <td>6281.9170</td>\n",
       "      <td>4256.5208</td>\n",
       "      <td>0.3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>44720754.0</td>\n",
       "      <td>6687.0793</td>\n",
       "      <td>4340.8086</td>\n",
       "      <td>0.3332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>43988400.0</td>\n",
       "      <td>6630.7839</td>\n",
       "      <td>4512.0051</td>\n",
       "      <td>0.3304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            21966914.0  4686.8765  2859.2512  0.2330\n",
       "         MSE            21689156.0  4657.0564  3016.6204  0.2316\n",
       "96       MAE            40131230.0  6331.1958  3995.4031  0.3153\n",
       "         MSE            39464452.0  6281.9170  4256.5208  0.3128\n",
       "168      MAE            44720754.0  6687.0793  4340.8086  0.3332\n",
       "         MSE            43988400.0  6630.7839  4512.0051  0.3304"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0414041\n",
      "\tspeed: 0.0401s/iter; left time: 716.9613s\n",
      "\titers: 200, epoch: 1 | loss: 0.8442047\n",
      "\tspeed: 0.0139s/iter; left time: 246.9785s\n",
      "\titers: 300, epoch: 1 | loss: 0.6250193\n",
      "\tspeed: 0.0173s/iter; left time: 306.4236s\n",
      "\titers: 400, epoch: 1 | loss: 0.6413666\n",
      "\tspeed: 0.0176s/iter; left time: 309.5700s\n",
      "\titers: 500, epoch: 1 | loss: 0.5653903\n",
      "\tspeed: 0.0170s/iter; left time: 297.2502s\n",
      "\titers: 600, epoch: 1 | loss: 0.5006524\n",
      "\tspeed: 0.0171s/iter; left time: 297.0276s\n",
      "\titers: 700, epoch: 1 | loss: 0.4667799\n",
      "\tspeed: 0.0184s/iter; left time: 318.3238s\n",
      "\titers: 800, epoch: 1 | loss: 0.4749154\n",
      "\tspeed: 0.0184s/iter; left time: 316.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 899 | Train Loss: 0.6451582 Vali Loss: 0.5301403 Test Loss: 0.5831461\n",
      "Validation loss decreased (inf --> 0.530140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4444825\n",
      "\tspeed: 0.0656s/iter; left time: 1114.6426s\n",
      "\titers: 200, epoch: 2 | loss: 0.3697219\n",
      "\tspeed: 0.0212s/iter; left time: 357.9709s\n",
      "\titers: 300, epoch: 2 | loss: 0.3729038\n",
      "\tspeed: 0.0152s/iter; left time: 254.8382s\n",
      "\titers: 400, epoch: 2 | loss: 0.2669922\n",
      "\tspeed: 0.0164s/iter; left time: 273.0786s\n",
      "\titers: 500, epoch: 2 | loss: 0.3205202\n",
      "\tspeed: 0.0160s/iter; left time: 265.7039s\n",
      "\titers: 600, epoch: 2 | loss: 0.2187390\n",
      "\tspeed: 0.0101s/iter; left time: 166.9166s\n",
      "\titers: 700, epoch: 2 | loss: 0.2229261\n",
      "\tspeed: 0.0193s/iter; left time: 316.6101s\n",
      "\titers: 800, epoch: 2 | loss: 0.2755716\n",
      "\tspeed: 0.0206s/iter; left time: 335.3057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.52s\n",
      "Steps: 899 | Train Loss: 0.3393681 Vali Loss: 0.4148295 Test Loss: 0.4561953\n",
      "Validation loss decreased (0.530140 --> 0.414830).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2489694\n",
      "\tspeed: 0.0632s/iter; left time: 1016.1644s\n",
      "\titers: 200, epoch: 3 | loss: 0.4093309\n",
      "\tspeed: 0.0211s/iter; left time: 336.8111s\n",
      "\titers: 300, epoch: 3 | loss: 0.3126713\n",
      "\tspeed: 0.0212s/iter; left time: 336.1332s\n",
      "\titers: 400, epoch: 3 | loss: 0.2710995\n",
      "\tspeed: 0.0203s/iter; left time: 320.2769s\n",
      "\titers: 500, epoch: 3 | loss: 0.3248448\n",
      "\tspeed: 0.0253s/iter; left time: 396.1420s\n",
      "\titers: 600, epoch: 3 | loss: 0.2838766\n",
      "\tspeed: 0.0176s/iter; left time: 273.5518s\n",
      "\titers: 700, epoch: 3 | loss: 0.2955272\n",
      "\tspeed: 0.0151s/iter; left time: 233.3085s\n",
      "\titers: 800, epoch: 3 | loss: 0.3196238\n",
      "\tspeed: 0.0195s/iter; left time: 300.5460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 899 | Train Loss: 0.3053139 Vali Loss: 0.4057026 Test Loss: 0.4455117\n",
      "Validation loss decreased (0.414830 --> 0.405703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3470268\n",
      "\tspeed: 0.0615s/iter; left time: 934.2366s\n",
      "\titers: 200, epoch: 4 | loss: 0.2830759\n",
      "\tspeed: 0.0198s/iter; left time: 298.9890s\n",
      "\titers: 300, epoch: 4 | loss: 0.3476118\n",
      "\tspeed: 0.0188s/iter; left time: 281.8899s\n",
      "\titers: 400, epoch: 4 | loss: 0.2643502\n",
      "\tspeed: 0.0194s/iter; left time: 288.8583s\n",
      "\titers: 500, epoch: 4 | loss: 0.2351335\n",
      "\tspeed: 0.0188s/iter; left time: 277.6739s\n",
      "\titers: 600, epoch: 4 | loss: 0.2520867\n",
      "\tspeed: 0.0188s/iter; left time: 275.9442s\n",
      "\titers: 700, epoch: 4 | loss: 0.2428680\n",
      "\tspeed: 0.0199s/iter; left time: 290.9019s\n",
      "\titers: 800, epoch: 4 | loss: 0.2451192\n",
      "\tspeed: 0.0202s/iter; left time: 292.4509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.66s\n",
      "Steps: 899 | Train Loss: 0.2945614 Vali Loss: 0.4020638 Test Loss: 0.4439253\n",
      "Validation loss decreased (0.405703 --> 0.402064).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4249115\n",
      "\tspeed: 0.0633s/iter; left time: 904.8970s\n",
      "\titers: 200, epoch: 5 | loss: 0.3224394\n",
      "\tspeed: 0.0124s/iter; left time: 176.2535s\n",
      "\titers: 300, epoch: 5 | loss: 0.2385400\n",
      "\tspeed: 0.0101s/iter; left time: 142.9064s\n",
      "\titers: 400, epoch: 5 | loss: 0.2677107\n",
      "\tspeed: 0.0115s/iter; left time: 161.3573s\n",
      "\titers: 500, epoch: 5 | loss: 0.3429607\n",
      "\tspeed: 0.0194s/iter; left time: 269.4558s\n",
      "\titers: 600, epoch: 5 | loss: 0.2426579\n",
      "\tspeed: 0.0199s/iter; left time: 274.9812s\n",
      "\titers: 700, epoch: 5 | loss: 0.3441966\n",
      "\tspeed: 0.0191s/iter; left time: 260.7193s\n",
      "\titers: 800, epoch: 5 | loss: 0.2663293\n",
      "\tspeed: 0.0203s/iter; left time: 275.5287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 899 | Train Loss: 0.2859814 Vali Loss: 0.4002837 Test Loss: 0.4444229\n",
      "Validation loss decreased (0.402064 --> 0.400284).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2966055\n",
      "\tspeed: 0.0548s/iter; left time: 733.1907s\n",
      "\titers: 200, epoch: 6 | loss: 0.2780593\n",
      "\tspeed: 0.0085s/iter; left time: 113.3519s\n",
      "\titers: 300, epoch: 6 | loss: 0.2187532\n",
      "\tspeed: 0.0085s/iter; left time: 112.1615s\n",
      "\titers: 400, epoch: 6 | loss: 0.2880644\n",
      "\tspeed: 0.0085s/iter; left time: 111.1855s\n",
      "\titers: 500, epoch: 6 | loss: 0.2290629\n",
      "\tspeed: 0.0085s/iter; left time: 110.1351s\n",
      "\titers: 600, epoch: 6 | loss: 0.2206191\n",
      "\tspeed: 0.0085s/iter; left time: 109.4284s\n",
      "\titers: 700, epoch: 6 | loss: 0.3303756\n",
      "\tspeed: 0.0085s/iter; left time: 108.4579s\n",
      "\titers: 800, epoch: 6 | loss: 0.2770058\n",
      "\tspeed: 0.0085s/iter; left time: 107.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 899 | Train Loss: 0.2815845 Vali Loss: 0.3886742 Test Loss: 0.4340417\n",
      "Validation loss decreased (0.400284 --> 0.388674).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3823954\n",
      "\tspeed: 0.0509s/iter; left time: 635.0566s\n",
      "\titers: 200, epoch: 7 | loss: 0.2233027\n",
      "\tspeed: 0.0121s/iter; left time: 149.7768s\n",
      "\titers: 300, epoch: 7 | loss: 0.4291381\n",
      "\tspeed: 0.0085s/iter; left time: 104.8819s\n",
      "\titers: 400, epoch: 7 | loss: 0.3388808\n",
      "\tspeed: 0.0085s/iter; left time: 104.1030s\n",
      "\titers: 500, epoch: 7 | loss: 0.2953984\n",
      "\tspeed: 0.0085s/iter; left time: 102.8237s\n",
      "\titers: 600, epoch: 7 | loss: 0.2632775\n",
      "\tspeed: 0.0085s/iter; left time: 101.4016s\n",
      "\titers: 700, epoch: 7 | loss: 0.2206812\n",
      "\tspeed: 0.0085s/iter; left time: 100.7192s\n",
      "\titers: 800, epoch: 7 | loss: 0.3811227\n",
      "\tspeed: 0.0085s/iter; left time: 99.9349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:09.36s\n",
      "Steps: 899 | Train Loss: 0.2761277 Vali Loss: 0.3919926 Test Loss: 0.4357160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3079284\n",
      "\tspeed: 0.0524s/iter; left time: 607.3010s\n",
      "\titers: 200, epoch: 8 | loss: 0.2464034\n",
      "\tspeed: 0.0199s/iter; left time: 228.7087s\n",
      "\titers: 300, epoch: 8 | loss: 0.2545118\n",
      "\tspeed: 0.0198s/iter; left time: 225.0520s\n",
      "\titers: 400, epoch: 8 | loss: 0.3176038\n",
      "\tspeed: 0.0185s/iter; left time: 208.7494s\n",
      "\titers: 500, epoch: 8 | loss: 0.2673494\n",
      "\tspeed: 0.0158s/iter; left time: 176.3196s\n",
      "\titers: 600, epoch: 8 | loss: 0.2570074\n",
      "\tspeed: 0.0155s/iter; left time: 171.4675s\n",
      "\titers: 700, epoch: 8 | loss: 0.3332931\n",
      "\tspeed: 0.0167s/iter; left time: 183.4849s\n",
      "\titers: 800, epoch: 8 | loss: 0.2150307\n",
      "\tspeed: 0.0098s/iter; left time: 106.2638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 899 | Train Loss: 0.2729065 Vali Loss: 0.3910934 Test Loss: 0.4380831\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2766456\n",
      "\tspeed: 0.0599s/iter; left time: 639.9192s\n",
      "\titers: 200, epoch: 9 | loss: 0.3710009\n",
      "\tspeed: 0.0190s/iter; left time: 201.4265s\n",
      "\titers: 300, epoch: 9 | loss: 0.3004199\n",
      "\tspeed: 0.0172s/iter; left time: 180.0607s\n",
      "\titers: 400, epoch: 9 | loss: 0.2826853\n",
      "\tspeed: 0.0170s/iter; left time: 176.4257s\n",
      "\titers: 500, epoch: 9 | loss: 0.2543755\n",
      "\tspeed: 0.0170s/iter; left time: 174.8681s\n",
      "\titers: 600, epoch: 9 | loss: 0.1914008\n",
      "\tspeed: 0.0166s/iter; left time: 168.8684s\n",
      "\titers: 700, epoch: 9 | loss: 0.3358374\n",
      "\tspeed: 0.0182s/iter; left time: 183.4818s\n",
      "\titers: 800, epoch: 9 | loss: 0.2803228\n",
      "\tspeed: 0.0106s/iter; left time: 105.6934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 899 | Train Loss: 0.2693706 Vali Loss: 0.3937411 Test Loss: 0.4406287\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1992505\n",
      "\tspeed: 0.0596s/iter; left time: 583.8186s\n",
      "\titers: 200, epoch: 10 | loss: 0.2192778\n",
      "\tspeed: 0.0150s/iter; left time: 145.2335s\n",
      "\titers: 300, epoch: 10 | loss: 0.2909761\n",
      "\tspeed: 0.0203s/iter; left time: 195.0320s\n",
      "\titers: 400, epoch: 10 | loss: 0.2422285\n",
      "\tspeed: 0.0202s/iter; left time: 191.2805s\n",
      "\titers: 500, epoch: 10 | loss: 0.3045113\n",
      "\tspeed: 0.0201s/iter; left time: 188.3506s\n",
      "\titers: 600, epoch: 10 | loss: 0.2824683\n",
      "\tspeed: 0.0200s/iter; left time: 185.6856s\n",
      "\titers: 700, epoch: 10 | loss: 0.2907839\n",
      "\tspeed: 0.0196s/iter; left time: 180.1775s\n",
      "\titers: 800, epoch: 10 | loss: 0.2553306\n",
      "\tspeed: 0.0198s/iter; left time: 179.5741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.74s\n",
      "Steps: 899 | Train Loss: 0.2665528 Vali Loss: 0.3887717 Test Loss: 0.4402139\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2447527\n",
      "\tspeed: 0.0626s/iter; left time: 557.0068s\n",
      "\titers: 200, epoch: 11 | loss: 0.3313461\n",
      "\tspeed: 0.0173s/iter; left time: 151.8473s\n",
      "\titers: 300, epoch: 11 | loss: 0.1891783\n",
      "\tspeed: 0.0173s/iter; left time: 150.3383s\n",
      "\titers: 400, epoch: 11 | loss: 0.2130098\n",
      "\tspeed: 0.0175s/iter; left time: 150.2833s\n",
      "\titers: 500, epoch: 11 | loss: 0.1904548\n",
      "\tspeed: 0.0172s/iter; left time: 146.3797s\n",
      "\titers: 600, epoch: 11 | loss: 0.3067642\n",
      "\tspeed: 0.0171s/iter; left time: 143.4954s\n",
      "\titers: 700, epoch: 11 | loss: 0.2801913\n",
      "\tspeed: 0.0176s/iter; left time: 145.5329s\n",
      "\titers: 800, epoch: 11 | loss: 0.2553191\n",
      "\tspeed: 0.0151s/iter; left time: 123.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.01s\n",
      "Steps: 899 | Train Loss: 0.2637876 Vali Loss: 0.3881606 Test Loss: 0.4390803\n",
      "Validation loss decreased (0.388674 --> 0.388161).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2851705\n",
      "\tspeed: 0.0517s/iter; left time: 413.2402s\n",
      "\titers: 200, epoch: 12 | loss: 0.2886828\n",
      "\tspeed: 0.0188s/iter; left time: 148.6645s\n",
      "\titers: 300, epoch: 12 | loss: 0.2980938\n",
      "\tspeed: 0.0191s/iter; left time: 149.0963s\n",
      "\titers: 400, epoch: 12 | loss: 0.2767529\n",
      "\tspeed: 0.0197s/iter; left time: 151.3064s\n",
      "\titers: 500, epoch: 12 | loss: 0.2206130\n",
      "\tspeed: 0.0201s/iter; left time: 152.6228s\n",
      "\titers: 600, epoch: 12 | loss: 0.2577218\n",
      "\tspeed: 0.0143s/iter; left time: 106.9741s\n",
      "\titers: 700, epoch: 12 | loss: 0.2419273\n",
      "\tspeed: 0.0085s/iter; left time: 63.0465s\n",
      "\titers: 800, epoch: 12 | loss: 0.2802715\n",
      "\tspeed: 0.0085s/iter; left time: 61.8840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.55s\n",
      "Steps: 899 | Train Loss: 0.2613883 Vali Loss: 0.3921930 Test Loss: 0.4411546\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2049088\n",
      "\tspeed: 0.0569s/iter; left time: 403.6013s\n",
      "\titers: 200, epoch: 13 | loss: 0.2360600\n",
      "\tspeed: 0.0189s/iter; left time: 131.9682s\n",
      "\titers: 300, epoch: 13 | loss: 0.2386016\n",
      "\tspeed: 0.0187s/iter; left time: 129.1818s\n",
      "\titers: 400, epoch: 13 | loss: 0.2651370\n",
      "\tspeed: 0.0204s/iter; left time: 138.5791s\n",
      "\titers: 500, epoch: 13 | loss: 0.1924810\n",
      "\tspeed: 0.0196s/iter; left time: 131.2295s\n",
      "\titers: 600, epoch: 13 | loss: 0.2581726\n",
      "\tspeed: 0.0196s/iter; left time: 129.0432s\n",
      "\titers: 700, epoch: 13 | loss: 0.2130048\n",
      "\tspeed: 0.0185s/iter; left time: 119.8743s\n",
      "\titers: 800, epoch: 13 | loss: 0.2747229\n",
      "\tspeed: 0.0193s/iter; left time: 123.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:17.70s\n",
      "Steps: 899 | Train Loss: 0.2588022 Vali Loss: 0.3927080 Test Loss: 0.4400181\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2296983\n",
      "\tspeed: 0.0624s/iter; left time: 386.6558s\n",
      "\titers: 200, epoch: 14 | loss: 0.2826217\n",
      "\tspeed: 0.0203s/iter; left time: 123.4663s\n",
      "\titers: 300, epoch: 14 | loss: 0.2519561\n",
      "\tspeed: 0.0208s/iter; left time: 124.7083s\n",
      "\titers: 400, epoch: 14 | loss: 0.2673980\n",
      "\tspeed: 0.0204s/iter; left time: 120.3527s\n",
      "\titers: 500, epoch: 14 | loss: 0.2942949\n",
      "\tspeed: 0.0200s/iter; left time: 115.8022s\n",
      "\titers: 600, epoch: 14 | loss: 0.2978082\n",
      "\tspeed: 0.0203s/iter; left time: 115.5569s\n",
      "\titers: 700, epoch: 14 | loss: 0.2693021\n",
      "\tspeed: 0.0224s/iter; left time: 125.0287s\n",
      "\titers: 800, epoch: 14 | loss: 0.2905435\n",
      "\tspeed: 0.0226s/iter; left time: 124.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.85s\n",
      "Steps: 899 | Train Loss: 0.2576740 Vali Loss: 0.3907124 Test Loss: 0.4387711\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2405425\n",
      "\tspeed: 0.0605s/iter; left time: 320.4117s\n",
      "\titers: 200, epoch: 15 | loss: 0.2342897\n",
      "\tspeed: 0.0192s/iter; left time: 99.5746s\n",
      "\titers: 300, epoch: 15 | loss: 0.3100643\n",
      "\tspeed: 0.0178s/iter; left time: 90.5564s\n",
      "\titers: 400, epoch: 15 | loss: 0.2551574\n",
      "\tspeed: 0.0167s/iter; left time: 83.5376s\n",
      "\titers: 500, epoch: 15 | loss: 0.2769737\n",
      "\tspeed: 0.0161s/iter; left time: 79.0066s\n",
      "\titers: 600, epoch: 15 | loss: 0.2637854\n",
      "\tspeed: 0.0165s/iter; left time: 79.1721s\n",
      "\titers: 700, epoch: 15 | loss: 0.2619573\n",
      "\tspeed: 0.0170s/iter; left time: 79.8045s\n",
      "\titers: 800, epoch: 15 | loss: 0.2683541\n",
      "\tspeed: 0.0191s/iter; left time: 87.6043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:16.38s\n",
      "Steps: 899 | Train Loss: 0.2550056 Vali Loss: 0.3954844 Test Loss: 0.4436757\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.2387226\n",
      "\tspeed: 0.0639s/iter; left time: 280.7479s\n",
      "\titers: 200, epoch: 16 | loss: 0.2510532\n",
      "\tspeed: 0.0201s/iter; left time: 86.3868s\n",
      "\titers: 300, epoch: 16 | loss: 0.2155646\n",
      "\tspeed: 0.0203s/iter; left time: 85.0191s\n",
      "\titers: 400, epoch: 16 | loss: 0.2664495\n",
      "\tspeed: 0.0198s/iter; left time: 81.0749s\n",
      "\titers: 500, epoch: 16 | loss: 0.3292328\n",
      "\tspeed: 0.0199s/iter; left time: 79.3779s\n",
      "\titers: 600, epoch: 16 | loss: 0.2465894\n",
      "\tspeed: 0.0198s/iter; left time: 77.1846s\n",
      "\titers: 700, epoch: 16 | loss: 0.2892612\n",
      "\tspeed: 0.0198s/iter; left time: 75.1811s\n",
      "\titers: 800, epoch: 16 | loss: 0.2319811\n",
      "\tspeed: 0.0194s/iter; left time: 71.6979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 899 | Train Loss: 0.2531814 Vali Loss: 0.3934851 Test Loss: 0.4417687\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4390804171562195, rmse:0.6626314520835876, mae:0.4261071979999542, rse:0.5244309306144714\n",
      "Original data scale mse:16458542.0, rmse:4056.912841796875, mae:2476.096435546875, rse:0.20171788334846497\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0098028\n",
      "\tspeed: 0.0239s/iter; left time: 427.0612s\n",
      "\titers: 200, epoch: 1 | loss: 0.7931145\n",
      "\tspeed: 0.0183s/iter; left time: 325.7904s\n",
      "\titers: 300, epoch: 1 | loss: 0.7141766\n",
      "\tspeed: 0.0180s/iter; left time: 317.6781s\n",
      "\titers: 400, epoch: 1 | loss: 0.5899090\n",
      "\tspeed: 0.0194s/iter; left time: 341.2266s\n",
      "\titers: 500, epoch: 1 | loss: 0.5818306\n",
      "\tspeed: 0.0194s/iter; left time: 338.9822s\n",
      "\titers: 600, epoch: 1 | loss: 0.5879701\n",
      "\tspeed: 0.0195s/iter; left time: 338.9506s\n",
      "\titers: 700, epoch: 1 | loss: 0.4975373\n",
      "\tspeed: 0.0186s/iter; left time: 321.0454s\n",
      "\titers: 800, epoch: 1 | loss: 0.6021367\n",
      "\tspeed: 0.0189s/iter; left time: 324.9243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:17.64s\n",
      "Steps: 899 | Train Loss: 0.6311770 Vali Loss: 0.5382283 Test Loss: 0.5877714\n",
      "Validation loss decreased (inf --> 0.538228).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4125207\n",
      "\tspeed: 0.0640s/iter; left time: 1086.0374s\n",
      "\titers: 200, epoch: 2 | loss: 0.3261748\n",
      "\tspeed: 0.0194s/iter; left time: 327.3737s\n",
      "\titers: 300, epoch: 2 | loss: 0.4313876\n",
      "\tspeed: 0.0193s/iter; left time: 323.3911s\n",
      "\titers: 400, epoch: 2 | loss: 0.2854418\n",
      "\tspeed: 0.0190s/iter; left time: 316.9384s\n",
      "\titers: 500, epoch: 2 | loss: 0.3463714\n",
      "\tspeed: 0.0193s/iter; left time: 319.8812s\n",
      "\titers: 600, epoch: 2 | loss: 0.3259590\n",
      "\tspeed: 0.0188s/iter; left time: 310.2042s\n",
      "\titers: 700, epoch: 2 | loss: 0.2693709\n",
      "\tspeed: 0.0188s/iter; left time: 308.0269s\n",
      "\titers: 800, epoch: 2 | loss: 0.1969150\n",
      "\tspeed: 0.0206s/iter; left time: 335.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.78s\n",
      "Steps: 899 | Train Loss: 0.3402044 Vali Loss: 0.4168401 Test Loss: 0.4580937\n",
      "Validation loss decreased (0.538228 --> 0.416840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2243953\n",
      "\tspeed: 0.0604s/iter; left time: 970.7934s\n",
      "\titers: 200, epoch: 3 | loss: 0.3212492\n",
      "\tspeed: 0.0167s/iter; left time: 266.4254s\n",
      "\titers: 300, epoch: 3 | loss: 0.2539202\n",
      "\tspeed: 0.0163s/iter; left time: 259.0662s\n",
      "\titers: 400, epoch: 3 | loss: 0.2657521\n",
      "\tspeed: 0.0155s/iter; left time: 244.2605s\n",
      "\titers: 500, epoch: 3 | loss: 0.3429642\n",
      "\tspeed: 0.0146s/iter; left time: 228.4258s\n",
      "\titers: 600, epoch: 3 | loss: 0.2723836\n",
      "\tspeed: 0.0221s/iter; left time: 345.0033s\n",
      "\titers: 700, epoch: 3 | loss: 0.3158261\n",
      "\tspeed: 0.0225s/iter; left time: 347.7972s\n",
      "\titers: 800, epoch: 3 | loss: 0.3031791\n",
      "\tspeed: 0.0142s/iter; left time: 218.8868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:14.90s\n",
      "Steps: 899 | Train Loss: 0.3059196 Vali Loss: 0.4109266 Test Loss: 0.4478649\n",
      "Validation loss decreased (0.416840 --> 0.410927).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3821213\n",
      "\tspeed: 0.0502s/iter; left time: 761.5414s\n",
      "\titers: 200, epoch: 4 | loss: 0.3977962\n",
      "\tspeed: 0.0188s/iter; left time: 283.3967s\n",
      "\titers: 300, epoch: 4 | loss: 0.2952610\n",
      "\tspeed: 0.0191s/iter; left time: 285.7313s\n",
      "\titers: 400, epoch: 4 | loss: 0.2762023\n",
      "\tspeed: 0.0186s/iter; left time: 276.9581s\n",
      "\titers: 500, epoch: 4 | loss: 0.2295543\n",
      "\tspeed: 0.0195s/iter; left time: 288.0019s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613762\n",
      "\tspeed: 0.0106s/iter; left time: 155.0448s\n",
      "\titers: 700, epoch: 4 | loss: 0.3251058\n",
      "\tspeed: 0.0106s/iter; left time: 154.0759s\n",
      "\titers: 800, epoch: 4 | loss: 0.3254914\n",
      "\tspeed: 0.0108s/iter; left time: 157.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.20s\n",
      "Steps: 899 | Train Loss: 0.2953411 Vali Loss: 0.4063374 Test Loss: 0.4469289\n",
      "Validation loss decreased (0.410927 --> 0.406337).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2898278\n",
      "\tspeed: 0.0548s/iter; left time: 783.1816s\n",
      "\titers: 200, epoch: 5 | loss: 0.4058898\n",
      "\tspeed: 0.0143s/iter; left time: 202.9630s\n",
      "\titers: 300, epoch: 5 | loss: 0.2562516\n",
      "\tspeed: 0.0108s/iter; left time: 152.0300s\n",
      "\titers: 400, epoch: 5 | loss: 0.2240031\n",
      "\tspeed: 0.0107s/iter; left time: 149.2736s\n",
      "\titers: 500, epoch: 5 | loss: 0.3253909\n",
      "\tspeed: 0.0106s/iter; left time: 147.7031s\n",
      "\titers: 600, epoch: 5 | loss: 0.3100591\n",
      "\tspeed: 0.0106s/iter; left time: 146.4656s\n",
      "\titers: 700, epoch: 5 | loss: 0.3055955\n",
      "\tspeed: 0.0107s/iter; left time: 145.9329s\n",
      "\titers: 800, epoch: 5 | loss: 0.2390330\n",
      "\tspeed: 0.0106s/iter; left time: 144.6100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:11.03s\n",
      "Steps: 899 | Train Loss: 0.2872378 Vali Loss: 0.4002195 Test Loss: 0.4416959\n",
      "Validation loss decreased (0.406337 --> 0.400219).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2536861\n",
      "\tspeed: 0.0539s/iter; left time: 721.5075s\n",
      "\titers: 200, epoch: 6 | loss: 0.2392722\n",
      "\tspeed: 0.0199s/iter; left time: 264.2903s\n",
      "\titers: 300, epoch: 6 | loss: 0.3013912\n",
      "\tspeed: 0.0202s/iter; left time: 266.6307s\n",
      "\titers: 400, epoch: 6 | loss: 0.2880810\n",
      "\tspeed: 0.0200s/iter; left time: 261.3346s\n",
      "\titers: 500, epoch: 6 | loss: 0.2885015\n",
      "\tspeed: 0.0201s/iter; left time: 260.9319s\n",
      "\titers: 600, epoch: 6 | loss: 0.2998963\n",
      "\tspeed: 0.0193s/iter; left time: 248.9725s\n",
      "\titers: 700, epoch: 6 | loss: 0.2727202\n",
      "\tspeed: 0.0208s/iter; left time: 266.1383s\n",
      "\titers: 800, epoch: 6 | loss: 0.2740783\n",
      "\tspeed: 0.0193s/iter; left time: 244.6426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 899 | Train Loss: 0.2814571 Vali Loss: 0.4026161 Test Loss: 0.4440562\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2476400\n",
      "\tspeed: 0.0643s/iter; left time: 802.6671s\n",
      "\titers: 200, epoch: 7 | loss: 0.3259465\n",
      "\tspeed: 0.0202s/iter; left time: 250.1836s\n",
      "\titers: 300, epoch: 7 | loss: 0.3162635\n",
      "\tspeed: 0.0203s/iter; left time: 249.0666s\n",
      "\titers: 400, epoch: 7 | loss: 0.2273343\n",
      "\tspeed: 0.0212s/iter; left time: 258.4859s\n",
      "\titers: 500, epoch: 7 | loss: 0.2160948\n",
      "\tspeed: 0.0198s/iter; left time: 238.9845s\n",
      "\titers: 600, epoch: 7 | loss: 0.2663230\n",
      "\tspeed: 0.0186s/iter; left time: 222.6314s\n",
      "\titers: 700, epoch: 7 | loss: 0.2737223\n",
      "\tspeed: 0.0178s/iter; left time: 211.2473s\n",
      "\titers: 800, epoch: 7 | loss: 0.2266348\n",
      "\tspeed: 0.0174s/iter; left time: 204.7345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.71s\n",
      "Steps: 899 | Train Loss: 0.2769257 Vali Loss: 0.3944005 Test Loss: 0.4451964\n",
      "Validation loss decreased (0.400219 --> 0.394400).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2051058\n",
      "\tspeed: 0.0625s/iter; left time: 724.0382s\n",
      "\titers: 200, epoch: 8 | loss: 0.2371893\n",
      "\tspeed: 0.0214s/iter; left time: 246.0800s\n",
      "\titers: 300, epoch: 8 | loss: 0.2850325\n",
      "\tspeed: 0.0225s/iter; left time: 256.6353s\n",
      "\titers: 400, epoch: 8 | loss: 0.2032665\n",
      "\tspeed: 0.0218s/iter; left time: 245.9404s\n",
      "\titers: 500, epoch: 8 | loss: 0.2586315\n",
      "\tspeed: 0.0194s/iter; left time: 217.3023s\n",
      "\titers: 600, epoch: 8 | loss: 0.2503371\n",
      "\tspeed: 0.0219s/iter; left time: 243.0495s\n",
      "\titers: 700, epoch: 8 | loss: 0.2661831\n",
      "\tspeed: 0.0164s/iter; left time: 180.1908s\n",
      "\titers: 800, epoch: 8 | loss: 0.3574231\n",
      "\tspeed: 0.0165s/iter; left time: 179.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:17.99s\n",
      "Steps: 899 | Train Loss: 0.2732103 Vali Loss: 0.3949395 Test Loss: 0.4412445\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3910027\n",
      "\tspeed: 0.0615s/iter; left time: 657.6897s\n",
      "\titers: 200, epoch: 9 | loss: 0.2476625\n",
      "\tspeed: 0.0221s/iter; left time: 233.9685s\n",
      "\titers: 300, epoch: 9 | loss: 0.2413643\n",
      "\tspeed: 0.0242s/iter; left time: 253.5501s\n",
      "\titers: 400, epoch: 9 | loss: 0.2645285\n",
      "\tspeed: 0.0198s/iter; left time: 206.1443s\n",
      "\titers: 500, epoch: 9 | loss: 0.3022782\n",
      "\tspeed: 0.0167s/iter; left time: 171.5082s\n",
      "\titers: 600, epoch: 9 | loss: 0.2770307\n",
      "\tspeed: 0.0166s/iter; left time: 168.7639s\n",
      "\titers: 700, epoch: 9 | loss: 0.2980419\n",
      "\tspeed: 0.0166s/iter; left time: 167.7318s\n",
      "\titers: 800, epoch: 9 | loss: 0.2512561\n",
      "\tspeed: 0.0165s/iter; left time: 164.8209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.04s\n",
      "Steps: 899 | Train Loss: 0.2697922 Vali Loss: 0.3948476 Test Loss: 0.4388514\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2389732\n",
      "\tspeed: 0.0589s/iter; left time: 576.4205s\n",
      "\titers: 200, epoch: 10 | loss: 0.1812928\n",
      "\tspeed: 0.0206s/iter; left time: 199.2918s\n",
      "\titers: 300, epoch: 10 | loss: 0.2925011\n",
      "\tspeed: 0.0209s/iter; left time: 200.2538s\n",
      "\titers: 400, epoch: 10 | loss: 0.2840322\n",
      "\tspeed: 0.0211s/iter; left time: 200.6655s\n",
      "\titers: 500, epoch: 10 | loss: 0.2483186\n",
      "\tspeed: 0.0204s/iter; left time: 191.6955s\n",
      "\titers: 600, epoch: 10 | loss: 0.2405655\n",
      "\tspeed: 0.0198s/iter; left time: 183.5500s\n",
      "\titers: 700, epoch: 10 | loss: 0.2131758\n",
      "\tspeed: 0.0199s/iter; left time: 183.2071s\n",
      "\titers: 800, epoch: 10 | loss: 0.2478241\n",
      "\tspeed: 0.0195s/iter; left time: 177.6338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 899 | Train Loss: 0.2658201 Vali Loss: 0.3917488 Test Loss: 0.4390316\n",
      "Validation loss decreased (0.394400 --> 0.391749).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.2450460\n",
      "\tspeed: 0.0631s/iter; left time: 561.0870s\n",
      "\titers: 200, epoch: 11 | loss: 0.2409744\n",
      "\tspeed: 0.0187s/iter; left time: 164.7422s\n",
      "\titers: 300, epoch: 11 | loss: 0.3209303\n",
      "\tspeed: 0.0202s/iter; left time: 175.6859s\n",
      "\titers: 400, epoch: 11 | loss: 0.2603195\n",
      "\tspeed: 0.0200s/iter; left time: 171.9945s\n",
      "\titers: 500, epoch: 11 | loss: 0.3269995\n",
      "\tspeed: 0.0209s/iter; left time: 177.0800s\n",
      "\titers: 600, epoch: 11 | loss: 0.2641385\n",
      "\tspeed: 0.0086s/iter; left time: 72.2722s\n",
      "\titers: 700, epoch: 11 | loss: 0.2321479\n",
      "\tspeed: 0.0147s/iter; left time: 121.4797s\n",
      "\titers: 800, epoch: 11 | loss: 0.2749519\n",
      "\tspeed: 0.0171s/iter; left time: 140.0426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.19s\n",
      "Steps: 899 | Train Loss: 0.2631649 Vali Loss: 0.3922333 Test Loss: 0.4431054\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.2533589\n",
      "\tspeed: 0.0578s/iter; left time: 462.3104s\n",
      "\titers: 200, epoch: 12 | loss: 0.3170035\n",
      "\tspeed: 0.0187s/iter; left time: 147.7747s\n",
      "\titers: 300, epoch: 12 | loss: 0.2061291\n",
      "\tspeed: 0.0202s/iter; left time: 157.3783s\n",
      "\titers: 400, epoch: 12 | loss: 0.2961630\n",
      "\tspeed: 0.0212s/iter; left time: 163.2314s\n",
      "\titers: 500, epoch: 12 | loss: 0.2354252\n",
      "\tspeed: 0.0216s/iter; left time: 163.8001s\n",
      "\titers: 600, epoch: 12 | loss: 0.2060347\n",
      "\tspeed: 0.0201s/iter; left time: 150.8933s\n",
      "\titers: 700, epoch: 12 | loss: 0.2768680\n",
      "\tspeed: 0.0173s/iter; left time: 127.6534s\n",
      "\titers: 800, epoch: 12 | loss: 0.2491012\n",
      "\tspeed: 0.0199s/iter; left time: 145.3498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.66s\n",
      "Steps: 899 | Train Loss: 0.2610149 Vali Loss: 0.3906112 Test Loss: 0.4438090\n",
      "Validation loss decreased (0.391749 --> 0.390611).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.2737297\n",
      "\tspeed: 0.0662s/iter; left time: 469.3827s\n",
      "\titers: 200, epoch: 13 | loss: 0.2588952\n",
      "\tspeed: 0.0202s/iter; left time: 141.5500s\n",
      "\titers: 300, epoch: 13 | loss: 0.2233246\n",
      "\tspeed: 0.0202s/iter; left time: 139.4513s\n",
      "\titers: 400, epoch: 13 | loss: 0.3011863\n",
      "\tspeed: 0.0201s/iter; left time: 136.8644s\n",
      "\titers: 500, epoch: 13 | loss: 0.2922587\n",
      "\tspeed: 0.0102s/iter; left time: 68.4516s\n",
      "\titers: 600, epoch: 13 | loss: 0.2638078\n",
      "\tspeed: 0.0102s/iter; left time: 67.0153s\n",
      "\titers: 700, epoch: 13 | loss: 0.2231455\n",
      "\tspeed: 0.0102s/iter; left time: 65.9055s\n",
      "\titers: 800, epoch: 13 | loss: 0.2095841\n",
      "\tspeed: 0.0161s/iter; left time: 102.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.17s\n",
      "Steps: 899 | Train Loss: 0.2580827 Vali Loss: 0.3961122 Test Loss: 0.4458779\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2551421\n",
      "\tspeed: 0.0654s/iter; left time: 405.1992s\n",
      "\titers: 200, epoch: 14 | loss: 0.2357194\n",
      "\tspeed: 0.0203s/iter; left time: 123.7246s\n",
      "\titers: 300, epoch: 14 | loss: 0.2315693\n",
      "\tspeed: 0.0198s/iter; left time: 118.9195s\n",
      "\titers: 400, epoch: 14 | loss: 0.3188085\n",
      "\tspeed: 0.0198s/iter; left time: 116.9066s\n",
      "\titers: 500, epoch: 14 | loss: 0.2235951\n",
      "\tspeed: 0.0204s/iter; left time: 117.9293s\n",
      "\titers: 600, epoch: 14 | loss: 0.3151458\n",
      "\tspeed: 0.0202s/iter; left time: 115.1909s\n",
      "\titers: 700, epoch: 14 | loss: 0.2249697\n",
      "\tspeed: 0.0201s/iter; left time: 112.5004s\n",
      "\titers: 800, epoch: 14 | loss: 0.2797646\n",
      "\tspeed: 0.0198s/iter; left time: 108.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.43s\n",
      "Steps: 899 | Train Loss: 0.2558818 Vali Loss: 0.3922498 Test Loss: 0.4424182\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.2675577\n",
      "\tspeed: 0.0609s/iter; left time: 322.3693s\n",
      "\titers: 200, epoch: 15 | loss: 0.2826785\n",
      "\tspeed: 0.0195s/iter; left time: 101.2931s\n",
      "\titers: 300, epoch: 15 | loss: 0.2403086\n",
      "\tspeed: 0.0198s/iter; left time: 100.6845s\n",
      "\titers: 400, epoch: 15 | loss: 0.2554872\n",
      "\tspeed: 0.0200s/iter; left time: 99.8866s\n",
      "\titers: 500, epoch: 15 | loss: 0.2306364\n",
      "\tspeed: 0.0262s/iter; left time: 128.3847s\n",
      "\titers: 600, epoch: 15 | loss: 0.1986412\n",
      "\tspeed: 0.0244s/iter; left time: 116.8429s\n",
      "\titers: 700, epoch: 15 | loss: 0.2465286\n",
      "\tspeed: 0.0230s/iter; left time: 108.1119s\n",
      "\titers: 800, epoch: 15 | loss: 0.2492920\n",
      "\tspeed: 0.0181s/iter; left time: 83.1063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.84s\n",
      "Steps: 899 | Train Loss: 0.2542694 Vali Loss: 0.3907748 Test Loss: 0.4402420\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.2407851\n",
      "\tspeed: 0.0596s/iter; left time: 262.0983s\n",
      "\titers: 200, epoch: 16 | loss: 0.2604583\n",
      "\tspeed: 0.0190s/iter; left time: 81.5586s\n",
      "\titers: 300, epoch: 16 | loss: 0.2359287\n",
      "\tspeed: 0.0189s/iter; left time: 79.1355s\n",
      "\titers: 400, epoch: 16 | loss: 0.2062299\n",
      "\tspeed: 0.0193s/iter; left time: 78.8870s\n",
      "\titers: 500, epoch: 16 | loss: 0.2400995\n",
      "\tspeed: 0.0200s/iter; left time: 80.0954s\n",
      "\titers: 600, epoch: 16 | loss: 0.3302300\n",
      "\tspeed: 0.0201s/iter; left time: 78.3893s\n",
      "\titers: 700, epoch: 16 | loss: 0.2406563\n",
      "\tspeed: 0.0201s/iter; left time: 76.4397s\n",
      "\titers: 800, epoch: 16 | loss: 0.2455799\n",
      "\tspeed: 0.0186s/iter; left time: 68.6525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:17.53s\n",
      "Steps: 899 | Train Loss: 0.2520669 Vali Loss: 0.3927305 Test Loss: 0.4469537\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.3619433\n",
      "\tspeed: 0.0618s/iter; left time: 216.2754s\n",
      "\titers: 200, epoch: 17 | loss: 0.2037300\n",
      "\tspeed: 0.0195s/iter; left time: 66.1789s\n",
      "\titers: 300, epoch: 17 | loss: 0.2533571\n",
      "\tspeed: 0.0204s/iter; left time: 67.1678s\n",
      "\titers: 400, epoch: 17 | loss: 0.2131058\n",
      "\tspeed: 0.0223s/iter; left time: 71.2400s\n",
      "\titers: 500, epoch: 17 | loss: 0.2014949\n",
      "\tspeed: 0.0171s/iter; left time: 52.9500s\n",
      "\titers: 600, epoch: 17 | loss: 0.1992988\n",
      "\tspeed: 0.0166s/iter; left time: 49.8534s\n",
      "\titers: 700, epoch: 17 | loss: 0.2717407\n",
      "\tspeed: 0.0099s/iter; left time: 28.5705s\n",
      "\titers: 800, epoch: 17 | loss: 0.2505529\n",
      "\tspeed: 0.0088s/iter; left time: 24.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.61s\n",
      "Steps: 899 | Train Loss: 0.2505050 Vali Loss: 0.3886082 Test Loss: 0.4413072\n",
      "Validation loss decreased (0.390611 --> 0.388608).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1860594\n",
      "\tspeed: 0.0563s/iter; left time: 146.2323s\n",
      "\titers: 200, epoch: 18 | loss: 0.2555207\n",
      "\tspeed: 0.0216s/iter; left time: 53.8834s\n",
      "\titers: 300, epoch: 18 | loss: 0.2713555\n",
      "\tspeed: 0.0208s/iter; left time: 49.7800s\n",
      "\titers: 400, epoch: 18 | loss: 0.2479037\n",
      "\tspeed: 0.0196s/iter; left time: 45.0366s\n",
      "\titers: 500, epoch: 18 | loss: 0.2382314\n",
      "\tspeed: 0.0191s/iter; left time: 41.8834s\n",
      "\titers: 600, epoch: 18 | loss: 0.2409414\n",
      "\tspeed: 0.0190s/iter; left time: 39.8258s\n",
      "\titers: 700, epoch: 18 | loss: 0.3131574\n",
      "\tspeed: 0.0197s/iter; left time: 39.3537s\n",
      "\titers: 800, epoch: 18 | loss: 0.2037579\n",
      "\tspeed: 0.0188s/iter; left time: 35.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 899 | Train Loss: 0.2490653 Vali Loss: 0.3913469 Test Loss: 0.4465493\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.2871087\n",
      "\tspeed: 0.0642s/iter; left time: 109.1110s\n",
      "\titers: 200, epoch: 19 | loss: 0.2507946\n",
      "\tspeed: 0.0176s/iter; left time: 28.1469s\n",
      "\titers: 300, epoch: 19 | loss: 0.2903683\n",
      "\tspeed: 0.0170s/iter; left time: 25.4854s\n",
      "\titers: 400, epoch: 19 | loss: 0.2113480\n",
      "\tspeed: 0.0183s/iter; left time: 25.5988s\n",
      "\titers: 500, epoch: 19 | loss: 0.2786103\n",
      "\tspeed: 0.0166s/iter; left time: 21.5187s\n",
      "\titers: 600, epoch: 19 | loss: 0.2745212\n",
      "\tspeed: 0.0217s/iter; left time: 26.0334s\n",
      "\titers: 700, epoch: 19 | loss: 0.2470861\n",
      "\tspeed: 0.0211s/iter; left time: 23.1815s\n",
      "\titers: 800, epoch: 19 | loss: 0.2803708\n",
      "\tspeed: 0.0202s/iter; left time: 20.1869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:17.58s\n",
      "Steps: 899 | Train Loss: 0.2478971 Vali Loss: 0.3913135 Test Loss: 0.4452154\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2825477\n",
      "\tspeed: 0.0677s/iter; left time: 54.1585s\n",
      "\titers: 200, epoch: 20 | loss: 0.2089818\n",
      "\tspeed: 0.0220s/iter; left time: 15.4060s\n",
      "\titers: 300, epoch: 20 | loss: 0.2837274\n",
      "\tspeed: 0.0210s/iter; left time: 12.5783s\n",
      "\titers: 400, epoch: 20 | loss: 0.2633418\n",
      "\tspeed: 0.0212s/iter; left time: 10.5861s\n",
      "\titers: 500, epoch: 20 | loss: 0.1988058\n",
      "\tspeed: 0.0165s/iter; left time: 6.5977s\n",
      "\titers: 600, epoch: 20 | loss: 0.2672268\n",
      "\tspeed: 0.0146s/iter; left time: 4.3928s\n",
      "\titers: 700, epoch: 20 | loss: 0.2880944\n",
      "\tspeed: 0.0151s/iter; left time: 3.0180s\n",
      "\titers: 800, epoch: 20 | loss: 0.3261764\n",
      "\tspeed: 0.0087s/iter; left time: 0.8719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:16.43s\n",
      "Steps: 899 | Train Loss: 0.2465259 Vali Loss: 0.3922843 Test Loss: 0.4452493\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4413072168827057, rmse:0.664309561252594, mae:0.42702677845954895, rse:0.5257591009140015\n",
      "Original data scale mse:16442007.0, rmse:4054.87451171875, mae:2471.834228515625, rse:0.20161652565002441\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0036007\n",
      "\tspeed: 0.0403s/iter; left time: 718.8942s\n",
      "\titers: 200, epoch: 1 | loss: 0.8659157\n",
      "\tspeed: 0.0124s/iter; left time: 219.2353s\n",
      "\titers: 300, epoch: 1 | loss: 0.7883008\n",
      "\tspeed: 0.0148s/iter; left time: 260.4257s\n",
      "\titers: 400, epoch: 1 | loss: 0.6852372\n",
      "\tspeed: 0.0123s/iter; left time: 216.4550s\n",
      "\titers: 500, epoch: 1 | loss: 0.7147670\n",
      "\tspeed: 0.0109s/iter; left time: 190.1819s\n",
      "\titers: 600, epoch: 1 | loss: 0.8557405\n",
      "\tspeed: 0.0109s/iter; left time: 189.2505s\n",
      "\titers: 700, epoch: 1 | loss: 0.7494398\n",
      "\tspeed: 0.0116s/iter; left time: 199.1834s\n",
      "\titers: 800, epoch: 1 | loss: 0.7792521\n",
      "\tspeed: 0.0156s/iter; left time: 267.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 897 | Train Loss: 0.7829168 Vali Loss: 0.7323837 Test Loss: 0.8488080\n",
      "Validation loss decreased (inf --> 0.732384).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4927089\n",
      "\tspeed: 0.0604s/iter; left time: 1023.6589s\n",
      "\titers: 200, epoch: 2 | loss: 0.5134741\n",
      "\tspeed: 0.0202s/iter; left time: 340.9590s\n",
      "\titers: 300, epoch: 2 | loss: 0.3693707\n",
      "\tspeed: 0.0209s/iter; left time: 349.7866s\n",
      "\titers: 400, epoch: 2 | loss: 0.4823176\n",
      "\tspeed: 0.0188s/iter; left time: 313.6883s\n",
      "\titers: 500, epoch: 2 | loss: 0.4836394\n",
      "\tspeed: 0.0173s/iter; left time: 285.9309s\n",
      "\titers: 600, epoch: 2 | loss: 0.4998482\n",
      "\tspeed: 0.0207s/iter; left time: 339.9086s\n",
      "\titers: 700, epoch: 2 | loss: 0.4310081\n",
      "\tspeed: 0.0235s/iter; left time: 384.7308s\n",
      "\titers: 800, epoch: 2 | loss: 0.6791657\n",
      "\tspeed: 0.0250s/iter; left time: 405.3283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.26s\n",
      "Steps: 897 | Train Loss: 0.5522953 Vali Loss: 0.6377288 Test Loss: 0.7691358\n",
      "Validation loss decreased (0.732384 --> 0.637729).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4742892\n",
      "\tspeed: 0.0749s/iter; left time: 1201.3686s\n",
      "\titers: 200, epoch: 3 | loss: 0.5765079\n",
      "\tspeed: 0.0236s/iter; left time: 376.8228s\n",
      "\titers: 300, epoch: 3 | loss: 0.4968456\n",
      "\tspeed: 0.0137s/iter; left time: 217.1624s\n",
      "\titers: 400, epoch: 3 | loss: 0.5451829\n",
      "\tspeed: 0.0086s/iter; left time: 136.1675s\n",
      "\titers: 500, epoch: 3 | loss: 0.3946830\n",
      "\tspeed: 0.0086s/iter; left time: 134.9376s\n",
      "\titers: 600, epoch: 3 | loss: 0.4536867\n",
      "\tspeed: 0.0118s/iter; left time: 183.8856s\n",
      "\titers: 700, epoch: 3 | loss: 0.4801989\n",
      "\tspeed: 0.0178s/iter; left time: 274.8662s\n",
      "\titers: 800, epoch: 3 | loss: 0.4495756\n",
      "\tspeed: 0.0197s/iter; left time: 302.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 897 | Train Loss: 0.5144843 Vali Loss: 0.6382230 Test Loss: 0.7778355\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4739161\n",
      "\tspeed: 0.0629s/iter; left time: 952.6288s\n",
      "\titers: 200, epoch: 4 | loss: 0.5050730\n",
      "\tspeed: 0.0202s/iter; left time: 304.0285s\n",
      "\titers: 300, epoch: 4 | loss: 0.5803653\n",
      "\tspeed: 0.0193s/iter; left time: 288.2321s\n",
      "\titers: 400, epoch: 4 | loss: 0.3793481\n",
      "\tspeed: 0.0101s/iter; left time: 149.9726s\n",
      "\titers: 500, epoch: 4 | loss: 0.4313786\n",
      "\tspeed: 0.0101s/iter; left time: 149.2891s\n",
      "\titers: 600, epoch: 4 | loss: 0.5378112\n",
      "\tspeed: 0.0102s/iter; left time: 148.8133s\n",
      "\titers: 700, epoch: 4 | loss: 0.6757889\n",
      "\tspeed: 0.0160s/iter; left time: 233.4455s\n",
      "\titers: 800, epoch: 4 | loss: 0.4181479\n",
      "\tspeed: 0.0156s/iter; left time: 224.9289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.21s\n",
      "Steps: 897 | Train Loss: 0.4982164 Vali Loss: 0.6374664 Test Loss: 0.7833850\n",
      "Validation loss decreased (0.637729 --> 0.637466).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4235303\n",
      "\tspeed: 0.0641s/iter; left time: 913.6843s\n",
      "\titers: 200, epoch: 5 | loss: 0.5065235\n",
      "\tspeed: 0.0207s/iter; left time: 292.6842s\n",
      "\titers: 300, epoch: 5 | loss: 0.4971471\n",
      "\tspeed: 0.0218s/iter; left time: 306.9959s\n",
      "\titers: 400, epoch: 5 | loss: 0.4296460\n",
      "\tspeed: 0.0210s/iter; left time: 293.7091s\n",
      "\titers: 500, epoch: 5 | loss: 0.4853855\n",
      "\tspeed: 0.0195s/iter; left time: 270.0319s\n",
      "\titers: 600, epoch: 5 | loss: 0.4427166\n",
      "\tspeed: 0.0157s/iter; left time: 216.1422s\n",
      "\titers: 700, epoch: 5 | loss: 0.5283141\n",
      "\tspeed: 0.0117s/iter; left time: 159.4799s\n",
      "\titers: 800, epoch: 5 | loss: 0.5820613\n",
      "\tspeed: 0.0110s/iter; left time: 149.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 897 | Train Loss: 0.4786183 Vali Loss: 0.6581296 Test Loss: 0.8438063\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4811776\n",
      "\tspeed: 0.0522s/iter; left time: 696.5652s\n",
      "\titers: 200, epoch: 6 | loss: 0.4544136\n",
      "\tspeed: 0.0166s/iter; left time: 219.5111s\n",
      "\titers: 300, epoch: 6 | loss: 0.4330066\n",
      "\tspeed: 0.0186s/iter; left time: 244.2046s\n",
      "\titers: 400, epoch: 6 | loss: 0.4883741\n",
      "\tspeed: 0.0194s/iter; left time: 253.0707s\n",
      "\titers: 500, epoch: 6 | loss: 0.5200531\n",
      "\tspeed: 0.0212s/iter; left time: 274.4511s\n",
      "\titers: 600, epoch: 6 | loss: 0.3233039\n",
      "\tspeed: 0.0210s/iter; left time: 270.1936s\n",
      "\titers: 700, epoch: 6 | loss: 0.4925390\n",
      "\tspeed: 0.0219s/iter; left time: 279.9646s\n",
      "\titers: 800, epoch: 6 | loss: 0.4444473\n",
      "\tspeed: 0.0201s/iter; left time: 254.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.79s\n",
      "Steps: 897 | Train Loss: 0.4608661 Vali Loss: 0.6464520 Test Loss: 0.8377957\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4890899\n",
      "\tspeed: 0.0626s/iter; left time: 779.7163s\n",
      "\titers: 200, epoch: 7 | loss: 0.3894350\n",
      "\tspeed: 0.0197s/iter; left time: 243.5481s\n",
      "\titers: 300, epoch: 7 | loss: 0.5395073\n",
      "\tspeed: 0.0198s/iter; left time: 242.5713s\n",
      "\titers: 400, epoch: 7 | loss: 0.3752795\n",
      "\tspeed: 0.0188s/iter; left time: 228.1370s\n",
      "\titers: 500, epoch: 7 | loss: 0.4241392\n",
      "\tspeed: 0.0183s/iter; left time: 221.0702s\n",
      "\titers: 600, epoch: 7 | loss: 0.4259531\n",
      "\tspeed: 0.0194s/iter; left time: 231.9364s\n",
      "\titers: 700, epoch: 7 | loss: 0.4353227\n",
      "\tspeed: 0.0193s/iter; left time: 229.0933s\n",
      "\titers: 800, epoch: 7 | loss: 0.4062093\n",
      "\tspeed: 0.0197s/iter; left time: 231.1006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.13s\n",
      "Steps: 897 | Train Loss: 0.4445307 Vali Loss: 0.6452436 Test Loss: 0.8297157\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4766429\n",
      "\tspeed: 0.0582s/iter; left time: 673.4620s\n",
      "\titers: 200, epoch: 8 | loss: 0.3975609\n",
      "\tspeed: 0.0165s/iter; left time: 189.4013s\n",
      "\titers: 300, epoch: 8 | loss: 0.4251489\n",
      "\tspeed: 0.0162s/iter; left time: 184.0416s\n",
      "\titers: 400, epoch: 8 | loss: 0.4063973\n",
      "\tspeed: 0.0164s/iter; left time: 184.3686s\n",
      "\titers: 500, epoch: 8 | loss: 0.4645744\n",
      "\tspeed: 0.0171s/iter; left time: 191.1531s\n",
      "\titers: 600, epoch: 8 | loss: 0.3313241\n",
      "\tspeed: 0.0181s/iter; left time: 200.5089s\n",
      "\titers: 700, epoch: 8 | loss: 0.4924751\n",
      "\tspeed: 0.0167s/iter; left time: 182.7500s\n",
      "\titers: 800, epoch: 8 | loss: 0.4069167\n",
      "\tspeed: 0.0165s/iter; left time: 179.3401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.31s\n",
      "Steps: 897 | Train Loss: 0.4300141 Vali Loss: 0.6600727 Test Loss: 0.8497572\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.4901921\n",
      "\tspeed: 0.0587s/iter; left time: 626.2086s\n",
      "\titers: 200, epoch: 9 | loss: 0.5012779\n",
      "\tspeed: 0.0199s/iter; left time: 210.3235s\n",
      "\titers: 300, epoch: 9 | loss: 0.4554010\n",
      "\tspeed: 0.0219s/iter; left time: 229.1340s\n",
      "\titers: 400, epoch: 9 | loss: 0.3993935\n",
      "\tspeed: 0.0215s/iter; left time: 223.0161s\n",
      "\titers: 500, epoch: 9 | loss: 0.3993191\n",
      "\tspeed: 0.0214s/iter; left time: 219.7575s\n",
      "\titers: 600, epoch: 9 | loss: 0.4552777\n",
      "\tspeed: 0.0220s/iter; left time: 223.9906s\n",
      "\titers: 700, epoch: 9 | loss: 0.4633452\n",
      "\tspeed: 0.0196s/iter; left time: 197.5764s\n",
      "\titers: 800, epoch: 9 | loss: 0.3318105\n",
      "\tspeed: 0.0201s/iter; left time: 200.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.89s\n",
      "Steps: 897 | Train Loss: 0.4168187 Vali Loss: 0.6642299 Test Loss: 0.8599736\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7833850383758545, rmse:0.8850904107093811, mae:0.6169462203979492, rse:0.701985776424408\n",
      "Original data scale mse:32124580.0, rmse:5667.85498046875, mae:3648.32373046875, rse:0.2822612226009369\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0687970\n",
      "\tspeed: 0.0194s/iter; left time: 345.8491s\n",
      "\titers: 200, epoch: 1 | loss: 0.7686523\n",
      "\tspeed: 0.0162s/iter; left time: 288.2023s\n",
      "\titers: 300, epoch: 1 | loss: 0.7562232\n",
      "\tspeed: 0.0167s/iter; left time: 295.1956s\n",
      "\titers: 400, epoch: 1 | loss: 0.7929258\n",
      "\tspeed: 0.0164s/iter; left time: 286.8426s\n",
      "\titers: 500, epoch: 1 | loss: 0.8766662\n",
      "\tspeed: 0.0161s/iter; left time: 281.2747s\n",
      "\titers: 600, epoch: 1 | loss: 0.6665626\n",
      "\tspeed: 0.0172s/iter; left time: 298.7554s\n",
      "\titers: 700, epoch: 1 | loss: 0.6320493\n",
      "\tspeed: 0.0206s/iter; left time: 354.7916s\n",
      "\titers: 800, epoch: 1 | loss: 0.6784168\n",
      "\tspeed: 0.0194s/iter; left time: 333.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.13s\n",
      "Steps: 897 | Train Loss: 0.7800162 Vali Loss: 0.7335658 Test Loss: 0.8474568\n",
      "Validation loss decreased (inf --> 0.733566).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6880530\n",
      "\tspeed: 0.0624s/iter; left time: 1057.1211s\n",
      "\titers: 200, epoch: 2 | loss: 0.4602619\n",
      "\tspeed: 0.0147s/iter; left time: 247.7576s\n",
      "\titers: 300, epoch: 2 | loss: 0.5445536\n",
      "\tspeed: 0.0102s/iter; left time: 170.1044s\n",
      "\titers: 400, epoch: 2 | loss: 0.4921171\n",
      "\tspeed: 0.0102s/iter; left time: 169.0634s\n",
      "\titers: 500, epoch: 2 | loss: 0.4060183\n",
      "\tspeed: 0.0101s/iter; left time: 167.7652s\n",
      "\titers: 600, epoch: 2 | loss: 0.5637963\n",
      "\tspeed: 0.0102s/iter; left time: 167.0603s\n",
      "\titers: 700, epoch: 2 | loss: 0.5291440\n",
      "\tspeed: 0.0102s/iter; left time: 166.1373s\n",
      "\titers: 800, epoch: 2 | loss: 0.5387043\n",
      "\tspeed: 0.0101s/iter; left time: 164.8757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.67s\n",
      "Steps: 897 | Train Loss: 0.5507675 Vali Loss: 0.6433254 Test Loss: 0.7773381\n",
      "Validation loss decreased (0.733566 --> 0.643325).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5210739\n",
      "\tspeed: 0.0546s/iter; left time: 876.2423s\n",
      "\titers: 200, epoch: 3 | loss: 0.4844965\n",
      "\tspeed: 0.0196s/iter; left time: 312.4332s\n",
      "\titers: 300, epoch: 3 | loss: 0.6088915\n",
      "\tspeed: 0.0183s/iter; left time: 290.2094s\n",
      "\titers: 400, epoch: 3 | loss: 0.5037915\n",
      "\tspeed: 0.0184s/iter; left time: 289.2805s\n",
      "\titers: 500, epoch: 3 | loss: 0.4920396\n",
      "\tspeed: 0.0190s/iter; left time: 297.6064s\n",
      "\titers: 600, epoch: 3 | loss: 0.5419345\n",
      "\tspeed: 0.0192s/iter; left time: 298.0589s\n",
      "\titers: 700, epoch: 3 | loss: 0.4696251\n",
      "\tspeed: 0.0190s/iter; left time: 294.1538s\n",
      "\titers: 800, epoch: 3 | loss: 0.5837649\n",
      "\tspeed: 0.0196s/iter; left time: 301.5088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.33s\n",
      "Steps: 897 | Train Loss: 0.5133748 Vali Loss: 0.6299555 Test Loss: 0.7692862\n",
      "Validation loss decreased (0.643325 --> 0.629955).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5113783\n",
      "\tspeed: 0.0648s/iter; left time: 982.1972s\n",
      "\titers: 200, epoch: 4 | loss: 0.5887691\n",
      "\tspeed: 0.0207s/iter; left time: 311.9692s\n",
      "\titers: 300, epoch: 4 | loss: 0.4869276\n",
      "\tspeed: 0.0189s/iter; left time: 282.9658s\n",
      "\titers: 400, epoch: 4 | loss: 0.4299963\n",
      "\tspeed: 0.0193s/iter; left time: 286.5479s\n",
      "\titers: 500, epoch: 4 | loss: 0.4331246\n",
      "\tspeed: 0.0198s/iter; left time: 291.4867s\n",
      "\titers: 600, epoch: 4 | loss: 0.5348747\n",
      "\tspeed: 0.0177s/iter; left time: 259.1907s\n",
      "\titers: 700, epoch: 4 | loss: 0.4952002\n",
      "\tspeed: 0.0177s/iter; left time: 257.5405s\n",
      "\titers: 800, epoch: 4 | loss: 0.6168691\n",
      "\tspeed: 0.0181s/iter; left time: 262.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.08s\n",
      "Steps: 897 | Train Loss: 0.4952388 Vali Loss: 0.6461816 Test Loss: 0.7820819\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4502559\n",
      "\tspeed: 0.0586s/iter; left time: 834.7570s\n",
      "\titers: 200, epoch: 5 | loss: 0.4602151\n",
      "\tspeed: 0.0182s/iter; left time: 257.0639s\n",
      "\titers: 300, epoch: 5 | loss: 0.4068995\n",
      "\tspeed: 0.0183s/iter; left time: 257.8522s\n",
      "\titers: 400, epoch: 5 | loss: 0.5471209\n",
      "\tspeed: 0.0184s/iter; left time: 257.3595s\n",
      "\titers: 500, epoch: 5 | loss: 0.4812470\n",
      "\tspeed: 0.0182s/iter; left time: 252.0712s\n",
      "\titers: 600, epoch: 5 | loss: 0.4610892\n",
      "\tspeed: 0.0177s/iter; left time: 243.8833s\n",
      "\titers: 700, epoch: 5 | loss: 0.4922692\n",
      "\tspeed: 0.0185s/iter; left time: 251.9341s\n",
      "\titers: 800, epoch: 5 | loss: 0.5340741\n",
      "\tspeed: 0.0097s/iter; left time: 131.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:14.84s\n",
      "Steps: 897 | Train Loss: 0.4751102 Vali Loss: 0.6631474 Test Loss: 0.8063862\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4342424\n",
      "\tspeed: 0.0501s/iter; left time: 668.7240s\n",
      "\titers: 200, epoch: 6 | loss: 0.5546813\n",
      "\tspeed: 0.0153s/iter; left time: 202.6059s\n",
      "\titers: 300, epoch: 6 | loss: 0.4666362\n",
      "\tspeed: 0.0154s/iter; left time: 202.1674s\n",
      "\titers: 400, epoch: 6 | loss: 0.4635126\n",
      "\tspeed: 0.0153s/iter; left time: 199.7276s\n",
      "\titers: 500, epoch: 6 | loss: 0.5330849\n",
      "\tspeed: 0.0190s/iter; left time: 245.7535s\n",
      "\titers: 600, epoch: 6 | loss: 0.3967457\n",
      "\tspeed: 0.0176s/iter; left time: 226.4980s\n",
      "\titers: 700, epoch: 6 | loss: 0.4910803\n",
      "\tspeed: 0.0160s/iter; left time: 204.7100s\n",
      "\titers: 800, epoch: 6 | loss: 0.4278677\n",
      "\tspeed: 0.0169s/iter; left time: 214.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.01s\n",
      "Steps: 897 | Train Loss: 0.4565768 Vali Loss: 0.6628345 Test Loss: 0.8228671\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4364097\n",
      "\tspeed: 0.0582s/iter; left time: 725.4347s\n",
      "\titers: 200, epoch: 7 | loss: 0.5361828\n",
      "\tspeed: 0.0169s/iter; left time: 209.3768s\n",
      "\titers: 300, epoch: 7 | loss: 0.3912697\n",
      "\tspeed: 0.0167s/iter; left time: 205.2586s\n",
      "\titers: 400, epoch: 7 | loss: 0.4271880\n",
      "\tspeed: 0.0193s/iter; left time: 234.3952s\n",
      "\titers: 500, epoch: 7 | loss: 0.3556538\n",
      "\tspeed: 0.0200s/iter; left time: 241.7772s\n",
      "\titers: 600, epoch: 7 | loss: 0.4458830\n",
      "\tspeed: 0.0195s/iter; left time: 232.9961s\n",
      "\titers: 700, epoch: 7 | loss: 0.4163972\n",
      "\tspeed: 0.0195s/iter; left time: 231.6707s\n",
      "\titers: 800, epoch: 7 | loss: 0.4731756\n",
      "\tspeed: 0.0196s/iter; left time: 230.7792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.25s\n",
      "Steps: 897 | Train Loss: 0.4392845 Vali Loss: 0.6680853 Test Loss: 0.8326235\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3645411\n",
      "\tspeed: 0.0626s/iter; left time: 723.3915s\n",
      "\titers: 200, epoch: 8 | loss: 0.3439595\n",
      "\tspeed: 0.0202s/iter; left time: 232.0510s\n",
      "\titers: 300, epoch: 8 | loss: 0.4295338\n",
      "\tspeed: 0.0223s/iter; left time: 253.2346s\n",
      "\titers: 400, epoch: 8 | loss: 0.4484139\n",
      "\tspeed: 0.0201s/iter; left time: 226.0160s\n",
      "\titers: 500, epoch: 8 | loss: 0.4293389\n",
      "\tspeed: 0.0219s/iter; left time: 244.8618s\n",
      "\titers: 600, epoch: 8 | loss: 0.4293092\n",
      "\tspeed: 0.0217s/iter; left time: 239.6483s\n",
      "\titers: 700, epoch: 8 | loss: 0.3937083\n",
      "\tspeed: 0.0213s/iter; left time: 233.4373s\n",
      "\titers: 800, epoch: 8 | loss: 0.3453960\n",
      "\tspeed: 0.0235s/iter; left time: 255.3092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.38s\n",
      "Steps: 897 | Train Loss: 0.4246813 Vali Loss: 0.6693804 Test Loss: 0.8523927\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7692865133285522, rmse:0.87708979845047, mae:0.6145855188369751, rse:0.6956402659416199\n",
      "Original data scale mse:31628942.0, rmse:5623.96142578125, mae:3646.1298828125, rse:0.2800752818584442\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0956208\n",
      "\tspeed: 0.0420s/iter; left time: 746.2679s\n",
      "\titers: 200, epoch: 1 | loss: 0.7801767\n",
      "\tspeed: 0.0155s/iter; left time: 273.9515s\n",
      "\titers: 300, epoch: 1 | loss: 0.7709496\n",
      "\tspeed: 0.0171s/iter; left time: 300.7054s\n",
      "\titers: 400, epoch: 1 | loss: 0.7498941\n",
      "\tspeed: 0.0129s/iter; left time: 226.3443s\n",
      "\titers: 500, epoch: 1 | loss: 0.8669528\n",
      "\tspeed: 0.0176s/iter; left time: 305.6137s\n",
      "\titers: 600, epoch: 1 | loss: 0.8242336\n",
      "\tspeed: 0.0187s/iter; left time: 323.2937s\n",
      "\titers: 700, epoch: 1 | loss: 0.8320199\n",
      "\tspeed: 0.0186s/iter; left time: 319.3237s\n",
      "\titers: 800, epoch: 1 | loss: 0.6797956\n",
      "\tspeed: 0.0166s/iter; left time: 283.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.15s\n",
      "Steps: 894 | Train Loss: 0.8208512 Vali Loss: 0.7704357 Test Loss: 0.9012622\n",
      "Validation loss decreased (inf --> 0.770436).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6499233\n",
      "\tspeed: 0.0587s/iter; left time: 991.1208s\n",
      "\titers: 200, epoch: 2 | loss: 0.9092157\n",
      "\tspeed: 0.0165s/iter; left time: 277.3014s\n",
      "\titers: 300, epoch: 2 | loss: 0.5533442\n",
      "\tspeed: 0.0194s/iter; left time: 323.9378s\n",
      "\titers: 400, epoch: 2 | loss: 0.8615104\n",
      "\tspeed: 0.0192s/iter; left time: 318.8109s\n",
      "\titers: 500, epoch: 2 | loss: 0.5892518\n",
      "\tspeed: 0.0164s/iter; left time: 270.3101s\n",
      "\titers: 600, epoch: 2 | loss: 0.6250470\n",
      "\tspeed: 0.0164s/iter; left time: 269.1537s\n",
      "\titers: 700, epoch: 2 | loss: 0.7007781\n",
      "\tspeed: 0.0166s/iter; left time: 269.6584s\n",
      "\titers: 800, epoch: 2 | loss: 0.5500090\n",
      "\tspeed: 0.0164s/iter; left time: 265.3311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 894 | Train Loss: 0.6055586 Vali Loss: 0.6945205 Test Loss: 0.8520532\n",
      "Validation loss decreased (0.770436 --> 0.694520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6147045\n",
      "\tspeed: 0.0589s/iter; left time: 942.2978s\n",
      "\titers: 200, epoch: 3 | loss: 0.5172254\n",
      "\tspeed: 0.0181s/iter; left time: 287.0324s\n",
      "\titers: 300, epoch: 3 | loss: 0.4611413\n",
      "\tspeed: 0.0187s/iter; left time: 296.0969s\n",
      "\titers: 400, epoch: 3 | loss: 0.5876907\n",
      "\tspeed: 0.0204s/iter; left time: 320.7414s\n",
      "\titers: 500, epoch: 3 | loss: 0.6051956\n",
      "\tspeed: 0.0210s/iter; left time: 327.7882s\n",
      "\titers: 600, epoch: 3 | loss: 0.5900452\n",
      "\tspeed: 0.0197s/iter; left time: 305.1591s\n",
      "\titers: 700, epoch: 3 | loss: 0.5743088\n",
      "\tspeed: 0.0206s/iter; left time: 317.8074s\n",
      "\titers: 800, epoch: 3 | loss: 0.5886582\n",
      "\tspeed: 0.0210s/iter; left time: 321.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.75s\n",
      "Steps: 894 | Train Loss: 0.5630152 Vali Loss: 0.6922977 Test Loss: 0.8303193\n",
      "Validation loss decreased (0.694520 --> 0.692298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4679174\n",
      "\tspeed: 0.0575s/iter; left time: 867.7011s\n",
      "\titers: 200, epoch: 4 | loss: 0.4449886\n",
      "\tspeed: 0.0181s/iter; left time: 271.4180s\n",
      "\titers: 300, epoch: 4 | loss: 0.5926356\n",
      "\tspeed: 0.0167s/iter; left time: 248.6898s\n",
      "\titers: 400, epoch: 4 | loss: 0.4241680\n",
      "\tspeed: 0.0165s/iter; left time: 244.2103s\n",
      "\titers: 500, epoch: 4 | loss: 0.5667193\n",
      "\tspeed: 0.0174s/iter; left time: 255.5311s\n",
      "\titers: 600, epoch: 4 | loss: 0.4736584\n",
      "\tspeed: 0.0161s/iter; left time: 234.7975s\n",
      "\titers: 700, epoch: 4 | loss: 0.5231259\n",
      "\tspeed: 0.0159s/iter; left time: 229.9819s\n",
      "\titers: 800, epoch: 4 | loss: 0.5141959\n",
      "\tspeed: 0.0161s/iter; left time: 232.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.13s\n",
      "Steps: 894 | Train Loss: 0.5415957 Vali Loss: 0.7117304 Test Loss: 0.8507312\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4656080\n",
      "\tspeed: 0.0571s/iter; left time: 811.6833s\n",
      "\titers: 200, epoch: 5 | loss: 0.4797681\n",
      "\tspeed: 0.0162s/iter; left time: 228.1840s\n",
      "\titers: 300, epoch: 5 | loss: 0.5143790\n",
      "\tspeed: 0.0173s/iter; left time: 242.2697s\n",
      "\titers: 400, epoch: 5 | loss: 0.5228068\n",
      "\tspeed: 0.0192s/iter; left time: 266.3108s\n",
      "\titers: 500, epoch: 5 | loss: 0.5840532\n",
      "\tspeed: 0.0194s/iter; left time: 268.4744s\n",
      "\titers: 600, epoch: 5 | loss: 0.4919373\n",
      "\tspeed: 0.0181s/iter; left time: 248.7230s\n",
      "\titers: 700, epoch: 5 | loss: 0.5470178\n",
      "\tspeed: 0.0192s/iter; left time: 261.1803s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578973\n",
      "\tspeed: 0.0196s/iter; left time: 264.9539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 894 | Train Loss: 0.5157234 Vali Loss: 0.7126273 Test Loss: 0.8551058\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5758048\n",
      "\tspeed: 0.0648s/iter; left time: 862.9900s\n",
      "\titers: 200, epoch: 6 | loss: 0.4904285\n",
      "\tspeed: 0.0211s/iter; left time: 278.3081s\n",
      "\titers: 300, epoch: 6 | loss: 0.5029606\n",
      "\tspeed: 0.0088s/iter; left time: 115.2979s\n",
      "\titers: 400, epoch: 6 | loss: 0.4250714\n",
      "\tspeed: 0.0086s/iter; left time: 112.4033s\n",
      "\titers: 500, epoch: 6 | loss: 0.4621000\n",
      "\tspeed: 0.0114s/iter; left time: 147.4539s\n",
      "\titers: 600, epoch: 6 | loss: 0.4402039\n",
      "\tspeed: 0.0178s/iter; left time: 227.8918s\n",
      "\titers: 700, epoch: 6 | loss: 0.5502896\n",
      "\tspeed: 0.0185s/iter; left time: 234.7149s\n",
      "\titers: 800, epoch: 6 | loss: 0.4418719\n",
      "\tspeed: 0.0184s/iter; left time: 232.0734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.87s\n",
      "Steps: 894 | Train Loss: 0.4929694 Vali Loss: 0.7266393 Test Loss: 0.8745056\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5691193\n",
      "\tspeed: 0.0643s/iter; left time: 798.8660s\n",
      "\titers: 200, epoch: 7 | loss: 0.4533247\n",
      "\tspeed: 0.0202s/iter; left time: 248.5718s\n",
      "\titers: 300, epoch: 7 | loss: 0.4294037\n",
      "\tspeed: 0.0189s/iter; left time: 230.4482s\n",
      "\titers: 400, epoch: 7 | loss: 0.4727524\n",
      "\tspeed: 0.0201s/iter; left time: 243.6369s\n",
      "\titers: 500, epoch: 7 | loss: 0.4465404\n",
      "\tspeed: 0.0202s/iter; left time: 243.1814s\n",
      "\titers: 600, epoch: 7 | loss: 0.4881567\n",
      "\tspeed: 0.0199s/iter; left time: 237.1258s\n",
      "\titers: 700, epoch: 7 | loss: 0.4089688\n",
      "\tspeed: 0.0202s/iter; left time: 239.2192s\n",
      "\titers: 800, epoch: 7 | loss: 0.4918151\n",
      "\tspeed: 0.0206s/iter; left time: 240.9440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.09s\n",
      "Steps: 894 | Train Loss: 0.4734343 Vali Loss: 0.7337018 Test Loss: 0.8781210\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4792354\n",
      "\tspeed: 0.0651s/iter; left time: 750.2738s\n",
      "\titers: 200, epoch: 8 | loss: 0.4782509\n",
      "\tspeed: 0.0204s/iter; left time: 233.0211s\n",
      "\titers: 300, epoch: 8 | loss: 0.4927977\n",
      "\tspeed: 0.0203s/iter; left time: 229.3939s\n",
      "\titers: 400, epoch: 8 | loss: 0.4295945\n",
      "\tspeed: 0.0215s/iter; left time: 241.7631s\n",
      "\titers: 500, epoch: 8 | loss: 0.3864942\n",
      "\tspeed: 0.0211s/iter; left time: 235.0585s\n",
      "\titers: 600, epoch: 8 | loss: 0.4497687\n",
      "\tspeed: 0.0204s/iter; left time: 225.2679s\n",
      "\titers: 700, epoch: 8 | loss: 0.4909022\n",
      "\tspeed: 0.0213s/iter; left time: 232.1585s\n",
      "\titers: 800, epoch: 8 | loss: 0.4710271\n",
      "\tspeed: 0.0202s/iter; left time: 218.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.75s\n",
      "Steps: 894 | Train Loss: 0.4588768 Vali Loss: 0.7633100 Test Loss: 0.8961230\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8303201198577881, rmse:0.9112190008163452, mae:0.6474009156227112, rse:0.721846878528595\n",
      "Original data scale mse:34333700.0, rmse:5859.49658203125, mae:3841.31005859375, rse:0.2919482886791229\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9197516\n",
      "\tspeed: 0.0229s/iter; left time: 406.3790s\n",
      "\titers: 200, epoch: 1 | loss: 0.8550282\n",
      "\tspeed: 0.0199s/iter; left time: 351.1025s\n",
      "\titers: 300, epoch: 1 | loss: 0.7692910\n",
      "\tspeed: 0.0200s/iter; left time: 352.4801s\n",
      "\titers: 400, epoch: 1 | loss: 0.7845767\n",
      "\tspeed: 0.0200s/iter; left time: 349.7211s\n",
      "\titers: 500, epoch: 1 | loss: 0.7254980\n",
      "\tspeed: 0.0196s/iter; left time: 340.6415s\n",
      "\titers: 600, epoch: 1 | loss: 0.6560377\n",
      "\tspeed: 0.0197s/iter; left time: 340.9105s\n",
      "\titers: 700, epoch: 1 | loss: 0.6567000\n",
      "\tspeed: 0.0226s/iter; left time: 388.4519s\n",
      "\titers: 800, epoch: 1 | loss: 0.7396338\n",
      "\tspeed: 0.0213s/iter; left time: 363.8601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 894 | Train Loss: 0.8187022 Vali Loss: 0.7705207 Test Loss: 0.9003298\n",
      "Validation loss decreased (inf --> 0.770521).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6568864\n",
      "\tspeed: 0.0667s/iter; left time: 1126.2606s\n",
      "\titers: 200, epoch: 2 | loss: 0.6184781\n",
      "\tspeed: 0.0201s/iter; left time: 338.1633s\n",
      "\titers: 300, epoch: 2 | loss: 0.5858054\n",
      "\tspeed: 0.0194s/iter; left time: 323.2420s\n",
      "\titers: 400, epoch: 2 | loss: 0.5742517\n",
      "\tspeed: 0.0197s/iter; left time: 327.0161s\n",
      "\titers: 500, epoch: 2 | loss: 0.6324476\n",
      "\tspeed: 0.0193s/iter; left time: 318.0973s\n",
      "\titers: 600, epoch: 2 | loss: 0.5573840\n",
      "\tspeed: 0.0201s/iter; left time: 329.1402s\n",
      "\titers: 700, epoch: 2 | loss: 0.5113344\n",
      "\tspeed: 0.0225s/iter; left time: 365.9367s\n",
      "\titers: 800, epoch: 2 | loss: 0.6749502\n",
      "\tspeed: 0.0206s/iter; left time: 334.1333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.52s\n",
      "Steps: 894 | Train Loss: 0.6042834 Vali Loss: 0.6905153 Test Loss: 0.8392124\n",
      "Validation loss decreased (0.770521 --> 0.690515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6191050\n",
      "\tspeed: 0.0694s/iter; left time: 1109.1923s\n",
      "\titers: 200, epoch: 3 | loss: 0.6146412\n",
      "\tspeed: 0.0186s/iter; left time: 295.1714s\n",
      "\titers: 300, epoch: 3 | loss: 0.5809900\n",
      "\tspeed: 0.0192s/iter; left time: 303.5473s\n",
      "\titers: 400, epoch: 3 | loss: 0.6193781\n",
      "\tspeed: 0.0195s/iter; left time: 306.2619s\n",
      "\titers: 500, epoch: 3 | loss: 0.7234859\n",
      "\tspeed: 0.0196s/iter; left time: 305.9990s\n",
      "\titers: 600, epoch: 3 | loss: 0.4507079\n",
      "\tspeed: 0.0193s/iter; left time: 299.1162s\n",
      "\titers: 700, epoch: 3 | loss: 0.4401181\n",
      "\tspeed: 0.0192s/iter; left time: 294.9579s\n",
      "\titers: 800, epoch: 3 | loss: 0.5963544\n",
      "\tspeed: 0.0196s/iter; left time: 300.1722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.75s\n",
      "Steps: 894 | Train Loss: 0.5627134 Vali Loss: 0.7037000 Test Loss: 0.8708781\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4359128\n",
      "\tspeed: 0.0625s/iter; left time: 943.9221s\n",
      "\titers: 200, epoch: 4 | loss: 0.4941487\n",
      "\tspeed: 0.0198s/iter; left time: 296.3251s\n",
      "\titers: 300, epoch: 4 | loss: 0.4924490\n",
      "\tspeed: 0.0200s/iter; left time: 297.8219s\n",
      "\titers: 400, epoch: 4 | loss: 0.4683858\n",
      "\tspeed: 0.0192s/iter; left time: 283.9984s\n",
      "\titers: 500, epoch: 4 | loss: 0.4863323\n",
      "\tspeed: 0.0180s/iter; left time: 264.9963s\n",
      "\titers: 600, epoch: 4 | loss: 0.5580907\n",
      "\tspeed: 0.0205s/iter; left time: 298.7491s\n",
      "\titers: 700, epoch: 4 | loss: 0.6247132\n",
      "\tspeed: 0.0229s/iter; left time: 332.1968s\n",
      "\titers: 800, epoch: 4 | loss: 0.5251081\n",
      "\tspeed: 0.0209s/iter; left time: 301.4472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.18s\n",
      "Steps: 894 | Train Loss: 0.5428145 Vali Loss: 0.7042475 Test Loss: 0.8581391\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5090364\n",
      "\tspeed: 0.0673s/iter; left time: 956.3391s\n",
      "\titers: 200, epoch: 5 | loss: 0.5216534\n",
      "\tspeed: 0.0215s/iter; left time: 303.0432s\n",
      "\titers: 300, epoch: 5 | loss: 0.5150718\n",
      "\tspeed: 0.0173s/iter; left time: 241.6129s\n",
      "\titers: 400, epoch: 5 | loss: 0.5160028\n",
      "\tspeed: 0.0216s/iter; left time: 300.6103s\n",
      "\titers: 500, epoch: 5 | loss: 0.3896942\n",
      "\tspeed: 0.0228s/iter; left time: 315.1899s\n",
      "\titers: 600, epoch: 5 | loss: 0.4397736\n",
      "\tspeed: 0.0229s/iter; left time: 313.3486s\n",
      "\titers: 700, epoch: 5 | loss: 0.6378150\n",
      "\tspeed: 0.0226s/iter; left time: 307.6629s\n",
      "\titers: 800, epoch: 5 | loss: 0.5385353\n",
      "\tspeed: 0.0197s/iter; left time: 265.6299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.27s\n",
      "Steps: 894 | Train Loss: 0.5175077 Vali Loss: 0.7065778 Test Loss: 0.8820719\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4335459\n",
      "\tspeed: 0.0651s/iter; left time: 866.1426s\n",
      "\titers: 200, epoch: 6 | loss: 0.5169556\n",
      "\tspeed: 0.0198s/iter; left time: 261.0296s\n",
      "\titers: 300, epoch: 6 | loss: 0.4900910\n",
      "\tspeed: 0.0196s/iter; left time: 256.8395s\n",
      "\titers: 400, epoch: 6 | loss: 0.5887069\n",
      "\tspeed: 0.0186s/iter; left time: 242.4365s\n",
      "\titers: 500, epoch: 6 | loss: 0.5098942\n",
      "\tspeed: 0.0188s/iter; left time: 242.6276s\n",
      "\titers: 600, epoch: 6 | loss: 0.4063497\n",
      "\tspeed: 0.0186s/iter; left time: 238.6962s\n",
      "\titers: 700, epoch: 6 | loss: 0.4667610\n",
      "\tspeed: 0.0192s/iter; left time: 244.5962s\n",
      "\titers: 800, epoch: 6 | loss: 0.6042527\n",
      "\tspeed: 0.0209s/iter; left time: 263.5325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.66s\n",
      "Steps: 894 | Train Loss: 0.4926305 Vali Loss: 0.7257166 Test Loss: 0.8983177\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4660062\n",
      "\tspeed: 0.0674s/iter; left time: 837.3217s\n",
      "\titers: 200, epoch: 7 | loss: 0.5022681\n",
      "\tspeed: 0.0206s/iter; left time: 253.2316s\n",
      "\titers: 300, epoch: 7 | loss: 0.4632101\n",
      "\tspeed: 0.0200s/iter; left time: 244.6719s\n",
      "\titers: 400, epoch: 7 | loss: 0.4312131\n",
      "\tspeed: 0.0185s/iter; left time: 224.6086s\n",
      "\titers: 500, epoch: 7 | loss: 0.4130993\n",
      "\tspeed: 0.0178s/iter; left time: 213.4307s\n",
      "\titers: 600, epoch: 7 | loss: 0.5274547\n",
      "\tspeed: 0.0190s/iter; left time: 226.8962s\n",
      "\titers: 700, epoch: 7 | loss: 0.4688942\n",
      "\tspeed: 0.0194s/iter; left time: 229.3504s\n",
      "\titers: 800, epoch: 7 | loss: 0.4521865\n",
      "\tspeed: 0.0179s/iter; left time: 209.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.88s\n",
      "Steps: 894 | Train Loss: 0.4735116 Vali Loss: 0.7454515 Test Loss: 0.9066114\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8392124772071838, rmse:0.916085422039032, mae:0.6532085537910461, rse:0.7257018685340881\n",
      "Original data scale mse:35108288.0, rmse:5925.224609375, mae:3900.470947265625, rse:0.2952231466770172\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8021022\n",
      "\tspeed: 0.0406s/iter; left time: 726.1419s\n",
      "\titers: 200, epoch: 1 | loss: 0.6925995\n",
      "\tspeed: 0.0109s/iter; left time: 194.4804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5909751\n",
      "\tspeed: 0.0109s/iter; left time: 192.9879s\n",
      "\titers: 400, epoch: 1 | loss: 0.6011810\n",
      "\tspeed: 0.0109s/iter; left time: 191.1855s\n",
      "\titers: 500, epoch: 1 | loss: 0.5824918\n",
      "\tspeed: 0.0109s/iter; left time: 190.4994s\n",
      "\titers: 600, epoch: 1 | loss: 0.5279900\n",
      "\tspeed: 0.0109s/iter; left time: 189.3403s\n",
      "\titers: 700, epoch: 1 | loss: 0.5047048\n",
      "\tspeed: 0.0109s/iter; left time: 188.6852s\n",
      "\titers: 800, epoch: 1 | loss: 0.5128719\n",
      "\tspeed: 0.0109s/iter; left time: 187.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.38s\n",
      "Steps: 899 | Train Loss: 0.6012422 Vali Loss: 0.5246476 Test Loss: 0.5354317\n",
      "Validation loss decreased (inf --> 0.524648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4713942\n",
      "\tspeed: 0.0518s/iter; left time: 879.1281s\n",
      "\titers: 200, epoch: 2 | loss: 0.4152257\n",
      "\tspeed: 0.0172s/iter; left time: 289.9767s\n",
      "\titers: 300, epoch: 2 | loss: 0.4338688\n",
      "\tspeed: 0.0168s/iter; left time: 282.7242s\n",
      "\titers: 400, epoch: 2 | loss: 0.3667082\n",
      "\tspeed: 0.0170s/iter; left time: 283.8197s\n",
      "\titers: 500, epoch: 2 | loss: 0.3763907\n",
      "\tspeed: 0.0176s/iter; left time: 292.0303s\n",
      "\titers: 600, epoch: 2 | loss: 0.3366058\n",
      "\tspeed: 0.0202s/iter; left time: 332.3794s\n",
      "\titers: 700, epoch: 2 | loss: 0.3254713\n",
      "\tspeed: 0.0214s/iter; left time: 350.5500s\n",
      "\titers: 800, epoch: 2 | loss: 0.3705050\n",
      "\tspeed: 0.0211s/iter; left time: 344.0565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 899 | Train Loss: 0.4006373 Vali Loss: 0.4264728 Test Loss: 0.4378735\n",
      "Validation loss decreased (0.524648 --> 0.426473).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3245873\n",
      "\tspeed: 0.0647s/iter; left time: 1041.2503s\n",
      "\titers: 200, epoch: 3 | loss: 0.4314593\n",
      "\tspeed: 0.0190s/iter; left time: 304.0933s\n",
      "\titers: 300, epoch: 3 | loss: 0.3731487\n",
      "\tspeed: 0.0209s/iter; left time: 332.6729s\n",
      "\titers: 400, epoch: 3 | loss: 0.3511240\n",
      "\tspeed: 0.0173s/iter; left time: 272.6576s\n",
      "\titers: 500, epoch: 3 | loss: 0.3729074\n",
      "\tspeed: 0.0196s/iter; left time: 307.1529s\n",
      "\titers: 600, epoch: 3 | loss: 0.3496314\n",
      "\tspeed: 0.0203s/iter; left time: 315.7072s\n",
      "\titers: 700, epoch: 3 | loss: 0.3591028\n",
      "\tspeed: 0.0210s/iter; left time: 324.4343s\n",
      "\titers: 800, epoch: 3 | loss: 0.3763874\n",
      "\tspeed: 0.0197s/iter; left time: 303.2801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.99s\n",
      "Steps: 899 | Train Loss: 0.3691757 Vali Loss: 0.4183326 Test Loss: 0.4306229\n",
      "Validation loss decreased (0.426473 --> 0.418333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4066237\n",
      "\tspeed: 0.0652s/iter; left time: 990.4252s\n",
      "\titers: 200, epoch: 4 | loss: 0.3509343\n",
      "\tspeed: 0.0193s/iter; left time: 291.2284s\n",
      "\titers: 300, epoch: 4 | loss: 0.4020855\n",
      "\tspeed: 0.0192s/iter; left time: 288.0459s\n",
      "\titers: 400, epoch: 4 | loss: 0.3351272\n",
      "\tspeed: 0.0204s/iter; left time: 304.3253s\n",
      "\titers: 500, epoch: 4 | loss: 0.3231093\n",
      "\tspeed: 0.0200s/iter; left time: 296.0429s\n",
      "\titers: 600, epoch: 4 | loss: 0.3337501\n",
      "\tspeed: 0.0198s/iter; left time: 290.6340s\n",
      "\titers: 700, epoch: 4 | loss: 0.3343820\n",
      "\tspeed: 0.0211s/iter; left time: 307.5918s\n",
      "\titers: 800, epoch: 4 | loss: 0.3345044\n",
      "\tspeed: 0.0224s/iter; left time: 324.8658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 899 | Train Loss: 0.3591887 Vali Loss: 0.4129920 Test Loss: 0.4246629\n",
      "Validation loss decreased (0.418333 --> 0.412992).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4359350\n",
      "\tspeed: 0.0642s/iter; left time: 917.6187s\n",
      "\titers: 200, epoch: 5 | loss: 0.3883935\n",
      "\tspeed: 0.0243s/iter; left time: 344.3582s\n",
      "\titers: 300, epoch: 5 | loss: 0.3174652\n",
      "\tspeed: 0.0245s/iter; left time: 345.7636s\n",
      "\titers: 400, epoch: 5 | loss: 0.3357159\n",
      "\tspeed: 0.0245s/iter; left time: 342.6472s\n",
      "\titers: 500, epoch: 5 | loss: 0.3804760\n",
      "\tspeed: 0.0232s/iter; left time: 322.5969s\n",
      "\titers: 600, epoch: 5 | loss: 0.3102888\n",
      "\tspeed: 0.0246s/iter; left time: 338.5599s\n",
      "\titers: 700, epoch: 5 | loss: 0.3804379\n",
      "\tspeed: 0.0247s/iter; left time: 338.3317s\n",
      "\titers: 800, epoch: 5 | loss: 0.3525660\n",
      "\tspeed: 0.0244s/iter; left time: 331.1641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:21.64s\n",
      "Steps: 899 | Train Loss: 0.3519248 Vali Loss: 0.4065509 Test Loss: 0.4212925\n",
      "Validation loss decreased (0.412992 --> 0.406551).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3748753\n",
      "\tspeed: 0.0700s/iter; left time: 937.4610s\n",
      "\titers: 200, epoch: 6 | loss: 0.3444988\n",
      "\tspeed: 0.0227s/iter; left time: 301.8372s\n",
      "\titers: 300, epoch: 6 | loss: 0.3125870\n",
      "\tspeed: 0.0230s/iter; left time: 302.7161s\n",
      "\titers: 400, epoch: 6 | loss: 0.3483710\n",
      "\tspeed: 0.0204s/iter; left time: 267.2010s\n",
      "\titers: 500, epoch: 6 | loss: 0.2937910\n",
      "\tspeed: 0.0204s/iter; left time: 264.4659s\n",
      "\titers: 600, epoch: 6 | loss: 0.3081765\n",
      "\tspeed: 0.0204s/iter; left time: 262.9963s\n",
      "\titers: 700, epoch: 6 | loss: 0.3740537\n",
      "\tspeed: 0.0201s/iter; left time: 257.0805s\n",
      "\titers: 800, epoch: 6 | loss: 0.3556362\n",
      "\tspeed: 0.0200s/iter; left time: 253.7644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.19s\n",
      "Steps: 899 | Train Loss: 0.3474589 Vali Loss: 0.4025504 Test Loss: 0.4170190\n",
      "Validation loss decreased (0.406551 --> 0.402550).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4134621\n",
      "\tspeed: 0.0636s/iter; left time: 793.7449s\n",
      "\titers: 200, epoch: 7 | loss: 0.3164629\n",
      "\tspeed: 0.0198s/iter; left time: 244.8109s\n",
      "\titers: 300, epoch: 7 | loss: 0.4240907\n",
      "\tspeed: 0.0197s/iter; left time: 242.5240s\n",
      "\titers: 400, epoch: 7 | loss: 0.3781630\n",
      "\tspeed: 0.0198s/iter; left time: 241.8022s\n",
      "\titers: 500, epoch: 7 | loss: 0.3582739\n",
      "\tspeed: 0.0189s/iter; left time: 228.3434s\n",
      "\titers: 600, epoch: 7 | loss: 0.3242267\n",
      "\tspeed: 0.0198s/iter; left time: 237.5381s\n",
      "\titers: 700, epoch: 7 | loss: 0.3117477\n",
      "\tspeed: 0.0199s/iter; left time: 236.7747s\n",
      "\titers: 800, epoch: 7 | loss: 0.3922064\n",
      "\tspeed: 0.0199s/iter; left time: 234.7952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.03s\n",
      "Steps: 899 | Train Loss: 0.3432503 Vali Loss: 0.4033894 Test Loss: 0.4181160\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3459639\n",
      "\tspeed: 0.0623s/iter; left time: 722.0496s\n",
      "\titers: 200, epoch: 8 | loss: 0.3298652\n",
      "\tspeed: 0.0185s/iter; left time: 212.1786s\n",
      "\titers: 300, epoch: 8 | loss: 0.3398317\n",
      "\tspeed: 0.0195s/iter; left time: 222.4249s\n",
      "\titers: 400, epoch: 8 | loss: 0.3470849\n",
      "\tspeed: 0.0196s/iter; left time: 221.0657s\n",
      "\titers: 500, epoch: 8 | loss: 0.3479287\n",
      "\tspeed: 0.0155s/iter; left time: 173.2927s\n",
      "\titers: 600, epoch: 8 | loss: 0.3302499\n",
      "\tspeed: 0.0148s/iter; left time: 163.6577s\n",
      "\titers: 700, epoch: 8 | loss: 0.3836888\n",
      "\tspeed: 0.0164s/iter; left time: 180.4386s\n",
      "\titers: 800, epoch: 8 | loss: 0.3206917\n",
      "\tspeed: 0.0170s/iter; left time: 185.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 899 | Train Loss: 0.3401877 Vali Loss: 0.4012586 Test Loss: 0.4156455\n",
      "Validation loss decreased (0.402550 --> 0.401259).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3365163\n",
      "\tspeed: 0.0701s/iter; left time: 749.7717s\n",
      "\titers: 200, epoch: 9 | loss: 0.3980308\n",
      "\tspeed: 0.0204s/iter; left time: 215.5426s\n",
      "\titers: 300, epoch: 9 | loss: 0.3654304\n",
      "\tspeed: 0.0202s/iter; left time: 211.7215s\n",
      "\titers: 400, epoch: 9 | loss: 0.3431937\n",
      "\tspeed: 0.0204s/iter; left time: 211.4451s\n",
      "\titers: 500, epoch: 9 | loss: 0.3301879\n",
      "\tspeed: 0.0197s/iter; left time: 202.2974s\n",
      "\titers: 600, epoch: 9 | loss: 0.2898274\n",
      "\tspeed: 0.0199s/iter; left time: 202.3904s\n",
      "\titers: 700, epoch: 9 | loss: 0.3798852\n",
      "\tspeed: 0.0198s/iter; left time: 199.4453s\n",
      "\titers: 800, epoch: 9 | loss: 0.3374563\n",
      "\tspeed: 0.0204s/iter; left time: 203.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.54s\n",
      "Steps: 899 | Train Loss: 0.3380893 Vali Loss: 0.4003658 Test Loss: 0.4144184\n",
      "Validation loss decreased (0.401259 --> 0.400366).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2748985\n",
      "\tspeed: 0.0637s/iter; left time: 623.5131s\n",
      "\titers: 200, epoch: 10 | loss: 0.2892882\n",
      "\tspeed: 0.0198s/iter; left time: 191.6426s\n",
      "\titers: 300, epoch: 10 | loss: 0.3452616\n",
      "\tspeed: 0.0204s/iter; left time: 195.4609s\n",
      "\titers: 400, epoch: 10 | loss: 0.3137925\n",
      "\tspeed: 0.0204s/iter; left time: 193.9893s\n",
      "\titers: 500, epoch: 10 | loss: 0.3288341\n",
      "\tspeed: 0.0200s/iter; left time: 187.7470s\n",
      "\titers: 600, epoch: 10 | loss: 0.3502923\n",
      "\tspeed: 0.0202s/iter; left time: 187.4810s\n",
      "\titers: 700, epoch: 10 | loss: 0.3483107\n",
      "\tspeed: 0.0203s/iter; left time: 186.1908s\n",
      "\titers: 800, epoch: 10 | loss: 0.3366393\n",
      "\tspeed: 0.0203s/iter; left time: 184.1550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:18.44s\n",
      "Steps: 899 | Train Loss: 0.3358505 Vali Loss: 0.3992815 Test Loss: 0.4151999\n",
      "Validation loss decreased (0.400366 --> 0.399282).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.3204281\n",
      "\tspeed: 0.0647s/iter; left time: 574.9712s\n",
      "\titers: 200, epoch: 11 | loss: 0.3622302\n",
      "\tspeed: 0.0201s/iter; left time: 176.4523s\n",
      "\titers: 300, epoch: 11 | loss: 0.2878516\n",
      "\tspeed: 0.0190s/iter; left time: 165.0276s\n",
      "\titers: 400, epoch: 11 | loss: 0.2957679\n",
      "\tspeed: 0.0164s/iter; left time: 140.8817s\n",
      "\titers: 500, epoch: 11 | loss: 0.2958245\n",
      "\tspeed: 0.0168s/iter; left time: 142.8368s\n",
      "\titers: 600, epoch: 11 | loss: 0.3760688\n",
      "\tspeed: 0.0163s/iter; left time: 136.3733s\n",
      "\titers: 700, epoch: 11 | loss: 0.3425786\n",
      "\tspeed: 0.0168s/iter; left time: 139.5581s\n",
      "\titers: 800, epoch: 11 | loss: 0.3351161\n",
      "\tspeed: 0.0165s/iter; left time: 135.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.39s\n",
      "Steps: 899 | Train Loss: 0.3337537 Vali Loss: 0.3987756 Test Loss: 0.4149699\n",
      "Validation loss decreased (0.399282 --> 0.398776).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.3482745\n",
      "\tspeed: 0.0618s/iter; left time: 493.6766s\n",
      "\titers: 200, epoch: 12 | loss: 0.3422210\n",
      "\tspeed: 0.0205s/iter; left time: 162.0581s\n",
      "\titers: 300, epoch: 12 | loss: 0.3441858\n",
      "\tspeed: 0.0177s/iter; left time: 138.3058s\n",
      "\titers: 400, epoch: 12 | loss: 0.3296596\n",
      "\tspeed: 0.0140s/iter; left time: 107.4538s\n",
      "\titers: 500, epoch: 12 | loss: 0.3003051\n",
      "\tspeed: 0.0163s/iter; left time: 124.1145s\n",
      "\titers: 600, epoch: 12 | loss: 0.3317191\n",
      "\tspeed: 0.0199s/iter; left time: 148.9826s\n",
      "\titers: 700, epoch: 12 | loss: 0.3417106\n",
      "\tspeed: 0.0192s/iter; left time: 142.2726s\n",
      "\titers: 800, epoch: 12 | loss: 0.3538938\n",
      "\tspeed: 0.0219s/iter; left time: 159.3591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 899 | Train Loss: 0.3324552 Vali Loss: 0.3984899 Test Loss: 0.4129417\n",
      "Validation loss decreased (0.398776 --> 0.398490).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.3029528\n",
      "\tspeed: 0.0630s/iter; left time: 446.9801s\n",
      "\titers: 200, epoch: 13 | loss: 0.3160040\n",
      "\tspeed: 0.0199s/iter; left time: 139.5089s\n",
      "\titers: 300, epoch: 13 | loss: 0.3143843\n",
      "\tspeed: 0.0205s/iter; left time: 141.2669s\n",
      "\titers: 400, epoch: 13 | loss: 0.3354486\n",
      "\tspeed: 0.0196s/iter; left time: 133.0517s\n",
      "\titers: 500, epoch: 13 | loss: 0.2745283\n",
      "\tspeed: 0.0197s/iter; left time: 131.8864s\n",
      "\titers: 600, epoch: 13 | loss: 0.3366205\n",
      "\tspeed: 0.0199s/iter; left time: 131.2044s\n",
      "\titers: 700, epoch: 13 | loss: 0.3074122\n",
      "\tspeed: 0.0201s/iter; left time: 130.2205s\n",
      "\titers: 800, epoch: 13 | loss: 0.3574967\n",
      "\tspeed: 0.0197s/iter; left time: 126.2552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 899 | Train Loss: 0.3306730 Vali Loss: 0.3987166 Test Loss: 0.4134080\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.3147757\n",
      "\tspeed: 0.0642s/iter; left time: 397.8504s\n",
      "\titers: 200, epoch: 14 | loss: 0.3396772\n",
      "\tspeed: 0.0200s/iter; left time: 122.0331s\n",
      "\titers: 300, epoch: 14 | loss: 0.3204018\n",
      "\tspeed: 0.0196s/iter; left time: 117.3829s\n",
      "\titers: 400, epoch: 14 | loss: 0.3299358\n",
      "\tspeed: 0.0193s/iter; left time: 113.5343s\n",
      "\titers: 500, epoch: 14 | loss: 0.3511822\n",
      "\tspeed: 0.0197s/iter; left time: 114.1117s\n",
      "\titers: 600, epoch: 14 | loss: 0.3334781\n",
      "\tspeed: 0.0197s/iter; left time: 112.3741s\n",
      "\titers: 700, epoch: 14 | loss: 0.3416737\n",
      "\tspeed: 0.0202s/iter; left time: 113.0165s\n",
      "\titers: 800, epoch: 14 | loss: 0.3460114\n",
      "\tspeed: 0.0200s/iter; left time: 109.7604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 899 | Train Loss: 0.3298737 Vali Loss: 0.3963216 Test Loss: 0.4107592\n",
      "Validation loss decreased (0.398490 --> 0.396322).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.3186268\n",
      "\tspeed: 0.0646s/iter; left time: 341.9785s\n",
      "\titers: 200, epoch: 15 | loss: 0.3245509\n",
      "\tspeed: 0.0193s/iter; left time: 100.1391s\n",
      "\titers: 300, epoch: 15 | loss: 0.3586107\n",
      "\tspeed: 0.0199s/iter; left time: 101.5384s\n",
      "\titers: 400, epoch: 15 | loss: 0.3333652\n",
      "\tspeed: 0.0200s/iter; left time: 99.8220s\n",
      "\titers: 500, epoch: 15 | loss: 0.3217432\n",
      "\tspeed: 0.0203s/iter; left time: 99.3275s\n",
      "\titers: 600, epoch: 15 | loss: 0.3317134\n",
      "\tspeed: 0.0197s/iter; left time: 94.6178s\n",
      "\titers: 700, epoch: 15 | loss: 0.3255295\n",
      "\tspeed: 0.0202s/iter; left time: 94.9152s\n",
      "\titers: 800, epoch: 15 | loss: 0.3389094\n",
      "\tspeed: 0.0199s/iter; left time: 91.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 899 | Train Loss: 0.3287469 Vali Loss: 0.3984874 Test Loss: 0.4125227\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.3324057\n",
      "\tspeed: 0.0621s/iter; left time: 272.8934s\n",
      "\titers: 200, epoch: 16 | loss: 0.3357552\n",
      "\tspeed: 0.0187s/iter; left time: 80.4854s\n",
      "\titers: 300, epoch: 16 | loss: 0.3005940\n",
      "\tspeed: 0.0171s/iter; left time: 71.8137s\n",
      "\titers: 400, epoch: 16 | loss: 0.3388161\n",
      "\tspeed: 0.0190s/iter; left time: 77.9257s\n",
      "\titers: 500, epoch: 16 | loss: 0.3945983\n",
      "\tspeed: 0.0192s/iter; left time: 76.8482s\n",
      "\titers: 600, epoch: 16 | loss: 0.3372350\n",
      "\tspeed: 0.0182s/iter; left time: 70.8632s\n",
      "\titers: 700, epoch: 16 | loss: 0.3668875\n",
      "\tspeed: 0.0194s/iter; left time: 73.7207s\n",
      "\titers: 800, epoch: 16 | loss: 0.3084440\n",
      "\tspeed: 0.0198s/iter; left time: 73.2098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 899 | Train Loss: 0.3275084 Vali Loss: 0.3968629 Test Loss: 0.4119792\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.3498313\n",
      "\tspeed: 0.0625s/iter; left time: 218.4118s\n",
      "\titers: 200, epoch: 17 | loss: 0.3882523\n",
      "\tspeed: 0.0202s/iter; left time: 68.5033s\n",
      "\titers: 300, epoch: 17 | loss: 0.3590245\n",
      "\tspeed: 0.0199s/iter; left time: 65.6745s\n",
      "\titers: 400, epoch: 17 | loss: 0.3475539\n",
      "\tspeed: 0.0198s/iter; left time: 63.4264s\n",
      "\titers: 500, epoch: 17 | loss: 0.3129906\n",
      "\tspeed: 0.0197s/iter; left time: 61.0204s\n",
      "\titers: 600, epoch: 17 | loss: 0.3182841\n",
      "\tspeed: 0.0200s/iter; left time: 59.9583s\n",
      "\titers: 700, epoch: 17 | loss: 0.3276173\n",
      "\tspeed: 0.0201s/iter; left time: 58.1653s\n",
      "\titers: 800, epoch: 17 | loss: 0.3194119\n",
      "\tspeed: 0.0193s/iter; left time: 54.1093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 899 | Train Loss: 0.3267280 Vali Loss: 0.3977921 Test Loss: 0.4115823\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.3323283\n",
      "\tspeed: 0.0649s/iter; left time: 168.7105s\n",
      "\titers: 200, epoch: 18 | loss: 0.3527871\n",
      "\tspeed: 0.0196s/iter; left time: 48.9199s\n",
      "\titers: 300, epoch: 18 | loss: 0.3126848\n",
      "\tspeed: 0.0202s/iter; left time: 48.4840s\n",
      "\titers: 400, epoch: 18 | loss: 0.3332240\n",
      "\tspeed: 0.0195s/iter; left time: 44.7692s\n",
      "\titers: 500, epoch: 18 | loss: 0.3180348\n",
      "\tspeed: 0.0199s/iter; left time: 43.7548s\n",
      "\titers: 600, epoch: 18 | loss: 0.3772245\n",
      "\tspeed: 0.0200s/iter; left time: 42.0349s\n",
      "\titers: 700, epoch: 18 | loss: 0.3090008\n",
      "\tspeed: 0.0194s/iter; left time: 38.7106s\n",
      "\titers: 800, epoch: 18 | loss: 0.3447495\n",
      "\tspeed: 0.0203s/iter; left time: 38.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 899 | Train Loss: 0.3259955 Vali Loss: 0.3963337 Test Loss: 0.4117657\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.2862276\n",
      "\tspeed: 0.0626s/iter; left time: 106.3045s\n",
      "\titers: 200, epoch: 19 | loss: 0.2734141\n",
      "\tspeed: 0.0203s/iter; left time: 32.3873s\n",
      "\titers: 300, epoch: 19 | loss: 0.3490064\n",
      "\tspeed: 0.0201s/iter; left time: 30.2011s\n",
      "\titers: 400, epoch: 19 | loss: 0.3303302\n",
      "\tspeed: 0.0197s/iter; left time: 27.6074s\n",
      "\titers: 500, epoch: 19 | loss: 0.3080081\n",
      "\tspeed: 0.0203s/iter; left time: 26.4217s\n",
      "\titers: 600, epoch: 19 | loss: 0.3179322\n",
      "\tspeed: 0.0197s/iter; left time: 23.5816s\n",
      "\titers: 700, epoch: 19 | loss: 0.3100714\n",
      "\tspeed: 0.0197s/iter; left time: 21.6725s\n",
      "\titers: 800, epoch: 19 | loss: 0.2744577\n",
      "\tspeed: 0.0198s/iter; left time: 19.8015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.13s\n",
      "Steps: 899 | Train Loss: 0.3252018 Vali Loss: 0.3950129 Test Loss: 0.4106197\n",
      "Validation loss decreased (0.396322 --> 0.395013).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2854564\n",
      "\tspeed: 0.0638s/iter; left time: 51.0021s\n",
      "\titers: 200, epoch: 20 | loss: 0.3361687\n",
      "\tspeed: 0.0208s/iter; left time: 14.5560s\n",
      "\titers: 300, epoch: 20 | loss: 0.3174141\n",
      "\tspeed: 0.0206s/iter; left time: 12.3575s\n",
      "\titers: 400, epoch: 20 | loss: 0.3466935\n",
      "\tspeed: 0.0198s/iter; left time: 9.9174s\n",
      "\titers: 500, epoch: 20 | loss: 0.3229813\n",
      "\tspeed: 0.0184s/iter; left time: 7.3780s\n",
      "\titers: 600, epoch: 20 | loss: 0.3351645\n",
      "\tspeed: 0.0170s/iter; left time: 5.0930s\n",
      "\titers: 700, epoch: 20 | loss: 0.3589825\n",
      "\tspeed: 0.0171s/iter; left time: 3.4226s\n",
      "\titers: 800, epoch: 20 | loss: 0.2811244\n",
      "\tspeed: 0.0172s/iter; left time: 1.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:17.16s\n",
      "Steps: 899 | Train Loss: 0.3245955 Vali Loss: 0.3971672 Test Loss: 0.4119253\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4441284239292145, rmse:0.6664296388626099, mae:0.41061973571777344, rse:0.5274369716644287\n",
      "Original data scale mse:16317905.0, rmse:4039.542724609375, mae:2366.62255859375, rse:0.20085419714450836\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7716169\n",
      "\tspeed: 0.0196s/iter; left time: 350.5128s\n",
      "\titers: 200, epoch: 1 | loss: 0.7095734\n",
      "\tspeed: 0.0187s/iter; left time: 332.6389s\n",
      "\titers: 300, epoch: 1 | loss: 0.5834948\n",
      "\tspeed: 0.0187s/iter; left time: 330.5179s\n",
      "\titers: 400, epoch: 1 | loss: 0.5468243\n",
      "\tspeed: 0.0189s/iter; left time: 332.0737s\n",
      "\titers: 500, epoch: 1 | loss: 0.5882546\n",
      "\tspeed: 0.0198s/iter; left time: 345.4561s\n",
      "\titers: 600, epoch: 1 | loss: 0.5179299\n",
      "\tspeed: 0.0204s/iter; left time: 355.4155s\n",
      "\titers: 700, epoch: 1 | loss: 0.6194155\n",
      "\tspeed: 0.0229s/iter; left time: 395.5561s\n",
      "\titers: 800, epoch: 1 | loss: 0.4697834\n",
      "\tspeed: 0.0234s/iter; left time: 401.2854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.29s\n",
      "Steps: 899 | Train Loss: 0.6033202 Vali Loss: 0.5319014 Test Loss: 0.5408735\n",
      "Validation loss decreased (inf --> 0.531901).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4368583\n",
      "\tspeed: 0.0648s/iter; left time: 1099.8322s\n",
      "\titers: 200, epoch: 2 | loss: 0.3791084\n",
      "\tspeed: 0.0201s/iter; left time: 339.5153s\n",
      "\titers: 300, epoch: 2 | loss: 0.3995365\n",
      "\tspeed: 0.0202s/iter; left time: 338.3377s\n",
      "\titers: 400, epoch: 2 | loss: 0.4028520\n",
      "\tspeed: 0.0211s/iter; left time: 352.5399s\n",
      "\titers: 500, epoch: 2 | loss: 0.4257081\n",
      "\tspeed: 0.0201s/iter; left time: 332.8498s\n",
      "\titers: 600, epoch: 2 | loss: 0.3855752\n",
      "\tspeed: 0.0199s/iter; left time: 327.6044s\n",
      "\titers: 700, epoch: 2 | loss: 0.3628248\n",
      "\tspeed: 0.0194s/iter; left time: 318.5174s\n",
      "\titers: 800, epoch: 2 | loss: 0.3913488\n",
      "\tspeed: 0.0199s/iter; left time: 323.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.34s\n",
      "Steps: 899 | Train Loss: 0.4000261 Vali Loss: 0.4293926 Test Loss: 0.4381313\n",
      "Validation loss decreased (0.531901 --> 0.429393).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3720330\n",
      "\tspeed: 0.0654s/iter; left time: 1052.6120s\n",
      "\titers: 200, epoch: 3 | loss: 0.3860038\n",
      "\tspeed: 0.0201s/iter; left time: 320.5143s\n",
      "\titers: 300, epoch: 3 | loss: 0.4171456\n",
      "\tspeed: 0.0198s/iter; left time: 314.6655s\n",
      "\titers: 400, epoch: 3 | loss: 0.3384024\n",
      "\tspeed: 0.0209s/iter; left time: 329.5333s\n",
      "\titers: 500, epoch: 3 | loss: 0.3361163\n",
      "\tspeed: 0.0200s/iter; left time: 313.1787s\n",
      "\titers: 600, epoch: 3 | loss: 0.3757119\n",
      "\tspeed: 0.0203s/iter; left time: 315.5972s\n",
      "\titers: 700, epoch: 3 | loss: 0.3830750\n",
      "\tspeed: 0.0197s/iter; left time: 304.3333s\n",
      "\titers: 800, epoch: 3 | loss: 0.3459322\n",
      "\tspeed: 0.0193s/iter; left time: 297.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.31s\n",
      "Steps: 899 | Train Loss: 0.3691167 Vali Loss: 0.4176632 Test Loss: 0.4308388\n",
      "Validation loss decreased (0.429393 --> 0.417663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3203915\n",
      "\tspeed: 0.0652s/iter; left time: 990.6536s\n",
      "\titers: 200, epoch: 4 | loss: 0.3591068\n",
      "\tspeed: 0.0201s/iter; left time: 303.6648s\n",
      "\titers: 300, epoch: 4 | loss: 0.3693196\n",
      "\tspeed: 0.0204s/iter; left time: 304.9261s\n",
      "\titers: 400, epoch: 4 | loss: 0.3333595\n",
      "\tspeed: 0.0224s/iter; left time: 333.9703s\n",
      "\titers: 500, epoch: 4 | loss: 0.3576100\n",
      "\tspeed: 0.0215s/iter; left time: 318.1030s\n",
      "\titers: 600, epoch: 4 | loss: 0.3260174\n",
      "\tspeed: 0.0190s/iter; left time: 279.2351s\n",
      "\titers: 700, epoch: 4 | loss: 0.3668792\n",
      "\tspeed: 0.0166s/iter; left time: 241.4003s\n",
      "\titers: 800, epoch: 4 | loss: 0.4007554\n",
      "\tspeed: 0.0173s/iter; left time: 250.6958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.61s\n",
      "Steps: 899 | Train Loss: 0.3590103 Vali Loss: 0.4133446 Test Loss: 0.4259665\n",
      "Validation loss decreased (0.417663 --> 0.413345).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4414760\n",
      "\tspeed: 0.0591s/iter; left time: 844.6818s\n",
      "\titers: 200, epoch: 5 | loss: 0.3445090\n",
      "\tspeed: 0.0200s/iter; left time: 283.0884s\n",
      "\titers: 300, epoch: 5 | loss: 0.3410396\n",
      "\tspeed: 0.0221s/iter; left time: 311.5617s\n",
      "\titers: 400, epoch: 5 | loss: 0.3608033\n",
      "\tspeed: 0.0197s/iter; left time: 275.6978s\n",
      "\titers: 500, epoch: 5 | loss: 0.3670435\n",
      "\tspeed: 0.0196s/iter; left time: 272.0368s\n",
      "\titers: 600, epoch: 5 | loss: 0.3587507\n",
      "\tspeed: 0.0203s/iter; left time: 279.1512s\n",
      "\titers: 700, epoch: 5 | loss: 0.3597054\n",
      "\tspeed: 0.0194s/iter; left time: 265.1120s\n",
      "\titers: 800, epoch: 5 | loss: 0.3563690\n",
      "\tspeed: 0.0207s/iter; left time: 280.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.38s\n",
      "Steps: 899 | Train Loss: 0.3522467 Vali Loss: 0.4131323 Test Loss: 0.4252283\n",
      "Validation loss decreased (0.413345 --> 0.413132).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3444853\n",
      "\tspeed: 0.0664s/iter; left time: 889.4476s\n",
      "\titers: 200, epoch: 6 | loss: 0.2970652\n",
      "\tspeed: 0.0202s/iter; left time: 267.9227s\n",
      "\titers: 300, epoch: 6 | loss: 0.3702722\n",
      "\tspeed: 0.0204s/iter; left time: 269.2412s\n",
      "\titers: 400, epoch: 6 | loss: 0.3533135\n",
      "\tspeed: 0.0205s/iter; left time: 267.9277s\n",
      "\titers: 500, epoch: 6 | loss: 0.3430129\n",
      "\tspeed: 0.0203s/iter; left time: 263.9222s\n",
      "\titers: 600, epoch: 6 | loss: 0.3308817\n",
      "\tspeed: 0.0203s/iter; left time: 261.4888s\n",
      "\titers: 700, epoch: 6 | loss: 0.3118897\n",
      "\tspeed: 0.0207s/iter; left time: 265.0232s\n",
      "\titers: 800, epoch: 6 | loss: 0.3372318\n",
      "\tspeed: 0.0207s/iter; left time: 262.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.80s\n",
      "Steps: 899 | Train Loss: 0.3470957 Vali Loss: 0.4062421 Test Loss: 0.4185499\n",
      "Validation loss decreased (0.413132 --> 0.406242).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3395274\n",
      "\tspeed: 0.0647s/iter; left time: 808.4672s\n",
      "\titers: 200, epoch: 7 | loss: 0.3366167\n",
      "\tspeed: 0.0216s/iter; left time: 267.2069s\n",
      "\titers: 300, epoch: 7 | loss: 0.3837367\n",
      "\tspeed: 0.0212s/iter; left time: 260.7454s\n",
      "\titers: 400, epoch: 7 | loss: 0.3464078\n",
      "\tspeed: 0.0223s/iter; left time: 271.9915s\n",
      "\titers: 500, epoch: 7 | loss: 0.3941433\n",
      "\tspeed: 0.0203s/iter; left time: 245.7574s\n",
      "\titers: 600, epoch: 7 | loss: 0.3534853\n",
      "\tspeed: 0.0201s/iter; left time: 241.1127s\n",
      "\titers: 700, epoch: 7 | loss: 0.3343861\n",
      "\tspeed: 0.0201s/iter; left time: 239.2373s\n",
      "\titers: 800, epoch: 7 | loss: 0.3437279\n",
      "\tspeed: 0.0197s/iter; left time: 232.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.84s\n",
      "Steps: 899 | Train Loss: 0.3437673 Vali Loss: 0.4025058 Test Loss: 0.4169584\n",
      "Validation loss decreased (0.406242 --> 0.402506).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3392353\n",
      "\tspeed: 0.0621s/iter; left time: 719.4471s\n",
      "\titers: 200, epoch: 8 | loss: 0.3697390\n",
      "\tspeed: 0.0148s/iter; left time: 170.4555s\n",
      "\titers: 300, epoch: 8 | loss: 0.2895991\n",
      "\tspeed: 0.0198s/iter; left time: 224.9973s\n",
      "\titers: 400, epoch: 8 | loss: 0.3416536\n",
      "\tspeed: 0.0227s/iter; left time: 256.7078s\n",
      "\titers: 500, epoch: 8 | loss: 0.3193199\n",
      "\tspeed: 0.0203s/iter; left time: 226.8480s\n",
      "\titers: 600, epoch: 8 | loss: 0.3137123\n",
      "\tspeed: 0.0188s/iter; left time: 208.3800s\n",
      "\titers: 700, epoch: 8 | loss: 0.3403561\n",
      "\tspeed: 0.0198s/iter; left time: 217.7416s\n",
      "\titers: 800, epoch: 8 | loss: 0.3357542\n",
      "\tspeed: 0.0211s/iter; left time: 230.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 899 | Train Loss: 0.3407841 Vali Loss: 0.4036917 Test Loss: 0.4170645\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3217978\n",
      "\tspeed: 0.0655s/iter; left time: 700.5587s\n",
      "\titers: 200, epoch: 9 | loss: 0.3279561\n",
      "\tspeed: 0.0201s/iter; left time: 213.2199s\n",
      "\titers: 300, epoch: 9 | loss: 0.3186089\n",
      "\tspeed: 0.0198s/iter; left time: 208.0525s\n",
      "\titers: 400, epoch: 9 | loss: 0.3760067\n",
      "\tspeed: 0.0203s/iter; left time: 210.5812s\n",
      "\titers: 500, epoch: 9 | loss: 0.3551838\n",
      "\tspeed: 0.0202s/iter; left time: 207.6221s\n",
      "\titers: 600, epoch: 9 | loss: 0.3764420\n",
      "\tspeed: 0.0196s/iter; left time: 199.9947s\n",
      "\titers: 700, epoch: 9 | loss: 0.3166426\n",
      "\tspeed: 0.0197s/iter; left time: 199.0045s\n",
      "\titers: 800, epoch: 9 | loss: 0.3161252\n",
      "\tspeed: 0.0199s/iter; left time: 198.5529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.10s\n",
      "Steps: 899 | Train Loss: 0.3378858 Vali Loss: 0.4031201 Test Loss: 0.4157779\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.3361924\n",
      "\tspeed: 0.0642s/iter; left time: 628.9685s\n",
      "\titers: 200, epoch: 10 | loss: 0.3215369\n",
      "\tspeed: 0.0202s/iter; left time: 195.7818s\n",
      "\titers: 300, epoch: 10 | loss: 0.3170817\n",
      "\tspeed: 0.0199s/iter; left time: 190.8188s\n",
      "\titers: 400, epoch: 10 | loss: 0.3601951\n",
      "\tspeed: 0.0212s/iter; left time: 201.4049s\n",
      "\titers: 500, epoch: 10 | loss: 0.3217819\n",
      "\tspeed: 0.0202s/iter; left time: 189.9432s\n",
      "\titers: 600, epoch: 10 | loss: 0.3629886\n",
      "\tspeed: 0.0200s/iter; left time: 185.6293s\n",
      "\titers: 700, epoch: 10 | loss: 0.3226629\n",
      "\tspeed: 0.0208s/iter; left time: 191.1529s\n",
      "\titers: 800, epoch: 10 | loss: 0.3406248\n",
      "\tspeed: 0.0225s/iter; left time: 204.8327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:19.05s\n",
      "Steps: 899 | Train Loss: 0.3361287 Vali Loss: 0.4015146 Test Loss: 0.4144256\n",
      "Validation loss decreased (0.402506 --> 0.401515).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.3531895\n",
      "\tspeed: 0.0689s/iter; left time: 612.7710s\n",
      "\titers: 200, epoch: 11 | loss: 0.3330749\n",
      "\tspeed: 0.0243s/iter; left time: 213.9436s\n",
      "\titers: 300, epoch: 11 | loss: 0.3143811\n",
      "\tspeed: 0.0223s/iter; left time: 193.8815s\n",
      "\titers: 400, epoch: 11 | loss: 0.3223464\n",
      "\tspeed: 0.0199s/iter; left time: 171.1622s\n",
      "\titers: 500, epoch: 11 | loss: 0.3011385\n",
      "\tspeed: 0.0200s/iter; left time: 170.1441s\n",
      "\titers: 600, epoch: 11 | loss: 0.2918858\n",
      "\tspeed: 0.0234s/iter; left time: 196.1932s\n",
      "\titers: 700, epoch: 11 | loss: 0.3166992\n",
      "\tspeed: 0.0268s/iter; left time: 222.1102s\n",
      "\titers: 800, epoch: 11 | loss: 0.3245089\n",
      "\tspeed: 0.0281s/iter; left time: 230.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:21.67s\n",
      "Steps: 899 | Train Loss: 0.3338532 Vali Loss: 0.4020068 Test Loss: 0.4139721\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.3346046\n",
      "\tspeed: 0.0697s/iter; left time: 557.1096s\n",
      "\titers: 200, epoch: 12 | loss: 0.3433757\n",
      "\tspeed: 0.0229s/iter; left time: 181.1173s\n",
      "\titers: 300, epoch: 12 | loss: 0.3073155\n",
      "\tspeed: 0.0248s/iter; left time: 192.9214s\n",
      "\titers: 400, epoch: 12 | loss: 0.2916025\n",
      "\tspeed: 0.0215s/iter; left time: 165.6678s\n",
      "\titers: 500, epoch: 12 | loss: 0.3120934\n",
      "\tspeed: 0.0236s/iter; left time: 179.3359s\n",
      "\titers: 600, epoch: 12 | loss: 0.3826615\n",
      "\tspeed: 0.0201s/iter; left time: 150.4000s\n",
      "\titers: 700, epoch: 12 | loss: 0.3332570\n",
      "\tspeed: 0.0197s/iter; left time: 145.3220s\n",
      "\titers: 800, epoch: 12 | loss: 0.3266031\n",
      "\tspeed: 0.0212s/iter; left time: 154.9084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:19.71s\n",
      "Steps: 899 | Train Loss: 0.3323645 Vali Loss: 0.4015648 Test Loss: 0.4150464\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.3874180\n",
      "\tspeed: 0.0663s/iter; left time: 470.3347s\n",
      "\titers: 200, epoch: 13 | loss: 0.2944820\n",
      "\tspeed: 0.0199s/iter; left time: 138.9899s\n",
      "\titers: 300, epoch: 13 | loss: 0.3141252\n",
      "\tspeed: 0.0204s/iter; left time: 140.4678s\n",
      "\titers: 400, epoch: 13 | loss: 0.3116724\n",
      "\tspeed: 0.0198s/iter; left time: 134.1959s\n",
      "\titers: 500, epoch: 13 | loss: 0.3105265\n",
      "\tspeed: 0.0202s/iter; left time: 134.8808s\n",
      "\titers: 600, epoch: 13 | loss: 0.3021501\n",
      "\tspeed: 0.0204s/iter; left time: 134.4974s\n",
      "\titers: 700, epoch: 13 | loss: 0.3491513\n",
      "\tspeed: 0.0201s/iter; left time: 130.8040s\n",
      "\titers: 800, epoch: 13 | loss: 0.3344786\n",
      "\tspeed: 0.0199s/iter; left time: 127.1785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.46s\n",
      "Steps: 899 | Train Loss: 0.3309927 Vali Loss: 0.3986914 Test Loss: 0.4127441\n",
      "Validation loss decreased (0.401515 --> 0.398691).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.2813759\n",
      "\tspeed: 0.0664s/iter; left time: 411.4643s\n",
      "\titers: 200, epoch: 14 | loss: 0.3584751\n",
      "\tspeed: 0.0204s/iter; left time: 124.6194s\n",
      "\titers: 300, epoch: 14 | loss: 0.3399500\n",
      "\tspeed: 0.0203s/iter; left time: 121.8130s\n",
      "\titers: 400, epoch: 14 | loss: 0.3180052\n",
      "\tspeed: 0.0201s/iter; left time: 118.5903s\n",
      "\titers: 500, epoch: 14 | loss: 0.3224261\n",
      "\tspeed: 0.0198s/iter; left time: 114.7091s\n",
      "\titers: 600, epoch: 14 | loss: 0.3275618\n",
      "\tspeed: 0.0196s/iter; left time: 111.8356s\n",
      "\titers: 700, epoch: 14 | loss: 0.3477090\n",
      "\tspeed: 0.0193s/iter; left time: 107.8225s\n",
      "\titers: 800, epoch: 14 | loss: 0.2929604\n",
      "\tspeed: 0.0210s/iter; left time: 115.4157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.58s\n",
      "Steps: 899 | Train Loss: 0.3295226 Vali Loss: 0.3988410 Test Loss: 0.4132774\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.3748130\n",
      "\tspeed: 0.0639s/iter; left time: 338.2385s\n",
      "\titers: 200, epoch: 15 | loss: 0.3305564\n",
      "\tspeed: 0.0202s/iter; left time: 104.7792s\n",
      "\titers: 300, epoch: 15 | loss: 0.3628637\n",
      "\tspeed: 0.0197s/iter; left time: 100.3327s\n",
      "\titers: 400, epoch: 15 | loss: 0.2975491\n",
      "\tspeed: 0.0198s/iter; left time: 98.8936s\n",
      "\titers: 500, epoch: 15 | loss: 0.3562666\n",
      "\tspeed: 0.0197s/iter; left time: 96.5203s\n",
      "\titers: 600, epoch: 15 | loss: 0.3347860\n",
      "\tspeed: 0.0192s/iter; left time: 92.2384s\n",
      "\titers: 700, epoch: 15 | loss: 0.3191307\n",
      "\tspeed: 0.0193s/iter; left time: 90.5071s\n",
      "\titers: 800, epoch: 15 | loss: 0.3578419\n",
      "\tspeed: 0.0200s/iter; left time: 91.9667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:17.92s\n",
      "Steps: 899 | Train Loss: 0.3287351 Vali Loss: 0.3993179 Test Loss: 0.4129342\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.3287815\n",
      "\tspeed: 0.0617s/iter; left time: 271.3380s\n",
      "\titers: 200, epoch: 16 | loss: 0.3094699\n",
      "\tspeed: 0.0208s/iter; left time: 89.3669s\n",
      "\titers: 300, epoch: 16 | loss: 0.3409826\n",
      "\tspeed: 0.0205s/iter; left time: 86.1156s\n",
      "\titers: 400, epoch: 16 | loss: 0.3552598\n",
      "\tspeed: 0.0201s/iter; left time: 82.4874s\n",
      "\titers: 500, epoch: 16 | loss: 0.2806531\n",
      "\tspeed: 0.0196s/iter; left time: 78.1889s\n",
      "\titers: 600, epoch: 16 | loss: 0.3417759\n",
      "\tspeed: 0.0217s/iter; left time: 84.4580s\n",
      "\titers: 700, epoch: 16 | loss: 0.3529180\n",
      "\tspeed: 0.0206s/iter; left time: 78.3724s\n",
      "\titers: 800, epoch: 16 | loss: 0.3698572\n",
      "\tspeed: 0.0203s/iter; left time: 74.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 899 | Train Loss: 0.3275108 Vali Loss: 0.3979902 Test Loss: 0.4119526\n",
      "Validation loss decreased (0.398691 --> 0.397990).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.3180855\n",
      "\tspeed: 0.0640s/iter; left time: 223.7460s\n",
      "\titers: 200, epoch: 17 | loss: 0.3203923\n",
      "\tspeed: 0.0198s/iter; left time: 67.1350s\n",
      "\titers: 300, epoch: 17 | loss: 0.3621082\n",
      "\tspeed: 0.0196s/iter; left time: 64.6157s\n",
      "\titers: 400, epoch: 17 | loss: 0.3801754\n",
      "\tspeed: 0.0174s/iter; left time: 55.5687s\n",
      "\titers: 500, epoch: 17 | loss: 0.3564919\n",
      "\tspeed: 0.0157s/iter; left time: 48.5202s\n",
      "\titers: 600, epoch: 17 | loss: 0.3644741\n",
      "\tspeed: 0.0155s/iter; left time: 46.3770s\n",
      "\titers: 700, epoch: 17 | loss: 0.3353415\n",
      "\tspeed: 0.0190s/iter; left time: 54.9190s\n",
      "\titers: 800, epoch: 17 | loss: 0.2705296\n",
      "\tspeed: 0.0175s/iter; left time: 49.0837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:16.69s\n",
      "Steps: 899 | Train Loss: 0.3266981 Vali Loss: 0.3976265 Test Loss: 0.4128912\n",
      "Validation loss decreased (0.397990 --> 0.397626).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.3405659\n",
      "\tspeed: 0.0602s/iter; left time: 156.3685s\n",
      "\titers: 200, epoch: 18 | loss: 0.3526235\n",
      "\tspeed: 0.0182s/iter; left time: 45.4529s\n",
      "\titers: 300, epoch: 18 | loss: 0.3184077\n",
      "\tspeed: 0.0219s/iter; left time: 52.4959s\n",
      "\titers: 400, epoch: 18 | loss: 0.3885649\n",
      "\tspeed: 0.0244s/iter; left time: 56.0497s\n",
      "\titers: 500, epoch: 18 | loss: 0.2935861\n",
      "\tspeed: 0.0213s/iter; left time: 46.9189s\n",
      "\titers: 600, epoch: 18 | loss: 0.3523632\n",
      "\tspeed: 0.0204s/iter; left time: 42.7400s\n",
      "\titers: 700, epoch: 18 | loss: 0.3229299\n",
      "\tspeed: 0.0230s/iter; left time: 45.8758s\n",
      "\titers: 800, epoch: 18 | loss: 0.3456658\n",
      "\tspeed: 0.0248s/iter; left time: 46.9939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:19.67s\n",
      "Steps: 899 | Train Loss: 0.3258629 Vali Loss: 0.3986179 Test Loss: 0.4144174\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.3422670\n",
      "\tspeed: 0.0721s/iter; left time: 122.5728s\n",
      "\titers: 200, epoch: 19 | loss: 0.3643227\n",
      "\tspeed: 0.0243s/iter; left time: 38.8658s\n",
      "\titers: 300, epoch: 19 | loss: 0.3168053\n",
      "\tspeed: 0.0237s/iter; left time: 35.4585s\n",
      "\titers: 400, epoch: 19 | loss: 0.3122375\n",
      "\tspeed: 0.0201s/iter; left time: 28.0773s\n",
      "\titers: 500, epoch: 19 | loss: 0.2996842\n",
      "\tspeed: 0.0217s/iter; left time: 28.1384s\n",
      "\titers: 600, epoch: 19 | loss: 0.3302963\n",
      "\tspeed: 0.0224s/iter; left time: 26.8992s\n",
      "\titers: 700, epoch: 19 | loss: 0.2902902\n",
      "\tspeed: 0.0205s/iter; left time: 22.5543s\n",
      "\titers: 800, epoch: 19 | loss: 0.3612247\n",
      "\tspeed: 0.0183s/iter; left time: 18.3134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:19.56s\n",
      "Steps: 899 | Train Loss: 0.3249634 Vali Loss: 0.3980187 Test Loss: 0.4128316\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.2818643\n",
      "\tspeed: 0.0626s/iter; left time: 50.0822s\n",
      "\titers: 200, epoch: 20 | loss: 0.2950998\n",
      "\tspeed: 0.0195s/iter; left time: 13.6216s\n",
      "\titers: 300, epoch: 20 | loss: 0.3004586\n",
      "\tspeed: 0.0201s/iter; left time: 12.0330s\n",
      "\titers: 400, epoch: 20 | loss: 0.3419689\n",
      "\tspeed: 0.0240s/iter; left time: 11.9821s\n",
      "\titers: 500, epoch: 20 | loss: 0.3554202\n",
      "\tspeed: 0.0221s/iter; left time: 8.8245s\n",
      "\titers: 600, epoch: 20 | loss: 0.3039371\n",
      "\tspeed: 0.0212s/iter; left time: 6.3489s\n",
      "\titers: 700, epoch: 20 | loss: 0.3240073\n",
      "\tspeed: 0.0218s/iter; left time: 4.3604s\n",
      "\titers: 800, epoch: 20 | loss: 0.3065621\n",
      "\tspeed: 0.0239s/iter; left time: 2.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:19.51s\n",
      "Steps: 899 | Train Loss: 0.3242426 Vali Loss: 0.3981027 Test Loss: 0.4121802\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4469950199127197, rmse:0.6685768365859985, mae:0.4128912091255188, rse:0.5291363000869751\n",
      "Original data scale mse:16410974.0, rmse:4051.046142578125, mae:2383.52294921875, rse:0.2014261782169342\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7681341\n",
      "\tspeed: 0.0406s/iter; left time: 725.0894s\n",
      "\titers: 200, epoch: 1 | loss: 0.7098215\n",
      "\tspeed: 0.0109s/iter; left time: 192.5524s\n",
      "\titers: 300, epoch: 1 | loss: 0.6781722\n",
      "\tspeed: 0.0108s/iter; left time: 191.4037s\n",
      "\titers: 400, epoch: 1 | loss: 0.6333339\n",
      "\tspeed: 0.0109s/iter; left time: 191.2804s\n",
      "\titers: 500, epoch: 1 | loss: 0.6423066\n",
      "\tspeed: 0.0148s/iter; left time: 257.6929s\n",
      "\titers: 600, epoch: 1 | loss: 0.6641703\n",
      "\tspeed: 0.0108s/iter; left time: 188.0563s\n",
      "\titers: 700, epoch: 1 | loss: 0.6420035\n",
      "\tspeed: 0.0115s/iter; left time: 198.1470s\n",
      "\titers: 800, epoch: 1 | loss: 0.6533687\n",
      "\tspeed: 0.0110s/iter; left time: 188.1180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.83s\n",
      "Steps: 897 | Train Loss: 0.6656314 Vali Loss: 0.6287663 Test Loss: 0.6625250\n",
      "Validation loss decreased (inf --> 0.628766).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5131358\n",
      "\tspeed: 0.0556s/iter; left time: 942.3714s\n",
      "\titers: 200, epoch: 2 | loss: 0.5001085\n",
      "\tspeed: 0.0221s/iter; left time: 372.9028s\n",
      "\titers: 300, epoch: 2 | loss: 0.4389239\n",
      "\tspeed: 0.0138s/iter; left time: 230.8415s\n",
      "\titers: 400, epoch: 2 | loss: 0.4928966\n",
      "\tspeed: 0.0119s/iter; left time: 198.3869s\n",
      "\titers: 500, epoch: 2 | loss: 0.4846752\n",
      "\tspeed: 0.0113s/iter; left time: 187.1289s\n",
      "\titers: 600, epoch: 2 | loss: 0.4814074\n",
      "\tspeed: 0.0111s/iter; left time: 182.5506s\n",
      "\titers: 700, epoch: 2 | loss: 0.4727161\n",
      "\tspeed: 0.0111s/iter; left time: 180.9386s\n",
      "\titers: 800, epoch: 2 | loss: 0.5660453\n",
      "\tspeed: 0.0131s/iter; left time: 213.1820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.56s\n",
      "Steps: 897 | Train Loss: 0.5226770 Vali Loss: 0.5581455 Test Loss: 0.6020366\n",
      "Validation loss decreased (0.628766 --> 0.558146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4831755\n",
      "\tspeed: 0.0634s/iter; left time: 1017.7417s\n",
      "\titers: 200, epoch: 3 | loss: 0.5452403\n",
      "\tspeed: 0.0199s/iter; left time: 317.5931s\n",
      "\titers: 300, epoch: 3 | loss: 0.4891399\n",
      "\tspeed: 0.0202s/iter; left time: 320.7411s\n",
      "\titers: 400, epoch: 3 | loss: 0.5140144\n",
      "\tspeed: 0.0201s/iter; left time: 316.7044s\n",
      "\titers: 500, epoch: 3 | loss: 0.4405692\n",
      "\tspeed: 0.0199s/iter; left time: 311.4113s\n",
      "\titers: 600, epoch: 3 | loss: 0.4778003\n",
      "\tspeed: 0.0202s/iter; left time: 314.4605s\n",
      "\titers: 700, epoch: 3 | loss: 0.4842212\n",
      "\tspeed: 0.0202s/iter; left time: 311.6256s\n",
      "\titers: 800, epoch: 3 | loss: 0.4672265\n",
      "\tspeed: 0.0204s/iter; left time: 312.4359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.40s\n",
      "Steps: 897 | Train Loss: 0.4968352 Vali Loss: 0.5539119 Test Loss: 0.6010337\n",
      "Validation loss decreased (0.558146 --> 0.553912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4751979\n",
      "\tspeed: 0.0625s/iter; left time: 947.1845s\n",
      "\titers: 200, epoch: 4 | loss: 0.4924155\n",
      "\tspeed: 0.0203s/iter; left time: 305.0891s\n",
      "\titers: 300, epoch: 4 | loss: 0.5328815\n",
      "\tspeed: 0.0202s/iter; left time: 302.0385s\n",
      "\titers: 400, epoch: 4 | loss: 0.4229204\n",
      "\tspeed: 0.0199s/iter; left time: 295.1020s\n",
      "\titers: 500, epoch: 4 | loss: 0.4480296\n",
      "\tspeed: 0.0199s/iter; left time: 293.5758s\n",
      "\titers: 600, epoch: 4 | loss: 0.5039721\n",
      "\tspeed: 0.0191s/iter; left time: 279.4826s\n",
      "\titers: 700, epoch: 4 | loss: 0.5686306\n",
      "\tspeed: 0.0203s/iter; left time: 296.0100s\n",
      "\titers: 800, epoch: 4 | loss: 0.4515683\n",
      "\tspeed: 0.0196s/iter; left time: 283.9354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.23s\n",
      "Steps: 897 | Train Loss: 0.4880836 Vali Loss: 0.5501428 Test Loss: 0.5974890\n",
      "Validation loss decreased (0.553912 --> 0.550143).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4477876\n",
      "\tspeed: 0.0709s/iter; left time: 1011.0166s\n",
      "\titers: 200, epoch: 5 | loss: 0.4860590\n",
      "\tspeed: 0.0169s/iter; left time: 239.8433s\n",
      "\titers: 300, epoch: 5 | loss: 0.4821640\n",
      "\tspeed: 0.0202s/iter; left time: 284.1512s\n",
      "\titers: 400, epoch: 5 | loss: 0.4579794\n",
      "\tspeed: 0.0189s/iter; left time: 264.3783s\n",
      "\titers: 500, epoch: 5 | loss: 0.4842594\n",
      "\tspeed: 0.0188s/iter; left time: 260.2595s\n",
      "\titers: 600, epoch: 5 | loss: 0.4741156\n",
      "\tspeed: 0.0165s/iter; left time: 226.5936s\n",
      "\titers: 700, epoch: 5 | loss: 0.5094141\n",
      "\tspeed: 0.0165s/iter; left time: 225.0047s\n",
      "\titers: 800, epoch: 5 | loss: 0.5361459\n",
      "\tspeed: 0.0201s/iter; left time: 272.4694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 897 | Train Loss: 0.4797959 Vali Loss: 0.5562317 Test Loss: 0.6052639\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4852402\n",
      "\tspeed: 0.0526s/iter; left time: 702.3480s\n",
      "\titers: 200, epoch: 6 | loss: 0.4671575\n",
      "\tspeed: 0.0096s/iter; left time: 127.8218s\n",
      "\titers: 300, epoch: 6 | loss: 0.4650848\n",
      "\tspeed: 0.0136s/iter; left time: 179.0353s\n",
      "\titers: 400, epoch: 6 | loss: 0.4689575\n",
      "\tspeed: 0.0171s/iter; left time: 223.0829s\n",
      "\titers: 500, epoch: 6 | loss: 0.5155724\n",
      "\tspeed: 0.0181s/iter; left time: 234.1981s\n",
      "\titers: 600, epoch: 6 | loss: 0.3912028\n",
      "\tspeed: 0.0171s/iter; left time: 220.3532s\n",
      "\titers: 700, epoch: 6 | loss: 0.4853322\n",
      "\tspeed: 0.0181s/iter; left time: 230.4047s\n",
      "\titers: 800, epoch: 6 | loss: 0.4593610\n",
      "\tspeed: 0.0187s/iter; left time: 236.4637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.68s\n",
      "Steps: 897 | Train Loss: 0.4719286 Vali Loss: 0.5554512 Test Loss: 0.6044047\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4746378\n",
      "\tspeed: 0.0594s/iter; left time: 739.8798s\n",
      "\titers: 200, epoch: 7 | loss: 0.4353462\n",
      "\tspeed: 0.0156s/iter; left time: 192.9749s\n",
      "\titers: 300, epoch: 7 | loss: 0.5061290\n",
      "\tspeed: 0.0170s/iter; left time: 208.3248s\n",
      "\titers: 400, epoch: 7 | loss: 0.4201314\n",
      "\tspeed: 0.0156s/iter; left time: 189.2199s\n",
      "\titers: 500, epoch: 7 | loss: 0.4636760\n",
      "\tspeed: 0.0157s/iter; left time: 189.2547s\n",
      "\titers: 600, epoch: 7 | loss: 0.4565600\n",
      "\tspeed: 0.0168s/iter; left time: 201.0284s\n",
      "\titers: 700, epoch: 7 | loss: 0.4623772\n",
      "\tspeed: 0.0140s/iter; left time: 166.5609s\n",
      "\titers: 800, epoch: 7 | loss: 0.4357137\n",
      "\tspeed: 0.0086s/iter; left time: 101.1259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 897 | Train Loss: 0.4640694 Vali Loss: 0.5537003 Test Loss: 0.5996038\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4664937\n",
      "\tspeed: 0.0527s/iter; left time: 609.3371s\n",
      "\titers: 200, epoch: 8 | loss: 0.4542998\n",
      "\tspeed: 0.0188s/iter; left time: 215.3037s\n",
      "\titers: 300, epoch: 8 | loss: 0.4511668\n",
      "\tspeed: 0.0168s/iter; left time: 191.4292s\n",
      "\titers: 400, epoch: 8 | loss: 0.4351516\n",
      "\tspeed: 0.0194s/iter; left time: 218.4843s\n",
      "\titers: 500, epoch: 8 | loss: 0.4492470\n",
      "\tspeed: 0.0175s/iter; left time: 195.2438s\n",
      "\titers: 600, epoch: 8 | loss: 0.3974285\n",
      "\tspeed: 0.0172s/iter; left time: 190.1029s\n",
      "\titers: 700, epoch: 8 | loss: 0.4977673\n",
      "\tspeed: 0.0169s/iter; left time: 185.3011s\n",
      "\titers: 800, epoch: 8 | loss: 0.4433538\n",
      "\tspeed: 0.0172s/iter; left time: 186.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.78s\n",
      "Steps: 897 | Train Loss: 0.4572183 Vali Loss: 0.5552071 Test Loss: 0.6084688\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.5055850\n",
      "\tspeed: 0.0609s/iter; left time: 649.7355s\n",
      "\titers: 200, epoch: 9 | loss: 0.4811957\n",
      "\tspeed: 0.0182s/iter; left time: 192.2850s\n",
      "\titers: 300, epoch: 9 | loss: 0.5010182\n",
      "\tspeed: 0.0176s/iter; left time: 184.1116s\n",
      "\titers: 400, epoch: 9 | loss: 0.4434836\n",
      "\tspeed: 0.0161s/iter; left time: 167.2007s\n",
      "\titers: 500, epoch: 9 | loss: 0.4430868\n",
      "\tspeed: 0.0152s/iter; left time: 155.6572s\n",
      "\titers: 600, epoch: 9 | loss: 0.5033134\n",
      "\tspeed: 0.0156s/iter; left time: 158.3322s\n",
      "\titers: 700, epoch: 9 | loss: 0.4904265\n",
      "\tspeed: 0.0189s/iter; left time: 190.3207s\n",
      "\titers: 800, epoch: 9 | loss: 0.4102505\n",
      "\tspeed: 0.0224s/iter; left time: 223.0010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.35s\n",
      "Steps: 897 | Train Loss: 0.4511447 Vali Loss: 0.5572721 Test Loss: 0.6050890\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7926541566848755, rmse:0.8903112411499023, mae:0.5974887609481812, rse:0.7061265707015991\n",
      "Original data scale mse:32427548.0, rmse:5694.51904296875, mae:3520.055908203125, rse:0.28358909487724304\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7968292\n",
      "\tspeed: 0.0171s/iter; left time: 304.7681s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677732\n",
      "\tspeed: 0.0101s/iter; left time: 179.9474s\n",
      "\titers: 300, epoch: 1 | loss: 0.6710458\n",
      "\tspeed: 0.0102s/iter; left time: 179.1074s\n",
      "\titers: 400, epoch: 1 | loss: 0.6623638\n",
      "\tspeed: 0.0110s/iter; left time: 193.7472s\n",
      "\titers: 500, epoch: 1 | loss: 0.6755697\n",
      "\tspeed: 0.0186s/iter; left time: 324.5248s\n",
      "\titers: 600, epoch: 1 | loss: 0.6094369\n",
      "\tspeed: 0.0213s/iter; left time: 368.8842s\n",
      "\titers: 700, epoch: 1 | loss: 0.5901045\n",
      "\tspeed: 0.0202s/iter; left time: 347.4668s\n",
      "\titers: 800, epoch: 1 | loss: 0.6161879\n",
      "\tspeed: 0.0200s/iter; left time: 343.6680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.81s\n",
      "Steps: 897 | Train Loss: 0.6645801 Vali Loss: 0.6297336 Test Loss: 0.6631206\n",
      "Validation loss decreased (inf --> 0.629734).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5894655\n",
      "\tspeed: 0.0618s/iter; left time: 1046.7400s\n",
      "\titers: 200, epoch: 2 | loss: 0.4927329\n",
      "\tspeed: 0.0193s/iter; left time: 324.5752s\n",
      "\titers: 300, epoch: 2 | loss: 0.5202807\n",
      "\tspeed: 0.0176s/iter; left time: 293.8653s\n",
      "\titers: 400, epoch: 2 | loss: 0.4786786\n",
      "\tspeed: 0.0176s/iter; left time: 293.0328s\n",
      "\titers: 500, epoch: 2 | loss: 0.4493549\n",
      "\tspeed: 0.0172s/iter; left time: 284.4510s\n",
      "\titers: 600, epoch: 2 | loss: 0.5239192\n",
      "\tspeed: 0.0173s/iter; left time: 284.9839s\n",
      "\titers: 700, epoch: 2 | loss: 0.5055629\n",
      "\tspeed: 0.0163s/iter; left time: 266.0087s\n",
      "\titers: 800, epoch: 2 | loss: 0.5123243\n",
      "\tspeed: 0.0159s/iter; left time: 258.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.96s\n",
      "Steps: 897 | Train Loss: 0.5224391 Vali Loss: 0.5640802 Test Loss: 0.6090956\n",
      "Validation loss decreased (0.629734 --> 0.564080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4871354\n",
      "\tspeed: 0.0630s/iter; left time: 1010.6533s\n",
      "\titers: 200, epoch: 3 | loss: 0.4849430\n",
      "\tspeed: 0.0200s/iter; left time: 318.5802s\n",
      "\titers: 300, epoch: 3 | loss: 0.5454015\n",
      "\tspeed: 0.0203s/iter; left time: 321.0621s\n",
      "\titers: 400, epoch: 3 | loss: 0.4920644\n",
      "\tspeed: 0.0201s/iter; left time: 315.9152s\n",
      "\titers: 500, epoch: 3 | loss: 0.4909656\n",
      "\tspeed: 0.0202s/iter; left time: 316.6429s\n",
      "\titers: 600, epoch: 3 | loss: 0.5043185\n",
      "\tspeed: 0.0202s/iter; left time: 314.0848s\n",
      "\titers: 700, epoch: 3 | loss: 0.4826466\n",
      "\tspeed: 0.0202s/iter; left time: 312.4895s\n",
      "\titers: 800, epoch: 3 | loss: 0.5580964\n",
      "\tspeed: 0.0202s/iter; left time: 310.6765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.90s\n",
      "Steps: 897 | Train Loss: 0.4959829 Vali Loss: 0.5513532 Test Loss: 0.6009287\n",
      "Validation loss decreased (0.564080 --> 0.551353).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4812087\n",
      "\tspeed: 0.0605s/iter; left time: 916.7257s\n",
      "\titers: 200, epoch: 4 | loss: 0.5179583\n",
      "\tspeed: 0.0218s/iter; left time: 328.0471s\n",
      "\titers: 300, epoch: 4 | loss: 0.4682643\n",
      "\tspeed: 0.0238s/iter; left time: 355.4365s\n",
      "\titers: 400, epoch: 4 | loss: 0.4523818\n",
      "\tspeed: 0.0238s/iter; left time: 353.9088s\n",
      "\titers: 500, epoch: 4 | loss: 0.4465609\n",
      "\tspeed: 0.0207s/iter; left time: 304.9194s\n",
      "\titers: 600, epoch: 4 | loss: 0.5140533\n",
      "\tspeed: 0.0122s/iter; left time: 178.9947s\n",
      "\titers: 700, epoch: 4 | loss: 0.4926369\n",
      "\tspeed: 0.0192s/iter; left time: 279.7390s\n",
      "\titers: 800, epoch: 4 | loss: 0.5715377\n",
      "\tspeed: 0.0184s/iter; left time: 266.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 897 | Train Loss: 0.4865220 Vali Loss: 0.5521289 Test Loss: 0.6023161\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4688189\n",
      "\tspeed: 0.0584s/iter; left time: 832.0962s\n",
      "\titers: 200, epoch: 5 | loss: 0.4539979\n",
      "\tspeed: 0.0162s/iter; left time: 228.8982s\n",
      "\titers: 300, epoch: 5 | loss: 0.4594436\n",
      "\tspeed: 0.0168s/iter; left time: 235.9981s\n",
      "\titers: 400, epoch: 5 | loss: 0.5118880\n",
      "\tspeed: 0.0201s/iter; left time: 280.3834s\n",
      "\titers: 500, epoch: 5 | loss: 0.4889513\n",
      "\tspeed: 0.0187s/iter; left time: 258.4223s\n",
      "\titers: 600, epoch: 5 | loss: 0.4659404\n",
      "\tspeed: 0.0189s/iter; left time: 259.3497s\n",
      "\titers: 700, epoch: 5 | loss: 0.5015051\n",
      "\tspeed: 0.0201s/iter; left time: 274.2655s\n",
      "\titers: 800, epoch: 5 | loss: 0.5156211\n",
      "\tspeed: 0.0205s/iter; left time: 277.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 897 | Train Loss: 0.4776659 Vali Loss: 0.5573316 Test Loss: 0.6025979\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4651778\n",
      "\tspeed: 0.0658s/iter; left time: 878.6842s\n",
      "\titers: 200, epoch: 6 | loss: 0.4955299\n",
      "\tspeed: 0.0218s/iter; left time: 288.3223s\n",
      "\titers: 300, epoch: 6 | loss: 0.4856496\n",
      "\tspeed: 0.0211s/iter; left time: 277.9435s\n",
      "\titers: 400, epoch: 6 | loss: 0.4807419\n",
      "\tspeed: 0.0196s/iter; left time: 256.0883s\n",
      "\titers: 500, epoch: 6 | loss: 0.4966970\n",
      "\tspeed: 0.0191s/iter; left time: 247.5274s\n",
      "\titers: 600, epoch: 6 | loss: 0.4429293\n",
      "\tspeed: 0.0196s/iter; left time: 251.3547s\n",
      "\titers: 700, epoch: 6 | loss: 0.4820661\n",
      "\tspeed: 0.0195s/iter; left time: 248.6632s\n",
      "\titers: 800, epoch: 6 | loss: 0.4520912\n",
      "\tspeed: 0.0192s/iter; left time: 242.7258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.11s\n",
      "Steps: 897 | Train Loss: 0.4692948 Vali Loss: 0.5570992 Test Loss: 0.6051583\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4642062\n",
      "\tspeed: 0.0606s/iter; left time: 754.6530s\n",
      "\titers: 200, epoch: 7 | loss: 0.5187182\n",
      "\tspeed: 0.0188s/iter; left time: 232.0711s\n",
      "\titers: 300, epoch: 7 | loss: 0.4500763\n",
      "\tspeed: 0.0185s/iter; left time: 226.4853s\n",
      "\titers: 400, epoch: 7 | loss: 0.4632659\n",
      "\tspeed: 0.0219s/iter; left time: 266.1113s\n",
      "\titers: 500, epoch: 7 | loss: 0.4104843\n",
      "\tspeed: 0.0199s/iter; left time: 239.4476s\n",
      "\titers: 600, epoch: 7 | loss: 0.4750810\n",
      "\tspeed: 0.0192s/iter; left time: 229.2501s\n",
      "\titers: 700, epoch: 7 | loss: 0.4384900\n",
      "\tspeed: 0.0203s/iter; left time: 240.2881s\n",
      "\titers: 800, epoch: 7 | loss: 0.4676010\n",
      "\tspeed: 0.0184s/iter; left time: 215.8292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.58s\n",
      "Steps: 897 | Train Loss: 0.4610416 Vali Loss: 0.5554325 Test Loss: 0.6056845\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4321734\n",
      "\tspeed: 0.0563s/iter; left time: 651.1236s\n",
      "\titers: 200, epoch: 8 | loss: 0.4268806\n",
      "\tspeed: 0.0190s/iter; left time: 217.9717s\n",
      "\titers: 300, epoch: 8 | loss: 0.4372078\n",
      "\tspeed: 0.0189s/iter; left time: 214.6564s\n",
      "\titers: 400, epoch: 8 | loss: 0.4819112\n",
      "\tspeed: 0.0201s/iter; left time: 226.3217s\n",
      "\titers: 500, epoch: 8 | loss: 0.4317662\n",
      "\tspeed: 0.0185s/iter; left time: 206.7967s\n",
      "\titers: 600, epoch: 8 | loss: 0.4616611\n",
      "\tspeed: 0.0193s/iter; left time: 213.3327s\n",
      "\titers: 700, epoch: 8 | loss: 0.4275100\n",
      "\tspeed: 0.0205s/iter; left time: 224.4289s\n",
      "\titers: 800, epoch: 8 | loss: 0.3914445\n",
      "\tspeed: 0.0168s/iter; left time: 182.6775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.76s\n",
      "Steps: 897 | Train Loss: 0.4537987 Vali Loss: 0.5566676 Test Loss: 0.6073158\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7960056066513062, rmse:0.892191469669342, mae:0.6009284853935242, rse:0.7076177597045898\n",
      "Original data scale mse:32485964.0, rmse:5699.64599609375, mae:3545.96728515625, rse:0.2838444113731384\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8190661\n",
      "\tspeed: 0.0433s/iter; left time: 770.3941s\n",
      "\titers: 200, epoch: 1 | loss: 0.6760388\n",
      "\tspeed: 0.0119s/iter; left time: 209.5422s\n",
      "\titers: 300, epoch: 1 | loss: 0.6724653\n",
      "\tspeed: 0.0122s/iter; left time: 214.2533s\n",
      "\titers: 400, epoch: 1 | loss: 0.6553839\n",
      "\tspeed: 0.0111s/iter; left time: 193.5916s\n",
      "\titers: 500, epoch: 1 | loss: 0.6994035\n",
      "\tspeed: 0.0111s/iter; left time: 192.3224s\n",
      "\titers: 600, epoch: 1 | loss: 0.6690061\n",
      "\tspeed: 0.0110s/iter; left time: 189.9914s\n",
      "\titers: 700, epoch: 1 | loss: 0.6458501\n",
      "\tspeed: 0.0110s/iter; left time: 188.9865s\n",
      "\titers: 800, epoch: 1 | loss: 0.6208235\n",
      "\tspeed: 0.0110s/iter; left time: 187.8024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.92s\n",
      "Steps: 894 | Train Loss: 0.6807828 Vali Loss: 0.6452995 Test Loss: 0.6867455\n",
      "Validation loss decreased (inf --> 0.645299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5825350\n",
      "\tspeed: 0.0555s/iter; left time: 938.0035s\n",
      "\titers: 200, epoch: 2 | loss: 0.6532227\n",
      "\tspeed: 0.0158s/iter; left time: 265.4778s\n",
      "\titers: 300, epoch: 2 | loss: 0.5179463\n",
      "\tspeed: 0.0109s/iter; left time: 181.6045s\n",
      "\titers: 400, epoch: 2 | loss: 0.6639387\n",
      "\tspeed: 0.0120s/iter; left time: 198.9255s\n",
      "\titers: 500, epoch: 2 | loss: 0.5415326\n",
      "\tspeed: 0.0108s/iter; left time: 178.2518s\n",
      "\titers: 600, epoch: 2 | loss: 0.5623536\n",
      "\tspeed: 0.0108s/iter; left time: 176.1732s\n",
      "\titers: 700, epoch: 2 | loss: 0.5980336\n",
      "\tspeed: 0.0109s/iter; left time: 177.7224s\n",
      "\titers: 800, epoch: 2 | loss: 0.5190690\n",
      "\tspeed: 0.0178s/iter; left time: 287.4852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:12.14s\n",
      "Steps: 894 | Train Loss: 0.5505749 Vali Loss: 0.5860673 Test Loss: 0.6439115\n",
      "Validation loss decreased (0.645299 --> 0.586067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5454453\n",
      "\tspeed: 0.0567s/iter; left time: 906.8244s\n",
      "\titers: 200, epoch: 3 | loss: 0.5011094\n",
      "\tspeed: 0.0237s/iter; left time: 376.3684s\n",
      "\titers: 300, epoch: 3 | loss: 0.4670990\n",
      "\tspeed: 0.0232s/iter; left time: 366.6487s\n",
      "\titers: 400, epoch: 3 | loss: 0.5466903\n",
      "\tspeed: 0.0214s/iter; left time: 336.6076s\n",
      "\titers: 500, epoch: 3 | loss: 0.5373562\n",
      "\tspeed: 0.0223s/iter; left time: 347.2714s\n",
      "\titers: 600, epoch: 3 | loss: 0.5366769\n",
      "\tspeed: 0.0215s/iter; left time: 333.4914s\n",
      "\titers: 700, epoch: 3 | loss: 0.5370882\n",
      "\tspeed: 0.0226s/iter; left time: 348.6235s\n",
      "\titers: 800, epoch: 3 | loss: 0.5361103\n",
      "\tspeed: 0.0223s/iter; left time: 341.3964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:19.81s\n",
      "Steps: 894 | Train Loss: 0.5246986 Vali Loss: 0.5761129 Test Loss: 0.6323410\n",
      "Validation loss decreased (0.586067 --> 0.576113).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4819528\n",
      "\tspeed: 0.0625s/iter; left time: 943.6423s\n",
      "\titers: 200, epoch: 4 | loss: 0.4648619\n",
      "\tspeed: 0.0188s/iter; left time: 281.3439s\n",
      "\titers: 300, epoch: 4 | loss: 0.5319911\n",
      "\tspeed: 0.0194s/iter; left time: 288.9217s\n",
      "\titers: 400, epoch: 4 | loss: 0.4689876\n",
      "\tspeed: 0.0184s/iter; left time: 272.1867s\n",
      "\titers: 500, epoch: 4 | loss: 0.5222583\n",
      "\tspeed: 0.0247s/iter; left time: 363.3231s\n",
      "\titers: 600, epoch: 4 | loss: 0.4736815\n",
      "\tspeed: 0.0262s/iter; left time: 382.4267s\n",
      "\titers: 700, epoch: 4 | loss: 0.4997956\n",
      "\tspeed: 0.0175s/iter; left time: 254.2905s\n",
      "\titers: 800, epoch: 4 | loss: 0.5129088\n",
      "\tspeed: 0.0216s/iter; left time: 310.7723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.68s\n",
      "Steps: 894 | Train Loss: 0.5140763 Vali Loss: 0.5780205 Test Loss: 0.6381353\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4989245\n",
      "\tspeed: 0.0628s/iter; left time: 892.5622s\n",
      "\titers: 200, epoch: 5 | loss: 0.4752572\n",
      "\tspeed: 0.0194s/iter; left time: 273.1958s\n",
      "\titers: 300, epoch: 5 | loss: 0.5047307\n",
      "\tspeed: 0.0201s/iter; left time: 281.7970s\n",
      "\titers: 400, epoch: 5 | loss: 0.5280099\n",
      "\tspeed: 0.0215s/iter; left time: 298.9046s\n",
      "\titers: 500, epoch: 5 | loss: 0.5346044\n",
      "\tspeed: 0.0217s/iter; left time: 299.1082s\n",
      "\titers: 600, epoch: 5 | loss: 0.5108569\n",
      "\tspeed: 0.0166s/iter; left time: 228.0024s\n",
      "\titers: 700, epoch: 5 | loss: 0.5383428\n",
      "\tspeed: 0.0177s/iter; left time: 240.7351s\n",
      "\titers: 800, epoch: 5 | loss: 0.4663505\n",
      "\tspeed: 0.0175s/iter; left time: 236.3127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.34s\n",
      "Steps: 894 | Train Loss: 0.5036948 Vali Loss: 0.5790375 Test Loss: 0.6404501\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5514655\n",
      "\tspeed: 0.0619s/iter; left time: 823.5835s\n",
      "\titers: 200, epoch: 6 | loss: 0.5000620\n",
      "\tspeed: 0.0200s/iter; left time: 263.5608s\n",
      "\titers: 300, epoch: 6 | loss: 0.4931819\n",
      "\tspeed: 0.0204s/iter; left time: 267.0560s\n",
      "\titers: 400, epoch: 6 | loss: 0.4691879\n",
      "\tspeed: 0.0201s/iter; left time: 261.3812s\n",
      "\titers: 500, epoch: 6 | loss: 0.4817052\n",
      "\tspeed: 0.0193s/iter; left time: 249.4240s\n",
      "\titers: 600, epoch: 6 | loss: 0.4714150\n",
      "\tspeed: 0.0197s/iter; left time: 252.3806s\n",
      "\titers: 700, epoch: 6 | loss: 0.5432647\n",
      "\tspeed: 0.0203s/iter; left time: 257.7629s\n",
      "\titers: 800, epoch: 6 | loss: 0.4706648\n",
      "\tspeed: 0.0201s/iter; left time: 252.9135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.25s\n",
      "Steps: 894 | Train Loss: 0.4940693 Vali Loss: 0.5786283 Test Loss: 0.6399474\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5674875\n",
      "\tspeed: 0.0648s/iter; left time: 804.5334s\n",
      "\titers: 200, epoch: 7 | loss: 0.4820705\n",
      "\tspeed: 0.0199s/iter; left time: 244.7923s\n",
      "\titers: 300, epoch: 7 | loss: 0.4842468\n",
      "\tspeed: 0.0187s/iter; left time: 228.2974s\n",
      "\titers: 400, epoch: 7 | loss: 0.4807248\n",
      "\tspeed: 0.0172s/iter; left time: 208.7472s\n",
      "\titers: 500, epoch: 7 | loss: 0.4657267\n",
      "\tspeed: 0.0197s/iter; left time: 237.0432s\n",
      "\titers: 600, epoch: 7 | loss: 0.5179813\n",
      "\tspeed: 0.0179s/iter; left time: 212.8994s\n",
      "\titers: 700, epoch: 7 | loss: 0.4483672\n",
      "\tspeed: 0.0195s/iter; left time: 230.4595s\n",
      "\titers: 800, epoch: 7 | loss: 0.4749659\n",
      "\tspeed: 0.0190s/iter; left time: 222.8695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.17s\n",
      "Steps: 894 | Train Loss: 0.4856504 Vali Loss: 0.5812460 Test Loss: 0.6386864\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4675330\n",
      "\tspeed: 0.0616s/iter; left time: 709.2510s\n",
      "\titers: 200, epoch: 8 | loss: 0.4686923\n",
      "\tspeed: 0.0207s/iter; left time: 236.0807s\n",
      "\titers: 300, epoch: 8 | loss: 0.4980675\n",
      "\tspeed: 0.0188s/iter; left time: 213.0477s\n",
      "\titers: 400, epoch: 8 | loss: 0.4696684\n",
      "\tspeed: 0.0186s/iter; left time: 208.8676s\n",
      "\titers: 500, epoch: 8 | loss: 0.4488669\n",
      "\tspeed: 0.0172s/iter; left time: 191.1300s\n",
      "\titers: 600, epoch: 8 | loss: 0.4827161\n",
      "\tspeed: 0.0169s/iter; left time: 186.4233s\n",
      "\titers: 700, epoch: 8 | loss: 0.5145175\n",
      "\tspeed: 0.0163s/iter; left time: 178.1013s\n",
      "\titers: 800, epoch: 8 | loss: 0.4956875\n",
      "\tspeed: 0.0172s/iter; left time: 185.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.30s\n",
      "Steps: 894 | Train Loss: 0.4782310 Vali Loss: 0.5837930 Test Loss: 0.6410279\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8570437431335449, rmse:0.9257665872573853, mae:0.6323410272598267, rse:0.7333710789680481\n",
      "Original data scale mse:35343512.0, rmse:5945.041015625, mae:3735.31787109375, rse:0.29621049761772156\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7444492\n",
      "\tspeed: 0.0229s/iter; left time: 406.4849s\n",
      "\titers: 200, epoch: 1 | loss: 0.7074236\n",
      "\tspeed: 0.0227s/iter; left time: 400.9522s\n",
      "\titers: 300, epoch: 1 | loss: 0.6615036\n",
      "\tspeed: 0.0195s/iter; left time: 343.6999s\n",
      "\titers: 400, epoch: 1 | loss: 0.6728616\n",
      "\tspeed: 0.0175s/iter; left time: 305.9239s\n",
      "\titers: 500, epoch: 1 | loss: 0.6293275\n",
      "\tspeed: 0.0223s/iter; left time: 387.2869s\n",
      "\titers: 600, epoch: 1 | loss: 0.6136136\n",
      "\tspeed: 0.0222s/iter; left time: 382.8410s\n",
      "\titers: 700, epoch: 1 | loss: 0.6249164\n",
      "\tspeed: 0.0229s/iter; left time: 393.9625s\n",
      "\titers: 800, epoch: 1 | loss: 0.6308851\n",
      "\tspeed: 0.0225s/iter; left time: 384.7988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 894 | Train Loss: 0.6793310 Vali Loss: 0.6456056 Test Loss: 0.6862055\n",
      "Validation loss decreased (inf --> 0.645606).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5789584\n",
      "\tspeed: 0.0650s/iter; left time: 1097.0062s\n",
      "\titers: 200, epoch: 2 | loss: 0.5622197\n",
      "\tspeed: 0.0195s/iter; left time: 327.4949s\n",
      "\titers: 300, epoch: 2 | loss: 0.5356826\n",
      "\tspeed: 0.0188s/iter; left time: 314.4134s\n",
      "\titers: 400, epoch: 2 | loss: 0.5257044\n",
      "\tspeed: 0.0193s/iter; left time: 320.7182s\n",
      "\titers: 500, epoch: 2 | loss: 0.5632188\n",
      "\tspeed: 0.0195s/iter; left time: 321.2738s\n",
      "\titers: 600, epoch: 2 | loss: 0.5245808\n",
      "\tspeed: 0.0196s/iter; left time: 321.2960s\n",
      "\titers: 700, epoch: 2 | loss: 0.4829881\n",
      "\tspeed: 0.0197s/iter; left time: 320.6374s\n",
      "\titers: 800, epoch: 2 | loss: 0.6015505\n",
      "\tspeed: 0.0187s/iter; left time: 303.0787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 894 | Train Loss: 0.5504002 Vali Loss: 0.5826504 Test Loss: 0.6378465\n",
      "Validation loss decreased (0.645606 --> 0.582650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5516722\n",
      "\tspeed: 0.0665s/iter; left time: 1063.4519s\n",
      "\titers: 200, epoch: 3 | loss: 0.5485481\n",
      "\tspeed: 0.0205s/iter; left time: 326.0520s\n",
      "\titers: 300, epoch: 3 | loss: 0.5355166\n",
      "\tspeed: 0.0187s/iter; left time: 295.3442s\n",
      "\titers: 400, epoch: 3 | loss: 0.5486447\n",
      "\tspeed: 0.0192s/iter; left time: 300.8987s\n",
      "\titers: 500, epoch: 3 | loss: 0.5908508\n",
      "\tspeed: 0.0188s/iter; left time: 292.3790s\n",
      "\titers: 600, epoch: 3 | loss: 0.4693529\n",
      "\tspeed: 0.0164s/iter; left time: 253.5654s\n",
      "\titers: 700, epoch: 3 | loss: 0.4679536\n",
      "\tspeed: 0.0161s/iter; left time: 247.9764s\n",
      "\titers: 800, epoch: 3 | loss: 0.5544648\n",
      "\tspeed: 0.0161s/iter; left time: 246.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.69s\n",
      "Steps: 894 | Train Loss: 0.5240230 Vali Loss: 0.5826426 Test Loss: 0.6401865\n",
      "Validation loss decreased (0.582650 --> 0.582643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4586098\n",
      "\tspeed: 0.0574s/iter; left time: 866.7192s\n",
      "\titers: 200, epoch: 4 | loss: 0.4986608\n",
      "\tspeed: 0.0181s/iter; left time: 271.6047s\n",
      "\titers: 300, epoch: 4 | loss: 0.4926678\n",
      "\tspeed: 0.0191s/iter; left time: 284.8808s\n",
      "\titers: 400, epoch: 4 | loss: 0.4561566\n",
      "\tspeed: 0.0187s/iter; left time: 276.9767s\n",
      "\titers: 500, epoch: 4 | loss: 0.5037405\n",
      "\tspeed: 0.0188s/iter; left time: 276.8463s\n",
      "\titers: 600, epoch: 4 | loss: 0.5109681\n",
      "\tspeed: 0.0204s/iter; left time: 298.2271s\n",
      "\titers: 700, epoch: 4 | loss: 0.5387002\n",
      "\tspeed: 0.0205s/iter; left time: 296.6214s\n",
      "\titers: 800, epoch: 4 | loss: 0.4898967\n",
      "\tspeed: 0.0183s/iter; left time: 263.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 894 | Train Loss: 0.5132358 Vali Loss: 0.5802558 Test Loss: 0.6345837\n",
      "Validation loss decreased (0.582643 --> 0.580256).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4974952\n",
      "\tspeed: 0.0637s/iter; left time: 905.3189s\n",
      "\titers: 200, epoch: 5 | loss: 0.5068514\n",
      "\tspeed: 0.0202s/iter; left time: 284.9028s\n",
      "\titers: 300, epoch: 5 | loss: 0.5328151\n",
      "\tspeed: 0.0201s/iter; left time: 281.0618s\n",
      "\titers: 400, epoch: 5 | loss: 0.5091070\n",
      "\tspeed: 0.0202s/iter; left time: 280.4182s\n",
      "\titers: 500, epoch: 5 | loss: 0.4363185\n",
      "\tspeed: 0.0203s/iter; left time: 279.5856s\n",
      "\titers: 600, epoch: 5 | loss: 0.4535142\n",
      "\tspeed: 0.0201s/iter; left time: 276.0226s\n",
      "\titers: 700, epoch: 5 | loss: 0.5589042\n",
      "\tspeed: 0.0205s/iter; left time: 278.4206s\n",
      "\titers: 800, epoch: 5 | loss: 0.5145748\n",
      "\tspeed: 0.0202s/iter; left time: 272.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.36s\n",
      "Steps: 894 | Train Loss: 0.5017896 Vali Loss: 0.5830060 Test Loss: 0.6419264\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4486466\n",
      "\tspeed: 0.0654s/iter; left time: 871.0576s\n",
      "\titers: 200, epoch: 6 | loss: 0.5154990\n",
      "\tspeed: 0.0199s/iter; left time: 262.3377s\n",
      "\titers: 300, epoch: 6 | loss: 0.4910369\n",
      "\tspeed: 0.0202s/iter; left time: 265.2470s\n",
      "\titers: 400, epoch: 6 | loss: 0.5344271\n",
      "\tspeed: 0.0199s/iter; left time: 258.3648s\n",
      "\titers: 500, epoch: 6 | loss: 0.5121671\n",
      "\tspeed: 0.0208s/iter; left time: 268.1717s\n",
      "\titers: 600, epoch: 6 | loss: 0.4439685\n",
      "\tspeed: 0.0196s/iter; left time: 251.3562s\n",
      "\titers: 700, epoch: 6 | loss: 0.4867104\n",
      "\tspeed: 0.0222s/iter; left time: 282.3681s\n",
      "\titers: 800, epoch: 6 | loss: 0.5436158\n",
      "\tspeed: 0.0211s/iter; left time: 265.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.97s\n",
      "Steps: 894 | Train Loss: 0.4919026 Vali Loss: 0.5881553 Test Loss: 0.6460100\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4787514\n",
      "\tspeed: 0.0711s/iter; left time: 882.6605s\n",
      "\titers: 200, epoch: 7 | loss: 0.4827382\n",
      "\tspeed: 0.0200s/iter; left time: 246.8901s\n",
      "\titers: 300, epoch: 7 | loss: 0.4841968\n",
      "\tspeed: 0.0204s/iter; left time: 248.6176s\n",
      "\titers: 400, epoch: 7 | loss: 0.4776973\n",
      "\tspeed: 0.0197s/iter; left time: 239.0567s\n",
      "\titers: 500, epoch: 7 | loss: 0.4611305\n",
      "\tspeed: 0.0198s/iter; left time: 237.5954s\n",
      "\titers: 600, epoch: 7 | loss: 0.4906682\n",
      "\tspeed: 0.0212s/iter; left time: 252.9959s\n",
      "\titers: 700, epoch: 7 | loss: 0.4862408\n",
      "\tspeed: 0.0227s/iter; left time: 268.1421s\n",
      "\titers: 800, epoch: 7 | loss: 0.4852181\n",
      "\tspeed: 0.0198s/iter; left time: 232.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.83s\n",
      "Steps: 894 | Train Loss: 0.4837734 Vali Loss: 0.5921434 Test Loss: 0.6460310\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4300120\n",
      "\tspeed: 0.0710s/iter; left time: 818.0788s\n",
      "\titers: 200, epoch: 8 | loss: 0.4655212\n",
      "\tspeed: 0.0245s/iter; left time: 279.7907s\n",
      "\titers: 300, epoch: 8 | loss: 0.4929775\n",
      "\tspeed: 0.0243s/iter; left time: 274.6199s\n",
      "\titers: 400, epoch: 8 | loss: 0.4875152\n",
      "\tspeed: 0.0243s/iter; left time: 273.1568s\n",
      "\titers: 500, epoch: 8 | loss: 0.5024567\n",
      "\tspeed: 0.0234s/iter; left time: 260.7864s\n",
      "\titers: 600, epoch: 8 | loss: 0.4650752\n",
      "\tspeed: 0.0238s/iter; left time: 262.6054s\n",
      "\titers: 700, epoch: 8 | loss: 0.4142633\n",
      "\tspeed: 0.0213s/iter; left time: 232.3093s\n",
      "\titers: 800, epoch: 8 | loss: 0.4879524\n",
      "\tspeed: 0.0205s/iter; left time: 221.7591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:21.05s\n",
      "Steps: 894 | Train Loss: 0.4767124 Vali Loss: 0.5899422 Test Loss: 0.6389018\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.4858656\n",
      "\tspeed: 0.0698s/iter; left time: 741.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.4581102\n",
      "\tspeed: 0.0242s/iter; left time: 255.2193s\n",
      "\titers: 300, epoch: 9 | loss: 0.4878123\n",
      "\tspeed: 0.0229s/iter; left time: 238.9476s\n",
      "\titers: 400, epoch: 9 | loss: 0.4526521\n",
      "\tspeed: 0.0242s/iter; left time: 250.3628s\n",
      "\titers: 500, epoch: 9 | loss: 0.4937755\n",
      "\tspeed: 0.0236s/iter; left time: 241.0599s\n",
      "\titers: 600, epoch: 9 | loss: 0.5283943\n",
      "\tspeed: 0.0237s/iter; left time: 239.6259s\n",
      "\titers: 700, epoch: 9 | loss: 0.4494841\n",
      "\tspeed: 0.0241s/iter; left time: 241.9269s\n",
      "\titers: 800, epoch: 9 | loss: 0.4816501\n",
      "\tspeed: 0.0238s/iter; left time: 236.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:21.59s\n",
      "Steps: 894 | Train Loss: 0.4710166 Vali Loss: 0.5918128 Test Loss: 0.6377411\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8853008151054382, rmse:0.9409042596817017, mae:0.6345837712287903, rse:0.7453628182411194\n",
      "Original data scale mse:36740496.0, rmse:6061.39404296875, mae:3751.04296875, rse:0.3020077645778656\n"
     ]
    }
   ],
   "source": [
    "# Dynamic + default variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "                \n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4391</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.4261</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4413</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.5258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.6169</td>\n",
       "      <td>0.7020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7693</td>\n",
       "      <td>0.8771</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>0.7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8392</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4441</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>0.4106</td>\n",
       "      <td>0.5274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>0.5291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7927</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.6009</td>\n",
       "      <td>0.7076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.9409</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>0.7454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4391  0.6626  0.4261  0.5244\n",
       "              2         24        0.4413  0.6643  0.4270  0.5258\n",
       "              1         96        0.7834  0.8851  0.6169  0.7020\n",
       "              2         96        0.7693  0.8771  0.6146  0.6956\n",
       "              1         168       0.8303  0.9112  0.6474  0.7218\n",
       "              2         168       0.8392  0.9161  0.6532  0.7257\n",
       "MAE           1         24        0.4441  0.6664  0.4106  0.5274\n",
       "              2         24        0.4470  0.6686  0.4129  0.5291\n",
       "              1         96        0.7927  0.8903  0.5975  0.7061\n",
       "              2         96        0.7960  0.8922  0.6009  0.7076\n",
       "              1         168       0.8570  0.9258  0.6323  0.7334\n",
       "              2         168       0.8853  0.9409  0.6346  0.7454"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_default.csv'\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16458542.0</td>\n",
       "      <td>4056.9128</td>\n",
       "      <td>2476.0964</td>\n",
       "      <td>0.2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16442007.0</td>\n",
       "      <td>4054.8745</td>\n",
       "      <td>2471.8342</td>\n",
       "      <td>0.2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32124580.0</td>\n",
       "      <td>5667.8550</td>\n",
       "      <td>3648.3237</td>\n",
       "      <td>0.2823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31628942.0</td>\n",
       "      <td>5623.9614</td>\n",
       "      <td>3646.1299</td>\n",
       "      <td>0.2801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34333700.0</td>\n",
       "      <td>5859.4966</td>\n",
       "      <td>3841.3101</td>\n",
       "      <td>0.2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35108288.0</td>\n",
       "      <td>5925.2246</td>\n",
       "      <td>3900.4709</td>\n",
       "      <td>0.2952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16317905.0</td>\n",
       "      <td>4039.5427</td>\n",
       "      <td>2366.6226</td>\n",
       "      <td>0.2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16410974.0</td>\n",
       "      <td>4051.0461</td>\n",
       "      <td>2383.5229</td>\n",
       "      <td>0.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32427548.0</td>\n",
       "      <td>5694.5190</td>\n",
       "      <td>3520.0559</td>\n",
       "      <td>0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32485964.0</td>\n",
       "      <td>5699.6460</td>\n",
       "      <td>3545.9673</td>\n",
       "      <td>0.2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35343512.0</td>\n",
       "      <td>5945.0410</td>\n",
       "      <td>3735.3179</td>\n",
       "      <td>0.2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>36740496.0</td>\n",
       "      <td>6061.3940</td>\n",
       "      <td>3751.0430</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        16458542.0  4056.9128  2476.0964  0.2017\n",
       "              2         24        16442007.0  4054.8745  2471.8342  0.2016\n",
       "              1         96        32124580.0  5667.8550  3648.3237  0.2823\n",
       "              2         96        31628942.0  5623.9614  3646.1299  0.2801\n",
       "              1         168       34333700.0  5859.4966  3841.3101  0.2919\n",
       "              2         168       35108288.0  5925.2246  3900.4709  0.2952\n",
       "MAE           1         24        16317905.0  4039.5427  2366.6226  0.2009\n",
       "              2         24        16410974.0  4051.0461  2383.5229  0.2014\n",
       "              1         96        32427548.0  5694.5190  3520.0559  0.2836\n",
       "              2         96        32485964.0  5699.6460  3545.9673  0.2838\n",
       "              1         168       35343512.0  5945.0410  3735.3179  0.2962\n",
       "              2         168       36740496.0  6061.3940  3751.0430  0.3020"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.5283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>0.4266</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7943</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.7069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7763</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.6158</td>\n",
       "      <td>0.6988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>0.7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8348</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.7238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4456  0.6675  0.4118  0.5283\n",
       "         MSE            0.4402  0.6635  0.4266  0.5251\n",
       "96       MAE            0.7943  0.8913  0.5992  0.7069\n",
       "         MSE            0.7763  0.8811  0.6158  0.6988\n",
       "168      MAE            0.8712  0.9333  0.6335  0.7394\n",
       "         MSE            0.8348  0.9137  0.6503  0.7238"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16364439.5</td>\n",
       "      <td>4045.2944</td>\n",
       "      <td>2375.0728</td>\n",
       "      <td>0.2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>16450274.5</td>\n",
       "      <td>4055.8937</td>\n",
       "      <td>2473.9653</td>\n",
       "      <td>0.2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32456756.0</td>\n",
       "      <td>5697.0825</td>\n",
       "      <td>3533.0116</td>\n",
       "      <td>0.2837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31876761.0</td>\n",
       "      <td>5645.9082</td>\n",
       "      <td>3647.2268</td>\n",
       "      <td>0.2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>36042004.0</td>\n",
       "      <td>6003.2175</td>\n",
       "      <td>3743.1804</td>\n",
       "      <td>0.2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34720994.0</td>\n",
       "      <td>5892.3606</td>\n",
       "      <td>3870.8905</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16364439.5  4045.2944  2375.0728  0.2011\n",
       "         MSE            16450274.5  4055.8937  2473.9653  0.2017\n",
       "96       MAE            32456756.0  5697.0825  3533.0116  0.2837\n",
       "         MSE            31876761.0  5645.9082  3647.2268  0.2812\n",
       "168      MAE            36042004.0  6003.2175  3743.1804  0.2991\n",
       "         MSE            34720994.0  5892.3606  3870.8905  0.2936"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0889540\n",
      "\tspeed: 0.0794s/iter; left time: 1431.2169s\n",
      "\titers: 200, epoch: 1 | loss: 0.0714957\n",
      "\tspeed: 0.0487s/iter; left time: 872.9499s\n",
      "\titers: 300, epoch: 1 | loss: 0.0649580\n",
      "\tspeed: 0.0488s/iter; left time: 869.2606s\n",
      "\titers: 400, epoch: 1 | loss: 0.0558894\n",
      "\tspeed: 0.0486s/iter; left time: 862.1229s\n",
      "\titers: 500, epoch: 1 | loss: 0.0513557\n",
      "\tspeed: 0.0488s/iter; left time: 859.0808s\n",
      "\titers: 600, epoch: 1 | loss: 0.0467323\n",
      "\tspeed: 0.0482s/iter; left time: 844.1704s\n",
      "\titers: 700, epoch: 1 | loss: 0.0564197\n",
      "\tspeed: 0.0489s/iter; left time: 851.8578s\n",
      "\titers: 800, epoch: 1 | loss: 0.0399588\n",
      "\tspeed: 0.0485s/iter; left time: 840.5092s\n",
      "\titers: 900, epoch: 1 | loss: 0.0373530\n",
      "\tspeed: 0.0488s/iter; left time: 841.0225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 906 | Train Loss: 0.0623005 Vali Loss: 0.0411079 Test Loss: 0.0449583\n",
      "Validation loss decreased (inf --> 0.041108).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0251013\n",
      "\tspeed: 0.1277s/iter; left time: 2185.7381s\n",
      "\titers: 200, epoch: 2 | loss: 0.0291056\n",
      "\tspeed: 0.0459s/iter; left time: 781.3489s\n",
      "\titers: 300, epoch: 2 | loss: 0.0237322\n",
      "\tspeed: 0.0459s/iter; left time: 776.2473s\n",
      "\titers: 400, epoch: 2 | loss: 0.0179212\n",
      "\tspeed: 0.0458s/iter; left time: 770.4580s\n",
      "\titers: 500, epoch: 2 | loss: 0.0191282\n",
      "\tspeed: 0.0459s/iter; left time: 766.9781s\n",
      "\titers: 600, epoch: 2 | loss: 0.0162809\n",
      "\tspeed: 0.0461s/iter; left time: 766.0889s\n",
      "\titers: 700, epoch: 2 | loss: 0.0181878\n",
      "\tspeed: 0.0460s/iter; left time: 759.8769s\n",
      "\titers: 800, epoch: 2 | loss: 0.0173230\n",
      "\tspeed: 0.0457s/iter; left time: 750.7831s\n",
      "\titers: 900, epoch: 2 | loss: 0.0163690\n",
      "\tspeed: 0.0459s/iter; left time: 749.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.89s\n",
      "Steps: 906 | Train Loss: 0.0212079 Vali Loss: 0.0231991 Test Loss: 0.0246498\n",
      "Validation loss decreased (0.041108 --> 0.023199).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0189414\n",
      "\tspeed: 0.1193s/iter; left time: 1933.4022s\n",
      "\titers: 200, epoch: 3 | loss: 0.0161498\n",
      "\tspeed: 0.0461s/iter; left time: 743.0253s\n",
      "\titers: 300, epoch: 3 | loss: 0.0150468\n",
      "\tspeed: 0.0462s/iter; left time: 740.1304s\n",
      "\titers: 400, epoch: 3 | loss: 0.0135456\n",
      "\tspeed: 0.0462s/iter; left time: 734.5929s\n",
      "\titers: 500, epoch: 3 | loss: 0.0156522\n",
      "\tspeed: 0.0462s/iter; left time: 730.1422s\n",
      "\titers: 600, epoch: 3 | loss: 0.0142451\n",
      "\tspeed: 0.0461s/iter; left time: 724.1582s\n",
      "\titers: 700, epoch: 3 | loss: 0.0127103\n",
      "\tspeed: 0.0462s/iter; left time: 721.8299s\n",
      "\titers: 800, epoch: 3 | loss: 0.0153899\n",
      "\tspeed: 0.0461s/iter; left time: 715.1240s\n",
      "\titers: 900, epoch: 3 | loss: 0.0145129\n",
      "\tspeed: 0.0461s/iter; left time: 711.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 906 | Train Loss: 0.0150910 Vali Loss: 0.0236837 Test Loss: 0.0250194\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0123212\n",
      "\tspeed: 0.1125s/iter; left time: 1721.6635s\n",
      "\titers: 200, epoch: 4 | loss: 0.0131628\n",
      "\tspeed: 0.0461s/iter; left time: 700.4239s\n",
      "\titers: 300, epoch: 4 | loss: 0.0137543\n",
      "\tspeed: 0.0461s/iter; left time: 695.5525s\n",
      "\titers: 400, epoch: 4 | loss: 0.0127360\n",
      "\tspeed: 0.0462s/iter; left time: 692.4787s\n",
      "\titers: 500, epoch: 4 | loss: 0.0162075\n",
      "\tspeed: 0.0461s/iter; left time: 686.6808s\n",
      "\titers: 600, epoch: 4 | loss: 0.0164934\n",
      "\tspeed: 0.0459s/iter; left time: 679.8781s\n",
      "\titers: 700, epoch: 4 | loss: 0.0157711\n",
      "\tspeed: 0.0463s/iter; left time: 680.1503s\n",
      "\titers: 800, epoch: 4 | loss: 0.0139742\n",
      "\tspeed: 0.0459s/iter; left time: 670.5552s\n",
      "\titers: 900, epoch: 4 | loss: 0.0091856\n",
      "\tspeed: 0.0467s/iter; left time: 677.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.28s\n",
      "Steps: 906 | Train Loss: 0.0137226 Vali Loss: 0.0223549 Test Loss: 0.0245243\n",
      "Validation loss decreased (0.023199 --> 0.022355).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0122703\n",
      "\tspeed: 0.1125s/iter; left time: 1619.5796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0130608\n",
      "\tspeed: 0.0459s/iter; left time: 656.9044s\n",
      "\titers: 300, epoch: 5 | loss: 0.0119467\n",
      "\tspeed: 0.0460s/iter; left time: 653.2182s\n",
      "\titers: 400, epoch: 5 | loss: 0.0161895\n",
      "\tspeed: 0.0461s/iter; left time: 650.2650s\n",
      "\titers: 500, epoch: 5 | loss: 0.0131754\n",
      "\tspeed: 0.0461s/iter; left time: 644.8162s\n",
      "\titers: 600, epoch: 5 | loss: 0.0152469\n",
      "\tspeed: 0.0461s/iter; left time: 640.2177s\n",
      "\titers: 700, epoch: 5 | loss: 0.0146566\n",
      "\tspeed: 0.0462s/iter; left time: 636.9604s\n",
      "\titers: 800, epoch: 5 | loss: 0.0132227\n",
      "\tspeed: 0.0460s/iter; left time: 629.8289s\n",
      "\titers: 900, epoch: 5 | loss: 0.0157489\n",
      "\tspeed: 0.0461s/iter; left time: 626.5589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.00s\n",
      "Steps: 906 | Train Loss: 0.0126146 Vali Loss: 0.0215252 Test Loss: 0.0240971\n",
      "Validation loss decreased (0.022355 --> 0.021525).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0122672\n",
      "\tspeed: 0.1115s/iter; left time: 1504.3453s\n",
      "\titers: 200, epoch: 6 | loss: 0.0095617\n",
      "\tspeed: 0.0462s/iter; left time: 618.6466s\n",
      "\titers: 300, epoch: 6 | loss: 0.0104980\n",
      "\tspeed: 0.0462s/iter; left time: 613.5294s\n",
      "\titers: 400, epoch: 6 | loss: 0.0114006\n",
      "\tspeed: 0.0462s/iter; left time: 610.0344s\n",
      "\titers: 500, epoch: 6 | loss: 0.0120112\n",
      "\tspeed: 0.0459s/iter; left time: 601.3915s\n",
      "\titers: 600, epoch: 6 | loss: 0.0099131\n",
      "\tspeed: 0.0462s/iter; left time: 600.1782s\n",
      "\titers: 700, epoch: 6 | loss: 0.0124735\n",
      "\tspeed: 0.0462s/iter; left time: 595.2387s\n",
      "\titers: 800, epoch: 6 | loss: 0.0116021\n",
      "\tspeed: 0.0460s/iter; left time: 587.9891s\n",
      "\titers: 900, epoch: 6 | loss: 0.0115325\n",
      "\tspeed: 0.0459s/iter; left time: 582.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.00s\n",
      "Steps: 906 | Train Loss: 0.0116504 Vali Loss: 0.0209604 Test Loss: 0.0253650\n",
      "Validation loss decreased (0.021525 --> 0.020960).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0103144\n",
      "\tspeed: 0.0989s/iter; left time: 1244.2644s\n",
      "\titers: 200, epoch: 7 | loss: 0.0094773\n",
      "\tspeed: 0.0330s/iter; left time: 411.5988s\n",
      "\titers: 300, epoch: 7 | loss: 0.0107773\n",
      "\tspeed: 0.0330s/iter; left time: 408.4247s\n",
      "\titers: 400, epoch: 7 | loss: 0.0112905\n",
      "\tspeed: 0.0330s/iter; left time: 405.6809s\n",
      "\titers: 500, epoch: 7 | loss: 0.0135907\n",
      "\tspeed: 0.0330s/iter; left time: 402.2381s\n",
      "\titers: 600, epoch: 7 | loss: 0.0077475\n",
      "\tspeed: 0.0330s/iter; left time: 398.8276s\n",
      "\titers: 700, epoch: 7 | loss: 0.0116165\n",
      "\tspeed: 0.0329s/iter; left time: 394.7645s\n",
      "\titers: 800, epoch: 7 | loss: 0.0074359\n",
      "\tspeed: 0.0329s/iter; left time: 391.4851s\n",
      "\titers: 900, epoch: 7 | loss: 0.0092981\n",
      "\tspeed: 0.0329s/iter; left time: 388.0325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.17s\n",
      "Steps: 906 | Train Loss: 0.0106992 Vali Loss: 0.0215546 Test Loss: 0.0257658\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0086913\n",
      "\tspeed: 0.1096s/iter; left time: 1280.2612s\n",
      "\titers: 200, epoch: 8 | loss: 0.0107770\n",
      "\tspeed: 0.0460s/iter; left time: 532.9870s\n",
      "\titers: 300, epoch: 8 | loss: 0.0093537\n",
      "\tspeed: 0.0462s/iter; left time: 529.7791s\n",
      "\titers: 400, epoch: 8 | loss: 0.0098148\n",
      "\tspeed: 0.0458s/iter; left time: 521.5496s\n",
      "\titers: 500, epoch: 8 | loss: 0.0099128\n",
      "\tspeed: 0.0464s/iter; left time: 523.8675s\n",
      "\titers: 600, epoch: 8 | loss: 0.0107438\n",
      "\tspeed: 0.0463s/iter; left time: 517.1626s\n",
      "\titers: 700, epoch: 8 | loss: 0.0085027\n",
      "\tspeed: 0.0461s/iter; left time: 510.9204s\n",
      "\titers: 800, epoch: 8 | loss: 0.0089798\n",
      "\tspeed: 0.0461s/iter; left time: 505.7994s\n",
      "\titers: 900, epoch: 8 | loss: 0.0115799\n",
      "\tspeed: 0.0461s/iter; left time: 501.2643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.15s\n",
      "Steps: 906 | Train Loss: 0.0097173 Vali Loss: 0.0219505 Test Loss: 0.0251282\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0091102\n",
      "\tspeed: 0.1092s/iter; left time: 1176.3104s\n",
      "\titers: 200, epoch: 9 | loss: 0.0095892\n",
      "\tspeed: 0.0459s/iter; left time: 489.5709s\n",
      "\titers: 300, epoch: 9 | loss: 0.0086562\n",
      "\tspeed: 0.0458s/iter; left time: 484.4094s\n",
      "\titers: 400, epoch: 9 | loss: 0.0109971\n",
      "\tspeed: 0.0459s/iter; left time: 480.8066s\n",
      "\titers: 500, epoch: 9 | loss: 0.0084786\n",
      "\tspeed: 0.0460s/iter; left time: 477.1423s\n",
      "\titers: 600, epoch: 9 | loss: 0.0090113\n",
      "\tspeed: 0.0460s/iter; left time: 472.2389s\n",
      "\titers: 700, epoch: 9 | loss: 0.0098727\n",
      "\tspeed: 0.0460s/iter; left time: 467.6767s\n",
      "\titers: 800, epoch: 9 | loss: 0.0102971\n",
      "\tspeed: 0.0460s/iter; left time: 463.1382s\n",
      "\titers: 900, epoch: 9 | loss: 0.0074556\n",
      "\tspeed: 0.0459s/iter; left time: 457.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 906 | Train Loss: 0.0089141 Vali Loss: 0.0235584 Test Loss: 0.0279099\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0092319\n",
      "\tspeed: 0.1091s/iter; left time: 1076.2147s\n",
      "\titers: 200, epoch: 10 | loss: 0.0093835\n",
      "\tspeed: 0.0462s/iter; left time: 451.1998s\n",
      "\titers: 300, epoch: 10 | loss: 0.0104359\n",
      "\tspeed: 0.0463s/iter; left time: 447.3792s\n",
      "\titers: 400, epoch: 10 | loss: 0.0100298\n",
      "\tspeed: 0.0461s/iter; left time: 441.1716s\n",
      "\titers: 500, epoch: 10 | loss: 0.0080205\n",
      "\tspeed: 0.0463s/iter; left time: 438.1494s\n",
      "\titers: 600, epoch: 10 | loss: 0.0061100\n",
      "\tspeed: 0.0460s/iter; left time: 431.1182s\n",
      "\titers: 700, epoch: 10 | loss: 0.0075003\n",
      "\tspeed: 0.0461s/iter; left time: 427.3053s\n",
      "\titers: 800, epoch: 10 | loss: 0.0084718\n",
      "\tspeed: 0.0463s/iter; left time: 424.4440s\n",
      "\titers: 900, epoch: 10 | loss: 0.0072007\n",
      "\tspeed: 0.0460s/iter; left time: 416.7230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.02s\n",
      "Steps: 906 | Train Loss: 0.0082030 Vali Loss: 0.0227830 Test Loss: 0.0272810\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0071136\n",
      "\tspeed: 0.1102s/iter; left time: 987.7793s\n",
      "\titers: 200, epoch: 11 | loss: 0.0074179\n",
      "\tspeed: 0.0463s/iter; left time: 410.1530s\n",
      "\titers: 300, epoch: 11 | loss: 0.0064691\n",
      "\tspeed: 0.0463s/iter; left time: 405.6365s\n",
      "\titers: 400, epoch: 11 | loss: 0.0060781\n",
      "\tspeed: 0.0462s/iter; left time: 400.4551s\n",
      "\titers: 500, epoch: 11 | loss: 0.0095313\n",
      "\tspeed: 0.0459s/iter; left time: 393.1126s\n",
      "\titers: 600, epoch: 11 | loss: 0.0079396\n",
      "\tspeed: 0.0461s/iter; left time: 389.9177s\n",
      "\titers: 700, epoch: 11 | loss: 0.0070648\n",
      "\tspeed: 0.0462s/iter; left time: 385.9620s\n",
      "\titers: 800, epoch: 11 | loss: 0.0073901\n",
      "\tspeed: 0.0460s/iter; left time: 379.6078s\n",
      "\titers: 900, epoch: 11 | loss: 0.0055460\n",
      "\tspeed: 0.0460s/iter; left time: 375.1672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0074819 Vali Loss: 0.0232332 Test Loss: 0.0284187\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025418387725949287, rmse:0.15943145751953125, mae:0.10669958591461182, rse:0.5630365014076233\n",
      "Original data scale mse:22144956.0, rmse:4705.8427734375, mae:3012.8515625, rse:0.23398399353027344\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0839555\n",
      "\tspeed: 0.0477s/iter; left time: 860.4306s\n",
      "\titers: 200, epoch: 1 | loss: 0.0772359\n",
      "\tspeed: 0.0461s/iter; left time: 825.9172s\n",
      "\titers: 300, epoch: 1 | loss: 0.0609959\n",
      "\tspeed: 0.0459s/iter; left time: 818.0362s\n",
      "\titers: 400, epoch: 1 | loss: 0.0617306\n",
      "\tspeed: 0.0448s/iter; left time: 793.2835s\n",
      "\titers: 500, epoch: 1 | loss: 0.0614438\n",
      "\tspeed: 0.0462s/iter; left time: 813.2667s\n",
      "\titers: 600, epoch: 1 | loss: 0.0532663\n",
      "\tspeed: 0.0459s/iter; left time: 804.1786s\n",
      "\titers: 700, epoch: 1 | loss: 0.0478412\n",
      "\tspeed: 0.0461s/iter; left time: 803.7738s\n",
      "\titers: 800, epoch: 1 | loss: 0.0383974\n",
      "\tspeed: 0.0458s/iter; left time: 793.2222s\n",
      "\titers: 900, epoch: 1 | loss: 0.0422786\n",
      "\tspeed: 0.0459s/iter; left time: 790.4273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.79s\n",
      "Steps: 906 | Train Loss: 0.0621303 Vali Loss: 0.0395914 Test Loss: 0.0453429\n",
      "Validation loss decreased (inf --> 0.039591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0299126\n",
      "\tspeed: 0.1181s/iter; left time: 2020.8965s\n",
      "\titers: 200, epoch: 2 | loss: 0.0343125\n",
      "\tspeed: 0.0464s/iter; left time: 790.1730s\n",
      "\titers: 300, epoch: 2 | loss: 0.0229013\n",
      "\tspeed: 0.0464s/iter; left time: 785.4367s\n",
      "\titers: 400, epoch: 2 | loss: 0.0184162\n",
      "\tspeed: 0.0464s/iter; left time: 780.2460s\n",
      "\titers: 500, epoch: 2 | loss: 0.0189139\n",
      "\tspeed: 0.0464s/iter; left time: 775.9060s\n",
      "\titers: 600, epoch: 2 | loss: 0.0149041\n",
      "\tspeed: 0.0465s/iter; left time: 772.5355s\n",
      "\titers: 700, epoch: 2 | loss: 0.0162317\n",
      "\tspeed: 0.0464s/iter; left time: 765.9910s\n",
      "\titers: 800, epoch: 2 | loss: 0.0176783\n",
      "\tspeed: 0.0466s/iter; left time: 764.8657s\n",
      "\titers: 900, epoch: 2 | loss: 0.0113557\n",
      "\tspeed: 0.0463s/iter; left time: 755.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.45s\n",
      "Steps: 906 | Train Loss: 0.0212951 Vali Loss: 0.0237607 Test Loss: 0.0249531\n",
      "Validation loss decreased (0.039591 --> 0.023761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0153891\n",
      "\tspeed: 0.1141s/iter; left time: 1849.2807s\n",
      "\titers: 200, epoch: 3 | loss: 0.0146697\n",
      "\tspeed: 0.0464s/iter; left time: 746.6871s\n",
      "\titers: 300, epoch: 3 | loss: 0.0113931\n",
      "\tspeed: 0.0462s/iter; left time: 739.5620s\n",
      "\titers: 400, epoch: 3 | loss: 0.0157250\n",
      "\tspeed: 0.0459s/iter; left time: 730.8808s\n",
      "\titers: 500, epoch: 3 | loss: 0.0159854\n",
      "\tspeed: 0.0459s/iter; left time: 725.3780s\n",
      "\titers: 600, epoch: 3 | loss: 0.0136486\n",
      "\tspeed: 0.0461s/iter; left time: 723.6598s\n",
      "\titers: 700, epoch: 3 | loss: 0.0179389\n",
      "\tspeed: 0.0461s/iter; left time: 719.1335s\n",
      "\titers: 800, epoch: 3 | loss: 0.0115505\n",
      "\tspeed: 0.0461s/iter; left time: 715.2479s\n",
      "\titers: 900, epoch: 3 | loss: 0.0176185\n",
      "\tspeed: 0.0460s/iter; left time: 708.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 906 | Train Loss: 0.0150477 Vali Loss: 0.0217326 Test Loss: 0.0244139\n",
      "Validation loss decreased (0.023761 --> 0.021733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0133397\n",
      "\tspeed: 0.1155s/iter; left time: 1767.0157s\n",
      "\titers: 200, epoch: 4 | loss: 0.0108672\n",
      "\tspeed: 0.0465s/iter; left time: 707.4526s\n",
      "\titers: 300, epoch: 4 | loss: 0.0097218\n",
      "\tspeed: 0.0467s/iter; left time: 705.1329s\n",
      "\titers: 400, epoch: 4 | loss: 0.0149228\n",
      "\tspeed: 0.0462s/iter; left time: 693.5728s\n",
      "\titers: 500, epoch: 4 | loss: 0.0164744\n",
      "\tspeed: 0.0460s/iter; left time: 686.2132s\n",
      "\titers: 600, epoch: 4 | loss: 0.0134524\n",
      "\tspeed: 0.0462s/iter; left time: 684.1371s\n",
      "\titers: 700, epoch: 4 | loss: 0.0150345\n",
      "\tspeed: 0.0465s/iter; left time: 683.9007s\n",
      "\titers: 800, epoch: 4 | loss: 0.0150478\n",
      "\tspeed: 0.0466s/iter; left time: 680.4488s\n",
      "\titers: 900, epoch: 4 | loss: 0.0137827\n",
      "\tspeed: 0.0464s/iter; left time: 672.9430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.34s\n",
      "Steps: 906 | Train Loss: 0.0138225 Vali Loss: 0.0223138 Test Loss: 0.0253570\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0107822\n",
      "\tspeed: 0.1151s/iter; left time: 1656.7903s\n",
      "\titers: 200, epoch: 5 | loss: 0.0124853\n",
      "\tspeed: 0.0471s/iter; left time: 673.3936s\n",
      "\titers: 300, epoch: 5 | loss: 0.0107216\n",
      "\tspeed: 0.0462s/iter; left time: 655.9156s\n",
      "\titers: 400, epoch: 5 | loss: 0.0129788\n",
      "\tspeed: 0.0464s/iter; left time: 653.6115s\n",
      "\titers: 500, epoch: 5 | loss: 0.0105031\n",
      "\tspeed: 0.0462s/iter; left time: 647.1258s\n",
      "\titers: 600, epoch: 5 | loss: 0.0105376\n",
      "\tspeed: 0.0463s/iter; left time: 642.8091s\n",
      "\titers: 700, epoch: 5 | loss: 0.0122224\n",
      "\tspeed: 0.0462s/iter; left time: 636.9889s\n",
      "\titers: 800, epoch: 5 | loss: 0.0117344\n",
      "\tspeed: 0.0462s/iter; left time: 632.6077s\n",
      "\titers: 900, epoch: 5 | loss: 0.0112867\n",
      "\tspeed: 0.0464s/iter; left time: 631.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.57s\n",
      "Steps: 906 | Train Loss: 0.0125022 Vali Loss: 0.0217619 Test Loss: 0.0252066\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0097979\n",
      "\tspeed: 0.1085s/iter; left time: 1463.2478s\n",
      "\titers: 200, epoch: 6 | loss: 0.0102305\n",
      "\tspeed: 0.0463s/iter; left time: 619.7032s\n",
      "\titers: 300, epoch: 6 | loss: 0.0122559\n",
      "\tspeed: 0.0463s/iter; left time: 615.0520s\n",
      "\titers: 400, epoch: 6 | loss: 0.0106983\n",
      "\tspeed: 0.0461s/iter; left time: 608.3691s\n",
      "\titers: 500, epoch: 6 | loss: 0.0124830\n",
      "\tspeed: 0.0462s/iter; left time: 605.4450s\n",
      "\titers: 600, epoch: 6 | loss: 0.0092984\n",
      "\tspeed: 0.0463s/iter; left time: 601.8281s\n",
      "\titers: 700, epoch: 6 | loss: 0.0109635\n",
      "\tspeed: 0.0463s/iter; left time: 596.4593s\n",
      "\titers: 800, epoch: 6 | loss: 0.0097367\n",
      "\tspeed: 0.0464s/iter; left time: 592.9620s\n",
      "\titers: 900, epoch: 6 | loss: 0.0097875\n",
      "\tspeed: 0.0462s/iter; left time: 585.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.04s\n",
      "Steps: 906 | Train Loss: 0.0114199 Vali Loss: 0.0226759 Test Loss: 0.0257422\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0105115\n",
      "\tspeed: 0.1115s/iter; left time: 1403.0596s\n",
      "\titers: 200, epoch: 7 | loss: 0.0100602\n",
      "\tspeed: 0.0462s/iter; left time: 576.6594s\n",
      "\titers: 300, epoch: 7 | loss: 0.0116371\n",
      "\tspeed: 0.0461s/iter; left time: 571.0516s\n",
      "\titers: 400, epoch: 7 | loss: 0.0132124\n",
      "\tspeed: 0.0459s/iter; left time: 564.2511s\n",
      "\titers: 500, epoch: 7 | loss: 0.0112586\n",
      "\tspeed: 0.0459s/iter; left time: 558.9280s\n",
      "\titers: 600, epoch: 7 | loss: 0.0103566\n",
      "\tspeed: 0.0458s/iter; left time: 553.9815s\n",
      "\titers: 700, epoch: 7 | loss: 0.0108772\n",
      "\tspeed: 0.0458s/iter; left time: 549.4791s\n",
      "\titers: 800, epoch: 7 | loss: 0.0109211\n",
      "\tspeed: 0.0459s/iter; left time: 545.3752s\n",
      "\titers: 900, epoch: 7 | loss: 0.0094603\n",
      "\tspeed: 0.0457s/iter; left time: 538.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.94s\n",
      "Steps: 906 | Train Loss: 0.0105312 Vali Loss: 0.0254768 Test Loss: 0.0280278\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0106594\n",
      "\tspeed: 0.1096s/iter; left time: 1280.2415s\n",
      "\titers: 200, epoch: 8 | loss: 0.0097553\n",
      "\tspeed: 0.0460s/iter; left time: 532.8812s\n",
      "\titers: 300, epoch: 8 | loss: 0.0090890\n",
      "\tspeed: 0.0461s/iter; left time: 529.3385s\n",
      "\titers: 400, epoch: 8 | loss: 0.0097595\n",
      "\tspeed: 0.0462s/iter; left time: 525.4414s\n",
      "\titers: 500, epoch: 8 | loss: 0.0118219\n",
      "\tspeed: 0.0462s/iter; left time: 521.1422s\n",
      "\titers: 600, epoch: 8 | loss: 0.0094345\n",
      "\tspeed: 0.0461s/iter; left time: 515.5071s\n",
      "\titers: 700, epoch: 8 | loss: 0.0076706\n",
      "\tspeed: 0.0461s/iter; left time: 511.2933s\n",
      "\titers: 800, epoch: 8 | loss: 0.0109465\n",
      "\tspeed: 0.0462s/iter; left time: 507.6978s\n",
      "\titers: 900, epoch: 8 | loss: 0.0080756\n",
      "\tspeed: 0.0461s/iter; left time: 501.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.04s\n",
      "Steps: 906 | Train Loss: 0.0094944 Vali Loss: 0.0244696 Test Loss: 0.0282418\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024378953501582146, rmse:0.156137615442276, mae:0.1056724339723587, rse:0.5514042377471924\n",
      "Original data scale mse:20262382.0, rmse:4501.37548828125, mae:2949.740234375, rse:0.22381746768951416\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0917950\n",
      "\tspeed: 0.0748s/iter; left time: 1345.7809s\n",
      "\titers: 200, epoch: 1 | loss: 0.0819643\n",
      "\tspeed: 0.0390s/iter; left time: 697.6853s\n",
      "\titers: 300, epoch: 1 | loss: 0.0747558\n",
      "\tspeed: 0.0389s/iter; left time: 691.8474s\n",
      "\titers: 400, epoch: 1 | loss: 0.0663292\n",
      "\tspeed: 0.0390s/iter; left time: 688.7508s\n",
      "\titers: 500, epoch: 1 | loss: 0.0611893\n",
      "\tspeed: 0.0389s/iter; left time: 684.3168s\n",
      "\titers: 600, epoch: 1 | loss: 0.0581180\n",
      "\tspeed: 0.0390s/iter; left time: 680.8917s\n",
      "\titers: 700, epoch: 1 | loss: 0.0528059\n",
      "\tspeed: 0.0389s/iter; left time: 676.9142s\n",
      "\titers: 800, epoch: 1 | loss: 0.0546072\n",
      "\tspeed: 0.0390s/iter; left time: 673.2037s\n",
      "\titers: 900, epoch: 1 | loss: 0.0526653\n",
      "\tspeed: 0.0389s/iter; left time: 668.9742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.46s\n",
      "Steps: 904 | Train Loss: 0.0693719 Vali Loss: 0.0568419 Test Loss: 0.0725379\n",
      "Validation loss decreased (inf --> 0.056842).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0419734\n",
      "\tspeed: 0.1264s/iter; left time: 2159.2835s\n",
      "\titers: 200, epoch: 2 | loss: 0.0339260\n",
      "\tspeed: 0.0511s/iter; left time: 868.0516s\n",
      "\titers: 300, epoch: 2 | loss: 0.0308344\n",
      "\tspeed: 0.0509s/iter; left time: 858.9609s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342491\n",
      "\tspeed: 0.0512s/iter; left time: 859.5244s\n",
      "\titers: 500, epoch: 2 | loss: 0.0325936\n",
      "\tspeed: 0.0507s/iter; left time: 844.7726s\n",
      "\titers: 600, epoch: 2 | loss: 0.0281617\n",
      "\tspeed: 0.0507s/iter; left time: 839.9960s\n",
      "\titers: 700, epoch: 2 | loss: 0.0280526\n",
      "\tspeed: 0.0507s/iter; left time: 835.2716s\n",
      "\titers: 800, epoch: 2 | loss: 0.0281532\n",
      "\tspeed: 0.0505s/iter; left time: 827.4107s\n",
      "\titers: 900, epoch: 2 | loss: 0.0317203\n",
      "\tspeed: 0.0505s/iter; left time: 821.6985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.31s\n",
      "Steps: 904 | Train Loss: 0.0332989 Vali Loss: 0.0375602 Test Loss: 0.0476636\n",
      "Validation loss decreased (0.056842 --> 0.037560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0270751\n",
      "\tspeed: 0.1416s/iter; left time: 2289.4659s\n",
      "\titers: 200, epoch: 3 | loss: 0.0214316\n",
      "\tspeed: 0.0508s/iter; left time: 816.9361s\n",
      "\titers: 300, epoch: 3 | loss: 0.0244101\n",
      "\tspeed: 0.0510s/iter; left time: 814.9880s\n",
      "\titers: 400, epoch: 3 | loss: 0.0227072\n",
      "\tspeed: 0.0512s/iter; left time: 812.3316s\n",
      "\titers: 500, epoch: 3 | loss: 0.0228741\n",
      "\tspeed: 0.0506s/iter; left time: 798.7500s\n",
      "\titers: 600, epoch: 3 | loss: 0.0226891\n",
      "\tspeed: 0.0506s/iter; left time: 792.8692s\n",
      "\titers: 700, epoch: 3 | loss: 0.0255348\n",
      "\tspeed: 0.0507s/iter; left time: 788.7993s\n",
      "\titers: 800, epoch: 3 | loss: 0.0198547\n",
      "\tspeed: 0.0505s/iter; left time: 782.0638s\n",
      "\titers: 900, epoch: 3 | loss: 0.0253143\n",
      "\tspeed: 0.0505s/iter; left time: 776.8598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.24s\n",
      "Steps: 904 | Train Loss: 0.0236762 Vali Loss: 0.0333174 Test Loss: 0.0408283\n",
      "Validation loss decreased (0.037560 --> 0.033317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0273539\n",
      "\tspeed: 0.1275s/iter; left time: 1946.9101s\n",
      "\titers: 200, epoch: 4 | loss: 0.0186819\n",
      "\tspeed: 0.0503s/iter; left time: 762.7421s\n",
      "\titers: 300, epoch: 4 | loss: 0.0258013\n",
      "\tspeed: 0.0506s/iter; left time: 763.1951s\n",
      "\titers: 400, epoch: 4 | loss: 0.0207826\n",
      "\tspeed: 0.0505s/iter; left time: 755.7418s\n",
      "\titers: 500, epoch: 4 | loss: 0.0210331\n",
      "\tspeed: 0.0506s/iter; left time: 753.0551s\n",
      "\titers: 600, epoch: 4 | loss: 0.0201617\n",
      "\tspeed: 0.0506s/iter; left time: 746.5914s\n",
      "\titers: 700, epoch: 4 | loss: 0.0220215\n",
      "\tspeed: 0.0503s/iter; left time: 737.7658s\n",
      "\titers: 800, epoch: 4 | loss: 0.0176143\n",
      "\tspeed: 0.0505s/iter; left time: 736.2629s\n",
      "\titers: 900, epoch: 4 | loss: 0.0188049\n",
      "\tspeed: 0.0506s/iter; left time: 732.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.0206353 Vali Loss: 0.0356124 Test Loss: 0.0441076\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0178201\n",
      "\tspeed: 0.1229s/iter; left time: 1766.1002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0168458\n",
      "\tspeed: 0.0506s/iter; left time: 721.9598s\n",
      "\titers: 300, epoch: 5 | loss: 0.0181483\n",
      "\tspeed: 0.0505s/iter; left time: 715.5988s\n",
      "\titers: 400, epoch: 5 | loss: 0.0217341\n",
      "\tspeed: 0.0505s/iter; left time: 710.7253s\n",
      "\titers: 500, epoch: 5 | loss: 0.0167278\n",
      "\tspeed: 0.0505s/iter; left time: 705.2176s\n",
      "\titers: 600, epoch: 5 | loss: 0.0211218\n",
      "\tspeed: 0.0505s/iter; left time: 700.5178s\n",
      "\titers: 700, epoch: 5 | loss: 0.0215601\n",
      "\tspeed: 0.0506s/iter; left time: 695.9946s\n",
      "\titers: 800, epoch: 5 | loss: 0.0165067\n",
      "\tspeed: 0.0505s/iter; left time: 690.7444s\n",
      "\titers: 900, epoch: 5 | loss: 0.0164006\n",
      "\tspeed: 0.0506s/iter; left time: 685.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0182990 Vali Loss: 0.0355958 Test Loss: 0.0475302\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0152245\n",
      "\tspeed: 0.1227s/iter; left time: 1652.3226s\n",
      "\titers: 200, epoch: 6 | loss: 0.0136940\n",
      "\tspeed: 0.0505s/iter; left time: 675.2125s\n",
      "\titers: 300, epoch: 6 | loss: 0.0180512\n",
      "\tspeed: 0.0505s/iter; left time: 669.9272s\n",
      "\titers: 400, epoch: 6 | loss: 0.0170591\n",
      "\tspeed: 0.0504s/iter; left time: 662.8786s\n",
      "\titers: 500, epoch: 6 | loss: 0.0163392\n",
      "\tspeed: 0.0505s/iter; left time: 659.6237s\n",
      "\titers: 600, epoch: 6 | loss: 0.0166611\n",
      "\tspeed: 0.0506s/iter; left time: 655.6992s\n",
      "\titers: 700, epoch: 6 | loss: 0.0148792\n",
      "\tspeed: 0.0505s/iter; left time: 649.7604s\n",
      "\titers: 800, epoch: 6 | loss: 0.0159994\n",
      "\tspeed: 0.0505s/iter; left time: 644.9481s\n",
      "\titers: 900, epoch: 6 | loss: 0.0161016\n",
      "\tspeed: 0.0506s/iter; left time: 640.2285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.89s\n",
      "Steps: 904 | Train Loss: 0.0159075 Vali Loss: 0.0363593 Test Loss: 0.0485607\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0149461\n",
      "\tspeed: 0.1230s/iter; left time: 1544.1446s\n",
      "\titers: 200, epoch: 7 | loss: 0.0141894\n",
      "\tspeed: 0.0505s/iter; left time: 629.2430s\n",
      "\titers: 300, epoch: 7 | loss: 0.0134271\n",
      "\tspeed: 0.0505s/iter; left time: 624.3955s\n",
      "\titers: 400, epoch: 7 | loss: 0.0139210\n",
      "\tspeed: 0.0505s/iter; left time: 619.1622s\n",
      "\titers: 500, epoch: 7 | loss: 0.0121520\n",
      "\tspeed: 0.0505s/iter; left time: 614.5046s\n",
      "\titers: 600, epoch: 7 | loss: 0.0138680\n",
      "\tspeed: 0.0505s/iter; left time: 608.3713s\n",
      "\titers: 700, epoch: 7 | loss: 0.0142553\n",
      "\tspeed: 0.0505s/iter; left time: 604.3867s\n",
      "\titers: 800, epoch: 7 | loss: 0.0126925\n",
      "\tspeed: 0.0505s/iter; left time: 599.3370s\n",
      "\titers: 900, epoch: 7 | loss: 0.0126902\n",
      "\tspeed: 0.0505s/iter; left time: 594.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0139040 Vali Loss: 0.0368891 Test Loss: 0.0499817\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0113801\n",
      "\tspeed: 0.1237s/iter; left time: 1441.7226s\n",
      "\titers: 200, epoch: 8 | loss: 0.0120790\n",
      "\tspeed: 0.0507s/iter; left time: 586.1137s\n",
      "\titers: 300, epoch: 8 | loss: 0.0133392\n",
      "\tspeed: 0.0507s/iter; left time: 580.1108s\n",
      "\titers: 400, epoch: 8 | loss: 0.0119347\n",
      "\tspeed: 0.0506s/iter; left time: 574.1667s\n",
      "\titers: 500, epoch: 8 | loss: 0.0129353\n",
      "\tspeed: 0.0506s/iter; left time: 569.0955s\n",
      "\titers: 600, epoch: 8 | loss: 0.0145578\n",
      "\tspeed: 0.0506s/iter; left time: 564.0046s\n",
      "\titers: 700, epoch: 8 | loss: 0.0121463\n",
      "\tspeed: 0.0505s/iter; left time: 558.4269s\n",
      "\titers: 800, epoch: 8 | loss: 0.0110260\n",
      "\tspeed: 0.0505s/iter; left time: 553.0392s\n",
      "\titers: 900, epoch: 8 | loss: 0.0105354\n",
      "\tspeed: 0.0505s/iter; left time: 548.3013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0124046 Vali Loss: 0.0382070 Test Loss: 0.0507492\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04084266349673271, rmse:0.20209567248821259, mae:0.14526280760765076, rse:0.7156617045402527\n",
      "Original data scale mse:38047776.0, rmse:6168.2880859375, mae:4162.5185546875, rse:0.3071829378604889\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0893283\n",
      "\tspeed: 0.0539s/iter; left time: 968.6030s\n",
      "\titers: 200, epoch: 1 | loss: 0.0735831\n",
      "\tspeed: 0.0511s/iter; left time: 913.4927s\n",
      "\titers: 300, epoch: 1 | loss: 0.0727072\n",
      "\tspeed: 0.0507s/iter; left time: 902.1552s\n",
      "\titers: 400, epoch: 1 | loss: 0.0683077\n",
      "\tspeed: 0.0513s/iter; left time: 907.2469s\n",
      "\titers: 500, epoch: 1 | loss: 0.0709076\n",
      "\tspeed: 0.0511s/iter; left time: 898.8699s\n",
      "\titers: 600, epoch: 1 | loss: 0.0638759\n",
      "\tspeed: 0.0508s/iter; left time: 887.5317s\n",
      "\titers: 700, epoch: 1 | loss: 0.0574505\n",
      "\tspeed: 0.0511s/iter; left time: 887.3485s\n",
      "\titers: 800, epoch: 1 | loss: 0.0564992\n",
      "\tspeed: 0.0509s/iter; left time: 878.9981s\n",
      "\titers: 900, epoch: 1 | loss: 0.0565987\n",
      "\tspeed: 0.0508s/iter; left time: 873.5558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.44s\n",
      "Steps: 904 | Train Loss: 0.0726108 Vali Loss: 0.0553978 Test Loss: 0.0697813\n",
      "Validation loss decreased (inf --> 0.055398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0472007\n",
      "\tspeed: 0.1160s/iter; left time: 1981.1284s\n",
      "\titers: 200, epoch: 2 | loss: 0.0323604\n",
      "\tspeed: 0.0389s/iter; left time: 660.8532s\n",
      "\titers: 300, epoch: 2 | loss: 0.0356214\n",
      "\tspeed: 0.0389s/iter; left time: 656.4809s\n",
      "\titers: 400, epoch: 2 | loss: 0.0299824\n",
      "\tspeed: 0.0389s/iter; left time: 652.3767s\n",
      "\titers: 500, epoch: 2 | loss: 0.0306463\n",
      "\tspeed: 0.0389s/iter; left time: 648.1753s\n",
      "\titers: 600, epoch: 2 | loss: 0.0271657\n",
      "\tspeed: 0.0389s/iter; left time: 644.8197s\n",
      "\titers: 700, epoch: 2 | loss: 0.0288954\n",
      "\tspeed: 0.0389s/iter; left time: 640.9568s\n",
      "\titers: 800, epoch: 2 | loss: 0.0290882\n",
      "\tspeed: 0.0389s/iter; left time: 636.6009s\n",
      "\titers: 900, epoch: 2 | loss: 0.0265545\n",
      "\tspeed: 0.0389s/iter; left time: 632.7739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.52s\n",
      "Steps: 904 | Train Loss: 0.0331842 Vali Loss: 0.0385960 Test Loss: 0.0459614\n",
      "Validation loss decreased (0.055398 --> 0.038596).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0249778\n",
      "\tspeed: 0.1283s/iter; left time: 2074.5574s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222612\n",
      "\tspeed: 0.0506s/iter; left time: 813.1661s\n",
      "\titers: 300, epoch: 3 | loss: 0.0277519\n",
      "\tspeed: 0.0506s/iter; left time: 807.7399s\n",
      "\titers: 400, epoch: 3 | loss: 0.0247167\n",
      "\tspeed: 0.0506s/iter; left time: 802.6627s\n",
      "\titers: 500, epoch: 3 | loss: 0.0239453\n",
      "\tspeed: 0.0506s/iter; left time: 797.8007s\n",
      "\titers: 600, epoch: 3 | loss: 0.0298728\n",
      "\tspeed: 0.0505s/iter; left time: 792.0552s\n",
      "\titers: 700, epoch: 3 | loss: 0.0258534\n",
      "\tspeed: 0.0505s/iter; left time: 786.9435s\n",
      "\titers: 800, epoch: 3 | loss: 0.0214514\n",
      "\tspeed: 0.0506s/iter; left time: 783.0610s\n",
      "\titers: 900, epoch: 3 | loss: 0.0236749\n",
      "\tspeed: 0.0506s/iter; left time: 778.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.0242943 Vali Loss: 0.0326204 Test Loss: 0.0411562\n",
      "Validation loss decreased (0.038596 --> 0.032620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0223487\n",
      "\tspeed: 0.1269s/iter; left time: 1938.0408s\n",
      "\titers: 200, epoch: 4 | loss: 0.0216792\n",
      "\tspeed: 0.0504s/iter; left time: 764.6982s\n",
      "\titers: 300, epoch: 4 | loss: 0.0216846\n",
      "\tspeed: 0.0505s/iter; left time: 760.6837s\n",
      "\titers: 400, epoch: 4 | loss: 0.0205676\n",
      "\tspeed: 0.0506s/iter; left time: 756.9815s\n",
      "\titers: 500, epoch: 4 | loss: 0.0185526\n",
      "\tspeed: 0.0506s/iter; left time: 751.8838s\n",
      "\titers: 600, epoch: 4 | loss: 0.0201641\n",
      "\tspeed: 0.0506s/iter; left time: 746.9317s\n",
      "\titers: 700, epoch: 4 | loss: 0.0210966\n",
      "\tspeed: 0.0505s/iter; left time: 741.2043s\n",
      "\titers: 800, epoch: 4 | loss: 0.0195116\n",
      "\tspeed: 0.0501s/iter; left time: 730.2328s\n",
      "\titers: 900, epoch: 4 | loss: 0.0172624\n",
      "\tspeed: 0.0503s/iter; left time: 728.2492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.87s\n",
      "Steps: 904 | Train Loss: 0.0209589 Vali Loss: 0.0344875 Test Loss: 0.0430060\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0162590\n",
      "\tspeed: 0.1265s/iter; left time: 1816.9715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0194414\n",
      "\tspeed: 0.0510s/iter; left time: 727.4649s\n",
      "\titers: 300, epoch: 5 | loss: 0.0223341\n",
      "\tspeed: 0.0506s/iter; left time: 716.2234s\n",
      "\titers: 400, epoch: 5 | loss: 0.0170808\n",
      "\tspeed: 0.0506s/iter; left time: 711.0388s\n",
      "\titers: 500, epoch: 5 | loss: 0.0193028\n",
      "\tspeed: 0.0509s/iter; left time: 711.3993s\n",
      "\titers: 600, epoch: 5 | loss: 0.0168570\n",
      "\tspeed: 0.0506s/iter; left time: 700.9946s\n",
      "\titers: 700, epoch: 5 | loss: 0.0159915\n",
      "\tspeed: 0.0506s/iter; left time: 696.2933s\n",
      "\titers: 800, epoch: 5 | loss: 0.0155971\n",
      "\tspeed: 0.0506s/iter; left time: 691.0471s\n",
      "\titers: 900, epoch: 5 | loss: 0.0181776\n",
      "\tspeed: 0.0506s/iter; left time: 686.5567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.20s\n",
      "Steps: 904 | Train Loss: 0.0183832 Vali Loss: 0.0335291 Test Loss: 0.0447241\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0184734\n",
      "\tspeed: 0.1243s/iter; left time: 1673.1831s\n",
      "\titers: 200, epoch: 6 | loss: 0.0152495\n",
      "\tspeed: 0.0506s/iter; left time: 675.5907s\n",
      "\titers: 300, epoch: 6 | loss: 0.0145051\n",
      "\tspeed: 0.0505s/iter; left time: 670.0387s\n",
      "\titers: 400, epoch: 6 | loss: 0.0149216\n",
      "\tspeed: 0.0506s/iter; left time: 666.2780s\n",
      "\titers: 500, epoch: 6 | loss: 0.0165822\n",
      "\tspeed: 0.0505s/iter; left time: 660.0382s\n",
      "\titers: 600, epoch: 6 | loss: 0.0150371\n",
      "\tspeed: 0.0505s/iter; left time: 655.1006s\n",
      "\titers: 700, epoch: 6 | loss: 0.0149773\n",
      "\tspeed: 0.0505s/iter; left time: 649.5268s\n",
      "\titers: 800, epoch: 6 | loss: 0.0164939\n",
      "\tspeed: 0.0505s/iter; left time: 644.9219s\n",
      "\titers: 900, epoch: 6 | loss: 0.0189432\n",
      "\tspeed: 0.0505s/iter; left time: 639.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0161424 Vali Loss: 0.0343019 Test Loss: 0.0447358\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0145023\n",
      "\tspeed: 0.1256s/iter; left time: 1577.0610s\n",
      "\titers: 200, epoch: 7 | loss: 0.0133851\n",
      "\tspeed: 0.0505s/iter; left time: 629.5514s\n",
      "\titers: 300, epoch: 7 | loss: 0.0165993\n",
      "\tspeed: 0.0504s/iter; left time: 622.1919s\n",
      "\titers: 400, epoch: 7 | loss: 0.0142629\n",
      "\tspeed: 0.0506s/iter; left time: 620.2840s\n",
      "\titers: 500, epoch: 7 | loss: 0.0129146\n",
      "\tspeed: 0.0505s/iter; left time: 613.8919s\n",
      "\titers: 600, epoch: 7 | loss: 0.0134747\n",
      "\tspeed: 0.0501s/iter; left time: 604.0218s\n",
      "\titers: 700, epoch: 7 | loss: 0.0143096\n",
      "\tspeed: 0.0504s/iter; left time: 602.9928s\n",
      "\titers: 800, epoch: 7 | loss: 0.0144190\n",
      "\tspeed: 0.0501s/iter; left time: 594.4604s\n",
      "\titers: 900, epoch: 7 | loss: 0.0161796\n",
      "\tspeed: 0.0502s/iter; left time: 590.2794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.91s\n",
      "Steps: 904 | Train Loss: 0.0141712 Vali Loss: 0.0367467 Test Loss: 0.0497201\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0125143\n",
      "\tspeed: 0.1264s/iter; left time: 1472.6865s\n",
      "\titers: 200, epoch: 8 | loss: 0.0127424\n",
      "\tspeed: 0.0508s/iter; left time: 586.4615s\n",
      "\titers: 300, epoch: 8 | loss: 0.0124849\n",
      "\tspeed: 0.0507s/iter; left time: 580.4325s\n",
      "\titers: 400, epoch: 8 | loss: 0.0161115\n",
      "\tspeed: 0.0508s/iter; left time: 576.7677s\n",
      "\titers: 500, epoch: 8 | loss: 0.0127786\n",
      "\tspeed: 0.0505s/iter; left time: 567.7190s\n",
      "\titers: 600, epoch: 8 | loss: 0.0126412\n",
      "\tspeed: 0.0505s/iter; left time: 562.9992s\n",
      "\titers: 700, epoch: 8 | loss: 0.0110164\n",
      "\tspeed: 0.0506s/iter; left time: 558.7586s\n",
      "\titers: 800, epoch: 8 | loss: 0.0122362\n",
      "\tspeed: 0.0505s/iter; left time: 552.6328s\n",
      "\titers: 900, epoch: 8 | loss: 0.0119362\n",
      "\tspeed: 0.0505s/iter; left time: 548.4555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.08s\n",
      "Steps: 904 | Train Loss: 0.0125703 Vali Loss: 0.0383198 Test Loss: 0.0501347\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04111573100090027, rmse:0.2027701437473297, mae:0.1442083716392517, rse:0.7180501222610474\n",
      "Original data scale mse:37857840.0, rmse:6152.87255859375, mae:4103.22314453125, rse:0.30641525983810425\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0856365\n",
      "\tspeed: 0.0814s/iter; left time: 1461.2506s\n",
      "\titers: 200, epoch: 1 | loss: 0.0822781\n",
      "\tspeed: 0.0524s/iter; left time: 935.4229s\n",
      "\titers: 300, epoch: 1 | loss: 0.0688544\n",
      "\tspeed: 0.0530s/iter; left time: 939.7332s\n",
      "\titers: 400, epoch: 1 | loss: 0.0672917\n",
      "\tspeed: 0.0525s/iter; left time: 925.9272s\n",
      "\titers: 500, epoch: 1 | loss: 0.0622659\n",
      "\tspeed: 0.0526s/iter; left time: 921.8979s\n",
      "\titers: 600, epoch: 1 | loss: 0.0644743\n",
      "\tspeed: 0.0527s/iter; left time: 919.4619s\n",
      "\titers: 700, epoch: 1 | loss: 0.0586630\n",
      "\tspeed: 0.0545s/iter; left time: 944.7719s\n",
      "\titers: 800, epoch: 1 | loss: 0.0556894\n",
      "\tspeed: 0.0544s/iter; left time: 937.1935s\n",
      "\titers: 900, epoch: 1 | loss: 0.0586593\n",
      "\tspeed: 0.0476s/iter; left time: 816.3330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.05s\n",
      "Steps: 902 | Train Loss: 0.0709377 Vali Loss: 0.0584512 Test Loss: 0.0762226\n",
      "Validation loss decreased (inf --> 0.058451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0480875\n",
      "\tspeed: 0.1407s/iter; left time: 2397.2060s\n",
      "\titers: 200, epoch: 2 | loss: 0.0387325\n",
      "\tspeed: 0.0545s/iter; left time: 922.5462s\n",
      "\titers: 300, epoch: 2 | loss: 0.0376151\n",
      "\tspeed: 0.0543s/iter; left time: 913.6312s\n",
      "\titers: 400, epoch: 2 | loss: 0.0383116\n",
      "\tspeed: 0.0541s/iter; left time: 905.1264s\n",
      "\titers: 500, epoch: 2 | loss: 0.0325459\n",
      "\tspeed: 0.0522s/iter; left time: 869.1570s\n",
      "\titers: 600, epoch: 2 | loss: 0.0301406\n",
      "\tspeed: 0.0521s/iter; left time: 861.2147s\n",
      "\titers: 700, epoch: 2 | loss: 0.0289572\n",
      "\tspeed: 0.0519s/iter; left time: 852.8955s\n",
      "\titers: 800, epoch: 2 | loss: 0.0323006\n",
      "\tspeed: 0.0512s/iter; left time: 837.3317s\n",
      "\titers: 900, epoch: 2 | loss: 0.0280608\n",
      "\tspeed: 0.0526s/iter; left time: 854.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.03s\n",
      "Steps: 902 | Train Loss: 0.0371072 Vali Loss: 0.0431044 Test Loss: 0.0528431\n",
      "Validation loss decreased (0.058451 --> 0.043104).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0317479\n",
      "\tspeed: 0.1388s/iter; left time: 2239.2669s\n",
      "\titers: 200, epoch: 3 | loss: 0.0290232\n",
      "\tspeed: 0.0531s/iter; left time: 852.2238s\n",
      "\titers: 300, epoch: 3 | loss: 0.0279541\n",
      "\tspeed: 0.0511s/iter; left time: 814.7765s\n",
      "\titers: 400, epoch: 3 | loss: 0.0316129\n",
      "\tspeed: 0.0505s/iter; left time: 800.5280s\n",
      "\titers: 500, epoch: 3 | loss: 0.0275681\n",
      "\tspeed: 0.0538s/iter; left time: 846.8207s\n",
      "\titers: 600, epoch: 3 | loss: 0.0275447\n",
      "\tspeed: 0.0537s/iter; left time: 840.1643s\n",
      "\titers: 700, epoch: 3 | loss: 0.0253199\n",
      "\tspeed: 0.0539s/iter; left time: 837.7570s\n",
      "\titers: 800, epoch: 3 | loss: 0.0248027\n",
      "\tspeed: 0.0519s/iter; left time: 801.8939s\n",
      "\titers: 900, epoch: 3 | loss: 0.0248916\n",
      "\tspeed: 0.0517s/iter; left time: 793.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.0281104 Vali Loss: 0.0389437 Test Loss: 0.0484494\n",
      "Validation loss decreased (0.043104 --> 0.038944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0237192\n",
      "\tspeed: 0.1409s/iter; left time: 2147.2989s\n",
      "\titers: 200, epoch: 4 | loss: 0.0210810\n",
      "\tspeed: 0.0524s/iter; left time: 793.1782s\n",
      "\titers: 300, epoch: 4 | loss: 0.0217524\n",
      "\tspeed: 0.0543s/iter; left time: 816.5954s\n",
      "\titers: 400, epoch: 4 | loss: 0.0203227\n",
      "\tspeed: 0.0533s/iter; left time: 796.1464s\n",
      "\titers: 500, epoch: 4 | loss: 0.0196351\n",
      "\tspeed: 0.0512s/iter; left time: 759.2841s\n",
      "\titers: 600, epoch: 4 | loss: 0.0219737\n",
      "\tspeed: 0.0480s/iter; left time: 707.2732s\n",
      "\titers: 700, epoch: 4 | loss: 0.0194686\n",
      "\tspeed: 0.0469s/iter; left time: 686.5248s\n",
      "\titers: 800, epoch: 4 | loss: 0.0204415\n",
      "\tspeed: 0.0470s/iter; left time: 682.5237s\n",
      "\titers: 900, epoch: 4 | loss: 0.0187753\n",
      "\tspeed: 0.0470s/iter; left time: 677.9238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.66s\n",
      "Steps: 902 | Train Loss: 0.0219849 Vali Loss: 0.0407572 Test Loss: 0.0454560\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0188529\n",
      "\tspeed: 0.1413s/iter; left time: 2025.8885s\n",
      "\titers: 200, epoch: 5 | loss: 0.0181861\n",
      "\tspeed: 0.0537s/iter; left time: 764.4370s\n",
      "\titers: 300, epoch: 5 | loss: 0.0183679\n",
      "\tspeed: 0.0536s/iter; left time: 757.9601s\n",
      "\titers: 400, epoch: 5 | loss: 0.0198702\n",
      "\tspeed: 0.0518s/iter; left time: 727.0627s\n",
      "\titers: 500, epoch: 5 | loss: 0.0170631\n",
      "\tspeed: 0.0516s/iter; left time: 718.8913s\n",
      "\titers: 600, epoch: 5 | loss: 0.0168931\n",
      "\tspeed: 0.0537s/iter; left time: 742.8390s\n",
      "\titers: 700, epoch: 5 | loss: 0.0176449\n",
      "\tspeed: 0.0512s/iter; left time: 702.6051s\n",
      "\titers: 800, epoch: 5 | loss: 0.0199343\n",
      "\tspeed: 0.0513s/iter; left time: 699.9680s\n",
      "\titers: 900, epoch: 5 | loss: 0.0170837\n",
      "\tspeed: 0.0519s/iter; left time: 702.5610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 902 | Train Loss: 0.0190394 Vali Loss: 0.0388810 Test Loss: 0.0492462\n",
      "Validation loss decreased (0.038944 --> 0.038881).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0182623\n",
      "\tspeed: 0.1452s/iter; left time: 1950.5675s\n",
      "\titers: 200, epoch: 6 | loss: 0.0184906\n",
      "\tspeed: 0.0571s/iter; left time: 761.7764s\n",
      "\titers: 300, epoch: 6 | loss: 0.0168571\n",
      "\tspeed: 0.0572s/iter; left time: 757.1480s\n",
      "\titers: 400, epoch: 6 | loss: 0.0185491\n",
      "\tspeed: 0.0586s/iter; left time: 769.3949s\n",
      "\titers: 500, epoch: 6 | loss: 0.0185433\n",
      "\tspeed: 0.0591s/iter; left time: 769.5308s\n",
      "\titers: 600, epoch: 6 | loss: 0.0162967\n",
      "\tspeed: 0.0601s/iter; left time: 777.0610s\n",
      "\titers: 700, epoch: 6 | loss: 0.0129243\n",
      "\tspeed: 0.0603s/iter; left time: 773.1633s\n",
      "\titers: 800, epoch: 6 | loss: 0.0152315\n",
      "\tspeed: 0.0613s/iter; left time: 780.6862s\n",
      "\titers: 900, epoch: 6 | loss: 0.0156787\n",
      "\tspeed: 0.0578s/iter; left time: 729.9974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.26s\n",
      "Steps: 902 | Train Loss: 0.0167439 Vali Loss: 0.0394341 Test Loss: 0.0507995\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0143475\n",
      "\tspeed: 0.1444s/iter; left time: 1809.4069s\n",
      "\titers: 200, epoch: 7 | loss: 0.0144678\n",
      "\tspeed: 0.0593s/iter; left time: 737.1759s\n",
      "\titers: 300, epoch: 7 | loss: 0.0147584\n",
      "\tspeed: 0.0606s/iter; left time: 746.9616s\n",
      "\titers: 400, epoch: 7 | loss: 0.0137043\n",
      "\tspeed: 0.0598s/iter; left time: 731.3477s\n",
      "\titers: 500, epoch: 7 | loss: 0.0156212\n",
      "\tspeed: 0.0617s/iter; left time: 747.9470s\n",
      "\titers: 600, epoch: 7 | loss: 0.0134583\n",
      "\tspeed: 0.0610s/iter; left time: 733.6363s\n",
      "\titers: 700, epoch: 7 | loss: 0.0135892\n",
      "\tspeed: 0.0605s/iter; left time: 722.2901s\n",
      "\titers: 800, epoch: 7 | loss: 0.0144937\n",
      "\tspeed: 0.0593s/iter; left time: 701.3880s\n",
      "\titers: 900, epoch: 7 | loss: 0.0166991\n",
      "\tspeed: 0.0565s/iter; left time: 662.4584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:54.19s\n",
      "Steps: 902 | Train Loss: 0.0147164 Vali Loss: 0.0410335 Test Loss: 0.0530247\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0132180\n",
      "\tspeed: 0.1401s/iter; left time: 1629.0088s\n",
      "\titers: 200, epoch: 8 | loss: 0.0143367\n",
      "\tspeed: 0.0519s/iter; left time: 598.7377s\n",
      "\titers: 300, epoch: 8 | loss: 0.0140027\n",
      "\tspeed: 0.0521s/iter; left time: 595.6772s\n",
      "\titers: 400, epoch: 8 | loss: 0.0126987\n",
      "\tspeed: 0.0526s/iter; left time: 595.3703s\n",
      "\titers: 500, epoch: 8 | loss: 0.0124592\n",
      "\tspeed: 0.0521s/iter; left time: 585.4764s\n",
      "\titers: 600, epoch: 8 | loss: 0.0118358\n",
      "\tspeed: 0.0523s/iter; left time: 581.4889s\n",
      "\titers: 700, epoch: 8 | loss: 0.0134271\n",
      "\tspeed: 0.0525s/iter; left time: 579.4029s\n",
      "\titers: 800, epoch: 8 | loss: 0.0119293\n",
      "\tspeed: 0.0548s/iter; left time: 598.7355s\n",
      "\titers: 900, epoch: 8 | loss: 0.0122055\n",
      "\tspeed: 0.0545s/iter; left time: 589.9845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.03s\n",
      "Steps: 902 | Train Loss: 0.0132108 Vali Loss: 0.0423554 Test Loss: 0.0552067\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0110352\n",
      "\tspeed: 0.1389s/iter; left time: 1489.4607s\n",
      "\titers: 200, epoch: 9 | loss: 0.0128792\n",
      "\tspeed: 0.0545s/iter; left time: 579.1033s\n",
      "\titers: 300, epoch: 9 | loss: 0.0141634\n",
      "\tspeed: 0.0550s/iter; left time: 578.9632s\n",
      "\titers: 400, epoch: 9 | loss: 0.0114434\n",
      "\tspeed: 0.0534s/iter; left time: 556.7425s\n",
      "\titers: 500, epoch: 9 | loss: 0.0136011\n",
      "\tspeed: 0.0540s/iter; left time: 557.4277s\n",
      "\titers: 600, epoch: 9 | loss: 0.0113317\n",
      "\tspeed: 0.0521s/iter; left time: 532.3518s\n",
      "\titers: 700, epoch: 9 | loss: 0.0123179\n",
      "\tspeed: 0.0521s/iter; left time: 527.4674s\n",
      "\titers: 800, epoch: 9 | loss: 0.0125441\n",
      "\tspeed: 0.0524s/iter; left time: 525.1814s\n",
      "\titers: 900, epoch: 9 | loss: 0.0103887\n",
      "\tspeed: 0.0550s/iter; left time: 545.9523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0119466 Vali Loss: 0.0435941 Test Loss: 0.0566103\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0098271\n",
      "\tspeed: 0.1380s/iter; left time: 1355.0916s\n",
      "\titers: 200, epoch: 10 | loss: 0.0112665\n",
      "\tspeed: 0.0539s/iter; left time: 523.6762s\n",
      "\titers: 300, epoch: 10 | loss: 0.0116968\n",
      "\tspeed: 0.0543s/iter; left time: 522.3865s\n",
      "\titers: 400, epoch: 10 | loss: 0.0113380\n",
      "\tspeed: 0.0543s/iter; left time: 517.0420s\n",
      "\titers: 500, epoch: 10 | loss: 0.0108274\n",
      "\tspeed: 0.0552s/iter; left time: 520.2767s\n",
      "\titers: 600, epoch: 10 | loss: 0.0112059\n",
      "\tspeed: 0.0540s/iter; left time: 503.7433s\n",
      "\titers: 700, epoch: 10 | loss: 0.0107836\n",
      "\tspeed: 0.0538s/iter; left time: 496.4878s\n",
      "\titers: 800, epoch: 10 | loss: 0.0101606\n",
      "\tspeed: 0.0542s/iter; left time: 494.8377s\n",
      "\titers: 900, epoch: 10 | loss: 0.0114221\n",
      "\tspeed: 0.0478s/iter; left time: 431.5544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.0108850 Vali Loss: 0.0441342 Test Loss: 0.0575222\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04924887791275978, rmse:0.22192087769508362, mae:0.1555689126253128, rse:0.7861988544464111\n",
      "Original data scale mse:46881424.0, rmse:6847.0009765625, mae:4476.52685546875, rse:0.3411504924297333\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0762265\n",
      "\tspeed: 0.0560s/iter; left time: 1004.7580s\n",
      "\titers: 200, epoch: 1 | loss: 0.0755869\n",
      "\tspeed: 0.0538s/iter; left time: 960.1222s\n",
      "\titers: 300, epoch: 1 | loss: 0.0700133\n",
      "\tspeed: 0.0527s/iter; left time: 934.9025s\n",
      "\titers: 400, epoch: 1 | loss: 0.0685892\n",
      "\tspeed: 0.0473s/iter; left time: 834.3305s\n",
      "\titers: 500, epoch: 1 | loss: 0.0644335\n",
      "\tspeed: 0.0538s/iter; left time: 944.2842s\n",
      "\titers: 600, epoch: 1 | loss: 0.0553058\n",
      "\tspeed: 0.0544s/iter; left time: 948.9920s\n",
      "\titers: 700, epoch: 1 | loss: 0.0608006\n",
      "\tspeed: 0.0543s/iter; left time: 942.0026s\n",
      "\titers: 800, epoch: 1 | loss: 0.0586581\n",
      "\tspeed: 0.0534s/iter; left time: 921.3285s\n",
      "\titers: 900, epoch: 1 | loss: 0.0605691\n",
      "\tspeed: 0.0526s/iter; left time: 902.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.03s\n",
      "Steps: 902 | Train Loss: 0.0678698 Vali Loss: 0.0579249 Test Loss: 0.0741041\n",
      "Validation loss decreased (inf --> 0.057925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0463380\n",
      "\tspeed: 0.1440s/iter; left time: 2454.1217s\n",
      "\titers: 200, epoch: 2 | loss: 0.0402933\n",
      "\tspeed: 0.0541s/iter; left time: 916.6438s\n",
      "\titers: 300, epoch: 2 | loss: 0.0357477\n",
      "\tspeed: 0.0537s/iter; left time: 904.9738s\n",
      "\titers: 400, epoch: 2 | loss: 0.0346190\n",
      "\tspeed: 0.0543s/iter; left time: 908.9758s\n",
      "\titers: 500, epoch: 2 | loss: 0.0331729\n",
      "\tspeed: 0.0538s/iter; left time: 895.3012s\n",
      "\titers: 600, epoch: 2 | loss: 0.0321862\n",
      "\tspeed: 0.0543s/iter; left time: 898.3522s\n",
      "\titers: 700, epoch: 2 | loss: 0.0340191\n",
      "\tspeed: 0.0545s/iter; left time: 895.5505s\n",
      "\titers: 800, epoch: 2 | loss: 0.0336507\n",
      "\tspeed: 0.0539s/iter; left time: 880.5728s\n",
      "\titers: 900, epoch: 2 | loss: 0.0299100\n",
      "\tspeed: 0.0528s/iter; left time: 857.9765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.96s\n",
      "Steps: 902 | Train Loss: 0.0370553 Vali Loss: 0.0447307 Test Loss: 0.0573215\n",
      "Validation loss decreased (0.057925 --> 0.044731).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0324971\n",
      "\tspeed: 0.1476s/iter; left time: 2382.6038s\n",
      "\titers: 200, epoch: 3 | loss: 0.0292266\n",
      "\tspeed: 0.0541s/iter; left time: 868.0862s\n",
      "\titers: 300, epoch: 3 | loss: 0.0325685\n",
      "\tspeed: 0.0529s/iter; left time: 843.0242s\n",
      "\titers: 400, epoch: 3 | loss: 0.0287229\n",
      "\tspeed: 0.0511s/iter; left time: 809.4695s\n",
      "\titers: 500, epoch: 3 | loss: 0.0307664\n",
      "\tspeed: 0.0545s/iter; left time: 857.9159s\n",
      "\titers: 600, epoch: 3 | loss: 0.0276806\n",
      "\tspeed: 0.0562s/iter; left time: 879.1132s\n",
      "\titers: 700, epoch: 3 | loss: 0.0289106\n",
      "\tspeed: 0.0552s/iter; left time: 857.4445s\n",
      "\titers: 800, epoch: 3 | loss: 0.0268398\n",
      "\tspeed: 0.0532s/iter; left time: 821.3803s\n",
      "\titers: 900, epoch: 3 | loss: 0.0269526\n",
      "\tspeed: 0.0547s/iter; left time: 838.9770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.27s\n",
      "Steps: 902 | Train Loss: 0.0293589 Vali Loss: 0.0380121 Test Loss: 0.0479801\n",
      "Validation loss decreased (0.044731 --> 0.038012).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0247528\n",
      "\tspeed: 0.1415s/iter; left time: 2155.5236s\n",
      "\titers: 200, epoch: 4 | loss: 0.0271202\n",
      "\tspeed: 0.0524s/iter; left time: 793.1367s\n",
      "\titers: 300, epoch: 4 | loss: 0.0231130\n",
      "\tspeed: 0.0525s/iter; left time: 789.6942s\n",
      "\titers: 400, epoch: 4 | loss: 0.0257480\n",
      "\tspeed: 0.0524s/iter; left time: 782.7579s\n",
      "\titers: 500, epoch: 4 | loss: 0.0186300\n",
      "\tspeed: 0.0519s/iter; left time: 770.5774s\n",
      "\titers: 600, epoch: 4 | loss: 0.0222115\n",
      "\tspeed: 0.0517s/iter; left time: 762.0641s\n",
      "\titers: 700, epoch: 4 | loss: 0.0204722\n",
      "\tspeed: 0.0522s/iter; left time: 763.8162s\n",
      "\titers: 800, epoch: 4 | loss: 0.0210683\n",
      "\tspeed: 0.0528s/iter; left time: 767.7959s\n",
      "\titers: 900, epoch: 4 | loss: 0.0194034\n",
      "\tspeed: 0.0524s/iter; left time: 756.7436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.63s\n",
      "Steps: 902 | Train Loss: 0.0229407 Vali Loss: 0.0371608 Test Loss: 0.0470746\n",
      "Validation loss decreased (0.038012 --> 0.037161).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0194339\n",
      "\tspeed: 0.1440s/iter; left time: 2064.4494s\n",
      "\titers: 200, epoch: 5 | loss: 0.0215396\n",
      "\tspeed: 0.0557s/iter; left time: 792.8707s\n",
      "\titers: 300, epoch: 5 | loss: 0.0206623\n",
      "\tspeed: 0.0569s/iter; left time: 804.4330s\n",
      "\titers: 400, epoch: 5 | loss: 0.0224293\n",
      "\tspeed: 0.0556s/iter; left time: 779.5366s\n",
      "\titers: 500, epoch: 5 | loss: 0.0199041\n",
      "\tspeed: 0.0549s/iter; left time: 765.3272s\n",
      "\titers: 600, epoch: 5 | loss: 0.0202787\n",
      "\tspeed: 0.0547s/iter; left time: 756.8353s\n",
      "\titers: 700, epoch: 5 | loss: 0.0180535\n",
      "\tspeed: 0.0545s/iter; left time: 748.4957s\n",
      "\titers: 800, epoch: 5 | loss: 0.0198874\n",
      "\tspeed: 0.0547s/iter; left time: 745.1322s\n",
      "\titers: 900, epoch: 5 | loss: 0.0161006\n",
      "\tspeed: 0.0537s/iter; left time: 726.8247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.98s\n",
      "Steps: 902 | Train Loss: 0.0194365 Vali Loss: 0.0371264 Test Loss: 0.0481926\n",
      "Validation loss decreased (0.037161 --> 0.037126).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0193039\n",
      "\tspeed: 0.1420s/iter; left time: 1906.9982s\n",
      "\titers: 200, epoch: 6 | loss: 0.0167743\n",
      "\tspeed: 0.0521s/iter; left time: 694.3227s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151531\n",
      "\tspeed: 0.0515s/iter; left time: 681.0154s\n",
      "\titers: 400, epoch: 6 | loss: 0.0181889\n",
      "\tspeed: 0.0532s/iter; left time: 699.1818s\n",
      "\titers: 500, epoch: 6 | loss: 0.0157116\n",
      "\tspeed: 0.0545s/iter; left time: 709.9490s\n",
      "\titers: 600, epoch: 6 | loss: 0.0167276\n",
      "\tspeed: 0.0534s/iter; left time: 690.6601s\n",
      "\titers: 700, epoch: 6 | loss: 0.0161904\n",
      "\tspeed: 0.0539s/iter; left time: 692.1811s\n",
      "\titers: 800, epoch: 6 | loss: 0.0162031\n",
      "\tspeed: 0.0524s/iter; left time: 667.4235s\n",
      "\titers: 900, epoch: 6 | loss: 0.0153796\n",
      "\tspeed: 0.0546s/iter; left time: 689.4733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.30s\n",
      "Steps: 902 | Train Loss: 0.0169561 Vali Loss: 0.0409449 Test Loss: 0.0505744\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0175484\n",
      "\tspeed: 0.1405s/iter; left time: 1760.2026s\n",
      "\titers: 200, epoch: 7 | loss: 0.0146944\n",
      "\tspeed: 0.0546s/iter; left time: 679.0514s\n",
      "\titers: 300, epoch: 7 | loss: 0.0157311\n",
      "\tspeed: 0.0540s/iter; left time: 665.1702s\n",
      "\titers: 400, epoch: 7 | loss: 0.0153387\n",
      "\tspeed: 0.0526s/iter; left time: 643.1576s\n",
      "\titers: 500, epoch: 7 | loss: 0.0140595\n",
      "\tspeed: 0.0521s/iter; left time: 632.2307s\n",
      "\titers: 600, epoch: 7 | loss: 0.0166108\n",
      "\tspeed: 0.0523s/iter; left time: 629.0234s\n",
      "\titers: 700, epoch: 7 | loss: 0.0138311\n",
      "\tspeed: 0.0528s/iter; left time: 630.1563s\n",
      "\titers: 800, epoch: 7 | loss: 0.0155218\n",
      "\tspeed: 0.0540s/iter; left time: 638.4433s\n",
      "\titers: 900, epoch: 7 | loss: 0.0156782\n",
      "\tspeed: 0.0540s/iter; left time: 633.8190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.53s\n",
      "Steps: 902 | Train Loss: 0.0150699 Vali Loss: 0.0404431 Test Loss: 0.0500767\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0127887\n",
      "\tspeed: 0.1417s/iter; left time: 1647.0485s\n",
      "\titers: 200, epoch: 8 | loss: 0.0153872\n",
      "\tspeed: 0.0546s/iter; left time: 629.4243s\n",
      "\titers: 300, epoch: 8 | loss: 0.0128063\n",
      "\tspeed: 0.0544s/iter; left time: 621.4202s\n",
      "\titers: 400, epoch: 8 | loss: 0.0120029\n",
      "\tspeed: 0.0543s/iter; left time: 615.1087s\n",
      "\titers: 500, epoch: 8 | loss: 0.0124851\n",
      "\tspeed: 0.0540s/iter; left time: 606.6182s\n",
      "\titers: 600, epoch: 8 | loss: 0.0136099\n",
      "\tspeed: 0.0490s/iter; left time: 545.1487s\n",
      "\titers: 700, epoch: 8 | loss: 0.0131226\n",
      "\tspeed: 0.0527s/iter; left time: 581.6438s\n",
      "\titers: 800, epoch: 8 | loss: 0.0133852\n",
      "\tspeed: 0.0526s/iter; left time: 574.5524s\n",
      "\titers: 900, epoch: 8 | loss: 0.0133069\n",
      "\tspeed: 0.0496s/iter; left time: 536.7664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.06s\n",
      "Steps: 902 | Train Loss: 0.0135401 Vali Loss: 0.0422328 Test Loss: 0.0517165\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0122277\n",
      "\tspeed: 0.1391s/iter; left time: 1492.0834s\n",
      "\titers: 200, epoch: 9 | loss: 0.0114483\n",
      "\tspeed: 0.0544s/iter; left time: 578.1241s\n",
      "\titers: 300, epoch: 9 | loss: 0.0112001\n",
      "\tspeed: 0.0530s/iter; left time: 558.0458s\n",
      "\titers: 400, epoch: 9 | loss: 0.0127861\n",
      "\tspeed: 0.0541s/iter; left time: 563.7860s\n",
      "\titers: 500, epoch: 9 | loss: 0.0111842\n",
      "\tspeed: 0.0513s/iter; left time: 529.6487s\n",
      "\titers: 600, epoch: 9 | loss: 0.0134543\n",
      "\tspeed: 0.0546s/iter; left time: 557.9436s\n",
      "\titers: 700, epoch: 9 | loss: 0.0113651\n",
      "\tspeed: 0.0545s/iter; left time: 552.2708s\n",
      "\titers: 800, epoch: 9 | loss: 0.0117626\n",
      "\tspeed: 0.0542s/iter; left time: 543.4041s\n",
      "\titers: 900, epoch: 9 | loss: 0.0113065\n",
      "\tspeed: 0.0467s/iter; left time: 463.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.04s\n",
      "Steps: 902 | Train Loss: 0.0122485 Vali Loss: 0.0439766 Test Loss: 0.0554558\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0127465\n",
      "\tspeed: 0.1374s/iter; left time: 1349.4101s\n",
      "\titers: 200, epoch: 10 | loss: 0.0110613\n",
      "\tspeed: 0.0521s/iter; left time: 506.5781s\n",
      "\titers: 300, epoch: 10 | loss: 0.0118991\n",
      "\tspeed: 0.0563s/iter; left time: 541.8983s\n",
      "\titers: 400, epoch: 10 | loss: 0.0102813\n",
      "\tspeed: 0.0538s/iter; left time: 512.7055s\n",
      "\titers: 500, epoch: 10 | loss: 0.0108889\n",
      "\tspeed: 0.0541s/iter; left time: 510.1982s\n",
      "\titers: 600, epoch: 10 | loss: 0.0106128\n",
      "\tspeed: 0.0547s/iter; left time: 509.6298s\n",
      "\titers: 700, epoch: 10 | loss: 0.0109965\n",
      "\tspeed: 0.0540s/iter; left time: 498.4030s\n",
      "\titers: 800, epoch: 10 | loss: 0.0114885\n",
      "\tspeed: 0.0533s/iter; left time: 486.6925s\n",
      "\titers: 900, epoch: 10 | loss: 0.0109004\n",
      "\tspeed: 0.0509s/iter; left time: 459.1539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.0111697 Vali Loss: 0.0437707 Test Loss: 0.0548268\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048157546669244766, rmse:0.2194482833147049, mae:0.15382647514343262, rse:0.7774391770362854\n",
      "Original data scale mse:46423284.0, rmse:6813.46337890625, mae:4453.21337890625, rse:0.3394794762134552\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2193371\n",
      "\tspeed: 0.0799s/iter; left time: 1440.0503s\n",
      "\titers: 200, epoch: 1 | loss: 0.1977215\n",
      "\tspeed: 0.0489s/iter; left time: 877.0389s\n",
      "\titers: 300, epoch: 1 | loss: 0.1884996\n",
      "\tspeed: 0.0347s/iter; left time: 618.8193s\n",
      "\titers: 400, epoch: 1 | loss: 0.1732073\n",
      "\tspeed: 0.0347s/iter; left time: 614.3166s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717234\n",
      "\tspeed: 0.0346s/iter; left time: 610.4419s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616005\n",
      "\tspeed: 0.0347s/iter; left time: 607.8024s\n",
      "\titers: 700, epoch: 1 | loss: 0.1801115\n",
      "\tspeed: 0.0347s/iter; left time: 604.0894s\n",
      "\titers: 800, epoch: 1 | loss: 0.1560573\n",
      "\tspeed: 0.0347s/iter; left time: 600.4930s\n",
      "\titers: 900, epoch: 1 | loss: 0.1495997\n",
      "\tspeed: 0.0438s/iter; left time: 753.9915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.03s\n",
      "Steps: 906 | Train Loss: 0.1847156 Vali Loss: 0.1656234 Test Loss: 0.1741142\n",
      "Validation loss decreased (inf --> 0.165623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1349597\n",
      "\tspeed: 0.1025s/iter; left time: 1754.9309s\n",
      "\titers: 200, epoch: 2 | loss: 0.1336994\n",
      "\tspeed: 0.0348s/iter; left time: 592.6789s\n",
      "\titers: 300, epoch: 2 | loss: 0.1209916\n",
      "\tspeed: 0.0348s/iter; left time: 589.3908s\n",
      "\titers: 400, epoch: 2 | loss: 0.1125416\n",
      "\tspeed: 0.0348s/iter; left time: 585.3946s\n",
      "\titers: 500, epoch: 2 | loss: 0.1105493\n",
      "\tspeed: 0.0349s/iter; left time: 582.7173s\n",
      "\titers: 600, epoch: 2 | loss: 0.0970625\n",
      "\tspeed: 0.0348s/iter; left time: 578.6290s\n",
      "\titers: 700, epoch: 2 | loss: 0.1116746\n",
      "\tspeed: 0.0348s/iter; left time: 574.8921s\n",
      "\titers: 800, epoch: 2 | loss: 0.1117832\n",
      "\tspeed: 0.0348s/iter; left time: 571.5046s\n",
      "\titers: 900, epoch: 2 | loss: 0.1020986\n",
      "\tspeed: 0.0350s/iter; left time: 570.4527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.90s\n",
      "Steps: 906 | Train Loss: 0.1192016 Vali Loss: 0.1266201 Test Loss: 0.1359189\n",
      "Validation loss decreased (0.165623 --> 0.126620).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1158968\n",
      "\tspeed: 0.1173s/iter; left time: 1901.0742s\n",
      "\titers: 200, epoch: 3 | loss: 0.0924040\n",
      "\tspeed: 0.0499s/iter; left time: 804.0314s\n",
      "\titers: 300, epoch: 3 | loss: 0.0899346\n",
      "\tspeed: 0.0491s/iter; left time: 786.4489s\n",
      "\titers: 400, epoch: 3 | loss: 0.0857698\n",
      "\tspeed: 0.0496s/iter; left time: 789.4368s\n",
      "\titers: 500, epoch: 3 | loss: 0.0861939\n",
      "\tspeed: 0.0500s/iter; left time: 791.0658s\n",
      "\titers: 600, epoch: 3 | loss: 0.0858602\n",
      "\tspeed: 0.0501s/iter; left time: 786.7942s\n",
      "\titers: 700, epoch: 3 | loss: 0.0784063\n",
      "\tspeed: 0.0502s/iter; left time: 783.6788s\n",
      "\titers: 800, epoch: 3 | loss: 0.0878744\n",
      "\tspeed: 0.0501s/iter; left time: 777.2549s\n",
      "\titers: 900, epoch: 3 | loss: 0.0808627\n",
      "\tspeed: 0.0499s/iter; left time: 768.1543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.38s\n",
      "Steps: 906 | Train Loss: 0.0885531 Vali Loss: 0.1016488 Test Loss: 0.1044472\n",
      "Validation loss decreased (0.126620 --> 0.101649).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0792848\n",
      "\tspeed: 0.1160s/iter; left time: 1775.7736s\n",
      "\titers: 200, epoch: 4 | loss: 0.0834116\n",
      "\tspeed: 0.0487s/iter; left time: 739.8293s\n",
      "\titers: 300, epoch: 4 | loss: 0.0808930\n",
      "\tspeed: 0.0464s/iter; left time: 700.5026s\n",
      "\titers: 400, epoch: 4 | loss: 0.0806404\n",
      "\tspeed: 0.0464s/iter; left time: 695.6692s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863321\n",
      "\tspeed: 0.0466s/iter; left time: 693.7993s\n",
      "\titers: 600, epoch: 4 | loss: 0.0819875\n",
      "\tspeed: 0.0459s/iter; left time: 678.8118s\n",
      "\titers: 700, epoch: 4 | loss: 0.0820523\n",
      "\tspeed: 0.0464s/iter; left time: 682.3844s\n",
      "\titers: 800, epoch: 4 | loss: 0.0829418\n",
      "\tspeed: 0.0467s/iter; left time: 682.0135s\n",
      "\titers: 900, epoch: 4 | loss: 0.0640380\n",
      "\tspeed: 0.0485s/iter; left time: 704.0874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 906 | Train Loss: 0.0792295 Vali Loss: 0.0987642 Test Loss: 0.0995154\n",
      "Validation loss decreased (0.101649 --> 0.098764).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0736899\n",
      "\tspeed: 0.1146s/iter; left time: 1649.8024s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741243\n",
      "\tspeed: 0.0488s/iter; left time: 697.5204s\n",
      "\titers: 300, epoch: 5 | loss: 0.0739710\n",
      "\tspeed: 0.0491s/iter; left time: 697.4118s\n",
      "\titers: 400, epoch: 5 | loss: 0.0845009\n",
      "\tspeed: 0.0491s/iter; left time: 692.7180s\n",
      "\titers: 500, epoch: 5 | loss: 0.0734567\n",
      "\tspeed: 0.0490s/iter; left time: 686.3135s\n",
      "\titers: 600, epoch: 5 | loss: 0.0848674\n",
      "\tspeed: 0.0492s/iter; left time: 683.7819s\n",
      "\titers: 700, epoch: 5 | loss: 0.0792132\n",
      "\tspeed: 0.0478s/iter; left time: 659.2613s\n",
      "\titers: 800, epoch: 5 | loss: 0.0796287\n",
      "\tspeed: 0.0457s/iter; left time: 625.8121s\n",
      "\titers: 900, epoch: 5 | loss: 0.0893356\n",
      "\tspeed: 0.0463s/iter; left time: 629.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.96s\n",
      "Steps: 906 | Train Loss: 0.0754891 Vali Loss: 0.0970423 Test Loss: 0.1023288\n",
      "Validation loss decreased (0.098764 --> 0.097042).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0770415\n",
      "\tspeed: 0.1118s/iter; left time: 1508.8977s\n",
      "\titers: 200, epoch: 6 | loss: 0.0650214\n",
      "\tspeed: 0.0462s/iter; left time: 619.1697s\n",
      "\titers: 300, epoch: 6 | loss: 0.0709342\n",
      "\tspeed: 0.0462s/iter; left time: 614.7063s\n",
      "\titers: 400, epoch: 6 | loss: 0.0764454\n",
      "\tspeed: 0.0460s/iter; left time: 607.0304s\n",
      "\titers: 500, epoch: 6 | loss: 0.0718121\n",
      "\tspeed: 0.0461s/iter; left time: 603.3407s\n",
      "\titers: 600, epoch: 6 | loss: 0.0657555\n",
      "\tspeed: 0.0461s/iter; left time: 598.5209s\n",
      "\titers: 700, epoch: 6 | loss: 0.0661870\n",
      "\tspeed: 0.0461s/iter; left time: 594.5992s\n",
      "\titers: 800, epoch: 6 | loss: 0.0700175\n",
      "\tspeed: 0.0459s/iter; left time: 586.9217s\n",
      "\titers: 900, epoch: 6 | loss: 0.0714951\n",
      "\tspeed: 0.0461s/iter; left time: 585.1126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 906 | Train Loss: 0.0722549 Vali Loss: 0.0961112 Test Loss: 0.1040979\n",
      "Validation loss decreased (0.097042 --> 0.096111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0660138\n",
      "\tspeed: 0.1115s/iter; left time: 1403.4658s\n",
      "\titers: 200, epoch: 7 | loss: 0.0665872\n",
      "\tspeed: 0.0460s/iter; left time: 574.7932s\n",
      "\titers: 300, epoch: 7 | loss: 0.0691996\n",
      "\tspeed: 0.0464s/iter; left time: 574.0775s\n",
      "\titers: 400, epoch: 7 | loss: 0.0673207\n",
      "\tspeed: 0.0464s/iter; left time: 570.1206s\n",
      "\titers: 500, epoch: 7 | loss: 0.0736774\n",
      "\tspeed: 0.0464s/iter; left time: 565.4169s\n",
      "\titers: 600, epoch: 7 | loss: 0.0582451\n",
      "\tspeed: 0.0461s/iter; left time: 557.2789s\n",
      "\titers: 700, epoch: 7 | loss: 0.0747162\n",
      "\tspeed: 0.0462s/iter; left time: 554.0241s\n",
      "\titers: 800, epoch: 7 | loss: 0.0575175\n",
      "\tspeed: 0.0462s/iter; left time: 548.8776s\n",
      "\titers: 900, epoch: 7 | loss: 0.0671092\n",
      "\tspeed: 0.0460s/iter; left time: 542.6766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 906 | Train Loss: 0.0692671 Vali Loss: 0.0940558 Test Loss: 0.1026407\n",
      "Validation loss decreased (0.096111 --> 0.094056).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0589510\n",
      "\tspeed: 0.1131s/iter; left time: 1320.6464s\n",
      "\titers: 200, epoch: 8 | loss: 0.0728251\n",
      "\tspeed: 0.0459s/iter; left time: 530.9799s\n",
      "\titers: 300, epoch: 8 | loss: 0.0642487\n",
      "\tspeed: 0.0460s/iter; left time: 527.9372s\n",
      "\titers: 400, epoch: 8 | loss: 0.0674729\n",
      "\tspeed: 0.0459s/iter; left time: 522.8023s\n",
      "\titers: 500, epoch: 8 | loss: 0.0671887\n",
      "\tspeed: 0.0461s/iter; left time: 519.9183s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739231\n",
      "\tspeed: 0.0463s/iter; left time: 518.0946s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576856\n",
      "\tspeed: 0.0462s/iter; left time: 512.3815s\n",
      "\titers: 800, epoch: 8 | loss: 0.0614317\n",
      "\tspeed: 0.0464s/iter; left time: 509.1035s\n",
      "\titers: 900, epoch: 8 | loss: 0.0775866\n",
      "\tspeed: 0.0461s/iter; left time: 501.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.04s\n",
      "Steps: 906 | Train Loss: 0.0661331 Vali Loss: 0.0988925 Test Loss: 0.1027935\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0666226\n",
      "\tspeed: 0.1083s/iter; left time: 1167.1050s\n",
      "\titers: 200, epoch: 9 | loss: 0.0640848\n",
      "\tspeed: 0.0462s/iter; left time: 492.7474s\n",
      "\titers: 300, epoch: 9 | loss: 0.0630905\n",
      "\tspeed: 0.0459s/iter; left time: 484.9613s\n",
      "\titers: 400, epoch: 9 | loss: 0.0661945\n",
      "\tspeed: 0.0461s/iter; left time: 482.9389s\n",
      "\titers: 500, epoch: 9 | loss: 0.0665071\n",
      "\tspeed: 0.0458s/iter; left time: 474.5960s\n",
      "\titers: 600, epoch: 9 | loss: 0.0685818\n",
      "\tspeed: 0.0459s/iter; left time: 471.8985s\n",
      "\titers: 700, epoch: 9 | loss: 0.0656188\n",
      "\tspeed: 0.0460s/iter; left time: 467.8106s\n",
      "\titers: 800, epoch: 9 | loss: 0.0669846\n",
      "\tspeed: 0.0460s/iter; left time: 463.6845s\n",
      "\titers: 900, epoch: 9 | loss: 0.0599250\n",
      "\tspeed: 0.0461s/iter; left time: 459.6102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 906 | Train Loss: 0.0637068 Vali Loss: 0.0966993 Test Loss: 0.1047861\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0632723\n",
      "\tspeed: 0.1094s/iter; left time: 1079.7017s\n",
      "\titers: 200, epoch: 10 | loss: 0.0692926\n",
      "\tspeed: 0.0461s/iter; left time: 449.9957s\n",
      "\titers: 300, epoch: 10 | loss: 0.0645902\n",
      "\tspeed: 0.0461s/iter; left time: 445.7335s\n",
      "\titers: 400, epoch: 10 | loss: 0.0728916\n",
      "\tspeed: 0.0461s/iter; left time: 440.6280s\n",
      "\titers: 500, epoch: 10 | loss: 0.0589608\n",
      "\tspeed: 0.0460s/iter; left time: 435.3236s\n",
      "\titers: 600, epoch: 10 | loss: 0.0589466\n",
      "\tspeed: 0.0462s/iter; left time: 432.9739s\n",
      "\titers: 700, epoch: 10 | loss: 0.0540567\n",
      "\tspeed: 0.0462s/iter; left time: 427.9005s\n",
      "\titers: 800, epoch: 10 | loss: 0.0578213\n",
      "\tspeed: 0.0460s/iter; left time: 422.0872s\n",
      "\titers: 900, epoch: 10 | loss: 0.0561226\n",
      "\tspeed: 0.0460s/iter; left time: 417.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.96s\n",
      "Steps: 906 | Train Loss: 0.0611027 Vali Loss: 0.0954745 Test Loss: 0.1028340\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0608129\n",
      "\tspeed: 0.0963s/iter; left time: 862.8655s\n",
      "\titers: 200, epoch: 11 | loss: 0.0599368\n",
      "\tspeed: 0.0330s/iter; left time: 292.4757s\n",
      "\titers: 300, epoch: 11 | loss: 0.0558104\n",
      "\tspeed: 0.0330s/iter; left time: 289.0051s\n",
      "\titers: 400, epoch: 11 | loss: 0.0515542\n",
      "\tspeed: 0.0330s/iter; left time: 285.8763s\n",
      "\titers: 500, epoch: 11 | loss: 0.0650875\n",
      "\tspeed: 0.0330s/iter; left time: 282.2177s\n",
      "\titers: 600, epoch: 11 | loss: 0.0647349\n",
      "\tspeed: 0.0330s/iter; left time: 278.9706s\n",
      "\titers: 700, epoch: 11 | loss: 0.0569948\n",
      "\tspeed: 0.0330s/iter; left time: 275.7061s\n",
      "\titers: 800, epoch: 11 | loss: 0.0515813\n",
      "\tspeed: 0.0330s/iter; left time: 272.3039s\n",
      "\titers: 900, epoch: 11 | loss: 0.0487354\n",
      "\tspeed: 0.0330s/iter; left time: 269.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:30.15s\n",
      "Steps: 906 | Train Loss: 0.0585829 Vali Loss: 0.0957306 Test Loss: 0.1064269\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0584590\n",
      "\tspeed: 0.1084s/iter; left time: 873.0221s\n",
      "\titers: 200, epoch: 12 | loss: 0.0584398\n",
      "\tspeed: 0.0457s/iter; left time: 363.7703s\n",
      "\titers: 300, epoch: 12 | loss: 0.0573530\n",
      "\tspeed: 0.0458s/iter; left time: 360.1061s\n",
      "\titers: 400, epoch: 12 | loss: 0.0605661\n",
      "\tspeed: 0.0457s/iter; left time: 354.1991s\n",
      "\titers: 500, epoch: 12 | loss: 0.0548147\n",
      "\tspeed: 0.0458s/iter; left time: 350.3933s\n",
      "\titers: 600, epoch: 12 | loss: 0.0529713\n",
      "\tspeed: 0.0452s/iter; left time: 341.4496s\n",
      "\titers: 700, epoch: 12 | loss: 0.0574244\n",
      "\tspeed: 0.0456s/iter; left time: 339.8147s\n",
      "\titers: 800, epoch: 12 | loss: 0.0501836\n",
      "\tspeed: 0.0453s/iter; left time: 333.5429s\n",
      "\titers: 900, epoch: 12 | loss: 0.0584249\n",
      "\tspeed: 0.0455s/iter; left time: 329.7835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.45s\n",
      "Steps: 906 | Train Loss: 0.0567967 Vali Loss: 0.0991605 Test Loss: 0.1062757\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02503511682152748, rmse:0.1582248955965042, mae:0.10250058770179749, rse:0.5587754845619202\n",
      "Original data scale mse:21606588.0, rmse:4648.28857421875, mae:2894.677001953125, rse:0.23112228512763977\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2209228\n",
      "\tspeed: 0.0478s/iter; left time: 861.0330s\n",
      "\titers: 200, epoch: 1 | loss: 0.1902164\n",
      "\tspeed: 0.0465s/iter; left time: 832.6844s\n",
      "\titers: 300, epoch: 1 | loss: 0.1861653\n",
      "\tspeed: 0.0464s/iter; left time: 827.5889s\n",
      "\titers: 400, epoch: 1 | loss: 0.1823416\n",
      "\tspeed: 0.0465s/iter; left time: 824.3085s\n",
      "\titers: 500, epoch: 1 | loss: 0.1792150\n",
      "\tspeed: 0.0458s/iter; left time: 806.9885s\n",
      "\titers: 600, epoch: 1 | loss: 0.1767687\n",
      "\tspeed: 0.0464s/iter; left time: 813.1326s\n",
      "\titers: 700, epoch: 1 | loss: 0.1690864\n",
      "\tspeed: 0.0464s/iter; left time: 808.0412s\n",
      "\titers: 800, epoch: 1 | loss: 0.1706984\n",
      "\tspeed: 0.0464s/iter; left time: 802.9419s\n",
      "\titers: 900, epoch: 1 | loss: 0.1513919\n",
      "\tspeed: 0.0464s/iter; left time: 798.3341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.19s\n",
      "Steps: 906 | Train Loss: 0.1882799 Vali Loss: 0.1665931 Test Loss: 0.1768704\n",
      "Validation loss decreased (inf --> 0.166593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1368255\n",
      "\tspeed: 0.1142s/iter; left time: 1954.5640s\n",
      "\titers: 200, epoch: 2 | loss: 0.1390444\n",
      "\tspeed: 0.0480s/iter; left time: 816.2965s\n",
      "\titers: 300, epoch: 2 | loss: 0.1252545\n",
      "\tspeed: 0.0494s/iter; left time: 835.4457s\n",
      "\titers: 400, epoch: 2 | loss: 0.1175311\n",
      "\tspeed: 0.0490s/iter; left time: 824.1484s\n",
      "\titers: 500, epoch: 2 | loss: 0.1201848\n",
      "\tspeed: 0.0477s/iter; left time: 796.8492s\n",
      "\titers: 600, epoch: 2 | loss: 0.1047623\n",
      "\tspeed: 0.0483s/iter; left time: 803.2022s\n",
      "\titers: 700, epoch: 2 | loss: 0.1203549\n",
      "\tspeed: 0.0496s/iter; left time: 818.5162s\n",
      "\titers: 800, epoch: 2 | loss: 0.0944271\n",
      "\tspeed: 0.0493s/iter; left time: 809.6808s\n",
      "\titers: 900, epoch: 2 | loss: 0.1203178\n",
      "\tspeed: 0.0488s/iter; left time: 795.5801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.20s\n",
      "Steps: 906 | Train Loss: 0.1226015 Vali Loss: 0.1264837 Test Loss: 0.1367266\n",
      "Validation loss decreased (0.166593 --> 0.126484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049845\n",
      "\tspeed: 0.1190s/iter; left time: 1928.3016s\n",
      "\titers: 200, epoch: 3 | loss: 0.1047302\n",
      "\tspeed: 0.0500s/iter; left time: 805.2595s\n",
      "\titers: 300, epoch: 3 | loss: 0.0955707\n",
      "\tspeed: 0.0489s/iter; left time: 782.8316s\n",
      "\titers: 400, epoch: 3 | loss: 0.1100043\n",
      "\tspeed: 0.0495s/iter; left time: 786.7319s\n",
      "\titers: 500, epoch: 3 | loss: 0.1044606\n",
      "\tspeed: 0.0502s/iter; left time: 794.0292s\n",
      "\titers: 600, epoch: 3 | loss: 0.0991454\n",
      "\tspeed: 0.0494s/iter; left time: 776.3872s\n",
      "\titers: 700, epoch: 3 | loss: 0.1010945\n",
      "\tspeed: 0.0497s/iter; left time: 775.9127s\n",
      "\titers: 800, epoch: 3 | loss: 0.1062495\n",
      "\tspeed: 0.0496s/iter; left time: 769.8946s\n",
      "\titers: 900, epoch: 3 | loss: 0.1075993\n",
      "\tspeed: 0.0498s/iter; left time: 767.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.26s\n",
      "Steps: 906 | Train Loss: 0.1036576 Vali Loss: 0.1235929 Test Loss: 0.1351364\n",
      "Validation loss decreased (0.126484 --> 0.123593).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0985526\n",
      "\tspeed: 0.1170s/iter; left time: 1790.6937s\n",
      "\titers: 200, epoch: 4 | loss: 0.1032197\n",
      "\tspeed: 0.0460s/iter; left time: 699.1319s\n",
      "\titers: 300, epoch: 4 | loss: 0.0960748\n",
      "\tspeed: 0.0501s/iter; left time: 757.1920s\n",
      "\titers: 400, epoch: 4 | loss: 0.1083821\n",
      "\tspeed: 0.0499s/iter; left time: 748.3327s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976141\n",
      "\tspeed: 0.0496s/iter; left time: 739.3338s\n",
      "\titers: 600, epoch: 4 | loss: 0.0889361\n",
      "\tspeed: 0.0488s/iter; left time: 722.9771s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876954\n",
      "\tspeed: 0.0460s/iter; left time: 676.1459s\n",
      "\titers: 800, epoch: 4 | loss: 0.0864828\n",
      "\tspeed: 0.0462s/iter; left time: 674.3809s\n",
      "\titers: 900, epoch: 4 | loss: 0.0808749\n",
      "\tspeed: 0.0459s/iter; left time: 664.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.58s\n",
      "Steps: 906 | Train Loss: 0.0955038 Vali Loss: 0.0984326 Test Loss: 0.1020987\n",
      "Validation loss decreased (0.123593 --> 0.098433).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693327\n",
      "\tspeed: 0.1166s/iter; left time: 1679.2733s\n",
      "\titers: 200, epoch: 5 | loss: 0.0791737\n",
      "\tspeed: 0.0501s/iter; left time: 716.1611s\n",
      "\titers: 300, epoch: 5 | loss: 0.0842561\n",
      "\tspeed: 0.0500s/iter; left time: 709.8103s\n",
      "\titers: 400, epoch: 5 | loss: 0.0753921\n",
      "\tspeed: 0.0501s/iter; left time: 706.0464s\n",
      "\titers: 500, epoch: 5 | loss: 0.0805455\n",
      "\tspeed: 0.0501s/iter; left time: 700.6421s\n",
      "\titers: 600, epoch: 5 | loss: 0.0652466\n",
      "\tspeed: 0.0502s/iter; left time: 697.8490s\n",
      "\titers: 700, epoch: 5 | loss: 0.0767411\n",
      "\tspeed: 0.0503s/iter; left time: 694.5551s\n",
      "\titers: 800, epoch: 5 | loss: 0.0734380\n",
      "\tspeed: 0.0500s/iter; left time: 684.2448s\n",
      "\titers: 900, epoch: 5 | loss: 0.0672268\n",
      "\tspeed: 0.0501s/iter; left time: 680.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.63s\n",
      "Steps: 906 | Train Loss: 0.0775636 Vali Loss: 0.0965865 Test Loss: 0.1022946\n",
      "Validation loss decreased (0.098433 --> 0.096587).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0776920\n",
      "\tspeed: 0.1167s/iter; left time: 1573.8972s\n",
      "\titers: 200, epoch: 6 | loss: 0.0689330\n",
      "\tspeed: 0.0492s/iter; left time: 659.0781s\n",
      "\titers: 300, epoch: 6 | loss: 0.0715801\n",
      "\tspeed: 0.0492s/iter; left time: 653.7689s\n",
      "\titers: 400, epoch: 6 | loss: 0.0735732\n",
      "\tspeed: 0.0493s/iter; left time: 649.8235s\n",
      "\titers: 500, epoch: 6 | loss: 0.0734075\n",
      "\tspeed: 0.0489s/iter; left time: 640.5240s\n",
      "\titers: 600, epoch: 6 | loss: 0.0756910\n",
      "\tspeed: 0.0491s/iter; left time: 637.6909s\n",
      "\titers: 700, epoch: 6 | loss: 0.0700148\n",
      "\tspeed: 0.0489s/iter; left time: 630.7866s\n",
      "\titers: 800, epoch: 6 | loss: 0.0713590\n",
      "\tspeed: 0.0490s/iter; left time: 626.3290s\n",
      "\titers: 900, epoch: 6 | loss: 0.0711626\n",
      "\tspeed: 0.0491s/iter; left time: 623.2314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.77s\n",
      "Steps: 906 | Train Loss: 0.0737180 Vali Loss: 0.0977053 Test Loss: 0.1045457\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0707487\n",
      "\tspeed: 0.0979s/iter; left time: 1231.6815s\n",
      "\titers: 200, epoch: 7 | loss: 0.0672919\n",
      "\tspeed: 0.0330s/iter; left time: 412.5212s\n",
      "\titers: 300, epoch: 7 | loss: 0.0736401\n",
      "\tspeed: 0.0331s/iter; left time: 409.5098s\n",
      "\titers: 400, epoch: 7 | loss: 0.0677582\n",
      "\tspeed: 0.0330s/iter; left time: 405.9263s\n",
      "\titers: 500, epoch: 7 | loss: 0.0748733\n",
      "\tspeed: 0.0331s/iter; left time: 402.8686s\n",
      "\titers: 600, epoch: 7 | loss: 0.0729828\n",
      "\tspeed: 0.0330s/iter; left time: 399.2636s\n",
      "\titers: 700, epoch: 7 | loss: 0.0575399\n",
      "\tspeed: 0.0330s/iter; left time: 395.7644s\n",
      "\titers: 800, epoch: 7 | loss: 0.0780056\n",
      "\tspeed: 0.0330s/iter; left time: 392.5523s\n",
      "\titers: 900, epoch: 7 | loss: 0.0625338\n",
      "\tspeed: 0.0330s/iter; left time: 389.2472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:30.23s\n",
      "Steps: 906 | Train Loss: 0.0701726 Vali Loss: 0.0972105 Test Loss: 0.1042383\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0615204\n",
      "\tspeed: 0.1131s/iter; left time: 1320.5400s\n",
      "\titers: 200, epoch: 8 | loss: 0.0659045\n",
      "\tspeed: 0.0494s/iter; left time: 571.5862s\n",
      "\titers: 300, epoch: 8 | loss: 0.0652609\n",
      "\tspeed: 0.0493s/iter; left time: 566.1163s\n",
      "\titers: 400, epoch: 8 | loss: 0.0691719\n",
      "\tspeed: 0.0489s/iter; left time: 556.9058s\n",
      "\titers: 500, epoch: 8 | loss: 0.0823549\n",
      "\tspeed: 0.0492s/iter; left time: 554.9805s\n",
      "\titers: 600, epoch: 8 | loss: 0.0681711\n",
      "\tspeed: 0.0494s/iter; left time: 552.0011s\n",
      "\titers: 700, epoch: 8 | loss: 0.0681319\n",
      "\tspeed: 0.0493s/iter; left time: 546.5609s\n",
      "\titers: 800, epoch: 8 | loss: 0.0736955\n",
      "\tspeed: 0.0492s/iter; left time: 539.8055s\n",
      "\titers: 900, epoch: 8 | loss: 0.0596028\n",
      "\tspeed: 0.0492s/iter; left time: 535.4045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:44.82s\n",
      "Steps: 906 | Train Loss: 0.0674239 Vali Loss: 0.0962781 Test Loss: 0.1040185\n",
      "Validation loss decreased (0.096587 --> 0.096278).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0616742\n",
      "\tspeed: 0.1120s/iter; left time: 1206.3109s\n",
      "\titers: 200, epoch: 9 | loss: 0.0522444\n",
      "\tspeed: 0.0462s/iter; left time: 492.7658s\n",
      "\titers: 300, epoch: 9 | loss: 0.0629223\n",
      "\tspeed: 0.0460s/iter; left time: 486.6415s\n",
      "\titers: 400, epoch: 9 | loss: 0.0630886\n",
      "\tspeed: 0.0461s/iter; left time: 483.0145s\n",
      "\titers: 500, epoch: 9 | loss: 0.0573699\n",
      "\tspeed: 0.0463s/iter; left time: 479.7663s\n",
      "\titers: 600, epoch: 9 | loss: 0.0559906\n",
      "\tspeed: 0.0461s/iter; left time: 473.1879s\n",
      "\titers: 700, epoch: 9 | loss: 0.0674314\n",
      "\tspeed: 0.0461s/iter; left time: 469.4096s\n",
      "\titers: 800, epoch: 9 | loss: 0.0620898\n",
      "\tspeed: 0.0461s/iter; left time: 463.9950s\n",
      "\titers: 900, epoch: 9 | loss: 0.0567981\n",
      "\tspeed: 0.0460s/iter; left time: 458.4734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.99s\n",
      "Steps: 906 | Train Loss: 0.0646134 Vali Loss: 0.0964188 Test Loss: 0.1026151\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0548026\n",
      "\tspeed: 0.1097s/iter; left time: 1082.8463s\n",
      "\titers: 200, epoch: 10 | loss: 0.0589220\n",
      "\tspeed: 0.0469s/iter; left time: 458.5401s\n",
      "\titers: 300, epoch: 10 | loss: 0.0606921\n",
      "\tspeed: 0.0467s/iter; left time: 451.6453s\n",
      "\titers: 400, epoch: 10 | loss: 0.0613493\n",
      "\tspeed: 0.0462s/iter; left time: 442.4304s\n",
      "\titers: 500, epoch: 10 | loss: 0.0667166\n",
      "\tspeed: 0.0464s/iter; left time: 439.6497s\n",
      "\titers: 600, epoch: 10 | loss: 0.0655026\n",
      "\tspeed: 0.0461s/iter; left time: 432.0227s\n",
      "\titers: 700, epoch: 10 | loss: 0.0616325\n",
      "\tspeed: 0.0462s/iter; left time: 427.8859s\n",
      "\titers: 800, epoch: 10 | loss: 0.0592780\n",
      "\tspeed: 0.0482s/iter; left time: 441.4800s\n",
      "\titers: 900, epoch: 10 | loss: 0.0651274\n",
      "\tspeed: 0.0492s/iter; left time: 446.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.78s\n",
      "Steps: 906 | Train Loss: 0.0621331 Vali Loss: 0.0966932 Test Loss: 0.1082848\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0611093\n",
      "\tspeed: 0.1106s/iter; left time: 991.0041s\n",
      "\titers: 200, epoch: 11 | loss: 0.0578680\n",
      "\tspeed: 0.0459s/iter; left time: 406.4763s\n",
      "\titers: 300, epoch: 11 | loss: 0.0573885\n",
      "\tspeed: 0.0461s/iter; left time: 404.2706s\n",
      "\titers: 400, epoch: 11 | loss: 0.0532788\n",
      "\tspeed: 0.0460s/iter; left time: 398.7547s\n",
      "\titers: 500, epoch: 11 | loss: 0.0575405\n",
      "\tspeed: 0.0463s/iter; left time: 396.1567s\n",
      "\titers: 600, epoch: 11 | loss: 0.0601803\n",
      "\tspeed: 0.0462s/iter; left time: 391.0143s\n",
      "\titers: 700, epoch: 11 | loss: 0.0570868\n",
      "\tspeed: 0.0462s/iter; left time: 386.6273s\n",
      "\titers: 800, epoch: 11 | loss: 0.0665489\n",
      "\tspeed: 0.0451s/iter; left time: 372.9701s\n",
      "\titers: 900, epoch: 11 | loss: 0.0546679\n",
      "\tspeed: 0.0458s/iter; left time: 374.0804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.96s\n",
      "Steps: 906 | Train Loss: 0.0597120 Vali Loss: 0.0936789 Test Loss: 0.1029847\n",
      "Validation loss decreased (0.096278 --> 0.093679).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0630511\n",
      "\tspeed: 0.1199s/iter; left time: 965.9837s\n",
      "\titers: 200, epoch: 12 | loss: 0.0615881\n",
      "\tspeed: 0.0495s/iter; left time: 393.6427s\n",
      "\titers: 300, epoch: 12 | loss: 0.0559201\n",
      "\tspeed: 0.0493s/iter; left time: 387.0165s\n",
      "\titers: 400, epoch: 12 | loss: 0.0519277\n",
      "\tspeed: 0.0491s/iter; left time: 380.5295s\n",
      "\titers: 500, epoch: 12 | loss: 0.0599991\n",
      "\tspeed: 0.0491s/iter; left time: 376.1459s\n",
      "\titers: 600, epoch: 12 | loss: 0.0630212\n",
      "\tspeed: 0.0493s/iter; left time: 372.6157s\n",
      "\titers: 700, epoch: 12 | loss: 0.0543649\n",
      "\tspeed: 0.0494s/iter; left time: 368.0015s\n",
      "\titers: 800, epoch: 12 | loss: 0.0606494\n",
      "\tspeed: 0.0496s/iter; left time: 365.0870s\n",
      "\titers: 900, epoch: 12 | loss: 0.0567524\n",
      "\tspeed: 0.0494s/iter; left time: 358.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:44.93s\n",
      "Steps: 906 | Train Loss: 0.0571922 Vali Loss: 0.0974627 Test Loss: 0.1070443\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0593928\n",
      "\tspeed: 0.1110s/iter; left time: 793.8699s\n",
      "\titers: 200, epoch: 13 | loss: 0.0506865\n",
      "\tspeed: 0.0464s/iter; left time: 327.0141s\n",
      "\titers: 300, epoch: 13 | loss: 0.0564607\n",
      "\tspeed: 0.0460s/iter; left time: 319.9796s\n",
      "\titers: 400, epoch: 13 | loss: 0.0527917\n",
      "\tspeed: 0.0460s/iter; left time: 315.0097s\n",
      "\titers: 500, epoch: 13 | loss: 0.0548141\n",
      "\tspeed: 0.0461s/iter; left time: 311.0719s\n",
      "\titers: 600, epoch: 13 | loss: 0.0536862\n",
      "\tspeed: 0.0460s/iter; left time: 306.0372s\n",
      "\titers: 700, epoch: 13 | loss: 0.0593105\n",
      "\tspeed: 0.0459s/iter; left time: 300.7700s\n",
      "\titers: 800, epoch: 13 | loss: 0.0583405\n",
      "\tspeed: 0.0458s/iter; left time: 295.2676s\n",
      "\titers: 900, epoch: 13 | loss: 0.0595543\n",
      "\tspeed: 0.0459s/iter; left time: 291.1370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.97s\n",
      "Steps: 906 | Train Loss: 0.0552700 Vali Loss: 0.0980769 Test Loss: 0.1070963\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0560386\n",
      "\tspeed: 0.1110s/iter; left time: 692.7280s\n",
      "\titers: 200, epoch: 14 | loss: 0.0519739\n",
      "\tspeed: 0.0462s/iter; left time: 284.0134s\n",
      "\titers: 300, epoch: 14 | loss: 0.0482483\n",
      "\tspeed: 0.0460s/iter; left time: 277.9236s\n",
      "\titers: 400, epoch: 14 | loss: 0.0503040\n",
      "\tspeed: 0.0460s/iter; left time: 273.6123s\n",
      "\titers: 500, epoch: 14 | loss: 0.0518296\n",
      "\tspeed: 0.0465s/iter; left time: 271.4904s\n",
      "\titers: 600, epoch: 14 | loss: 0.0475292\n",
      "\tspeed: 0.0462s/iter; left time: 265.4241s\n",
      "\titers: 700, epoch: 14 | loss: 0.0490515\n",
      "\tspeed: 0.0491s/iter; left time: 277.0168s\n",
      "\titers: 800, epoch: 14 | loss: 0.0554480\n",
      "\tspeed: 0.0491s/iter; left time: 272.3680s\n",
      "\titers: 900, epoch: 14 | loss: 0.0600134\n",
      "\tspeed: 0.0490s/iter; left time: 266.7623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 906 | Train Loss: 0.0535541 Vali Loss: 0.0998057 Test Loss: 0.1077985\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0498628\n",
      "\tspeed: 0.1101s/iter; left time: 587.8443s\n",
      "\titers: 200, epoch: 15 | loss: 0.0509019\n",
      "\tspeed: 0.0477s/iter; left time: 249.8120s\n",
      "\titers: 300, epoch: 15 | loss: 0.0491260\n",
      "\tspeed: 0.0466s/iter; left time: 239.4858s\n",
      "\titers: 400, epoch: 15 | loss: 0.0523825\n",
      "\tspeed: 0.0473s/iter; left time: 238.0138s\n",
      "\titers: 500, epoch: 15 | loss: 0.0568884\n",
      "\tspeed: 0.0487s/iter; left time: 240.1897s\n",
      "\titers: 600, epoch: 15 | loss: 0.0534033\n",
      "\tspeed: 0.0463s/iter; left time: 223.8177s\n",
      "\titers: 700, epoch: 15 | loss: 0.0473140\n",
      "\tspeed: 0.0463s/iter; left time: 219.5327s\n",
      "\titers: 800, epoch: 15 | loss: 0.0530336\n",
      "\tspeed: 0.0463s/iter; left time: 214.6599s\n",
      "\titers: 900, epoch: 15 | loss: 0.0458356\n",
      "\tspeed: 0.0463s/iter; left time: 210.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:42.75s\n",
      "Steps: 906 | Train Loss: 0.0519952 Vali Loss: 0.0975314 Test Loss: 0.1075522\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0488202\n",
      "\tspeed: 0.1111s/iter; left time: 492.0683s\n",
      "\titers: 200, epoch: 16 | loss: 0.0530199\n",
      "\tspeed: 0.0461s/iter; left time: 199.6484s\n",
      "\titers: 300, epoch: 16 | loss: 0.0499976\n",
      "\tspeed: 0.0460s/iter; left time: 194.8058s\n",
      "\titers: 400, epoch: 16 | loss: 0.0442361\n",
      "\tspeed: 0.0460s/iter; left time: 189.9467s\n",
      "\titers: 500, epoch: 16 | loss: 0.0529236\n",
      "\tspeed: 0.0459s/iter; left time: 184.9096s\n",
      "\titers: 600, epoch: 16 | loss: 0.0488371\n",
      "\tspeed: 0.0460s/iter; left time: 180.7651s\n",
      "\titers: 700, epoch: 16 | loss: 0.0491037\n",
      "\tspeed: 0.0460s/iter; left time: 176.3118s\n",
      "\titers: 800, epoch: 16 | loss: 0.0455605\n",
      "\tspeed: 0.0462s/iter; left time: 172.3571s\n",
      "\titers: 900, epoch: 16 | loss: 0.0486577\n",
      "\tspeed: 0.0459s/iter; left time: 166.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:41.95s\n",
      "Steps: 906 | Train Loss: 0.0508140 Vali Loss: 0.0993314 Test Loss: 0.1080995\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026359017938375473, rmse:0.16235460340976715, mae:0.10303153097629547, rse:0.5733596682548523\n",
      "Original data scale mse:22582330.0, rmse:4752.0869140625, mae:2871.896484375, rse:0.2362833321094513\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2211680\n",
      "\tspeed: 0.0822s/iter; left time: 1477.6231s\n",
      "\titers: 200, epoch: 1 | loss: 0.2124181\n",
      "\tspeed: 0.0510s/iter; left time: 911.1317s\n",
      "\titers: 300, epoch: 1 | loss: 0.2027560\n",
      "\tspeed: 0.0512s/iter; left time: 909.9215s\n",
      "\titers: 400, epoch: 1 | loss: 0.1934510\n",
      "\tspeed: 0.0510s/iter; left time: 902.2204s\n",
      "\titers: 500, epoch: 1 | loss: 0.1852765\n",
      "\tspeed: 0.0511s/iter; left time: 898.5665s\n",
      "\titers: 600, epoch: 1 | loss: 0.1785509\n",
      "\tspeed: 0.0510s/iter; left time: 892.1800s\n",
      "\titers: 700, epoch: 1 | loss: 0.1699531\n",
      "\tspeed: 0.0512s/iter; left time: 889.9507s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744952\n",
      "\tspeed: 0.0512s/iter; left time: 883.9661s\n",
      "\titers: 900, epoch: 1 | loss: 0.1717111\n",
      "\tspeed: 0.0512s/iter; left time: 879.1874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 904 | Train Loss: 0.1950607 Vali Loss: 0.1829108 Test Loss: 0.2037840\n",
      "Validation loss decreased (inf --> 0.182911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1621778\n",
      "\tspeed: 0.1425s/iter; left time: 2433.5943s\n",
      "\titers: 200, epoch: 2 | loss: 0.1427496\n",
      "\tspeed: 0.0505s/iter; left time: 857.3725s\n",
      "\titers: 300, epoch: 2 | loss: 0.1401429\n",
      "\tspeed: 0.0504s/iter; left time: 850.8825s\n",
      "\titers: 400, epoch: 2 | loss: 0.1463907\n",
      "\tspeed: 0.0506s/iter; left time: 848.2351s\n",
      "\titers: 500, epoch: 2 | loss: 0.1395933\n",
      "\tspeed: 0.0506s/iter; left time: 843.3102s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227748\n",
      "\tspeed: 0.0506s/iter; left time: 839.3711s\n",
      "\titers: 700, epoch: 2 | loss: 0.1235877\n",
      "\tspeed: 0.0507s/iter; left time: 835.0227s\n",
      "\titers: 800, epoch: 2 | loss: 0.1240215\n",
      "\tspeed: 0.0505s/iter; left time: 827.7827s\n",
      "\titers: 900, epoch: 2 | loss: 0.1336349\n",
      "\tspeed: 0.0505s/iter; left time: 821.1790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.00s\n",
      "Steps: 904 | Train Loss: 0.1377187 Vali Loss: 0.1409242 Test Loss: 0.1577245\n",
      "Validation loss decreased (0.182911 --> 0.140924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216025\n",
      "\tspeed: 0.1268s/iter; left time: 2050.1718s\n",
      "\titers: 200, epoch: 3 | loss: 0.1104100\n",
      "\tspeed: 0.0505s/iter; left time: 811.8079s\n",
      "\titers: 300, epoch: 3 | loss: 0.1143406\n",
      "\tspeed: 0.0506s/iter; left time: 807.4796s\n",
      "\titers: 400, epoch: 3 | loss: 0.1088113\n",
      "\tspeed: 0.0506s/iter; left time: 802.4153s\n",
      "\titers: 500, epoch: 3 | loss: 0.1070392\n",
      "\tspeed: 0.0506s/iter; left time: 797.9117s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047399\n",
      "\tspeed: 0.0506s/iter; left time: 792.7033s\n",
      "\titers: 700, epoch: 3 | loss: 0.1145064\n",
      "\tspeed: 0.0507s/iter; left time: 789.4888s\n",
      "\titers: 800, epoch: 3 | loss: 0.0987913\n",
      "\tspeed: 0.0505s/iter; left time: 782.0701s\n",
      "\titers: 900, epoch: 3 | loss: 0.1122302\n",
      "\tspeed: 0.0506s/iter; left time: 778.0744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 904 | Train Loss: 0.1095338 Vali Loss: 0.1256561 Test Loss: 0.1422735\n",
      "Validation loss decreased (0.140924 --> 0.125656).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1153372\n",
      "\tspeed: 0.1194s/iter; left time: 1823.3435s\n",
      "\titers: 200, epoch: 4 | loss: 0.1000890\n",
      "\tspeed: 0.0506s/iter; left time: 766.8588s\n",
      "\titers: 300, epoch: 4 | loss: 0.1141460\n",
      "\tspeed: 0.0505s/iter; left time: 761.3384s\n",
      "\titers: 400, epoch: 4 | loss: 0.0980017\n",
      "\tspeed: 0.0506s/iter; left time: 757.1586s\n",
      "\titers: 500, epoch: 4 | loss: 0.1069045\n",
      "\tspeed: 0.0504s/iter; left time: 750.1182s\n",
      "\titers: 600, epoch: 4 | loss: 0.1010115\n",
      "\tspeed: 0.0506s/iter; left time: 746.7332s\n",
      "\titers: 700, epoch: 4 | loss: 0.1052074\n",
      "\tspeed: 0.0504s/iter; left time: 738.9984s\n",
      "\titers: 800, epoch: 4 | loss: 0.0944677\n",
      "\tspeed: 0.0505s/iter; left time: 735.0395s\n",
      "\titers: 900, epoch: 4 | loss: 0.0917887\n",
      "\tspeed: 0.0497s/iter; left time: 718.7954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.08s\n",
      "Steps: 904 | Train Loss: 0.1004663 Vali Loss: 0.1298832 Test Loss: 0.1427613\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0909345\n",
      "\tspeed: 0.1218s/iter; left time: 1749.3672s\n",
      "\titers: 200, epoch: 5 | loss: 0.0933988\n",
      "\tspeed: 0.0505s/iter; left time: 720.5103s\n",
      "\titers: 300, epoch: 5 | loss: 0.0942662\n",
      "\tspeed: 0.0506s/iter; left time: 716.2072s\n",
      "\titers: 400, epoch: 5 | loss: 0.1026393\n",
      "\tspeed: 0.0505s/iter; left time: 709.9133s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877419\n",
      "\tspeed: 0.0506s/iter; left time: 706.0683s\n",
      "\titers: 600, epoch: 5 | loss: 0.0984881\n",
      "\tspeed: 0.0506s/iter; left time: 701.8541s\n",
      "\titers: 700, epoch: 5 | loss: 0.0965933\n",
      "\tspeed: 0.0507s/iter; left time: 698.1556s\n",
      "\titers: 800, epoch: 5 | loss: 0.0884743\n",
      "\tspeed: 0.0504s/iter; left time: 688.9634s\n",
      "\titers: 900, epoch: 5 | loss: 0.0875624\n",
      "\tspeed: 0.0506s/iter; left time: 686.4237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.0937394 Vali Loss: 0.1292347 Test Loss: 0.1464715\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0844789\n",
      "\tspeed: 0.1245s/iter; left time: 1676.0815s\n",
      "\titers: 200, epoch: 6 | loss: 0.0831305\n",
      "\tspeed: 0.0505s/iter; left time: 674.3833s\n",
      "\titers: 300, epoch: 6 | loss: 0.0890788\n",
      "\tspeed: 0.0506s/iter; left time: 670.7970s\n",
      "\titers: 400, epoch: 6 | loss: 0.0890178\n",
      "\tspeed: 0.0505s/iter; left time: 665.0820s\n",
      "\titers: 500, epoch: 6 | loss: 0.0872497\n",
      "\tspeed: 0.0505s/iter; left time: 659.7283s\n",
      "\titers: 600, epoch: 6 | loss: 0.0838243\n",
      "\tspeed: 0.0506s/iter; left time: 656.1752s\n",
      "\titers: 700, epoch: 6 | loss: 0.0790157\n",
      "\tspeed: 0.0505s/iter; left time: 649.5653s\n",
      "\titers: 800, epoch: 6 | loss: 0.0860724\n",
      "\tspeed: 0.0506s/iter; left time: 645.8485s\n",
      "\titers: 900, epoch: 6 | loss: 0.0885994\n",
      "\tspeed: 0.0504s/iter; left time: 638.6200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0874963 Vali Loss: 0.1259206 Test Loss: 0.1465154\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0867068\n",
      "\tspeed: 0.1232s/iter; left time: 1547.1689s\n",
      "\titers: 200, epoch: 7 | loss: 0.0808286\n",
      "\tspeed: 0.0506s/iter; left time: 629.8593s\n",
      "\titers: 300, epoch: 7 | loss: 0.0818731\n",
      "\tspeed: 0.0503s/iter; left time: 621.1816s\n",
      "\titers: 400, epoch: 7 | loss: 0.0807535\n",
      "\tspeed: 0.0506s/iter; left time: 620.6941s\n",
      "\titers: 500, epoch: 7 | loss: 0.0798821\n",
      "\tspeed: 0.0506s/iter; left time: 615.1736s\n",
      "\titers: 600, epoch: 7 | loss: 0.0856204\n",
      "\tspeed: 0.0505s/iter; left time: 609.0609s\n",
      "\titers: 700, epoch: 7 | loss: 0.0826759\n",
      "\tspeed: 0.0506s/iter; left time: 605.2785s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764204\n",
      "\tspeed: 0.0505s/iter; left time: 598.6946s\n",
      "\titers: 900, epoch: 7 | loss: 0.0779424\n",
      "\tspeed: 0.0505s/iter; left time: 594.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0820894 Vali Loss: 0.1282384 Test Loss: 0.1467834\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0753770\n",
      "\tspeed: 0.1229s/iter; left time: 1432.1647s\n",
      "\titers: 200, epoch: 8 | loss: 0.0761234\n",
      "\tspeed: 0.0505s/iter; left time: 583.1241s\n",
      "\titers: 300, epoch: 8 | loss: 0.0806233\n",
      "\tspeed: 0.0506s/iter; left time: 579.1524s\n",
      "\titers: 400, epoch: 8 | loss: 0.0802709\n",
      "\tspeed: 0.0505s/iter; left time: 573.3936s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798946\n",
      "\tspeed: 0.0505s/iter; left time: 568.3120s\n",
      "\titers: 600, epoch: 8 | loss: 0.0823787\n",
      "\tspeed: 0.0502s/iter; left time: 559.9369s\n",
      "\titers: 700, epoch: 8 | loss: 0.0790553\n",
      "\tspeed: 0.0505s/iter; left time: 558.1396s\n",
      "\titers: 800, epoch: 8 | loss: 0.0728498\n",
      "\tspeed: 0.0505s/iter; left time: 553.3954s\n",
      "\titers: 900, epoch: 8 | loss: 0.0717074\n",
      "\tspeed: 0.0506s/iter; left time: 549.6744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.90s\n",
      "Steps: 904 | Train Loss: 0.0772998 Vali Loss: 0.1293028 Test Loss: 0.1479542\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04122032970190048, rmse:0.2030279040336609, mae:0.14230172336101532, rse:0.7189628481864929\n",
      "Original data scale mse:38691036.0, rmse:6220.2119140625, mae:4066.916259765625, rse:0.30976876616477966\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2228246\n",
      "\tspeed: 0.0525s/iter; left time: 944.8383s\n",
      "\titers: 200, epoch: 1 | loss: 0.1975601\n",
      "\tspeed: 0.0505s/iter; left time: 903.7009s\n",
      "\titers: 300, epoch: 1 | loss: 0.1984413\n",
      "\tspeed: 0.0505s/iter; left time: 898.6466s\n",
      "\titers: 400, epoch: 1 | loss: 0.1955372\n",
      "\tspeed: 0.0506s/iter; left time: 893.7754s\n",
      "\titers: 500, epoch: 1 | loss: 0.2015178\n",
      "\tspeed: 0.0505s/iter; left time: 888.5240s\n",
      "\titers: 600, epoch: 1 | loss: 0.1833165\n",
      "\tspeed: 0.0507s/iter; left time: 885.4225s\n",
      "\titers: 700, epoch: 1 | loss: 0.1784639\n",
      "\tspeed: 0.0506s/iter; left time: 879.8312s\n",
      "\titers: 800, epoch: 1 | loss: 0.1788543\n",
      "\tspeed: 0.0505s/iter; left time: 873.2941s\n",
      "\titers: 900, epoch: 1 | loss: 0.1769701\n",
      "\tspeed: 0.0505s/iter; left time: 867.9327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.1982861 Vali Loss: 0.1791447 Test Loss: 0.1982348\n",
      "Validation loss decreased (inf --> 0.179145).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1626676\n",
      "\tspeed: 0.1297s/iter; left time: 2214.2022s\n",
      "\titers: 200, epoch: 2 | loss: 0.1418535\n",
      "\tspeed: 0.0507s/iter; left time: 860.4838s\n",
      "\titers: 300, epoch: 2 | loss: 0.1512545\n",
      "\tspeed: 0.0506s/iter; left time: 853.5583s\n",
      "\titers: 400, epoch: 2 | loss: 0.1388979\n",
      "\tspeed: 0.0506s/iter; left time: 849.5570s\n",
      "\titers: 500, epoch: 2 | loss: 0.1387800\n",
      "\tspeed: 0.0507s/iter; left time: 845.8986s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259172\n",
      "\tspeed: 0.0505s/iter; left time: 836.4830s\n",
      "\titers: 700, epoch: 2 | loss: 0.1274560\n",
      "\tspeed: 0.0505s/iter; left time: 832.2923s\n",
      "\titers: 800, epoch: 2 | loss: 0.1289226\n",
      "\tspeed: 0.0504s/iter; left time: 825.9393s\n",
      "\titers: 900, epoch: 2 | loss: 0.1202111\n",
      "\tspeed: 0.0506s/iter; left time: 824.1881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.05s\n",
      "Steps: 904 | Train Loss: 0.1396447 Vali Loss: 0.1410816 Test Loss: 0.1541430\n",
      "Validation loss decreased (0.179145 --> 0.141082).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1146321\n",
      "\tspeed: 0.1288s/iter; left time: 2082.3880s\n",
      "\titers: 200, epoch: 3 | loss: 0.1086231\n",
      "\tspeed: 0.0508s/iter; left time: 816.9966s\n",
      "\titers: 300, epoch: 3 | loss: 0.1190881\n",
      "\tspeed: 0.0506s/iter; left time: 808.0596s\n",
      "\titers: 400, epoch: 3 | loss: 0.1126139\n",
      "\tspeed: 0.0504s/iter; left time: 800.4354s\n",
      "\titers: 500, epoch: 3 | loss: 0.1115104\n",
      "\tspeed: 0.0505s/iter; left time: 797.1156s\n",
      "\titers: 600, epoch: 3 | loss: 0.1236731\n",
      "\tspeed: 0.0505s/iter; left time: 791.2384s\n",
      "\titers: 700, epoch: 3 | loss: 0.1179141\n",
      "\tspeed: 0.0505s/iter; left time: 786.2671s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989130\n",
      "\tspeed: 0.0505s/iter; left time: 780.9991s\n",
      "\titers: 900, epoch: 3 | loss: 0.1097365\n",
      "\tspeed: 0.0507s/iter; left time: 779.1547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 904 | Train Loss: 0.1114375 Vali Loss: 0.1281263 Test Loss: 0.1431220\n",
      "Validation loss decreased (0.141082 --> 0.128126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1071102\n",
      "\tspeed: 0.1287s/iter; left time: 1964.3804s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969764\n",
      "\tspeed: 0.0511s/iter; left time: 774.4328s\n",
      "\titers: 300, epoch: 4 | loss: 0.1046718\n",
      "\tspeed: 0.0508s/iter; left time: 764.8367s\n",
      "\titers: 400, epoch: 4 | loss: 0.0977541\n",
      "\tspeed: 0.0507s/iter; left time: 759.3087s\n",
      "\titers: 500, epoch: 4 | loss: 0.0945625\n",
      "\tspeed: 0.0508s/iter; left time: 755.6627s\n",
      "\titers: 600, epoch: 4 | loss: 0.0986999\n",
      "\tspeed: 0.0506s/iter; left time: 747.9217s\n",
      "\titers: 700, epoch: 4 | loss: 0.1048499\n",
      "\tspeed: 0.0507s/iter; left time: 744.2550s\n",
      "\titers: 800, epoch: 4 | loss: 0.0994669\n",
      "\tspeed: 0.0505s/iter; left time: 736.1719s\n",
      "\titers: 900, epoch: 4 | loss: 0.0925757\n",
      "\tspeed: 0.0506s/iter; left time: 731.7885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.16s\n",
      "Steps: 904 | Train Loss: 0.1004518 Vali Loss: 0.1291285 Test Loss: 0.1425716\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0874742\n",
      "\tspeed: 0.1234s/iter; left time: 1772.5239s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963328\n",
      "\tspeed: 0.0507s/iter; left time: 723.4081s\n",
      "\titers: 300, epoch: 5 | loss: 0.1027813\n",
      "\tspeed: 0.0505s/iter; left time: 715.8079s\n",
      "\titers: 400, epoch: 5 | loss: 0.0895675\n",
      "\tspeed: 0.0505s/iter; left time: 710.9232s\n",
      "\titers: 500, epoch: 5 | loss: 0.0993130\n",
      "\tspeed: 0.0505s/iter; left time: 704.8449s\n",
      "\titers: 600, epoch: 5 | loss: 0.0953645\n",
      "\tspeed: 0.0506s/iter; left time: 701.7957s\n",
      "\titers: 700, epoch: 5 | loss: 0.0892349\n",
      "\tspeed: 0.0506s/iter; left time: 695.8353s\n",
      "\titers: 800, epoch: 5 | loss: 0.0873532\n",
      "\tspeed: 0.0505s/iter; left time: 690.4886s\n",
      "\titers: 900, epoch: 5 | loss: 0.0934440\n",
      "\tspeed: 0.0507s/iter; left time: 688.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 904 | Train Loss: 0.0931581 Vali Loss: 0.1246601 Test Loss: 0.1443280\n",
      "Validation loss decreased (0.128126 --> 0.124660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0961268\n",
      "\tspeed: 0.1279s/iter; left time: 1721.1083s\n",
      "\titers: 200, epoch: 6 | loss: 0.0822272\n",
      "\tspeed: 0.0504s/iter; left time: 673.6375s\n",
      "\titers: 300, epoch: 6 | loss: 0.0832755\n",
      "\tspeed: 0.0505s/iter; left time: 669.5990s\n",
      "\titers: 400, epoch: 6 | loss: 0.0851639\n",
      "\tspeed: 0.0506s/iter; left time: 666.0395s\n",
      "\titers: 500, epoch: 6 | loss: 0.0906663\n",
      "\tspeed: 0.0505s/iter; left time: 659.8162s\n",
      "\titers: 600, epoch: 6 | loss: 0.0864622\n",
      "\tspeed: 0.0508s/iter; left time: 658.0406s\n",
      "\titers: 700, epoch: 6 | loss: 0.0848670\n",
      "\tspeed: 0.0505s/iter; left time: 650.0453s\n",
      "\titers: 800, epoch: 6 | loss: 0.0853517\n",
      "\tspeed: 0.0506s/iter; left time: 645.1022s\n",
      "\titers: 900, epoch: 6 | loss: 0.0898180\n",
      "\tspeed: 0.0507s/iter; left time: 641.3651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.01s\n",
      "Steps: 904 | Train Loss: 0.0864279 Vali Loss: 0.1263104 Test Loss: 0.1436411\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0830620\n",
      "\tspeed: 0.1243s/iter; left time: 1561.4054s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811775\n",
      "\tspeed: 0.0506s/iter; left time: 629.8137s\n",
      "\titers: 300, epoch: 7 | loss: 0.0790765\n",
      "\tspeed: 0.0505s/iter; left time: 624.0118s\n",
      "\titers: 400, epoch: 7 | loss: 0.0794355\n",
      "\tspeed: 0.0505s/iter; left time: 619.5751s\n",
      "\titers: 500, epoch: 7 | loss: 0.0733461\n",
      "\tspeed: 0.0505s/iter; left time: 614.0822s\n",
      "\titers: 600, epoch: 7 | loss: 0.0799207\n",
      "\tspeed: 0.0506s/iter; left time: 609.6798s\n",
      "\titers: 700, epoch: 7 | loss: 0.0805053\n",
      "\tspeed: 0.0505s/iter; left time: 603.8798s\n",
      "\titers: 800, epoch: 7 | loss: 0.0797424\n",
      "\tspeed: 0.0505s/iter; left time: 598.8269s\n",
      "\titers: 900, epoch: 7 | loss: 0.0868520\n",
      "\tspeed: 0.0505s/iter; left time: 593.9478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0807042 Vali Loss: 0.1286382 Test Loss: 0.1478058\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0758880\n",
      "\tspeed: 0.1232s/iter; left time: 1435.6303s\n",
      "\titers: 200, epoch: 8 | loss: 0.0756853\n",
      "\tspeed: 0.0505s/iter; left time: 583.9250s\n",
      "\titers: 300, epoch: 8 | loss: 0.0763412\n",
      "\tspeed: 0.0504s/iter; left time: 577.6541s\n",
      "\titers: 400, epoch: 8 | loss: 0.0878913\n",
      "\tspeed: 0.0506s/iter; left time: 574.0437s\n",
      "\titers: 500, epoch: 8 | loss: 0.0778655\n",
      "\tspeed: 0.0505s/iter; left time: 568.3264s\n",
      "\titers: 600, epoch: 8 | loss: 0.0781955\n",
      "\tspeed: 0.0505s/iter; left time: 563.3367s\n",
      "\titers: 700, epoch: 8 | loss: 0.0686648\n",
      "\tspeed: 0.0504s/iter; left time: 556.5568s\n",
      "\titers: 800, epoch: 8 | loss: 0.0766425\n",
      "\tspeed: 0.0506s/iter; left time: 553.8396s\n",
      "\titers: 900, epoch: 8 | loss: 0.0713768\n",
      "\tspeed: 0.0505s/iter; left time: 548.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.95s\n",
      "Steps: 904 | Train Loss: 0.0758714 Vali Loss: 0.1294556 Test Loss: 0.1475389\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0722367\n",
      "\tspeed: 0.1237s/iter; left time: 1330.1463s\n",
      "\titers: 200, epoch: 9 | loss: 0.0719918\n",
      "\tspeed: 0.0506s/iter; left time: 538.5504s\n",
      "\titers: 300, epoch: 9 | loss: 0.0682079\n",
      "\tspeed: 0.0505s/iter; left time: 532.7542s\n",
      "\titers: 400, epoch: 9 | loss: 0.0657540\n",
      "\tspeed: 0.0506s/iter; left time: 528.2565s\n",
      "\titers: 500, epoch: 9 | loss: 0.0733435\n",
      "\tspeed: 0.0506s/iter; left time: 523.1868s\n",
      "\titers: 600, epoch: 9 | loss: 0.0733633\n",
      "\tspeed: 0.0505s/iter; left time: 517.5701s\n",
      "\titers: 700, epoch: 9 | loss: 0.0705372\n",
      "\tspeed: 0.0506s/iter; left time: 513.1743s\n",
      "\titers: 800, epoch: 9 | loss: 0.0677424\n",
      "\tspeed: 0.0505s/iter; left time: 507.8987s\n",
      "\titers: 900, epoch: 9 | loss: 0.0660145\n",
      "\tspeed: 0.0505s/iter; left time: 502.6783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.94s\n",
      "Steps: 904 | Train Loss: 0.0715858 Vali Loss: 0.1315246 Test Loss: 0.1502602\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0692005\n",
      "\tspeed: 0.1235s/iter; left time: 1215.4430s\n",
      "\titers: 200, epoch: 10 | loss: 0.0691886\n",
      "\tspeed: 0.0504s/iter; left time: 491.1772s\n",
      "\titers: 300, epoch: 10 | loss: 0.0687930\n",
      "\tspeed: 0.0505s/iter; left time: 487.4926s\n",
      "\titers: 400, epoch: 10 | loss: 0.0692857\n",
      "\tspeed: 0.0506s/iter; left time: 483.1829s\n",
      "\titers: 500, epoch: 10 | loss: 0.0661787\n",
      "\tspeed: 0.0505s/iter; left time: 477.0429s\n",
      "\titers: 600, epoch: 10 | loss: 0.0713165\n",
      "\tspeed: 0.0505s/iter; left time: 471.8417s\n",
      "\titers: 700, epoch: 10 | loss: 0.0668727\n",
      "\tspeed: 0.0506s/iter; left time: 467.3897s\n",
      "\titers: 800, epoch: 10 | loss: 0.0665657\n",
      "\tspeed: 0.0506s/iter; left time: 462.3819s\n",
      "\titers: 900, epoch: 10 | loss: 0.0688492\n",
      "\tspeed: 0.0507s/iter; left time: 458.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:45.97s\n",
      "Steps: 904 | Train Loss: 0.0680333 Vali Loss: 0.1297180 Test Loss: 0.1483256\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04413595050573349, rmse:0.21008558571338654, mae:0.14426378905773163, rse:0.7439554929733276\n",
      "Original data scale mse:41274512.0, rmse:6424.5244140625, mae:4134.96875, rse:0.3199436068534851\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=96, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2143676\n",
      "\tspeed: 0.0835s/iter; left time: 1498.4609s\n",
      "\titers: 200, epoch: 1 | loss: 0.2117515\n",
      "\tspeed: 0.0540s/iter; left time: 963.9553s\n",
      "\titers: 300, epoch: 1 | loss: 0.1927727\n",
      "\tspeed: 0.0543s/iter; left time: 963.8398s\n",
      "\titers: 400, epoch: 1 | loss: 0.1908412\n",
      "\tspeed: 0.0549s/iter; left time: 968.0605s\n",
      "\titers: 500, epoch: 1 | loss: 0.1840956\n",
      "\tspeed: 0.0535s/iter; left time: 939.0784s\n",
      "\titers: 600, epoch: 1 | loss: 0.1887111\n",
      "\tspeed: 0.0540s/iter; left time: 941.2601s\n",
      "\titers: 700, epoch: 1 | loss: 0.1783495\n",
      "\tspeed: 0.0542s/iter; left time: 940.7196s\n",
      "\titers: 800, epoch: 1 | loss: 0.1741387\n",
      "\tspeed: 0.0541s/iter; left time: 933.5395s\n",
      "\titers: 900, epoch: 1 | loss: 0.1796458\n",
      "\tspeed: 0.0539s/iter; left time: 924.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.57s\n",
      "Steps: 902 | Train Loss: 0.1965990 Vali Loss: 0.1828116 Test Loss: 0.2071697\n",
      "Validation loss decreased (inf --> 0.182812).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1720107\n",
      "\tspeed: 0.1457s/iter; left time: 2483.1914s\n",
      "\titers: 200, epoch: 2 | loss: 0.1494585\n",
      "\tspeed: 0.0534s/iter; left time: 903.7907s\n",
      "\titers: 300, epoch: 2 | loss: 0.1520132\n",
      "\tspeed: 0.0542s/iter; left time: 912.2201s\n",
      "\titers: 400, epoch: 2 | loss: 0.1517190\n",
      "\tspeed: 0.0551s/iter; left time: 923.1156s\n",
      "\titers: 500, epoch: 2 | loss: 0.1381914\n",
      "\tspeed: 0.0533s/iter; left time: 886.8111s\n",
      "\titers: 600, epoch: 2 | loss: 0.1325774\n",
      "\tspeed: 0.0536s/iter; left time: 885.9514s\n",
      "\titers: 700, epoch: 2 | loss: 0.1320532\n",
      "\tspeed: 0.0549s/iter; left time: 903.1931s\n",
      "\titers: 800, epoch: 2 | loss: 0.1355543\n",
      "\tspeed: 0.0531s/iter; left time: 868.3174s\n",
      "\titers: 900, epoch: 2 | loss: 0.1268250\n",
      "\tspeed: 0.0532s/iter; left time: 863.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.1479768 Vali Loss: 0.1571483 Test Loss: 0.1725036\n",
      "Validation loss decreased (0.182812 --> 0.157148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1298213\n",
      "\tspeed: 0.1448s/iter; left time: 2336.1010s\n",
      "\titers: 200, epoch: 3 | loss: 0.1270678\n",
      "\tspeed: 0.0531s/iter; left time: 851.7187s\n",
      "\titers: 300, epoch: 3 | loss: 0.1299838\n",
      "\tspeed: 0.0529s/iter; left time: 842.9641s\n",
      "\titers: 400, epoch: 3 | loss: 0.1339503\n",
      "\tspeed: 0.0530s/iter; left time: 839.2175s\n",
      "\titers: 500, epoch: 3 | loss: 0.1283429\n",
      "\tspeed: 0.0549s/iter; left time: 863.3064s\n",
      "\titers: 600, epoch: 3 | loss: 0.1257501\n",
      "\tspeed: 0.0545s/iter; left time: 851.4904s\n",
      "\titers: 700, epoch: 3 | loss: 0.1190765\n",
      "\tspeed: 0.0539s/iter; left time: 837.4507s\n",
      "\titers: 800, epoch: 3 | loss: 0.1205630\n",
      "\tspeed: 0.0486s/iter; left time: 749.7877s\n",
      "\titers: 900, epoch: 3 | loss: 0.1183924\n",
      "\tspeed: 0.0568s/iter; left time: 870.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.47s\n",
      "Steps: 902 | Train Loss: 0.1263652 Vali Loss: 0.1494838 Test Loss: 0.1698276\n",
      "Validation loss decreased (0.157148 --> 0.149484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1155508\n",
      "\tspeed: 0.1406s/iter; left time: 2141.3145s\n",
      "\titers: 200, epoch: 4 | loss: 0.1041115\n",
      "\tspeed: 0.0471s/iter; left time: 712.8244s\n",
      "\titers: 300, epoch: 4 | loss: 0.1034060\n",
      "\tspeed: 0.0470s/iter; left time: 705.9693s\n",
      "\titers: 400, epoch: 4 | loss: 0.1053993\n",
      "\tspeed: 0.0476s/iter; left time: 710.7085s\n",
      "\titers: 500, epoch: 4 | loss: 0.1018088\n",
      "\tspeed: 0.0542s/iter; left time: 803.6553s\n",
      "\titers: 600, epoch: 4 | loss: 0.1077380\n",
      "\tspeed: 0.0546s/iter; left time: 803.8817s\n",
      "\titers: 700, epoch: 4 | loss: 0.1009760\n",
      "\tspeed: 0.0546s/iter; left time: 798.8853s\n",
      "\titers: 800, epoch: 4 | loss: 0.1029728\n",
      "\tspeed: 0.0529s/iter; left time: 768.3360s\n",
      "\titers: 900, epoch: 4 | loss: 0.0969269\n",
      "\tspeed: 0.0530s/iter; left time: 765.6199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.66s\n",
      "Steps: 902 | Train Loss: 0.1071249 Vali Loss: 0.1498666 Test Loss: 0.1581961\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0921835\n",
      "\tspeed: 0.1319s/iter; left time: 1889.9498s\n",
      "\titers: 200, epoch: 5 | loss: 0.0946247\n",
      "\tspeed: 0.0473s/iter; left time: 673.7834s\n",
      "\titers: 300, epoch: 5 | loss: 0.0958237\n",
      "\tspeed: 0.0487s/iter; left time: 688.4046s\n",
      "\titers: 400, epoch: 5 | loss: 0.1009195\n",
      "\tspeed: 0.0529s/iter; left time: 742.2102s\n",
      "\titers: 500, epoch: 5 | loss: 0.0915284\n",
      "\tspeed: 0.0526s/iter; left time: 732.3738s\n",
      "\titers: 600, epoch: 5 | loss: 0.0905648\n",
      "\tspeed: 0.0548s/iter; left time: 757.7377s\n",
      "\titers: 700, epoch: 5 | loss: 0.0927724\n",
      "\tspeed: 0.0530s/iter; left time: 728.0918s\n",
      "\titers: 800, epoch: 5 | loss: 0.1016190\n",
      "\tspeed: 0.0530s/iter; left time: 721.9376s\n",
      "\titers: 900, epoch: 5 | loss: 0.0944772\n",
      "\tspeed: 0.0535s/iter; left time: 723.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.65s\n",
      "Steps: 902 | Train Loss: 0.0974058 Vali Loss: 0.1408406 Test Loss: 0.1551649\n",
      "Validation loss decreased (0.149484 --> 0.140841).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932021\n",
      "\tspeed: 0.1440s/iter; left time: 1933.8637s\n",
      "\titers: 200, epoch: 6 | loss: 0.0926236\n",
      "\tspeed: 0.0542s/iter; left time: 722.9813s\n",
      "\titers: 300, epoch: 6 | loss: 0.0907288\n",
      "\tspeed: 0.0527s/iter; left time: 696.8059s\n",
      "\titers: 400, epoch: 6 | loss: 0.0978973\n",
      "\tspeed: 0.0540s/iter; left time: 708.8305s\n",
      "\titers: 500, epoch: 6 | loss: 0.0956134\n",
      "\tspeed: 0.0524s/iter; left time: 682.8031s\n",
      "\titers: 600, epoch: 6 | loss: 0.0908729\n",
      "\tspeed: 0.0525s/iter; left time: 679.3839s\n",
      "\titers: 700, epoch: 6 | loss: 0.0814253\n",
      "\tspeed: 0.0526s/iter; left time: 674.8453s\n",
      "\titers: 800, epoch: 6 | loss: 0.0882680\n",
      "\tspeed: 0.0525s/iter; left time: 668.2728s\n",
      "\titers: 900, epoch: 6 | loss: 0.0903395\n",
      "\tspeed: 0.0532s/iter; left time: 671.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.0906075 Vali Loss: 0.1435234 Test Loss: 0.1569311\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0823340\n",
      "\tspeed: 0.1395s/iter; left time: 1747.3352s\n",
      "\titers: 200, epoch: 7 | loss: 0.0836407\n",
      "\tspeed: 0.0547s/iter; left time: 679.2460s\n",
      "\titers: 300, epoch: 7 | loss: 0.0852123\n",
      "\tspeed: 0.0552s/iter; left time: 680.2182s\n",
      "\titers: 400, epoch: 7 | loss: 0.0818945\n",
      "\tspeed: 0.0548s/iter; left time: 669.8543s\n",
      "\titers: 500, epoch: 7 | loss: 0.0864603\n",
      "\tspeed: 0.0547s/iter; left time: 663.2574s\n",
      "\titers: 600, epoch: 7 | loss: 0.0815249\n",
      "\tspeed: 0.0548s/iter; left time: 659.2493s\n",
      "\titers: 700, epoch: 7 | loss: 0.0842814\n",
      "\tspeed: 0.0543s/iter; left time: 647.4016s\n",
      "\titers: 800, epoch: 7 | loss: 0.0859686\n",
      "\tspeed: 0.0548s/iter; left time: 648.1783s\n",
      "\titers: 900, epoch: 7 | loss: 0.0876295\n",
      "\tspeed: 0.0547s/iter; left time: 641.6488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.59s\n",
      "Steps: 902 | Train Loss: 0.0842573 Vali Loss: 0.1383368 Test Loss: 0.1558025\n",
      "Validation loss decreased (0.140841 --> 0.138337).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0780885\n",
      "\tspeed: 0.1430s/iter; left time: 1663.2404s\n",
      "\titers: 200, epoch: 8 | loss: 0.0838111\n",
      "\tspeed: 0.0542s/iter; left time: 624.5835s\n",
      "\titers: 300, epoch: 8 | loss: 0.0805265\n",
      "\tspeed: 0.0527s/iter; left time: 602.6738s\n",
      "\titers: 400, epoch: 8 | loss: 0.0790132\n",
      "\tspeed: 0.0529s/iter; left time: 599.3116s\n",
      "\titers: 500, epoch: 8 | loss: 0.0785694\n",
      "\tspeed: 0.0549s/iter; left time: 616.6074s\n",
      "\titers: 600, epoch: 8 | loss: 0.0750216\n",
      "\tspeed: 0.0538s/iter; left time: 598.1154s\n",
      "\titers: 700, epoch: 8 | loss: 0.0776697\n",
      "\tspeed: 0.0520s/iter; left time: 573.4838s\n",
      "\titers: 800, epoch: 8 | loss: 0.0769325\n",
      "\tspeed: 0.0546s/iter; left time: 596.4638s\n",
      "\titers: 900, epoch: 8 | loss: 0.0747403\n",
      "\tspeed: 0.0568s/iter; left time: 615.1256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.07s\n",
      "Steps: 902 | Train Loss: 0.0794519 Vali Loss: 0.1417993 Test Loss: 0.1582901\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0711918\n",
      "\tspeed: 0.1387s/iter; left time: 1487.6319s\n",
      "\titers: 200, epoch: 9 | loss: 0.0793033\n",
      "\tspeed: 0.0531s/iter; left time: 564.0481s\n",
      "\titers: 300, epoch: 9 | loss: 0.0817263\n",
      "\tspeed: 0.0524s/iter; left time: 551.3093s\n",
      "\titers: 400, epoch: 9 | loss: 0.0761158\n",
      "\tspeed: 0.0528s/iter; left time: 549.9390s\n",
      "\titers: 500, epoch: 9 | loss: 0.0807231\n",
      "\tspeed: 0.0531s/iter; left time: 548.4880s\n",
      "\titers: 600, epoch: 9 | loss: 0.0731832\n",
      "\tspeed: 0.0530s/iter; left time: 542.0448s\n",
      "\titers: 700, epoch: 9 | loss: 0.0774617\n",
      "\tspeed: 0.0550s/iter; left time: 556.6073s\n",
      "\titers: 800, epoch: 9 | loss: 0.0772811\n",
      "\tspeed: 0.0548s/iter; left time: 549.0747s\n",
      "\titers: 900, epoch: 9 | loss: 0.0736872\n",
      "\tspeed: 0.0544s/iter; left time: 539.8436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0751518 Vali Loss: 0.1422561 Test Loss: 0.1584524\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0668368\n",
      "\tspeed: 0.1362s/iter; left time: 1338.2166s\n",
      "\titers: 200, epoch: 10 | loss: 0.0728021\n",
      "\tspeed: 0.0542s/iter; left time: 527.4205s\n",
      "\titers: 300, epoch: 10 | loss: 0.0750305\n",
      "\tspeed: 0.0546s/iter; left time: 525.6635s\n",
      "\titers: 400, epoch: 10 | loss: 0.0713177\n",
      "\tspeed: 0.0542s/iter; left time: 516.5369s\n",
      "\titers: 500, epoch: 10 | loss: 0.0725282\n",
      "\tspeed: 0.0511s/iter; left time: 481.6772s\n",
      "\titers: 600, epoch: 10 | loss: 0.0728812\n",
      "\tspeed: 0.0523s/iter; left time: 487.7846s\n",
      "\titers: 700, epoch: 10 | loss: 0.0732005\n",
      "\tspeed: 0.0546s/iter; left time: 503.5526s\n",
      "\titers: 800, epoch: 10 | loss: 0.0709999\n",
      "\tspeed: 0.0548s/iter; left time: 499.8310s\n",
      "\titers: 900, epoch: 10 | loss: 0.0734219\n",
      "\tspeed: 0.0545s/iter; left time: 491.5159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0715689 Vali Loss: 0.1426778 Test Loss: 0.1605491\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0681446\n",
      "\tspeed: 0.1376s/iter; left time: 1227.6264s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697667\n",
      "\tspeed: 0.0545s/iter; left time: 481.1513s\n",
      "\titers: 300, epoch: 11 | loss: 0.0655064\n",
      "\tspeed: 0.0545s/iter; left time: 475.0273s\n",
      "\titers: 400, epoch: 11 | loss: 0.0666977\n",
      "\tspeed: 0.0514s/iter; left time: 443.1507s\n",
      "\titers: 500, epoch: 11 | loss: 0.0786548\n",
      "\tspeed: 0.0506s/iter; left time: 430.9571s\n",
      "\titers: 600, epoch: 11 | loss: 0.0678788\n",
      "\tspeed: 0.0534s/iter; left time: 449.9691s\n",
      "\titers: 700, epoch: 11 | loss: 0.0705262\n",
      "\tspeed: 0.0522s/iter; left time: 434.5606s\n",
      "\titers: 800, epoch: 11 | loss: 0.0674626\n",
      "\tspeed: 0.0518s/iter; left time: 426.1227s\n",
      "\titers: 900, epoch: 11 | loss: 0.0651507\n",
      "\tspeed: 0.0527s/iter; left time: 427.9407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.83s\n",
      "Steps: 902 | Train Loss: 0.0687391 Vali Loss: 0.1402910 Test Loss: 0.1587802\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0653112\n",
      "\tspeed: 0.1382s/iter; left time: 1108.0502s\n",
      "\titers: 200, epoch: 12 | loss: 0.0699357\n",
      "\tspeed: 0.0547s/iter; left time: 433.4006s\n",
      "\titers: 300, epoch: 12 | loss: 0.0649073\n",
      "\tspeed: 0.0545s/iter; left time: 425.8914s\n",
      "\titers: 400, epoch: 12 | loss: 0.0659068\n",
      "\tspeed: 0.0538s/iter; left time: 415.5479s\n",
      "\titers: 500, epoch: 12 | loss: 0.0660025\n",
      "\tspeed: 0.0546s/iter; left time: 416.2270s\n",
      "\titers: 600, epoch: 12 | loss: 0.0685619\n",
      "\tspeed: 0.0548s/iter; left time: 411.9983s\n",
      "\titers: 700, epoch: 12 | loss: 0.0702067\n",
      "\tspeed: 0.0547s/iter; left time: 405.8893s\n",
      "\titers: 800, epoch: 12 | loss: 0.0664895\n",
      "\tspeed: 0.0539s/iter; left time: 394.2282s\n",
      "\titers: 900, epoch: 12 | loss: 0.0690533\n",
      "\tspeed: 0.0545s/iter; left time: 393.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:49.35s\n",
      "Steps: 902 | Train Loss: 0.0663095 Vali Loss: 0.1424346 Test Loss: 0.1606143\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.053022854030132294, rmse:0.23026691377162933, mae:0.15602098405361176, rse:0.8157663345336914\n",
      "Original data scale mse:50191892.0, rmse:7084.62353515625, mae:4464.84228515625, rse:0.35298997163772583\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2201324\n",
      "\tspeed: 0.0617s/iter; left time: 1106.0656s\n",
      "\titers: 200, epoch: 1 | loss: 0.2001715\n",
      "\tspeed: 0.0604s/iter; left time: 1077.3772s\n",
      "\titers: 300, epoch: 1 | loss: 0.1991532\n",
      "\tspeed: 0.0585s/iter; left time: 1038.2783s\n",
      "\titers: 400, epoch: 1 | loss: 0.1883941\n",
      "\tspeed: 0.0540s/iter; left time: 952.1109s\n",
      "\titers: 500, epoch: 1 | loss: 0.1873800\n",
      "\tspeed: 0.0520s/iter; left time: 911.4615s\n",
      "\titers: 600, epoch: 1 | loss: 0.1834275\n",
      "\tspeed: 0.0529s/iter; left time: 923.1811s\n",
      "\titers: 700, epoch: 1 | loss: 0.1915931\n",
      "\tspeed: 0.0523s/iter; left time: 906.5056s\n",
      "\titers: 800, epoch: 1 | loss: 0.1855758\n",
      "\tspeed: 0.0519s/iter; left time: 894.8432s\n",
      "\titers: 900, epoch: 1 | loss: 0.1799206\n",
      "\tspeed: 0.0524s/iter; left time: 897.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.78s\n",
      "Steps: 902 | Train Loss: 0.1969401 Vali Loss: 0.1832115 Test Loss: 0.2068883\n",
      "Validation loss decreased (inf --> 0.183212).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1596465\n",
      "\tspeed: 0.1392s/iter; left time: 2372.5383s\n",
      "\titers: 200, epoch: 2 | loss: 0.1578218\n",
      "\tspeed: 0.0526s/iter; left time: 891.3177s\n",
      "\titers: 300, epoch: 2 | loss: 0.1497701\n",
      "\tspeed: 0.0515s/iter; left time: 867.5384s\n",
      "\titers: 400, epoch: 2 | loss: 0.1531094\n",
      "\tspeed: 0.0525s/iter; left time: 879.6232s\n",
      "\titers: 500, epoch: 2 | loss: 0.1408316\n",
      "\tspeed: 0.0534s/iter; left time: 888.8657s\n",
      "\titers: 600, epoch: 2 | loss: 0.1419959\n",
      "\tspeed: 0.0550s/iter; left time: 908.9571s\n",
      "\titers: 700, epoch: 2 | loss: 0.1315546\n",
      "\tspeed: 0.0547s/iter; left time: 899.2121s\n",
      "\titers: 800, epoch: 2 | loss: 0.1384183\n",
      "\tspeed: 0.0541s/iter; left time: 884.6430s\n",
      "\titers: 900, epoch: 2 | loss: 0.1377827\n",
      "\tspeed: 0.0541s/iter; left time: 877.9655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.39s\n",
      "Steps: 902 | Train Loss: 0.1480785 Vali Loss: 0.1684496 Test Loss: 0.1873153\n",
      "Validation loss decreased (0.183212 --> 0.168450).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1325896\n",
      "\tspeed: 0.1459s/iter; left time: 2354.0274s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413253\n",
      "\tspeed: 0.0532s/iter; left time: 852.7820s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303057\n",
      "\tspeed: 0.0543s/iter; left time: 864.8343s\n",
      "\titers: 400, epoch: 3 | loss: 0.1383175\n",
      "\tspeed: 0.0523s/iter; left time: 828.5851s\n",
      "\titers: 500, epoch: 3 | loss: 0.1243712\n",
      "\tspeed: 0.0507s/iter; left time: 798.5930s\n",
      "\titers: 600, epoch: 3 | loss: 0.1304547\n",
      "\tspeed: 0.0506s/iter; left time: 791.3385s\n",
      "\titers: 700, epoch: 3 | loss: 0.1181477\n",
      "\tspeed: 0.0523s/iter; left time: 812.6986s\n",
      "\titers: 800, epoch: 3 | loss: 0.1223750\n",
      "\tspeed: 0.0532s/iter; left time: 820.5714s\n",
      "\titers: 900, epoch: 3 | loss: 0.1114032\n",
      "\tspeed: 0.0542s/iter; left time: 830.7548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 902 | Train Loss: 0.1275883 Vali Loss: 0.1371416 Test Loss: 0.1529757\n",
      "Validation loss decreased (0.168450 --> 0.137142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1154191\n",
      "\tspeed: 0.1380s/iter; left time: 2102.0716s\n",
      "\titers: 200, epoch: 4 | loss: 0.1040316\n",
      "\tspeed: 0.0542s/iter; left time: 820.0498s\n",
      "\titers: 300, epoch: 4 | loss: 0.0999732\n",
      "\tspeed: 0.0549s/iter; left time: 825.1447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1075287\n",
      "\tspeed: 0.0548s/iter; left time: 818.7344s\n",
      "\titers: 500, epoch: 4 | loss: 0.1019707\n",
      "\tspeed: 0.0544s/iter; left time: 807.6332s\n",
      "\titers: 600, epoch: 4 | loss: 0.0993232\n",
      "\tspeed: 0.0546s/iter; left time: 803.8109s\n",
      "\titers: 700, epoch: 4 | loss: 0.1015184\n",
      "\tspeed: 0.0541s/iter; left time: 792.3443s\n",
      "\titers: 800, epoch: 4 | loss: 0.1015958\n",
      "\tspeed: 0.0544s/iter; left time: 790.0520s\n",
      "\titers: 900, epoch: 4 | loss: 0.1020327\n",
      "\tspeed: 0.0542s/iter; left time: 782.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.99s\n",
      "Steps: 902 | Train Loss: 0.1058670 Vali Loss: 0.1376515 Test Loss: 0.1540516\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1028747\n",
      "\tspeed: 0.1397s/iter; left time: 2002.7160s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934217\n",
      "\tspeed: 0.0548s/iter; left time: 780.1205s\n",
      "\titers: 300, epoch: 5 | loss: 0.0986301\n",
      "\tspeed: 0.0546s/iter; left time: 771.6814s\n",
      "\titers: 400, epoch: 5 | loss: 0.0986802\n",
      "\tspeed: 0.0553s/iter; left time: 776.4805s\n",
      "\titers: 500, epoch: 5 | loss: 0.0942053\n",
      "\tspeed: 0.0553s/iter; left time: 769.8424s\n",
      "\titers: 600, epoch: 5 | loss: 0.1024459\n",
      "\tspeed: 0.0550s/iter; left time: 760.6740s\n",
      "\titers: 700, epoch: 5 | loss: 0.0918240\n",
      "\tspeed: 0.0543s/iter; left time: 746.3635s\n",
      "\titers: 800, epoch: 5 | loss: 0.0978398\n",
      "\tspeed: 0.0527s/iter; left time: 719.0903s\n",
      "\titers: 900, epoch: 5 | loss: 0.1018387\n",
      "\tspeed: 0.0532s/iter; left time: 719.6025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.35s\n",
      "Steps: 902 | Train Loss: 0.0971580 Vali Loss: 0.1384684 Test Loss: 0.1528751\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0907427\n",
      "\tspeed: 0.1361s/iter; left time: 1827.8565s\n",
      "\titers: 200, epoch: 6 | loss: 0.1008368\n",
      "\tspeed: 0.0515s/iter; left time: 686.5154s\n",
      "\titers: 300, epoch: 6 | loss: 0.0912324\n",
      "\tspeed: 0.0517s/iter; left time: 684.3093s\n",
      "\titers: 400, epoch: 6 | loss: 0.0817516\n",
      "\tspeed: 0.0521s/iter; left time: 683.8038s\n",
      "\titers: 500, epoch: 6 | loss: 0.0888023\n",
      "\tspeed: 0.0514s/iter; left time: 670.0343s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920842\n",
      "\tspeed: 0.0515s/iter; left time: 666.2554s\n",
      "\titers: 700, epoch: 6 | loss: 0.0880135\n",
      "\tspeed: 0.0518s/iter; left time: 665.1887s\n",
      "\titers: 800, epoch: 6 | loss: 0.0896069\n",
      "\tspeed: 0.0523s/iter; left time: 665.2916s\n",
      "\titers: 900, epoch: 6 | loss: 0.0879484\n",
      "\tspeed: 0.0547s/iter; left time: 691.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.24s\n",
      "Steps: 902 | Train Loss: 0.0902217 Vali Loss: 0.1371762 Test Loss: 0.1525187\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0811038\n",
      "\tspeed: 0.1405s/iter; left time: 1759.8974s\n",
      "\titers: 200, epoch: 7 | loss: 0.0820944\n",
      "\tspeed: 0.0543s/iter; left time: 674.9313s\n",
      "\titers: 300, epoch: 7 | loss: 0.0783249\n",
      "\tspeed: 0.0546s/iter; left time: 672.8414s\n",
      "\titers: 400, epoch: 7 | loss: 0.0892762\n",
      "\tspeed: 0.0543s/iter; left time: 663.7511s\n",
      "\titers: 500, epoch: 7 | loss: 0.0804740\n",
      "\tspeed: 0.0526s/iter; left time: 638.4514s\n",
      "\titers: 600, epoch: 7 | loss: 0.0863952\n",
      "\tspeed: 0.0522s/iter; left time: 627.6950s\n",
      "\titers: 700, epoch: 7 | loss: 0.0759322\n",
      "\tspeed: 0.0533s/iter; left time: 635.7257s\n",
      "\titers: 800, epoch: 7 | loss: 0.0835908\n",
      "\tspeed: 0.0554s/iter; left time: 655.3730s\n",
      "\titers: 900, epoch: 7 | loss: 0.0783999\n",
      "\tspeed: 0.0544s/iter; left time: 637.6940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.96s\n",
      "Steps: 902 | Train Loss: 0.0839978 Vali Loss: 0.1375310 Test Loss: 0.1532999\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0879491\n",
      "\tspeed: 0.1382s/iter; left time: 1606.6503s\n",
      "\titers: 200, epoch: 8 | loss: 0.0793215\n",
      "\tspeed: 0.0532s/iter; left time: 613.0693s\n",
      "\titers: 300, epoch: 8 | loss: 0.0858402\n",
      "\tspeed: 0.0530s/iter; left time: 605.3308s\n",
      "\titers: 400, epoch: 8 | loss: 0.0771001\n",
      "\tspeed: 0.0541s/iter; left time: 612.3555s\n",
      "\titers: 500, epoch: 8 | loss: 0.0798749\n",
      "\tspeed: 0.0538s/iter; left time: 604.0902s\n",
      "\titers: 600, epoch: 8 | loss: 0.0801735\n",
      "\tspeed: 0.0547s/iter; left time: 608.5483s\n",
      "\titers: 700, epoch: 8 | loss: 0.0771784\n",
      "\tspeed: 0.0533s/iter; left time: 587.6364s\n",
      "\titers: 800, epoch: 8 | loss: 0.0812665\n",
      "\tspeed: 0.0516s/iter; left time: 563.4369s\n",
      "\titers: 900, epoch: 8 | loss: 0.0811051\n",
      "\tspeed: 0.0524s/iter; left time: 566.9903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.33s\n",
      "Steps: 902 | Train Loss: 0.0789480 Vali Loss: 0.1395975 Test Loss: 0.1572920\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04767633229494095, rmse:0.21834909915924072, mae:0.15297505259513855, rse:0.7735451459884644\n",
      "Original data scale mse:45013488.0, rmse:6709.208984375, mae:4394.25244140625, rse:0.33428502082824707\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.5630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1561</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.5514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.7157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.7181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.7862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>0.7774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.5588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.5734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.7190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.7440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.8158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>0.7735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0254  0.1594  0.1067  0.5630\n",
       "              2         24        0.0244  0.1561  0.1057  0.5514\n",
       "              1         96        0.0408  0.2021  0.1453  0.7157\n",
       "              2         96        0.0411  0.2028  0.1442  0.7181\n",
       "              1         168       0.0492  0.2219  0.1556  0.7862\n",
       "              2         168       0.0482  0.2194  0.1538  0.7774\n",
       "MAE           1         24        0.0250  0.1582  0.1025  0.5588\n",
       "              2         24        0.0264  0.1624  0.1030  0.5734\n",
       "              1         96        0.0412  0.2030  0.1423  0.7190\n",
       "              2         96        0.0441  0.2101  0.1443  0.7440\n",
       "              1         168       0.0530  0.2303  0.1560  0.8158\n",
       "              2         168       0.0477  0.2183  0.1530  0.7735"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_default.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_default.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>22144956.0</td>\n",
       "      <td>4705.8428</td>\n",
       "      <td>3012.8516</td>\n",
       "      <td>0.2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>20262382.0</td>\n",
       "      <td>4501.3755</td>\n",
       "      <td>2949.7402</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38047776.0</td>\n",
       "      <td>6168.2881</td>\n",
       "      <td>4162.5186</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37857840.0</td>\n",
       "      <td>6152.8726</td>\n",
       "      <td>4103.2231</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>46881424.0</td>\n",
       "      <td>6847.0010</td>\n",
       "      <td>4476.5269</td>\n",
       "      <td>0.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>46423284.0</td>\n",
       "      <td>6813.4634</td>\n",
       "      <td>4453.2134</td>\n",
       "      <td>0.3395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21606588.0</td>\n",
       "      <td>4648.2886</td>\n",
       "      <td>2894.6770</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>22582330.0</td>\n",
       "      <td>4752.0869</td>\n",
       "      <td>2871.8965</td>\n",
       "      <td>0.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38691036.0</td>\n",
       "      <td>6220.2119</td>\n",
       "      <td>4066.9163</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>41274512.0</td>\n",
       "      <td>6424.5244</td>\n",
       "      <td>4134.9688</td>\n",
       "      <td>0.3199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>50191892.0</td>\n",
       "      <td>7084.6235</td>\n",
       "      <td>4464.8423</td>\n",
       "      <td>0.3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45013488.0</td>\n",
       "      <td>6709.2090</td>\n",
       "      <td>4394.2524</td>\n",
       "      <td>0.3343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        22144956.0  4705.8428  3012.8516  0.2340\n",
       "              2         24        20262382.0  4501.3755  2949.7402  0.2238\n",
       "              1         96        38047776.0  6168.2881  4162.5186  0.3072\n",
       "              2         96        37857840.0  6152.8726  4103.2231  0.3064\n",
       "              1         168       46881424.0  6847.0010  4476.5269  0.3412\n",
       "              2         168       46423284.0  6813.4634  4453.2134  0.3395\n",
       "MAE           1         24        21606588.0  4648.2886  2894.6770  0.2311\n",
       "              2         24        22582330.0  4752.0869  2871.8965  0.2363\n",
       "              1         96        38691036.0  6220.2119  4066.9163  0.3098\n",
       "              2         96        41274512.0  6424.5244  4134.9688  0.3199\n",
       "              1         168       50191892.0  7084.6235  4464.8423  0.3530\n",
       "              2         168       45013488.0  6709.2090  4394.2524  0.3343"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.5661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>0.1062</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.7315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.7169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.2243</td>\n",
       "      <td>0.1545</td>\n",
       "      <td>0.7947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.7818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0257  0.1603  0.1028  0.5661\n",
       "         MSE            0.0249  0.1578  0.1062  0.5572\n",
       "96       MAE            0.0427  0.2066  0.1433  0.7315\n",
       "         MSE            0.0410  0.2024  0.1447  0.7169\n",
       "168      MAE            0.0503  0.2243  0.1545  0.7947\n",
       "         MSE            0.0487  0.2207  0.1547  0.7818"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>22094459.0</td>\n",
       "      <td>4700.1877</td>\n",
       "      <td>2883.2867</td>\n",
       "      <td>0.2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>21203669.0</td>\n",
       "      <td>4603.6091</td>\n",
       "      <td>2981.2959</td>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39982774.0</td>\n",
       "      <td>6322.3682</td>\n",
       "      <td>4100.9425</td>\n",
       "      <td>0.3149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37952808.0</td>\n",
       "      <td>6160.5803</td>\n",
       "      <td>4132.8708</td>\n",
       "      <td>0.3068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>47602690.0</td>\n",
       "      <td>6896.9163</td>\n",
       "      <td>4429.5474</td>\n",
       "      <td>0.3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>46652354.0</td>\n",
       "      <td>6830.2322</td>\n",
       "      <td>4464.8701</td>\n",
       "      <td>0.3403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            22094459.0  4700.1877  2883.2867  0.2337\n",
       "         MSE            21203669.0  4603.6091  2981.2959  0.2289\n",
       "96       MAE            39982774.0  6322.3682  4100.9425  0.3149\n",
       "         MSE            37952808.0  6160.5803  4132.8708  0.3068\n",
       "168      MAE            47602690.0  6896.9163  4429.5474  0.3436\n",
       "         MSE            46652354.0  6830.2322  4464.8701  0.3403"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL 0.00001 - from 96 - BAD\n",
    "# # 24 lr=0.000001; 96, 168 lr=0.00001 - BAD\n",
    "\n",
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0473826\n",
      "\tspeed: 0.0429s/iter; left time: 766.4097s\n",
      "\titers: 200, epoch: 1 | loss: 0.0382832\n",
      "\tspeed: 0.0160s/iter; left time: 283.8101s\n",
      "\titers: 300, epoch: 1 | loss: 0.0282230\n",
      "\tspeed: 0.0108s/iter; left time: 190.8130s\n",
      "\titers: 400, epoch: 1 | loss: 0.0289671\n",
      "\tspeed: 0.0108s/iter; left time: 190.2701s\n",
      "\titers: 500, epoch: 1 | loss: 0.0260729\n",
      "\tspeed: 0.0108s/iter; left time: 188.6951s\n",
      "\titers: 600, epoch: 1 | loss: 0.0225421\n",
      "\tspeed: 0.0109s/iter; left time: 188.7687s\n",
      "\titers: 700, epoch: 1 | loss: 0.0213244\n",
      "\tspeed: 0.0108s/iter; left time: 186.3340s\n",
      "\titers: 800, epoch: 1 | loss: 0.0216568\n",
      "\tspeed: 0.0108s/iter; left time: 185.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.08s\n",
      "Steps: 899 | Train Loss: 0.0292821 Vali Loss: 0.0252822 Test Loss: 0.0276659\n",
      "Validation loss decreased (inf --> 0.025282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0204176\n",
      "\tspeed: 0.0455s/iter; left time: 773.0555s\n",
      "\titers: 200, epoch: 2 | loss: 0.0170012\n",
      "\tspeed: 0.0107s/iter; left time: 179.8023s\n",
      "\titers: 300, epoch: 2 | loss: 0.0168107\n",
      "\tspeed: 0.0113s/iter; left time: 190.0252s\n",
      "\titers: 400, epoch: 2 | loss: 0.0125571\n",
      "\tspeed: 0.0106s/iter; left time: 176.8208s\n",
      "\titers: 500, epoch: 2 | loss: 0.0147066\n",
      "\tspeed: 0.0107s/iter; left time: 176.7441s\n",
      "\titers: 600, epoch: 2 | loss: 0.0100354\n",
      "\tspeed: 0.0106s/iter; left time: 174.9945s\n",
      "\titers: 700, epoch: 2 | loss: 0.0100348\n",
      "\tspeed: 0.0106s/iter; left time: 173.9739s\n",
      "\titers: 800, epoch: 2 | loss: 0.0125034\n",
      "\tspeed: 0.0106s/iter; left time: 173.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:10.19s\n",
      "Steps: 899 | Train Loss: 0.0154533 Vali Loss: 0.0197036 Test Loss: 0.0215209\n",
      "Validation loss decreased (0.025282 --> 0.019704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0112982\n",
      "\tspeed: 0.0582s/iter; left time: 936.2815s\n",
      "\titers: 200, epoch: 3 | loss: 0.0180719\n",
      "\tspeed: 0.0176s/iter; left time: 280.6525s\n",
      "\titers: 300, epoch: 3 | loss: 0.0139573\n",
      "\tspeed: 0.0162s/iter; left time: 257.7517s\n",
      "\titers: 400, epoch: 3 | loss: 0.0121949\n",
      "\tspeed: 0.0162s/iter; left time: 254.9505s\n",
      "\titers: 500, epoch: 3 | loss: 0.0142472\n",
      "\tspeed: 0.0163s/iter; left time: 255.6709s\n",
      "\titers: 600, epoch: 3 | loss: 0.0131088\n",
      "\tspeed: 0.0166s/iter; left time: 259.1802s\n",
      "\titers: 700, epoch: 3 | loss: 0.0133883\n",
      "\tspeed: 0.0169s/iter; left time: 262.2611s\n",
      "\titers: 800, epoch: 3 | loss: 0.0144125\n",
      "\tspeed: 0.0187s/iter; left time: 287.0897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.06s\n",
      "Steps: 899 | Train Loss: 0.0139125 Vali Loss: 0.0192315 Test Loss: 0.0209720\n",
      "Validation loss decreased (0.019704 --> 0.019232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0158415\n",
      "\tspeed: 0.0561s/iter; left time: 852.0978s\n",
      "\titers: 200, epoch: 4 | loss: 0.0129197\n",
      "\tspeed: 0.0164s/iter; left time: 247.7919s\n",
      "\titers: 300, epoch: 4 | loss: 0.0161630\n",
      "\tspeed: 0.0159s/iter; left time: 238.1904s\n",
      "\titers: 400, epoch: 4 | loss: 0.0122462\n",
      "\tspeed: 0.0155s/iter; left time: 231.4451s\n",
      "\titers: 500, epoch: 4 | loss: 0.0110393\n",
      "\tspeed: 0.0162s/iter; left time: 239.0960s\n",
      "\titers: 600, epoch: 4 | loss: 0.0115260\n",
      "\tspeed: 0.0157s/iter; left time: 230.9596s\n",
      "\titers: 700, epoch: 4 | loss: 0.0113594\n",
      "\tspeed: 0.0158s/iter; left time: 230.5126s\n",
      "\titers: 800, epoch: 4 | loss: 0.0114810\n",
      "\tspeed: 0.0168s/iter; left time: 243.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.70s\n",
      "Steps: 899 | Train Loss: 0.0134540 Vali Loss: 0.0191918 Test Loss: 0.0210814\n",
      "Validation loss decreased (0.019232 --> 0.019192).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0192404\n",
      "\tspeed: 0.0564s/iter; left time: 805.1714s\n",
      "\titers: 200, epoch: 5 | loss: 0.0148859\n",
      "\tspeed: 0.0153s/iter; left time: 217.1418s\n",
      "\titers: 300, epoch: 5 | loss: 0.0109130\n",
      "\tspeed: 0.0177s/iter; left time: 249.2278s\n",
      "\titers: 400, epoch: 5 | loss: 0.0123077\n",
      "\tspeed: 0.0189s/iter; left time: 264.2303s\n",
      "\titers: 500, epoch: 5 | loss: 0.0160494\n",
      "\tspeed: 0.0100s/iter; left time: 139.1236s\n",
      "\titers: 600, epoch: 5 | loss: 0.0113626\n",
      "\tspeed: 0.0192s/iter; left time: 264.0963s\n",
      "\titers: 700, epoch: 5 | loss: 0.0158431\n",
      "\tspeed: 0.0188s/iter; left time: 256.7790s\n",
      "\titers: 800, epoch: 5 | loss: 0.0127649\n",
      "\tspeed: 0.0195s/iter; left time: 264.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 899 | Train Loss: 0.0130898 Vali Loss: 0.0190935 Test Loss: 0.0209935\n",
      "Validation loss decreased (0.019192 --> 0.019093).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0140317\n",
      "\tspeed: 0.0600s/iter; left time: 803.5088s\n",
      "\titers: 200, epoch: 6 | loss: 0.0131839\n",
      "\tspeed: 0.0184s/iter; left time: 244.3444s\n",
      "\titers: 300, epoch: 6 | loss: 0.0101417\n",
      "\tspeed: 0.0163s/iter; left time: 215.0747s\n",
      "\titers: 400, epoch: 6 | loss: 0.0134418\n",
      "\tspeed: 0.0167s/iter; left time: 218.6410s\n",
      "\titers: 500, epoch: 6 | loss: 0.0104398\n",
      "\tspeed: 0.0187s/iter; left time: 242.7794s\n",
      "\titers: 600, epoch: 6 | loss: 0.0101812\n",
      "\tspeed: 0.0185s/iter; left time: 238.5254s\n",
      "\titers: 700, epoch: 6 | loss: 0.0152789\n",
      "\tspeed: 0.0185s/iter; left time: 236.4850s\n",
      "\titers: 800, epoch: 6 | loss: 0.0126685\n",
      "\tspeed: 0.0199s/iter; left time: 252.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.76s\n",
      "Steps: 899 | Train Loss: 0.0129204 Vali Loss: 0.0186697 Test Loss: 0.0206775\n",
      "Validation loss decreased (0.019093 --> 0.018670).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0171441\n",
      "\tspeed: 0.0594s/iter; left time: 741.2459s\n",
      "\titers: 200, epoch: 7 | loss: 0.0108239\n",
      "\tspeed: 0.0175s/iter; left time: 216.6574s\n",
      "\titers: 300, epoch: 7 | loss: 0.0196332\n",
      "\tspeed: 0.0180s/iter; left time: 221.4526s\n",
      "\titers: 400, epoch: 7 | loss: 0.0158535\n",
      "\tspeed: 0.0174s/iter; left time: 211.8458s\n",
      "\titers: 500, epoch: 7 | loss: 0.0139498\n",
      "\tspeed: 0.0188s/iter; left time: 226.8901s\n",
      "\titers: 600, epoch: 7 | loss: 0.0117080\n",
      "\tspeed: 0.0202s/iter; left time: 242.6373s\n",
      "\titers: 700, epoch: 7 | loss: 0.0102545\n",
      "\tspeed: 0.0200s/iter; left time: 237.8097s\n",
      "\titers: 800, epoch: 7 | loss: 0.0169946\n",
      "\tspeed: 0.0197s/iter; left time: 232.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.13s\n",
      "Steps: 899 | Train Loss: 0.0126911 Vali Loss: 0.0187594 Test Loss: 0.0206989\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0143879\n",
      "\tspeed: 0.0655s/iter; left time: 758.6131s\n",
      "\titers: 200, epoch: 8 | loss: 0.0121330\n",
      "\tspeed: 0.0198s/iter; left time: 227.2081s\n",
      "\titers: 300, epoch: 8 | loss: 0.0122098\n",
      "\tspeed: 0.0180s/iter; left time: 205.1964s\n",
      "\titers: 400, epoch: 8 | loss: 0.0147501\n",
      "\tspeed: 0.0193s/iter; left time: 218.2898s\n",
      "\titers: 500, epoch: 8 | loss: 0.0121360\n",
      "\tspeed: 0.0167s/iter; left time: 186.8652s\n",
      "\titers: 600, epoch: 8 | loss: 0.0119715\n",
      "\tspeed: 0.0171s/iter; left time: 189.1786s\n",
      "\titers: 700, epoch: 8 | loss: 0.0151747\n",
      "\tspeed: 0.0175s/iter; left time: 192.7053s\n",
      "\titers: 800, epoch: 8 | loss: 0.0103758\n",
      "\tspeed: 0.0192s/iter; left time: 209.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:17.14s\n",
      "Steps: 899 | Train Loss: 0.0125652 Vali Loss: 0.0188131 Test Loss: 0.0208157\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0125781\n",
      "\tspeed: 0.0612s/iter; left time: 653.6908s\n",
      "\titers: 200, epoch: 9 | loss: 0.0167858\n",
      "\tspeed: 0.0228s/iter; left time: 241.7648s\n",
      "\titers: 300, epoch: 9 | loss: 0.0140185\n",
      "\tspeed: 0.0224s/iter; left time: 235.4578s\n",
      "\titers: 400, epoch: 9 | loss: 0.0133994\n",
      "\tspeed: 0.0228s/iter; left time: 237.3642s\n",
      "\titers: 500, epoch: 9 | loss: 0.0118968\n",
      "\tspeed: 0.0217s/iter; left time: 223.5112s\n",
      "\titers: 600, epoch: 9 | loss: 0.0093683\n",
      "\tspeed: 0.0215s/iter; left time: 218.8538s\n",
      "\titers: 700, epoch: 9 | loss: 0.0154592\n",
      "\tspeed: 0.0216s/iter; left time: 217.8284s\n",
      "\titers: 800, epoch: 9 | loss: 0.0124763\n",
      "\tspeed: 0.0207s/iter; left time: 207.1482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:19.44s\n",
      "Steps: 899 | Train Loss: 0.0124188 Vali Loss: 0.0189290 Test Loss: 0.0211098\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0087976\n",
      "\tspeed: 0.0582s/iter; left time: 569.4610s\n",
      "\titers: 200, epoch: 10 | loss: 0.0098200\n",
      "\tspeed: 0.0198s/iter; left time: 191.5070s\n",
      "\titers: 300, epoch: 10 | loss: 0.0132224\n",
      "\tspeed: 0.0214s/iter; left time: 205.3200s\n",
      "\titers: 400, epoch: 10 | loss: 0.0113000\n",
      "\tspeed: 0.0188s/iter; left time: 178.1690s\n",
      "\titers: 500, epoch: 10 | loss: 0.0133694\n",
      "\tspeed: 0.0160s/iter; left time: 150.6370s\n",
      "\titers: 600, epoch: 10 | loss: 0.0128332\n",
      "\tspeed: 0.0175s/iter; left time: 162.8379s\n",
      "\titers: 700, epoch: 10 | loss: 0.0134831\n",
      "\tspeed: 0.0178s/iter; left time: 163.6248s\n",
      "\titers: 800, epoch: 10 | loss: 0.0114747\n",
      "\tspeed: 0.0223s/iter; left time: 202.3296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.42s\n",
      "Steps: 899 | Train Loss: 0.0123164 Vali Loss: 0.0186438 Test Loss: 0.0209615\n",
      "Validation loss decreased (0.018670 --> 0.018644).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0112410\n",
      "\tspeed: 0.0685s/iter; left time: 609.0555s\n",
      "\titers: 200, epoch: 11 | loss: 0.0149329\n",
      "\tspeed: 0.0231s/iter; left time: 203.4270s\n",
      "\titers: 300, epoch: 11 | loss: 0.0088868\n",
      "\tspeed: 0.0181s/iter; left time: 157.3479s\n",
      "\titers: 400, epoch: 11 | loss: 0.0098565\n",
      "\tspeed: 0.0173s/iter; left time: 149.0418s\n",
      "\titers: 500, epoch: 11 | loss: 0.0090272\n",
      "\tspeed: 0.0160s/iter; left time: 136.2683s\n",
      "\titers: 600, epoch: 11 | loss: 0.0134638\n",
      "\tspeed: 0.0163s/iter; left time: 137.0963s\n",
      "\titers: 700, epoch: 11 | loss: 0.0131333\n",
      "\tspeed: 0.0179s/iter; left time: 148.0523s\n",
      "\titers: 800, epoch: 11 | loss: 0.0115494\n",
      "\tspeed: 0.0184s/iter; left time: 150.7499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:17.27s\n",
      "Steps: 899 | Train Loss: 0.0122033 Vali Loss: 0.0185995 Test Loss: 0.0209250\n",
      "Validation loss decreased (0.018644 --> 0.018599).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0132741\n",
      "\tspeed: 0.0641s/iter; left time: 512.3858s\n",
      "\titers: 200, epoch: 12 | loss: 0.0130187\n",
      "\tspeed: 0.0088s/iter; left time: 69.4154s\n",
      "\titers: 300, epoch: 12 | loss: 0.0138484\n",
      "\tspeed: 0.0201s/iter; left time: 156.5811s\n",
      "\titers: 400, epoch: 12 | loss: 0.0129776\n",
      "\tspeed: 0.0187s/iter; left time: 143.5053s\n",
      "\titers: 500, epoch: 12 | loss: 0.0102051\n",
      "\tspeed: 0.0087s/iter; left time: 66.1024s\n",
      "\titers: 600, epoch: 12 | loss: 0.0115387\n",
      "\tspeed: 0.0086s/iter; left time: 64.7806s\n",
      "\titers: 700, epoch: 12 | loss: 0.0113493\n",
      "\tspeed: 0.0087s/iter; left time: 64.1947s\n",
      "\titers: 800, epoch: 12 | loss: 0.0128784\n",
      "\tspeed: 0.0086s/iter; left time: 62.9926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:11.39s\n",
      "Steps: 899 | Train Loss: 0.0121029 Vali Loss: 0.0187714 Test Loss: 0.0210115\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0097516\n",
      "\tspeed: 0.0505s/iter; left time: 358.2600s\n",
      "\titers: 200, epoch: 13 | loss: 0.0108325\n",
      "\tspeed: 0.0204s/iter; left time: 142.7687s\n",
      "\titers: 300, epoch: 13 | loss: 0.0117053\n",
      "\tspeed: 0.0200s/iter; left time: 137.7016s\n",
      "\titers: 400, epoch: 13 | loss: 0.0121307\n",
      "\tspeed: 0.0177s/iter; left time: 120.4825s\n",
      "\titers: 500, epoch: 13 | loss: 0.0089015\n",
      "\tspeed: 0.0156s/iter; left time: 104.7182s\n",
      "\titers: 600, epoch: 13 | loss: 0.0115309\n",
      "\tspeed: 0.0173s/iter; left time: 114.3554s\n",
      "\titers: 700, epoch: 13 | loss: 0.0097252\n",
      "\tspeed: 0.0194s/iter; left time: 125.9390s\n",
      "\titers: 800, epoch: 13 | loss: 0.0126883\n",
      "\tspeed: 0.0167s/iter; left time: 106.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:16.52s\n",
      "Steps: 899 | Train Loss: 0.0119877 Vali Loss: 0.0187343 Test Loss: 0.0209784\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0114555\n",
      "\tspeed: 0.0583s/iter; left time: 361.2459s\n",
      "\titers: 200, epoch: 14 | loss: 0.0137882\n",
      "\tspeed: 0.0180s/iter; left time: 109.6560s\n",
      "\titers: 300, epoch: 14 | loss: 0.0107610\n",
      "\tspeed: 0.0177s/iter; left time: 106.3153s\n",
      "\titers: 400, epoch: 14 | loss: 0.0122185\n",
      "\tspeed: 0.0188s/iter; left time: 110.8854s\n",
      "\titers: 500, epoch: 14 | loss: 0.0136675\n",
      "\tspeed: 0.0186s/iter; left time: 107.4849s\n",
      "\titers: 600, epoch: 14 | loss: 0.0128220\n",
      "\tspeed: 0.0195s/iter; left time: 110.7561s\n",
      "\titers: 700, epoch: 14 | loss: 0.0129853\n",
      "\tspeed: 0.0178s/iter; left time: 99.7437s\n",
      "\titers: 800, epoch: 14 | loss: 0.0131193\n",
      "\tspeed: 0.0165s/iter; left time: 90.7290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:16.58s\n",
      "Steps: 899 | Train Loss: 0.0119468 Vali Loss: 0.0186277 Test Loss: 0.0208803\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0115108\n",
      "\tspeed: 0.0627s/iter; left time: 331.8918s\n",
      "\titers: 200, epoch: 15 | loss: 0.0109533\n",
      "\tspeed: 0.0189s/iter; left time: 97.9545s\n",
      "\titers: 300, epoch: 15 | loss: 0.0138024\n",
      "\tspeed: 0.0177s/iter; left time: 90.3800s\n",
      "\titers: 400, epoch: 15 | loss: 0.0116320\n",
      "\tspeed: 0.0163s/iter; left time: 81.5418s\n",
      "\titers: 500, epoch: 15 | loss: 0.0119067\n",
      "\tspeed: 0.0180s/iter; left time: 87.9020s\n",
      "\titers: 600, epoch: 15 | loss: 0.0121463\n",
      "\tspeed: 0.0170s/iter; left time: 81.5355s\n",
      "\titers: 700, epoch: 15 | loss: 0.0126663\n",
      "\tspeed: 0.0161s/iter; left time: 75.6697s\n",
      "\titers: 800, epoch: 15 | loss: 0.0127733\n",
      "\tspeed: 0.0197s/iter; left time: 90.7167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:16.39s\n",
      "Steps: 899 | Train Loss: 0.0118416 Vali Loss: 0.0189211 Test Loss: 0.0212232\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0113680\n",
      "\tspeed: 0.0599s/iter; left time: 263.5102s\n",
      "\titers: 200, epoch: 16 | loss: 0.0115266\n",
      "\tspeed: 0.0185s/iter; left time: 79.6216s\n",
      "\titers: 300, epoch: 16 | loss: 0.0108524\n",
      "\tspeed: 0.0167s/iter; left time: 70.1580s\n",
      "\titers: 400, epoch: 16 | loss: 0.0118309\n",
      "\tspeed: 0.0187s/iter; left time: 76.4557s\n",
      "\titers: 500, epoch: 16 | loss: 0.0155532\n",
      "\tspeed: 0.0179s/iter; left time: 71.4268s\n",
      "\titers: 600, epoch: 16 | loss: 0.0110256\n",
      "\tspeed: 0.0187s/iter; left time: 72.9954s\n",
      "\titers: 700, epoch: 16 | loss: 0.0143026\n",
      "\tspeed: 0.0193s/iter; left time: 73.3534s\n",
      "\titers: 800, epoch: 16 | loss: 0.0108716\n",
      "\tspeed: 0.0183s/iter; left time: 67.7205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:16.83s\n",
      "Steps: 899 | Train Loss: 0.0117593 Vali Loss: 0.0188102 Test Loss: 0.0211945\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020925024524331093, rmse:0.14465484023094177, mae:0.09108760952949524, rse:0.5108525156974792\n",
      "Original data scale mse:16410582.0, rmse:4050.99755859375, mae:2452.97607421875, rse:0.2014237642288208\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0457902\n",
      "\tspeed: 0.0228s/iter; left time: 407.0866s\n",
      "\titers: 200, epoch: 1 | loss: 0.0355251\n",
      "\tspeed: 0.0183s/iter; left time: 326.0660s\n",
      "\titers: 300, epoch: 1 | loss: 0.0321882\n",
      "\tspeed: 0.0197s/iter; left time: 349.1447s\n",
      "\titers: 400, epoch: 1 | loss: 0.0265955\n",
      "\tspeed: 0.0187s/iter; left time: 328.0005s\n",
      "\titers: 500, epoch: 1 | loss: 0.0265549\n",
      "\tspeed: 0.0164s/iter; left time: 286.7171s\n",
      "\titers: 600, epoch: 1 | loss: 0.0270767\n",
      "\tspeed: 0.0175s/iter; left time: 304.4347s\n",
      "\titers: 700, epoch: 1 | loss: 0.0222197\n",
      "\tspeed: 0.0167s/iter; left time: 287.9407s\n",
      "\titers: 800, epoch: 1 | loss: 0.0270662\n",
      "\tspeed: 0.0189s/iter; left time: 324.1542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.79s\n",
      "Steps: 899 | Train Loss: 0.0286808 Vali Loss: 0.0256522 Test Loss: 0.0278483\n",
      "Validation loss decreased (inf --> 0.025652).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0186993\n",
      "\tspeed: 0.0617s/iter; left time: 1047.9287s\n",
      "\titers: 200, epoch: 2 | loss: 0.0149490\n",
      "\tspeed: 0.0189s/iter; left time: 318.6197s\n",
      "\titers: 300, epoch: 2 | loss: 0.0192263\n",
      "\tspeed: 0.0179s/iter; left time: 301.0738s\n",
      "\titers: 400, epoch: 2 | loss: 0.0128396\n",
      "\tspeed: 0.0200s/iter; left time: 334.2309s\n",
      "\titers: 500, epoch: 2 | loss: 0.0161713\n",
      "\tspeed: 0.0188s/iter; left time: 312.4111s\n",
      "\titers: 600, epoch: 2 | loss: 0.0152990\n",
      "\tspeed: 0.0191s/iter; left time: 314.7716s\n",
      "\titers: 700, epoch: 2 | loss: 0.0124367\n",
      "\tspeed: 0.0188s/iter; left time: 308.0633s\n",
      "\titers: 800, epoch: 2 | loss: 0.0091507\n",
      "\tspeed: 0.0186s/iter; left time: 303.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.34s\n",
      "Steps: 899 | Train Loss: 0.0155124 Vali Loss: 0.0197862 Test Loss: 0.0216443\n",
      "Validation loss decreased (0.025652 --> 0.019786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0105506\n",
      "\tspeed: 0.0595s/iter; left time: 956.4873s\n",
      "\titers: 200, epoch: 3 | loss: 0.0149882\n",
      "\tspeed: 0.0160s/iter; left time: 256.4830s\n",
      "\titers: 300, epoch: 3 | loss: 0.0119419\n",
      "\tspeed: 0.0161s/iter; left time: 256.2383s\n",
      "\titers: 400, epoch: 3 | loss: 0.0121237\n",
      "\tspeed: 0.0158s/iter; left time: 249.7382s\n",
      "\titers: 500, epoch: 3 | loss: 0.0155098\n",
      "\tspeed: 0.0160s/iter; left time: 251.6846s\n",
      "\titers: 600, epoch: 3 | loss: 0.0122041\n",
      "\tspeed: 0.0202s/iter; left time: 314.5368s\n",
      "\titers: 700, epoch: 3 | loss: 0.0144254\n",
      "\tspeed: 0.0163s/iter; left time: 252.5926s\n",
      "\titers: 800, epoch: 3 | loss: 0.0138710\n",
      "\tspeed: 0.0163s/iter; left time: 250.5907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.24s\n",
      "Steps: 899 | Train Loss: 0.0139672 Vali Loss: 0.0195890 Test Loss: 0.0213333\n",
      "Validation loss decreased (0.019786 --> 0.019589).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0175538\n",
      "\tspeed: 0.0579s/iter; left time: 878.6400s\n",
      "\titers: 200, epoch: 4 | loss: 0.0181735\n",
      "\tspeed: 0.0176s/iter; left time: 265.2235s\n",
      "\titers: 300, epoch: 4 | loss: 0.0136603\n",
      "\tspeed: 0.0176s/iter; left time: 263.8607s\n",
      "\titers: 400, epoch: 4 | loss: 0.0123173\n",
      "\tspeed: 0.0184s/iter; left time: 274.3616s\n",
      "\titers: 500, epoch: 4 | loss: 0.0111201\n",
      "\tspeed: 0.0179s/iter; left time: 263.9085s\n",
      "\titers: 600, epoch: 4 | loss: 0.0121893\n",
      "\tspeed: 0.0164s/iter; left time: 241.1222s\n",
      "\titers: 700, epoch: 4 | loss: 0.0150079\n",
      "\tspeed: 0.0158s/iter; left time: 231.1436s\n",
      "\titers: 800, epoch: 4 | loss: 0.0141909\n",
      "\tspeed: 0.0171s/iter; left time: 248.3293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 899 | Train Loss: 0.0135126 Vali Loss: 0.0193653 Test Loss: 0.0211665\n",
      "Validation loss decreased (0.019589 --> 0.019365).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0136079\n",
      "\tspeed: 0.0581s/iter; left time: 829.5254s\n",
      "\titers: 200, epoch: 5 | loss: 0.0180696\n",
      "\tspeed: 0.0143s/iter; left time: 202.1993s\n",
      "\titers: 300, epoch: 5 | loss: 0.0120717\n",
      "\tspeed: 0.0188s/iter; left time: 264.1002s\n",
      "\titers: 400, epoch: 5 | loss: 0.0101836\n",
      "\tspeed: 0.0195s/iter; left time: 273.2081s\n",
      "\titers: 500, epoch: 5 | loss: 0.0144089\n",
      "\tspeed: 0.0189s/iter; left time: 262.0629s\n",
      "\titers: 600, epoch: 5 | loss: 0.0143754\n",
      "\tspeed: 0.0165s/iter; left time: 227.7947s\n",
      "\titers: 700, epoch: 5 | loss: 0.0142654\n",
      "\tspeed: 0.0177s/iter; left time: 241.7287s\n",
      "\titers: 800, epoch: 5 | loss: 0.0109925\n",
      "\tspeed: 0.0192s/iter; left time: 260.6925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.41s\n",
      "Steps: 899 | Train Loss: 0.0131593 Vali Loss: 0.0190608 Test Loss: 0.0209979\n",
      "Validation loss decreased (0.019365 --> 0.019061).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0115359\n",
      "\tspeed: 0.0624s/iter; left time: 835.0572s\n",
      "\titers: 200, epoch: 6 | loss: 0.0108407\n",
      "\tspeed: 0.0199s/iter; left time: 265.0475s\n",
      "\titers: 300, epoch: 6 | loss: 0.0132991\n",
      "\tspeed: 0.0197s/iter; left time: 260.3301s\n",
      "\titers: 400, epoch: 6 | loss: 0.0130980\n",
      "\tspeed: 0.0196s/iter; left time: 256.6222s\n",
      "\titers: 500, epoch: 6 | loss: 0.0135049\n",
      "\tspeed: 0.0204s/iter; left time: 265.4094s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131979\n",
      "\tspeed: 0.0198s/iter; left time: 255.5879s\n",
      "\titers: 700, epoch: 6 | loss: 0.0121974\n",
      "\tspeed: 0.0202s/iter; left time: 258.2961s\n",
      "\titers: 800, epoch: 6 | loss: 0.0127625\n",
      "\tspeed: 0.0196s/iter; left time: 248.8161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 899 | Train Loss: 0.0129192 Vali Loss: 0.0191539 Test Loss: 0.0210567\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0110964\n",
      "\tspeed: 0.0669s/iter; left time: 835.3470s\n",
      "\titers: 200, epoch: 7 | loss: 0.0146689\n",
      "\tspeed: 0.0235s/iter; left time: 290.8161s\n",
      "\titers: 300, epoch: 7 | loss: 0.0142497\n",
      "\tspeed: 0.0237s/iter; left time: 290.8322s\n",
      "\titers: 400, epoch: 7 | loss: 0.0107652\n",
      "\tspeed: 0.0215s/iter; left time: 261.6463s\n",
      "\titers: 500, epoch: 7 | loss: 0.0096064\n",
      "\tspeed: 0.0163s/iter; left time: 197.3293s\n",
      "\titers: 600, epoch: 7 | loss: 0.0124354\n",
      "\tspeed: 0.0208s/iter; left time: 249.8459s\n",
      "\titers: 700, epoch: 7 | loss: 0.0127589\n",
      "\tspeed: 0.0201s/iter; left time: 238.3545s\n",
      "\titers: 800, epoch: 7 | loss: 0.0107064\n",
      "\tspeed: 0.0219s/iter; left time: 257.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:19.53s\n",
      "Steps: 899 | Train Loss: 0.0127138 Vali Loss: 0.0188986 Test Loss: 0.0212267\n",
      "Validation loss decreased (0.019061 --> 0.018899).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0096301\n",
      "\tspeed: 0.0647s/iter; left time: 749.3729s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110550\n",
      "\tspeed: 0.0194s/iter; left time: 223.2548s\n",
      "\titers: 300, epoch: 8 | loss: 0.0126958\n",
      "\tspeed: 0.0196s/iter; left time: 222.7146s\n",
      "\titers: 400, epoch: 8 | loss: 0.0093505\n",
      "\tspeed: 0.0202s/iter; left time: 228.2251s\n",
      "\titers: 500, epoch: 8 | loss: 0.0120393\n",
      "\tspeed: 0.0206s/iter; left time: 230.0351s\n",
      "\titers: 600, epoch: 8 | loss: 0.0113242\n",
      "\tspeed: 0.0200s/iter; left time: 222.1750s\n",
      "\titers: 700, epoch: 8 | loss: 0.0125462\n",
      "\tspeed: 0.0158s/iter; left time: 173.6181s\n",
      "\titers: 800, epoch: 8 | loss: 0.0160858\n",
      "\tspeed: 0.0083s/iter; left time: 90.2132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.23s\n",
      "Steps: 899 | Train Loss: 0.0125526 Vali Loss: 0.0189686 Test Loss: 0.0210197\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0178093\n",
      "\tspeed: 0.0516s/iter; left time: 551.5051s\n",
      "\titers: 200, epoch: 9 | loss: 0.0114021\n",
      "\tspeed: 0.0180s/iter; left time: 190.6484s\n",
      "\titers: 300, epoch: 9 | loss: 0.0114934\n",
      "\tspeed: 0.0197s/iter; left time: 206.5565s\n",
      "\titers: 400, epoch: 9 | loss: 0.0122732\n",
      "\tspeed: 0.0181s/iter; left time: 188.2241s\n",
      "\titers: 500, epoch: 9 | loss: 0.0140426\n",
      "\tspeed: 0.0186s/iter; left time: 191.7168s\n",
      "\titers: 600, epoch: 9 | loss: 0.0130213\n",
      "\tspeed: 0.0181s/iter; left time: 184.3502s\n",
      "\titers: 700, epoch: 9 | loss: 0.0135283\n",
      "\tspeed: 0.0193s/iter; left time: 195.1340s\n",
      "\titers: 800, epoch: 9 | loss: 0.0115506\n",
      "\tspeed: 0.0190s/iter; left time: 189.7858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.27s\n",
      "Steps: 899 | Train Loss: 0.0124008 Vali Loss: 0.0189153 Test Loss: 0.0209448\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0114106\n",
      "\tspeed: 0.0620s/iter; left time: 606.5195s\n",
      "\titers: 200, epoch: 10 | loss: 0.0084461\n",
      "\tspeed: 0.0179s/iter; left time: 173.4275s\n",
      "\titers: 300, epoch: 10 | loss: 0.0135540\n",
      "\tspeed: 0.0174s/iter; left time: 167.2821s\n",
      "\titers: 400, epoch: 10 | loss: 0.0126588\n",
      "\tspeed: 0.0220s/iter; left time: 208.9601s\n",
      "\titers: 500, epoch: 10 | loss: 0.0115303\n",
      "\tspeed: 0.0185s/iter; left time: 173.4740s\n",
      "\titers: 600, epoch: 10 | loss: 0.0111041\n",
      "\tspeed: 0.0192s/iter; left time: 178.2186s\n",
      "\titers: 700, epoch: 10 | loss: 0.0098951\n",
      "\tspeed: 0.0102s/iter; left time: 94.0044s\n",
      "\titers: 800, epoch: 10 | loss: 0.0117667\n",
      "\tspeed: 0.0086s/iter; left time: 78.1524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.50s\n",
      "Steps: 899 | Train Loss: 0.0122310 Vali Loss: 0.0188724 Test Loss: 0.0210248\n",
      "Validation loss decreased (0.018899 --> 0.018872).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0115265\n",
      "\tspeed: 0.0537s/iter; left time: 477.4787s\n",
      "\titers: 200, epoch: 11 | loss: 0.0110451\n",
      "\tspeed: 0.0202s/iter; left time: 177.4942s\n",
      "\titers: 300, epoch: 11 | loss: 0.0152067\n",
      "\tspeed: 0.0202s/iter; left time: 175.6778s\n",
      "\titers: 400, epoch: 11 | loss: 0.0120371\n",
      "\tspeed: 0.0188s/iter; left time: 161.4086s\n",
      "\titers: 500, epoch: 11 | loss: 0.0152251\n",
      "\tspeed: 0.0109s/iter; left time: 92.4566s\n",
      "\titers: 600, epoch: 11 | loss: 0.0120589\n",
      "\tspeed: 0.0146s/iter; left time: 122.3123s\n",
      "\titers: 700, epoch: 11 | loss: 0.0109666\n",
      "\tspeed: 0.0191s/iter; left time: 158.6520s\n",
      "\titers: 800, epoch: 11 | loss: 0.0131762\n",
      "\tspeed: 0.0192s/iter; left time: 157.5616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.36s\n",
      "Steps: 899 | Train Loss: 0.0121217 Vali Loss: 0.0189243 Test Loss: 0.0211811\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0117351\n",
      "\tspeed: 0.0561s/iter; left time: 448.1463s\n",
      "\titers: 200, epoch: 12 | loss: 0.0145740\n",
      "\tspeed: 0.0176s/iter; left time: 138.7905s\n",
      "\titers: 300, epoch: 12 | loss: 0.0094202\n",
      "\tspeed: 0.0182s/iter; left time: 142.1416s\n",
      "\titers: 400, epoch: 12 | loss: 0.0136812\n",
      "\tspeed: 0.0121s/iter; left time: 92.9979s\n",
      "\titers: 500, epoch: 12 | loss: 0.0107710\n",
      "\tspeed: 0.0168s/iter; left time: 127.5803s\n",
      "\titers: 600, epoch: 12 | loss: 0.0095288\n",
      "\tspeed: 0.0206s/iter; left time: 154.0528s\n",
      "\titers: 700, epoch: 12 | loss: 0.0133060\n",
      "\tspeed: 0.0110s/iter; left time: 81.4173s\n",
      "\titers: 800, epoch: 12 | loss: 0.0114591\n",
      "\tspeed: 0.0172s/iter; left time: 125.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 899 | Train Loss: 0.0120311 Vali Loss: 0.0188604 Test Loss: 0.0213185\n",
      "Validation loss decreased (0.018872 --> 0.018860).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0122448\n",
      "\tspeed: 0.0661s/iter; left time: 468.8721s\n",
      "\titers: 200, epoch: 13 | loss: 0.0119946\n",
      "\tspeed: 0.0222s/iter; left time: 155.5929s\n",
      "\titers: 300, epoch: 13 | loss: 0.0103137\n",
      "\tspeed: 0.0219s/iter; left time: 151.1393s\n",
      "\titers: 400, epoch: 13 | loss: 0.0136998\n",
      "\tspeed: 0.0199s/iter; left time: 135.1488s\n",
      "\titers: 500, epoch: 13 | loss: 0.0130183\n",
      "\tspeed: 0.0123s/iter; left time: 82.0878s\n",
      "\titers: 600, epoch: 13 | loss: 0.0121690\n",
      "\tspeed: 0.0179s/iter; left time: 118.1473s\n",
      "\titers: 700, epoch: 13 | loss: 0.0104109\n",
      "\tspeed: 0.0157s/iter; left time: 102.1388s\n",
      "\titers: 800, epoch: 13 | loss: 0.0097443\n",
      "\tspeed: 0.0193s/iter; left time: 123.3918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:16.54s\n",
      "Steps: 899 | Train Loss: 0.0119037 Vali Loss: 0.0191147 Test Loss: 0.0212845\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0115623\n",
      "\tspeed: 0.0561s/iter; left time: 347.4070s\n",
      "\titers: 200, epoch: 14 | loss: 0.0116535\n",
      "\tspeed: 0.0194s/iter; left time: 118.2713s\n",
      "\titers: 300, epoch: 14 | loss: 0.0111167\n",
      "\tspeed: 0.0198s/iter; left time: 118.4055s\n",
      "\titers: 400, epoch: 14 | loss: 0.0150699\n",
      "\tspeed: 0.0192s/iter; left time: 113.1924s\n",
      "\titers: 500, epoch: 14 | loss: 0.0101135\n",
      "\tspeed: 0.0194s/iter; left time: 112.2127s\n",
      "\titers: 600, epoch: 14 | loss: 0.0137401\n",
      "\tspeed: 0.0180s/iter; left time: 102.4338s\n",
      "\titers: 700, epoch: 14 | loss: 0.0105622\n",
      "\tspeed: 0.0181s/iter; left time: 101.5020s\n",
      "\titers: 800, epoch: 14 | loss: 0.0125808\n",
      "\tspeed: 0.0181s/iter; left time: 99.4605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:17.42s\n",
      "Steps: 899 | Train Loss: 0.0118196 Vali Loss: 0.0188819 Test Loss: 0.0211417\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0127577\n",
      "\tspeed: 0.0631s/iter; left time: 334.2990s\n",
      "\titers: 200, epoch: 15 | loss: 0.0126878\n",
      "\tspeed: 0.0182s/iter; left time: 94.6683s\n",
      "\titers: 300, epoch: 15 | loss: 0.0105862\n",
      "\tspeed: 0.0172s/iter; left time: 87.4261s\n",
      "\titers: 400, epoch: 15 | loss: 0.0114713\n",
      "\tspeed: 0.0202s/iter; left time: 100.6534s\n",
      "\titers: 500, epoch: 15 | loss: 0.0105691\n",
      "\tspeed: 0.0204s/iter; left time: 99.8182s\n",
      "\titers: 600, epoch: 15 | loss: 0.0091331\n",
      "\tspeed: 0.0188s/iter; left time: 90.1838s\n",
      "\titers: 700, epoch: 15 | loss: 0.0114861\n",
      "\tspeed: 0.0194s/iter; left time: 91.3148s\n",
      "\titers: 800, epoch: 15 | loss: 0.0114381\n",
      "\tspeed: 0.0188s/iter; left time: 86.2829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:17.38s\n",
      "Steps: 899 | Train Loss: 0.0117170 Vali Loss: 0.0188412 Test Loss: 0.0211004\n",
      "Validation loss decreased (0.018860 --> 0.018841).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0109407\n",
      "\tspeed: 0.0602s/iter; left time: 264.5944s\n",
      "\titers: 200, epoch: 16 | loss: 0.0117844\n",
      "\tspeed: 0.0211s/iter; left time: 90.7275s\n",
      "\titers: 300, epoch: 16 | loss: 0.0109369\n",
      "\tspeed: 0.0205s/iter; left time: 86.1632s\n",
      "\titers: 400, epoch: 16 | loss: 0.0095382\n",
      "\tspeed: 0.0214s/iter; left time: 87.6412s\n",
      "\titers: 500, epoch: 16 | loss: 0.0110272\n",
      "\tspeed: 0.0228s/iter; left time: 91.1840s\n",
      "\titers: 600, epoch: 16 | loss: 0.0149711\n",
      "\tspeed: 0.0185s/iter; left time: 71.9656s\n",
      "\titers: 700, epoch: 16 | loss: 0.0109164\n",
      "\tspeed: 0.0168s/iter; left time: 63.6153s\n",
      "\titers: 800, epoch: 16 | loss: 0.0116376\n",
      "\tspeed: 0.0171s/iter; left time: 63.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:17.95s\n",
      "Steps: 899 | Train Loss: 0.0116308 Vali Loss: 0.0189512 Test Loss: 0.0213696\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0168966\n",
      "\tspeed: 0.0618s/iter; left time: 216.1208s\n",
      "\titers: 200, epoch: 17 | loss: 0.0092044\n",
      "\tspeed: 0.0191s/iter; left time: 64.8667s\n",
      "\titers: 300, epoch: 17 | loss: 0.0114219\n",
      "\tspeed: 0.0187s/iter; left time: 61.5153s\n",
      "\titers: 400, epoch: 17 | loss: 0.0098255\n",
      "\tspeed: 0.0187s/iter; left time: 59.8654s\n",
      "\titers: 500, epoch: 17 | loss: 0.0093097\n",
      "\tspeed: 0.0188s/iter; left time: 58.2517s\n",
      "\titers: 600, epoch: 17 | loss: 0.0092668\n",
      "\tspeed: 0.0180s/iter; left time: 54.0624s\n",
      "\titers: 700, epoch: 17 | loss: 0.0126876\n",
      "\tspeed: 0.0192s/iter; left time: 55.5045s\n",
      "\titers: 800, epoch: 17 | loss: 0.0120877\n",
      "\tspeed: 0.0185s/iter; left time: 51.8683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:17.08s\n",
      "Steps: 899 | Train Loss: 0.0115721 Vali Loss: 0.0187740 Test Loss: 0.0211937\n",
      "Validation loss decreased (0.018841 --> 0.018774).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0084854\n",
      "\tspeed: 0.0612s/iter; left time: 159.1020s\n",
      "\titers: 200, epoch: 18 | loss: 0.0119431\n",
      "\tspeed: 0.0185s/iter; left time: 46.3319s\n",
      "\titers: 300, epoch: 18 | loss: 0.0130659\n",
      "\tspeed: 0.0193s/iter; left time: 46.2206s\n",
      "\titers: 400, epoch: 18 | loss: 0.0111225\n",
      "\tspeed: 0.0194s/iter; left time: 44.6205s\n",
      "\titers: 500, epoch: 18 | loss: 0.0110643\n",
      "\tspeed: 0.0210s/iter; left time: 46.1073s\n",
      "\titers: 600, epoch: 18 | loss: 0.0112308\n",
      "\tspeed: 0.0198s/iter; left time: 41.4554s\n",
      "\titers: 700, epoch: 18 | loss: 0.0140438\n",
      "\tspeed: 0.0200s/iter; left time: 39.9879s\n",
      "\titers: 800, epoch: 18 | loss: 0.0093938\n",
      "\tspeed: 0.0210s/iter; left time: 39.8771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.15s\n",
      "Steps: 899 | Train Loss: 0.0114896 Vali Loss: 0.0189394 Test Loss: 0.0214415\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0138919\n",
      "\tspeed: 0.0655s/iter; left time: 111.3433s\n",
      "\titers: 200, epoch: 19 | loss: 0.0112486\n",
      "\tspeed: 0.0200s/iter; left time: 31.9048s\n",
      "\titers: 300, epoch: 19 | loss: 0.0129541\n",
      "\tspeed: 0.0186s/iter; left time: 27.9067s\n",
      "\titers: 400, epoch: 19 | loss: 0.0097651\n",
      "\tspeed: 0.0195s/iter; left time: 27.2724s\n",
      "\titers: 500, epoch: 19 | loss: 0.0133860\n",
      "\tspeed: 0.0186s/iter; left time: 24.1583s\n",
      "\titers: 600, epoch: 19 | loss: 0.0123336\n",
      "\tspeed: 0.0186s/iter; left time: 22.3221s\n",
      "\titers: 700, epoch: 19 | loss: 0.0115520\n",
      "\tspeed: 0.0176s/iter; left time: 19.3634s\n",
      "\titers: 800, epoch: 19 | loss: 0.0127096\n",
      "\tspeed: 0.0155s/iter; left time: 15.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:16.85s\n",
      "Steps: 899 | Train Loss: 0.0114378 Vali Loss: 0.0189171 Test Loss: 0.0212900\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0129342\n",
      "\tspeed: 0.0595s/iter; left time: 47.6221s\n",
      "\titers: 200, epoch: 20 | loss: 0.0098808\n",
      "\tspeed: 0.0200s/iter; left time: 14.0146s\n",
      "\titers: 300, epoch: 20 | loss: 0.0129181\n",
      "\tspeed: 0.0200s/iter; left time: 11.9975s\n",
      "\titers: 400, epoch: 20 | loss: 0.0116030\n",
      "\tspeed: 0.0197s/iter; left time: 9.8557s\n",
      "\titers: 500, epoch: 20 | loss: 0.0084945\n",
      "\tspeed: 0.0199s/iter; left time: 7.9506s\n",
      "\titers: 600, epoch: 20 | loss: 0.0133949\n",
      "\tspeed: 0.0200s/iter; left time: 6.0043s\n",
      "\titers: 700, epoch: 20 | loss: 0.0140682\n",
      "\tspeed: 0.0199s/iter; left time: 3.9888s\n",
      "\titers: 800, epoch: 20 | loss: 0.0153431\n",
      "\tspeed: 0.0199s/iter; left time: 1.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.08s\n",
      "Steps: 899 | Train Loss: 0.0114011 Vali Loss: 0.0189303 Test Loss: 0.0213578\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021193696185946465, rmse:0.14558054506778717, mae:0.09138137102127075, rse:0.5141216516494751\n",
      "Original data scale mse:16438184.0, rmse:4054.403076171875, mae:2448.48974609375, rse:0.20159310102462769\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0454178\n",
      "\tspeed: 0.0439s/iter; left time: 782.7347s\n",
      "\titers: 200, epoch: 1 | loss: 0.0397962\n",
      "\tspeed: 0.0148s/iter; left time: 262.0030s\n",
      "\titers: 300, epoch: 1 | loss: 0.0354371\n",
      "\tspeed: 0.0152s/iter; left time: 268.6352s\n",
      "\titers: 400, epoch: 1 | loss: 0.0309083\n",
      "\tspeed: 0.0154s/iter; left time: 270.7394s\n",
      "\titers: 500, epoch: 1 | loss: 0.0320752\n",
      "\tspeed: 0.0164s/iter; left time: 286.8482s\n",
      "\titers: 600, epoch: 1 | loss: 0.0379417\n",
      "\tspeed: 0.0163s/iter; left time: 282.5256s\n",
      "\titers: 700, epoch: 1 | loss: 0.0335319\n",
      "\tspeed: 0.0160s/iter; left time: 276.3985s\n",
      "\titers: 800, epoch: 1 | loss: 0.0350816\n",
      "\tspeed: 0.0158s/iter; left time: 271.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.75s\n",
      "Steps: 897 | Train Loss: 0.0353925 Vali Loss: 0.0347506 Test Loss: 0.0400152\n",
      "Validation loss decreased (inf --> 0.034751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0227573\n",
      "\tspeed: 0.0627s/iter; left time: 1063.0781s\n",
      "\titers: 200, epoch: 2 | loss: 0.0234786\n",
      "\tspeed: 0.0166s/iter; left time: 279.2412s\n",
      "\titers: 300, epoch: 2 | loss: 0.0171458\n",
      "\tspeed: 0.0122s/iter; left time: 203.9718s\n",
      "\titers: 400, epoch: 2 | loss: 0.0217151\n",
      "\tspeed: 0.0181s/iter; left time: 301.2240s\n",
      "\titers: 500, epoch: 2 | loss: 0.0217050\n",
      "\tspeed: 0.0183s/iter; left time: 302.9941s\n",
      "\titers: 600, epoch: 2 | loss: 0.0227017\n",
      "\tspeed: 0.0187s/iter; left time: 306.7710s\n",
      "\titers: 700, epoch: 2 | loss: 0.0198010\n",
      "\tspeed: 0.0191s/iter; left time: 311.4303s\n",
      "\titers: 800, epoch: 2 | loss: 0.0304950\n",
      "\tspeed: 0.0171s/iter; left time: 277.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.98s\n",
      "Steps: 897 | Train Loss: 0.0248638 Vali Loss: 0.0302816 Test Loss: 0.0361787\n",
      "Validation loss decreased (0.034751 --> 0.030282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0215603\n",
      "\tspeed: 0.0624s/iter; left time: 1001.0231s\n",
      "\titers: 200, epoch: 3 | loss: 0.0261222\n",
      "\tspeed: 0.0200s/iter; left time: 319.6790s\n",
      "\titers: 300, epoch: 3 | loss: 0.0223573\n",
      "\tspeed: 0.0201s/iter; left time: 319.3141s\n",
      "\titers: 400, epoch: 3 | loss: 0.0243935\n",
      "\tspeed: 0.0203s/iter; left time: 320.4170s\n",
      "\titers: 500, epoch: 3 | loss: 0.0181809\n",
      "\tspeed: 0.0200s/iter; left time: 313.6363s\n",
      "\titers: 600, epoch: 3 | loss: 0.0206299\n",
      "\tspeed: 0.0176s/iter; left time: 274.0914s\n",
      "\titers: 700, epoch: 3 | loss: 0.0213240\n",
      "\tspeed: 0.0200s/iter; left time: 309.3914s\n",
      "\titers: 800, epoch: 3 | loss: 0.0205193\n",
      "\tspeed: 0.0189s/iter; left time: 289.3513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.81s\n",
      "Steps: 897 | Train Loss: 0.0231737 Vali Loss: 0.0302289 Test Loss: 0.0364739\n",
      "Validation loss decreased (0.030282 --> 0.030229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0216619\n",
      "\tspeed: 0.0616s/iter; left time: 932.9526s\n",
      "\titers: 200, epoch: 4 | loss: 0.0230161\n",
      "\tspeed: 0.0179s/iter; left time: 270.1248s\n",
      "\titers: 300, epoch: 4 | loss: 0.0271709\n",
      "\tspeed: 0.0220s/iter; left time: 328.6585s\n",
      "\titers: 400, epoch: 4 | loss: 0.0177641\n",
      "\tspeed: 0.0224s/iter; left time: 332.4496s\n",
      "\titers: 500, epoch: 4 | loss: 0.0196505\n",
      "\tspeed: 0.0186s/iter; left time: 275.0343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0241141\n",
      "\tspeed: 0.0178s/iter; left time: 260.6172s\n",
      "\titers: 700, epoch: 4 | loss: 0.0289479\n",
      "\tspeed: 0.0167s/iter; left time: 243.0279s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192867\n",
      "\tspeed: 0.0164s/iter; left time: 236.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.81s\n",
      "Steps: 897 | Train Loss: 0.0225280 Vali Loss: 0.0301759 Test Loss: 0.0362453\n",
      "Validation loss decreased (0.030229 --> 0.030176).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0186624\n",
      "\tspeed: 0.0608s/iter; left time: 866.4464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0230913\n",
      "\tspeed: 0.0201s/iter; left time: 284.1443s\n",
      "\titers: 300, epoch: 5 | loss: 0.0222964\n",
      "\tspeed: 0.0157s/iter; left time: 220.0603s\n",
      "\titers: 400, epoch: 5 | loss: 0.0199487\n",
      "\tspeed: 0.0161s/iter; left time: 224.0752s\n",
      "\titers: 500, epoch: 5 | loss: 0.0223834\n",
      "\tspeed: 0.0169s/iter; left time: 233.9160s\n",
      "\titers: 600, epoch: 5 | loss: 0.0207086\n",
      "\tspeed: 0.0184s/iter; left time: 253.4104s\n",
      "\titers: 700, epoch: 5 | loss: 0.0237754\n",
      "\tspeed: 0.0183s/iter; left time: 249.9169s\n",
      "\titers: 800, epoch: 5 | loss: 0.0262149\n",
      "\tspeed: 0.0173s/iter; left time: 234.2373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.72s\n",
      "Steps: 897 | Train Loss: 0.0217862 Vali Loss: 0.0310518 Test Loss: 0.0380594\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0213672\n",
      "\tspeed: 0.0570s/iter; left time: 761.0058s\n",
      "\titers: 200, epoch: 6 | loss: 0.0214000\n",
      "\tspeed: 0.0225s/iter; left time: 298.1819s\n",
      "\titers: 300, epoch: 6 | loss: 0.0208532\n",
      "\tspeed: 0.0179s/iter; left time: 235.8547s\n",
      "\titers: 400, epoch: 6 | loss: 0.0223042\n",
      "\tspeed: 0.0178s/iter; left time: 232.5217s\n",
      "\titers: 500, epoch: 6 | loss: 0.0232060\n",
      "\tspeed: 0.0190s/iter; left time: 246.1710s\n",
      "\titers: 600, epoch: 6 | loss: 0.0158212\n",
      "\tspeed: 0.0184s/iter; left time: 236.0461s\n",
      "\titers: 700, epoch: 6 | loss: 0.0217535\n",
      "\tspeed: 0.0179s/iter; left time: 228.5578s\n",
      "\titers: 800, epoch: 6 | loss: 0.0200092\n",
      "\tspeed: 0.0185s/iter; left time: 234.0417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.40s\n",
      "Steps: 897 | Train Loss: 0.0210645 Vali Loss: 0.0304606 Test Loss: 0.0381366\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0232773\n",
      "\tspeed: 0.0617s/iter; left time: 769.1755s\n",
      "\titers: 200, epoch: 7 | loss: 0.0181432\n",
      "\tspeed: 0.0183s/iter; left time: 225.6052s\n",
      "\titers: 300, epoch: 7 | loss: 0.0247703\n",
      "\tspeed: 0.0229s/iter; left time: 280.6627s\n",
      "\titers: 400, epoch: 7 | loss: 0.0179177\n",
      "\tspeed: 0.0228s/iter; left time: 277.1161s\n",
      "\titers: 500, epoch: 7 | loss: 0.0192368\n",
      "\tspeed: 0.0207s/iter; left time: 249.0676s\n",
      "\titers: 600, epoch: 7 | loss: 0.0192931\n",
      "\tspeed: 0.0199s/iter; left time: 238.1325s\n",
      "\titers: 700, epoch: 7 | loss: 0.0205836\n",
      "\tspeed: 0.0197s/iter; left time: 233.7586s\n",
      "\titers: 800, epoch: 7 | loss: 0.0182765\n",
      "\tspeed: 0.0200s/iter; left time: 235.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 897 | Train Loss: 0.0203373 Vali Loss: 0.0305170 Test Loss: 0.0382544\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0224325\n",
      "\tspeed: 0.0608s/iter; left time: 702.4761s\n",
      "\titers: 200, epoch: 8 | loss: 0.0190388\n",
      "\tspeed: 0.0190s/iter; left time: 217.8516s\n",
      "\titers: 300, epoch: 8 | loss: 0.0190860\n",
      "\tspeed: 0.0189s/iter; left time: 214.5018s\n",
      "\titers: 400, epoch: 8 | loss: 0.0183008\n",
      "\tspeed: 0.0164s/iter; left time: 184.7345s\n",
      "\titers: 500, epoch: 8 | loss: 0.0212030\n",
      "\tspeed: 0.0085s/iter; left time: 94.8905s\n",
      "\titers: 600, epoch: 8 | loss: 0.0151645\n",
      "\tspeed: 0.0085s/iter; left time: 94.0752s\n",
      "\titers: 700, epoch: 8 | loss: 0.0223684\n",
      "\tspeed: 0.0086s/iter; left time: 94.7841s\n",
      "\titers: 800, epoch: 8 | loss: 0.0183364\n",
      "\tspeed: 0.0120s/iter; left time: 130.4558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:12.95s\n",
      "Steps: 897 | Train Loss: 0.0196408 Vali Loss: 0.0312472 Test Loss: 0.0394033\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0212666\n",
      "\tspeed: 0.0624s/iter; left time: 665.9275s\n",
      "\titers: 200, epoch: 9 | loss: 0.0223828\n",
      "\tspeed: 0.0153s/iter; left time: 161.4426s\n",
      "\titers: 300, epoch: 9 | loss: 0.0207783\n",
      "\tspeed: 0.0099s/iter; left time: 103.8679s\n",
      "\titers: 400, epoch: 9 | loss: 0.0185441\n",
      "\tspeed: 0.0102s/iter; left time: 105.2993s\n",
      "\titers: 500, epoch: 9 | loss: 0.0183192\n",
      "\tspeed: 0.0146s/iter; left time: 149.8182s\n",
      "\titers: 600, epoch: 9 | loss: 0.0207369\n",
      "\tspeed: 0.0183s/iter; left time: 186.0859s\n",
      "\titers: 700, epoch: 9 | loss: 0.0219641\n",
      "\tspeed: 0.0170s/iter; left time: 171.0586s\n",
      "\titers: 800, epoch: 9 | loss: 0.0159893\n",
      "\tspeed: 0.0170s/iter; left time: 169.3840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:14.17s\n",
      "Steps: 897 | Train Loss: 0.0191264 Vali Loss: 0.0310072 Test Loss: 0.0396145\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03624531254172325, rmse:0.19038201868534088, mae:0.12985822558403015, rse:0.6741812229156494\n",
      "Original data scale mse:31191604.0, rmse:5584.9443359375, mae:3552.86279296875, rse:0.27813223004341125\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0480926\n",
      "\tspeed: 0.0193s/iter; left time: 344.3783s\n",
      "\titers: 200, epoch: 1 | loss: 0.0346505\n",
      "\tspeed: 0.0175s/iter; left time: 309.8649s\n",
      "\titers: 300, epoch: 1 | loss: 0.0340154\n",
      "\tspeed: 0.0190s/iter; left time: 335.7935s\n",
      "\titers: 400, epoch: 1 | loss: 0.0353862\n",
      "\tspeed: 0.0190s/iter; left time: 333.2096s\n",
      "\titers: 500, epoch: 1 | loss: 0.0388062\n",
      "\tspeed: 0.0171s/iter; left time: 298.9140s\n",
      "\titers: 600, epoch: 1 | loss: 0.0301650\n",
      "\tspeed: 0.0190s/iter; left time: 329.7281s\n",
      "\titers: 700, epoch: 1 | loss: 0.0287005\n",
      "\tspeed: 0.0201s/iter; left time: 346.8553s\n",
      "\titers: 800, epoch: 1 | loss: 0.0306839\n",
      "\tspeed: 0.0185s/iter; left time: 316.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.90s\n",
      "Steps: 897 | Train Loss: 0.0352779 Vali Loss: 0.0348270 Test Loss: 0.0399521\n",
      "Validation loss decreased (inf --> 0.034827).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0306245\n",
      "\tspeed: 0.0646s/iter; left time: 1094.4535s\n",
      "\titers: 200, epoch: 2 | loss: 0.0211526\n",
      "\tspeed: 0.0213s/iter; left time: 359.0968s\n",
      "\titers: 300, epoch: 2 | loss: 0.0244329\n",
      "\tspeed: 0.0181s/iter; left time: 302.8525s\n",
      "\titers: 400, epoch: 2 | loss: 0.0218056\n",
      "\tspeed: 0.0170s/iter; left time: 282.6358s\n",
      "\titers: 500, epoch: 2 | loss: 0.0186560\n",
      "\tspeed: 0.0173s/iter; left time: 285.6657s\n",
      "\titers: 600, epoch: 2 | loss: 0.0251740\n",
      "\tspeed: 0.0179s/iter; left time: 294.2436s\n",
      "\titers: 700, epoch: 2 | loss: 0.0240572\n",
      "\tspeed: 0.0163s/iter; left time: 265.8226s\n",
      "\titers: 800, epoch: 2 | loss: 0.0243016\n",
      "\tspeed: 0.0159s/iter; left time: 258.5445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.28s\n",
      "Steps: 897 | Train Loss: 0.0248065 Vali Loss: 0.0302696 Test Loss: 0.0361194\n",
      "Validation loss decreased (0.034827 --> 0.030270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0229246\n",
      "\tspeed: 0.0641s/iter; left time: 1028.8839s\n",
      "\titers: 200, epoch: 3 | loss: 0.0219153\n",
      "\tspeed: 0.0230s/iter; left time: 367.5589s\n",
      "\titers: 300, epoch: 3 | loss: 0.0271484\n",
      "\tspeed: 0.0209s/iter; left time: 331.3048s\n",
      "\titers: 400, epoch: 3 | loss: 0.0232124\n",
      "\tspeed: 0.0187s/iter; left time: 294.8708s\n",
      "\titers: 500, epoch: 3 | loss: 0.0224791\n",
      "\tspeed: 0.0206s/iter; left time: 322.2318s\n",
      "\titers: 600, epoch: 3 | loss: 0.0243500\n",
      "\tspeed: 0.0114s/iter; left time: 176.8316s\n",
      "\titers: 700, epoch: 3 | loss: 0.0215095\n",
      "\tspeed: 0.0111s/iter; left time: 171.9625s\n",
      "\titers: 800, epoch: 3 | loss: 0.0264937\n",
      "\tspeed: 0.0150s/iter; left time: 230.3096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.65s\n",
      "Steps: 897 | Train Loss: 0.0231274 Vali Loss: 0.0299051 Test Loss: 0.0361650\n",
      "Validation loss decreased (0.030270 --> 0.029905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0234405\n",
      "\tspeed: 0.0670s/iter; left time: 1015.7441s\n",
      "\titers: 200, epoch: 4 | loss: 0.0262239\n",
      "\tspeed: 0.0197s/iter; left time: 297.0777s\n",
      "\titers: 300, epoch: 4 | loss: 0.0223818\n",
      "\tspeed: 0.0262s/iter; left time: 391.2732s\n",
      "\titers: 400, epoch: 4 | loss: 0.0194408\n",
      "\tspeed: 0.0121s/iter; left time: 179.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.0195965\n",
      "\tspeed: 0.0085s/iter; left time: 126.0192s\n",
      "\titers: 600, epoch: 4 | loss: 0.0240217\n",
      "\tspeed: 0.0085s/iter; left time: 125.2256s\n",
      "\titers: 700, epoch: 4 | loss: 0.0228018\n",
      "\tspeed: 0.0146s/iter; left time: 213.0469s\n",
      "\titers: 800, epoch: 4 | loss: 0.0269684\n",
      "\tspeed: 0.0191s/iter; left time: 276.1400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.67s\n",
      "Steps: 897 | Train Loss: 0.0224228 Vali Loss: 0.0305619 Test Loss: 0.0364216\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0203036\n",
      "\tspeed: 0.0665s/iter; left time: 947.4883s\n",
      "\titers: 200, epoch: 5 | loss: 0.0201176\n",
      "\tspeed: 0.0191s/iter; left time: 270.2614s\n",
      "\titers: 300, epoch: 5 | loss: 0.0187731\n",
      "\tspeed: 0.0172s/iter; left time: 241.3921s\n",
      "\titers: 400, epoch: 5 | loss: 0.0239524\n",
      "\tspeed: 0.0174s/iter; left time: 243.2646s\n",
      "\titers: 500, epoch: 5 | loss: 0.0219218\n",
      "\tspeed: 0.0200s/iter; left time: 277.2443s\n",
      "\titers: 600, epoch: 5 | loss: 0.0209345\n",
      "\tspeed: 0.0213s/iter; left time: 292.8423s\n",
      "\titers: 700, epoch: 5 | loss: 0.0226463\n",
      "\tspeed: 0.0183s/iter; left time: 249.8474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0247946\n",
      "\tspeed: 0.0192s/iter; left time: 260.2434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.06s\n",
      "Steps: 897 | Train Loss: 0.0216586 Vali Loss: 0.0315939 Test Loss: 0.0378979\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0206733\n",
      "\tspeed: 0.0606s/iter; left time: 809.9448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0250075\n",
      "\tspeed: 0.0186s/iter; left time: 246.0424s\n",
      "\titers: 300, epoch: 6 | loss: 0.0212101\n",
      "\tspeed: 0.0165s/iter; left time: 217.5977s\n",
      "\titers: 400, epoch: 6 | loss: 0.0215767\n",
      "\tspeed: 0.0165s/iter; left time: 215.9437s\n",
      "\titers: 500, epoch: 6 | loss: 0.0238246\n",
      "\tspeed: 0.0165s/iter; left time: 213.7702s\n",
      "\titers: 600, epoch: 6 | loss: 0.0179306\n",
      "\tspeed: 0.0185s/iter; left time: 237.9077s\n",
      "\titers: 700, epoch: 6 | loss: 0.0221316\n",
      "\tspeed: 0.0168s/iter; left time: 214.8540s\n",
      "\titers: 800, epoch: 6 | loss: 0.0201810\n",
      "\tspeed: 0.0162s/iter; left time: 204.6983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.78s\n",
      "Steps: 897 | Train Loss: 0.0209496 Vali Loss: 0.0315850 Test Loss: 0.0383113\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0198822\n",
      "\tspeed: 0.0522s/iter; left time: 650.2380s\n",
      "\titers: 200, epoch: 7 | loss: 0.0238185\n",
      "\tspeed: 0.0085s/iter; left time: 104.4911s\n",
      "\titers: 300, epoch: 7 | loss: 0.0161765\n",
      "\tspeed: 0.0117s/iter; left time: 143.4475s\n",
      "\titers: 400, epoch: 7 | loss: 0.0200485\n",
      "\tspeed: 0.0163s/iter; left time: 198.5456s\n",
      "\titers: 500, epoch: 7 | loss: 0.0170087\n",
      "\tspeed: 0.0165s/iter; left time: 198.9633s\n",
      "\titers: 600, epoch: 7 | loss: 0.0204161\n",
      "\tspeed: 0.0184s/iter; left time: 219.4922s\n",
      "\titers: 700, epoch: 7 | loss: 0.0183387\n",
      "\tspeed: 0.0200s/iter; left time: 237.6737s\n",
      "\titers: 800, epoch: 7 | loss: 0.0210243\n",
      "\tspeed: 0.0209s/iter; left time: 245.7425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:14.64s\n",
      "Steps: 897 | Train Loss: 0.0202090 Vali Loss: 0.0314153 Test Loss: 0.0390077\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0169401\n",
      "\tspeed: 0.0642s/iter; left time: 742.7248s\n",
      "\titers: 200, epoch: 8 | loss: 0.0163040\n",
      "\tspeed: 0.0178s/iter; left time: 203.9793s\n",
      "\titers: 300, epoch: 8 | loss: 0.0196233\n",
      "\tspeed: 0.0182s/iter; left time: 206.8487s\n",
      "\titers: 400, epoch: 8 | loss: 0.0208273\n",
      "\tspeed: 0.0188s/iter; left time: 211.2737s\n",
      "\titers: 500, epoch: 8 | loss: 0.0188705\n",
      "\tspeed: 0.0187s/iter; left time: 208.2624s\n",
      "\titers: 600, epoch: 8 | loss: 0.0197150\n",
      "\tspeed: 0.0160s/iter; left time: 176.7825s\n",
      "\titers: 700, epoch: 8 | loss: 0.0180949\n",
      "\tspeed: 0.0160s/iter; left time: 175.8757s\n",
      "\titers: 800, epoch: 8 | loss: 0.0159072\n",
      "\tspeed: 0.0190s/iter; left time: 206.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.33s\n",
      "Steps: 897 | Train Loss: 0.0196304 Vali Loss: 0.0314431 Test Loss: 0.0396318\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036165010184049606, rmse:0.1901710033416748, mae:0.1306578665971756, rse:0.6734339594841003\n",
      "Original data scale mse:31495776.0, rmse:5612.10986328125, mae:3599.37841796875, rse:0.2794850766658783\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0496292\n",
      "\tspeed: 0.0460s/iter; left time: 818.0903s\n",
      "\titers: 200, epoch: 1 | loss: 0.0353908\n",
      "\tspeed: 0.0145s/iter; left time: 255.7177s\n",
      "\titers: 300, epoch: 1 | loss: 0.0345863\n",
      "\tspeed: 0.0114s/iter; left time: 200.1178s\n",
      "\titers: 400, epoch: 1 | loss: 0.0340177\n",
      "\tspeed: 0.0115s/iter; left time: 201.3495s\n",
      "\titers: 500, epoch: 1 | loss: 0.0387260\n",
      "\tspeed: 0.0110s/iter; left time: 190.3438s\n",
      "\titers: 600, epoch: 1 | loss: 0.0367151\n",
      "\tspeed: 0.0156s/iter; left time: 269.7006s\n",
      "\titers: 700, epoch: 1 | loss: 0.0371933\n",
      "\tspeed: 0.0137s/iter; left time: 234.7172s\n",
      "\titers: 800, epoch: 1 | loss: 0.0305589\n",
      "\tspeed: 0.0109s/iter; left time: 186.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:12.15s\n",
      "Steps: 894 | Train Loss: 0.0370488 Vali Loss: 0.0365667 Test Loss: 0.0423963\n",
      "Validation loss decreased (inf --> 0.036567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0288069\n",
      "\tspeed: 0.0587s/iter; left time: 991.6726s\n",
      "\titers: 200, epoch: 2 | loss: 0.0401227\n",
      "\tspeed: 0.0111s/iter; left time: 185.8955s\n",
      "\titers: 300, epoch: 2 | loss: 0.0245465\n",
      "\tspeed: 0.0111s/iter; left time: 185.2290s\n",
      "\titers: 400, epoch: 2 | loss: 0.0382174\n",
      "\tspeed: 0.0114s/iter; left time: 189.1971s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265731\n",
      "\tspeed: 0.0111s/iter; left time: 182.9000s\n",
      "\titers: 600, epoch: 2 | loss: 0.0278608\n",
      "\tspeed: 0.0183s/iter; left time: 300.0597s\n",
      "\titers: 700, epoch: 2 | loss: 0.0313551\n",
      "\tspeed: 0.0202s/iter; left time: 329.6616s\n",
      "\titers: 800, epoch: 2 | loss: 0.0247113\n",
      "\tspeed: 0.0173s/iter; left time: 279.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:14.11s\n",
      "Steps: 894 | Train Loss: 0.0271316 Vali Loss: 0.0328129 Test Loss: 0.0396719\n",
      "Validation loss decreased (0.036567 --> 0.032813).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0268928\n",
      "\tspeed: 0.0632s/iter; left time: 1010.8612s\n",
      "\titers: 200, epoch: 3 | loss: 0.0233744\n",
      "\tspeed: 0.0193s/iter; left time: 306.3687s\n",
      "\titers: 300, epoch: 3 | loss: 0.0207643\n",
      "\tspeed: 0.0195s/iter; left time: 308.3913s\n",
      "\titers: 400, epoch: 3 | loss: 0.0258979\n",
      "\tspeed: 0.0123s/iter; left time: 192.8793s\n",
      "\titers: 500, epoch: 3 | loss: 0.0270142\n",
      "\tspeed: 0.0087s/iter; left time: 135.5356s\n",
      "\titers: 600, epoch: 3 | loss: 0.0265181\n",
      "\tspeed: 0.0087s/iter; left time: 134.4536s\n",
      "\titers: 700, epoch: 3 | loss: 0.0255306\n",
      "\tspeed: 0.0087s/iter; left time: 133.4842s\n",
      "\titers: 800, epoch: 3 | loss: 0.0262585\n",
      "\tspeed: 0.0087s/iter; left time: 132.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:11.60s\n",
      "Steps: 894 | Train Loss: 0.0252249 Vali Loss: 0.0325171 Test Loss: 0.0391518\n",
      "Validation loss decreased (0.032813 --> 0.032517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0212256\n",
      "\tspeed: 0.0568s/iter; left time: 857.1271s\n",
      "\titers: 200, epoch: 4 | loss: 0.0205573\n",
      "\tspeed: 0.0209s/iter; left time: 313.6460s\n",
      "\titers: 300, epoch: 4 | loss: 0.0260446\n",
      "\tspeed: 0.0208s/iter; left time: 309.2260s\n",
      "\titers: 400, epoch: 4 | loss: 0.0197930\n",
      "\tspeed: 0.0198s/iter; left time: 292.5778s\n",
      "\titers: 500, epoch: 4 | loss: 0.0256136\n",
      "\tspeed: 0.0200s/iter; left time: 294.6985s\n",
      "\titers: 600, epoch: 4 | loss: 0.0212975\n",
      "\tspeed: 0.0209s/iter; left time: 305.2697s\n",
      "\titers: 700, epoch: 4 | loss: 0.0232032\n",
      "\tspeed: 0.0148s/iter; left time: 214.7103s\n",
      "\titers: 800, epoch: 4 | loss: 0.0235420\n",
      "\tspeed: 0.0182s/iter; left time: 262.5076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.02s\n",
      "Steps: 894 | Train Loss: 0.0243221 Vali Loss: 0.0333812 Test Loss: 0.0400170\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0210756\n",
      "\tspeed: 0.0655s/iter; left time: 929.9122s\n",
      "\titers: 200, epoch: 5 | loss: 0.0214975\n",
      "\tspeed: 0.0198s/iter; left time: 279.3437s\n",
      "\titers: 300, epoch: 5 | loss: 0.0234191\n",
      "\tspeed: 0.0212s/iter; left time: 296.9660s\n",
      "\titers: 400, epoch: 5 | loss: 0.0234666\n",
      "\tspeed: 0.0195s/iter; left time: 270.4750s\n",
      "\titers: 500, epoch: 5 | loss: 0.0268623\n",
      "\tspeed: 0.0217s/iter; left time: 299.8856s\n",
      "\titers: 600, epoch: 5 | loss: 0.0225183\n",
      "\tspeed: 0.0204s/iter; left time: 279.8087s\n",
      "\titers: 700, epoch: 5 | loss: 0.0249611\n",
      "\tspeed: 0.0219s/iter; left time: 297.9588s\n",
      "\titers: 800, epoch: 5 | loss: 0.0207153\n",
      "\tspeed: 0.0180s/iter; left time: 243.6844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.56s\n",
      "Steps: 894 | Train Loss: 0.0232772 Vali Loss: 0.0335892 Test Loss: 0.0405001\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0262145\n",
      "\tspeed: 0.0551s/iter; left time: 734.0647s\n",
      "\titers: 200, epoch: 6 | loss: 0.0221402\n",
      "\tspeed: 0.0185s/iter; left time: 244.2301s\n",
      "\titers: 300, epoch: 6 | loss: 0.0233662\n",
      "\tspeed: 0.0200s/iter; left time: 262.5091s\n",
      "\titers: 400, epoch: 6 | loss: 0.0198535\n",
      "\tspeed: 0.0179s/iter; left time: 232.9607s\n",
      "\titers: 500, epoch: 6 | loss: 0.0213320\n",
      "\tspeed: 0.0091s/iter; left time: 118.0869s\n",
      "\titers: 600, epoch: 6 | loss: 0.0200154\n",
      "\tspeed: 0.0089s/iter; left time: 114.0893s\n",
      "\titers: 700, epoch: 6 | loss: 0.0245876\n",
      "\tspeed: 0.0090s/iter; left time: 113.8392s\n",
      "\titers: 800, epoch: 6 | loss: 0.0201409\n",
      "\tspeed: 0.0090s/iter; left time: 113.1375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:12.35s\n",
      "Steps: 894 | Train Loss: 0.0224032 Vali Loss: 0.0337677 Test Loss: 0.0411684\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0263704\n",
      "\tspeed: 0.0540s/iter; left time: 670.6281s\n",
      "\titers: 200, epoch: 7 | loss: 0.0209116\n",
      "\tspeed: 0.0144s/iter; left time: 176.9367s\n",
      "\titers: 300, epoch: 7 | loss: 0.0202025\n",
      "\tspeed: 0.0151s/iter; left time: 184.4846s\n",
      "\titers: 400, epoch: 7 | loss: 0.0217714\n",
      "\tspeed: 0.0088s/iter; left time: 106.1023s\n",
      "\titers: 500, epoch: 7 | loss: 0.0198609\n",
      "\tspeed: 0.0151s/iter; left time: 181.8183s\n",
      "\titers: 600, epoch: 7 | loss: 0.0215424\n",
      "\tspeed: 0.0126s/iter; left time: 150.4785s\n",
      "\titers: 700, epoch: 7 | loss: 0.0183721\n",
      "\tspeed: 0.0184s/iter; left time: 217.0645s\n",
      "\titers: 800, epoch: 7 | loss: 0.0219598\n",
      "\tspeed: 0.0089s/iter; left time: 104.1837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:12.13s\n",
      "Steps: 894 | Train Loss: 0.0216842 Vali Loss: 0.0347317 Test Loss: 0.0409208\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0210522\n",
      "\tspeed: 0.0554s/iter; left time: 637.8769s\n",
      "\titers: 200, epoch: 8 | loss: 0.0209354\n",
      "\tspeed: 0.0190s/iter; left time: 217.4374s\n",
      "\titers: 300, epoch: 8 | loss: 0.0221724\n",
      "\tspeed: 0.0181s/iter; left time: 204.9943s\n",
      "\titers: 400, epoch: 8 | loss: 0.0208420\n",
      "\tspeed: 0.0171s/iter; left time: 192.3932s\n",
      "\titers: 500, epoch: 8 | loss: 0.0184332\n",
      "\tspeed: 0.0169s/iter; left time: 188.0477s\n",
      "\titers: 600, epoch: 8 | loss: 0.0214133\n",
      "\tspeed: 0.0177s/iter; left time: 195.1367s\n",
      "\titers: 700, epoch: 8 | loss: 0.0229768\n",
      "\tspeed: 0.0199s/iter; left time: 217.0275s\n",
      "\titers: 800, epoch: 8 | loss: 0.0217104\n",
      "\tspeed: 0.0199s/iter; left time: 215.1562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:17.33s\n",
      "Steps: 894 | Train Loss: 0.0210871 Vali Loss: 0.0353425 Test Loss: 0.0419443\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03915177658200264, rmse:0.19786807894706726, mae:0.13804472982883453, rse:0.7009870409965515\n",
      "Original data scale mse:34339608.0, rmse:5860.00048828125, mae:3805.825439453125, rse:0.29197338223457336\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0420810\n",
      "\tspeed: 0.0246s/iter; left time: 438.2734s\n",
      "\titers: 200, epoch: 1 | loss: 0.0386314\n",
      "\tspeed: 0.0116s/iter; left time: 205.5332s\n",
      "\titers: 300, epoch: 1 | loss: 0.0348747\n",
      "\tspeed: 0.0087s/iter; left time: 152.1508s\n",
      "\titers: 400, epoch: 1 | loss: 0.0354991\n",
      "\tspeed: 0.0086s/iter; left time: 150.6910s\n",
      "\titers: 500, epoch: 1 | loss: 0.0327938\n",
      "\tspeed: 0.0087s/iter; left time: 150.3590s\n",
      "\titers: 600, epoch: 1 | loss: 0.0298085\n",
      "\tspeed: 0.0087s/iter; left time: 149.6950s\n",
      "\titers: 700, epoch: 1 | loss: 0.0295443\n",
      "\tspeed: 0.0087s/iter; left time: 149.0014s\n",
      "\titers: 800, epoch: 1 | loss: 0.0332421\n",
      "\tspeed: 0.0155s/iter; left time: 264.2408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.67s\n",
      "Steps: 894 | Train Loss: 0.0369663 Vali Loss: 0.0365914 Test Loss: 0.0423416\n",
      "Validation loss decreased (inf --> 0.036591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0298073\n",
      "\tspeed: 0.0582s/iter; left time: 983.2295s\n",
      "\titers: 200, epoch: 2 | loss: 0.0276770\n",
      "\tspeed: 0.0201s/iter; left time: 338.1907s\n",
      "\titers: 300, epoch: 2 | loss: 0.0264912\n",
      "\tspeed: 0.0191s/iter; left time: 317.8937s\n",
      "\titers: 400, epoch: 2 | loss: 0.0257129\n",
      "\tspeed: 0.0189s/iter; left time: 312.7949s\n",
      "\titers: 500, epoch: 2 | loss: 0.0281139\n",
      "\tspeed: 0.0186s/iter; left time: 306.3558s\n",
      "\titers: 600, epoch: 2 | loss: 0.0252819\n",
      "\tspeed: 0.0188s/iter; left time: 308.4893s\n",
      "\titers: 700, epoch: 2 | loss: 0.0229821\n",
      "\tspeed: 0.0178s/iter; left time: 290.2879s\n",
      "\titers: 800, epoch: 2 | loss: 0.0302041\n",
      "\tspeed: 0.0201s/iter; left time: 324.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.70s\n",
      "Steps: 894 | Train Loss: 0.0271362 Vali Loss: 0.0325874 Test Loss: 0.0390298\n",
      "Validation loss decreased (0.036591 --> 0.032587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0275192\n",
      "\tspeed: 0.0687s/iter; left time: 1099.3251s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276977\n",
      "\tspeed: 0.0206s/iter; left time: 327.9016s\n",
      "\titers: 300, epoch: 3 | loss: 0.0257137\n",
      "\tspeed: 0.0199s/iter; left time: 313.9781s\n",
      "\titers: 400, epoch: 3 | loss: 0.0280709\n",
      "\tspeed: 0.0192s/iter; left time: 301.7428s\n",
      "\titers: 500, epoch: 3 | loss: 0.0321924\n",
      "\tspeed: 0.0208s/iter; left time: 324.4738s\n",
      "\titers: 600, epoch: 3 | loss: 0.0206190\n",
      "\tspeed: 0.0185s/iter; left time: 287.0948s\n",
      "\titers: 700, epoch: 3 | loss: 0.0204047\n",
      "\tspeed: 0.0217s/iter; left time: 333.9465s\n",
      "\titers: 800, epoch: 3 | loss: 0.0270967\n",
      "\tspeed: 0.0191s/iter; left time: 291.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 894 | Train Loss: 0.0252945 Vali Loss: 0.0331874 Test Loss: 0.0401605\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0196697\n",
      "\tspeed: 0.0631s/iter; left time: 952.3527s\n",
      "\titers: 200, epoch: 4 | loss: 0.0221571\n",
      "\tspeed: 0.0194s/iter; left time: 291.2127s\n",
      "\titers: 300, epoch: 4 | loss: 0.0222807\n",
      "\tspeed: 0.0204s/iter; left time: 304.3149s\n",
      "\titers: 400, epoch: 4 | loss: 0.0209460\n",
      "\tspeed: 0.0181s/iter; left time: 267.9111s\n",
      "\titers: 500, epoch: 4 | loss: 0.0225330\n",
      "\tspeed: 0.0183s/iter; left time: 268.3976s\n",
      "\titers: 600, epoch: 4 | loss: 0.0258525\n",
      "\tspeed: 0.0178s/iter; left time: 260.0937s\n",
      "\titers: 700, epoch: 4 | loss: 0.0277432\n",
      "\tspeed: 0.0197s/iter; left time: 285.5929s\n",
      "\titers: 800, epoch: 4 | loss: 0.0232017\n",
      "\tspeed: 0.0220s/iter; left time: 317.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.52s\n",
      "Steps: 894 | Train Loss: 0.0244976 Vali Loss: 0.0332647 Test Loss: 0.0396323\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0228070\n",
      "\tspeed: 0.0612s/iter; left time: 868.7227s\n",
      "\titers: 200, epoch: 5 | loss: 0.0236709\n",
      "\tspeed: 0.0181s/iter; left time: 255.9749s\n",
      "\titers: 300, epoch: 5 | loss: 0.0238024\n",
      "\tspeed: 0.0188s/iter; left time: 263.2273s\n",
      "\titers: 400, epoch: 5 | loss: 0.0237379\n",
      "\tspeed: 0.0149s/iter; left time: 206.4902s\n",
      "\titers: 500, epoch: 5 | loss: 0.0180401\n",
      "\tspeed: 0.0172s/iter; left time: 237.2939s\n",
      "\titers: 600, epoch: 5 | loss: 0.0202489\n",
      "\tspeed: 0.0172s/iter; left time: 235.7938s\n",
      "\titers: 700, epoch: 5 | loss: 0.0286180\n",
      "\tspeed: 0.0225s/iter; left time: 305.6185s\n",
      "\titers: 800, epoch: 5 | loss: 0.0233924\n",
      "\tspeed: 0.0227s/iter; left time: 306.1653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:17.15s\n",
      "Steps: 894 | Train Loss: 0.0235689 Vali Loss: 0.0332572 Test Loss: 0.0404304\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0199518\n",
      "\tspeed: 0.0669s/iter; left time: 890.7236s\n",
      "\titers: 200, epoch: 6 | loss: 0.0241909\n",
      "\tspeed: 0.0180s/iter; left time: 237.8770s\n",
      "\titers: 300, epoch: 6 | loss: 0.0226961\n",
      "\tspeed: 0.0193s/iter; left time: 252.8566s\n",
      "\titers: 400, epoch: 6 | loss: 0.0256515\n",
      "\tspeed: 0.0192s/iter; left time: 250.3534s\n",
      "\titers: 500, epoch: 6 | loss: 0.0236923\n",
      "\tspeed: 0.0172s/iter; left time: 221.4986s\n",
      "\titers: 600, epoch: 6 | loss: 0.0198184\n",
      "\tspeed: 0.0186s/iter; left time: 238.9047s\n",
      "\titers: 700, epoch: 6 | loss: 0.0217244\n",
      "\tspeed: 0.0185s/iter; left time: 235.2918s\n",
      "\titers: 800, epoch: 6 | loss: 0.0273252\n",
      "\tspeed: 0.0214s/iter; left time: 269.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.51s\n",
      "Steps: 894 | Train Loss: 0.0225785 Vali Loss: 0.0340634 Test Loss: 0.0419131\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0228320\n",
      "\tspeed: 0.0647s/iter; left time: 803.5539s\n",
      "\titers: 200, epoch: 7 | loss: 0.0226776\n",
      "\tspeed: 0.0188s/iter; left time: 231.3728s\n",
      "\titers: 300, epoch: 7 | loss: 0.0202659\n",
      "\tspeed: 0.0212s/iter; left time: 259.1499s\n",
      "\titers: 400, epoch: 7 | loss: 0.0204980\n",
      "\tspeed: 0.0195s/iter; left time: 236.6869s\n",
      "\titers: 500, epoch: 7 | loss: 0.0192253\n",
      "\tspeed: 0.0194s/iter; left time: 232.9981s\n",
      "\titers: 600, epoch: 7 | loss: 0.0220071\n",
      "\tspeed: 0.0188s/iter; left time: 224.2808s\n",
      "\titers: 700, epoch: 7 | loss: 0.0215449\n",
      "\tspeed: 0.0202s/iter; left time: 239.1001s\n",
      "\titers: 800, epoch: 7 | loss: 0.0225065\n",
      "\tspeed: 0.0198s/iter; left time: 232.4097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.93s\n",
      "Steps: 894 | Train Loss: 0.0217327 Vali Loss: 0.0344858 Test Loss: 0.0418395\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039029814302921295, rmse:0.197559654712677, mae:0.13822495937347412, rse:0.699894368648529\n",
      "Original data scale mse:34692824.0, rmse:5890.0615234375, mae:3834.89208984375, rse:0.29347115755081177\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1699114\n",
      "\tspeed: 0.0457s/iter; left time: 816.8690s\n",
      "\titers: 200, epoch: 1 | loss: 0.1456228\n",
      "\tspeed: 0.0148s/iter; left time: 263.5175s\n",
      "\titers: 300, epoch: 1 | loss: 0.1230900\n",
      "\tspeed: 0.0124s/iter; left time: 218.6555s\n",
      "\titers: 400, epoch: 1 | loss: 0.1254754\n",
      "\tspeed: 0.0105s/iter; left time: 185.3160s\n",
      "\titers: 500, epoch: 1 | loss: 0.1222176\n",
      "\tspeed: 0.0099s/iter; left time: 172.6239s\n",
      "\titers: 600, epoch: 1 | loss: 0.1092779\n",
      "\tspeed: 0.0101s/iter; left time: 174.7617s\n",
      "\titers: 700, epoch: 1 | loss: 0.1044666\n",
      "\tspeed: 0.0100s/iter; left time: 172.6017s\n",
      "\titers: 800, epoch: 1 | loss: 0.1063705\n",
      "\tspeed: 0.0099s/iter; left time: 170.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.93s\n",
      "Steps: 899 | Train Loss: 0.1257798 Vali Loss: 0.1110929 Test Loss: 0.1128930\n",
      "Validation loss decreased (inf --> 0.111093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0975361\n",
      "\tspeed: 0.0537s/iter; left time: 912.0560s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860673\n",
      "\tspeed: 0.0185s/iter; left time: 311.7853s\n",
      "\titers: 300, epoch: 2 | loss: 0.0904538\n",
      "\tspeed: 0.0174s/iter; left time: 292.2267s\n",
      "\titers: 400, epoch: 2 | loss: 0.0762541\n",
      "\tspeed: 0.0191s/iter; left time: 318.1887s\n",
      "\titers: 500, epoch: 2 | loss: 0.0780700\n",
      "\tspeed: 0.0202s/iter; left time: 334.6747s\n",
      "\titers: 600, epoch: 2 | loss: 0.0692537\n",
      "\tspeed: 0.0196s/iter; left time: 322.3614s\n",
      "\titers: 700, epoch: 2 | loss: 0.0680461\n",
      "\tspeed: 0.0202s/iter; left time: 331.0704s\n",
      "\titers: 800, epoch: 2 | loss: 0.0763900\n",
      "\tspeed: 0.0202s/iter; left time: 328.1605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.64s\n",
      "Steps: 899 | Train Loss: 0.0832708 Vali Loss: 0.0902659 Test Loss: 0.0924854\n",
      "Validation loss decreased (0.111093 --> 0.090266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679687\n",
      "\tspeed: 0.0666s/iter; left time: 1071.5083s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901940\n",
      "\tspeed: 0.0198s/iter; left time: 315.9727s\n",
      "\titers: 300, epoch: 3 | loss: 0.0764005\n",
      "\tspeed: 0.0200s/iter; left time: 317.1616s\n",
      "\titers: 400, epoch: 3 | loss: 0.0723383\n",
      "\tspeed: 0.0192s/iter; left time: 302.2820s\n",
      "\titers: 500, epoch: 3 | loss: 0.0779710\n",
      "\tspeed: 0.0171s/iter; left time: 268.6704s\n",
      "\titers: 600, epoch: 3 | loss: 0.0727503\n",
      "\tspeed: 0.0177s/iter; left time: 275.6315s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751205\n",
      "\tspeed: 0.0178s/iter; left time: 275.6734s\n",
      "\titers: 800, epoch: 3 | loss: 0.0780661\n",
      "\tspeed: 0.0181s/iter; left time: 278.2055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.60s\n",
      "Steps: 899 | Train Loss: 0.0770012 Vali Loss: 0.0891606 Test Loss: 0.0912216\n",
      "Validation loss decreased (0.090266 --> 0.089161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849877\n",
      "\tspeed: 0.0653s/iter; left time: 992.1254s\n",
      "\titers: 200, epoch: 4 | loss: 0.0722153\n",
      "\tspeed: 0.0218s/iter; left time: 328.7052s\n",
      "\titers: 300, epoch: 4 | loss: 0.0854225\n",
      "\tspeed: 0.0235s/iter; left time: 352.0971s\n",
      "\titers: 400, epoch: 4 | loss: 0.0708546\n",
      "\tspeed: 0.0240s/iter; left time: 357.8555s\n",
      "\titers: 500, epoch: 4 | loss: 0.0673474\n",
      "\tspeed: 0.0236s/iter; left time: 348.7911s\n",
      "\titers: 600, epoch: 4 | loss: 0.0692550\n",
      "\tspeed: 0.0251s/iter; left time: 368.2503s\n",
      "\titers: 700, epoch: 4 | loss: 0.0690826\n",
      "\tspeed: 0.0260s/iter; left time: 379.5481s\n",
      "\titers: 800, epoch: 4 | loss: 0.0702298\n",
      "\tspeed: 0.0243s/iter; left time: 352.2192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.68s\n",
      "Steps: 899 | Train Loss: 0.0750933 Vali Loss: 0.0877253 Test Loss: 0.0901212\n",
      "Validation loss decreased (0.089161 --> 0.087725).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0923176\n",
      "\tspeed: 0.0702s/iter; left time: 1003.4930s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822757\n",
      "\tspeed: 0.0198s/iter; left time: 281.3096s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662893\n",
      "\tspeed: 0.0195s/iter; left time: 274.4636s\n",
      "\titers: 400, epoch: 5 | loss: 0.0707256\n",
      "\tspeed: 0.0191s/iter; left time: 267.1786s\n",
      "\titers: 500, epoch: 5 | loss: 0.0802359\n",
      "\tspeed: 0.0194s/iter; left time: 269.8136s\n",
      "\titers: 600, epoch: 5 | loss: 0.0645350\n",
      "\tspeed: 0.0170s/iter; left time: 234.0376s\n",
      "\titers: 700, epoch: 5 | loss: 0.0807229\n",
      "\tspeed: 0.0155s/iter; left time: 211.7206s\n",
      "\titers: 800, epoch: 5 | loss: 0.0742908\n",
      "\tspeed: 0.0180s/iter; left time: 244.8630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.99s\n",
      "Steps: 899 | Train Loss: 0.0736888 Vali Loss: 0.0868323 Test Loss: 0.0893674\n",
      "Validation loss decreased (0.087725 --> 0.086832).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0786779\n",
      "\tspeed: 0.0662s/iter; left time: 886.7868s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729970\n",
      "\tspeed: 0.0205s/iter; left time: 271.9326s\n",
      "\titers: 300, epoch: 6 | loss: 0.0655113\n",
      "\tspeed: 0.0179s/iter; left time: 235.5227s\n",
      "\titers: 400, epoch: 6 | loss: 0.0733098\n",
      "\tspeed: 0.0176s/iter; left time: 229.7505s\n",
      "\titers: 500, epoch: 6 | loss: 0.0624508\n",
      "\tspeed: 0.0200s/iter; left time: 259.6631s\n",
      "\titers: 600, epoch: 6 | loss: 0.0645986\n",
      "\tspeed: 0.0193s/iter; left time: 249.0268s\n",
      "\titers: 700, epoch: 6 | loss: 0.0776242\n",
      "\tspeed: 0.0195s/iter; left time: 249.4668s\n",
      "\titers: 800, epoch: 6 | loss: 0.0744509\n",
      "\tspeed: 0.0197s/iter; left time: 249.3943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 899 | Train Loss: 0.0728320 Vali Loss: 0.0860531 Test Loss: 0.0887993\n",
      "Validation loss decreased (0.086832 --> 0.086053).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855157\n",
      "\tspeed: 0.0616s/iter; left time: 768.6090s\n",
      "\titers: 200, epoch: 7 | loss: 0.0673508\n",
      "\tspeed: 0.0196s/iter; left time: 243.2538s\n",
      "\titers: 300, epoch: 7 | loss: 0.0899708\n",
      "\tspeed: 0.0214s/iter; left time: 262.8477s\n",
      "\titers: 400, epoch: 7 | loss: 0.0789183\n",
      "\tspeed: 0.0199s/iter; left time: 243.0802s\n",
      "\titers: 500, epoch: 7 | loss: 0.0747509\n",
      "\tspeed: 0.0202s/iter; left time: 244.0939s\n",
      "\titers: 600, epoch: 7 | loss: 0.0671256\n",
      "\tspeed: 0.0206s/iter; left time: 246.5104s\n",
      "\titers: 700, epoch: 7 | loss: 0.0650975\n",
      "\tspeed: 0.0200s/iter; left time: 237.5151s\n",
      "\titers: 800, epoch: 7 | loss: 0.0809915\n",
      "\tspeed: 0.0169s/iter; left time: 198.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.45s\n",
      "Steps: 899 | Train Loss: 0.0720725 Vali Loss: 0.0861470 Test Loss: 0.0888172\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729383\n",
      "\tspeed: 0.0584s/iter; left time: 676.2092s\n",
      "\titers: 200, epoch: 8 | loss: 0.0698166\n",
      "\tspeed: 0.0198s/iter; left time: 227.6044s\n",
      "\titers: 300, epoch: 8 | loss: 0.0721286\n",
      "\tspeed: 0.0199s/iter; left time: 226.5584s\n",
      "\titers: 400, epoch: 8 | loss: 0.0737807\n",
      "\tspeed: 0.0197s/iter; left time: 222.4343s\n",
      "\titers: 500, epoch: 8 | loss: 0.0726368\n",
      "\tspeed: 0.0205s/iter; left time: 229.1571s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704511\n",
      "\tspeed: 0.0248s/iter; left time: 274.4880s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792957\n",
      "\tspeed: 0.0256s/iter; left time: 281.2576s\n",
      "\titers: 800, epoch: 8 | loss: 0.0663496\n",
      "\tspeed: 0.0277s/iter; left time: 301.1327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:20.77s\n",
      "Steps: 899 | Train Loss: 0.0714903 Vali Loss: 0.0861474 Test Loss: 0.0886393\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698867\n",
      "\tspeed: 0.0725s/iter; left time: 774.7275s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845585\n",
      "\tspeed: 0.0218s/iter; left time: 231.1563s\n",
      "\titers: 300, epoch: 9 | loss: 0.0753064\n",
      "\tspeed: 0.0226s/iter; left time: 237.2697s\n",
      "\titers: 400, epoch: 9 | loss: 0.0718598\n",
      "\tspeed: 0.0198s/iter; left time: 206.1163s\n",
      "\titers: 500, epoch: 9 | loss: 0.0694097\n",
      "\tspeed: 0.0202s/iter; left time: 207.4812s\n",
      "\titers: 600, epoch: 9 | loss: 0.0620578\n",
      "\tspeed: 0.0202s/iter; left time: 205.9631s\n",
      "\titers: 700, epoch: 9 | loss: 0.0795895\n",
      "\tspeed: 0.0201s/iter; left time: 202.5973s\n",
      "\titers: 800, epoch: 9 | loss: 0.0709405\n",
      "\tspeed: 0.0199s/iter; left time: 199.2692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:18.97s\n",
      "Steps: 899 | Train Loss: 0.0710822 Vali Loss: 0.0856650 Test Loss: 0.0884287\n",
      "Validation loss decreased (0.086053 --> 0.085665).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0581429\n",
      "\tspeed: 0.0648s/iter; left time: 634.0349s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608211\n",
      "\tspeed: 0.0189s/iter; left time: 183.3856s\n",
      "\titers: 300, epoch: 10 | loss: 0.0734590\n",
      "\tspeed: 0.0193s/iter; left time: 184.7433s\n",
      "\titers: 400, epoch: 10 | loss: 0.0669398\n",
      "\tspeed: 0.0193s/iter; left time: 182.8565s\n",
      "\titers: 500, epoch: 10 | loss: 0.0692659\n",
      "\tspeed: 0.0194s/iter; left time: 182.1800s\n",
      "\titers: 600, epoch: 10 | loss: 0.0722333\n",
      "\tspeed: 0.0203s/iter; left time: 188.9341s\n",
      "\titers: 700, epoch: 10 | loss: 0.0733956\n",
      "\tspeed: 0.0176s/iter; left time: 162.1092s\n",
      "\titers: 800, epoch: 10 | loss: 0.0692956\n",
      "\tspeed: 0.0166s/iter; left time: 151.2866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.41s\n",
      "Steps: 899 | Train Loss: 0.0706859 Vali Loss: 0.0855614 Test Loss: 0.0887001\n",
      "Validation loss decreased (0.085665 --> 0.085561).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678060\n",
      "\tspeed: 0.0599s/iter; left time: 532.4406s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759341\n",
      "\tspeed: 0.0200s/iter; left time: 176.2273s\n",
      "\titers: 300, epoch: 11 | loss: 0.0601577\n",
      "\tspeed: 0.0160s/iter; left time: 139.1998s\n",
      "\titers: 400, epoch: 11 | loss: 0.0633233\n",
      "\tspeed: 0.0162s/iter; left time: 138.8292s\n",
      "\titers: 500, epoch: 11 | loss: 0.0629569\n",
      "\tspeed: 0.0164s/iter; left time: 139.3294s\n",
      "\titers: 600, epoch: 11 | loss: 0.0797240\n",
      "\tspeed: 0.0162s/iter; left time: 136.1404s\n",
      "\titers: 700, epoch: 11 | loss: 0.0731003\n",
      "\tspeed: 0.0185s/iter; left time: 153.3154s\n",
      "\titers: 800, epoch: 11 | loss: 0.0702309\n",
      "\tspeed: 0.0203s/iter; left time: 166.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.20s\n",
      "Steps: 899 | Train Loss: 0.0703157 Vali Loss: 0.0855017 Test Loss: 0.0885759\n",
      "Validation loss decreased (0.085561 --> 0.085502).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0732969\n",
      "\tspeed: 0.0577s/iter; left time: 461.5373s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719201\n",
      "\tspeed: 0.0153s/iter; left time: 120.6908s\n",
      "\titers: 300, epoch: 12 | loss: 0.0729044\n",
      "\tspeed: 0.0166s/iter; left time: 129.1417s\n",
      "\titers: 400, epoch: 12 | loss: 0.0696154\n",
      "\tspeed: 0.0166s/iter; left time: 128.0139s\n",
      "\titers: 500, epoch: 12 | loss: 0.0639770\n",
      "\tspeed: 0.0173s/iter; left time: 131.1743s\n",
      "\titers: 600, epoch: 12 | loss: 0.0690082\n",
      "\tspeed: 0.0168s/iter; left time: 125.6421s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722357\n",
      "\tspeed: 0.0167s/iter; left time: 123.8129s\n",
      "\titers: 800, epoch: 12 | loss: 0.0758104\n",
      "\tspeed: 0.0165s/iter; left time: 120.4234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.13s\n",
      "Steps: 899 | Train Loss: 0.0700508 Vali Loss: 0.0856699 Test Loss: 0.0881188\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0642084\n",
      "\tspeed: 0.0610s/iter; left time: 432.6633s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658650\n",
      "\tspeed: 0.0195s/iter; left time: 136.0755s\n",
      "\titers: 300, epoch: 13 | loss: 0.0665561\n",
      "\tspeed: 0.0144s/iter; left time: 99.1831s\n",
      "\titers: 400, epoch: 13 | loss: 0.0709723\n",
      "\tspeed: 0.0107s/iter; left time: 72.7470s\n",
      "\titers: 500, epoch: 13 | loss: 0.0583445\n",
      "\tspeed: 0.0107s/iter; left time: 71.7639s\n",
      "\titers: 600, epoch: 13 | loss: 0.0703394\n",
      "\tspeed: 0.0107s/iter; left time: 70.6589s\n",
      "\titers: 700, epoch: 13 | loss: 0.0637120\n",
      "\tspeed: 0.0107s/iter; left time: 69.4983s\n",
      "\titers: 800, epoch: 13 | loss: 0.0745235\n",
      "\tspeed: 0.0109s/iter; left time: 69.8197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:12.09s\n",
      "Steps: 899 | Train Loss: 0.0697134 Vali Loss: 0.0855094 Test Loss: 0.0881550\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0681760\n",
      "\tspeed: 0.0574s/iter; left time: 355.7974s\n",
      "\titers: 200, epoch: 14 | loss: 0.0720782\n",
      "\tspeed: 0.0245s/iter; left time: 149.0295s\n",
      "\titers: 300, epoch: 14 | loss: 0.0658425\n",
      "\tspeed: 0.0206s/iter; left time: 123.6462s\n",
      "\titers: 400, epoch: 14 | loss: 0.0700388\n",
      "\tspeed: 0.0179s/iter; left time: 105.2407s\n",
      "\titers: 500, epoch: 14 | loss: 0.0745661\n",
      "\tspeed: 0.0165s/iter; left time: 95.5802s\n",
      "\titers: 600, epoch: 14 | loss: 0.0695124\n",
      "\tspeed: 0.0181s/iter; left time: 103.2966s\n",
      "\titers: 700, epoch: 14 | loss: 0.0733287\n",
      "\tspeed: 0.0164s/iter; left time: 91.5885s\n",
      "\titers: 800, epoch: 14 | loss: 0.0721176\n",
      "\tspeed: 0.0165s/iter; left time: 90.5495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 899 | Train Loss: 0.0695946 Vali Loss: 0.0849960 Test Loss: 0.0877232\n",
      "Validation loss decreased (0.085502 --> 0.084996).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0672869\n",
      "\tspeed: 0.0559s/iter; left time: 296.2513s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669682\n",
      "\tspeed: 0.0166s/iter; left time: 86.4160s\n",
      "\titers: 300, epoch: 15 | loss: 0.0773682\n",
      "\tspeed: 0.0178s/iter; left time: 90.7581s\n",
      "\titers: 400, epoch: 15 | loss: 0.0696334\n",
      "\tspeed: 0.0181s/iter; left time: 90.2114s\n",
      "\titers: 500, epoch: 15 | loss: 0.0679439\n",
      "\tspeed: 0.0192s/iter; left time: 93.8823s\n",
      "\titers: 600, epoch: 15 | loss: 0.0699499\n",
      "\tspeed: 0.0173s/iter; left time: 82.8957s\n",
      "\titers: 700, epoch: 15 | loss: 0.0687645\n",
      "\tspeed: 0.0181s/iter; left time: 84.9540s\n",
      "\titers: 800, epoch: 15 | loss: 0.0707458\n",
      "\tspeed: 0.0196s/iter; left time: 90.2824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:16.55s\n",
      "Steps: 899 | Train Loss: 0.0693259 Vali Loss: 0.0855420 Test Loss: 0.0882043\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0684329\n",
      "\tspeed: 0.0619s/iter; left time: 272.0757s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708930\n",
      "\tspeed: 0.0218s/iter; left time: 93.8382s\n",
      "\titers: 300, epoch: 16 | loss: 0.0641553\n",
      "\tspeed: 0.0148s/iter; left time: 62.2811s\n",
      "\titers: 400, epoch: 16 | loss: 0.0702678\n",
      "\tspeed: 0.0107s/iter; left time: 43.7225s\n",
      "\titers: 500, epoch: 16 | loss: 0.0832398\n",
      "\tspeed: 0.0106s/iter; left time: 42.3116s\n",
      "\titers: 600, epoch: 16 | loss: 0.0708020\n",
      "\tspeed: 0.0106s/iter; left time: 41.3515s\n",
      "\titers: 700, epoch: 16 | loss: 0.0765868\n",
      "\tspeed: 0.0106s/iter; left time: 40.2321s\n",
      "\titers: 800, epoch: 16 | loss: 0.0663463\n",
      "\tspeed: 0.0106s/iter; left time: 39.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:12.30s\n",
      "Steps: 899 | Train Loss: 0.0691016 Vali Loss: 0.0853662 Test Loss: 0.0881296\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0738917\n",
      "\tspeed: 0.0504s/iter; left time: 176.3249s\n",
      "\titers: 200, epoch: 17 | loss: 0.0827880\n",
      "\tspeed: 0.0192s/iter; left time: 65.2094s\n",
      "\titers: 300, epoch: 17 | loss: 0.0735467\n",
      "\tspeed: 0.0194s/iter; left time: 63.8403s\n",
      "\titers: 400, epoch: 17 | loss: 0.0745451\n",
      "\tspeed: 0.0189s/iter; left time: 60.3046s\n",
      "\titers: 500, epoch: 17 | loss: 0.0648416\n",
      "\tspeed: 0.0187s/iter; left time: 58.0533s\n",
      "\titers: 600, epoch: 17 | loss: 0.0672527\n",
      "\tspeed: 0.0178s/iter; left time: 53.4090s\n",
      "\titers: 700, epoch: 17 | loss: 0.0694189\n",
      "\tspeed: 0.0189s/iter; left time: 54.6813s\n",
      "\titers: 800, epoch: 17 | loss: 0.0670546\n",
      "\tspeed: 0.0196s/iter; left time: 54.9224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:17.17s\n",
      "Steps: 899 | Train Loss: 0.0689764 Vali Loss: 0.0854846 Test Loss: 0.0880764\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0699533\n",
      "\tspeed: 0.0591s/iter; left time: 153.4253s\n",
      "\titers: 200, epoch: 18 | loss: 0.0751193\n",
      "\tspeed: 0.0190s/iter; left time: 47.4410s\n",
      "\titers: 300, epoch: 18 | loss: 0.0668175\n",
      "\tspeed: 0.0197s/iter; left time: 47.1489s\n",
      "\titers: 400, epoch: 18 | loss: 0.0705100\n",
      "\tspeed: 0.0190s/iter; left time: 43.6333s\n",
      "\titers: 500, epoch: 18 | loss: 0.0660879\n",
      "\tspeed: 0.0185s/iter; left time: 40.6899s\n",
      "\titers: 600, epoch: 18 | loss: 0.0796074\n",
      "\tspeed: 0.0188s/iter; left time: 39.5119s\n",
      "\titers: 700, epoch: 18 | loss: 0.0651793\n",
      "\tspeed: 0.0188s/iter; left time: 37.6131s\n",
      "\titers: 800, epoch: 18 | loss: 0.0704948\n",
      "\tspeed: 0.0202s/iter; left time: 38.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:17.36s\n",
      "Steps: 899 | Train Loss: 0.0688134 Vali Loss: 0.0850827 Test Loss: 0.0879960\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0602385\n",
      "\tspeed: 0.0616s/iter; left time: 104.6793s\n",
      "\titers: 200, epoch: 19 | loss: 0.0575550\n",
      "\tspeed: 0.0186s/iter; left time: 29.7690s\n",
      "\titers: 300, epoch: 19 | loss: 0.0749375\n",
      "\tspeed: 0.0192s/iter; left time: 28.8236s\n",
      "\titers: 400, epoch: 19 | loss: 0.0689627\n",
      "\tspeed: 0.0198s/iter; left time: 27.7352s\n",
      "\titers: 500, epoch: 19 | loss: 0.0644957\n",
      "\tspeed: 0.0191s/iter; left time: 24.7794s\n",
      "\titers: 600, epoch: 19 | loss: 0.0673711\n",
      "\tspeed: 0.0188s/iter; left time: 22.5285s\n",
      "\titers: 700, epoch: 19 | loss: 0.0659366\n",
      "\tspeed: 0.0190s/iter; left time: 20.8805s\n",
      "\titers: 800, epoch: 19 | loss: 0.0577507\n",
      "\tspeed: 0.0185s/iter; left time: 18.5035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 899 | Train Loss: 0.0686713 Vali Loss: 0.0849701 Test Loss: 0.0879816\n",
      "Validation loss decreased (0.084996 --> 0.084970).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0591534\n",
      "\tspeed: 0.0587s/iter; left time: 46.9762s\n",
      "\titers: 200, epoch: 20 | loss: 0.0697608\n",
      "\tspeed: 0.0197s/iter; left time: 13.7552s\n",
      "\titers: 300, epoch: 20 | loss: 0.0678148\n",
      "\tspeed: 0.0215s/iter; left time: 12.8784s\n",
      "\titers: 400, epoch: 20 | loss: 0.0731931\n",
      "\tspeed: 0.0186s/iter; left time: 9.2824s\n",
      "\titers: 500, epoch: 20 | loss: 0.0690914\n",
      "\tspeed: 0.0196s/iter; left time: 7.8257s\n",
      "\titers: 600, epoch: 20 | loss: 0.0679998\n",
      "\tspeed: 0.0164s/iter; left time: 4.9229s\n",
      "\titers: 700, epoch: 20 | loss: 0.0755195\n",
      "\tspeed: 0.0183s/iter; left time: 3.6653s\n",
      "\titers: 800, epoch: 20 | loss: 0.0581007\n",
      "\tspeed: 0.0193s/iter; left time: 1.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:17.27s\n",
      "Steps: 899 | Train Loss: 0.0684733 Vali Loss: 0.0852797 Test Loss: 0.0881990\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02125086635351181, rmse:0.14577676355838776, mae:0.08798161149024963, rse:0.5148146152496338\n",
      "Original data scale mse:16238499.0, rmse:4029.7021484375, mae:2347.381103515625, rse:0.20036490261554718\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1631498\n",
      "\tspeed: 0.0199s/iter; left time: 356.4999s\n",
      "\titers: 200, epoch: 1 | loss: 0.1497927\n",
      "\tspeed: 0.0164s/iter; left time: 291.3332s\n",
      "\titers: 300, epoch: 1 | loss: 0.1224728\n",
      "\tspeed: 0.0180s/iter; left time: 318.3983s\n",
      "\titers: 400, epoch: 1 | loss: 0.1143017\n",
      "\tspeed: 0.0165s/iter; left time: 289.4657s\n",
      "\titers: 500, epoch: 1 | loss: 0.1212442\n",
      "\tspeed: 0.0186s/iter; left time: 324.5784s\n",
      "\titers: 600, epoch: 1 | loss: 0.1078135\n",
      "\tspeed: 0.0184s/iter; left time: 320.2396s\n",
      "\titers: 700, epoch: 1 | loss: 0.1286664\n",
      "\tspeed: 0.0198s/iter; left time: 342.8201s\n",
      "\titers: 800, epoch: 1 | loss: 0.0968631\n",
      "\tspeed: 0.0196s/iter; left time: 336.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.63s\n",
      "Steps: 899 | Train Loss: 0.1262647 Vali Loss: 0.1126089 Test Loss: 0.1140863\n",
      "Validation loss decreased (inf --> 0.112609).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0904887\n",
      "\tspeed: 0.0621s/iter; left time: 1054.1531s\n",
      "\titers: 200, epoch: 2 | loss: 0.0781962\n",
      "\tspeed: 0.0200s/iter; left time: 338.0879s\n",
      "\titers: 300, epoch: 2 | loss: 0.0830004\n",
      "\tspeed: 0.0196s/iter; left time: 328.2823s\n",
      "\titers: 400, epoch: 2 | loss: 0.0841751\n",
      "\tspeed: 0.0209s/iter; left time: 348.8619s\n",
      "\titers: 500, epoch: 2 | loss: 0.0895703\n",
      "\tspeed: 0.0130s/iter; left time: 215.9361s\n",
      "\titers: 600, epoch: 2 | loss: 0.0797614\n",
      "\tspeed: 0.0107s/iter; left time: 175.9525s\n",
      "\titers: 700, epoch: 2 | loss: 0.0758386\n",
      "\tspeed: 0.0106s/iter; left time: 174.0958s\n",
      "\titers: 800, epoch: 2 | loss: 0.0827135\n",
      "\tspeed: 0.0106s/iter; left time: 172.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.87s\n",
      "Steps: 899 | Train Loss: 0.0832802 Vali Loss: 0.0911568 Test Loss: 0.0928057\n",
      "Validation loss decreased (0.112609 --> 0.091157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0759813\n",
      "\tspeed: 0.0542s/iter; left time: 870.9911s\n",
      "\titers: 200, epoch: 3 | loss: 0.0807376\n",
      "\tspeed: 0.0197s/iter; left time: 315.2973s\n",
      "\titers: 300, epoch: 3 | loss: 0.0869432\n",
      "\tspeed: 0.0195s/iter; left time: 309.4760s\n",
      "\titers: 400, epoch: 3 | loss: 0.0710320\n",
      "\tspeed: 0.0194s/iter; left time: 306.5749s\n",
      "\titers: 500, epoch: 3 | loss: 0.0696261\n",
      "\tspeed: 0.0197s/iter; left time: 308.5209s\n",
      "\titers: 600, epoch: 3 | loss: 0.0797288\n",
      "\tspeed: 0.0197s/iter; left time: 307.1991s\n",
      "\titers: 700, epoch: 3 | loss: 0.0803255\n",
      "\tspeed: 0.0194s/iter; left time: 300.2010s\n",
      "\titers: 800, epoch: 3 | loss: 0.0711106\n",
      "\tspeed: 0.0190s/iter; left time: 291.6234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.62s\n",
      "Steps: 899 | Train Loss: 0.0772403 Vali Loss: 0.0886865 Test Loss: 0.0912267\n",
      "Validation loss decreased (0.091157 --> 0.088686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0678243\n",
      "\tspeed: 0.0593s/iter; left time: 900.8072s\n",
      "\titers: 200, epoch: 4 | loss: 0.0743998\n",
      "\tspeed: 0.0189s/iter; left time: 284.7247s\n",
      "\titers: 300, epoch: 4 | loss: 0.0775956\n",
      "\tspeed: 0.0187s/iter; left time: 279.9049s\n",
      "\titers: 400, epoch: 4 | loss: 0.0696422\n",
      "\tspeed: 0.0195s/iter; left time: 290.1551s\n",
      "\titers: 500, epoch: 4 | loss: 0.0750090\n",
      "\tspeed: 0.0200s/iter; left time: 296.3837s\n",
      "\titers: 600, epoch: 4 | loss: 0.0675189\n",
      "\tspeed: 0.0203s/iter; left time: 297.4572s\n",
      "\titers: 700, epoch: 4 | loss: 0.0774582\n",
      "\tspeed: 0.0201s/iter; left time: 293.8497s\n",
      "\titers: 800, epoch: 4 | loss: 0.0845516\n",
      "\tspeed: 0.0201s/iter; left time: 291.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.96s\n",
      "Steps: 899 | Train Loss: 0.0751967 Vali Loss: 0.0882725 Test Loss: 0.0906460\n",
      "Validation loss decreased (0.088686 --> 0.088272).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0924980\n",
      "\tspeed: 0.0645s/iter; left time: 920.8338s\n",
      "\titers: 200, epoch: 5 | loss: 0.0717133\n",
      "\tspeed: 0.0206s/iter; left time: 291.7779s\n",
      "\titers: 300, epoch: 5 | loss: 0.0729038\n",
      "\tspeed: 0.0202s/iter; left time: 284.0953s\n",
      "\titers: 400, epoch: 5 | loss: 0.0757089\n",
      "\tspeed: 0.0203s/iter; left time: 284.5485s\n",
      "\titers: 500, epoch: 5 | loss: 0.0770153\n",
      "\tspeed: 0.0201s/iter; left time: 278.9862s\n",
      "\titers: 600, epoch: 5 | loss: 0.0755215\n",
      "\tspeed: 0.0201s/iter; left time: 277.3323s\n",
      "\titers: 700, epoch: 5 | loss: 0.0745732\n",
      "\tspeed: 0.0201s/iter; left time: 275.1848s\n",
      "\titers: 800, epoch: 5 | loss: 0.0735774\n",
      "\tspeed: 0.0201s/iter; left time: 272.5176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.50s\n",
      "Steps: 899 | Train Loss: 0.0738213 Vali Loss: 0.0880453 Test Loss: 0.0901448\n",
      "Validation loss decreased (0.088272 --> 0.088045).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0721607\n",
      "\tspeed: 0.0632s/iter; left time: 845.7910s\n",
      "\titers: 200, epoch: 6 | loss: 0.0626281\n",
      "\tspeed: 0.0191s/iter; left time: 253.3258s\n",
      "\titers: 300, epoch: 6 | loss: 0.0771642\n",
      "\tspeed: 0.0099s/iter; left time: 130.2503s\n",
      "\titers: 400, epoch: 6 | loss: 0.0734960\n",
      "\tspeed: 0.0084s/iter; left time: 110.4588s\n",
      "\titers: 500, epoch: 6 | loss: 0.0719008\n",
      "\tspeed: 0.0110s/iter; left time: 142.8759s\n",
      "\titers: 600, epoch: 6 | loss: 0.0687621\n",
      "\tspeed: 0.0189s/iter; left time: 243.2676s\n",
      "\titers: 700, epoch: 6 | loss: 0.0657437\n",
      "\tspeed: 0.0197s/iter; left time: 252.2520s\n",
      "\titers: 800, epoch: 6 | loss: 0.0710191\n",
      "\tspeed: 0.0195s/iter; left time: 246.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.74s\n",
      "Steps: 899 | Train Loss: 0.0728197 Vali Loss: 0.0865269 Test Loss: 0.0888708\n",
      "Validation loss decreased (0.088045 --> 0.086527).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0717923\n",
      "\tspeed: 0.0510s/iter; left time: 636.7958s\n",
      "\titers: 200, epoch: 7 | loss: 0.0705693\n",
      "\tspeed: 0.0084s/iter; left time: 104.6119s\n",
      "\titers: 300, epoch: 7 | loss: 0.0814302\n",
      "\tspeed: 0.0084s/iter; left time: 103.7594s\n",
      "\titers: 400, epoch: 7 | loss: 0.0749273\n",
      "\tspeed: 0.0084s/iter; left time: 102.6565s\n",
      "\titers: 500, epoch: 7 | loss: 0.0833129\n",
      "\tspeed: 0.0085s/iter; left time: 102.6332s\n",
      "\titers: 600, epoch: 7 | loss: 0.0740133\n",
      "\tspeed: 0.0085s/iter; left time: 101.3719s\n",
      "\titers: 700, epoch: 7 | loss: 0.0705647\n",
      "\tspeed: 0.0084s/iter; left time: 100.4136s\n",
      "\titers: 800, epoch: 7 | loss: 0.0744593\n",
      "\tspeed: 0.0085s/iter; left time: 99.6256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 899 | Train Loss: 0.0721643 Vali Loss: 0.0858901 Test Loss: 0.0887163\n",
      "Validation loss decreased (0.086527 --> 0.085890).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694137\n",
      "\tspeed: 0.0547s/iter; left time: 634.3788s\n",
      "\titers: 200, epoch: 8 | loss: 0.0775632\n",
      "\tspeed: 0.0202s/iter; left time: 232.1583s\n",
      "\titers: 300, epoch: 8 | loss: 0.0610222\n",
      "\tspeed: 0.0203s/iter; left time: 231.1031s\n",
      "\titers: 400, epoch: 8 | loss: 0.0720628\n",
      "\tspeed: 0.0126s/iter; left time: 142.0688s\n",
      "\titers: 500, epoch: 8 | loss: 0.0660339\n",
      "\tspeed: 0.0181s/iter; left time: 202.8611s\n",
      "\titers: 600, epoch: 8 | loss: 0.0646494\n",
      "\tspeed: 0.0195s/iter; left time: 216.0718s\n",
      "\titers: 700, epoch: 8 | loss: 0.0724894\n",
      "\tspeed: 0.0191s/iter; left time: 209.7862s\n",
      "\titers: 800, epoch: 8 | loss: 0.0708767\n",
      "\tspeed: 0.0181s/iter; left time: 196.6433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.89s\n",
      "Steps: 899 | Train Loss: 0.0716272 Vali Loss: 0.0862275 Test Loss: 0.0891104\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0682472\n",
      "\tspeed: 0.0573s/iter; left time: 612.4180s\n",
      "\titers: 200, epoch: 9 | loss: 0.0687185\n",
      "\tspeed: 0.0183s/iter; left time: 193.4582s\n",
      "\titers: 300, epoch: 9 | loss: 0.0675742\n",
      "\tspeed: 0.0180s/iter; left time: 188.5785s\n",
      "\titers: 400, epoch: 9 | loss: 0.0790244\n",
      "\tspeed: 0.0175s/iter; left time: 181.5086s\n",
      "\titers: 500, epoch: 9 | loss: 0.0742794\n",
      "\tspeed: 0.0181s/iter; left time: 186.1059s\n",
      "\titers: 600, epoch: 9 | loss: 0.0784170\n",
      "\tspeed: 0.0193s/iter; left time: 196.7434s\n",
      "\titers: 700, epoch: 9 | loss: 0.0661769\n",
      "\tspeed: 0.0188s/iter; left time: 189.6179s\n",
      "\titers: 800, epoch: 9 | loss: 0.0657198\n",
      "\tspeed: 0.0184s/iter; left time: 183.9181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 899 | Train Loss: 0.0710776 Vali Loss: 0.0859775 Test Loss: 0.0887144\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0718924\n",
      "\tspeed: 0.0623s/iter; left time: 609.5620s\n",
      "\titers: 200, epoch: 10 | loss: 0.0674917\n",
      "\tspeed: 0.0199s/iter; left time: 192.9195s\n",
      "\titers: 300, epoch: 10 | loss: 0.0667528\n",
      "\tspeed: 0.0188s/iter; left time: 180.5550s\n",
      "\titers: 400, epoch: 10 | loss: 0.0771219\n",
      "\tspeed: 0.0169s/iter; left time: 160.2434s\n",
      "\titers: 500, epoch: 10 | loss: 0.0680419\n",
      "\tspeed: 0.0171s/iter; left time: 160.3867s\n",
      "\titers: 600, epoch: 10 | loss: 0.0778542\n",
      "\tspeed: 0.0191s/iter; left time: 177.0863s\n",
      "\titers: 700, epoch: 10 | loss: 0.0683359\n",
      "\tspeed: 0.0192s/iter; left time: 176.7373s\n",
      "\titers: 800, epoch: 10 | loss: 0.0707038\n",
      "\tspeed: 0.0198s/iter; left time: 180.2252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 899 | Train Loss: 0.0707382 Vali Loss: 0.0856236 Test Loss: 0.0883160\n",
      "Validation loss decreased (0.085890 --> 0.085624).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0749262\n",
      "\tspeed: 0.0617s/iter; left time: 548.8022s\n",
      "\titers: 200, epoch: 11 | loss: 0.0701792\n",
      "\tspeed: 0.0195s/iter; left time: 171.1374s\n",
      "\titers: 300, epoch: 11 | loss: 0.0665850\n",
      "\tspeed: 0.0202s/iter; left time: 175.1901s\n",
      "\titers: 400, epoch: 11 | loss: 0.0675067\n",
      "\tspeed: 0.0200s/iter; left time: 172.0707s\n",
      "\titers: 500, epoch: 11 | loss: 0.0630933\n",
      "\tspeed: 0.0203s/iter; left time: 172.0048s\n",
      "\titers: 600, epoch: 11 | loss: 0.0624220\n",
      "\tspeed: 0.0199s/iter; left time: 167.1176s\n",
      "\titers: 700, epoch: 11 | loss: 0.0683502\n",
      "\tspeed: 0.0206s/iter; left time: 170.4606s\n",
      "\titers: 800, epoch: 11 | loss: 0.0688678\n",
      "\tspeed: 0.0199s/iter; left time: 162.8319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.27s\n",
      "Steps: 899 | Train Loss: 0.0703334 Vali Loss: 0.0857794 Test Loss: 0.0885536\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0698677\n",
      "\tspeed: 0.0641s/iter; left time: 512.1958s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719128\n",
      "\tspeed: 0.0194s/iter; left time: 153.1506s\n",
      "\titers: 300, epoch: 12 | loss: 0.0639158\n",
      "\tspeed: 0.0189s/iter; left time: 146.9174s\n",
      "\titers: 400, epoch: 12 | loss: 0.0611040\n",
      "\tspeed: 0.0172s/iter; left time: 132.4698s\n",
      "\titers: 500, epoch: 12 | loss: 0.0657806\n",
      "\tspeed: 0.0169s/iter; left time: 128.3179s\n",
      "\titers: 600, epoch: 12 | loss: 0.0800813\n",
      "\tspeed: 0.0170s/iter; left time: 127.1723s\n",
      "\titers: 700, epoch: 12 | loss: 0.0694001\n",
      "\tspeed: 0.0200s/iter; left time: 147.6694s\n",
      "\titers: 800, epoch: 12 | loss: 0.0699276\n",
      "\tspeed: 0.0179s/iter; left time: 130.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.00s\n",
      "Steps: 899 | Train Loss: 0.0700470 Vali Loss: 0.0854090 Test Loss: 0.0886136\n",
      "Validation loss decreased (0.085624 --> 0.085409).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0806684\n",
      "\tspeed: 0.0591s/iter; left time: 419.1547s\n",
      "\titers: 200, epoch: 13 | loss: 0.0621645\n",
      "\tspeed: 0.0163s/iter; left time: 114.2154s\n",
      "\titers: 300, epoch: 13 | loss: 0.0654562\n",
      "\tspeed: 0.0159s/iter; left time: 109.4330s\n",
      "\titers: 400, epoch: 13 | loss: 0.0668519\n",
      "\tspeed: 0.0183s/iter; left time: 124.5273s\n",
      "\titers: 500, epoch: 13 | loss: 0.0649320\n",
      "\tspeed: 0.0179s/iter; left time: 119.7639s\n",
      "\titers: 600, epoch: 13 | loss: 0.0633161\n",
      "\tspeed: 0.0187s/iter; left time: 123.2839s\n",
      "\titers: 700, epoch: 13 | loss: 0.0723601\n",
      "\tspeed: 0.0185s/iter; left time: 119.8201s\n",
      "\titers: 800, epoch: 13 | loss: 0.0700012\n",
      "\tspeed: 0.0189s/iter; left time: 120.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:16.18s\n",
      "Steps: 899 | Train Loss: 0.0697935 Vali Loss: 0.0851159 Test Loss: 0.0884142\n",
      "Validation loss decreased (0.085409 --> 0.085116).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0605425\n",
      "\tspeed: 0.0598s/iter; left time: 370.0972s\n",
      "\titers: 200, epoch: 14 | loss: 0.0737010\n",
      "\tspeed: 0.0195s/iter; left time: 118.9156s\n",
      "\titers: 300, epoch: 14 | loss: 0.0722969\n",
      "\tspeed: 0.0178s/iter; left time: 106.8622s\n",
      "\titers: 400, epoch: 14 | loss: 0.0671104\n",
      "\tspeed: 0.0167s/iter; left time: 98.5025s\n",
      "\titers: 500, epoch: 14 | loss: 0.0678294\n",
      "\tspeed: 0.0167s/iter; left time: 96.6353s\n",
      "\titers: 600, epoch: 14 | loss: 0.0695572\n",
      "\tspeed: 0.0159s/iter; left time: 90.3902s\n",
      "\titers: 700, epoch: 14 | loss: 0.0733814\n",
      "\tspeed: 0.0167s/iter; left time: 93.5412s\n",
      "\titers: 800, epoch: 14 | loss: 0.0617286\n",
      "\tspeed: 0.0165s/iter; left time: 90.6505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.70s\n",
      "Steps: 899 | Train Loss: 0.0694799 Vali Loss: 0.0852486 Test Loss: 0.0885301\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0786636\n",
      "\tspeed: 0.0610s/iter; left time: 323.2546s\n",
      "\titers: 200, epoch: 15 | loss: 0.0696910\n",
      "\tspeed: 0.0205s/iter; left time: 106.6113s\n",
      "\titers: 300, epoch: 15 | loss: 0.0758061\n",
      "\tspeed: 0.0198s/iter; left time: 100.8977s\n",
      "\titers: 400, epoch: 15 | loss: 0.0620856\n",
      "\tspeed: 0.0194s/iter; left time: 97.0008s\n",
      "\titers: 500, epoch: 15 | loss: 0.0759428\n",
      "\tspeed: 0.0198s/iter; left time: 96.7532s\n",
      "\titers: 600, epoch: 15 | loss: 0.0702283\n",
      "\tspeed: 0.0199s/iter; left time: 95.4999s\n",
      "\titers: 700, epoch: 15 | loss: 0.0677753\n",
      "\tspeed: 0.0202s/iter; left time: 94.8994s\n",
      "\titers: 800, epoch: 15 | loss: 0.0749781\n",
      "\tspeed: 0.0199s/iter; left time: 91.3626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 899 | Train Loss: 0.0693342 Vali Loss: 0.0851158 Test Loss: 0.0881972\n",
      "Validation loss decreased (0.085116 --> 0.085116).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692786\n",
      "\tspeed: 0.0640s/iter; left time: 281.2876s\n",
      "\titers: 200, epoch: 16 | loss: 0.0649260\n",
      "\tspeed: 0.0197s/iter; left time: 84.4977s\n",
      "\titers: 300, epoch: 16 | loss: 0.0722268\n",
      "\tspeed: 0.0195s/iter; left time: 81.7149s\n",
      "\titers: 400, epoch: 16 | loss: 0.0728802\n",
      "\tspeed: 0.0198s/iter; left time: 81.0383s\n",
      "\titers: 500, epoch: 16 | loss: 0.0594975\n",
      "\tspeed: 0.0199s/iter; left time: 79.6110s\n",
      "\titers: 600, epoch: 16 | loss: 0.0727794\n",
      "\tspeed: 0.0198s/iter; left time: 77.1572s\n",
      "\titers: 700, epoch: 16 | loss: 0.0756421\n",
      "\tspeed: 0.0195s/iter; left time: 73.8515s\n",
      "\titers: 800, epoch: 16 | loss: 0.0791641\n",
      "\tspeed: 0.0201s/iter; left time: 74.3403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.03s\n",
      "Steps: 899 | Train Loss: 0.0691109 Vali Loss: 0.0849670 Test Loss: 0.0881149\n",
      "Validation loss decreased (0.085116 --> 0.084967).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0663427\n",
      "\tspeed: 0.0646s/iter; left time: 226.0756s\n",
      "\titers: 200, epoch: 17 | loss: 0.0654110\n",
      "\tspeed: 0.0199s/iter; left time: 67.5694s\n",
      "\titers: 300, epoch: 17 | loss: 0.0751867\n",
      "\tspeed: 0.0198s/iter; left time: 65.1704s\n",
      "\titers: 400, epoch: 17 | loss: 0.0806298\n",
      "\tspeed: 0.0193s/iter; left time: 61.8369s\n",
      "\titers: 500, epoch: 17 | loss: 0.0749350\n",
      "\tspeed: 0.0203s/iter; left time: 62.8904s\n",
      "\titers: 600, epoch: 17 | loss: 0.0769133\n",
      "\tspeed: 0.0199s/iter; left time: 59.7397s\n",
      "\titers: 700, epoch: 17 | loss: 0.0700136\n",
      "\tspeed: 0.0200s/iter; left time: 57.9759s\n",
      "\titers: 800, epoch: 17 | loss: 0.0565658\n",
      "\tspeed: 0.0203s/iter; left time: 56.8297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 899 | Train Loss: 0.0688925 Vali Loss: 0.0848742 Test Loss: 0.0884414\n",
      "Validation loss decreased (0.084967 --> 0.084874).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0737057\n",
      "\tspeed: 0.0650s/iter; left time: 168.8870s\n",
      "\titers: 200, epoch: 18 | loss: 0.0740603\n",
      "\tspeed: 0.0197s/iter; left time: 49.1352s\n",
      "\titers: 300, epoch: 18 | loss: 0.0679640\n",
      "\tspeed: 0.0196s/iter; left time: 47.0511s\n",
      "\titers: 400, epoch: 18 | loss: 0.0828380\n",
      "\tspeed: 0.0196s/iter; left time: 44.9559s\n",
      "\titers: 500, epoch: 18 | loss: 0.0603770\n",
      "\tspeed: 0.0196s/iter; left time: 43.1708s\n",
      "\titers: 600, epoch: 18 | loss: 0.0733717\n",
      "\tspeed: 0.0196s/iter; left time: 41.0939s\n",
      "\titers: 700, epoch: 18 | loss: 0.0667348\n",
      "\tspeed: 0.0201s/iter; left time: 40.2037s\n",
      "\titers: 800, epoch: 18 | loss: 0.0707960\n",
      "\tspeed: 0.0199s/iter; left time: 37.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:18.07s\n",
      "Steps: 899 | Train Loss: 0.0687331 Vali Loss: 0.0850003 Test Loss: 0.0886662\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0701184\n",
      "\tspeed: 0.0631s/iter; left time: 107.1559s\n",
      "\titers: 200, epoch: 19 | loss: 0.0776851\n",
      "\tspeed: 0.0208s/iter; left time: 33.2722s\n",
      "\titers: 300, epoch: 19 | loss: 0.0674317\n",
      "\tspeed: 0.0096s/iter; left time: 14.4653s\n",
      "\titers: 400, epoch: 19 | loss: 0.0657173\n",
      "\tspeed: 0.0199s/iter; left time: 27.8775s\n",
      "\titers: 500, epoch: 19 | loss: 0.0635886\n",
      "\tspeed: 0.0193s/iter; left time: 25.1148s\n",
      "\titers: 600, epoch: 19 | loss: 0.0701072\n",
      "\tspeed: 0.0118s/iter; left time: 14.1759s\n",
      "\titers: 700, epoch: 19 | loss: 0.0608623\n",
      "\tspeed: 0.0156s/iter; left time: 17.1374s\n",
      "\titers: 800, epoch: 19 | loss: 0.0769143\n",
      "\tspeed: 0.0172s/iter; left time: 17.2317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.65s\n",
      "Steps: 899 | Train Loss: 0.0686018 Vali Loss: 0.0849541 Test Loss: 0.0884142\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0589864\n",
      "\tspeed: 0.0617s/iter; left time: 49.3829s\n",
      "\titers: 200, epoch: 20 | loss: 0.0615730\n",
      "\tspeed: 0.0177s/iter; left time: 12.3829s\n",
      "\titers: 300, epoch: 20 | loss: 0.0628639\n",
      "\tspeed: 0.0179s/iter; left time: 10.7164s\n",
      "\titers: 400, epoch: 20 | loss: 0.0715152\n",
      "\tspeed: 0.0172s/iter; left time: 8.6022s\n",
      "\titers: 500, epoch: 20 | loss: 0.0754993\n",
      "\tspeed: 0.0162s/iter; left time: 6.4849s\n",
      "\titers: 600, epoch: 20 | loss: 0.0634712\n",
      "\tspeed: 0.0164s/iter; left time: 4.9189s\n",
      "\titers: 700, epoch: 20 | loss: 0.0687074\n",
      "\tspeed: 0.0158s/iter; left time: 3.1603s\n",
      "\titers: 800, epoch: 20 | loss: 0.0659170\n",
      "\tspeed: 0.0172s/iter; left time: 1.7190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 899 | Train Loss: 0.0684520 Vali Loss: 0.0849311 Test Loss: 0.0882702\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021379102021455765, rmse:0.14621594548225403, mae:0.08844145387411118, rse:0.5163655877113342\n",
      "Original data scale mse:16319235.0, rmse:4039.707275390625, mae:2364.401123046875, rse:0.20086239278316498\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1624373\n",
      "\tspeed: 0.0396s/iter; left time: 707.3738s\n",
      "\titers: 200, epoch: 1 | loss: 0.1495584\n",
      "\tspeed: 0.0102s/iter; left time: 181.5060s\n",
      "\titers: 300, epoch: 1 | loss: 0.1414191\n",
      "\tspeed: 0.0101s/iter; left time: 178.8080s\n",
      "\titers: 400, epoch: 1 | loss: 0.1321810\n",
      "\tspeed: 0.0102s/iter; left time: 178.5006s\n",
      "\titers: 500, epoch: 1 | loss: 0.1338673\n",
      "\tspeed: 0.0102s/iter; left time: 177.5125s\n",
      "\titers: 600, epoch: 1 | loss: 0.1378949\n",
      "\tspeed: 0.0146s/iter; left time: 252.3585s\n",
      "\titers: 700, epoch: 1 | loss: 0.1337112\n",
      "\tspeed: 0.0153s/iter; left time: 264.5455s\n",
      "\titers: 800, epoch: 1 | loss: 0.1365577\n",
      "\tspeed: 0.0172s/iter; left time: 295.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 897 | Train Loss: 0.1394758 Vali Loss: 0.1337583 Test Loss: 0.1404198\n",
      "Validation loss decreased (inf --> 0.133758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1079771\n",
      "\tspeed: 0.0502s/iter; left time: 851.3076s\n",
      "\titers: 200, epoch: 2 | loss: 0.1055217\n",
      "\tspeed: 0.0199s/iter; left time: 335.7710s\n",
      "\titers: 300, epoch: 2 | loss: 0.0919300\n",
      "\tspeed: 0.0179s/iter; left time: 299.4616s\n",
      "\titers: 400, epoch: 2 | loss: 0.1027721\n",
      "\tspeed: 0.0175s/iter; left time: 290.8931s\n",
      "\titers: 500, epoch: 2 | loss: 0.1014314\n",
      "\tspeed: 0.0149s/iter; left time: 246.6639s\n",
      "\titers: 600, epoch: 2 | loss: 0.1017559\n",
      "\tspeed: 0.0161s/iter; left time: 264.9487s\n",
      "\titers: 700, epoch: 2 | loss: 0.0990915\n",
      "\tspeed: 0.0157s/iter; left time: 257.3339s\n",
      "\titers: 800, epoch: 2 | loss: 0.1187553\n",
      "\tspeed: 0.0167s/iter; left time: 270.8755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.28s\n",
      "Steps: 897 | Train Loss: 0.1096793 Vali Loss: 0.1188789 Test Loss: 0.1278648\n",
      "Validation loss decreased (0.133758 --> 0.118879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1014483\n",
      "\tspeed: 0.0557s/iter; left time: 894.0521s\n",
      "\titers: 200, epoch: 3 | loss: 0.1129514\n",
      "\tspeed: 0.0182s/iter; left time: 289.8696s\n",
      "\titers: 300, epoch: 3 | loss: 0.1025537\n",
      "\tspeed: 0.0198s/iter; left time: 313.6412s\n",
      "\titers: 400, epoch: 3 | loss: 0.1085270\n",
      "\tspeed: 0.0193s/iter; left time: 303.9045s\n",
      "\titers: 500, epoch: 3 | loss: 0.0925697\n",
      "\tspeed: 0.0166s/iter; left time: 260.4741s\n",
      "\titers: 600, epoch: 3 | loss: 0.1004613\n",
      "\tspeed: 0.0159s/iter; left time: 246.5961s\n",
      "\titers: 700, epoch: 3 | loss: 0.1009231\n",
      "\tspeed: 0.0180s/iter; left time: 278.3974s\n",
      "\titers: 800, epoch: 3 | loss: 0.0977693\n",
      "\tspeed: 0.0176s/iter; left time: 270.6701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:16.00s\n",
      "Steps: 897 | Train Loss: 0.1044511 Vali Loss: 0.1180299 Test Loss: 0.1283112\n",
      "Validation loss decreased (0.118879 --> 0.118030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0999790\n",
      "\tspeed: 0.0570s/iter; left time: 863.1290s\n",
      "\titers: 200, epoch: 4 | loss: 0.1037364\n",
      "\tspeed: 0.0194s/iter; left time: 292.2912s\n",
      "\titers: 300, epoch: 4 | loss: 0.1129832\n",
      "\tspeed: 0.0190s/iter; left time: 284.6738s\n",
      "\titers: 400, epoch: 4 | loss: 0.0895463\n",
      "\tspeed: 0.0200s/iter; left time: 297.7183s\n",
      "\titers: 500, epoch: 4 | loss: 0.0946499\n",
      "\tspeed: 0.0193s/iter; left time: 284.9370s\n",
      "\titers: 600, epoch: 4 | loss: 0.1047741\n",
      "\tspeed: 0.0198s/iter; left time: 290.1955s\n",
      "\titers: 700, epoch: 4 | loss: 0.1182179\n",
      "\tspeed: 0.0188s/iter; left time: 273.6328s\n",
      "\titers: 800, epoch: 4 | loss: 0.0951526\n",
      "\tspeed: 0.0191s/iter; left time: 275.7195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:17.32s\n",
      "Steps: 897 | Train Loss: 0.1025502 Vali Loss: 0.1178503 Test Loss: 0.1271106\n",
      "Validation loss decreased (0.118030 --> 0.117850).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0934159\n",
      "\tspeed: 0.0614s/iter; left time: 874.4490s\n",
      "\titers: 200, epoch: 5 | loss: 0.1031000\n",
      "\tspeed: 0.0174s/iter; left time: 246.5926s\n",
      "\titers: 300, epoch: 5 | loss: 0.1011724\n",
      "\tspeed: 0.0194s/iter; left time: 273.0393s\n",
      "\titers: 400, epoch: 5 | loss: 0.0967638\n",
      "\tspeed: 0.0198s/iter; left time: 276.5609s\n",
      "\titers: 500, epoch: 5 | loss: 0.1014039\n",
      "\tspeed: 0.0185s/iter; left time: 255.7325s\n",
      "\titers: 600, epoch: 5 | loss: 0.1004380\n",
      "\tspeed: 0.0169s/iter; left time: 232.2317s\n",
      "\titers: 700, epoch: 5 | loss: 0.1076094\n",
      "\tspeed: 0.0185s/iter; left time: 252.6232s\n",
      "\titers: 800, epoch: 5 | loss: 0.1145029\n",
      "\tspeed: 0.0177s/iter; left time: 239.5187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.84s\n",
      "Steps: 897 | Train Loss: 0.1006376 Vali Loss: 0.1185626 Test Loss: 0.1277468\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1009128\n",
      "\tspeed: 0.0635s/iter; left time: 848.1548s\n",
      "\titers: 200, epoch: 6 | loss: 0.0982019\n",
      "\tspeed: 0.0223s/iter; left time: 295.4496s\n",
      "\titers: 300, epoch: 6 | loss: 0.0977693\n",
      "\tspeed: 0.0184s/iter; left time: 242.2940s\n",
      "\titers: 400, epoch: 6 | loss: 0.0989243\n",
      "\tspeed: 0.0173s/iter; left time: 225.8126s\n",
      "\titers: 500, epoch: 6 | loss: 0.1068044\n",
      "\tspeed: 0.0204s/iter; left time: 263.6648s\n",
      "\titers: 600, epoch: 6 | loss: 0.0854930\n",
      "\tspeed: 0.0199s/iter; left time: 255.3115s\n",
      "\titers: 700, epoch: 6 | loss: 0.1021510\n",
      "\tspeed: 0.0193s/iter; left time: 246.0939s\n",
      "\titers: 800, epoch: 6 | loss: 0.0982522\n",
      "\tspeed: 0.0194s/iter; left time: 245.5837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:17.85s\n",
      "Steps: 897 | Train Loss: 0.0989243 Vali Loss: 0.1187071 Test Loss: 0.1288469\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0990655\n",
      "\tspeed: 0.0616s/iter; left time: 767.3870s\n",
      "\titers: 200, epoch: 7 | loss: 0.0888730\n",
      "\tspeed: 0.0192s/iter; left time: 236.9249s\n",
      "\titers: 300, epoch: 7 | loss: 0.1046220\n",
      "\tspeed: 0.0203s/iter; left time: 248.2934s\n",
      "\titers: 400, epoch: 7 | loss: 0.0893665\n",
      "\tspeed: 0.0208s/iter; left time: 252.6911s\n",
      "\titers: 500, epoch: 7 | loss: 0.0978014\n",
      "\tspeed: 0.0194s/iter; left time: 234.5144s\n",
      "\titers: 600, epoch: 7 | loss: 0.0948966\n",
      "\tspeed: 0.0198s/iter; left time: 237.2108s\n",
      "\titers: 700, epoch: 7 | loss: 0.0951869\n",
      "\tspeed: 0.0201s/iter; left time: 238.4768s\n",
      "\titers: 800, epoch: 7 | loss: 0.0926890\n",
      "\tspeed: 0.0212s/iter; left time: 249.6423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.42s\n",
      "Steps: 897 | Train Loss: 0.0971943 Vali Loss: 0.1188075 Test Loss: 0.1284872\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1010363\n",
      "\tspeed: 0.0617s/iter; left time: 713.3129s\n",
      "\titers: 200, epoch: 8 | loss: 0.0927735\n",
      "\tspeed: 0.0107s/iter; left time: 122.3500s\n",
      "\titers: 300, epoch: 8 | loss: 0.0935527\n",
      "\tspeed: 0.0121s/iter; left time: 136.9755s\n",
      "\titers: 400, epoch: 8 | loss: 0.0914038\n",
      "\tspeed: 0.0179s/iter; left time: 201.6591s\n",
      "\titers: 500, epoch: 8 | loss: 0.0963805\n",
      "\tspeed: 0.0187s/iter; left time: 208.6342s\n",
      "\titers: 600, epoch: 8 | loss: 0.0847994\n",
      "\tspeed: 0.0175s/iter; left time: 193.1620s\n",
      "\titers: 700, epoch: 8 | loss: 0.1009729\n",
      "\tspeed: 0.0191s/iter; left time: 209.4652s\n",
      "\titers: 800, epoch: 8 | loss: 0.0938417\n",
      "\tspeed: 0.0170s/iter; left time: 184.8649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:14.75s\n",
      "Steps: 897 | Train Loss: 0.0956007 Vali Loss: 0.1189903 Test Loss: 0.1296951\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1050703\n",
      "\tspeed: 0.0592s/iter; left time: 630.9980s\n",
      "\titers: 200, epoch: 9 | loss: 0.1012625\n",
      "\tspeed: 0.0197s/iter; left time: 208.1609s\n",
      "\titers: 300, epoch: 9 | loss: 0.1016364\n",
      "\tspeed: 0.0178s/iter; left time: 186.3783s\n",
      "\titers: 400, epoch: 9 | loss: 0.0936815\n",
      "\tspeed: 0.0161s/iter; left time: 166.9852s\n",
      "\titers: 500, epoch: 9 | loss: 0.0934360\n",
      "\tspeed: 0.0160s/iter; left time: 164.2347s\n",
      "\titers: 600, epoch: 9 | loss: 0.1066008\n",
      "\tspeed: 0.0164s/iter; left time: 167.0259s\n",
      "\titers: 700, epoch: 9 | loss: 0.1040160\n",
      "\tspeed: 0.0164s/iter; left time: 164.6591s\n",
      "\titers: 800, epoch: 9 | loss: 0.0854952\n",
      "\tspeed: 0.0164s/iter; left time: 163.5566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 897 | Train Loss: 0.0943813 Vali Loss: 0.1196732 Test Loss: 0.1299682\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03700297698378563, rmse:0.19236157834529877, mae:0.1271105706691742, rse:0.6811912655830383\n",
      "Original data scale mse:31829424.0, rmse:5641.75732421875, mae:3474.244140625, rse:0.2809615433216095\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1684518\n",
      "\tspeed: 0.0212s/iter; left time: 377.9746s\n",
      "\titers: 200, epoch: 1 | loss: 0.1397480\n",
      "\tspeed: 0.0196s/iter; left time: 348.4230s\n",
      "\titers: 300, epoch: 1 | loss: 0.1398443\n",
      "\tspeed: 0.0195s/iter; left time: 343.8879s\n",
      "\titers: 400, epoch: 1 | loss: 0.1379159\n",
      "\tspeed: 0.0185s/iter; left time: 324.3159s\n",
      "\titers: 500, epoch: 1 | loss: 0.1406273\n",
      "\tspeed: 0.0169s/iter; left time: 294.0941s\n",
      "\titers: 600, epoch: 1 | loss: 0.1272685\n",
      "\tspeed: 0.0193s/iter; left time: 334.2063s\n",
      "\titers: 700, epoch: 1 | loss: 0.1231053\n",
      "\tspeed: 0.0203s/iter; left time: 349.8855s\n",
      "\titers: 800, epoch: 1 | loss: 0.1284896\n",
      "\tspeed: 0.0203s/iter; left time: 348.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:17.60s\n",
      "Steps: 897 | Train Loss: 0.1392744 Vali Loss: 0.1339747 Test Loss: 0.1404881\n",
      "Validation loss decreased (inf --> 0.133975).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1230945\n",
      "\tspeed: 0.0645s/iter; left time: 1092.8817s\n",
      "\titers: 200, epoch: 2 | loss: 0.1039227\n",
      "\tspeed: 0.0221s/iter; left time: 371.9695s\n",
      "\titers: 300, epoch: 2 | loss: 0.1086058\n",
      "\tspeed: 0.0184s/iter; left time: 307.3034s\n",
      "\titers: 400, epoch: 2 | loss: 0.1001232\n",
      "\tspeed: 0.0178s/iter; left time: 295.8985s\n",
      "\titers: 500, epoch: 2 | loss: 0.0954005\n",
      "\tspeed: 0.0212s/iter; left time: 350.0505s\n",
      "\titers: 600, epoch: 2 | loss: 0.1100541\n",
      "\tspeed: 0.0204s/iter; left time: 335.7666s\n",
      "\titers: 700, epoch: 2 | loss: 0.1061610\n",
      "\tspeed: 0.0215s/iter; left time: 351.4542s\n",
      "\titers: 800, epoch: 2 | loss: 0.1079476\n",
      "\tspeed: 0.0209s/iter; left time: 339.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.17s\n",
      "Steps: 897 | Train Loss: 0.1095564 Vali Loss: 0.1197646 Test Loss: 0.1285753\n",
      "Validation loss decreased (0.133975 --> 0.119765).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1020490\n",
      "\tspeed: 0.0629s/iter; left time: 1008.6158s\n",
      "\titers: 200, epoch: 3 | loss: 0.1014096\n",
      "\tspeed: 0.0220s/iter; left time: 350.2040s\n",
      "\titers: 300, epoch: 3 | loss: 0.1149631\n",
      "\tspeed: 0.0224s/iter; left time: 355.0044s\n",
      "\titers: 400, epoch: 3 | loss: 0.1045849\n",
      "\tspeed: 0.0196s/iter; left time: 308.4910s\n",
      "\titers: 500, epoch: 3 | loss: 0.1030072\n",
      "\tspeed: 0.0191s/iter; left time: 298.6764s\n",
      "\titers: 600, epoch: 3 | loss: 0.1060789\n",
      "\tspeed: 0.0190s/iter; left time: 295.6469s\n",
      "\titers: 700, epoch: 3 | loss: 0.1022111\n",
      "\tspeed: 0.0192s/iter; left time: 296.0067s\n",
      "\titers: 800, epoch: 3 | loss: 0.1164054\n",
      "\tspeed: 0.0175s/iter; left time: 268.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:17.86s\n",
      "Steps: 897 | Train Loss: 0.1043068 Vali Loss: 0.1179735 Test Loss: 0.1279643\n",
      "Validation loss decreased (0.119765 --> 0.117973).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1020686\n",
      "\tspeed: 0.0590s/iter; left time: 893.5151s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097809\n",
      "\tspeed: 0.0171s/iter; left time: 256.8734s\n",
      "\titers: 300, epoch: 4 | loss: 0.0998711\n",
      "\tspeed: 0.0164s/iter; left time: 245.4938s\n",
      "\titers: 400, epoch: 4 | loss: 0.0942199\n",
      "\tspeed: 0.0218s/iter; left time: 323.8911s\n",
      "\titers: 500, epoch: 4 | loss: 0.0938553\n",
      "\tspeed: 0.0211s/iter; left time: 310.5351s\n",
      "\titers: 600, epoch: 4 | loss: 0.1069582\n",
      "\tspeed: 0.0215s/iter; left time: 315.0421s\n",
      "\titers: 700, epoch: 4 | loss: 0.1025306\n",
      "\tspeed: 0.0227s/iter; left time: 330.9662s\n",
      "\titers: 800, epoch: 4 | loss: 0.1181513\n",
      "\tspeed: 0.0212s/iter; left time: 306.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.22s\n",
      "Steps: 897 | Train Loss: 0.1023561 Vali Loss: 0.1179995 Test Loss: 0.1273383\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0977717\n",
      "\tspeed: 0.0619s/iter; left time: 881.7423s\n",
      "\titers: 200, epoch: 5 | loss: 0.0957746\n",
      "\tspeed: 0.0174s/iter; left time: 246.7964s\n",
      "\titers: 300, epoch: 5 | loss: 0.0955755\n",
      "\tspeed: 0.0165s/iter; left time: 232.4191s\n",
      "\titers: 400, epoch: 5 | loss: 0.1082682\n",
      "\tspeed: 0.0171s/iter; left time: 238.7784s\n",
      "\titers: 500, epoch: 5 | loss: 0.1029422\n",
      "\tspeed: 0.0184s/iter; left time: 254.9887s\n",
      "\titers: 600, epoch: 5 | loss: 0.0985259\n",
      "\tspeed: 0.0192s/iter; left time: 263.8257s\n",
      "\titers: 700, epoch: 5 | loss: 0.1053031\n",
      "\tspeed: 0.0199s/iter; left time: 271.2094s\n",
      "\titers: 800, epoch: 5 | loss: 0.1089401\n",
      "\tspeed: 0.0195s/iter; left time: 264.5854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.52s\n",
      "Steps: 897 | Train Loss: 0.1004667 Vali Loss: 0.1196466 Test Loss: 0.1285089\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0988021\n",
      "\tspeed: 0.0577s/iter; left time: 770.9924s\n",
      "\titers: 200, epoch: 6 | loss: 0.1051256\n",
      "\tspeed: 0.0169s/iter; left time: 223.8091s\n",
      "\titers: 300, epoch: 6 | loss: 0.1016301\n",
      "\tspeed: 0.0193s/iter; left time: 254.1807s\n",
      "\titers: 400, epoch: 6 | loss: 0.0993770\n",
      "\tspeed: 0.0179s/iter; left time: 234.3336s\n",
      "\titers: 500, epoch: 6 | loss: 0.1046961\n",
      "\tspeed: 0.0160s/iter; left time: 207.5400s\n",
      "\titers: 600, epoch: 6 | loss: 0.0944948\n",
      "\tspeed: 0.0166s/iter; left time: 213.1044s\n",
      "\titers: 700, epoch: 6 | loss: 0.1005476\n",
      "\tspeed: 0.0154s/iter; left time: 196.4749s\n",
      "\titers: 800, epoch: 6 | loss: 0.0968493\n",
      "\tspeed: 0.0164s/iter; left time: 208.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 897 | Train Loss: 0.0986084 Vali Loss: 0.1197372 Test Loss: 0.1288851\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0977516\n",
      "\tspeed: 0.0631s/iter; left time: 786.3038s\n",
      "\titers: 200, epoch: 7 | loss: 0.1090908\n",
      "\tspeed: 0.0208s/iter; left time: 257.3447s\n",
      "\titers: 300, epoch: 7 | loss: 0.0941811\n",
      "\tspeed: 0.0235s/iter; left time: 287.5507s\n",
      "\titers: 400, epoch: 7 | loss: 0.0969901\n",
      "\tspeed: 0.0238s/iter; left time: 289.9061s\n",
      "\titers: 500, epoch: 7 | loss: 0.0880445\n",
      "\tspeed: 0.0198s/iter; left time: 238.2841s\n",
      "\titers: 600, epoch: 7 | loss: 0.0978840\n",
      "\tspeed: 0.0111s/iter; left time: 132.1767s\n",
      "\titers: 700, epoch: 7 | loss: 0.0935492\n",
      "\tspeed: 0.0110s/iter; left time: 130.6608s\n",
      "\titers: 800, epoch: 7 | loss: 0.0979174\n",
      "\tspeed: 0.0108s/iter; left time: 127.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.24s\n",
      "Steps: 897 | Train Loss: 0.0968090 Vali Loss: 0.1197181 Test Loss: 0.1298983\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0893549\n",
      "\tspeed: 0.0584s/iter; left time: 675.6319s\n",
      "\titers: 200, epoch: 8 | loss: 0.0883367\n",
      "\tspeed: 0.0185s/iter; left time: 212.2948s\n",
      "\titers: 300, epoch: 8 | loss: 0.0928142\n",
      "\tspeed: 0.0195s/iter; left time: 221.5419s\n",
      "\titers: 400, epoch: 8 | loss: 0.1002690\n",
      "\tspeed: 0.0198s/iter; left time: 223.4745s\n",
      "\titers: 500, epoch: 8 | loss: 0.0909080\n",
      "\tspeed: 0.0192s/iter; left time: 214.1859s\n",
      "\titers: 600, epoch: 8 | loss: 0.0974930\n",
      "\tspeed: 0.0170s/iter; left time: 187.5883s\n",
      "\titers: 700, epoch: 8 | loss: 0.0905802\n",
      "\tspeed: 0.0179s/iter; left time: 196.7461s\n",
      "\titers: 800, epoch: 8 | loss: 0.0839966\n",
      "\tspeed: 0.0205s/iter; left time: 222.2431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:17.31s\n",
      "Steps: 897 | Train Loss: 0.0951614 Vali Loss: 0.1198636 Test Loss: 0.1299840\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03724890947341919, rmse:0.19299976527690887, mae:0.12796425819396973, rse:0.6834511756896973\n",
      "Original data scale mse:32093164.0, rmse:5665.0830078125, mae:3500.149658203125, rse:0.2821231484413147\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1732848\n",
      "\tspeed: 0.0451s/iter; left time: 801.9775s\n",
      "\titers: 200, epoch: 1 | loss: 0.1419301\n",
      "\tspeed: 0.0174s/iter; left time: 307.8608s\n",
      "\titers: 300, epoch: 1 | loss: 0.1402960\n",
      "\tspeed: 0.0158s/iter; left time: 278.4595s\n",
      "\titers: 400, epoch: 1 | loss: 0.1369116\n",
      "\tspeed: 0.0168s/iter; left time: 293.5981s\n",
      "\titers: 500, epoch: 1 | loss: 0.1461538\n",
      "\tspeed: 0.0165s/iter; left time: 285.9357s\n",
      "\titers: 600, epoch: 1 | loss: 0.1394300\n",
      "\tspeed: 0.0175s/iter; left time: 302.5870s\n",
      "\titers: 700, epoch: 1 | loss: 0.1345970\n",
      "\tspeed: 0.0201s/iter; left time: 345.8201s\n",
      "\titers: 800, epoch: 1 | loss: 0.1295278\n",
      "\tspeed: 0.0180s/iter; left time: 308.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.36s\n",
      "Steps: 894 | Train Loss: 0.1427015 Vali Loss: 0.1374301 Test Loss: 0.1455456\n",
      "Validation loss decreased (inf --> 0.137430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1215639\n",
      "\tspeed: 0.0657s/iter; left time: 1109.9193s\n",
      "\titers: 200, epoch: 2 | loss: 0.1363863\n",
      "\tspeed: 0.0200s/iter; left time: 335.4811s\n",
      "\titers: 300, epoch: 2 | loss: 0.1086964\n",
      "\tspeed: 0.0225s/iter; left time: 374.8717s\n",
      "\titers: 400, epoch: 2 | loss: 0.1399455\n",
      "\tspeed: 0.0252s/iter; left time: 417.9952s\n",
      "\titers: 500, epoch: 2 | loss: 0.1136179\n",
      "\tspeed: 0.0208s/iter; left time: 342.8196s\n",
      "\titers: 600, epoch: 2 | loss: 0.1180402\n",
      "\tspeed: 0.0200s/iter; left time: 327.7326s\n",
      "\titers: 700, epoch: 2 | loss: 0.1263573\n",
      "\tspeed: 0.0200s/iter; left time: 325.1913s\n",
      "\titers: 800, epoch: 2 | loss: 0.1093086\n",
      "\tspeed: 0.0200s/iter; left time: 323.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 894 | Train Loss: 0.1156173 Vali Loss: 0.1250059 Test Loss: 0.1365682\n",
      "Validation loss decreased (0.137430 --> 0.125006).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1140615\n",
      "\tspeed: 0.0656s/iter; left time: 1049.7106s\n",
      "\titers: 200, epoch: 3 | loss: 0.1057609\n",
      "\tspeed: 0.0202s/iter; left time: 320.7616s\n",
      "\titers: 300, epoch: 3 | loss: 0.0982953\n",
      "\tspeed: 0.0195s/iter; left time: 307.8685s\n",
      "\titers: 400, epoch: 3 | loss: 0.1137326\n",
      "\tspeed: 0.0202s/iter; left time: 316.4581s\n",
      "\titers: 500, epoch: 3 | loss: 0.1132094\n",
      "\tspeed: 0.0202s/iter; left time: 314.4999s\n",
      "\titers: 600, epoch: 3 | loss: 0.1121700\n",
      "\tspeed: 0.0205s/iter; left time: 318.3690s\n",
      "\titers: 700, epoch: 3 | loss: 0.1112360\n",
      "\tspeed: 0.0216s/iter; left time: 332.5048s\n",
      "\titers: 800, epoch: 3 | loss: 0.1110158\n",
      "\tspeed: 0.0208s/iter; left time: 317.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.47s\n",
      "Steps: 894 | Train Loss: 0.1101006 Vali Loss: 0.1233593 Test Loss: 0.1349155\n",
      "Validation loss decreased (0.125006 --> 0.123359).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1013669\n",
      "\tspeed: 0.0619s/iter; left time: 934.0154s\n",
      "\titers: 200, epoch: 4 | loss: 0.0969161\n",
      "\tspeed: 0.0203s/iter; left time: 303.7678s\n",
      "\titers: 300, epoch: 4 | loss: 0.1126773\n",
      "\tspeed: 0.0203s/iter; left time: 302.9170s\n",
      "\titers: 400, epoch: 4 | loss: 0.0994314\n",
      "\tspeed: 0.0202s/iter; left time: 298.8815s\n",
      "\titers: 500, epoch: 4 | loss: 0.1087467\n",
      "\tspeed: 0.0205s/iter; left time: 301.4169s\n",
      "\titers: 600, epoch: 4 | loss: 0.0992603\n",
      "\tspeed: 0.0200s/iter; left time: 291.5732s\n",
      "\titers: 700, epoch: 4 | loss: 0.1041176\n",
      "\tspeed: 0.0211s/iter; left time: 305.7308s\n",
      "\titers: 800, epoch: 4 | loss: 0.1049955\n",
      "\tspeed: 0.0204s/iter; left time: 293.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.44s\n",
      "Steps: 894 | Train Loss: 0.1077172 Vali Loss: 0.1242746 Test Loss: 0.1361853\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029469\n",
      "\tspeed: 0.0635s/iter; left time: 902.3419s\n",
      "\titers: 200, epoch: 5 | loss: 0.0987288\n",
      "\tspeed: 0.0204s/iter; left time: 287.3707s\n",
      "\titers: 300, epoch: 5 | loss: 0.1077937\n",
      "\tspeed: 0.0212s/iter; left time: 297.2865s\n",
      "\titers: 400, epoch: 5 | loss: 0.1087716\n",
      "\tspeed: 0.0240s/iter; left time: 333.4037s\n",
      "\titers: 500, epoch: 5 | loss: 0.1120908\n",
      "\tspeed: 0.0241s/iter; left time: 333.0942s\n",
      "\titers: 600, epoch: 5 | loss: 0.1078796\n",
      "\tspeed: 0.0208s/iter; left time: 285.1775s\n",
      "\titers: 700, epoch: 5 | loss: 0.1130117\n",
      "\tspeed: 0.0201s/iter; left time: 273.9154s\n",
      "\titers: 800, epoch: 5 | loss: 0.0986416\n",
      "\tspeed: 0.0176s/iter; left time: 238.3391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:18.79s\n",
      "Steps: 894 | Train Loss: 0.1053120 Vali Loss: 0.1245870 Test Loss: 0.1364750\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1125292\n",
      "\tspeed: 0.0600s/iter; left time: 798.9357s\n",
      "\titers: 200, epoch: 6 | loss: 0.1047987\n",
      "\tspeed: 0.0206s/iter; left time: 272.1175s\n",
      "\titers: 300, epoch: 6 | loss: 0.1046208\n",
      "\tspeed: 0.0201s/iter; left time: 262.9204s\n",
      "\titers: 400, epoch: 6 | loss: 0.0988005\n",
      "\tspeed: 0.0205s/iter; left time: 266.7291s\n",
      "\titers: 500, epoch: 6 | loss: 0.1013660\n",
      "\tspeed: 0.0197s/iter; left time: 254.7255s\n",
      "\titers: 600, epoch: 6 | loss: 0.0980055\n",
      "\tspeed: 0.0202s/iter; left time: 258.1693s\n",
      "\titers: 700, epoch: 6 | loss: 0.1137770\n",
      "\tspeed: 0.0200s/iter; left time: 254.2422s\n",
      "\titers: 800, epoch: 6 | loss: 0.0959709\n",
      "\tspeed: 0.0199s/iter; left time: 251.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.20s\n",
      "Steps: 894 | Train Loss: 0.1031840 Vali Loss: 0.1252124 Test Loss: 0.1371029\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1161828\n",
      "\tspeed: 0.0631s/iter; left time: 783.4942s\n",
      "\titers: 200, epoch: 7 | loss: 0.1003138\n",
      "\tspeed: 0.0217s/iter; left time: 266.6799s\n",
      "\titers: 300, epoch: 7 | loss: 0.1006321\n",
      "\tspeed: 0.0224s/iter; left time: 273.1012s\n",
      "\titers: 400, epoch: 7 | loss: 0.1000796\n",
      "\tspeed: 0.0193s/iter; left time: 234.2698s\n",
      "\titers: 500, epoch: 7 | loss: 0.0951050\n",
      "\tspeed: 0.0196s/iter; left time: 234.9370s\n",
      "\titers: 600, epoch: 7 | loss: 0.1077745\n",
      "\tspeed: 0.0229s/iter; left time: 272.8934s\n",
      "\titers: 700, epoch: 7 | loss: 0.0923458\n",
      "\tspeed: 0.0203s/iter; left time: 239.9153s\n",
      "\titers: 800, epoch: 7 | loss: 0.1010812\n",
      "\tspeed: 0.0200s/iter; left time: 234.2335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.85s\n",
      "Steps: 894 | Train Loss: 0.1012665 Vali Loss: 0.1262887 Test Loss: 0.1381352\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0989093\n",
      "\tspeed: 0.0652s/iter; left time: 751.7483s\n",
      "\titers: 200, epoch: 8 | loss: 0.0991450\n",
      "\tspeed: 0.0235s/iter; left time: 268.9118s\n",
      "\titers: 300, epoch: 8 | loss: 0.1052031\n",
      "\tspeed: 0.0210s/iter; left time: 237.7784s\n",
      "\titers: 400, epoch: 8 | loss: 0.0984328\n",
      "\tspeed: 0.0205s/iter; left time: 229.8076s\n",
      "\titers: 500, epoch: 8 | loss: 0.0925399\n",
      "\tspeed: 0.0198s/iter; left time: 219.8453s\n",
      "\titers: 600, epoch: 8 | loss: 0.0995884\n",
      "\tspeed: 0.0201s/iter; left time: 221.6655s\n",
      "\titers: 700, epoch: 8 | loss: 0.1049649\n",
      "\tspeed: 0.0202s/iter; left time: 220.8703s\n",
      "\titers: 800, epoch: 8 | loss: 0.1010569\n",
      "\tspeed: 0.0203s/iter; left time: 219.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.81s\n",
      "Steps: 894 | Train Loss: 0.0997548 Vali Loss: 0.1269251 Test Loss: 0.1386151\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039616893976926804, rmse:0.19903993606567383, mae:0.13491539657115936, rse:0.7051385641098022\n",
      "Original data scale mse:34746828.0, rmse:5894.64404296875, mae:3705.5087890625, rse:0.2936994731426239\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1578886\n",
      "\tspeed: 0.0226s/iter; left time: 402.4009s\n",
      "\titers: 200, epoch: 1 | loss: 0.1484953\n",
      "\tspeed: 0.0201s/iter; left time: 355.2342s\n",
      "\titers: 300, epoch: 1 | loss: 0.1381736\n",
      "\tspeed: 0.0221s/iter; left time: 388.2731s\n",
      "\titers: 400, epoch: 1 | loss: 0.1408224\n",
      "\tspeed: 0.0240s/iter; left time: 419.5573s\n",
      "\titers: 500, epoch: 1 | loss: 0.1312700\n",
      "\tspeed: 0.0244s/iter; left time: 423.5345s\n",
      "\titers: 600, epoch: 1 | loss: 0.1284460\n",
      "\tspeed: 0.0240s/iter; left time: 414.9779s\n",
      "\titers: 700, epoch: 1 | loss: 0.1301628\n",
      "\tspeed: 0.0218s/iter; left time: 374.4957s\n",
      "\titers: 800, epoch: 1 | loss: 0.1319579\n",
      "\tspeed: 0.0225s/iter; left time: 384.2404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:20.11s\n",
      "Steps: 894 | Train Loss: 0.1424819 Vali Loss: 0.1376038 Test Loss: 0.1455242\n",
      "Validation loss decreased (inf --> 0.137604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1222153\n",
      "\tspeed: 0.0638s/iter; left time: 1077.5932s\n",
      "\titers: 200, epoch: 2 | loss: 0.1185519\n",
      "\tspeed: 0.0195s/iter; left time: 326.7497s\n",
      "\titers: 300, epoch: 2 | loss: 0.1126062\n",
      "\tspeed: 0.0207s/iter; left time: 344.9904s\n",
      "\titers: 400, epoch: 2 | loss: 0.1103911\n",
      "\tspeed: 0.0205s/iter; left time: 339.3614s\n",
      "\titers: 500, epoch: 2 | loss: 0.1181933\n",
      "\tspeed: 0.0202s/iter; left time: 332.6096s\n",
      "\titers: 600, epoch: 2 | loss: 0.1099948\n",
      "\tspeed: 0.0202s/iter; left time: 331.1001s\n",
      "\titers: 700, epoch: 2 | loss: 0.1016928\n",
      "\tspeed: 0.0203s/iter; left time: 331.0942s\n",
      "\titers: 800, epoch: 2 | loss: 0.1255443\n",
      "\tspeed: 0.0207s/iter; left time: 334.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:18.49s\n",
      "Steps: 894 | Train Loss: 0.1155752 Vali Loss: 0.1240289 Test Loss: 0.1353690\n",
      "Validation loss decreased (0.137604 --> 0.124029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1152651\n",
      "\tspeed: 0.0647s/iter; left time: 1034.5332s\n",
      "\titers: 200, epoch: 3 | loss: 0.1151162\n",
      "\tspeed: 0.0203s/iter; left time: 322.1988s\n",
      "\titers: 300, epoch: 3 | loss: 0.1114071\n",
      "\tspeed: 0.0227s/iter; left time: 358.1558s\n",
      "\titers: 400, epoch: 3 | loss: 0.1155474\n",
      "\tspeed: 0.0209s/iter; left time: 327.5957s\n",
      "\titers: 500, epoch: 3 | loss: 0.1239645\n",
      "\tspeed: 0.0205s/iter; left time: 319.7877s\n",
      "\titers: 600, epoch: 3 | loss: 0.0993141\n",
      "\tspeed: 0.0205s/iter; left time: 317.3480s\n",
      "\titers: 700, epoch: 3 | loss: 0.0982265\n",
      "\tspeed: 0.0204s/iter; left time: 314.1467s\n",
      "\titers: 800, epoch: 3 | loss: 0.1155415\n",
      "\tspeed: 0.0201s/iter; left time: 307.9263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:18.73s\n",
      "Steps: 894 | Train Loss: 0.1100449 Vali Loss: 0.1245508 Test Loss: 0.1362227\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0969878\n",
      "\tspeed: 0.0614s/iter; left time: 927.7784s\n",
      "\titers: 200, epoch: 4 | loss: 0.1044634\n",
      "\tspeed: 0.0201s/iter; left time: 300.7677s\n",
      "\titers: 300, epoch: 4 | loss: 0.1043139\n",
      "\tspeed: 0.0201s/iter; left time: 299.4839s\n",
      "\titers: 400, epoch: 4 | loss: 0.0963696\n",
      "\tspeed: 0.0204s/iter; left time: 301.9426s\n",
      "\titers: 500, epoch: 4 | loss: 0.1041794\n",
      "\tspeed: 0.0211s/iter; left time: 309.8915s\n",
      "\titers: 600, epoch: 4 | loss: 0.1074749\n",
      "\tspeed: 0.0202s/iter; left time: 294.4673s\n",
      "\titers: 700, epoch: 4 | loss: 0.1123017\n",
      "\tspeed: 0.0200s/iter; left time: 290.0636s\n",
      "\titers: 800, epoch: 4 | loss: 0.1035271\n",
      "\tspeed: 0.0202s/iter; left time: 291.1609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:18.28s\n",
      "Steps: 894 | Train Loss: 0.1076611 Vali Loss: 0.1237966 Test Loss: 0.1345979\n",
      "Validation loss decreased (0.124029 --> 0.123797).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1034608\n",
      "\tspeed: 0.0616s/iter; left time: 874.9363s\n",
      "\titers: 200, epoch: 5 | loss: 0.1040511\n",
      "\tspeed: 0.0203s/iter; left time: 286.4922s\n",
      "\titers: 300, epoch: 5 | loss: 0.1110868\n",
      "\tspeed: 0.0238s/iter; left time: 333.4452s\n",
      "\titers: 400, epoch: 5 | loss: 0.1070608\n",
      "\tspeed: 0.0234s/iter; left time: 324.8202s\n",
      "\titers: 500, epoch: 5 | loss: 0.0912461\n",
      "\tspeed: 0.0206s/iter; left time: 283.7383s\n",
      "\titers: 600, epoch: 5 | loss: 0.0934486\n",
      "\tspeed: 0.0233s/iter; left time: 319.1589s\n",
      "\titers: 700, epoch: 5 | loss: 0.1138148\n",
      "\tspeed: 0.0209s/iter; left time: 284.5010s\n",
      "\titers: 800, epoch: 5 | loss: 0.1081163\n",
      "\tspeed: 0.0198s/iter; left time: 267.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:19.30s\n",
      "Steps: 894 | Train Loss: 0.1052116 Vali Loss: 0.1243563 Test Loss: 0.1359007\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950445\n",
      "\tspeed: 0.0625s/iter; left time: 832.4451s\n",
      "\titers: 200, epoch: 6 | loss: 0.1071503\n",
      "\tspeed: 0.0199s/iter; left time: 262.4680s\n",
      "\titers: 300, epoch: 6 | loss: 0.1049523\n",
      "\tspeed: 0.0199s/iter; left time: 260.5355s\n",
      "\titers: 400, epoch: 6 | loss: 0.1091378\n",
      "\tspeed: 0.0205s/iter; left time: 266.6256s\n",
      "\titers: 500, epoch: 6 | loss: 0.1049193\n",
      "\tspeed: 0.0204s/iter; left time: 263.8833s\n",
      "\titers: 600, epoch: 6 | loss: 0.0922959\n",
      "\tspeed: 0.0201s/iter; left time: 257.7947s\n",
      "\titers: 700, epoch: 6 | loss: 0.1038610\n",
      "\tspeed: 0.0204s/iter; left time: 258.8500s\n",
      "\titers: 800, epoch: 6 | loss: 0.1132800\n",
      "\tspeed: 0.0200s/iter; left time: 252.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 894 | Train Loss: 0.1029269 Vali Loss: 0.1254826 Test Loss: 0.1359840\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0997124\n",
      "\tspeed: 0.0643s/iter; left time: 798.5764s\n",
      "\titers: 200, epoch: 7 | loss: 0.1037607\n",
      "\tspeed: 0.0197s/iter; left time: 242.6481s\n",
      "\titers: 300, epoch: 7 | loss: 0.0986875\n",
      "\tspeed: 0.0197s/iter; left time: 240.7092s\n",
      "\titers: 400, epoch: 7 | loss: 0.1002348\n",
      "\tspeed: 0.0186s/iter; left time: 224.7816s\n",
      "\titers: 500, epoch: 7 | loss: 0.0963891\n",
      "\tspeed: 0.0209s/iter; left time: 251.5105s\n",
      "\titers: 600, epoch: 7 | loss: 0.1026957\n",
      "\tspeed: 0.0198s/iter; left time: 236.2900s\n",
      "\titers: 700, epoch: 7 | loss: 0.1008334\n",
      "\tspeed: 0.0207s/iter; left time: 244.4560s\n",
      "\titers: 800, epoch: 7 | loss: 0.1010140\n",
      "\tspeed: 0.0177s/iter; left time: 207.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.25s\n",
      "Steps: 894 | Train Loss: 0.1008772 Vali Loss: 0.1258458 Test Loss: 0.1363829\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0911774\n",
      "\tspeed: 0.0554s/iter; left time: 638.1398s\n",
      "\titers: 200, epoch: 8 | loss: 0.0942971\n",
      "\tspeed: 0.0193s/iter; left time: 220.4519s\n",
      "\titers: 300, epoch: 8 | loss: 0.1009466\n",
      "\tspeed: 0.0243s/iter; left time: 274.7480s\n",
      "\titers: 400, epoch: 8 | loss: 0.0973688\n",
      "\tspeed: 0.0192s/iter; left time: 215.7866s\n",
      "\titers: 500, epoch: 8 | loss: 0.1048021\n",
      "\tspeed: 0.0191s/iter; left time: 212.8108s\n",
      "\titers: 600, epoch: 8 | loss: 0.0976510\n",
      "\tspeed: 0.0160s/iter; left time: 175.9069s\n",
      "\titers: 700, epoch: 8 | loss: 0.0864443\n",
      "\tspeed: 0.0186s/iter; left time: 202.7737s\n",
      "\titers: 800, epoch: 8 | loss: 0.1001459\n",
      "\tspeed: 0.0198s/iter; left time: 214.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.95s\n",
      "Steps: 894 | Train Loss: 0.0993556 Vali Loss: 0.1255206 Test Loss: 0.1358746\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982838\n",
      "\tspeed: 0.0548s/iter; left time: 582.6467s\n",
      "\titers: 200, epoch: 9 | loss: 0.0972885\n",
      "\tspeed: 0.0107s/iter; left time: 112.2141s\n",
      "\titers: 300, epoch: 9 | loss: 0.1003829\n",
      "\tspeed: 0.0093s/iter; left time: 96.6267s\n",
      "\titers: 400, epoch: 9 | loss: 0.0934334\n",
      "\tspeed: 0.0219s/iter; left time: 226.1517s\n",
      "\titers: 500, epoch: 9 | loss: 0.1014232\n",
      "\tspeed: 0.0200s/iter; left time: 204.3515s\n",
      "\titers: 600, epoch: 9 | loss: 0.1100227\n",
      "\tspeed: 0.0198s/iter; left time: 200.3064s\n",
      "\titers: 700, epoch: 9 | loss: 0.0951592\n",
      "\tspeed: 0.0198s/iter; left time: 198.9326s\n",
      "\titers: 800, epoch: 9 | loss: 0.0990681\n",
      "\tspeed: 0.0212s/iter; left time: 210.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.50s\n",
      "Steps: 894 | Train Loss: 0.0979329 Vali Loss: 0.1268965 Test Loss: 0.1367731\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04051763936877251, rmse:0.20128993690013885, mae:0.13459789752960205, rse:0.7131096124649048\n",
      "Original data scale mse:35872592.0, rmse:5989.373046875, mae:3699.549072265625, rse:0.29841935634613037\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2 \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.5109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.5141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.6734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.7010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.5148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.6812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0372</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.6835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.7131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0209  0.1447  0.0911  0.5109\n",
       "              2         24        0.0212  0.1456  0.0914  0.5141\n",
       "              1         96        0.0362  0.1904  0.1299  0.6742\n",
       "              2         96        0.0362  0.1902  0.1307  0.6734\n",
       "              1         168       0.0392  0.1979  0.1380  0.7010\n",
       "              2         168       0.0390  0.1976  0.1382  0.6999\n",
       "MAE           1         24        0.0213  0.1458  0.0880  0.5148\n",
       "              2         24        0.0214  0.1462  0.0884  0.5164\n",
       "              1         96        0.0370  0.1924  0.1271  0.6812\n",
       "              2         96        0.0372  0.1930  0.1280  0.6835\n",
       "              1         168       0.0396  0.1990  0.1349  0.7051\n",
       "              2         168       0.0405  0.2013  0.1346  0.7131"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './results/loss_fnc_choice'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_default.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16410582.0</td>\n",
       "      <td>4050.9976</td>\n",
       "      <td>2452.9761</td>\n",
       "      <td>0.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16438184.0</td>\n",
       "      <td>4054.4031</td>\n",
       "      <td>2448.4897</td>\n",
       "      <td>0.2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31191604.0</td>\n",
       "      <td>5584.9443</td>\n",
       "      <td>3552.8628</td>\n",
       "      <td>0.2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31495776.0</td>\n",
       "      <td>5612.1099</td>\n",
       "      <td>3599.3784</td>\n",
       "      <td>0.2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34339608.0</td>\n",
       "      <td>5860.0005</td>\n",
       "      <td>3805.8254</td>\n",
       "      <td>0.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34692824.0</td>\n",
       "      <td>5890.0615</td>\n",
       "      <td>3834.8921</td>\n",
       "      <td>0.2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16238499.0</td>\n",
       "      <td>4029.7021</td>\n",
       "      <td>2347.3811</td>\n",
       "      <td>0.2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16319235.0</td>\n",
       "      <td>4039.7073</td>\n",
       "      <td>2364.4011</td>\n",
       "      <td>0.2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31829424.0</td>\n",
       "      <td>5641.7573</td>\n",
       "      <td>3474.2441</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32093164.0</td>\n",
       "      <td>5665.0830</td>\n",
       "      <td>3500.1497</td>\n",
       "      <td>0.2821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34746828.0</td>\n",
       "      <td>5894.6440</td>\n",
       "      <td>3705.5088</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35872592.0</td>\n",
       "      <td>5989.3730</td>\n",
       "      <td>3699.5491</td>\n",
       "      <td>0.2984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        16410582.0  4050.9976  2452.9761  0.2014\n",
       "              2         24        16438184.0  4054.4031  2448.4897  0.2016\n",
       "              1         96        31191604.0  5584.9443  3552.8628  0.2781\n",
       "              2         96        31495776.0  5612.1099  3599.3784  0.2795\n",
       "              1         168       34339608.0  5860.0005  3805.8254  0.2920\n",
       "              2         168       34692824.0  5890.0615  3834.8921  0.2935\n",
       "MAE           1         24        16238499.0  4029.7021  2347.3811  0.2004\n",
       "              2         24        16319235.0  4039.7073  2364.4011  0.2009\n",
       "              1         96        31829424.0  5641.7573  3474.2441  0.2810\n",
       "              2         96        32093164.0  5665.0830  3500.1497  0.2821\n",
       "              1         168       34746828.0  5894.6440  3705.5088  0.2937\n",
       "              2         168       35872592.0  5989.3730  3699.5491  0.2984"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.6738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2002</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>0.7091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0213  0.1460  0.0882  0.5156\n",
       "         MSE            0.0211  0.1451  0.0912  0.5125\n",
       "96       MAE            0.0371  0.1927  0.1275  0.6823\n",
       "         MSE            0.0362  0.1903  0.1303  0.6738\n",
       "168      MAE            0.0401  0.2002  0.1348  0.7091\n",
       "         MSE            0.0391  0.1977  0.1381  0.7004"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16278867.0</td>\n",
       "      <td>4034.7047</td>\n",
       "      <td>2355.8911</td>\n",
       "      <td>0.2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>16424383.0</td>\n",
       "      <td>4052.7003</td>\n",
       "      <td>2450.7329</td>\n",
       "      <td>0.2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>31961294.0</td>\n",
       "      <td>5653.4202</td>\n",
       "      <td>3487.1969</td>\n",
       "      <td>0.2815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31343690.0</td>\n",
       "      <td>5598.5271</td>\n",
       "      <td>3576.1206</td>\n",
       "      <td>0.2788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35309710.0</td>\n",
       "      <td>5942.0085</td>\n",
       "      <td>3702.5289</td>\n",
       "      <td>0.2961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34516216.0</td>\n",
       "      <td>5875.0310</td>\n",
       "      <td>3820.3588</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16278867.0  4034.7047  2355.8911  0.2006\n",
       "         MSE            16424383.0  4052.7003  2450.7329  0.2015\n",
       "96       MAE            31961294.0  5653.4202  3487.1969  0.2815\n",
       "         MSE            31343690.0  5598.5271  3576.1206  0.2788\n",
       "168      MAE            35309710.0  5942.0085  3702.5289  0.2961\n",
       "         MSE            34516216.0  5875.0310  3820.3588  0.2927"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'minmax')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
