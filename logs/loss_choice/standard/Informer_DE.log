
=== Starting experiments for loss function: MSE ===

=== Starting experiments for pred_len: 24 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:43.99s
Steps: 28 | Train Loss: 0.1478413 Vali Loss: 0.1479133 Test Loss: 0.1622173
Validation loss decreased (inf --> 0.147913).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:43.57s
Steps: 28 | Train Loss: 0.1003771 Vali Loss: 0.0883402 Test Loss: 0.1008069
Validation loss decreased (0.147913 --> 0.088340).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:35.11s
Steps: 28 | Train Loss: 0.0611825 Vali Loss: 0.0585965 Test Loss: 0.0708997
Validation loss decreased (0.088340 --> 0.058597).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:31.30s
Steps: 28 | Train Loss: 0.0466702 Vali Loss: 0.0498720 Test Loss: 0.0613980
Validation loss decreased (0.058597 --> 0.049872).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:31.32s
Steps: 28 | Train Loss: 0.0405702 Vali Loss: 0.0461421 Test Loss: 0.0569167
Validation loss decreased (0.049872 --> 0.046142).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:29.67s
Steps: 28 | Train Loss: 0.0375222 Vali Loss: 0.0449380 Test Loss: 0.0547776
Validation loss decreased (0.046142 --> 0.044938).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:29.62s
Steps: 28 | Train Loss: 0.0355482 Vali Loss: 0.0419016 Test Loss: 0.0520547
Validation loss decreased (0.044938 --> 0.041902).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:30.32s
Steps: 28 | Train Loss: 0.0339485 Vali Loss: 0.0416504 Test Loss: 0.0519045
Validation loss decreased (0.041902 --> 0.041650).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:31.45s
Steps: 28 | Train Loss: 0.0328839 Vali Loss: 0.0400875 Test Loss: 0.0502859
Validation loss decreased (0.041650 --> 0.040088).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:30.73s
Steps: 28 | Train Loss: 0.0319811 Vali Loss: 0.0400712 Test Loss: 0.0502475
Validation loss decreased (0.040088 --> 0.040071).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.05030380189418793, rmse:0.2242850959300995, mae:0.1427113264799118, rse:0.7909361720085144
Original data scale mse:46405980.0, rmse:6812.193359375, mae:4173.82861328125, rse:0.338646799325943
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:29.01s
Steps: 28 | Train Loss: 0.1162238 Vali Loss: 0.1173103 Test Loss: 0.1402464
Validation loss decreased (inf --> 0.117310).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:29.95s
Steps: 28 | Train Loss: 0.0871348 Vali Loss: 0.0826918 Test Loss: 0.0981774
Validation loss decreased (0.117310 --> 0.082692).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:30.76s
Steps: 28 | Train Loss: 0.0604664 Vali Loss: 0.0618657 Test Loss: 0.0743486
Validation loss decreased (0.082692 --> 0.061866).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:31.55s
Steps: 28 | Train Loss: 0.0468714 Vali Loss: 0.0517536 Test Loss: 0.0637684
Validation loss decreased (0.061866 --> 0.051754).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:29.84s
Steps: 28 | Train Loss: 0.0391820 Vali Loss: 0.0454237 Test Loss: 0.0566263
Validation loss decreased (0.051754 --> 0.045424).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:30.18s
Steps: 28 | Train Loss: 0.0357501 Vali Loss: 0.0434478 Test Loss: 0.0547515
Validation loss decreased (0.045424 --> 0.043448).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:29.91s
Steps: 28 | Train Loss: 0.0331016 Vali Loss: 0.0420277 Test Loss: 0.0527713
Validation loss decreased (0.043448 --> 0.042028).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:31.19s
Steps: 28 | Train Loss: 0.0315370 Vali Loss: 0.0402860 Test Loss: 0.0507687
Validation loss decreased (0.042028 --> 0.040286).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:30.47s
Steps: 28 | Train Loss: 0.0306962 Vali Loss: 0.0395377 Test Loss: 0.0499608
Validation loss decreased (0.040286 --> 0.039538).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:30.08s
Steps: 28 | Train Loss: 0.0301308 Vali Loss: 0.0392296 Test Loss: 0.0495566
Validation loss decreased (0.039538 --> 0.039230).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.04969227313995361, rmse:0.22291763126850128, mae:0.1400560736656189, rse:0.7861139178276062
Original data scale mse:43607452.0, rmse:6603.59375, mae:4028.170166015625, rse:0.32827693223953247

Extracted Metrics for DE, pred_len=24, iteration=1:
Scaled Metrics - MSE: 0.05030380189418793, RMSE: 0.2242850959300995, MAE: 0.1427113264799118, RSE: 0.7909361720085144
Unscaled Metrics - MSE: 46405980.0, RMSE: 6812.193359375, MAE: 4173.82861328125, RSE: 0.338646799325943

Extracted Metrics for DE, pred_len=24, iteration=2:
Scaled Metrics - MSE: 0.04969227313995361, RMSE: 0.22291763126850128, MAE: 0.1400560736656189, RSE: 0.7861139178276062
Unscaled Metrics - MSE: 43607452.0, RMSE: 6603.59375, MAE: 4028.170166015625, RSE: 0.32827693223953247

=== Starting experiments for pred_len: 96 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:43.93s
Steps: 28 | Train Loss: 0.1429120 Vali Loss: 0.1345022 Test Loss: 0.1515718
Validation loss decreased (inf --> 0.134502).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.48s
Steps: 28 | Train Loss: 0.1117858 Vali Loss: 0.0968687 Test Loss: 0.1157689
Validation loss decreased (0.134502 --> 0.096869).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.44s
Steps: 28 | Train Loss: 0.0792876 Vali Loss: 0.0795699 Test Loss: 0.0971754
Validation loss decreased (0.096869 --> 0.079570).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.39s
Steps: 28 | Train Loss: 0.0677733 Vali Loss: 0.0735438 Test Loss: 0.0925086
Validation loss decreased (0.079570 --> 0.073544).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.44s
Steps: 28 | Train Loss: 0.0625541 Vali Loss: 0.0704064 Test Loss: 0.0888667
Validation loss decreased (0.073544 --> 0.070406).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.39s
Steps: 28 | Train Loss: 0.0547506 Vali Loss: 0.0622938 Test Loss: 0.0799943
Validation loss decreased (0.070406 --> 0.062294).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.36s
Steps: 28 | Train Loss: 0.0498998 Vali Loss: 0.0603099 Test Loss: 0.0778767
Validation loss decreased (0.062294 --> 0.060310).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.42s
Steps: 28 | Train Loss: 0.0476811 Vali Loss: 0.0578569 Test Loss: 0.0746367
Validation loss decreased (0.060310 --> 0.057857).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.35s
Steps: 28 | Train Loss: 0.0464486 Vali Loss: 0.0569047 Test Loss: 0.0737764
Validation loss decreased (0.057857 --> 0.056905).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.33s
Steps: 28 | Train Loss: 0.0455137 Vali Loss: 0.0573742 Test Loss: 0.0737012
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.07380359619855881, rmse:0.2716681659221649, mae:0.18987499177455902, rse:0.9611194729804993
Original data scale mse:74929952.0, rmse:8656.208984375, mae:5689.70166015625, rse:0.430941641330719
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:22.42s
Steps: 28 | Train Loss: 0.1425895 Vali Loss: 0.1214478 Test Loss: 0.1416976
Validation loss decreased (inf --> 0.121448).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.38s
Steps: 28 | Train Loss: 0.1085077 Vali Loss: 0.1049502 Test Loss: 0.1217570
Validation loss decreased (0.121448 --> 0.104950).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.42s
Steps: 28 | Train Loss: 0.0831164 Vali Loss: 0.0858065 Test Loss: 0.1040811
Validation loss decreased (0.104950 --> 0.085807).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.49s
Steps: 28 | Train Loss: 0.0723830 Vali Loss: 0.0791383 Test Loss: 0.0965923
Validation loss decreased (0.085807 --> 0.079138).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.35s
Steps: 28 | Train Loss: 0.0668388 Vali Loss: 0.0742808 Test Loss: 0.0901530
Validation loss decreased (0.079138 --> 0.074281).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.42s
Steps: 28 | Train Loss: 0.0634842 Vali Loss: 0.0720548 Test Loss: 0.0875859
Validation loss decreased (0.074281 --> 0.072055).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.0615657 Vali Loss: 0.0698413 Test Loss: 0.0843607
Validation loss decreased (0.072055 --> 0.069841).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.44s
Steps: 28 | Train Loss: 0.0576271 Vali Loss: 0.0649973 Test Loss: 0.0795622
Validation loss decreased (0.069841 --> 0.064997).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.47s
Steps: 28 | Train Loss: 0.0544603 Vali Loss: 0.0638632 Test Loss: 0.0776023
Validation loss decreased (0.064997 --> 0.063863).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.37s
Steps: 28 | Train Loss: 0.0533784 Vali Loss: 0.0632801 Test Loss: 0.0764951
Validation loss decreased (0.063863 --> 0.063280).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.07649966329336166, rmse:0.27658572793006897, mae:0.19428807497024536, rse:0.9785170555114746
Original data scale mse:89511848.0, rmse:9461.0703125, mae:6032.8173828125, rse:0.4710109531879425

Extracted Metrics for DE, pred_len=96, iteration=1:
Scaled Metrics - MSE: 0.07380359619855881, RMSE: 0.2716681659221649, MAE: 0.18987499177455902, RSE: 0.9611194729804993
Unscaled Metrics - MSE: 74929952.0, RMSE: 8656.208984375, MAE: 5689.70166015625, RSE: 0.430941641330719

Extracted Metrics for DE, pred_len=96, iteration=2:
Scaled Metrics - MSE: 0.07649966329336166, RMSE: 0.27658572793006897, MAE: 0.19428807497024536, RSE: 0.9785170555114746
Unscaled Metrics - MSE: 89511848.0, RMSE: 9461.0703125, MAE: 6032.8173828125, RSE: 0.4710109531879425

=== Starting experiments for pred_len: 168 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.89s
Steps: 28 | Train Loss: 0.1430627 Vali Loss: 0.1317333 Test Loss: 0.1489007
Validation loss decreased (inf --> 0.131733).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.75s
Steps: 28 | Train Loss: 0.1084212 Vali Loss: 0.1018991 Test Loss: 0.1243320
Validation loss decreased (0.131733 --> 0.101899).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.74s
Steps: 28 | Train Loss: 0.0851678 Vali Loss: 0.0898231 Test Loss: 0.1090990
Validation loss decreased (0.101899 --> 0.089823).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.75s
Steps: 28 | Train Loss: 0.0734836 Vali Loss: 0.0814941 Test Loss: 0.1018331
Validation loss decreased (0.089823 --> 0.081494).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.87s
Steps: 28 | Train Loss: 0.0690890 Vali Loss: 0.0788708 Test Loss: 0.0991569
Validation loss decreased (0.081494 --> 0.078871).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.79s
Steps: 28 | Train Loss: 0.0628266 Vali Loss: 0.0725407 Test Loss: 0.0927750
Validation loss decreased (0.078871 --> 0.072541).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.79s
Steps: 28 | Train Loss: 0.0589013 Vali Loss: 0.0721834 Test Loss: 0.0915030
Validation loss decreased (0.072541 --> 0.072183).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.71s
Steps: 28 | Train Loss: 0.0575295 Vali Loss: 0.0706287 Test Loss: 0.0901585
Validation loss decreased (0.072183 --> 0.070629).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.74s
Steps: 28 | Train Loss: 0.0566050 Vali Loss: 0.0701231 Test Loss: 0.0891233
Validation loss decreased (0.070629 --> 0.070123).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.75s
Steps: 28 | Train Loss: 0.0552465 Vali Loss: 0.0680880 Test Loss: 0.0862923
Validation loss decreased (0.070123 --> 0.068088).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.08629170805215836, rmse:0.2937544882297516, mae:0.2106221318244934, rse:1.0409144163131714
Original data scale mse:94133624.0, rmse:9702.248046875, mae:6475.05615234375, rse:0.4833827316761017
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.72s
Steps: 28 | Train Loss: 0.1276621 Vali Loss: 0.1351274 Test Loss: 0.1580724
Validation loss decreased (inf --> 0.135127).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.80s
Steps: 28 | Train Loss: 0.0948020 Vali Loss: 0.0837675 Test Loss: 0.1051739
Validation loss decreased (0.135127 --> 0.083768).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.77s
Steps: 28 | Train Loss: 0.0610302 Vali Loss: 0.0638251 Test Loss: 0.0825315
Validation loss decreased (0.083768 --> 0.063825).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.87s
Steps: 28 | Train Loss: 0.0512073 Vali Loss: 0.0579880 Test Loss: 0.0758483
Validation loss decreased (0.063825 --> 0.057988).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.85s
Steps: 28 | Train Loss: 0.0470926 Vali Loss: 0.0554911 Test Loss: 0.0724829
Validation loss decreased (0.057988 --> 0.055491).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.82s
Steps: 28 | Train Loss: 0.0448498 Vali Loss: 0.0565048 Test Loss: 0.0727061
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.72s
Steps: 28 | Train Loss: 0.0433158 Vali Loss: 0.0549381 Test Loss: 0.0701488
Validation loss decreased (0.055491 --> 0.054938).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.86s
Steps: 28 | Train Loss: 0.0422918 Vali Loss: 0.0523053 Test Loss: 0.0670834
Validation loss decreased (0.054938 --> 0.052305).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.76s
Steps: 28 | Train Loss: 0.0414314 Vali Loss: 0.0541319 Test Loss: 0.0693071
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.83s
Steps: 28 | Train Loss: 0.0405167 Vali Loss: 0.0526614 Test Loss: 0.0678187
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.06709600985050201, rmse:0.25902897119522095, mae:0.18583549559116364, rse:0.917864978313446
Original data scale mse:64578692.0, rmse:8036.0869140625, mae:5500.42919921875, rse:0.40037164092063904

Extracted Metrics for DE, pred_len=168, iteration=1:
Scaled Metrics - MSE: 0.08629170805215836, RMSE: 0.2937544882297516, MAE: 0.2106221318244934, RSE: 1.0409144163131714
Unscaled Metrics - MSE: 94133624.0, RMSE: 9702.248046875, MAE: 6475.05615234375, RSE: 0.4833827316761017

Extracted Metrics for DE, pred_len=168, iteration=2:
Scaled Metrics - MSE: 0.06709600985050201, RMSE: 0.25902897119522095, MAE: 0.18583549559116364, RSE: 0.917864978313446
Unscaled Metrics - MSE: 64578692.0, RMSE: 8036.0869140625, MAE: 5500.42919921875, RSE: 0.40037164092063904

=== Starting experiments for loss function: RMSE ===

=== Starting experiments for pred_len: 24 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:16.16s
Steps: 28 | Train Loss: 0.3836824 Vali Loss: 0.1475245 Test Loss: 0.1619418
Validation loss decreased (inf --> 0.147524).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:15.89s
Steps: 28 | Train Loss: 0.3109871 Vali Loss: 0.0831558 Test Loss: 0.0957884
Validation loss decreased (0.147524 --> 0.083156).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:15.84s
Steps: 28 | Train Loss: 0.2413680 Vali Loss: 0.0585563 Test Loss: 0.0701640
Validation loss decreased (0.083156 --> 0.058556).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:15.77s
Steps: 28 | Train Loss: 0.2111342 Vali Loss: 0.0487607 Test Loss: 0.0601849
Validation loss decreased (0.058556 --> 0.048761).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:15.88s
Steps: 28 | Train Loss: 0.1959499 Vali Loss: 0.0467963 Test Loss: 0.0581303
Validation loss decreased (0.048761 --> 0.046796).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1889319 Vali Loss: 0.0435502 Test Loss: 0.0531463
Validation loss decreased (0.046796 --> 0.043550).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1834087 Vali Loss: 0.0406070 Test Loss: 0.0507918
Validation loss decreased (0.043550 --> 0.040607).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:15.80s
Steps: 28 | Train Loss: 0.1791590 Vali Loss: 0.0400041 Test Loss: 0.0502523
Validation loss decreased (0.040607 --> 0.040004).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1767288 Vali Loss: 0.0393128 Test Loss: 0.0492908
Validation loss decreased (0.040004 --> 0.039313).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:15.84s
Steps: 28 | Train Loss: 0.1744270 Vali Loss: 0.0385130 Test Loss: 0.0489489
Validation loss decreased (0.039313 --> 0.038513).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.04896596074104309, rmse:0.22128254175186157, mae:0.14034901559352875, rse:0.7803477644920349
Original data scale mse:45284148.0, rmse:6729.349609375, mae:4104.0556640625, rse:0.33452850580215454
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:15.87s
Steps: 28 | Train Loss: 0.3402217 Vali Loss: 0.1170932 Test Loss: 0.1400332
Validation loss decreased (inf --> 0.117093).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.2922450 Vali Loss: 0.0809019 Test Loss: 0.0959922
Validation loss decreased (0.117093 --> 0.080902).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:15.86s
Steps: 28 | Train Loss: 0.2414145 Vali Loss: 0.0584040 Test Loss: 0.0718129
Validation loss decreased (0.080902 --> 0.058404).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:15.81s
Steps: 28 | Train Loss: 0.2098276 Vali Loss: 0.0491670 Test Loss: 0.0613946
Validation loss decreased (0.058404 --> 0.049167).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:15.82s
Steps: 28 | Train Loss: 0.1946334 Vali Loss: 0.0453628 Test Loss: 0.0563042
Validation loss decreased (0.049167 --> 0.045363).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:15.80s
Steps: 28 | Train Loss: 0.1850141 Vali Loss: 0.0415536 Test Loss: 0.0522479
Validation loss decreased (0.045363 --> 0.041554).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1785505 Vali Loss: 0.0416024 Test Loss: 0.0518538
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:15.81s
Steps: 28 | Train Loss: 0.1749837 Vali Loss: 0.0393005 Test Loss: 0.0496530
Validation loss decreased (0.041554 --> 0.039300).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:15.85s
Steps: 28 | Train Loss: 0.1726247 Vali Loss: 0.0391269 Test Loss: 0.0495515
Validation loss decreased (0.039300 --> 0.039127).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:15.82s
Steps: 28 | Train Loss: 0.1710701 Vali Loss: 0.0387349 Test Loss: 0.0489874
Validation loss decreased (0.039127 --> 0.038735).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.04910042881965637, rmse:0.2215861678123474, mae:0.13834482431411743, rse:0.78141850233078
Original data scale mse:43182320.0, rmse:6571.32568359375, mae:3982.245361328125, rse:0.3266727924346924

Extracted Metrics for DE, pred_len=24, iteration=1:
Scaled Metrics - MSE: 0.04896596074104309, RMSE: 0.22128254175186157, MAE: 0.14034901559352875, RSE: 0.7803477644920349
Unscaled Metrics - MSE: 45284148.0, RMSE: 6729.349609375, MAE: 4104.0556640625, RSE: 0.33452850580215454

Extracted Metrics for DE, pred_len=24, iteration=2:
Scaled Metrics - MSE: 0.04910042881965637, RMSE: 0.2215861678123474, MAE: 0.13834482431411743, RSE: 0.78141850233078
Unscaled Metrics - MSE: 43182320.0, RMSE: 6571.32568359375, MAE: 3982.245361328125, RSE: 0.3266727924346924

=== Starting experiments for pred_len: 96 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:22.59s
Steps: 28 | Train Loss: 0.3768496 Vali Loss: 0.1340947 Test Loss: 0.1512964
Validation loss decreased (inf --> 0.134095).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.3329076 Vali Loss: 0.0958184 Test Loss: 0.1152645
Validation loss decreased (0.134095 --> 0.095818).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.45s
Steps: 28 | Train Loss: 0.2776295 Vali Loss: 0.0791948 Test Loss: 0.0967024
Validation loss decreased (0.095818 --> 0.079195).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.36s
Steps: 28 | Train Loss: 0.2566589 Vali Loss: 0.0722741 Test Loss: 0.0901412
Validation loss decreased (0.079195 --> 0.072274).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.28s
Steps: 28 | Train Loss: 0.2380046 Vali Loss: 0.0643677 Test Loss: 0.0822200
Validation loss decreased (0.072274 --> 0.064368).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.32s
Steps: 28 | Train Loss: 0.2223493 Vali Loss: 0.0603848 Test Loss: 0.0771667
Validation loss decreased (0.064368 --> 0.060385).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.30s
Steps: 28 | Train Loss: 0.2144373 Vali Loss: 0.0577169 Test Loss: 0.0739786
Validation loss decreased (0.060385 --> 0.057717).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.28s
Steps: 28 | Train Loss: 0.2099563 Vali Loss: 0.0573954 Test Loss: 0.0731090
Validation loss decreased (0.057717 --> 0.057395).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.36s
Steps: 28 | Train Loss: 0.2071383 Vali Loss: 0.0545822 Test Loss: 0.0696995
Validation loss decreased (0.057395 --> 0.054582).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.28s
Steps: 28 | Train Loss: 0.2050681 Vali Loss: 0.0542387 Test Loss: 0.0693841
Validation loss decreased (0.054582 --> 0.054239).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.06937795132398605, rmse:0.2633969485759735, mae:0.18275697529315948, rse:0.9318572282791138
Original data scale mse:68338648.0, rmse:8266.7197265625, mae:5414.369140625, rse:0.41155126690864563
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.3755680 Vali Loss: 0.1209967 Test Loss: 0.1413337
Validation loss decreased (inf --> 0.120997).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.38s
Steps: 28 | Train Loss: 0.3285324 Vali Loss: 0.1028639 Test Loss: 0.1201359
Validation loss decreased (0.120997 --> 0.102864).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.44s
Steps: 28 | Train Loss: 0.2885717 Vali Loss: 0.0864469 Test Loss: 0.1048454
Validation loss decreased (0.102864 --> 0.086447).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.38s
Steps: 28 | Train Loss: 0.2671690 Vali Loss: 0.0789518 Test Loss: 0.0963433
Validation loss decreased (0.086447 --> 0.078952).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.35s
Steps: 28 | Train Loss: 0.2568436 Vali Loss: 0.0746554 Test Loss: 0.0903459
Validation loss decreased (0.078952 --> 0.074655).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.37s
Steps: 28 | Train Loss: 0.2483323 Vali Loss: 0.0683163 Test Loss: 0.0842139
Validation loss decreased (0.074655 --> 0.068316).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.31s
Steps: 28 | Train Loss: 0.2370632 Vali Loss: 0.0662413 Test Loss: 0.0807126
Validation loss decreased (0.068316 --> 0.066241).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.39s
Steps: 28 | Train Loss: 0.2329740 Vali Loss: 0.0639063 Test Loss: 0.0779105
Validation loss decreased (0.066241 --> 0.063906).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.35s
Steps: 28 | Train Loss: 0.2306211 Vali Loss: 0.0634197 Test Loss: 0.0765235
Validation loss decreased (0.063906 --> 0.063420).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.2287093 Vali Loss: 0.0631505 Test Loss: 0.0759496
Validation loss decreased (0.063420 --> 0.063151).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.07593496888875961, rmse:0.27556300163269043, mae:0.19298534095287323, rse:0.9748988747596741
Original data scale mse:88241352.0, rmse:9393.6865234375, mae:5970.7509765625, rse:0.46765631437301636

Extracted Metrics for DE, pred_len=96, iteration=1:
Scaled Metrics - MSE: 0.06937795132398605, RMSE: 0.2633969485759735, MAE: 0.18275697529315948, RSE: 0.9318572282791138
Unscaled Metrics - MSE: 68338648.0, RMSE: 8266.7197265625, MAE: 5414.369140625, RSE: 0.41155126690864563

Extracted Metrics for DE, pred_len=96, iteration=2:
Scaled Metrics - MSE: 0.07593496888875961, RMSE: 0.27556300163269043, MAE: 0.19298534095287323, RSE: 0.9748988747596741
Unscaled Metrics - MSE: 88241352.0, RMSE: 9393.6865234375, MAE: 5970.7509765625, RSE: 0.46765631437301636

=== Starting experiments for pred_len: 168 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.96s
Steps: 28 | Train Loss: 0.3766729 Vali Loss: 0.1314879 Test Loss: 0.1488897
Validation loss decreased (inf --> 0.131488).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.67s
Steps: 28 | Train Loss: 0.3272812 Vali Loss: 0.1021089 Test Loss: 0.1236654
Validation loss decreased (0.131488 --> 0.102109).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.65s
Steps: 28 | Train Loss: 0.2877763 Vali Loss: 0.0864091 Test Loss: 0.1081491
Validation loss decreased (0.102109 --> 0.086409).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.60s
Steps: 28 | Train Loss: 0.2674507 Vali Loss: 0.0805171 Test Loss: 0.1013707
Validation loss decreased (0.086409 --> 0.080517).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.60s
Steps: 28 | Train Loss: 0.2509862 Vali Loss: 0.0726450 Test Loss: 0.0933231
Validation loss decreased (0.080517 --> 0.072645).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.59s
Steps: 28 | Train Loss: 0.2429923 Vali Loss: 0.0742906 Test Loss: 0.0942496
EarlyStopping counter: 1 out of 3
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.57s
Steps: 28 | Train Loss: 0.2396471 Vali Loss: 0.0715609 Test Loss: 0.0906302
Validation loss decreased (0.072645 --> 0.071561).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.63s
Steps: 28 | Train Loss: 0.2356598 Vali Loss: 0.0670107 Test Loss: 0.0857976
Validation loss decreased (0.071561 --> 0.067011).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.72s
Steps: 28 | Train Loss: 0.2321605 Vali Loss: 0.0671617 Test Loss: 0.0858888
EarlyStopping counter: 1 out of 3
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.57s
Steps: 28 | Train Loss: 0.2285442 Vali Loss: 0.0653109 Test Loss: 0.0834161
Validation loss decreased (0.067011 --> 0.065311).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.08343031257390976, rmse:0.2888430655002594, mae:0.20613108575344086, rse:1.0235108137130737
Original data scale mse:88408408.0, rmse:9402.57421875, mae:6272.15625, rse:0.46845245361328125
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.69s
Steps: 28 | Train Loss: 0.3567430 Vali Loss: 0.1349375 Test Loss: 0.1578523
Validation loss decreased (inf --> 0.134937).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.77s
Steps: 28 | Train Loss: 0.3039208 Vali Loss: 0.0807954 Test Loss: 0.1013127
Validation loss decreased (0.134937 --> 0.080795).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.69s
Steps: 28 | Train Loss: 0.2427866 Vali Loss: 0.0636032 Test Loss: 0.0832736
Validation loss decreased (0.080795 --> 0.063603).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.71s
Steps: 28 | Train Loss: 0.2224566 Vali Loss: 0.0590888 Test Loss: 0.0761857
Validation loss decreased (0.063603 --> 0.059089).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.61s
Steps: 28 | Train Loss: 0.2135578 Vali Loss: 0.0575753 Test Loss: 0.0740269
Validation loss decreased (0.059089 --> 0.057575).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.2081886 Vali Loss: 0.0560215 Test Loss: 0.0705516
Validation loss decreased (0.057575 --> 0.056021).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.63s
Steps: 28 | Train Loss: 0.2044576 Vali Loss: 0.0532188 Test Loss: 0.0681387
Validation loss decreased (0.056021 --> 0.053219).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.62s
Steps: 28 | Train Loss: 0.2017081 Vali Loss: 0.0525884 Test Loss: 0.0668747
Validation loss decreased (0.053219 --> 0.052588).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.1993914 Vali Loss: 0.0523482 Test Loss: 0.0665242
Validation loss decreased (0.052588 --> 0.052348).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.65s
Steps: 28 | Train Loss: 0.1975558 Vali Loss: 0.0512603 Test Loss: 0.0656318
Validation loss decreased (0.052348 --> 0.051260).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.06560055166482925, rmse:0.2561260461807251, mae:0.18409141898155212, rse:0.9075785279273987
Original data scale mse:62719496.0, rmse:7919.56396484375, mae:5426.11328125, rse:0.3945663273334503

Extracted Metrics for DE, pred_len=168, iteration=1:
Scaled Metrics - MSE: 0.08343031257390976, RMSE: 0.2888430655002594, MAE: 0.20613108575344086, RSE: 1.0235108137130737
Unscaled Metrics - MSE: 88408408.0, RMSE: 9402.57421875, MAE: 6272.15625, RSE: 0.46845245361328125

Extracted Metrics for DE, pred_len=168, iteration=2:
Scaled Metrics - MSE: 0.06560055166482925, RMSE: 0.2561260461807251, MAE: 0.18409141898155212, RSE: 0.9075785279273987
Unscaled Metrics - MSE: 62719496.0, RMSE: 7919.56396484375, MAE: 5426.11328125, RSE: 0.3945663273334503

=== Starting experiments for loss function: MAE ===

=== Starting experiments for pred_len: 24 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:16.09s
Steps: 28 | Train Loss: 0.2947908 Vali Loss: 0.2937580 Test Loss: 0.3044341
Validation loss decreased (inf --> 0.293758).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:15.84s
Steps: 28 | Train Loss: 0.2322744 Vali Loss: 0.2122709 Test Loss: 0.2253419
Validation loss decreased (0.293758 --> 0.212271).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1733862 Vali Loss: 0.1723166 Test Loss: 0.1838678
Validation loss decreased (0.212271 --> 0.172317).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:15.85s
Steps: 28 | Train Loss: 0.1478614 Vali Loss: 0.1521061 Test Loss: 0.1642524
Validation loss decreased (0.172317 --> 0.152106).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1352463 Vali Loss: 0.1453684 Test Loss: 0.1572480
Validation loss decreased (0.152106 --> 0.145368).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1287323 Vali Loss: 0.1382259 Test Loss: 0.1488564
Validation loss decreased (0.145368 --> 0.138226).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:15.84s
Steps: 28 | Train Loss: 0.1241396 Vali Loss: 0.1342070 Test Loss: 0.1452231
Validation loss decreased (0.138226 --> 0.134207).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:15.82s
Steps: 28 | Train Loss: 0.1203154 Vali Loss: 0.1316905 Test Loss: 0.1436729
Validation loss decreased (0.134207 --> 0.131690).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:15.81s
Steps: 28 | Train Loss: 0.1179415 Vali Loss: 0.1309829 Test Loss: 0.1418640
Validation loss decreased (0.131690 --> 0.130983).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:15.80s
Steps: 28 | Train Loss: 0.1160507 Vali Loss: 0.1284569 Test Loss: 0.1415629
Validation loss decreased (0.130983 --> 0.128457).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.05152120813727379, rmse:0.22698283195495605, mae:0.14175660908222198, rse:0.8004497289657593
Original data scale mse:47569352.0, rmse:6897.0537109375, mae:4171.75341796875, rse:0.34286537766456604
Use GPU: cuda:0
>>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29017
val 6217
test 6217
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:15.82s
Steps: 28 | Train Loss: 0.2575649 Vali Loss: 0.2591725 Test Loss: 0.2809412
Validation loss decreased (inf --> 0.259172).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:15.81s
Steps: 28 | Train Loss: 0.2140734 Vali Loss: 0.2053963 Test Loss: 0.2179028
Validation loss decreased (0.259172 --> 0.205396).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:15.88s
Steps: 28 | Train Loss: 0.1697982 Vali Loss: 0.1658626 Test Loss: 0.1787270
Validation loss decreased (0.205396 --> 0.165863).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:15.78s
Steps: 28 | Train Loss: 0.1451544 Vali Loss: 0.1509439 Test Loss: 0.1634326
Validation loss decreased (0.165863 --> 0.150944).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:15.78s
Steps: 28 | Train Loss: 0.1328623 Vali Loss: 0.1474236 Test Loss: 0.1581578
Validation loss decreased (0.150944 --> 0.147424).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:15.80s
Steps: 28 | Train Loss: 0.1258616 Vali Loss: 0.1347188 Test Loss: 0.1454468
Validation loss decreased (0.147424 --> 0.134719).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:15.85s
Steps: 28 | Train Loss: 0.1210962 Vali Loss: 0.1367234 Test Loss: 0.1481154
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:15.83s
Steps: 28 | Train Loss: 0.1172891 Vali Loss: 0.1285980 Test Loss: 0.1387363
Validation loss decreased (0.134719 --> 0.128598).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:15.85s
Steps: 28 | Train Loss: 0.1148916 Vali Loss: 0.1277641 Test Loss: 0.1381029
Validation loss decreased (0.128598 --> 0.127764).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:15.85s
Steps: 28 | Train Loss: 0.1123120 Vali Loss: 0.1261625 Test Loss: 0.1350870
Validation loss decreased (0.127764 --> 0.126162).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.049480877816677094, rmse:0.22244296967983246, mae:0.13551434874534607, rse:0.7844399809837341
Original data scale mse:42594408.0, rmse:6526.43896484375, mae:3862.489990234375, rse:0.32444143295288086

Extracted Metrics for DE, pred_len=24, iteration=1:
Scaled Metrics - MSE: 0.05152120813727379, RMSE: 0.22698283195495605, MAE: 0.14175660908222198, RSE: 0.8004497289657593
Unscaled Metrics - MSE: 47569352.0, RMSE: 6897.0537109375, MAE: 4171.75341796875, RSE: 0.34286537766456604

Extracted Metrics for DE, pred_len=24, iteration=2:
Scaled Metrics - MSE: 0.049480877816677094, RMSE: 0.22244296967983246, MAE: 0.13551434874534607, RSE: 0.7844399809837341
Unscaled Metrics - MSE: 42594408.0, RMSE: 6526.43896484375, MAE: 3862.489990234375, RSE: 0.32444143295288086

=== Starting experiments for pred_len: 96 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:22.56s
Steps: 28 | Train Loss: 0.2878554 Vali Loss: 0.2782973 Test Loss: 0.2939489
Validation loss decreased (inf --> 0.278297).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.2493361 Vali Loss: 0.2293183 Test Loss: 0.2486968
Validation loss decreased (0.278297 --> 0.229318).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.49s
Steps: 28 | Train Loss: 0.2030089 Vali Loss: 0.2091734 Test Loss: 0.2290067
Validation loss decreased (0.229318 --> 0.209173).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.37s
Steps: 28 | Train Loss: 0.1847991 Vali Loss: 0.1949806 Test Loss: 0.2154967
Validation loss decreased (0.209173 --> 0.194981).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.35s
Steps: 28 | Train Loss: 0.1700992 Vali Loss: 0.1852759 Test Loss: 0.2057747
Validation loss decreased (0.194981 --> 0.185276).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.37s
Steps: 28 | Train Loss: 0.1618569 Vali Loss: 0.1822602 Test Loss: 0.2004764
Validation loss decreased (0.185276 --> 0.182260).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.47s
Steps: 28 | Train Loss: 0.1563207 Vali Loss: 0.1768445 Test Loss: 0.1953603
Validation loss decreased (0.182260 --> 0.176845).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.36s
Steps: 28 | Train Loss: 0.1526811 Vali Loss: 0.1746443 Test Loss: 0.1926536
Validation loss decreased (0.176845 --> 0.174644).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.34s
Steps: 28 | Train Loss: 0.1503826 Vali Loss: 0.1678682 Test Loss: 0.1877999
Validation loss decreased (0.174644 --> 0.167868).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.36s
Steps: 28 | Train Loss: 0.1483403 Vali Loss: 0.1685538 Test Loss: 0.1875833
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.0748060792684555, rmse:0.2735069990158081, mae:0.18794004619121552, rse:0.9676250219345093
Original data scale mse:75528064.0, rmse:8690.6884765625, mae:5614.416015625, rse:0.43265819549560547
Use GPU: cuda:0
>>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6145
test 6145
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:22.39s
Steps: 28 | Train Loss: 0.2882317 Vali Loss: 0.2631274 Test Loss: 0.2839217
Validation loss decreased (inf --> 0.263127).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:22.39s
Steps: 28 | Train Loss: 0.2430416 Vali Loss: 0.2384012 Test Loss: 0.2577145
Validation loss decreased (0.263127 --> 0.238401).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:22.43s
Steps: 28 | Train Loss: 0.2094272 Vali Loss: 0.2146222 Test Loss: 0.2353859
Validation loss decreased (0.238401 --> 0.214622).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:22.37s
Steps: 28 | Train Loss: 0.1908530 Vali Loss: 0.2051060 Test Loss: 0.2259538
Validation loss decreased (0.214622 --> 0.205106).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:22.44s
Steps: 28 | Train Loss: 0.1793411 Vali Loss: 0.1979372 Test Loss: 0.2174060
Validation loss decreased (0.205106 --> 0.197937).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:22.40s
Steps: 28 | Train Loss: 0.1731107 Vali Loss: 0.1909645 Test Loss: 0.2098604
Validation loss decreased (0.197937 --> 0.190965).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:22.43s
Steps: 28 | Train Loss: 0.1691855 Vali Loss: 0.1907061 Test Loss: 0.2076954
Validation loss decreased (0.190965 --> 0.190706).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:22.41s
Steps: 28 | Train Loss: 0.1663984 Vali Loss: 0.1852930 Test Loss: 0.2037387
Validation loss decreased (0.190706 --> 0.185293).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:22.49s
Steps: 28 | Train Loss: 0.1645354 Vali Loss: 0.1850846 Test Loss: 0.2021091
Validation loss decreased (0.185293 --> 0.185085).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:22.43s
Steps: 28 | Train Loss: 0.1613234 Vali Loss: 0.1794551 Test Loss: 0.1958371
Validation loss decreased (0.185085 --> 0.179455).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.08098553866147995, rmse:0.2845795750617981, mae:0.19587472081184387, rse:1.0067980289459229
Original data scale mse:89470656.0, rmse:9458.892578125, mae:5998.423828125, rse:0.47090256214141846

Extracted Metrics for DE, pred_len=96, iteration=1:
Scaled Metrics - MSE: 0.0748060792684555, RMSE: 0.2735069990158081, MAE: 0.18794004619121552, RSE: 0.9676250219345093
Unscaled Metrics - MSE: 75528064.0, RMSE: 8690.6884765625, MAE: 5614.416015625, RSE: 0.43265819549560547

Extracted Metrics for DE, pred_len=96, iteration=2:
Scaled Metrics - MSE: 0.08098553866147995, RMSE: 0.2845795750617981, MAE: 0.19587472081184387, RSE: 1.0067980289459229
Unscaled Metrics - MSE: 89470656.0, RMSE: 9458.892578125, MAE: 5998.423828125, RSE: 0.47090256214141846

=== Starting experiments for pred_len: 168 ===
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=1012, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.89s
Steps: 28 | Train Loss: 0.2883625 Vali Loss: 0.2744152 Test Loss: 0.2912167
Validation loss decreased (inf --> 0.274415).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.62s
Steps: 28 | Train Loss: 0.2420541 Vali Loss: 0.2364504 Test Loss: 0.2568461
Validation loss decreased (0.274415 --> 0.236450).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.65s
Steps: 28 | Train Loss: 0.2081043 Vali Loss: 0.2151280 Test Loss: 0.2395024
Validation loss decreased (0.236450 --> 0.215128).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.70s
Steps: 28 | Train Loss: 0.1920660 Vali Loss: 0.2084296 Test Loss: 0.2309803
Validation loss decreased (0.215128 --> 0.208430).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.67s
Steps: 28 | Train Loss: 0.1843401 Vali Loss: 0.2045137 Test Loss: 0.2269140
Validation loss decreased (0.208430 --> 0.204514).  Saving model ...
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.65s
Steps: 28 | Train Loss: 0.1804253 Vali Loss: 0.2041298 Test Loss: 0.2235822
Validation loss decreased (0.204514 --> 0.204130).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.69s
Steps: 28 | Train Loss: 0.1777200 Vali Loss: 0.1969302 Test Loss: 0.2169832
Validation loss decreased (0.204130 --> 0.196930).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.66s
Steps: 28 | Train Loss: 0.1754926 Vali Loss: 0.1958101 Test Loss: 0.2159849
Validation loss decreased (0.196930 --> 0.195810).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.62s
Steps: 28 | Train Loss: 0.1723891 Vali Loss: 0.1938504 Test Loss: 0.2132314
Validation loss decreased (0.195810 --> 0.193850).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.65s
Steps: 28 | Train Loss: 0.1650979 Vali Loss: 0.1860104 Test Loss: 0.2066018
Validation loss decreased (0.193850 --> 0.186010).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.08583909273147583, rmse:0.2929830849170685, mae:0.20661520957946777, rse:1.0381808280944824
Original data scale mse:90432272.0, rmse:9509.5888671875, mae:6289.66015625, rse:0.47378408908843994
Use GPU: cuda:0
>>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6073
test 6073
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.2706786 Vali Loss: 0.2762237 Test Loss: 0.2973826
Validation loss decreased (inf --> 0.276224).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.2249503 Vali Loss: 0.2066383 Test Loss: 0.2302177
Validation loss decreased (0.276224 --> 0.206638).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.1780946 Vali Loss: 0.1838707 Test Loss: 0.2095166
Validation loss decreased (0.206638 --> 0.183871).  Saving model ...
Updating learning rate to 0.0001
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:28.63s
Steps: 28 | Train Loss: 0.1637856 Vali Loss: 0.1815404 Test Loss: 0.2054647
Validation loss decreased (0.183871 --> 0.181540).  Saving model ...
Updating learning rate to 9e-05
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.1575828 Vali Loss: 0.1823689 Test Loss: 0.2041115
EarlyStopping counter: 1 out of 3
Updating learning rate to 8.1e-05
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:28.69s
Steps: 28 | Train Loss: 0.1532559 Vali Loss: 0.1715331 Test Loss: 0.1925302
Validation loss decreased (0.181540 --> 0.171533).  Saving model ...
Updating learning rate to 7.290000000000001e-05
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:28.63s
Steps: 28 | Train Loss: 0.1501432 Vali Loss: 0.1685363 Test Loss: 0.1896459
Validation loss decreased (0.171533 --> 0.168536).  Saving model ...
Updating learning rate to 6.561e-05
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:28.69s
Steps: 28 | Train Loss: 0.1475339 Vali Loss: 0.1655381 Test Loss: 0.1862747
Validation loss decreased (0.168536 --> 0.165538).  Saving model ...
Updating learning rate to 5.904900000000001e-05
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:28.72s
Steps: 28 | Train Loss: 0.1455269 Vali Loss: 0.1653684 Test Loss: 0.1859854
Validation loss decreased (0.165538 --> 0.165368).  Saving model ...
Updating learning rate to 5.3144100000000005e-05
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:28.68s
Steps: 28 | Train Loss: 0.1439553 Vali Loss: 0.1643438 Test Loss: 0.1861979
Validation loss decreased (0.165368 --> 0.164344).  Saving model ...
Updating learning rate to 4.782969000000001e-05
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.0709955170750618, rmse:0.26644983887672424, mae:0.18616598844528198, rse:0.9441606998443604
Original data scale mse:67397576.0, rmse:8209.6025390625, mae:5481.0166015625, rse:0.40901654958724976

Extracted Metrics for DE, pred_len=168, iteration=1:
Scaled Metrics - MSE: 0.08583909273147583, RMSE: 0.2929830849170685, MAE: 0.20661520957946777, RSE: 1.0381808280944824
Unscaled Metrics - MSE: 90432272.0, RMSE: 9509.5888671875, MAE: 6289.66015625, RSE: 0.47378408908843994

Extracted Metrics for DE, pred_len=168, iteration=2:
Scaled Metrics - MSE: 0.0709955170750618, RMSE: 0.26644983887672424, MAE: 0.18616598844528198, RSE: 0.9441606998443604
Unscaled Metrics - MSE: 67397576.0, RMSE: 8209.6025390625, MAE: 5481.0166015625, RSE: 0.40901654958724976
