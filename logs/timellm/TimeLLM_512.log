
=== Starting experiments for country: DE ===

=== Starting experiments for pred_len: 24 ===

--- Running model for DE, pred_len=24 ---
train 143005
val 31085
test 31085
[2024-11-03 01:12:05,716] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 01:12:06,757] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 01:12:06,757] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 01:12:06,757] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 01:12:06,848] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 01:12:06,848] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 01:12:07,583] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 01:12:07,584] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 01:12:07,584] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 01:12:07,586] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 01:12:07,586] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 01:12:07,586] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 01:12:07,586] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 01:12:07,586] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 01:12:07,586] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 01:12:07,586] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 01:12:07,942] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 01:12:07,944] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 01:12:07,944] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 75.49 GB, percent = 10.0%
[2024-11-03 01:12:08,122] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 01:12:08,123] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 01:12:08,123] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 75.53 GB, percent = 10.0%
[2024-11-03 01:12:08,123] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 01:12:08,286] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 01:12:08,287] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 01:12:08,287] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 75.42 GB, percent = 10.0%
[2024-11-03 01:12:08,288] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 01:12:08,288] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 01:12:08,288] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 01:12:08,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 01:12:08,289] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 01:12:08,289] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 01:12:08,289] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1cacb059d0>
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 01:12:08,290] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 01:12:08,291] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 01:12:08,292] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 01:12:08,292] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1688982
	speed: 0.1674s/iter; left time: 14941.3446s
	iters: 200, epoch: 1 | loss: 0.1398762
	speed: 0.1227s/iter; left time: 10938.8876s
	iters: 300, epoch: 1 | loss: 0.1594033
	speed: 0.1246s/iter; left time: 11095.0762s
	iters: 400, epoch: 1 | loss: 0.1548022
	speed: 0.1240s/iter; left time: 11033.2634s
	iters: 500, epoch: 1 | loss: 0.1380969
	speed: 0.1244s/iter; left time: 11056.1716s
	iters: 600, epoch: 1 | loss: 0.1172558
	speed: 0.1254s/iter; left time: 11131.3914s
	iters: 700, epoch: 1 | loss: 0.1290968
	speed: 0.1249s/iter; left time: 11072.9375s
	iters: 800, epoch: 1 | loss: 0.1323915
	speed: 0.1237s/iter; left time: 10953.4734s
	iters: 900, epoch: 1 | loss: 0.0968730
	speed: 0.1241s/iter; left time: 10982.1952s
	iters: 1000, epoch: 1 | loss: 0.1262417
	speed: 0.1247s/iter; left time: 11018.8563s
	iters: 1100, epoch: 1 | loss: 0.1081160
	speed: 0.1254s/iter; left time: 11067.6072s
	iters: 1200, epoch: 1 | loss: 0.1055638
	speed: 0.1233s/iter; left time: 10866.4606s
	iters: 1300, epoch: 1 | loss: 0.0805435
	speed: 0.1236s/iter; left time: 10880.7501s
	iters: 1400, epoch: 1 | loss: 0.1116071
	speed: 0.1239s/iter; left time: 10895.0457s
	iters: 1500, epoch: 1 | loss: 0.0692826
	speed: 0.1238s/iter; left time: 10879.3045s
	iters: 1600, epoch: 1 | loss: 0.0953681
	speed: 0.1243s/iter; left time: 10905.0177s
	iters: 1700, epoch: 1 | loss: 0.1187560
	speed: 0.1228s/iter; left time: 10768.5576s
	iters: 1800, epoch: 1 | loss: 0.0991687
	speed: 0.1231s/iter; left time: 10777.3760s
	iters: 1900, epoch: 1 | loss: 0.1227836
	speed: 0.1242s/iter; left time: 10861.5365s
	iters: 2000, epoch: 1 | loss: 0.0913499
	speed: 0.1222s/iter; left time: 10676.2045s
	iters: 2100, epoch: 1 | loss: 0.0831885
	speed: 0.1243s/iter; left time: 10845.1859s
	iters: 2200, epoch: 1 | loss: 0.1006144
	speed: 0.1223s/iter; left time: 10662.3231s
	iters: 2300, epoch: 1 | loss: 0.1002881
	speed: 0.1232s/iter; left time: 10727.6874s
	iters: 2400, epoch: 1 | loss: 0.0858188
	speed: 0.1241s/iter; left time: 10787.8205s
	iters: 2500, epoch: 1 | loss: 0.0878481
	speed: 0.1233s/iter; left time: 10707.2554s
	iters: 2600, epoch: 1 | loss: 0.0938092
	speed: 0.1251s/iter; left time: 10856.3638s
	iters: 2700, epoch: 1 | loss: 0.1014624
	speed: 0.1246s/iter; left time: 10801.6068s
	iters: 2800, epoch: 1 | loss: 0.0828544
	speed: 0.1242s/iter; left time: 10747.8099s
	iters: 2900, epoch: 1 | loss: 0.0846184
	speed: 0.1240s/iter; left time: 10719.4482s
	iters: 3000, epoch: 1 | loss: 0.0732674
	speed: 0.1233s/iter; left time: 10648.1436s
	iters: 3100, epoch: 1 | loss: 0.0863261
	speed: 0.1233s/iter; left time: 10635.2736s
	iters: 3200, epoch: 1 | loss: 0.1145399
	speed: 0.1231s/iter; left time: 10606.0279s
	iters: 3300, epoch: 1 | loss: 0.0950736
	speed: 0.1244s/iter; left time: 10705.7121s
	iters: 3400, epoch: 1 | loss: 0.1013337
	speed: 0.1254s/iter; left time: 10783.4548s
	iters: 3500, epoch: 1 | loss: 0.0962714
	speed: 0.1234s/iter; left time: 10599.2676s
	iters: 3600, epoch: 1 | loss: 0.1045466
	speed: 0.1249s/iter; left time: 10713.2908s
	iters: 3700, epoch: 1 | loss: 0.0921188
	speed: 0.1228s/iter; left time: 10516.2821s
	iters: 3800, epoch: 1 | loss: 0.0915671
	speed: 0.1235s/iter; left time: 10562.9555s
	iters: 3900, epoch: 1 | loss: 0.1059835
	speed: 0.1255s/iter; left time: 10726.9688s
	iters: 4000, epoch: 1 | loss: 0.0626834
	speed: 0.1229s/iter; left time: 10488.5240s
	iters: 4100, epoch: 1 | loss: 0.0807726
	speed: 0.1229s/iter; left time: 10482.4050s
	iters: 4200, epoch: 1 | loss: 0.1075011
	speed: 0.1222s/iter; left time: 10402.4167s
	iters: 4300, epoch: 1 | loss: 0.0953812
	speed: 0.1234s/iter; left time: 10499.2678s
	iters: 4400, epoch: 1 | loss: 0.0955328
	speed: 0.1237s/iter; left time: 10509.4145s
Epoch: 1 cost time: 00h:09m:14.48s
Epoch: 1 | Train Loss: 0.1053388 Vali Loss: 0.0971123 Test Loss: 0.0994308
Validation loss decreased (inf --> 0.097112).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0704475
	speed: 1.7948s/iter; left time: 152182.9881s
	iters: 200, epoch: 2 | loss: 0.0855533
	speed: 0.1141s/iter; left time: 9659.3097s
	iters: 300, epoch: 2 | loss: 0.0774946
	speed: 0.1140s/iter; left time: 9640.4392s
	iters: 400, epoch: 2 | loss: 0.0883429
	speed: 0.1123s/iter; left time: 9491.7135s
	iters: 500, epoch: 2 | loss: 0.0867326
	speed: 0.1123s/iter; left time: 9475.7204s
	iters: 600, epoch: 2 | loss: 0.0939545
	speed: 0.1139s/iter; left time: 9597.7267s
	iters: 700, epoch: 2 | loss: 0.0739971
	speed: 0.1128s/iter; left time: 9497.3048s
	iters: 800, epoch: 2 | loss: 0.0977335
	speed: 0.1149s/iter; left time: 9664.4324s
	iters: 900, epoch: 2 | loss: 0.0857365
	speed: 0.1138s/iter; left time: 9555.0482s
	iters: 1000, epoch: 2 | loss: 0.0865258
	speed: 0.1149s/iter; left time: 9639.7231s
	iters: 1100, epoch: 2 | loss: 0.0972862
	speed: 0.1140s/iter; left time: 9554.6080s
	iters: 1200, epoch: 2 | loss: 0.0832878
	speed: 0.1144s/iter; left time: 9574.7462s
	iters: 1300, epoch: 2 | loss: 0.0947991
	speed: 0.1156s/iter; left time: 9662.8164s
	iters: 1400, epoch: 2 | loss: 0.0940965
	speed: 0.1154s/iter; left time: 9639.0286s
	iters: 1500, epoch: 2 | loss: 0.0825809
	speed: 0.1155s/iter; left time: 9628.6063s
	iters: 1600, epoch: 2 | loss: 0.0861147
	speed: 0.1136s/iter; left time: 9465.3499s
	iters: 1700, epoch: 2 | loss: 0.1065482
	speed: 0.1139s/iter; left time: 9479.3903s
	iters: 1800, epoch: 2 | loss: 0.0846911
	speed: 0.1132s/iter; left time: 9403.8697s
	iters: 1900, epoch: 2 | loss: 0.1024258
	speed: 0.1142s/iter; left time: 9480.0655s
	iters: 2000, epoch: 2 | loss: 0.0896808
	speed: 0.1129s/iter; left time: 9358.1236s
	iters: 2100, epoch: 2 | loss: 0.1056611
	speed: 0.1135s/iter; left time: 9397.8205s
	iters: 2200, epoch: 2 | loss: 0.0911830
	speed: 0.1128s/iter; left time: 9331.4414s
	iters: 2300, epoch: 2 | loss: 0.0980409
	speed: 0.1141s/iter; left time: 9421.8908s
	iters: 2400, epoch: 2 | loss: 0.0799288
	speed: 0.1155s/iter; left time: 9529.0887s
	iters: 2500, epoch: 2 | loss: 0.0872002
	speed: 0.1140s/iter; left time: 9391.3248s
	iters: 2600, epoch: 2 | loss: 0.0915525
	speed: 0.1120s/iter; left time: 9218.2102s
	iters: 2700, epoch: 2 | loss: 0.1013657
	speed: 0.1136s/iter; left time: 9339.5619s
	iters: 2800, epoch: 2 | loss: 0.0794303
	speed: 0.1132s/iter; left time: 9294.8333s
	iters: 2900, epoch: 2 | loss: 0.0900755
	speed: 0.1148s/iter; left time: 9411.2400s
	iters: 3000, epoch: 2 | loss: 0.0776787
	speed: 0.1129s/iter; left time: 9244.6546s
	iters: 3100, epoch: 2 | loss: 0.1028968
	speed: 0.1133s/iter; left time: 9268.9056s
	iters: 3200, epoch: 2 | loss: 0.0771540
	speed: 0.1152s/iter; left time: 9411.0392s
	iters: 3300, epoch: 2 | loss: 0.0871339
	speed: 0.1157s/iter; left time: 9437.3403s
	iters: 3400, epoch: 2 | loss: 0.1009780
	speed: 0.1145s/iter; left time: 9332.5256s
	iters: 3500, epoch: 2 | loss: 0.0891745
	speed: 0.1149s/iter; left time: 9348.6727s
	iters: 3600, epoch: 2 | loss: 0.0985909
	speed: 0.1155s/iter; left time: 9389.6240s
	iters: 3700, epoch: 2 | loss: 0.1067271
	speed: 0.1178s/iter; left time: 9560.6694s
	iters: 3800, epoch: 2 | loss: 0.0852604
	speed: 0.1159s/iter; left time: 9395.5152s
	iters: 3900, epoch: 2 | loss: 0.0817025
	speed: 0.1128s/iter; left time: 9132.8653s
	iters: 4000, epoch: 2 | loss: 0.0846763
	speed: 0.1128s/iter; left time: 9121.4540s
	iters: 4100, epoch: 2 | loss: 0.0871173
	speed: 0.1136s/iter; left time: 9175.4806s
	iters: 4200, epoch: 2 | loss: 0.0959664
	speed: 0.1137s/iter; left time: 9174.5179s
	iters: 4300, epoch: 2 | loss: 0.0784686
	speed: 0.1134s/iter; left time: 9141.7126s
	iters: 4400, epoch: 2 | loss: 0.0950680
	speed: 0.1138s/iter; left time: 9156.8940s
Epoch: 2 cost time: 00h:08m:30.16s
Epoch: 2 | Train Loss: 0.0889246 Vali Loss: 0.0918921 Test Loss: 0.0945349
Validation loss decreased (0.097112 --> 0.091892).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1014844
	speed: 1.6040s/iter; left time: 128842.4170s
	iters: 200, epoch: 3 | loss: 0.0968780
	speed: 0.1137s/iter; left time: 9122.6059s
	iters: 300, epoch: 3 | loss: 0.0694327
	speed: 0.1162s/iter; left time: 9306.7944s
	iters: 400, epoch: 3 | loss: 0.0818534
	speed: 0.1131s/iter; left time: 9049.8084s
	iters: 500, epoch: 3 | loss: 0.1179019
	speed: 0.1105s/iter; left time: 8835.4020s
	iters: 600, epoch: 3 | loss: 0.0902409
	speed: 0.1127s/iter; left time: 8993.7143s
	iters: 700, epoch: 3 | loss: 0.0945199
	speed: 0.1126s/iter; left time: 8973.5594s
	iters: 800, epoch: 3 | loss: 0.0943223
	speed: 0.1126s/iter; left time: 8965.1199s
	iters: 900, epoch: 3 | loss: 0.0608129
	speed: 0.1143s/iter; left time: 9089.2406s
	iters: 1000, epoch: 3 | loss: 0.0815312
	speed: 0.1142s/iter; left time: 9067.5614s
	iters: 1100, epoch: 3 | loss: 0.0903181
	speed: 0.1137s/iter; left time: 9020.1890s
	iters: 1200, epoch: 3 | loss: 0.0806858
	speed: 0.1142s/iter; left time: 9044.4942s
	iters: 1300, epoch: 3 | loss: 0.0762755
	speed: 0.1140s/iter; left time: 9017.3213s
	iters: 1400, epoch: 3 | loss: 0.0923751
	speed: 0.1116s/iter; left time: 8821.8508s
	iters: 1500, epoch: 3 | loss: 0.0904863
	speed: 0.1127s/iter; left time: 8895.6489s
	iters: 1600, epoch: 3 | loss: 0.0592667
	speed: 0.1135s/iter; left time: 8942.9849s
	iters: 1700, epoch: 3 | loss: 0.0708085
	speed: 0.1157s/iter; left time: 9110.4364s
	iters: 1800, epoch: 3 | loss: 0.0865551
	speed: 0.1119s/iter; left time: 8795.0520s
	iters: 1900, epoch: 3 | loss: 0.0666124
	speed: 0.1124s/iter; left time: 8822.9030s
	iters: 2000, epoch: 3 | loss: 0.0717531
	speed: 0.1142s/iter; left time: 8953.9096s
	iters: 2100, epoch: 3 | loss: 0.1037164
	speed: 0.1134s/iter; left time: 8884.8049s
	iters: 2200, epoch: 3 | loss: 0.0819335
	speed: 0.1118s/iter; left time: 8748.3673s
	iters: 2300, epoch: 3 | loss: 0.0837101
	speed: 0.1114s/iter; left time: 8701.8710s
	iters: 2400, epoch: 3 | loss: 0.0792184
	speed: 0.1116s/iter; left time: 8710.8425s
	iters: 2500, epoch: 3 | loss: 0.0968816
	speed: 0.1135s/iter; left time: 8845.6248s
	iters: 2600, epoch: 3 | loss: 0.0933213
	speed: 0.1132s/iter; left time: 8806.5863s
	iters: 2700, epoch: 3 | loss: 0.0743180
	speed: 0.1126s/iter; left time: 8748.4160s
	iters: 2800, epoch: 3 | loss: 0.0937308
	speed: 0.1126s/iter; left time: 8740.1547s
	iters: 2900, epoch: 3 | loss: 0.0838305
	speed: 0.1137s/iter; left time: 8813.0296s
	iters: 3000, epoch: 3 | loss: 0.0647273
	speed: 0.1146s/iter; left time: 8875.4268s
	iters: 3100, epoch: 3 | loss: 0.0913395
	speed: 0.1137s/iter; left time: 8793.1195s
	iters: 3200, epoch: 3 | loss: 0.0819122
	speed: 0.1131s/iter; left time: 8732.8662s
	iters: 3300, epoch: 3 | loss: 0.0788185
	speed: 0.1123s/iter; left time: 8659.5411s
	iters: 3400, epoch: 3 | loss: 0.0784381
	speed: 0.1121s/iter; left time: 8636.4983s
	iters: 3500, epoch: 3 | loss: 0.0678186
	speed: 0.1117s/iter; left time: 8588.7881s
	iters: 3600, epoch: 3 | loss: 0.0698414
	speed: 0.1137s/iter; left time: 8736.1703s
	iters: 3700, epoch: 3 | loss: 0.0900844
	speed: 0.1122s/iter; left time: 8606.1957s
	iters: 3800, epoch: 3 | loss: 0.0756922
	speed: 0.1149s/iter; left time: 8805.2898s
	iters: 3900, epoch: 3 | loss: 0.0685307
	speed: 0.1125s/iter; left time: 8610.4216s
	iters: 4000, epoch: 3 | loss: 0.0735308
	speed: 0.1119s/iter; left time: 8552.9052s
	iters: 4100, epoch: 3 | loss: 0.0800254
	speed: 0.1119s/iter; left time: 8542.2113s
	iters: 4200, epoch: 3 | loss: 0.0855180
	speed: 0.1154s/iter; left time: 8796.0084s
	iters: 4300, epoch: 3 | loss: 0.0667157
	speed: 0.1144s/iter; left time: 8708.6890s
	iters: 4400, epoch: 3 | loss: 0.0843554
	speed: 0.1124s/iter; left time: 8544.1850s
Epoch: 3 cost time: 00h:08m:26.09s
Epoch: 3 | Train Loss: 0.0853331 Vali Loss: 0.0911640 Test Loss: 0.0942841
Validation loss decreased (0.091892 --> 0.091164).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0739329
	speed: 1.5815s/iter; left time: 119968.3080s
	iters: 200, epoch: 4 | loss: 0.1006263
	speed: 0.1141s/iter; left time: 8647.2176s
	iters: 300, epoch: 4 | loss: 0.0738416
	speed: 0.1155s/iter; left time: 8739.9632s
	iters: 400, epoch: 4 | loss: 0.0781351
	speed: 0.1131s/iter; left time: 8548.7698s
	iters: 500, epoch: 4 | loss: 0.0675929
	speed: 0.1151s/iter; left time: 8687.4375s
	iters: 600, epoch: 4 | loss: 0.0722866
	speed: 0.1138s/iter; left time: 8578.3459s
	iters: 700, epoch: 4 | loss: 0.0852794
	speed: 0.1146s/iter; left time: 8627.3161s
	iters: 800, epoch: 4 | loss: 0.0830615
	speed: 0.1136s/iter; left time: 8539.2426s
	iters: 900, epoch: 4 | loss: 0.0746369
	speed: 0.1127s/iter; left time: 8458.1302s
	iters: 1000, epoch: 4 | loss: 0.0714534
	speed: 0.1134s/iter; left time: 8499.4897s
	iters: 1100, epoch: 4 | loss: 0.0721987
	speed: 0.1133s/iter; left time: 8483.5015s
	iters: 1200, epoch: 4 | loss: 0.0848372
	speed: 0.1142s/iter; left time: 8540.1918s
	iters: 1300, epoch: 4 | loss: 0.0901184
	speed: 0.1126s/iter; left time: 8406.3739s
	iters: 1400, epoch: 4 | loss: 0.0873635
	speed: 0.1127s/iter; left time: 8402.5782s
	iters: 1500, epoch: 4 | loss: 0.0672005
	speed: 0.1121s/iter; left time: 8348.9412s
	iters: 1600, epoch: 4 | loss: 0.0815371
	speed: 0.1119s/iter; left time: 8321.4581s
	iters: 1700, epoch: 4 | loss: 0.0967667
	speed: 0.1143s/iter; left time: 8487.8214s
	iters: 1800, epoch: 4 | loss: 0.1003437
	speed: 0.1123s/iter; left time: 8328.0192s
	iters: 1900, epoch: 4 | loss: 0.0772678
	speed: 0.1121s/iter; left time: 8303.8600s
	iters: 2000, epoch: 4 | loss: 0.1023371
	speed: 0.1112s/iter; left time: 8226.3107s
	iters: 2100, epoch: 4 | loss: 0.0959407
	speed: 0.1126s/iter; left time: 8313.9698s
	iters: 2200, epoch: 4 | loss: 0.0707141
	speed: 0.1121s/iter; left time: 8266.0775s
	iters: 2300, epoch: 4 | loss: 0.1181110
	speed: 0.1130s/iter; left time: 8323.1719s
	iters: 2400, epoch: 4 | loss: 0.0988108
	speed: 0.1115s/iter; left time: 8201.0479s
	iters: 2500, epoch: 4 | loss: 0.1022194
	speed: 0.1111s/iter; left time: 8160.0609s
	iters: 2600, epoch: 4 | loss: 0.0755848
	speed: 0.1114s/iter; left time: 8168.9965s
	iters: 2700, epoch: 4 | loss: 0.0852136
	speed: 0.1122s/iter; left time: 8220.4746s
	iters: 2800, epoch: 4 | loss: 0.1073938
	speed: 0.1111s/iter; left time: 8125.4232s
	iters: 2900, epoch: 4 | loss: 0.0776819
	speed: 0.1122s/iter; left time: 8200.1518s
	iters: 3000, epoch: 4 | loss: 0.0915424
	speed: 0.1117s/iter; left time: 8146.3091s
	iters: 3100, epoch: 4 | loss: 0.0914509
	speed: 0.1155s/iter; left time: 8412.5511s
	iters: 3200, epoch: 4 | loss: 0.0769955
	speed: 0.1168s/iter; left time: 8498.2199s
	iters: 3300, epoch: 4 | loss: 0.0912195
	speed: 0.1177s/iter; left time: 8550.1338s
	iters: 3400, epoch: 4 | loss: 0.0864609
	speed: 0.1169s/iter; left time: 8485.3160s
	iters: 3500, epoch: 4 | loss: 0.0855569
	speed: 0.1181s/iter; left time: 8557.3971s
	iters: 3600, epoch: 4 | loss: 0.0880700
	speed: 0.1181s/iter; left time: 8544.6155s
	iters: 3700, epoch: 4 | loss: 0.0775939
	speed: 0.1193s/iter; left time: 8618.5048s
	iters: 3800, epoch: 4 | loss: 0.0855137
	speed: 0.1171s/iter; left time: 8451.2831s
	iters: 3900, epoch: 4 | loss: 0.0877626
	speed: 0.1153s/iter; left time: 8308.4451s
	iters: 4000, epoch: 4 | loss: 0.0802846
	speed: 0.1172s/iter; left time: 8436.5780s
	iters: 4100, epoch: 4 | loss: 0.0870235
	speed: 0.1202s/iter; left time: 8634.0718s
	iters: 4200, epoch: 4 | loss: 0.0716099
	speed: 0.1207s/iter; left time: 8660.1850s
	iters: 4300, epoch: 4 | loss: 0.0780072
	speed: 0.1156s/iter; left time: 8281.9815s
	iters: 4400, epoch: 4 | loss: 0.0948033
	speed: 0.1183s/iter; left time: 8463.4481s
Epoch: 4 cost time: 00h:08m:31.84s
Epoch: 4 | Train Loss: 0.0836256 Vali Loss: 0.0897763 Test Loss: 0.0933365
Validation loss decreased (0.091164 --> 0.089776).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0797964
	speed: 1.6464s/iter; left time: 117532.0136s
	iters: 200, epoch: 5 | loss: 0.0838478
	speed: 0.1194s/iter; left time: 8512.3885s
	iters: 300, epoch: 5 | loss: 0.0742453
	speed: 0.1179s/iter; left time: 8390.0387s
	iters: 400, epoch: 5 | loss: 0.0888728
	speed: 0.1203s/iter; left time: 8551.0436s
	iters: 500, epoch: 5 | loss: 0.0898506
	speed: 0.1186s/iter; left time: 8422.4576s
	iters: 600, epoch: 5 | loss: 0.0773116
	speed: 0.1140s/iter; left time: 8081.0151s
	iters: 700, epoch: 5 | loss: 0.0626944
	speed: 0.1191s/iter; left time: 8430.4481s
	iters: 800, epoch: 5 | loss: 0.0781008
	speed: 0.1205s/iter; left time: 8519.7659s
	iters: 900, epoch: 5 | loss: 0.0825634
	speed: 0.1205s/iter; left time: 8509.4591s
	iters: 1000, epoch: 5 | loss: 0.0848518
	speed: 0.1189s/iter; left time: 8377.6728s
	iters: 1100, epoch: 5 | loss: 0.0829829
	speed: 0.1204s/iter; left time: 8472.5536s
	iters: 1200, epoch: 5 | loss: 0.0997171
	speed: 0.1201s/iter; left time: 8443.6639s
	iters: 1300, epoch: 5 | loss: 0.0798143
	speed: 0.1197s/iter; left time: 8402.1515s
	iters: 1400, epoch: 5 | loss: 0.0764720
	speed: 0.1176s/iter; left time: 8243.6340s
	iters: 1500, epoch: 5 | loss: 0.0732888
	speed: 0.1193s/iter; left time: 8351.0889s
	iters: 1600, epoch: 5 | loss: 0.0836849
	speed: 0.1157s/iter; left time: 8085.6975s
	iters: 1700, epoch: 5 | loss: 0.0724503
	speed: 0.1156s/iter; left time: 8069.1478s
	iters: 1800, epoch: 5 | loss: 0.0894237
	speed: 0.1198s/iter; left time: 8348.4672s
	iters: 1900, epoch: 5 | loss: 0.0685364
	speed: 0.1178s/iter; left time: 8200.5653s
	iters: 2000, epoch: 5 | loss: 0.0697801
	speed: 0.1175s/iter; left time: 8164.8331s
	iters: 2100, epoch: 5 | loss: 0.0814900
	speed: 0.1169s/iter; left time: 8113.5792s
	iters: 2200, epoch: 5 | loss: 0.0934933
	speed: 0.1142s/iter; left time: 7911.7020s
	iters: 2300, epoch: 5 | loss: 0.0861936
	speed: 0.1145s/iter; left time: 7919.7570s
	iters: 2400, epoch: 5 | loss: 0.0938417
	speed: 0.1149s/iter; left time: 7940.1099s
	iters: 2500, epoch: 5 | loss: 0.0799977
	speed: 0.1189s/iter; left time: 8205.5438s
	iters: 2600, epoch: 5 | loss: 0.0855416
	speed: 0.1195s/iter; left time: 8229.9662s
	iters: 2700, epoch: 5 | loss: 0.0920220
	speed: 0.1158s/iter; left time: 7968.0307s
	iters: 2800, epoch: 5 | loss: 0.0856894
	speed: 0.1187s/iter; left time: 8154.6670s
	iters: 2900, epoch: 5 | loss: 0.0774287
	speed: 0.1181s/iter; left time: 8098.6651s
	iters: 3000, epoch: 5 | loss: 0.0683412
	speed: 0.1165s/iter; left time: 7976.2434s
	iters: 3100, epoch: 5 | loss: 0.0973268
	speed: 0.1172s/iter; left time: 8015.3452s
	iters: 3200, epoch: 5 | loss: 0.0831058
	speed: 0.1146s/iter; left time: 7827.2519s
	iters: 3300, epoch: 5 | loss: 0.0682414
	speed: 0.1170s/iter; left time: 7980.1976s
	iters: 3400, epoch: 5 | loss: 0.0845700
	speed: 0.1196s/iter; left time: 8140.1191s
	iters: 3500, epoch: 5 | loss: 0.0771565
	speed: 0.1187s/iter; left time: 8072.2449s
	iters: 3600, epoch: 5 | loss: 0.0795133
	speed: 0.1174s/iter; left time: 7969.1133s
	iters: 3700, epoch: 5 | loss: 0.0733312
	speed: 0.1185s/iter; left time: 8031.3167s
	iters: 3800, epoch: 5 | loss: 0.0908493
	speed: 0.1188s/iter; left time: 8044.7092s
	iters: 3900, epoch: 5 | loss: 0.0670330
	speed: 0.1188s/iter; left time: 8032.0109s
	iters: 4000, epoch: 5 | loss: 0.0631396
	speed: 0.1181s/iter; left time: 7969.3271s
	iters: 4100, epoch: 5 | loss: 0.0828409
	speed: 0.1209s/iter; left time: 8148.0262s
	iters: 4200, epoch: 5 | loss: 0.0800139
	speed: 0.1177s/iter; left time: 7917.2847s
	iters: 4300, epoch: 5 | loss: 0.0884054
	speed: 0.1186s/iter; left time: 7967.7376s
	iters: 4400, epoch: 5 | loss: 0.0831661
	speed: 0.1184s/iter; left time: 7943.2696s
Epoch: 5 cost time: 00h:08m:48.26s
Epoch: 5 | Train Loss: 0.0823728 Vali Loss: 0.0899557 Test Loss: 0.0942943
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1001324
	speed: 1.6218s/iter; left time: 108534.5492s
	iters: 200, epoch: 6 | loss: 0.0886922
	speed: 0.1213s/iter; left time: 8105.9663s
	iters: 300, epoch: 6 | loss: 0.0843214
	speed: 0.1200s/iter; left time: 8005.3656s
	iters: 400, epoch: 6 | loss: 0.0734667
	speed: 0.1185s/iter; left time: 7896.9387s
	iters: 500, epoch: 6 | loss: 0.0924280
	speed: 0.1199s/iter; left time: 7979.1377s
	iters: 600, epoch: 6 | loss: 0.0591974
	speed: 0.1180s/iter; left time: 7835.7974s
	iters: 700, epoch: 6 | loss: 0.0633274
	speed: 0.1191s/iter; left time: 7899.5425s
	iters: 800, epoch: 6 | loss: 0.0738303
	speed: 0.1198s/iter; left time: 7930.7576s
	iters: 900, epoch: 6 | loss: 0.1071520
	speed: 0.1218s/iter; left time: 8053.4950s
	iters: 1000, epoch: 6 | loss: 0.0735545
	speed: 0.1204s/iter; left time: 7946.3154s
	iters: 1100, epoch: 6 | loss: 0.0729964
	speed: 0.1196s/iter; left time: 7881.9557s
	iters: 1200, epoch: 6 | loss: 0.0962333
	speed: 0.1199s/iter; left time: 7892.1226s
	iters: 1300, epoch: 6 | loss: 0.0923874
	speed: 0.1202s/iter; left time: 7901.9868s
	iters: 1400, epoch: 6 | loss: 0.0971264
	speed: 0.1218s/iter; left time: 7992.7890s
	iters: 1500, epoch: 6 | loss: 0.0751228
	speed: 0.1189s/iter; left time: 7790.8841s
	iters: 1600, epoch: 6 | loss: 0.0779485
	speed: 0.1172s/iter; left time: 7668.9793s
	iters: 1700, epoch: 6 | loss: 0.0823796
	speed: 0.1168s/iter; left time: 7627.4802s
	iters: 1800, epoch: 6 | loss: 0.0782527
	speed: 0.1174s/iter; left time: 7659.5757s
	iters: 1900, epoch: 6 | loss: 0.0854593
	speed: 0.1211s/iter; left time: 7887.2417s
	iters: 2000, epoch: 6 | loss: 0.0940582
	speed: 0.1216s/iter; left time: 7906.6408s
	iters: 2100, epoch: 6 | loss: 0.0806722
	speed: 0.1156s/iter; left time: 7503.7319s
	iters: 2200, epoch: 6 | loss: 0.0820966
	speed: 0.1188s/iter; left time: 7698.6315s
	iters: 2300, epoch: 6 | loss: 0.0738427
	speed: 0.1190s/iter; left time: 7704.3061s
	iters: 2400, epoch: 6 | loss: 0.0772219
	speed: 0.1199s/iter; left time: 7749.0500s
	iters: 2500, epoch: 6 | loss: 0.0898360
	speed: 0.1188s/iter; left time: 7662.1246s
	iters: 2600, epoch: 6 | loss: 0.0820411
	speed: 0.1181s/iter; left time: 7605.2153s
	iters: 2700, epoch: 6 | loss: 0.0796860
	speed: 0.1185s/iter; left time: 7624.4024s
	iters: 2800, epoch: 6 | loss: 0.0989802
	speed: 0.1191s/iter; left time: 7649.2150s
	iters: 2900, epoch: 6 | loss: 0.0941869
	speed: 0.1154s/iter; left time: 7401.6936s
	iters: 3000, epoch: 6 | loss: 0.0823741
	speed: 0.1177s/iter; left time: 7534.3386s
	iters: 3100, epoch: 6 | loss: 0.0726927
	speed: 0.1189s/iter; left time: 7598.8294s
	iters: 3200, epoch: 6 | loss: 0.0867132
	speed: 0.1197s/iter; left time: 7638.2616s
	iters: 3300, epoch: 6 | loss: 0.0877910
	speed: 0.1177s/iter; left time: 7499.8711s
	iters: 3400, epoch: 6 | loss: 0.1008532
	speed: 0.1194s/iter; left time: 7595.2404s
	iters: 3500, epoch: 6 | loss: 0.0882527
	speed: 0.1193s/iter; left time: 7575.1135s
	iters: 3600, epoch: 6 | loss: 0.0798398
	speed: 0.1182s/iter; left time: 7498.4859s
	iters: 3700, epoch: 6 | loss: 0.0708239
	speed: 0.1203s/iter; left time: 7614.6941s
	iters: 3800, epoch: 6 | loss: 0.0720952
	speed: 0.1156s/iter; left time: 7310.8871s
	iters: 3900, epoch: 6 | loss: 0.0832081
	speed: 0.1173s/iter; left time: 7402.6487s
	iters: 4000, epoch: 6 | loss: 0.0772891
	speed: 0.1173s/iter; left time: 7395.4665s
	iters: 4100, epoch: 6 | loss: 0.0615834
	speed: 0.1181s/iter; left time: 7433.2315s
	iters: 4200, epoch: 6 | loss: 0.0647544
	speed: 0.1197s/iter; left time: 7521.8139s
	iters: 4300, epoch: 6 | loss: 0.0650132
	speed: 0.1182s/iter; left time: 7414.9879s
	iters: 4400, epoch: 6 | loss: 0.0766972
	speed: 0.1205s/iter; left time: 7544.8569s
Epoch: 6 cost time: 00h:08m:52.30s
Epoch: 6 | Train Loss: 0.0813646 Vali Loss: 0.0895673 Test Loss: 0.0940461
Validation loss decreased (0.089776 --> 0.089567).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0841343
	speed: 1.6530s/iter; left time: 103235.3819s
	iters: 200, epoch: 7 | loss: 0.0774401
	speed: 0.1200s/iter; left time: 7484.1355s
	iters: 300, epoch: 7 | loss: 0.0646475
	speed: 0.1200s/iter; left time: 7471.3773s
	iters: 400, epoch: 7 | loss: 0.0766103
	speed: 0.1180s/iter; left time: 7334.7613s
	iters: 500, epoch: 7 | loss: 0.0919630
	speed: 0.1200s/iter; left time: 7444.7187s
	iters: 600, epoch: 7 | loss: 0.0806891
	speed: 0.1211s/iter; left time: 7504.7698s
	iters: 700, epoch: 7 | loss: 0.0947759
	speed: 0.1203s/iter; left time: 7441.6268s
	iters: 800, epoch: 7 | loss: 0.0886568
	speed: 0.1175s/iter; left time: 7256.5548s
	iters: 900, epoch: 7 | loss: 0.0786587
	speed: 0.1190s/iter; left time: 7336.4875s
	iters: 1000, epoch: 7 | loss: 0.0800228
	speed: 0.1187s/iter; left time: 7306.3839s
	iters: 1100, epoch: 7 | loss: 0.0899325
	speed: 0.1206s/iter; left time: 7411.1211s
	iters: 1200, epoch: 7 | loss: 0.0851249
	speed: 0.1214s/iter; left time: 7446.7356s
	iters: 1300, epoch: 7 | loss: 0.0694570
	speed: 0.1176s/iter; left time: 7206.4126s
	iters: 1400, epoch: 7 | loss: 0.0889620
	speed: 0.1177s/iter; left time: 7198.9649s
	iters: 1500, epoch: 7 | loss: 0.0885222
	speed: 0.1168s/iter; left time: 7131.5664s
	iters: 1600, epoch: 7 | loss: 0.0703967
	speed: 0.1198s/iter; left time: 7302.7558s
	iters: 1700, epoch: 7 | loss: 0.0967138
	speed: 0.1184s/iter; left time: 7206.5879s
	iters: 1800, epoch: 7 | loss: 0.0742753
	speed: 0.1198s/iter; left time: 7275.4256s
	iters: 1900, epoch: 7 | loss: 0.0714891
	speed: 0.1200s/iter; left time: 7276.5838s
	iters: 2000, epoch: 7 | loss: 0.0690335
	speed: 0.1203s/iter; left time: 7285.5115s
	iters: 2100, epoch: 7 | loss: 0.0778978
	speed: 0.1159s/iter; left time: 7006.8084s
	iters: 2200, epoch: 7 | loss: 0.0716214
	speed: 0.1175s/iter; left time: 7091.8659s
	iters: 2300, epoch: 7 | loss: 0.0747692
	speed: 0.1168s/iter; left time: 7040.1868s
	iters: 2400, epoch: 7 | loss: 0.0834282
	speed: 0.1175s/iter; left time: 7065.8316s
	iters: 2500, epoch: 7 | loss: 0.0855097
	speed: 0.1192s/iter; left time: 7161.0485s
	iters: 2600, epoch: 7 | loss: 0.0906422
	speed: 0.1192s/iter; left time: 7149.1376s
	iters: 2700, epoch: 7 | loss: 0.0708709
	speed: 0.1180s/iter; left time: 7059.7972s
	iters: 2800, epoch: 7 | loss: 0.0859929
	speed: 0.1210s/iter; left time: 7230.0027s
	iters: 2900, epoch: 7 | loss: 0.0687493
	speed: 0.1198s/iter; left time: 7147.2599s
	iters: 3000, epoch: 7 | loss: 0.0796787
	speed: 0.1212s/iter; left time: 7216.8474s
	iters: 3100, epoch: 7 | loss: 0.0671332
	speed: 0.1196s/iter; left time: 7109.6244s
	iters: 3200, epoch: 7 | loss: 0.0683739
	speed: 0.1167s/iter; left time: 6927.9818s
	iters: 3300, epoch: 7 | loss: 0.0691068
	speed: 0.1165s/iter; left time: 6902.6622s
	iters: 3400, epoch: 7 | loss: 0.0798232
	speed: 0.1187s/iter; left time: 7021.1931s
	iters: 3500, epoch: 7 | loss: 0.0687565
	speed: 0.1172s/iter; left time: 6919.3256s
	iters: 3600, epoch: 7 | loss: 0.0730739
	speed: 0.1182s/iter; left time: 6967.3658s
	iters: 3700, epoch: 7 | loss: 0.0768365
	speed: 0.1170s/iter; left time: 6888.0754s
	iters: 3800, epoch: 7 | loss: 0.0917242
	speed: 0.1202s/iter; left time: 7063.0170s
	iters: 3900, epoch: 7 | loss: 0.0721889
	speed: 0.1199s/iter; left time: 7035.1511s
	iters: 4000, epoch: 7 | loss: 0.1057147
	speed: 0.1143s/iter; left time: 6692.7616s
	iters: 4100, epoch: 7 | loss: 0.0877508
	speed: 0.1129s/iter; left time: 6600.3418s
	iters: 4200, epoch: 7 | loss: 0.0842020
	speed: 0.1130s/iter; left time: 6595.8754s
	iters: 4300, epoch: 7 | loss: 0.0788388
	speed: 0.1125s/iter; left time: 6555.2348s
	iters: 4400, epoch: 7 | loss: 0.0780672
	speed: 0.1129s/iter; left time: 6565.9990s
Epoch: 7 cost time: 00h:08m:48.62s
Epoch: 7 | Train Loss: 0.0802900 Vali Loss: 0.0892569 Test Loss: 0.0938624
Validation loss decreased (0.089567 --> 0.089257).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0878868
	speed: 1.5867s/iter; left time: 92005.2740s
	iters: 200, epoch: 8 | loss: 0.0819466
	speed: 0.1146s/iter; left time: 6632.6594s
	iters: 300, epoch: 8 | loss: 0.0872314
	speed: 0.1134s/iter; left time: 6552.0696s
	iters: 400, epoch: 8 | loss: 0.0871727
	speed: 0.1149s/iter; left time: 6629.7226s
	iters: 500, epoch: 8 | loss: 0.0690386
	speed: 0.1146s/iter; left time: 6600.8306s
	iters: 600, epoch: 8 | loss: 0.0786107
	speed: 0.1151s/iter; left time: 6617.8909s
	iters: 700, epoch: 8 | loss: 0.0654001
	speed: 0.1152s/iter; left time: 6608.6635s
	iters: 800, epoch: 8 | loss: 0.0706811
	speed: 0.1148s/iter; left time: 6578.6997s
	iters: 900, epoch: 8 | loss: 0.0823400
	speed: 0.1177s/iter; left time: 6731.2845s
	iters: 1000, epoch: 8 | loss: 0.0656414
	speed: 0.1133s/iter; left time: 6466.9469s
	iters: 1100, epoch: 8 | loss: 0.0717802
	speed: 0.1147s/iter; left time: 6537.9668s
	iters: 1200, epoch: 8 | loss: 0.0914649
	speed: 0.1137s/iter; left time: 6465.6763s
	iters: 1300, epoch: 8 | loss: 0.0788195
	speed: 0.1150s/iter; left time: 6529.7991s
	iters: 1400, epoch: 8 | loss: 0.0938862
	speed: 0.1143s/iter; left time: 6480.2686s
	iters: 1500, epoch: 8 | loss: 0.0883940
	speed: 0.1134s/iter; left time: 6417.5553s
	iters: 1600, epoch: 8 | loss: 0.0923529
	speed: 0.1169s/iter; left time: 6605.7957s
	iters: 1700, epoch: 8 | loss: 0.1006962
	speed: 0.1165s/iter; left time: 6570.9238s
	iters: 1800, epoch: 8 | loss: 0.0933289
	speed: 0.1140s/iter; left time: 6417.5089s
	iters: 1900, epoch: 8 | loss: 0.0580641
	speed: 0.1138s/iter; left time: 6393.3432s
	iters: 2000, epoch: 8 | loss: 0.0778803
	speed: 0.1146s/iter; left time: 6429.3977s
	iters: 2100, epoch: 8 | loss: 0.0813645
	speed: 0.1118s/iter; left time: 6261.6275s
	iters: 2200, epoch: 8 | loss: 0.0837200
	speed: 0.1152s/iter; left time: 6438.9706s
	iters: 2300, epoch: 8 | loss: 0.0852636
	speed: 0.1148s/iter; left time: 6404.3086s
	iters: 2400, epoch: 8 | loss: 0.0721436
	speed: 0.1121s/iter; left time: 6240.5479s
	iters: 2500, epoch: 8 | loss: 0.0740744
	speed: 0.1138s/iter; left time: 6324.6577s
	iters: 2600, epoch: 8 | loss: 0.0824070
	speed: 0.1133s/iter; left time: 6285.7820s
	iters: 2700, epoch: 8 | loss: 0.0793054
	speed: 0.1134s/iter; left time: 6278.7559s
	iters: 2800, epoch: 8 | loss: 0.0864588
	speed: 0.1141s/iter; left time: 6305.7187s
	iters: 2900, epoch: 8 | loss: 0.0741376
	speed: 0.1149s/iter; left time: 6342.0597s
	iters: 3000, epoch: 8 | loss: 0.0899623
	speed: 0.1143s/iter; left time: 6298.8285s
	iters: 3100, epoch: 8 | loss: 0.0805951
	speed: 0.1152s/iter; left time: 6334.0774s
	iters: 3200, epoch: 8 | loss: 0.0612919
	speed: 0.1161s/iter; left time: 6371.3833s
	iters: 3300, epoch: 8 | loss: 0.0753164
	speed: 0.1166s/iter; left time: 6387.3990s
	iters: 3400, epoch: 8 | loss: 0.0797729
	speed: 0.1152s/iter; left time: 6298.6305s
	iters: 3500, epoch: 8 | loss: 0.0591326
	speed: 0.1120s/iter; left time: 6112.7558s
	iters: 3600, epoch: 8 | loss: 0.0769536
	speed: 0.1158s/iter; left time: 6309.2520s
	iters: 3700, epoch: 8 | loss: 0.0768749
	speed: 0.1139s/iter; left time: 6192.3924s
	iters: 3800, epoch: 8 | loss: 0.0756438
	speed: 0.1140s/iter; left time: 6185.8640s
	iters: 3900, epoch: 8 | loss: 0.0782435
	speed: 0.1146s/iter; left time: 6211.7814s
	iters: 4000, epoch: 8 | loss: 0.0735168
	speed: 0.1134s/iter; left time: 6135.4879s
	iters: 4100, epoch: 8 | loss: 0.0852071
	speed: 0.1144s/iter; left time: 6174.2145s
	iters: 4200, epoch: 8 | loss: 0.0820105
	speed: 0.1162s/iter; left time: 6259.5710s
	iters: 4300, epoch: 8 | loss: 0.0806806
	speed: 0.1163s/iter; left time: 6256.4244s
	iters: 4400, epoch: 8 | loss: 0.0883520
	speed: 0.1131s/iter; left time: 6069.3030s
Epoch: 8 cost time: 00h:08m:32.31s
Epoch: 8 | Train Loss: 0.0793348 Vali Loss: 0.0892188 Test Loss: 0.0953779
Validation loss decreased (0.089257 --> 0.089219).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0749750
	speed: 1.5935s/iter; left time: 85278.7636s
	iters: 200, epoch: 9 | loss: 0.0862554
	speed: 0.1149s/iter; left time: 6139.0793s
	iters: 300, epoch: 9 | loss: 0.0647535
	speed: 0.1153s/iter; left time: 6147.8544s
	iters: 400, epoch: 9 | loss: 0.0730983
	speed: 0.1161s/iter; left time: 6177.1792s
	iters: 500, epoch: 9 | loss: 0.0695380
	speed: 0.1143s/iter; left time: 6073.9151s
	iters: 600, epoch: 9 | loss: 0.0691377
	speed: 0.1138s/iter; left time: 6031.9767s
	iters: 700, epoch: 9 | loss: 0.0765528
	speed: 0.1150s/iter; left time: 6086.4702s
	iters: 800, epoch: 9 | loss: 0.0613169
	speed: 0.1157s/iter; left time: 6112.7932s
	iters: 900, epoch: 9 | loss: 0.0732772
	speed: 0.1128s/iter; left time: 5946.8314s
	iters: 1000, epoch: 9 | loss: 0.0607491
	speed: 0.1141s/iter; left time: 6005.3762s
	iters: 1100, epoch: 9 | loss: 0.0597287
	speed: 0.1145s/iter; left time: 6014.2623s
	iters: 1200, epoch: 9 | loss: 0.0944503
	speed: 0.1158s/iter; left time: 6068.9104s
	iters: 1300, epoch: 9 | loss: 0.0612135
	speed: 0.1167s/iter; left time: 6104.9545s
	iters: 1400, epoch: 9 | loss: 0.0633327
	speed: 0.1161s/iter; left time: 6061.6466s
	iters: 1500, epoch: 9 | loss: 0.0837415
	speed: 0.1161s/iter; left time: 6052.5368s
	iters: 1600, epoch: 9 | loss: 0.0839318
	speed: 0.1145s/iter; left time: 5957.2857s
	iters: 1700, epoch: 9 | loss: 0.0879491
	speed: 0.1153s/iter; left time: 5987.8238s
	iters: 1800, epoch: 9 | loss: 0.0665905
	speed: 0.1159s/iter; left time: 6007.1897s
	iters: 1900, epoch: 9 | loss: 0.0713467
	speed: 0.1132s/iter; left time: 5856.2024s
	iters: 2000, epoch: 9 | loss: 0.0669027
	speed: 0.1109s/iter; left time: 5722.6558s
	iters: 2100, epoch: 9 | loss: 0.0749533
	speed: 0.1125s/iter; left time: 5795.3411s
	iters: 2200, epoch: 9 | loss: 0.0823501
	speed: 0.1112s/iter; left time: 5718.2462s
	iters: 2300, epoch: 9 | loss: 0.0919251
	speed: 0.1139s/iter; left time: 5844.6386s
	iters: 2400, epoch: 9 | loss: 0.0902282
	speed: 0.1126s/iter; left time: 5768.5829s
	iters: 2500, epoch: 9 | loss: 0.0695416
	speed: 0.1117s/iter; left time: 5711.8656s
	iters: 2600, epoch: 9 | loss: 0.0872029
	speed: 0.1133s/iter; left time: 5778.4650s
	iters: 2700, epoch: 9 | loss: 0.0668999
	speed: 0.1119s/iter; left time: 5698.7334s
	iters: 2800, epoch: 9 | loss: 0.0708064
	speed: 0.1127s/iter; left time: 5725.9843s
	iters: 2900, epoch: 9 | loss: 0.0776473
	speed: 0.1123s/iter; left time: 5694.7808s
	iters: 3000, epoch: 9 | loss: 0.0897343
	speed: 0.1122s/iter; left time: 5681.0087s
	iters: 3100, epoch: 9 | loss: 0.0689395
	speed: 0.1124s/iter; left time: 5679.9443s
	iters: 3200, epoch: 9 | loss: 0.0872946
	speed: 0.1139s/iter; left time: 5744.6518s
	iters: 3300, epoch: 9 | loss: 0.0869129
	speed: 0.1114s/iter; left time: 5604.8787s
	iters: 3400, epoch: 9 | loss: 0.0875106
	speed: 0.1127s/iter; left time: 5660.6692s
	iters: 3500, epoch: 9 | loss: 0.0698793
	speed: 0.1125s/iter; left time: 5636.6617s
	iters: 3600, epoch: 9 | loss: 0.0638036
	speed: 0.1135s/iter; left time: 5676.5612s
	iters: 3700, epoch: 9 | loss: 0.0692865
	speed: 0.1122s/iter; left time: 5601.1650s
	iters: 3800, epoch: 9 | loss: 0.0771837
	speed: 0.1136s/iter; left time: 5659.3342s
	iters: 3900, epoch: 9 | loss: 0.0842480
	speed: 0.1127s/iter; left time: 5605.2598s
	iters: 4000, epoch: 9 | loss: 0.0725595
	speed: 0.1126s/iter; left time: 5588.1288s
	iters: 4100, epoch: 9 | loss: 0.0908936
	speed: 0.1121s/iter; left time: 5549.9859s
	iters: 4200, epoch: 9 | loss: 0.0893085
	speed: 0.1131s/iter; left time: 5589.3018s
	iters: 4300, epoch: 9 | loss: 0.0930462
	speed: 0.1122s/iter; left time: 5534.2020s
	iters: 4400, epoch: 9 | loss: 0.0681519
	speed: 0.1128s/iter; left time: 5549.7471s
Epoch: 9 cost time: 00h:08m:28.34s
Epoch: 9 | Train Loss: 0.0783692 Vali Loss: 0.0899408 Test Loss: 0.0950079
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0844053
	speed: 1.5703s/iter; left time: 77023.2284s
	iters: 200, epoch: 10 | loss: 0.1195817
	speed: 0.1156s/iter; left time: 5658.7668s
	iters: 300, epoch: 10 | loss: 0.0776654
	speed: 0.1157s/iter; left time: 5653.6352s
	iters: 400, epoch: 10 | loss: 0.0721945
	speed: 0.1144s/iter; left time: 5577.8280s
	iters: 500, epoch: 10 | loss: 0.0767422
	speed: 0.1146s/iter; left time: 5576.6377s
	iters: 600, epoch: 10 | loss: 0.0819118
	speed: 0.1156s/iter; left time: 5610.0326s
	iters: 700, epoch: 10 | loss: 0.0688704
	speed: 0.1144s/iter; left time: 5540.6791s
	iters: 800, epoch: 10 | loss: 0.1010805
	speed: 0.1162s/iter; left time: 5619.3736s
	iters: 900, epoch: 10 | loss: 0.0890266
	speed: 0.1134s/iter; left time: 5473.4191s
	iters: 1000, epoch: 10 | loss: 0.0743395
	speed: 0.1156s/iter; left time: 5567.6560s
	iters: 1100, epoch: 10 | loss: 0.0623439
	speed: 0.1154s/iter; left time: 5542.6937s
	iters: 1200, epoch: 10 | loss: 0.0886193
	speed: 0.1170s/iter; left time: 5610.6100s
	iters: 1300, epoch: 10 | loss: 0.0903579
	speed: 0.1158s/iter; left time: 5541.5628s
	iters: 1400, epoch: 10 | loss: 0.0970001
	speed: 0.1163s/iter; left time: 5550.9740s
	iters: 1500, epoch: 10 | loss: 0.0763897
	speed: 0.1151s/iter; left time: 5483.7668s
	iters: 1600, epoch: 10 | loss: 0.0659897
	speed: 0.1148s/iter; left time: 5460.3132s
	iters: 1700, epoch: 10 | loss: 0.0725043
	speed: 0.1165s/iter; left time: 5526.4024s
	iters: 1800, epoch: 10 | loss: 0.0614413
	speed: 0.1146s/iter; left time: 5425.1157s
	iters: 1900, epoch: 10 | loss: 0.0763310
	speed: 0.1134s/iter; left time: 5356.3255s
	iters: 2000, epoch: 10 | loss: 0.0819842
	speed: 0.1137s/iter; left time: 5362.4754s
	iters: 2100, epoch: 10 | loss: 0.0654081
	speed: 0.1132s/iter; left time: 5325.6774s
	iters: 2200, epoch: 10 | loss: 0.0653410
	speed: 0.1146s/iter; left time: 5380.6889s
	iters: 2300, epoch: 10 | loss: 0.0690481
	speed: 0.1151s/iter; left time: 5390.4317s
	iters: 2400, epoch: 10 | loss: 0.0936227
	speed: 0.1119s/iter; left time: 5232.1446s
	iters: 2500, epoch: 10 | loss: 0.0709767
	speed: 0.1150s/iter; left time: 5366.5604s
	iters: 2600, epoch: 10 | loss: 0.0593837
	speed: 0.1114s/iter; left time: 5186.2645s
	iters: 2700, epoch: 10 | loss: 0.1029781
	speed: 0.1120s/iter; left time: 5201.3187s
	iters: 2800, epoch: 10 | loss: 0.0660925
	speed: 0.1124s/iter; left time: 5209.6535s
	iters: 2900, epoch: 10 | loss: 0.0810724
	speed: 0.1154s/iter; left time: 5335.9264s
	iters: 3000, epoch: 10 | loss: 0.0861325
	speed: 0.1147s/iter; left time: 5292.0603s
	iters: 3100, epoch: 10 | loss: 0.0749175
	speed: 0.1137s/iter; left time: 5237.6337s
	iters: 3200, epoch: 10 | loss: 0.0772474
	speed: 0.1164s/iter; left time: 5349.7385s
	iters: 3300, epoch: 10 | loss: 0.0663424
	speed: 0.1137s/iter; left time: 5214.7671s
	iters: 3400, epoch: 10 | loss: 0.0681792
	speed: 0.1141s/iter; left time: 5221.7219s
	iters: 3500, epoch: 10 | loss: 0.0826567
	speed: 0.1140s/iter; left time: 5203.0824s
	iters: 3600, epoch: 10 | loss: 0.0750645
	speed: 0.1131s/iter; left time: 5151.3906s
	iters: 3700, epoch: 10 | loss: 0.0935027
	speed: 0.1151s/iter; left time: 5229.2264s
	iters: 3800, epoch: 10 | loss: 0.0815245
	speed: 0.1150s/iter; left time: 5214.8541s
	iters: 3900, epoch: 10 | loss: 0.0724220
	speed: 0.1144s/iter; left time: 5177.2966s
	iters: 4000, epoch: 10 | loss: 0.0900971
	speed: 0.1154s/iter; left time: 5208.8186s
	iters: 4100, epoch: 10 | loss: 0.0711545
	speed: 0.1136s/iter; left time: 5116.8096s
	iters: 4200, epoch: 10 | loss: 0.0712163
	speed: 0.1162s/iter; left time: 5225.1819s
	iters: 4300, epoch: 10 | loss: 0.0879692
	speed: 0.1138s/iter; left time: 5103.8100s
	iters: 4400, epoch: 10 | loss: 0.0614536
	speed: 0.1149s/iter; left time: 5140.8918s
Epoch: 10 cost time: 00h:08m:32.57s
Epoch: 10 | Train Loss: 0.0775587 Vali Loss: 0.0896562 Test Loss: 0.0955003
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 11 | loss: 0.0843296
	speed: 1.5739s/iter; left time: 70164.0240s
	iters: 200, epoch: 11 | loss: 0.0733311
	speed: 0.1145s/iter; left time: 5093.0879s
	iters: 300, epoch: 11 | loss: 0.0601665
	speed: 0.1165s/iter; left time: 5171.7973s
	iters: 400, epoch: 11 | loss: 0.0716488
	speed: 0.1158s/iter; left time: 5126.9430s
	iters: 500, epoch: 11 | loss: 0.0750899
	speed: 0.1165s/iter; left time: 5148.0669s
	iters: 600, epoch: 11 | loss: 0.0896189
	speed: 0.1153s/iter; left time: 5083.1043s
	iters: 700, epoch: 11 | loss: 0.0716856
	speed: 0.1139s/iter; left time: 5009.0067s
	iters: 800, epoch: 11 | loss: 0.0796735
	speed: 0.1153s/iter; left time: 5057.4234s
	iters: 900, epoch: 11 | loss: 0.0532320
	speed: 0.1148s/iter; left time: 5027.0354s
	iters: 1000, epoch: 11 | loss: 0.0739114
	speed: 0.1165s/iter; left time: 5090.5324s
	iters: 1100, epoch: 11 | loss: 0.0947660
	speed: 0.1156s/iter; left time: 5038.4828s
	iters: 1200, epoch: 11 | loss: 0.0835808
	speed: 0.1145s/iter; left time: 4977.6359s
	iters: 1300, epoch: 11 | loss: 0.0754700
	speed: 0.1149s/iter; left time: 4984.0475s
	iters: 1400, epoch: 11 | loss: 0.0658226
	speed: 0.1150s/iter; left time: 4975.6781s
	iters: 1500, epoch: 11 | loss: 0.0543421
	speed: 0.1149s/iter; left time: 4960.4601s
	iters: 1600, epoch: 11 | loss: 0.0710039
	speed: 0.1151s/iter; left time: 4957.1768s
	iters: 1700, epoch: 11 | loss: 0.0833827
	speed: 0.1159s/iter; left time: 4982.1454s
	iters: 1800, epoch: 11 | loss: 0.0674744
	speed: 0.1155s/iter; left time: 4951.2929s
	iters: 1900, epoch: 11 | loss: 0.0692966
	speed: 0.1154s/iter; left time: 4936.1148s
	iters: 2000, epoch: 11 | loss: 0.0941740
	speed: 0.1148s/iter; left time: 4899.7874s
	iters: 2100, epoch: 11 | loss: 0.0860964
	speed: 0.1159s/iter; left time: 4934.5398s
	iters: 2200, epoch: 11 | loss: 0.0810799
	speed: 0.1154s/iter; left time: 4901.1828s
	iters: 2300, epoch: 11 | loss: 0.0745259
	speed: 0.1157s/iter; left time: 4902.2137s
	iters: 2400, epoch: 11 | loss: 0.0968850
	speed: 0.1147s/iter; left time: 4850.8245s
	iters: 2500, epoch: 11 | loss: 0.0774877
	speed: 0.1128s/iter; left time: 4759.7731s
	iters: 2600, epoch: 11 | loss: 0.0719790
	speed: 0.1129s/iter; left time: 4750.8537s
	iters: 2700, epoch: 11 | loss: 0.0613416
	speed: 0.1133s/iter; left time: 4755.9070s
	iters: 2800, epoch: 11 | loss: 0.0705149
	speed: 0.1153s/iter; left time: 4828.2350s
	iters: 2900, epoch: 11 | loss: 0.0600997
	speed: 0.1193s/iter; left time: 4982.8862s
	iters: 3000, epoch: 11 | loss: 0.0838152
	speed: 0.1120s/iter; left time: 4666.8976s
	iters: 3100, epoch: 11 | loss: 0.0801776
	speed: 0.1128s/iter; left time: 4691.7418s
	iters: 3200, epoch: 11 | loss: 0.0818057
	speed: 0.1120s/iter; left time: 4647.3603s
	iters: 3300, epoch: 11 | loss: 0.0967920
	speed: 0.1119s/iter; left time: 4631.3189s
	iters: 3400, epoch: 11 | loss: 0.0851540
	speed: 0.1118s/iter; left time: 4617.2067s
	iters: 3500, epoch: 11 | loss: 0.0771672
	speed: 0.1114s/iter; left time: 4589.0794s
	iters: 3600, epoch: 11 | loss: 0.0722381
	speed: 0.1124s/iter; left time: 4615.8247s
	iters: 3700, epoch: 11 | loss: 0.0777316
	speed: 0.1131s/iter; left time: 4634.9475s
	iters: 3800, epoch: 11 | loss: 0.0811023
	speed: 0.1122s/iter; left time: 4587.1586s
	iters: 3900, epoch: 11 | loss: 0.0592589
	speed: 0.1135s/iter; left time: 4629.6078s
	iters: 4000, epoch: 11 | loss: 0.0921532
	speed: 0.1125s/iter; left time: 4574.9062s
	iters: 4100, epoch: 11 | loss: 0.0703947
	speed: 0.1131s/iter; left time: 4591.6095s
	iters: 4200, epoch: 11 | loss: 0.0643912
	speed: 0.1144s/iter; left time: 4629.1487s
	iters: 4300, epoch: 11 | loss: 0.0791592
	speed: 0.1142s/iter; left time: 4612.0469s
	iters: 4400, epoch: 11 | loss: 0.0683983
	speed: 0.1123s/iter; left time: 4524.4935s
Epoch: 11 cost time: 00h:08m:31.37s
Epoch: 11 | Train Loss: 0.0766384 Vali Loss: 0.0910036 Test Loss: 0.0970744
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 12 | loss: 0.0710792
	speed: 1.5636s/iter; left time: 62721.0444s
	iters: 200, epoch: 12 | loss: 0.0842273
	speed: 0.1133s/iter; left time: 4533.8282s
	iters: 300, epoch: 12 | loss: 0.0629760
	speed: 0.1142s/iter; left time: 4557.5035s
	iters: 400, epoch: 12 | loss: 0.0810391
	speed: 0.1137s/iter; left time: 4525.0781s
	iters: 500, epoch: 12 | loss: 0.1013014
	speed: 0.1144s/iter; left time: 4542.3369s
	iters: 600, epoch: 12 | loss: 0.0584819
	speed: 0.1137s/iter; left time: 4503.4232s
	iters: 700, epoch: 12 | loss: 0.0732251
	speed: 0.1132s/iter; left time: 4471.8834s
	iters: 800, epoch: 12 | loss: 0.0754556
	speed: 0.1120s/iter; left time: 4413.5894s
	iters: 900, epoch: 12 | loss: 0.0640929
	speed: 0.1135s/iter; left time: 4461.7356s
	iters: 1000, epoch: 12 | loss: 0.0760040
	speed: 0.1133s/iter; left time: 4442.3115s
	iters: 1100, epoch: 12 | loss: 0.0927217
	speed: 0.1133s/iter; left time: 4433.2293s
	iters: 1200, epoch: 12 | loss: 0.0876345
	speed: 0.1150s/iter; left time: 4487.2739s
	iters: 1300, epoch: 12 | loss: 0.0746380
	speed: 0.1136s/iter; left time: 4422.2023s
	iters: 1400, epoch: 12 | loss: 0.0757993
	speed: 0.1150s/iter; left time: 4463.8057s
	iters: 1500, epoch: 12 | loss: 0.0810570
	speed: 0.1153s/iter; left time: 4464.1727s
	iters: 1600, epoch: 12 | loss: 0.0619826
	speed: 0.1155s/iter; left time: 4460.3334s
	iters: 1700, epoch: 12 | loss: 0.0746262
	speed: 0.1122s/iter; left time: 4321.5653s
	iters: 1800, epoch: 12 | loss: 0.0823452
	speed: 0.1131s/iter; left time: 4343.0094s
	iters: 1900, epoch: 12 | loss: 0.0711706
	speed: 0.1119s/iter; left time: 4286.5702s
	iters: 2000, epoch: 12 | loss: 0.0654976
	speed: 0.1114s/iter; left time: 4257.2980s
	iters: 2100, epoch: 12 | loss: 0.0801418
	speed: 0.1130s/iter; left time: 4308.3075s
	iters: 2200, epoch: 12 | loss: 0.0796125
	speed: 0.1143s/iter; left time: 4345.9646s
	iters: 2300, epoch: 12 | loss: 0.0880586
	speed: 0.1140s/iter; left time: 4322.5583s
	iters: 2400, epoch: 12 | loss: 0.0664747
	speed: 0.1128s/iter; left time: 4266.0571s
	iters: 2500, epoch: 12 | loss: 0.0685178
	speed: 0.1133s/iter; left time: 4272.3721s
	iters: 2600, epoch: 12 | loss: 0.0550742
	speed: 0.1131s/iter; left time: 4252.6892s
	iters: 2700, epoch: 12 | loss: 0.0827314
	speed: 0.1116s/iter; left time: 4186.3833s
	iters: 2800, epoch: 12 | loss: 0.0665130
	speed: 0.1129s/iter; left time: 4225.7916s
	iters: 2900, epoch: 12 | loss: 0.0725770
	speed: 0.1153s/iter; left time: 4301.2409s
	iters: 3000, epoch: 12 | loss: 0.0761487
	speed: 0.1131s/iter; left time: 4207.9793s
	iters: 3100, epoch: 12 | loss: 0.0791091
	speed: 0.1113s/iter; left time: 4129.1158s
	iters: 3200, epoch: 12 | loss: 0.0671570
	speed: 0.1132s/iter; left time: 4188.6470s
	iters: 3300, epoch: 12 | loss: 0.0749104
	speed: 0.1108s/iter; left time: 4090.0929s
	iters: 3400, epoch: 12 | loss: 0.0909807
	speed: 0.1113s/iter; left time: 4097.7149s
	iters: 3500, epoch: 12 | loss: 0.0923854
	speed: 0.1126s/iter; left time: 4132.9393s
	iters: 3600, epoch: 12 | loss: 0.0831650
	speed: 0.1131s/iter; left time: 4139.3141s
	iters: 3700, epoch: 12 | loss: 0.0813926
	speed: 0.1130s/iter; left time: 4127.1017s
	iters: 3800, epoch: 12 | loss: 0.0719712
	speed: 0.1118s/iter; left time: 4070.7835s
	iters: 3900, epoch: 12 | loss: 0.0697064
	speed: 0.1118s/iter; left time: 4060.5863s
	iters: 4000, epoch: 12 | loss: 0.0884542
	speed: 0.1128s/iter; left time: 4084.2641s
	iters: 4100, epoch: 12 | loss: 0.0673367
	speed: 0.1129s/iter; left time: 4075.9061s
	iters: 4200, epoch: 12 | loss: 0.0795303
	speed: 0.1130s/iter; left time: 4069.6429s
	iters: 4300, epoch: 12 | loss: 0.0724135
	speed: 0.1119s/iter; left time: 4018.1664s
	iters: 4400, epoch: 12 | loss: 0.0837259
	speed: 0.1092s/iter; left time: 3912.5087s
Epoch: 12 cost time: 00h:08m:26.23s
Epoch: 12 | Train Loss: 0.0758073 Vali Loss: 0.0911360 Test Loss: 0.0977819
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 13 | loss: 0.0696547
	speed: 1.5893s/iter; left time: 56649.7380s
	iters: 200, epoch: 13 | loss: 0.0783792
	speed: 0.1172s/iter; left time: 4164.4258s
	iters: 300, epoch: 13 | loss: 0.0612777
	speed: 0.1179s/iter; left time: 4178.9516s
	iters: 400, epoch: 13 | loss: 0.0669738
	speed: 0.1177s/iter; left time: 4158.8186s
	iters: 500, epoch: 13 | loss: 0.0753981
	speed: 0.1177s/iter; left time: 4147.4482s
	iters: 600, epoch: 13 | loss: 0.0703675
	speed: 0.1153s/iter; left time: 4053.7467s
	iters: 700, epoch: 13 | loss: 0.0807081
	speed: 0.1164s/iter; left time: 4077.7579s
	iters: 800, epoch: 13 | loss: 0.0631655
	speed: 0.1182s/iter; left time: 4130.4168s
	iters: 900, epoch: 13 | loss: 0.0665464
	speed: 0.1170s/iter; left time: 4075.9742s
	iters: 1000, epoch: 13 | loss: 0.0889466
	speed: 0.1150s/iter; left time: 3996.6718s
	iters: 1100, epoch: 13 | loss: 0.0937114
	speed: 0.1159s/iter; left time: 4013.9217s
	iters: 1200, epoch: 13 | loss: 0.0855564
	speed: 0.1143s/iter; left time: 3949.4810s
	iters: 1300, epoch: 13 | loss: 0.0802188
	speed: 0.1161s/iter; left time: 3999.4400s
	iters: 1400, epoch: 13 | loss: 0.0752418
	speed: 0.1170s/iter; left time: 4019.6635s
	iters: 1500, epoch: 13 | loss: 0.0920139
	speed: 0.1172s/iter; left time: 4013.8930s
	iters: 1600, epoch: 13 | loss: 0.0802863
	speed: 0.1177s/iter; left time: 4019.6514s
	iters: 1700, epoch: 13 | loss: 0.0784608
	speed: 0.1200s/iter; left time: 4086.0264s
	iters: 1800, epoch: 13 | loss: 0.0880799
	speed: 0.1172s/iter; left time: 3979.4404s
	iters: 1900, epoch: 13 | loss: 0.0902761
	speed: 0.1177s/iter; left time: 3984.6787s
	iters: 2000, epoch: 13 | loss: 0.0855317
	speed: 0.1162s/iter; left time: 3920.8780s
	iters: 2100, epoch: 13 | loss: 0.0778534
	speed: 0.1169s/iter; left time: 3934.1143s
	iters: 2200, epoch: 13 | loss: 0.0732491
	speed: 0.1166s/iter; left time: 3910.2686s
	iters: 2300, epoch: 13 | loss: 0.0718696
	speed: 0.1174s/iter; left time: 3927.0261s
	iters: 2400, epoch: 13 | loss: 0.0643891
	speed: 0.1167s/iter; left time: 3891.0356s
	iters: 2500, epoch: 13 | loss: 0.0634482
	speed: 0.1176s/iter; left time: 3909.0249s
	iters: 2600, epoch: 13 | loss: 0.0696910
	speed: 0.1181s/iter; left time: 3915.0711s
	iters: 2700, epoch: 13 | loss: 0.0817821
	speed: 0.1158s/iter; left time: 3825.6326s
	iters: 2800, epoch: 13 | loss: 0.0640855
	speed: 0.1157s/iter; left time: 3811.4909s
	iters: 2900, epoch: 13 | loss: 0.0694307
	speed: 0.1160s/iter; left time: 3810.3136s
	iters: 3000, epoch: 13 | loss: 0.0864336
	speed: 0.1171s/iter; left time: 3835.8686s
	iters: 3100, epoch: 13 | loss: 0.0733568
	speed: 0.1175s/iter; left time: 3835.4461s
	iters: 3200, epoch: 13 | loss: 0.0625381
	speed: 0.1159s/iter; left time: 3770.5600s
	iters: 3300, epoch: 13 | loss: 0.0875661
	speed: 0.1187s/iter; left time: 3852.2250s
	iters: 3400, epoch: 13 | loss: 0.0675188
	speed: 0.1180s/iter; left time: 3818.2630s
	iters: 3500, epoch: 13 | loss: 0.0647626
	speed: 0.1167s/iter; left time: 3763.5709s
	iters: 3600, epoch: 13 | loss: 0.0939891
	speed: 0.1169s/iter; left time: 3756.8278s
	iters: 3700, epoch: 13 | loss: 0.0905394
	speed: 0.1158s/iter; left time: 3709.2596s
	iters: 3800, epoch: 13 | loss: 0.0685588
	speed: 0.1173s/iter; left time: 3748.1331s
	iters: 3900, epoch: 13 | loss: 0.0648391
	speed: 0.1175s/iter; left time: 3740.8344s
	iters: 4000, epoch: 13 | loss: 0.0833651
	speed: 0.1160s/iter; left time: 3682.8446s
	iters: 4100, epoch: 13 | loss: 0.0707878
	speed: 0.1176s/iter; left time: 3722.4901s
	iters: 4200, epoch: 13 | loss: 0.0837740
	speed: 0.1175s/iter; left time: 3707.5046s
	iters: 4300, epoch: 13 | loss: 0.0526903
	speed: 0.1160s/iter; left time: 3649.0515s
	iters: 4400, epoch: 13 | loss: 0.0681901
	speed: 0.1168s/iter; left time: 3661.2333s
Epoch: 13 cost time: 00h:08m:43.12s
Epoch: 13 | Train Loss: 0.0749393 Vali Loss: 0.0928503 Test Loss: 0.1000453
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.02273400127887726, rmse:0.15077798068523407, mae:0.09537788480520248, rse:0.5325193405151367
success delete checkpoints
Intermediate time for DE and pred_len 24: 02h:24m:39.95s

=== Starting experiments for pred_len: 96 ===

--- Running model for DE, pred_len=96 ---
train 142645
val 30725
test 30725
[2024-11-03 03:36:47,323] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 03:36:48,374] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 03:36:48,374] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 03:36:48,374] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 03:36:48,464] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 03:36:48,464] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 03:36:49,208] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 03:36:49,210] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 03:36:49,210] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 03:36:49,211] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 03:36:49,211] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 03:36:49,212] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 03:36:49,212] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 03:36:49,212] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 03:36:49,212] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 03:36:49,212] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 03:36:49,660] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 03:36:49,661] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 03:36:49,661] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 76.86 GB, percent = 10.2%
[2024-11-03 03:36:49,845] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 03:36:49,846] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 03:36:49,846] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 76.8 GB, percent = 10.2%
[2024-11-03 03:36:49,846] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 03:36:49,986] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 03:36:49,987] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 03:36:49,987] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 76.83 GB, percent = 10.2%
[2024-11-03 03:36:49,988] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 03:36:49,988] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 03:36:49,988] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 03:36:49,988] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 03:36:49,989] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 03:36:49,989] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 03:36:49,989] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 03:36:49,989] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 03:36:49,989] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5e609dadd0>
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 03:36:49,990] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 03:36:49,991] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 03:36:49,992] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 03:36:49,992] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 03:36:49,992] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 03:36:49,992] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 03:36:49,992] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1857200
	speed: 0.1749s/iter; left time: 15577.3743s
	iters: 200, epoch: 1 | loss: 0.1687170
	speed: 0.1288s/iter; left time: 11457.6404s
	iters: 300, epoch: 1 | loss: 0.1724844
	speed: 0.1281s/iter; left time: 11376.5133s
	iters: 400, epoch: 1 | loss: 0.1656757
	speed: 0.1285s/iter; left time: 11406.8328s
	iters: 500, epoch: 1 | loss: 0.1675965
	speed: 0.1308s/iter; left time: 11595.5959s
	iters: 600, epoch: 1 | loss: 0.1443687
	speed: 0.1283s/iter; left time: 11360.4195s
	iters: 700, epoch: 1 | loss: 0.1422241
	speed: 0.1294s/iter; left time: 11444.9010s
	iters: 800, epoch: 1 | loss: 0.1226619
	speed: 0.1311s/iter; left time: 11583.9627s
	iters: 900, epoch: 1 | loss: 0.1330729
	speed: 0.1320s/iter; left time: 11645.3274s
	iters: 1000, epoch: 1 | loss: 0.1138731
	speed: 0.1279s/iter; left time: 11277.5582s
	iters: 1100, epoch: 1 | loss: 0.1071478
	speed: 0.1286s/iter; left time: 11321.9161s
	iters: 1200, epoch: 1 | loss: 0.1303404
	speed: 0.1277s/iter; left time: 11226.3168s
	iters: 1300, epoch: 1 | loss: 0.1238685
	speed: 0.1295s/iter; left time: 11371.7322s
	iters: 1400, epoch: 1 | loss: 0.1032463
	speed: 0.1281s/iter; left time: 11238.4410s
	iters: 1500, epoch: 1 | loss: 0.1194469
	speed: 0.1278s/iter; left time: 11204.7918s
	iters: 1600, epoch: 1 | loss: 0.1207578
	speed: 0.1295s/iter; left time: 11336.0300s
	iters: 1700, epoch: 1 | loss: 0.1394709
	speed: 0.1296s/iter; left time: 11329.0578s
	iters: 1800, epoch: 1 | loss: 0.1160002
	speed: 0.1284s/iter; left time: 11216.9853s
	iters: 1900, epoch: 1 | loss: 0.1103131
	speed: 0.1283s/iter; left time: 11196.2989s
	iters: 2000, epoch: 1 | loss: 0.1130958
	speed: 0.1258s/iter; left time: 10963.6410s
	iters: 2100, epoch: 1 | loss: 0.1089309
	speed: 0.1278s/iter; left time: 11119.7526s
	iters: 2200, epoch: 1 | loss: 0.1244033
	speed: 0.1307s/iter; left time: 11360.0311s
	iters: 2300, epoch: 1 | loss: 0.1284142
	speed: 0.1305s/iter; left time: 11330.0133s
	iters: 2400, epoch: 1 | loss: 0.1186614
	speed: 0.1310s/iter; left time: 11359.6028s
	iters: 2500, epoch: 1 | loss: 0.1169964
	speed: 0.1281s/iter; left time: 11094.6381s
	iters: 2600, epoch: 1 | loss: 0.1132365
	speed: 0.1305s/iter; left time: 11294.7278s
	iters: 2700, epoch: 1 | loss: 0.1326390
	speed: 0.1299s/iter; left time: 11227.3974s
	iters: 2800, epoch: 1 | loss: 0.1291778
	speed: 0.1271s/iter; left time: 10971.6094s
	iters: 2900, epoch: 1 | loss: 0.1308049
	speed: 0.1309s/iter; left time: 11287.2538s
	iters: 3000, epoch: 1 | loss: 0.1142576
	speed: 0.1295s/iter; left time: 11153.1138s
	iters: 3100, epoch: 1 | loss: 0.0980470
	speed: 0.1265s/iter; left time: 10886.4749s
	iters: 3200, epoch: 1 | loss: 0.1026124
	speed: 0.1282s/iter; left time: 11013.8344s
	iters: 3300, epoch: 1 | loss: 0.1019026
	speed: 0.1289s/iter; left time: 11065.1453s
	iters: 3400, epoch: 1 | loss: 0.1156720
	speed: 0.1297s/iter; left time: 11123.8672s
	iters: 3500, epoch: 1 | loss: 0.1253485
	speed: 0.1298s/iter; left time: 11116.5148s
	iters: 3600, epoch: 1 | loss: 0.1046039
	speed: 0.1302s/iter; left time: 11137.7349s
	iters: 3700, epoch: 1 | loss: 0.1413063
	speed: 0.1318s/iter; left time: 11263.1589s
	iters: 3800, epoch: 1 | loss: 0.1070143
	speed: 0.1292s/iter; left time: 11023.9143s
	iters: 3900, epoch: 1 | loss: 0.1359391
	speed: 0.1286s/iter; left time: 10961.5411s
	iters: 4000, epoch: 1 | loss: 0.1120188
	speed: 0.1300s/iter; left time: 11066.3841s
	iters: 4100, epoch: 1 | loss: 0.1373022
	speed: 0.1296s/iter; left time: 11017.7127s
	iters: 4200, epoch: 1 | loss: 0.1048007
	speed: 0.1290s/iter; left time: 10959.8018s
	iters: 4300, epoch: 1 | loss: 0.1046956
	speed: 0.1312s/iter; left time: 11129.0249s
	iters: 4400, epoch: 1 | loss: 0.1285643
	speed: 0.1288s/iter; left time: 10912.1558s
Epoch: 1 cost time: 00h:09m:37.13s
Epoch: 1 | Train Loss: 0.1245267 Vali Loss: 0.1197564 Test Loss: 0.1277876
Validation loss decreased (inf --> 0.119756).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1362824
	speed: 1.8577s/iter; left time: 157131.2041s
	iters: 200, epoch: 2 | loss: 0.1034659
	speed: 0.1181s/iter; left time: 9979.1355s
	iters: 300, epoch: 2 | loss: 0.1078680
	speed: 0.1176s/iter; left time: 9924.3209s
	iters: 400, epoch: 2 | loss: 0.1090891
	speed: 0.1186s/iter; left time: 9997.2466s
	iters: 500, epoch: 2 | loss: 0.0995298
	speed: 0.1178s/iter; left time: 9912.9384s
	iters: 600, epoch: 2 | loss: 0.1253273
	speed: 0.1185s/iter; left time: 9967.8242s
	iters: 700, epoch: 2 | loss: 0.1308996
	speed: 0.1184s/iter; left time: 9945.0339s
	iters: 800, epoch: 2 | loss: 0.1199580
	speed: 0.1172s/iter; left time: 9827.3807s
	iters: 900, epoch: 2 | loss: 0.1126412
	speed: 0.1192s/iter; left time: 9990.0129s
	iters: 1000, epoch: 2 | loss: 0.1188750
	speed: 0.1181s/iter; left time: 9884.5111s
	iters: 1100, epoch: 2 | loss: 0.1189725
	speed: 0.1185s/iter; left time: 9905.0032s
	iters: 1200, epoch: 2 | loss: 0.1217855
	speed: 0.1181s/iter; left time: 9861.4114s
	iters: 1300, epoch: 2 | loss: 0.1159035
	speed: 0.1170s/iter; left time: 9752.8977s
	iters: 1400, epoch: 2 | loss: 0.0984060
	speed: 0.1196s/iter; left time: 9960.2194s
	iters: 1500, epoch: 2 | loss: 0.0966178
	speed: 0.1195s/iter; left time: 9938.6067s
	iters: 1600, epoch: 2 | loss: 0.1044325
	speed: 0.1182s/iter; left time: 9816.7587s
	iters: 1700, epoch: 2 | loss: 0.1260282
	speed: 0.1179s/iter; left time: 9784.6770s
	iters: 1800, epoch: 2 | loss: 0.1024257
	speed: 0.1167s/iter; left time: 9671.8226s
	iters: 1900, epoch: 2 | loss: 0.0874435
	speed: 0.1193s/iter; left time: 9873.2542s
	iters: 2000, epoch: 2 | loss: 0.1199540
	speed: 0.1158s/iter; left time: 9576.7465s
	iters: 2100, epoch: 2 | loss: 0.1297425
	speed: 0.1176s/iter; left time: 9711.1511s
	iters: 2200, epoch: 2 | loss: 0.1000140
	speed: 0.1163s/iter; left time: 9589.7147s
	iters: 2300, epoch: 2 | loss: 0.1035635
	speed: 0.1180s/iter; left time: 9723.6046s
	iters: 2400, epoch: 2 | loss: 0.1033574
	speed: 0.1183s/iter; left time: 9735.6153s
	iters: 2500, epoch: 2 | loss: 0.1072888
	speed: 0.1175s/iter; left time: 9658.7560s
	iters: 2600, epoch: 2 | loss: 0.1190963
	speed: 0.1174s/iter; left time: 9636.4540s
	iters: 2700, epoch: 2 | loss: 0.1066877
	speed: 0.1181s/iter; left time: 9686.3330s
	iters: 2800, epoch: 2 | loss: 0.1129730
	speed: 0.1128s/iter; left time: 9237.4035s
	iters: 2900, epoch: 2 | loss: 0.1384397
	speed: 0.1173s/iter; left time: 9596.9501s
	iters: 3000, epoch: 2 | loss: 0.1114533
	speed: 0.1192s/iter; left time: 9732.7134s
	iters: 3100, epoch: 2 | loss: 0.1163946
	speed: 0.1176s/iter; left time: 9597.6541s
	iters: 3200, epoch: 2 | loss: 0.1102893
	speed: 0.1175s/iter; left time: 9575.9749s
	iters: 3300, epoch: 2 | loss: 0.0999768
	speed: 0.1159s/iter; left time: 9432.5478s
	iters: 3400, epoch: 2 | loss: 0.0817148
	speed: 0.1176s/iter; left time: 9559.8251s
	iters: 3500, epoch: 2 | loss: 0.1148444
	speed: 0.1182s/iter; left time: 9593.3125s
	iters: 3600, epoch: 2 | loss: 0.1212692
	speed: 0.1160s/iter; left time: 9403.9745s
	iters: 3700, epoch: 2 | loss: 0.1155532
	speed: 0.1158s/iter; left time: 9379.7291s
	iters: 3800, epoch: 2 | loss: 0.1284737
	speed: 0.1156s/iter; left time: 9351.2049s
	iters: 3900, epoch: 2 | loss: 0.1278360
	speed: 0.1177s/iter; left time: 9505.1319s
	iters: 4000, epoch: 2 | loss: 0.1092012
	speed: 0.1165s/iter; left time: 9396.7610s
	iters: 4100, epoch: 2 | loss: 0.0933397
	speed: 0.1175s/iter; left time: 9467.4941s
	iters: 4200, epoch: 2 | loss: 0.1042761
	speed: 0.1169s/iter; left time: 9407.1105s
	iters: 4300, epoch: 2 | loss: 0.1036103
	speed: 0.1155s/iter; left time: 9285.9710s
	iters: 4400, epoch: 2 | loss: 0.0886638
	speed: 0.1162s/iter; left time: 9326.1864s
Epoch: 2 cost time: 00h:08m:44.44s
Epoch: 2 | Train Loss: 0.1098625 Vali Loss: 0.1185164 Test Loss: 0.1282422
Validation loss decreased (0.119756 --> 0.118516).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1121855
	speed: 1.6093s/iter; left time: 128949.3745s
	iters: 200, epoch: 3 | loss: 0.0993601
	speed: 0.1182s/iter; left time: 9455.5526s
	iters: 300, epoch: 3 | loss: 0.0954742
	speed: 0.1185s/iter; left time: 9471.8841s
	iters: 400, epoch: 3 | loss: 0.1022189
	speed: 0.1167s/iter; left time: 9318.9562s
	iters: 500, epoch: 3 | loss: 0.1028623
	speed: 0.1179s/iter; left time: 9400.1779s
	iters: 600, epoch: 3 | loss: 0.1073780
	speed: 0.1188s/iter; left time: 9455.7653s
	iters: 700, epoch: 3 | loss: 0.1252172
	speed: 0.1184s/iter; left time: 9415.0870s
	iters: 800, epoch: 3 | loss: 0.0985473
	speed: 0.1175s/iter; left time: 9332.2909s
	iters: 900, epoch: 3 | loss: 0.1068274
	speed: 0.1197s/iter; left time: 9496.0076s
	iters: 1000, epoch: 3 | loss: 0.1010967
	speed: 0.1183s/iter; left time: 9374.0746s
	iters: 1100, epoch: 3 | loss: 0.1209155
	speed: 0.1169s/iter; left time: 9252.1070s
	iters: 1200, epoch: 3 | loss: 0.1471111
	speed: 0.1176s/iter; left time: 9295.8203s
	iters: 1300, epoch: 3 | loss: 0.0935464
	speed: 0.1189s/iter; left time: 9381.0565s
	iters: 1400, epoch: 3 | loss: 0.1135274
	speed: 0.1186s/iter; left time: 9352.5755s
	iters: 1500, epoch: 3 | loss: 0.0995740
	speed: 0.1168s/iter; left time: 9194.3072s
	iters: 1600, epoch: 3 | loss: 0.0949781
	speed: 0.1172s/iter; left time: 9212.4557s
	iters: 1700, epoch: 3 | loss: 0.1161713
	speed: 0.1180s/iter; left time: 9264.1771s
	iters: 1800, epoch: 3 | loss: 0.1313455
	speed: 0.1162s/iter; left time: 9111.7358s
	iters: 1900, epoch: 3 | loss: 0.1055434
	speed: 0.1190s/iter; left time: 9317.3203s
	iters: 2000, epoch: 3 | loss: 0.1189179
	speed: 0.1176s/iter; left time: 9198.3426s
	iters: 2100, epoch: 3 | loss: 0.0911239
	speed: 0.1181s/iter; left time: 9227.0430s
	iters: 2200, epoch: 3 | loss: 0.1390544
	speed: 0.1160s/iter; left time: 9050.4505s
	iters: 2300, epoch: 3 | loss: 0.0976654
	speed: 0.1182s/iter; left time: 9211.7403s
	iters: 2400, epoch: 3 | loss: 0.1079981
	speed: 0.1198s/iter; left time: 9321.4916s
	iters: 2500, epoch: 3 | loss: 0.1111981
	speed: 0.1177s/iter; left time: 9145.8877s
	iters: 2600, epoch: 3 | loss: 0.1110975
	speed: 0.1151s/iter; left time: 8936.2508s
	iters: 2700, epoch: 3 | loss: 0.1392076
	speed: 0.1162s/iter; left time: 9005.2980s
	iters: 2800, epoch: 3 | loss: 0.1271442
	speed: 0.1160s/iter; left time: 8980.1116s
	iters: 2900, epoch: 3 | loss: 0.1141754
	speed: 0.1152s/iter; left time: 8905.0857s
	iters: 3000, epoch: 3 | loss: 0.1144832
	speed: 0.1152s/iter; left time: 8899.4490s
	iters: 3100, epoch: 3 | loss: 0.0868490
	speed: 0.1183s/iter; left time: 9124.7607s
	iters: 3200, epoch: 3 | loss: 0.1013458
	speed: 0.1181s/iter; left time: 9098.0172s
	iters: 3300, epoch: 3 | loss: 0.0867222
	speed: 0.1157s/iter; left time: 8899.0869s
	iters: 3400, epoch: 3 | loss: 0.0821788
	speed: 0.1162s/iter; left time: 8927.4794s
	iters: 3500, epoch: 3 | loss: 0.1050519
	speed: 0.1156s/iter; left time: 8873.3044s
	iters: 3600, epoch: 3 | loss: 0.1225686
	speed: 0.1185s/iter; left time: 9080.4483s
	iters: 3700, epoch: 3 | loss: 0.1083653
	speed: 0.1174s/iter; left time: 8983.1473s
	iters: 3800, epoch: 3 | loss: 0.0852168
	speed: 0.1169s/iter; left time: 8936.1334s
	iters: 3900, epoch: 3 | loss: 0.1460541
	speed: 0.1177s/iter; left time: 8986.7995s
	iters: 4000, epoch: 3 | loss: 0.0892489
	speed: 0.1159s/iter; left time: 8836.6297s
	iters: 4100, epoch: 3 | loss: 0.1043740
	speed: 0.1151s/iter; left time: 8763.5466s
	iters: 4200, epoch: 3 | loss: 0.1233985
	speed: 0.1171s/iter; left time: 8903.0900s
	iters: 4300, epoch: 3 | loss: 0.1201573
	speed: 0.1143s/iter; left time: 8682.1961s
	iters: 4400, epoch: 3 | loss: 0.0884113
	speed: 0.1163s/iter; left time: 8815.0683s
Epoch: 3 cost time: 00h:08m:43.20s
Epoch: 3 | Train Loss: 0.1059200 Vali Loss: 0.1199043 Test Loss: 0.1320190
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.1017862
	speed: 1.5936s/iter; left time: 120585.6451s
	iters: 200, epoch: 4 | loss: 0.1054816
	speed: 0.1159s/iter; left time: 8755.5299s
	iters: 300, epoch: 4 | loss: 0.1008089
	speed: 0.1170s/iter; left time: 8831.5805s
	iters: 400, epoch: 4 | loss: 0.1103006
	speed: 0.1153s/iter; left time: 8688.9430s
	iters: 500, epoch: 4 | loss: 0.1008416
	speed: 0.1145s/iter; left time: 8619.2124s
	iters: 600, epoch: 4 | loss: 0.0872107
	speed: 0.1160s/iter; left time: 8722.1032s
	iters: 700, epoch: 4 | loss: 0.1059361
	speed: 0.1195s/iter; left time: 8968.0293s
	iters: 800, epoch: 4 | loss: 0.1094390
	speed: 0.1181s/iter; left time: 8851.8553s
	iters: 900, epoch: 4 | loss: 0.1180137
	speed: 0.1181s/iter; left time: 8844.5917s
	iters: 1000, epoch: 4 | loss: 0.1055246
	speed: 0.1197s/iter; left time: 8947.2815s
	iters: 1100, epoch: 4 | loss: 0.1000077
	speed: 0.1173s/iter; left time: 8759.0721s
	iters: 1200, epoch: 4 | loss: 0.0994589
	speed: 0.1172s/iter; left time: 8735.9921s
	iters: 1300, epoch: 4 | loss: 0.1067580
	speed: 0.1171s/iter; left time: 8721.4622s
	iters: 1400, epoch: 4 | loss: 0.0998731
	speed: 0.1158s/iter; left time: 8613.1813s
	iters: 1500, epoch: 4 | loss: 0.1033912
	speed: 0.1119s/iter; left time: 8308.1780s
	iters: 1600, epoch: 4 | loss: 0.0937374
	speed: 0.1107s/iter; left time: 8208.9945s
	iters: 1700, epoch: 4 | loss: 0.0970818
	speed: 0.1124s/iter; left time: 8327.5368s
	iters: 1800, epoch: 4 | loss: 0.1050920
	speed: 0.1120s/iter; left time: 8285.6897s
	iters: 1900, epoch: 4 | loss: 0.1291669
	speed: 0.1121s/iter; left time: 8279.0598s
	iters: 2000, epoch: 4 | loss: 0.0771152
	speed: 0.1133s/iter; left time: 8356.6795s
	iters: 2100, epoch: 4 | loss: 0.0940207
	speed: 0.1136s/iter; left time: 8366.1464s
	iters: 2200, epoch: 4 | loss: 0.0884763
	speed: 0.1108s/iter; left time: 8149.7752s
	iters: 2300, epoch: 4 | loss: 0.0902145
	speed: 0.1114s/iter; left time: 8187.5958s
	iters: 2400, epoch: 4 | loss: 0.1145035
	speed: 0.1129s/iter; left time: 8281.5547s
	iters: 2500, epoch: 4 | loss: 0.1050488
	speed: 0.1144s/iter; left time: 8378.4388s
	iters: 2600, epoch: 4 | loss: 0.0954266
	speed: 0.1140s/iter; left time: 8343.4925s
	iters: 2700, epoch: 4 | loss: 0.0995934
	speed: 0.1122s/iter; left time: 8201.3794s
	iters: 2800, epoch: 4 | loss: 0.1045068
	speed: 0.1108s/iter; left time: 8082.1594s
	iters: 2900, epoch: 4 | loss: 0.0896091
	speed: 0.1110s/iter; left time: 8087.5701s
	iters: 3000, epoch: 4 | loss: 0.1133813
	speed: 0.1100s/iter; left time: 8006.8918s
	iters: 3100, epoch: 4 | loss: 0.1004615
	speed: 0.1144s/iter; left time: 8311.1747s
	iters: 3200, epoch: 4 | loss: 0.1033023
	speed: 0.1111s/iter; left time: 8059.7486s
	iters: 3300, epoch: 4 | loss: 0.1076910
	speed: 0.1126s/iter; left time: 8158.9434s
	iters: 3400, epoch: 4 | loss: 0.0782520
	speed: 0.1114s/iter; left time: 8063.5273s
	iters: 3500, epoch: 4 | loss: 0.0946225
	speed: 0.1116s/iter; left time: 8068.2659s
	iters: 3600, epoch: 4 | loss: 0.1047806
	speed: 0.1135s/iter; left time: 8194.1758s
	iters: 3700, epoch: 4 | loss: 0.0901383
	speed: 0.1132s/iter; left time: 8157.3959s
	iters: 3800, epoch: 4 | loss: 0.0860445
	speed: 0.1126s/iter; left time: 8101.8086s
	iters: 3900, epoch: 4 | loss: 0.0885248
	speed: 0.1116s/iter; left time: 8023.3105s
	iters: 4000, epoch: 4 | loss: 0.1189710
	speed: 0.1109s/iter; left time: 7958.3027s
	iters: 4100, epoch: 4 | loss: 0.0907215
	speed: 0.1112s/iter; left time: 7967.6398s
	iters: 4200, epoch: 4 | loss: 0.1236514
	speed: 0.1111s/iter; left time: 7950.3721s
	iters: 4300, epoch: 4 | loss: 0.1064944
	speed: 0.1120s/iter; left time: 8004.7838s
	iters: 4400, epoch: 4 | loss: 0.0968458
	speed: 0.1119s/iter; left time: 7984.6857s
Epoch: 4 cost time: 00h:08m:27.07s
Epoch: 4 | Train Loss: 0.1021763 Vali Loss: 0.1203913 Test Loss: 0.1309304
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0960487
	speed: 1.5315s/iter; left time: 109064.0538s
	iters: 200, epoch: 5 | loss: 0.0997009
	speed: 0.1119s/iter; left time: 7958.2026s
	iters: 300, epoch: 5 | loss: 0.1327493
	speed: 0.1136s/iter; left time: 8067.9951s
	iters: 400, epoch: 5 | loss: 0.1110552
	speed: 0.1112s/iter; left time: 7884.0786s
	iters: 500, epoch: 5 | loss: 0.0997856
	speed: 0.1119s/iter; left time: 7927.2165s
	iters: 600, epoch: 5 | loss: 0.1085910
	speed: 0.1141s/iter; left time: 8068.7005s
	iters: 700, epoch: 5 | loss: 0.0906752
	speed: 0.1124s/iter; left time: 7937.0686s
	iters: 800, epoch: 5 | loss: 0.0881957
	speed: 0.1132s/iter; left time: 7983.2926s
	iters: 900, epoch: 5 | loss: 0.1219619
	speed: 0.1158s/iter; left time: 8154.0782s
	iters: 1000, epoch: 5 | loss: 0.1071277
	speed: 0.1137s/iter; left time: 7997.3908s
	iters: 1100, epoch: 5 | loss: 0.1084025
	speed: 0.1156s/iter; left time: 8117.4470s
	iters: 1200, epoch: 5 | loss: 0.0964981
	speed: 0.1152s/iter; left time: 8076.2562s
	iters: 1300, epoch: 5 | loss: 0.0842596
	speed: 0.1136s/iter; left time: 7952.2301s
	iters: 1400, epoch: 5 | loss: 0.0926249
	speed: 0.1134s/iter; left time: 7929.3991s
	iters: 1500, epoch: 5 | loss: 0.0907346
	speed: 0.1130s/iter; left time: 7888.9182s
	iters: 1600, epoch: 5 | loss: 0.1106110
	speed: 0.1145s/iter; left time: 7981.8965s
	iters: 1700, epoch: 5 | loss: 0.0988417
	speed: 0.1146s/iter; left time: 7978.9288s
	iters: 1800, epoch: 5 | loss: 0.0920804
	speed: 0.1143s/iter; left time: 7944.8159s
	iters: 1900, epoch: 5 | loss: 0.0919630
	speed: 0.1155s/iter; left time: 8015.5406s
	iters: 2000, epoch: 5 | loss: 0.1004907
	speed: 0.1155s/iter; left time: 8005.2387s
	iters: 2100, epoch: 5 | loss: 0.1181042
	speed: 0.1144s/iter; left time: 7914.6309s
	iters: 2200, epoch: 5 | loss: 0.0876759
	speed: 0.1135s/iter; left time: 7840.9967s
	iters: 2300, epoch: 5 | loss: 0.1073024
	speed: 0.1145s/iter; left time: 7900.6209s
	iters: 2400, epoch: 5 | loss: 0.0821408
	speed: 0.1135s/iter; left time: 7818.9375s
	iters: 2500, epoch: 5 | loss: 0.0953626
	speed: 0.1153s/iter; left time: 7932.7214s
	iters: 2600, epoch: 5 | loss: 0.1104295
	speed: 0.1141s/iter; left time: 7843.2803s
	iters: 2700, epoch: 5 | loss: 0.1122409
	speed: 0.1150s/iter; left time: 7888.2967s
	iters: 2800, epoch: 5 | loss: 0.0743636
	speed: 0.1139s/iter; left time: 7800.6765s
	iters: 2900, epoch: 5 | loss: 0.0947080
	speed: 0.1125s/iter; left time: 7699.2210s
	iters: 3000, epoch: 5 | loss: 0.1082617
	speed: 0.1138s/iter; left time: 7774.5218s
	iters: 3100, epoch: 5 | loss: 0.0972924
	speed: 0.1158s/iter; left time: 7897.4971s
	iters: 3200, epoch: 5 | loss: 0.1161426
	speed: 0.1147s/iter; left time: 7810.0341s
	iters: 3300, epoch: 5 | loss: 0.0934898
	speed: 0.1141s/iter; left time: 7761.1548s
	iters: 3400, epoch: 5 | loss: 0.0890894
	speed: 0.1152s/iter; left time: 7820.6728s
	iters: 3500, epoch: 5 | loss: 0.0774576
	speed: 0.1154s/iter; left time: 7827.0229s
	iters: 3600, epoch: 5 | loss: 0.1041150
	speed: 0.1168s/iter; left time: 7905.8663s
	iters: 3700, epoch: 5 | loss: 0.0764355
	speed: 0.1134s/iter; left time: 7667.8056s
	iters: 3800, epoch: 5 | loss: 0.0967276
	speed: 0.1140s/iter; left time: 7694.3834s
	iters: 3900, epoch: 5 | loss: 0.1057422
	speed: 0.1142s/iter; left time: 7697.6299s
	iters: 4000, epoch: 5 | loss: 0.1008978
	speed: 0.1144s/iter; left time: 7701.1571s
	iters: 4100, epoch: 5 | loss: 0.1179423
	speed: 0.1149s/iter; left time: 7720.0400s
	iters: 4200, epoch: 5 | loss: 0.1178501
	speed: 0.1099s/iter; left time: 7376.8081s
	iters: 4300, epoch: 5 | loss: 0.0911569
	speed: 0.1127s/iter; left time: 7551.5480s
	iters: 4400, epoch: 5 | loss: 0.0975429
	speed: 0.1136s/iter; left time: 7599.4730s
Epoch: 5 cost time: 00h:08m:29.17s
Epoch: 5 | Train Loss: 0.0987026 Vali Loss: 0.1216048 Test Loss: 0.1345417
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1011339
	speed: 1.5360s/iter; left time: 102536.0272s
	iters: 200, epoch: 6 | loss: 0.0883259
	speed: 0.1171s/iter; left time: 7804.2875s
	iters: 300, epoch: 6 | loss: 0.1075289
	speed: 0.1141s/iter; left time: 7594.8624s
	iters: 400, epoch: 6 | loss: 0.0989359
	speed: 0.1163s/iter; left time: 7728.1429s
	iters: 500, epoch: 6 | loss: 0.0862649
	speed: 0.1143s/iter; left time: 7586.5485s
	iters: 600, epoch: 6 | loss: 0.1002253
	speed: 0.1150s/iter; left time: 7621.8291s
	iters: 700, epoch: 6 | loss: 0.1083656
	speed: 0.1156s/iter; left time: 7648.8588s
	iters: 800, epoch: 6 | loss: 0.0928279
	speed: 0.1160s/iter; left time: 7662.9690s
	iters: 900, epoch: 6 | loss: 0.0807987
	speed: 0.1151s/iter; left time: 7593.2415s
	iters: 1000, epoch: 6 | loss: 0.0948872
	speed: 0.1148s/iter; left time: 7563.3529s
	iters: 1100, epoch: 6 | loss: 0.0827360
	speed: 0.1164s/iter; left time: 7655.3289s
	iters: 1200, epoch: 6 | loss: 0.1174165
	speed: 0.1145s/iter; left time: 7518.5707s
	iters: 1300, epoch: 6 | loss: 0.0992087
	speed: 0.1147s/iter; left time: 7520.0064s
	iters: 1400, epoch: 6 | loss: 0.0848289
	speed: 0.1166s/iter; left time: 7629.1240s
	iters: 1500, epoch: 6 | loss: 0.0922957
	speed: 0.1152s/iter; left time: 7528.3518s
	iters: 1600, epoch: 6 | loss: 0.1061229
	speed: 0.1166s/iter; left time: 7606.1201s
	iters: 1700, epoch: 6 | loss: 0.0937682
	speed: 0.1160s/iter; left time: 7561.1492s
	iters: 1800, epoch: 6 | loss: 0.1026462
	speed: 0.1133s/iter; left time: 7371.2713s
	iters: 1900, epoch: 6 | loss: 0.0818370
	speed: 0.1157s/iter; left time: 7513.2731s
	iters: 2000, epoch: 6 | loss: 0.1049387
	speed: 0.1159s/iter; left time: 7519.7116s
	iters: 2100, epoch: 6 | loss: 0.0856962
	speed: 0.1147s/iter; left time: 7428.7141s
	iters: 2200, epoch: 6 | loss: 0.1132535
	speed: 0.1156s/iter; left time: 7473.8852s
	iters: 2300, epoch: 6 | loss: 0.0780297
	speed: 0.1136s/iter; left time: 7334.1105s
	iters: 2400, epoch: 6 | loss: 0.0942708
	speed: 0.1139s/iter; left time: 7340.2087s
	iters: 2500, epoch: 6 | loss: 0.0917941
	speed: 0.1145s/iter; left time: 7366.6319s
	iters: 2600, epoch: 6 | loss: 0.0872721
	speed: 0.1154s/iter; left time: 7417.8992s
	iters: 2700, epoch: 6 | loss: 0.0825186
	speed: 0.1150s/iter; left time: 7377.3480s
	iters: 2800, epoch: 6 | loss: 0.0905587
	speed: 0.1162s/iter; left time: 7444.0894s
	iters: 2900, epoch: 6 | loss: 0.0887696
	speed: 0.1138s/iter; left time: 7277.6593s
	iters: 3000, epoch: 6 | loss: 0.1022261
	speed: 0.1136s/iter; left time: 7256.6604s
	iters: 3100, epoch: 6 | loss: 0.1016905
	speed: 0.1158s/iter; left time: 7382.1130s
	iters: 3200, epoch: 6 | loss: 0.0889834
	speed: 0.1147s/iter; left time: 7304.1106s
	iters: 3300, epoch: 6 | loss: 0.0868730
	speed: 0.1146s/iter; left time: 7285.4443s
	iters: 3400, epoch: 6 | loss: 0.0905508
	speed: 0.1136s/iter; left time: 7207.7473s
	iters: 3500, epoch: 6 | loss: 0.0885148
	speed: 0.1152s/iter; left time: 7298.9761s
	iters: 3600, epoch: 6 | loss: 0.0922447
	speed: 0.1151s/iter; left time: 7280.8357s
	iters: 3700, epoch: 6 | loss: 0.0886584
	speed: 0.1145s/iter; left time: 7228.4714s
	iters: 3800, epoch: 6 | loss: 0.0922629
	speed: 0.1146s/iter; left time: 7225.4081s
	iters: 3900, epoch: 6 | loss: 0.0939470
	speed: 0.1130s/iter; left time: 7113.7216s
	iters: 4000, epoch: 6 | loss: 0.0905015
	speed: 0.1145s/iter; left time: 7194.3585s
	iters: 4100, epoch: 6 | loss: 0.0758674
	speed: 0.1167s/iter; left time: 7321.7619s
	iters: 4200, epoch: 6 | loss: 0.0957208
	speed: 0.1136s/iter; left time: 7117.3013s
	iters: 4300, epoch: 6 | loss: 0.1053216
	speed: 0.1134s/iter; left time: 7095.8461s
	iters: 4400, epoch: 6 | loss: 0.0906008
	speed: 0.1147s/iter; left time: 7163.6950s
Epoch: 6 cost time: 00h:08m:32.77s
Epoch: 6 | Train Loss: 0.0954798 Vali Loss: 0.1227273 Test Loss: 0.1344287
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.1033562
	speed: 1.5449s/iter; left time: 96242.8774s
	iters: 200, epoch: 7 | loss: 0.0896851
	speed: 0.1128s/iter; left time: 7014.1229s
	iters: 300, epoch: 7 | loss: 0.0913225
	speed: 0.1154s/iter; left time: 7166.6403s
	iters: 400, epoch: 7 | loss: 0.0853823
	speed: 0.1144s/iter; left time: 7095.4587s
	iters: 500, epoch: 7 | loss: 0.0857644
	speed: 0.1135s/iter; left time: 7026.9296s
	iters: 600, epoch: 7 | loss: 0.0806916
	speed: 0.1141s/iter; left time: 7053.9584s
	iters: 700, epoch: 7 | loss: 0.1021493
	speed: 0.1169s/iter; left time: 7212.0236s
	iters: 800, epoch: 7 | loss: 0.0732420
	speed: 0.1147s/iter; left time: 7066.7822s
	iters: 900, epoch: 7 | loss: 0.0850529
	speed: 0.1133s/iter; left time: 6969.6772s
	iters: 1000, epoch: 7 | loss: 0.0993610
	speed: 0.1148s/iter; left time: 7050.6510s
	iters: 1100, epoch: 7 | loss: 0.1097831
	speed: 0.1150s/iter; left time: 7049.1661s
	iters: 1200, epoch: 7 | loss: 0.1054772
	speed: 0.1153s/iter; left time: 7054.5038s
	iters: 1300, epoch: 7 | loss: 0.0870716
	speed: 0.1149s/iter; left time: 7022.7027s
	iters: 1400, epoch: 7 | loss: 0.0907186
	speed: 0.1148s/iter; left time: 7003.8567s
	iters: 1500, epoch: 7 | loss: 0.0836305
	speed: 0.1153s/iter; left time: 7019.3724s
	iters: 1600, epoch: 7 | loss: 0.0796124
	speed: 0.1154s/iter; left time: 7013.8048s
	iters: 1700, epoch: 7 | loss: 0.0783959
	speed: 0.1152s/iter; left time: 6994.2668s
	iters: 1800, epoch: 7 | loss: 0.1006658
	speed: 0.1179s/iter; left time: 7146.0686s
	iters: 1900, epoch: 7 | loss: 0.0884392
	speed: 0.1131s/iter; left time: 6844.4431s
	iters: 2000, epoch: 7 | loss: 0.0906714
	speed: 0.1152s/iter; left time: 6955.5823s
	iters: 2100, epoch: 7 | loss: 0.0930545
	speed: 0.1124s/iter; left time: 6774.6318s
	iters: 2200, epoch: 7 | loss: 0.0999339
	speed: 0.1150s/iter; left time: 6923.0216s
	iters: 2300, epoch: 7 | loss: 0.0763448
	speed: 0.1141s/iter; left time: 6858.2620s
	iters: 2400, epoch: 7 | loss: 0.0873501
	speed: 0.1148s/iter; left time: 6890.8708s
	iters: 2500, epoch: 7 | loss: 0.0835626
	speed: 0.1134s/iter; left time: 6789.8264s
	iters: 2600, epoch: 7 | loss: 0.0899396
	speed: 0.1144s/iter; left time: 6843.9955s
	iters: 2700, epoch: 7 | loss: 0.0973071
	speed: 0.1155s/iter; left time: 6893.7186s
	iters: 2800, epoch: 7 | loss: 0.0889941
	speed: 0.1119s/iter; left time: 6669.7559s
	iters: 2900, epoch: 7 | loss: 0.0885513
	speed: 0.1140s/iter; left time: 6784.7081s
	iters: 3000, epoch: 7 | loss: 0.0899405
	speed: 0.1142s/iter; left time: 6782.1823s
	iters: 3100, epoch: 7 | loss: 0.0913069
	speed: 0.1141s/iter; left time: 6766.5576s
	iters: 3200, epoch: 7 | loss: 0.0929181
	speed: 0.1131s/iter; left time: 6693.3679s
	iters: 3300, epoch: 7 | loss: 0.0748527
	speed: 0.1134s/iter; left time: 6702.6012s
	iters: 3400, epoch: 7 | loss: 0.0883430
	speed: 0.1127s/iter; left time: 6649.7692s
	iters: 3500, epoch: 7 | loss: 0.0995779
	speed: 0.1146s/iter; left time: 6752.0857s
	iters: 3600, epoch: 7 | loss: 0.0879578
	speed: 0.1146s/iter; left time: 6737.0533s
	iters: 3700, epoch: 7 | loss: 0.0936343
	speed: 0.1164s/iter; left time: 6831.2676s
	iters: 3800, epoch: 7 | loss: 0.0912004
	speed: 0.1137s/iter; left time: 6662.9285s
	iters: 3900, epoch: 7 | loss: 0.0808091
	speed: 0.1143s/iter; left time: 6686.6893s
	iters: 4000, epoch: 7 | loss: 0.1068037
	speed: 0.1160s/iter; left time: 6773.0787s
	iters: 4100, epoch: 7 | loss: 0.0853559
	speed: 0.1127s/iter; left time: 6573.1499s
	iters: 4200, epoch: 7 | loss: 0.1038158
	speed: 0.1145s/iter; left time: 6666.0709s
	iters: 4300, epoch: 7 | loss: 0.1103765
	speed: 0.1153s/iter; left time: 6698.0690s
	iters: 4400, epoch: 7 | loss: 0.0968011
	speed: 0.1133s/iter; left time: 6573.2121s
Epoch: 7 cost time: 00h:08m:30.89s
Epoch: 7 | Train Loss: 0.0925967 Vali Loss: 0.1245577 Test Loss: 0.1345884
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.03578183427453041, rmse:0.18916086852550507, mae:0.12824216485023499, rse:0.6698496341705322
success delete checkpoints
Intermediate time for DE and pred_len 96: 01h:19m:09.94s

=== Starting experiments for pred_len: 168 ===

--- Running model for DE, pred_len=168 ---
train 142285
val 30365
test 30365
[2024-11-03 04:55:56,825] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 04:55:57,946] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 04:55:57,946] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 04:55:57,946] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 04:55:58,038] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 04:55:58,038] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 04:55:58,773] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 04:55:58,774] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 04:55:58,774] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 04:55:58,775] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 04:55:58,775] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 04:55:58,775] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 04:55:58,775] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 04:55:58,775] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 04:55:58,775] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 04:55:58,775] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 04:55:59,162] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 04:55:59,163] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 04:55:59,194] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 88.96 GB, percent = 11.8%
[2024-11-03 04:55:59,359] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 04:55:59,360] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-03 04:55:59,360] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 88.97 GB, percent = 11.8%
[2024-11-03 04:55:59,360] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 04:55:59,504] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 04:55:59,505] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-03 04:55:59,505] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 89.03 GB, percent = 11.8%
[2024-11-03 04:55:59,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 04:55:59,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 04:55:59,506] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 04:55:59,506] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 04:55:59,507] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 04:55:59,507] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f01f9fd6f50>
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 04:55:59,508] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 04:55:59,509] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 04:55:59,510] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 04:55:59,510] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 04:55:59,510] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 04:55:59,510] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1492427
	speed: 0.1689s/iter; left time: 14998.9946s
	iters: 200, epoch: 1 | loss: 0.1605359
	speed: 0.1261s/iter; left time: 11190.3225s
	iters: 300, epoch: 1 | loss: 0.1671229
	speed: 0.1253s/iter; left time: 11106.0189s
	iters: 400, epoch: 1 | loss: 0.1654047
	speed: 0.1255s/iter; left time: 11113.6227s
	iters: 500, epoch: 1 | loss: 0.1528231
	speed: 0.1259s/iter; left time: 11130.4096s
	iters: 600, epoch: 1 | loss: 0.1641308
	speed: 0.1259s/iter; left time: 11120.4534s
	iters: 700, epoch: 1 | loss: 0.1460070
	speed: 0.1265s/iter; left time: 11163.3958s
	iters: 800, epoch: 1 | loss: 0.1177307
	speed: 0.1276s/iter; left time: 11242.2914s
	iters: 900, epoch: 1 | loss: 0.1349947
	speed: 0.1269s/iter; left time: 11173.5874s
	iters: 1000, epoch: 1 | loss: 0.1090521
	speed: 0.1261s/iter; left time: 11086.5921s
	iters: 1100, epoch: 1 | loss: 0.1334336
	speed: 0.1265s/iter; left time: 11109.3633s
	iters: 1200, epoch: 1 | loss: 0.1300411
	speed: 0.1276s/iter; left time: 11197.1827s
	iters: 1300, epoch: 1 | loss: 0.1205211
	speed: 0.1266s/iter; left time: 11093.1295s
	iters: 1400, epoch: 1 | loss: 0.1304281
	speed: 0.1244s/iter; left time: 10886.0260s
	iters: 1500, epoch: 1 | loss: 0.1271410
	speed: 0.1264s/iter; left time: 11049.2675s
	iters: 1600, epoch: 1 | loss: 0.1058479
	speed: 0.1275s/iter; left time: 11129.7255s
	iters: 1700, epoch: 1 | loss: 0.1209870
	speed: 0.1265s/iter; left time: 11029.6078s
	iters: 1800, epoch: 1 | loss: 0.1023959
	speed: 0.1272s/iter; left time: 11078.7808s
	iters: 1900, epoch: 1 | loss: 0.1413429
	speed: 0.1274s/iter; left time: 11089.8278s
	iters: 2000, epoch: 1 | loss: 0.1427599
	speed: 0.1268s/iter; left time: 11019.0196s
	iters: 2100, epoch: 1 | loss: 0.1329999
	speed: 0.1256s/iter; left time: 10905.1808s
	iters: 2200, epoch: 1 | loss: 0.1120558
	speed: 0.1267s/iter; left time: 10986.1723s
	iters: 2300, epoch: 1 | loss: 0.0989436
	speed: 0.1277s/iter; left time: 11060.9135s
	iters: 2400, epoch: 1 | loss: 0.1160462
	speed: 0.1281s/iter; left time: 11079.1538s
	iters: 2500, epoch: 1 | loss: 0.1234167
	speed: 0.1267s/iter; left time: 10953.3932s
	iters: 2600, epoch: 1 | loss: 0.1299602
	speed: 0.1275s/iter; left time: 11009.6709s
	iters: 2700, epoch: 1 | loss: 0.1306166
	speed: 0.1254s/iter; left time: 10812.0762s
	iters: 2800, epoch: 1 | loss: 0.1211876
	speed: 0.1246s/iter; left time: 10732.5673s
	iters: 2900, epoch: 1 | loss: 0.1157711
	speed: 0.1257s/iter; left time: 10811.2061s
	iters: 3000, epoch: 1 | loss: 0.0999164
	speed: 0.1260s/iter; left time: 10828.2032s
	iters: 3100, epoch: 1 | loss: 0.1516199
	speed: 0.1257s/iter; left time: 10790.8558s
	iters: 3200, epoch: 1 | loss: 0.1097987
	speed: 0.1227s/iter; left time: 10516.8003s
	iters: 3300, epoch: 1 | loss: 0.1195762
	speed: 0.1243s/iter; left time: 10638.8691s
	iters: 3400, epoch: 1 | loss: 0.1289778
	speed: 0.1240s/iter; left time: 10602.2915s
	iters: 3500, epoch: 1 | loss: 0.1021916
	speed: 0.1258s/iter; left time: 10744.1492s
	iters: 3600, epoch: 1 | loss: 0.1183287
	speed: 0.1243s/iter; left time: 10606.4077s
	iters: 3700, epoch: 1 | loss: 0.1355938
	speed: 0.1235s/iter; left time: 10522.3467s
	iters: 3800, epoch: 1 | loss: 0.1252127
	speed: 0.1223s/iter; left time: 10407.7603s
	iters: 3900, epoch: 1 | loss: 0.1068365
	speed: 0.1246s/iter; left time: 10597.5062s
	iters: 4000, epoch: 1 | loss: 0.1084060
	speed: 0.1245s/iter; left time: 10571.2230s
	iters: 4100, epoch: 1 | loss: 0.1262050
	speed: 0.1235s/iter; left time: 10477.3395s
	iters: 4200, epoch: 1 | loss: 0.1099667
	speed: 0.1241s/iter; left time: 10516.0039s
	iters: 4300, epoch: 1 | loss: 0.1208501
	speed: 0.1237s/iter; left time: 10468.0181s
	iters: 4400, epoch: 1 | loss: 0.1325888
	speed: 0.1255s/iter; left time: 10609.7889s
Epoch: 1 cost time: 00h:09m:20.32s
Epoch: 1 | Train Loss: 0.1270849 Vali Loss: 0.1233267 Test Loss: 0.1336193
Validation loss decreased (inf --> 0.123327).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1183373
	speed: 1.8223s/iter; left time: 153754.1186s
	iters: 200, epoch: 2 | loss: 0.1098894
	speed: 0.1182s/iter; left time: 9964.4478s
	iters: 300, epoch: 2 | loss: 0.1131674
	speed: 0.1166s/iter; left time: 9818.2258s
	iters: 400, epoch: 2 | loss: 0.1160400
	speed: 0.1172s/iter; left time: 9850.7146s
	iters: 500, epoch: 2 | loss: 0.0886714
	speed: 0.1199s/iter; left time: 10065.0167s
	iters: 600, epoch: 2 | loss: 0.1193221
	speed: 0.1171s/iter; left time: 9825.4766s
	iters: 700, epoch: 2 | loss: 0.1303138
	speed: 0.1174s/iter; left time: 9832.2253s
	iters: 800, epoch: 2 | loss: 0.1092902
	speed: 0.1191s/iter; left time: 9966.0618s
	iters: 900, epoch: 2 | loss: 0.0996466
	speed: 0.1227s/iter; left time: 10250.5498s
	iters: 1000, epoch: 2 | loss: 0.1157148
	speed: 0.1179s/iter; left time: 9845.2584s
	iters: 1100, epoch: 2 | loss: 0.1112141
	speed: 0.1194s/iter; left time: 9953.4943s
	iters: 1200, epoch: 2 | loss: 0.1180607
	speed: 0.1182s/iter; left time: 9846.0720s
	iters: 1300, epoch: 2 | loss: 0.0878751
	speed: 0.1193s/iter; left time: 9920.3713s
	iters: 1400, epoch: 2 | loss: 0.1204318
	speed: 0.1198s/iter; left time: 9951.3580s
	iters: 1500, epoch: 2 | loss: 0.1055659
	speed: 0.1207s/iter; left time: 10015.5060s
	iters: 1600, epoch: 2 | loss: 0.1180415
	speed: 0.1220s/iter; left time: 10108.0111s
	iters: 1700, epoch: 2 | loss: 0.1256569
	speed: 0.1165s/iter; left time: 9646.1022s
	iters: 1800, epoch: 2 | loss: 0.1117147
	speed: 0.1159s/iter; left time: 9583.7666s
	iters: 1900, epoch: 2 | loss: 0.1046314
	speed: 0.1190s/iter; left time: 9824.2144s
	iters: 2000, epoch: 2 | loss: 0.1071824
	speed: 0.1218s/iter; left time: 10045.4236s
	iters: 2100, epoch: 2 | loss: 0.1128184
	speed: 0.1198s/iter; left time: 9872.1925s
	iters: 2200, epoch: 2 | loss: 0.1227209
	speed: 0.1191s/iter; left time: 9795.1126s
	iters: 2300, epoch: 2 | loss: 0.1197821
	speed: 0.1197s/iter; left time: 9834.7361s
	iters: 2400, epoch: 2 | loss: 0.1249823
	speed: 0.1185s/iter; left time: 9729.3528s
	iters: 2500, epoch: 2 | loss: 0.1261758
	speed: 0.1177s/iter; left time: 9645.1390s
	iters: 2600, epoch: 2 | loss: 0.1112454
	speed: 0.1169s/iter; left time: 9568.3370s
	iters: 2700, epoch: 2 | loss: 0.1138095
	speed: 0.1158s/iter; left time: 9466.3586s
	iters: 2800, epoch: 2 | loss: 0.0994604
	speed: 0.1175s/iter; left time: 9597.1147s
	iters: 2900, epoch: 2 | loss: 0.1096554
	speed: 0.1142s/iter; left time: 9316.7782s
	iters: 3000, epoch: 2 | loss: 0.1068463
	speed: 0.1170s/iter; left time: 9529.2329s
	iters: 3100, epoch: 2 | loss: 0.1206979
	speed: 0.1152s/iter; left time: 9372.1133s
	iters: 3200, epoch: 2 | loss: 0.1085434
	speed: 0.1208s/iter; left time: 9814.7812s
	iters: 3300, epoch: 2 | loss: 0.1045549
	speed: 0.1196s/iter; left time: 9709.0210s
	iters: 3400, epoch: 2 | loss: 0.1207838
	speed: 0.1189s/iter; left time: 9640.1564s
	iters: 3500, epoch: 2 | loss: 0.1154747
	speed: 0.1164s/iter; left time: 9424.9487s
	iters: 3600, epoch: 2 | loss: 0.1074588
	speed: 0.1167s/iter; left time: 9435.2399s
	iters: 3700, epoch: 2 | loss: 0.1014723
	speed: 0.1171s/iter; left time: 9457.4684s
	iters: 3800, epoch: 2 | loss: 0.0964471
	speed: 0.1169s/iter; left time: 9432.4725s
	iters: 3900, epoch: 2 | loss: 0.1228269
	speed: 0.1173s/iter; left time: 9447.5816s
	iters: 4000, epoch: 2 | loss: 0.1099236
	speed: 0.1169s/iter; left time: 9405.8898s
	iters: 4100, epoch: 2 | loss: 0.1171050
	speed: 0.1216s/iter; left time: 9775.9550s
	iters: 4200, epoch: 2 | loss: 0.1104717
	speed: 0.1183s/iter; left time: 9499.1964s
	iters: 4300, epoch: 2 | loss: 0.1126500
	speed: 0.1213s/iter; left time: 9726.5423s
	iters: 4400, epoch: 2 | loss: 0.1323302
	speed: 0.1198s/iter; left time: 9595.5465s
Epoch: 2 cost time: 00h:08m:47.56s
Epoch: 2 | Train Loss: 0.1139773 Vali Loss: 0.1234052 Test Loss: 0.1342462
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1082153
	speed: 1.5796s/iter; left time: 126255.4090s
	iters: 200, epoch: 3 | loss: 0.1202841
	speed: 0.1189s/iter; left time: 9493.6879s
	iters: 300, epoch: 3 | loss: 0.0996917
	speed: 0.1184s/iter; left time: 9435.9582s
	iters: 400, epoch: 3 | loss: 0.1064174
	speed: 0.1157s/iter; left time: 9214.8919s
	iters: 500, epoch: 3 | loss: 0.1139071
	speed: 0.1180s/iter; left time: 9386.0109s
	iters: 600, epoch: 3 | loss: 0.1215968
	speed: 0.1142s/iter; left time: 9071.2138s
	iters: 700, epoch: 3 | loss: 0.1096018
	speed: 0.1197s/iter; left time: 9495.2993s
	iters: 800, epoch: 3 | loss: 0.1310975
	speed: 0.1203s/iter; left time: 9530.2566s
	iters: 900, epoch: 3 | loss: 0.1056969
	speed: 0.1183s/iter; left time: 9362.9065s
	iters: 1000, epoch: 3 | loss: 0.1081555
	speed: 0.1158s/iter; left time: 9150.0619s
	iters: 1100, epoch: 3 | loss: 0.0982659
	speed: 0.1183s/iter; left time: 9336.1627s
	iters: 1200, epoch: 3 | loss: 0.1056586
	speed: 0.1197s/iter; left time: 9436.5511s
	iters: 1300, epoch: 3 | loss: 0.1162706
	speed: 0.1196s/iter; left time: 9419.4681s
	iters: 1400, epoch: 3 | loss: 0.1264145
	speed: 0.1210s/iter; left time: 9512.3302s
	iters: 1500, epoch: 3 | loss: 0.1110645
	speed: 0.1198s/iter; left time: 9411.0207s
	iters: 1600, epoch: 3 | loss: 0.1157964
	speed: 0.1202s/iter; left time: 9428.6409s
	iters: 1700, epoch: 3 | loss: 0.1245955
	speed: 0.1179s/iter; left time: 9236.0999s
	iters: 1800, epoch: 3 | loss: 0.1219978
	speed: 0.1211s/iter; left time: 9474.4907s
	iters: 1900, epoch: 3 | loss: 0.1215639
	speed: 0.1194s/iter; left time: 9329.4055s
	iters: 2000, epoch: 3 | loss: 0.1222039
	speed: 0.1194s/iter; left time: 9318.2211s
	iters: 2100, epoch: 3 | loss: 0.0978573
	speed: 0.1180s/iter; left time: 9193.5410s
	iters: 2200, epoch: 3 | loss: 0.1149430
	speed: 0.1199s/iter; left time: 9330.3611s
	iters: 2300, epoch: 3 | loss: 0.1145440
	speed: 0.1201s/iter; left time: 9334.5904s
	iters: 2400, epoch: 3 | loss: 0.0993142
	speed: 0.1208s/iter; left time: 9376.5978s
	iters: 2500, epoch: 3 | loss: 0.0932033
	speed: 0.1171s/iter; left time: 9076.9066s
	iters: 2600, epoch: 3 | loss: 0.1083821
	speed: 0.1178s/iter; left time: 9120.5453s
	iters: 2700, epoch: 3 | loss: 0.1158013
	speed: 0.1144s/iter; left time: 8849.0927s
	iters: 2800, epoch: 3 | loss: 0.1378757
	speed: 0.1162s/iter; left time: 8974.1123s
	iters: 2900, epoch: 3 | loss: 0.0924771
	speed: 0.1162s/iter; left time: 8961.4239s
	iters: 3000, epoch: 3 | loss: 0.1077057
	speed: 0.1180s/iter; left time: 9090.4405s
	iters: 3100, epoch: 3 | loss: 0.1156989
	speed: 0.1167s/iter; left time: 8979.6128s
	iters: 3200, epoch: 3 | loss: 0.1000350
	speed: 0.1160s/iter; left time: 8909.7129s
	iters: 3300, epoch: 3 | loss: 0.1146565
	speed: 0.1172s/iter; left time: 8990.0227s
	iters: 3400, epoch: 3 | loss: 0.1231436
	speed: 0.1170s/iter; left time: 8968.6194s
	iters: 3500, epoch: 3 | loss: 0.1224817
	speed: 0.1151s/iter; left time: 8805.5514s
	iters: 3600, epoch: 3 | loss: 0.1114092
	speed: 0.1154s/iter; left time: 8821.8669s
	iters: 3700, epoch: 3 | loss: 0.1154894
	speed: 0.1148s/iter; left time: 8760.2005s
	iters: 3800, epoch: 3 | loss: 0.0983998
	speed: 0.1184s/iter; left time: 9027.7861s
	iters: 3900, epoch: 3 | loss: 0.1058075
	speed: 0.1176s/iter; left time: 8949.7973s
	iters: 4000, epoch: 3 | loss: 0.1094842
	speed: 0.1186s/iter; left time: 9016.7895s
	iters: 4100, epoch: 3 | loss: 0.1029801
	speed: 0.1215s/iter; left time: 9222.0609s
	iters: 4200, epoch: 3 | loss: 0.1099910
	speed: 0.1177s/iter; left time: 8921.4090s
	iters: 4300, epoch: 3 | loss: 0.1054428
	speed: 0.1200s/iter; left time: 9088.1881s
	iters: 4400, epoch: 3 | loss: 0.0913317
	speed: 0.1180s/iter; left time: 8925.4389s
Epoch: 3 cost time: 00h:08m:45.78s
Epoch: 3 | Train Loss: 0.1093807 Vali Loss: 0.1236754 Test Loss: 0.1367024
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0959466
	speed: 1.5738s/iter; left time: 118798.5643s
	iters: 200, epoch: 4 | loss: 0.0858854
	speed: 0.1189s/iter; left time: 8961.9629s
	iters: 300, epoch: 4 | loss: 0.0893636
	speed: 0.1198s/iter; left time: 9019.7581s
	iters: 400, epoch: 4 | loss: 0.1088450
	speed: 0.1180s/iter; left time: 8870.8322s
	iters: 500, epoch: 4 | loss: 0.1087373
	speed: 0.1165s/iter; left time: 8747.7988s
	iters: 600, epoch: 4 | loss: 0.1005550
	speed: 0.1151s/iter; left time: 8630.8889s
	iters: 700, epoch: 4 | loss: 0.0969683
	speed: 0.1181s/iter; left time: 8846.1387s
	iters: 800, epoch: 4 | loss: 0.1045174
	speed: 0.1171s/iter; left time: 8754.9369s
	iters: 900, epoch: 4 | loss: 0.1086594
	speed: 0.1166s/iter; left time: 8704.5463s
	iters: 1000, epoch: 4 | loss: 0.1303164
	speed: 0.1176s/iter; left time: 8774.3390s
	iters: 1100, epoch: 4 | loss: 0.1121879
	speed: 0.1182s/iter; left time: 8802.4399s
	iters: 1200, epoch: 4 | loss: 0.1189122
	speed: 0.1178s/iter; left time: 8761.6614s
	iters: 1300, epoch: 4 | loss: 0.1055549
	speed: 0.1178s/iter; left time: 8754.0308s
	iters: 1400, epoch: 4 | loss: 0.1178071
	speed: 0.1213s/iter; left time: 8998.8108s
	iters: 1500, epoch: 4 | loss: 0.1012621
	speed: 0.1200s/iter; left time: 8890.9761s
	iters: 1600, epoch: 4 | loss: 0.1049342
	speed: 0.1199s/iter; left time: 8871.7970s
	iters: 1700, epoch: 4 | loss: 0.1118138
	speed: 0.1209s/iter; left time: 8934.2080s
	iters: 1800, epoch: 4 | loss: 0.1249317
	speed: 0.1209s/iter; left time: 8916.8846s
	iters: 1900, epoch: 4 | loss: 0.1314284
	speed: 0.1186s/iter; left time: 8740.8187s
	iters: 2000, epoch: 4 | loss: 0.1265800
	speed: 0.1188s/iter; left time: 8738.2363s
	iters: 2100, epoch: 4 | loss: 0.1018833
	speed: 0.1207s/iter; left time: 8866.4914s
	iters: 2200, epoch: 4 | loss: 0.1211214
	speed: 0.1200s/iter; left time: 8803.3129s
	iters: 2300, epoch: 4 | loss: 0.0848068
	speed: 0.1199s/iter; left time: 8789.0981s
	iters: 2400, epoch: 4 | loss: 0.1038890
	speed: 0.1198s/iter; left time: 8769.5086s
	iters: 2500, epoch: 4 | loss: 0.1123954
	speed: 0.1190s/iter; left time: 8694.3077s
	iters: 2600, epoch: 4 | loss: 0.0989040
	speed: 0.1209s/iter; left time: 8822.2843s
	iters: 2700, epoch: 4 | loss: 0.1005402
	speed: 0.1177s/iter; left time: 8575.7761s
	iters: 2800, epoch: 4 | loss: 0.1054526
	speed: 0.1200s/iter; left time: 8734.2448s
	iters: 2900, epoch: 4 | loss: 0.1114677
	speed: 0.1160s/iter; left time: 8431.7920s
	iters: 3000, epoch: 4 | loss: 0.1075196
	speed: 0.1189s/iter; left time: 8628.7340s
	iters: 3100, epoch: 4 | loss: 0.0856683
	speed: 0.1195s/iter; left time: 8658.9518s
	iters: 3200, epoch: 4 | loss: 0.1058800
	speed: 0.1180s/iter; left time: 8543.6849s
	iters: 3300, epoch: 4 | loss: 0.1083319
	speed: 0.1208s/iter; left time: 8732.2973s
	iters: 3400, epoch: 4 | loss: 0.0981609
	speed: 0.1202s/iter; left time: 8678.0036s
	iters: 3500, epoch: 4 | loss: 0.0921983
	speed: 0.1207s/iter; left time: 8697.5703s
	iters: 3600, epoch: 4 | loss: 0.1049358
	speed: 0.1205s/iter; left time: 8675.4825s
	iters: 3700, epoch: 4 | loss: 0.0929390
	speed: 0.1195s/iter; left time: 8590.2117s
	iters: 3800, epoch: 4 | loss: 0.0982588
	speed: 0.1194s/iter; left time: 8569.5723s
	iters: 3900, epoch: 4 | loss: 0.0918985
	speed: 0.1207s/iter; left time: 8649.6845s
	iters: 4000, epoch: 4 | loss: 0.1195650
	speed: 0.1191s/iter; left time: 8526.0042s
	iters: 4100, epoch: 4 | loss: 0.1090801
	speed: 0.1204s/iter; left time: 8606.8944s
	iters: 4200, epoch: 4 | loss: 0.1110307
	speed: 0.1192s/iter; left time: 8505.5317s
	iters: 4300, epoch: 4 | loss: 0.1110436
	speed: 0.1168s/iter; left time: 8327.9308s
	iters: 4400, epoch: 4 | loss: 0.1014118
	speed: 0.1167s/iter; left time: 8308.2562s
Epoch: 4 cost time: 00h:08m:50.08s
Epoch: 4 | Train Loss: 0.1046495 Vali Loss: 0.1247817 Test Loss: 0.1472365
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.1008341
	speed: 1.5943s/iter; left time: 113251.2470s
	iters: 200, epoch: 5 | loss: 0.1144764
	speed: 0.1212s/iter; left time: 8596.8570s
	iters: 300, epoch: 5 | loss: 0.1179324
	speed: 0.1224s/iter; left time: 8667.5363s
	iters: 400, epoch: 5 | loss: 0.1061344
	speed: 0.1203s/iter; left time: 8507.9813s
	iters: 500, epoch: 5 | loss: 0.0869319
	speed: 0.1168s/iter; left time: 8251.2865s
	iters: 600, epoch: 5 | loss: 0.0929676
	speed: 0.1206s/iter; left time: 8505.0312s
	iters: 700, epoch: 5 | loss: 0.1068786
	speed: 0.1206s/iter; left time: 8494.8491s
	iters: 800, epoch: 5 | loss: 0.0935982
	speed: 0.1185s/iter; left time: 8337.9691s
	iters: 900, epoch: 5 | loss: 0.1054375
	speed: 0.1175s/iter; left time: 8254.9225s
	iters: 1000, epoch: 5 | loss: 0.1086309
	speed: 0.1202s/iter; left time: 8432.1821s
	iters: 1100, epoch: 5 | loss: 0.1122420
	speed: 0.1192s/iter; left time: 8346.6720s
	iters: 1200, epoch: 5 | loss: 0.1004656
	speed: 0.1199s/iter; left time: 8382.4266s
	iters: 1300, epoch: 5 | loss: 0.0959615
	speed: 0.1190s/iter; left time: 8312.2799s
	iters: 1400, epoch: 5 | loss: 0.1126448
	speed: 0.1158s/iter; left time: 8076.4031s
	iters: 1500, epoch: 5 | loss: 0.0902287
	speed: 0.1192s/iter; left time: 8298.4404s
	iters: 1600, epoch: 5 | loss: 0.0997650
	speed: 0.1182s/iter; left time: 8220.6378s
	iters: 1700, epoch: 5 | loss: 0.1175994
	speed: 0.1196s/iter; left time: 8304.8478s
	iters: 1800, epoch: 5 | loss: 0.1059145
	speed: 0.1186s/iter; left time: 8226.3011s
	iters: 1900, epoch: 5 | loss: 0.0982435
	speed: 0.1187s/iter; left time: 8218.5163s
	iters: 2000, epoch: 5 | loss: 0.1148793
	speed: 0.1204s/iter; left time: 8326.4242s
	iters: 2100, epoch: 5 | loss: 0.1237828
	speed: 0.1166s/iter; left time: 8049.6795s
	iters: 2200, epoch: 5 | loss: 0.0931523
	speed: 0.1141s/iter; left time: 7862.8554s
	iters: 2300, epoch: 5 | loss: 0.0861305
	speed: 0.1160s/iter; left time: 7987.8383s
	iters: 2400, epoch: 5 | loss: 0.0990851
	speed: 0.1203s/iter; left time: 8266.9898s
	iters: 2500, epoch: 5 | loss: 0.0847341
	speed: 0.1185s/iter; left time: 8131.6616s
	iters: 2600, epoch: 5 | loss: 0.1076903
	speed: 0.1178s/iter; left time: 8076.7580s
	iters: 2700, epoch: 5 | loss: 0.1186636
	speed: 0.1187s/iter; left time: 8124.0679s
	iters: 2800, epoch: 5 | loss: 0.0813073
	speed: 0.1194s/iter; left time: 8161.1644s
	iters: 2900, epoch: 5 | loss: 0.0954584
	speed: 0.1186s/iter; left time: 8091.0418s
	iters: 3000, epoch: 5 | loss: 0.0905743
	speed: 0.1183s/iter; left time: 8063.9963s
	iters: 3100, epoch: 5 | loss: 0.1002901
	speed: 0.1187s/iter; left time: 8075.8405s
	iters: 3200, epoch: 5 | loss: 0.0847461
	speed: 0.1158s/iter; left time: 7868.1699s
	iters: 3300, epoch: 5 | loss: 0.1024117
	speed: 0.1141s/iter; left time: 7742.7515s
	iters: 3400, epoch: 5 | loss: 0.0998646
	speed: 0.1148s/iter; left time: 7772.8822s
	iters: 3500, epoch: 5 | loss: 0.0978041
	speed: 0.1169s/iter; left time: 7909.1294s
	iters: 3600, epoch: 5 | loss: 0.1110223
	speed: 0.1153s/iter; left time: 7785.4547s
	iters: 3700, epoch: 5 | loss: 0.0857197
	speed: 0.1136s/iter; left time: 7663.1865s
	iters: 3800, epoch: 5 | loss: 0.0900995
	speed: 0.1147s/iter; left time: 7720.9080s
	iters: 3900, epoch: 5 | loss: 0.0950421
	speed: 0.1149s/iter; left time: 7724.4726s
	iters: 4000, epoch: 5 | loss: 0.1002941
	speed: 0.1176s/iter; left time: 7894.1738s
	iters: 4100, epoch: 5 | loss: 0.1072492
	speed: 0.1189s/iter; left time: 7973.0274s
	iters: 4200, epoch: 5 | loss: 0.0923533
	speed: 0.1184s/iter; left time: 7922.1517s
	iters: 4300, epoch: 5 | loss: 0.0978186
	speed: 0.1173s/iter; left time: 7837.3911s
	iters: 4400, epoch: 5 | loss: 0.0912306
	speed: 0.1186s/iter; left time: 7914.4866s
Epoch: 5 cost time: 00h:08m:46.01s
Epoch: 5 | Train Loss: 0.1001263 Vali Loss: 0.1304869 Test Loss: 0.1511040
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1040925
	speed: 1.5616s/iter; left time: 103988.1173s
	iters: 200, epoch: 6 | loss: 0.1047199
	speed: 0.1154s/iter; left time: 7674.7197s
	iters: 300, epoch: 6 | loss: 0.0804931
	speed: 0.1161s/iter; left time: 7705.3513s
	iters: 400, epoch: 6 | loss: 0.0875467
	speed: 0.1160s/iter; left time: 7688.9225s
	iters: 500, epoch: 6 | loss: 0.0984672
	speed: 0.1171s/iter; left time: 7747.7005s
	iters: 600, epoch: 6 | loss: 0.1009006
	speed: 0.1151s/iter; left time: 7604.0128s
	iters: 700, epoch: 6 | loss: 0.0918718
	speed: 0.1153s/iter; left time: 7606.5829s
	iters: 800, epoch: 6 | loss: 0.1056673
	speed: 0.1163s/iter; left time: 7662.1389s
	iters: 900, epoch: 6 | loss: 0.0862563
	speed: 0.1173s/iter; left time: 7717.6531s
	iters: 1000, epoch: 6 | loss: 0.0999702
	speed: 0.1183s/iter; left time: 7772.3439s
	iters: 1100, epoch: 6 | loss: 0.0961189
	speed: 0.1175s/iter; left time: 7709.2899s
	iters: 1200, epoch: 6 | loss: 0.1147054
	speed: 0.1196s/iter; left time: 7832.8036s
	iters: 1300, epoch: 6 | loss: 0.0912160
	speed: 0.1159s/iter; left time: 7580.3703s
	iters: 1400, epoch: 6 | loss: 0.0981800
	speed: 0.1178s/iter; left time: 7691.0740s
	iters: 1500, epoch: 6 | loss: 0.0838766
	speed: 0.1163s/iter; left time: 7580.5629s
	iters: 1600, epoch: 6 | loss: 0.0883116
	speed: 0.1173s/iter; left time: 7636.6964s
	iters: 1700, epoch: 6 | loss: 0.0896513
	speed: 0.1184s/iter; left time: 7691.9413s
	iters: 1800, epoch: 6 | loss: 0.0974333
	speed: 0.1184s/iter; left time: 7682.3544s
	iters: 1900, epoch: 6 | loss: 0.0899982
	speed: 0.1191s/iter; left time: 7717.4354s
	iters: 2000, epoch: 6 | loss: 0.0925732
	speed: 0.1177s/iter; left time: 7611.6916s
	iters: 2100, epoch: 6 | loss: 0.0867949
	speed: 0.1157s/iter; left time: 7475.8082s
	iters: 2200, epoch: 6 | loss: 0.1011756
	speed: 0.1154s/iter; left time: 7445.3419s
	iters: 2300, epoch: 6 | loss: 0.0931246
	speed: 0.1148s/iter; left time: 7393.9080s
	iters: 2400, epoch: 6 | loss: 0.0912003
	speed: 0.1158s/iter; left time: 7443.0243s
	iters: 2500, epoch: 6 | loss: 0.0813842
	speed: 0.1183s/iter; left time: 7595.5862s
	iters: 2600, epoch: 6 | loss: 0.0974265
	speed: 0.1168s/iter; left time: 7488.7034s
	iters: 2700, epoch: 6 | loss: 0.1037935
	speed: 0.1178s/iter; left time: 7539.9889s
	iters: 2800, epoch: 6 | loss: 0.0945832
	speed: 0.1156s/iter; left time: 7388.0370s
	iters: 2900, epoch: 6 | loss: 0.0993364
	speed: 0.1164s/iter; left time: 7422.9639s
	iters: 3000, epoch: 6 | loss: 0.0983878
	speed: 0.1167s/iter; left time: 7434.3003s
	iters: 3100, epoch: 6 | loss: 0.0967573
	speed: 0.1179s/iter; left time: 7497.4195s
	iters: 3200, epoch: 6 | loss: 0.0809352
	speed: 0.1174s/iter; left time: 7454.3270s
	iters: 3300, epoch: 6 | loss: 0.0907727
	speed: 0.1185s/iter; left time: 7510.3753s
	iters: 3400, epoch: 6 | loss: 0.1019389
	speed: 0.1167s/iter; left time: 7387.1968s
	iters: 3500, epoch: 6 | loss: 0.1059106
	speed: 0.1177s/iter; left time: 7434.7280s
	iters: 3600, epoch: 6 | loss: 0.0917989
	speed: 0.1153s/iter; left time: 7276.6796s
	iters: 3700, epoch: 6 | loss: 0.0842525
	speed: 0.1166s/iter; left time: 7343.0432s
	iters: 3800, epoch: 6 | loss: 0.0876396
	speed: 0.1160s/iter; left time: 7297.2793s
	iters: 3900, epoch: 6 | loss: 0.1118588
	speed: 0.1165s/iter; left time: 7313.6204s
	iters: 4000, epoch: 6 | loss: 0.0991682
	speed: 0.1169s/iter; left time: 7331.3833s
	iters: 4100, epoch: 6 | loss: 0.0930842
	speed: 0.1147s/iter; left time: 7177.1510s
	iters: 4200, epoch: 6 | loss: 0.0981919
	speed: 0.1146s/iter; left time: 7161.5941s
	iters: 4300, epoch: 6 | loss: 0.0870969
	speed: 0.1152s/iter; left time: 7187.5492s
	iters: 4400, epoch: 6 | loss: 0.0964762
	speed: 0.1156s/iter; left time: 7198.3402s
Epoch: 6 cost time: 00h:08m:39.51s
Epoch: 6 | Train Loss: 0.0960726 Vali Loss: 0.1291619 Test Loss: 0.1511165
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.03767301142215729, rmse:0.19409537315368652, mae:0.1336192935705185, rse:0.6876434087753296
success delete checkpoints
Intermediate time for DE and pred_len 168: 01h:09m:06.59s
Intermediate time for DE: 04h:52m:56.47s

=== Starting experiments for country: GB ===

=== Starting experiments for pred_len: 24 ===

--- Running model for GB, pred_len=24 ---
train 143005
val 31085
test 31085
[2024-11-03 06:05:07,960] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 06:05:09,402] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 06:05:09,402] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 06:05:09,402] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 06:05:09,558] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 06:05:09,558] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 06:05:10,275] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 06:05:10,277] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 06:05:10,277] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 06:05:10,278] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 06:05:10,279] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 06:05:10,279] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 06:05:10,279] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 06:05:10,279] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 06:05:10,279] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 06:05:10,279] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 06:05:10,610] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 06:05:10,611] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 06:05:10,611] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 99.89 GB, percent = 13.2%
[2024-11-03 06:05:10,736] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 06:05:10,737] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 06:05:10,737] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 99.89 GB, percent = 13.2%
[2024-11-03 06:05:10,737] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 06:05:10,860] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 06:05:10,861] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 06:05:10,861] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 99.87 GB, percent = 13.2%
[2024-11-03 06:05:10,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 06:05:10,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 06:05:10,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 06:05:10,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 06:05:10,863] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 06:05:10,863] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f31c2cc07d0>
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 06:05:10,864] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 06:05:10,865] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 06:05:10,866] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1466742
	speed: 0.1748s/iter; left time: 15598.4857s
	iters: 200, epoch: 1 | loss: 0.1377795
	speed: 0.1298s/iter; left time: 11573.9787s
	iters: 300, epoch: 1 | loss: 0.1637115
	speed: 0.1289s/iter; left time: 11478.2904s
	iters: 400, epoch: 1 | loss: 0.1077301
	speed: 0.1275s/iter; left time: 11342.6149s
	iters: 500, epoch: 1 | loss: 0.1226833
	speed: 0.1276s/iter; left time: 11334.4573s
	iters: 600, epoch: 1 | loss: 0.1199201
	speed: 0.1312s/iter; left time: 11642.2717s
	iters: 700, epoch: 1 | loss: 0.1068131
	speed: 0.1287s/iter; left time: 11414.0931s
	iters: 800, epoch: 1 | loss: 0.1092960
	speed: 0.1320s/iter; left time: 11692.7568s
	iters: 900, epoch: 1 | loss: 0.0919815
	speed: 0.1286s/iter; left time: 11373.6150s
	iters: 1000, epoch: 1 | loss: 0.1038064
	speed: 0.1298s/iter; left time: 11468.7619s
	iters: 1100, epoch: 1 | loss: 0.0846845
	speed: 0.1312s/iter; left time: 11578.5412s
	iters: 1200, epoch: 1 | loss: 0.0949691
	speed: 0.1288s/iter; left time: 11353.3324s
	iters: 1300, epoch: 1 | loss: 0.0737247
	speed: 0.1311s/iter; left time: 11545.0504s
	iters: 1400, epoch: 1 | loss: 0.1031198
	speed: 0.1302s/iter; left time: 11452.3215s
	iters: 1500, epoch: 1 | loss: 0.0780963
	speed: 0.1307s/iter; left time: 11482.6928s
	iters: 1600, epoch: 1 | loss: 0.0978673
	speed: 0.1296s/iter; left time: 11371.6500s
	iters: 1700, epoch: 1 | loss: 0.1247796
	speed: 0.1308s/iter; left time: 11464.9652s
	iters: 1800, epoch: 1 | loss: 0.1062685
	speed: 0.1303s/iter; left time: 11404.8978s
	iters: 1900, epoch: 1 | loss: 0.1049088
	speed: 0.1276s/iter; left time: 11160.2830s
	iters: 2000, epoch: 1 | loss: 0.0870789
	speed: 0.1304s/iter; left time: 11394.5054s
	iters: 2100, epoch: 1 | loss: 0.0814199
	speed: 0.1311s/iter; left time: 11437.0125s
	iters: 2200, epoch: 1 | loss: 0.0885388
	speed: 0.1297s/iter; left time: 11307.0506s
	iters: 2300, epoch: 1 | loss: 0.0876981
	speed: 0.1284s/iter; left time: 11179.8422s
	iters: 2400, epoch: 1 | loss: 0.0750865
	speed: 0.1304s/iter; left time: 11339.8303s
	iters: 2500, epoch: 1 | loss: 0.0770076
	speed: 0.1299s/iter; left time: 11285.7984s
	iters: 2600, epoch: 1 | loss: 0.0930856
	speed: 0.1271s/iter; left time: 11031.3798s
	iters: 2700, epoch: 1 | loss: 0.0914229
	speed: 0.1238s/iter; left time: 10727.8290s
	iters: 2800, epoch: 1 | loss: 0.0742800
	speed: 0.1251s/iter; left time: 10831.5647s
	iters: 2900, epoch: 1 | loss: 0.0699159
	speed: 0.1299s/iter; left time: 11227.7913s
	iters: 3000, epoch: 1 | loss: 0.0888919
	speed: 0.1286s/iter; left time: 11104.4819s
	iters: 3100, epoch: 1 | loss: 0.0732918
	speed: 0.1276s/iter; left time: 11008.2922s
	iters: 3200, epoch: 1 | loss: 0.0881244
	speed: 0.1289s/iter; left time: 11106.4858s
	iters: 3300, epoch: 1 | loss: 0.0822907
	speed: 0.1264s/iter; left time: 10876.1296s
	iters: 3400, epoch: 1 | loss: 0.0753193
	speed: 0.1298s/iter; left time: 11160.7985s
	iters: 3500, epoch: 1 | loss: 0.0816539
	speed: 0.1282s/iter; left time: 11005.9994s
	iters: 3600, epoch: 1 | loss: 0.0759263
	speed: 0.1307s/iter; left time: 11205.8377s
	iters: 3700, epoch: 1 | loss: 0.0969475
	speed: 0.1297s/iter; left time: 11113.0399s
	iters: 3800, epoch: 1 | loss: 0.0810152
	speed: 0.1271s/iter; left time: 10871.4882s
	iters: 3900, epoch: 1 | loss: 0.0943139
	speed: 0.1299s/iter; left time: 11097.8455s
	iters: 4000, epoch: 1 | loss: 0.0698772
	speed: 0.1268s/iter; left time: 10825.6037s
	iters: 4100, epoch: 1 | loss: 0.0704658
	speed: 0.1269s/iter; left time: 10819.6445s
	iters: 4200, epoch: 1 | loss: 0.1035011
	speed: 0.1271s/iter; left time: 10823.0052s
	iters: 4300, epoch: 1 | loss: 0.0949263
	speed: 0.1275s/iter; left time: 10844.8182s
	iters: 4400, epoch: 1 | loss: 0.0885897
	speed: 0.1288s/iter; left time: 10939.3516s
Epoch: 1 cost time: 00h:09m:37.08s
Epoch: 1 | Train Loss: 0.0973537 Vali Loss: 0.0928246 Test Loss: 0.1050737
Validation loss decreased (inf --> 0.092825).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0701588
	speed: 1.8726s/iter; left time: 158786.1147s
	iters: 200, epoch: 2 | loss: 0.1044648
	speed: 0.1163s/iter; left time: 9848.0479s
	iters: 300, epoch: 2 | loss: 0.0884274
	speed: 0.1176s/iter; left time: 9950.3132s
	iters: 400, epoch: 2 | loss: 0.1147017
	speed: 0.1188s/iter; left time: 10040.6889s
	iters: 500, epoch: 2 | loss: 0.0937675
	speed: 0.1192s/iter; left time: 10056.2784s
	iters: 600, epoch: 2 | loss: 0.0921706
	speed: 0.1180s/iter; left time: 9950.1293s
	iters: 700, epoch: 2 | loss: 0.0930738
	speed: 0.1198s/iter; left time: 10087.4863s
	iters: 800, epoch: 2 | loss: 0.1000150
	speed: 0.1200s/iter; left time: 10094.0531s
	iters: 900, epoch: 2 | loss: 0.0975661
	speed: 0.1182s/iter; left time: 9925.3564s
	iters: 1000, epoch: 2 | loss: 0.0700671
	speed: 0.1170s/iter; left time: 9816.9412s
	iters: 1100, epoch: 2 | loss: 0.0929756
	speed: 0.1192s/iter; left time: 9988.0118s
	iters: 1200, epoch: 2 | loss: 0.0745666
	speed: 0.1180s/iter; left time: 9879.2296s
	iters: 1300, epoch: 2 | loss: 0.0924439
	speed: 0.1171s/iter; left time: 9789.0249s
	iters: 1400, epoch: 2 | loss: 0.1111560
	speed: 0.1153s/iter; left time: 9628.5784s
	iters: 1500, epoch: 2 | loss: 0.0793124
	speed: 0.1199s/iter; left time: 10001.1410s
	iters: 1600, epoch: 2 | loss: 0.0794686
	speed: 0.1185s/iter; left time: 9867.7083s
	iters: 1700, epoch: 2 | loss: 0.0875069
	speed: 0.1171s/iter; left time: 9738.6008s
	iters: 1800, epoch: 2 | loss: 0.0863800
	speed: 0.1146s/iter; left time: 9522.1638s
	iters: 1900, epoch: 2 | loss: 0.0864655
	speed: 0.1185s/iter; left time: 9833.4448s
	iters: 2000, epoch: 2 | loss: 0.0874661
	speed: 0.1182s/iter; left time: 9800.8815s
	iters: 2100, epoch: 2 | loss: 0.0986785
	speed: 0.1171s/iter; left time: 9692.0347s
	iters: 2200, epoch: 2 | loss: 0.0935980
	speed: 0.1163s/iter; left time: 9617.8344s
	iters: 2300, epoch: 2 | loss: 0.0926060
	speed: 0.1199s/iter; left time: 9902.1111s
	iters: 2400, epoch: 2 | loss: 0.0731041
	speed: 0.1162s/iter; left time: 9588.0168s
	iters: 2500, epoch: 2 | loss: 0.0878800
	speed: 0.1154s/iter; left time: 9504.3980s
	iters: 2600, epoch: 2 | loss: 0.1000494
	speed: 0.1144s/iter; left time: 9412.6264s
	iters: 2700, epoch: 2 | loss: 0.0909730
	speed: 0.1134s/iter; left time: 9324.6489s
	iters: 2800, epoch: 2 | loss: 0.1120826
	speed: 0.1131s/iter; left time: 9284.1912s
	iters: 2900, epoch: 2 | loss: 0.0753991
	speed: 0.1170s/iter; left time: 9593.3664s
	iters: 3000, epoch: 2 | loss: 0.0918223
	speed: 0.1166s/iter; left time: 9550.6203s
	iters: 3100, epoch: 2 | loss: 0.1169008
	speed: 0.1160s/iter; left time: 9491.9086s
	iters: 3200, epoch: 2 | loss: 0.0799625
	speed: 0.1160s/iter; left time: 9477.0554s
	iters: 3300, epoch: 2 | loss: 0.0924724
	speed: 0.1156s/iter; left time: 9434.9133s
	iters: 3400, epoch: 2 | loss: 0.0893005
	speed: 0.1156s/iter; left time: 9423.6612s
	iters: 3500, epoch: 2 | loss: 0.0870048
	speed: 0.1142s/iter; left time: 9291.7373s
	iters: 3600, epoch: 2 | loss: 0.0749805
	speed: 0.1153s/iter; left time: 9374.1188s
	iters: 3700, epoch: 2 | loss: 0.0773853
	speed: 0.1178s/iter; left time: 9567.4743s
	iters: 3800, epoch: 2 | loss: 0.0819646
	speed: 0.1175s/iter; left time: 9526.6254s
	iters: 3900, epoch: 2 | loss: 0.0823601
	speed: 0.1144s/iter; left time: 9265.6871s
	iters: 4000, epoch: 2 | loss: 0.0686158
	speed: 0.1143s/iter; left time: 9248.0084s
	iters: 4100, epoch: 2 | loss: 0.0982631
	speed: 0.1139s/iter; left time: 9199.3269s
	iters: 4200, epoch: 2 | loss: 0.0787107
	speed: 0.1149s/iter; left time: 9272.7571s
	iters: 4300, epoch: 2 | loss: 0.0879422
	speed: 0.1146s/iter; left time: 9238.3802s
	iters: 4400, epoch: 2 | loss: 0.0896147
	speed: 0.1152s/iter; left time: 9276.6456s
Epoch: 2 cost time: 00h:08m:41.97s
Epoch: 2 | Train Loss: 0.0860910 Vali Loss: 0.0922121 Test Loss: 0.1065872
Validation loss decreased (0.092825 --> 0.092212).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0907432
	speed: 1.6204s/iter; left time: 130160.2971s
	iters: 200, epoch: 3 | loss: 0.0779589
	speed: 0.1152s/iter; left time: 9241.5971s
	iters: 300, epoch: 3 | loss: 0.0885364
	speed: 0.1163s/iter; left time: 9316.8426s
	iters: 400, epoch: 3 | loss: 0.0848934
	speed: 0.1171s/iter; left time: 9367.1094s
	iters: 500, epoch: 3 | loss: 0.0842507
	speed: 0.1172s/iter; left time: 9364.6484s
	iters: 600, epoch: 3 | loss: 0.0788545
	speed: 0.1169s/iter; left time: 9328.3574s
	iters: 700, epoch: 3 | loss: 0.0803074
	speed: 0.1174s/iter; left time: 9359.3329s
	iters: 800, epoch: 3 | loss: 0.0902780
	speed: 0.1153s/iter; left time: 9179.2263s
	iters: 900, epoch: 3 | loss: 0.0700542
	speed: 0.1165s/iter; left time: 9260.9572s
	iters: 1000, epoch: 3 | loss: 0.0909660
	speed: 0.1148s/iter; left time: 9119.6276s
	iters: 1100, epoch: 3 | loss: 0.0937846
	speed: 0.1147s/iter; left time: 9097.6639s
	iters: 1200, epoch: 3 | loss: 0.0607558
	speed: 0.1154s/iter; left time: 9145.7810s
	iters: 1300, epoch: 3 | loss: 0.0803862
	speed: 0.1159s/iter; left time: 9167.5892s
	iters: 1400, epoch: 3 | loss: 0.0932646
	speed: 0.1168s/iter; left time: 9233.6737s
	iters: 1500, epoch: 3 | loss: 0.0733327
	speed: 0.1160s/iter; left time: 9157.2614s
	iters: 1600, epoch: 3 | loss: 0.0595024
	speed: 0.1156s/iter; left time: 9109.5161s
	iters: 1700, epoch: 3 | loss: 0.0652814
	speed: 0.1152s/iter; left time: 9072.5026s
	iters: 1800, epoch: 3 | loss: 0.0982525
	speed: 0.1133s/iter; left time: 8909.1675s
	iters: 1900, epoch: 3 | loss: 0.0716447
	speed: 0.1150s/iter; left time: 9034.0922s
	iters: 2000, epoch: 3 | loss: 0.0835190
	speed: 0.1154s/iter; left time: 9052.4635s
	iters: 2100, epoch: 3 | loss: 0.0834547
	speed: 0.1173s/iter; left time: 9187.7496s
	iters: 2200, epoch: 3 | loss: 0.0948817
	speed: 0.1146s/iter; left time: 8965.3189s
	iters: 2300, epoch: 3 | loss: 0.0844729
	speed: 0.1131s/iter; left time: 8832.9053s
	iters: 2400, epoch: 3 | loss: 0.0765860
	speed: 0.1153s/iter; left time: 8993.3148s
	iters: 2500, epoch: 3 | loss: 0.0919627
	speed: 0.1158s/iter; left time: 9022.1140s
	iters: 2600, epoch: 3 | loss: 0.0797675
	speed: 0.1170s/iter; left time: 9102.4720s
	iters: 2700, epoch: 3 | loss: 0.0741416
	speed: 0.1155s/iter; left time: 8973.8882s
	iters: 2800, epoch: 3 | loss: 0.0829531
	speed: 0.1155s/iter; left time: 8968.6057s
	iters: 2900, epoch: 3 | loss: 0.0889192
	speed: 0.1147s/iter; left time: 8889.3441s
	iters: 3000, epoch: 3 | loss: 0.0789738
	speed: 0.1158s/iter; left time: 8968.2427s
	iters: 3100, epoch: 3 | loss: 0.0949245
	speed: 0.1167s/iter; left time: 9026.3304s
	iters: 3200, epoch: 3 | loss: 0.0981605
	speed: 0.1178s/iter; left time: 9098.8648s
	iters: 3300, epoch: 3 | loss: 0.0789458
	speed: 0.1169s/iter; left time: 9016.7586s
	iters: 3400, epoch: 3 | loss: 0.0741549
	speed: 0.1187s/iter; left time: 9139.5161s
	iters: 3500, epoch: 3 | loss: 0.0773597
	speed: 0.1182s/iter; left time: 9091.3377s
	iters: 3600, epoch: 3 | loss: 0.0935745
	speed: 0.1173s/iter; left time: 9012.3308s
	iters: 3700, epoch: 3 | loss: 0.0769829
	speed: 0.1185s/iter; left time: 9089.8660s
	iters: 3800, epoch: 3 | loss: 0.0949859
	speed: 0.1183s/iter; left time: 9068.1966s
	iters: 3900, epoch: 3 | loss: 0.0808080
	speed: 0.1185s/iter; left time: 9066.9092s
	iters: 4000, epoch: 3 | loss: 0.0665414
	speed: 0.1160s/iter; left time: 8861.8437s
	iters: 4100, epoch: 3 | loss: 0.0754559
	speed: 0.1176s/iter; left time: 8973.6887s
	iters: 4200, epoch: 3 | loss: 0.0699142
	speed: 0.1166s/iter; left time: 8885.9167s
	iters: 4300, epoch: 3 | loss: 0.0632910
	speed: 0.1188s/iter; left time: 9041.2206s
	iters: 4400, epoch: 3 | loss: 0.0808305
	speed: 0.1158s/iter; left time: 8802.9235s
Epoch: 3 cost time: 00h:08m:40.38s
Epoch: 3 | Train Loss: 0.0838997 Vali Loss: 0.0905142 Test Loss: 0.1035439
Validation loss decreased (0.092212 --> 0.090514).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0914321
	speed: 1.6342s/iter; left time: 123966.1902s
	iters: 200, epoch: 4 | loss: 0.0923484
	speed: 0.1178s/iter; left time: 8923.0128s
	iters: 300, epoch: 4 | loss: 0.0886503
	speed: 0.1152s/iter; left time: 8712.2391s
	iters: 400, epoch: 4 | loss: 0.0890385
	speed: 0.1155s/iter; left time: 8726.3773s
	iters: 500, epoch: 4 | loss: 0.0889764
	speed: 0.1156s/iter; left time: 8719.1197s
	iters: 600, epoch: 4 | loss: 0.0682504
	speed: 0.1178s/iter; left time: 8874.6318s
	iters: 700, epoch: 4 | loss: 0.0858520
	speed: 0.1163s/iter; left time: 8755.5159s
	iters: 800, epoch: 4 | loss: 0.0807579
	speed: 0.1139s/iter; left time: 8558.9584s
	iters: 900, epoch: 4 | loss: 0.0771627
	speed: 0.1157s/iter; left time: 8685.2748s
	iters: 1000, epoch: 4 | loss: 0.0891313
	speed: 0.1158s/iter; left time: 8678.3248s
	iters: 1100, epoch: 4 | loss: 0.0808600
	speed: 0.1133s/iter; left time: 8481.0700s
	iters: 1200, epoch: 4 | loss: 0.1001335
	speed: 0.1148s/iter; left time: 8579.0647s
	iters: 1300, epoch: 4 | loss: 0.1131133
	speed: 0.1136s/iter; left time: 8482.4180s
	iters: 1400, epoch: 4 | loss: 0.0778967
	speed: 0.1156s/iter; left time: 8617.9859s
	iters: 1500, epoch: 4 | loss: 0.0659208
	speed: 0.1143s/iter; left time: 8512.1282s
	iters: 1600, epoch: 4 | loss: 0.0821595
	speed: 0.1144s/iter; left time: 8504.2124s
	iters: 1700, epoch: 4 | loss: 0.0919877
	speed: 0.1148s/iter; left time: 8525.1535s
	iters: 1800, epoch: 4 | loss: 0.0923949
	speed: 0.1144s/iter; left time: 8486.7110s
	iters: 1900, epoch: 4 | loss: 0.0738678
	speed: 0.1155s/iter; left time: 8557.1487s
	iters: 2000, epoch: 4 | loss: 0.0819451
	speed: 0.1135s/iter; left time: 8393.9204s
	iters: 2100, epoch: 4 | loss: 0.0814312
	speed: 0.1126s/iter; left time: 8317.2582s
	iters: 2200, epoch: 4 | loss: 0.0888639
	speed: 0.1129s/iter; left time: 8323.5396s
	iters: 2300, epoch: 4 | loss: 0.1003453
	speed: 0.1129s/iter; left time: 8318.3946s
	iters: 2400, epoch: 4 | loss: 0.0999414
	speed: 0.1145s/iter; left time: 8425.5708s
	iters: 2500, epoch: 4 | loss: 0.0742211
	speed: 0.1128s/iter; left time: 8283.9718s
	iters: 2600, epoch: 4 | loss: 0.0718067
	speed: 0.1142s/iter; left time: 8377.3046s
	iters: 2700, epoch: 4 | loss: 0.0911036
	speed: 0.1134s/iter; left time: 8308.4250s
	iters: 2800, epoch: 4 | loss: 0.0877281
	speed: 0.1117s/iter; left time: 8169.8015s
	iters: 2900, epoch: 4 | loss: 0.0797919
	speed: 0.1138s/iter; left time: 8314.7661s
	iters: 3000, epoch: 4 | loss: 0.0775673
	speed: 0.1138s/iter; left time: 8305.5354s
	iters: 3100, epoch: 4 | loss: 0.0879129
	speed: 0.1121s/iter; left time: 8167.1228s
	iters: 3200, epoch: 4 | loss: 0.0780287
	speed: 0.1125s/iter; left time: 8183.4866s
	iters: 3300, epoch: 4 | loss: 0.0876071
	speed: 0.1155s/iter; left time: 8394.3315s
	iters: 3400, epoch: 4 | loss: 0.0757971
	speed: 0.1134s/iter; left time: 8226.7189s
	iters: 3500, epoch: 4 | loss: 0.0894305
	speed: 0.1156s/iter; left time: 8377.4186s
	iters: 3600, epoch: 4 | loss: 0.0851934
	speed: 0.1136s/iter; left time: 8218.1792s
	iters: 3700, epoch: 4 | loss: 0.0877569
	speed: 0.1131s/iter; left time: 8175.3755s
	iters: 3800, epoch: 4 | loss: 0.0781913
	speed: 0.1133s/iter; left time: 8172.6620s
	iters: 3900, epoch: 4 | loss: 0.0874085
	speed: 0.1160s/iter; left time: 8359.8425s
	iters: 4000, epoch: 4 | loss: 0.0781264
	speed: 0.1144s/iter; left time: 8235.0631s
	iters: 4100, epoch: 4 | loss: 0.0745134
	speed: 0.1133s/iter; left time: 8138.9936s
	iters: 4200, epoch: 4 | loss: 0.0732169
	speed: 0.1151s/iter; left time: 8258.0444s
	iters: 4300, epoch: 4 | loss: 0.0699919
	speed: 0.1143s/iter; left time: 8192.2432s
	iters: 4400, epoch: 4 | loss: 0.0951408
	speed: 0.1139s/iter; left time: 8151.1855s
Epoch: 4 cost time: 00h:08m:31.76s
Epoch: 4 | Train Loss: 0.0825824 Vali Loss: 0.0908698 Test Loss: 0.1047861
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0933834
	speed: 1.5999s/iter; left time: 114213.8981s
	iters: 200, epoch: 5 | loss: 0.0743399
	speed: 0.1159s/iter; left time: 8264.3638s
	iters: 300, epoch: 5 | loss: 0.0725531
	speed: 0.1166s/iter; left time: 8303.3212s
	iters: 400, epoch: 5 | loss: 0.0881155
	speed: 0.1159s/iter; left time: 8242.0165s
	iters: 500, epoch: 5 | loss: 0.0945252
	speed: 0.1146s/iter; left time: 8136.5189s
	iters: 600, epoch: 5 | loss: 0.0865966
	speed: 0.1161s/iter; left time: 8226.7902s
	iters: 700, epoch: 5 | loss: 0.0829508
	speed: 0.1164s/iter; left time: 8240.0986s
	iters: 800, epoch: 5 | loss: 0.0887444
	speed: 0.1174s/iter; left time: 8298.8268s
	iters: 900, epoch: 5 | loss: 0.1051521
	speed: 0.1152s/iter; left time: 8132.9371s
	iters: 1000, epoch: 5 | loss: 0.0809733
	speed: 0.1146s/iter; left time: 8075.1920s
	iters: 1100, epoch: 5 | loss: 0.0754441
	speed: 0.1171s/iter; left time: 8239.9571s
	iters: 1200, epoch: 5 | loss: 0.0971770
	speed: 0.1164s/iter; left time: 8179.7599s
	iters: 1300, epoch: 5 | loss: 0.0774984
	speed: 0.1165s/iter; left time: 8179.5923s
	iters: 1400, epoch: 5 | loss: 0.0693193
	speed: 0.1139s/iter; left time: 7981.7273s
	iters: 1500, epoch: 5 | loss: 0.0622493
	speed: 0.1144s/iter; left time: 8004.3232s
	iters: 1600, epoch: 5 | loss: 0.0728563
	speed: 0.1140s/iter; left time: 7964.1308s
	iters: 1700, epoch: 5 | loss: 0.0667490
	speed: 0.1165s/iter; left time: 8131.8763s
	iters: 1800, epoch: 5 | loss: 0.0948240
	speed: 0.1157s/iter; left time: 8066.1557s
	iters: 1900, epoch: 5 | loss: 0.0625855
	speed: 0.1140s/iter; left time: 7935.2409s
	iters: 2000, epoch: 5 | loss: 0.0731169
	speed: 0.1153s/iter; left time: 8012.9702s
	iters: 2100, epoch: 5 | loss: 0.0691220
	speed: 0.1131s/iter; left time: 7850.1405s
	iters: 2200, epoch: 5 | loss: 0.0799258
	speed: 0.1139s/iter; left time: 7891.7664s
	iters: 2300, epoch: 5 | loss: 0.0892581
	speed: 0.1147s/iter; left time: 7938.9441s
	iters: 2400, epoch: 5 | loss: 0.0849659
	speed: 0.1138s/iter; left time: 7859.0180s
	iters: 2500, epoch: 5 | loss: 0.0802421
	speed: 0.1131s/iter; left time: 7804.0505s
	iters: 2600, epoch: 5 | loss: 0.0774631
	speed: 0.1140s/iter; left time: 7852.8952s
	iters: 2700, epoch: 5 | loss: 0.0812496
	speed: 0.1143s/iter; left time: 7862.3026s
	iters: 2800, epoch: 5 | loss: 0.0752958
	speed: 0.1138s/iter; left time: 7819.8376s
	iters: 2900, epoch: 5 | loss: 0.0816401
	speed: 0.1172s/iter; left time: 8041.8530s
	iters: 3000, epoch: 5 | loss: 0.0708815
	speed: 0.1164s/iter; left time: 7969.1932s
	iters: 3100, epoch: 5 | loss: 0.1038611
	speed: 0.1152s/iter; left time: 7878.3293s
	iters: 3200, epoch: 5 | loss: 0.0952071
	speed: 0.1161s/iter; left time: 7926.1036s
	iters: 3300, epoch: 5 | loss: 0.0748858
	speed: 0.1175s/iter; left time: 8012.6982s
	iters: 3400, epoch: 5 | loss: 0.0783696
	speed: 0.1139s/iter; left time: 7758.4646s
	iters: 3500, epoch: 5 | loss: 0.0848109
	speed: 0.1161s/iter; left time: 7894.9146s
	iters: 3600, epoch: 5 | loss: 0.0840811
	speed: 0.1160s/iter; left time: 7871.9308s
	iters: 3700, epoch: 5 | loss: 0.0691066
	speed: 0.1172s/iter; left time: 7944.3060s
	iters: 3800, epoch: 5 | loss: 0.0793731
	speed: 0.1158s/iter; left time: 7835.1559s
	iters: 3900, epoch: 5 | loss: 0.0673810
	speed: 0.1163s/iter; left time: 7860.3347s
	iters: 4000, epoch: 5 | loss: 0.0856006
	speed: 0.1140s/iter; left time: 7696.4913s
	iters: 4100, epoch: 5 | loss: 0.0628996
	speed: 0.1153s/iter; left time: 7768.3951s
	iters: 4200, epoch: 5 | loss: 0.0903348
	speed: 0.1154s/iter; left time: 7765.9766s
	iters: 4300, epoch: 5 | loss: 0.0866672
	speed: 0.1165s/iter; left time: 7825.4286s
	iters: 4400, epoch: 5 | loss: 0.0803752
	speed: 0.1151s/iter; left time: 7723.7072s
Epoch: 5 cost time: 00h:08m:36.25s
Epoch: 5 | Train Loss: 0.0813836 Vali Loss: 0.0900973 Test Loss: 0.1040331
Validation loss decreased (0.090514 --> 0.090097).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0863184
	speed: 1.6079s/iter; left time: 107602.2371s
	iters: 200, epoch: 6 | loss: 0.0890369
	speed: 0.1166s/iter; left time: 7792.9815s
	iters: 300, epoch: 6 | loss: 0.0835939
	speed: 0.1167s/iter; left time: 7788.6726s
	iters: 400, epoch: 6 | loss: 0.0703793
	speed: 0.1153s/iter; left time: 7681.3484s
	iters: 500, epoch: 6 | loss: 0.0827197
	speed: 0.1163s/iter; left time: 7737.2977s
	iters: 600, epoch: 6 | loss: 0.0714470
	speed: 0.1183s/iter; left time: 7858.6330s
	iters: 700, epoch: 6 | loss: 0.0747727
	speed: 0.1166s/iter; left time: 7734.6799s
	iters: 800, epoch: 6 | loss: 0.0732784
	speed: 0.1169s/iter; left time: 7739.5273s
	iters: 900, epoch: 6 | loss: 0.0771534
	speed: 0.1158s/iter; left time: 7658.9947s
	iters: 1000, epoch: 6 | loss: 0.0741465
	speed: 0.1157s/iter; left time: 7640.8549s
	iters: 1100, epoch: 6 | loss: 0.0746656
	speed: 0.1148s/iter; left time: 7567.3418s
	iters: 1200, epoch: 6 | loss: 0.0931855
	speed: 0.1191s/iter; left time: 7837.7050s
	iters: 1300, epoch: 6 | loss: 0.0977927
	speed: 0.1163s/iter; left time: 7644.3140s
	iters: 1400, epoch: 6 | loss: 0.0876032
	speed: 0.1166s/iter; left time: 7651.1682s
	iters: 1500, epoch: 6 | loss: 0.0801408
	speed: 0.1177s/iter; left time: 7712.7444s
	iters: 1600, epoch: 6 | loss: 0.0721369
	speed: 0.1177s/iter; left time: 7696.8397s
	iters: 1700, epoch: 6 | loss: 0.0922342
	speed: 0.1171s/iter; left time: 7648.3469s
	iters: 1800, epoch: 6 | loss: 0.0814926
	speed: 0.1143s/iter; left time: 7452.2997s
	iters: 1900, epoch: 6 | loss: 0.0799462
	speed: 0.1161s/iter; left time: 7563.4943s
	iters: 2000, epoch: 6 | loss: 0.0895512
	speed: 0.1159s/iter; left time: 7538.6946s
	iters: 2100, epoch: 6 | loss: 0.0853165
	speed: 0.1170s/iter; left time: 7596.2929s
	iters: 2200, epoch: 6 | loss: 0.1018588
	speed: 0.1164s/iter; left time: 7545.7194s
	iters: 2300, epoch: 6 | loss: 0.0753619
	speed: 0.1164s/iter; left time: 7536.7268s
	iters: 2400, epoch: 6 | loss: 0.0675035
	speed: 0.1160s/iter; left time: 7493.0730s
	iters: 2500, epoch: 6 | loss: 0.0995846
	speed: 0.1147s/iter; left time: 7398.4242s
	iters: 2600, epoch: 6 | loss: 0.0759167
	speed: 0.1147s/iter; left time: 7387.5417s
	iters: 2700, epoch: 6 | loss: 0.0709326
	speed: 0.1167s/iter; left time: 7503.3345s
	iters: 2800, epoch: 6 | loss: 0.1127540
	speed: 0.1168s/iter; left time: 7503.3535s
	iters: 2900, epoch: 6 | loss: 0.0813409
	speed: 0.1158s/iter; left time: 7424.7262s
	iters: 3000, epoch: 6 | loss: 0.0786561
	speed: 0.1145s/iter; left time: 7330.6350s
	iters: 3100, epoch: 6 | loss: 0.0826245
	speed: 0.1170s/iter; left time: 7480.9854s
	iters: 3200, epoch: 6 | loss: 0.0986693
	speed: 0.1163s/iter; left time: 7423.9302s
	iters: 3300, epoch: 6 | loss: 0.0849674
	speed: 0.1173s/iter; left time: 7471.3527s
	iters: 3400, epoch: 6 | loss: 0.0744465
	speed: 0.1141s/iter; left time: 7260.0666s
	iters: 3500, epoch: 6 | loss: 0.0913548
	speed: 0.1164s/iter; left time: 7393.4716s
	iters: 3600, epoch: 6 | loss: 0.0656657
	speed: 0.1173s/iter; left time: 7438.1420s
	iters: 3700, epoch: 6 | loss: 0.0794955
	speed: 0.1132s/iter; left time: 7168.1313s
	iters: 3800, epoch: 6 | loss: 0.0760554
	speed: 0.1145s/iter; left time: 7239.6268s
	iters: 3900, epoch: 6 | loss: 0.0779494
	speed: 0.1147s/iter; left time: 7242.1353s
	iters: 4000, epoch: 6 | loss: 0.0917149
	speed: 0.1142s/iter; left time: 7199.8447s
	iters: 4100, epoch: 6 | loss: 0.0724742
	speed: 0.1148s/iter; left time: 7224.6386s
	iters: 4200, epoch: 6 | loss: 0.0769409
	speed: 0.1161s/iter; left time: 7291.8852s
	iters: 4300, epoch: 6 | loss: 0.0667945
	speed: 0.1167s/iter; left time: 7317.3923s
	iters: 4400, epoch: 6 | loss: 0.0704586
	speed: 0.1129s/iter; left time: 7072.5778s
Epoch: 6 cost time: 00h:08m:38.83s
Epoch: 6 | Train Loss: 0.0803718 Vali Loss: 0.0905898 Test Loss: 0.1044702
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0694771
	speed: 1.5992s/iter; left time: 99877.1591s
	iters: 200, epoch: 7 | loss: 0.0701124
	speed: 0.1165s/iter; left time: 7262.2913s
	iters: 300, epoch: 7 | loss: 0.0611065
	speed: 0.1148s/iter; left time: 7147.6222s
	iters: 400, epoch: 7 | loss: 0.0853083
	speed: 0.1183s/iter; left time: 7353.4378s
	iters: 500, epoch: 7 | loss: 0.0865817
	speed: 0.1156s/iter; left time: 7176.3244s
	iters: 600, epoch: 7 | loss: 0.0731895
	speed: 0.1170s/iter; left time: 7250.7958s
	iters: 700, epoch: 7 | loss: 0.1010686
	speed: 0.1172s/iter; left time: 7250.9657s
	iters: 800, epoch: 7 | loss: 0.0807473
	speed: 0.1166s/iter; left time: 7200.2405s
	iters: 900, epoch: 7 | loss: 0.0729549
	speed: 0.1158s/iter; left time: 7137.6264s
	iters: 1000, epoch: 7 | loss: 0.0784136
	speed: 0.1160s/iter; left time: 7142.9028s
	iters: 1100, epoch: 7 | loss: 0.0915089
	speed: 0.1162s/iter; left time: 7138.6109s
	iters: 1200, epoch: 7 | loss: 0.0813137
	speed: 0.1176s/iter; left time: 7214.8011s
	iters: 1300, epoch: 7 | loss: 0.0710811
	speed: 0.1147s/iter; left time: 7023.3959s
	iters: 1400, epoch: 7 | loss: 0.0674738
	speed: 0.1169s/iter; left time: 7146.4507s
	iters: 1500, epoch: 7 | loss: 0.0731219
	speed: 0.1159s/iter; left time: 7076.6751s
	iters: 1600, epoch: 7 | loss: 0.0795863
	speed: 0.1175s/iter; left time: 7159.0093s
	iters: 1700, epoch: 7 | loss: 0.0768837
	speed: 0.1178s/iter; left time: 7169.3604s
	iters: 1800, epoch: 7 | loss: 0.0973881
	speed: 0.1162s/iter; left time: 7058.1413s
	iters: 1900, epoch: 7 | loss: 0.0784142
	speed: 0.1173s/iter; left time: 7111.9250s
	iters: 2000, epoch: 7 | loss: 0.0736109
	speed: 0.1175s/iter; left time: 7113.4931s
	iters: 2100, epoch: 7 | loss: 0.0847631
	speed: 0.1163s/iter; left time: 7030.1128s
	iters: 2200, epoch: 7 | loss: 0.0700621
	speed: 0.1185s/iter; left time: 7152.6374s
	iters: 2300, epoch: 7 | loss: 0.0826743
	speed: 0.1178s/iter; left time: 7096.9864s
	iters: 2400, epoch: 7 | loss: 0.0855349
	speed: 0.1179s/iter; left time: 7089.6478s
	iters: 2500, epoch: 7 | loss: 0.0894471
	speed: 0.1159s/iter; left time: 6961.7498s
	iters: 2600, epoch: 7 | loss: 0.0709336
	speed: 0.1170s/iter; left time: 7014.0372s
	iters: 2700, epoch: 7 | loss: 0.0635979
	speed: 0.1142s/iter; left time: 6838.1543s
	iters: 2800, epoch: 7 | loss: 0.0727365
	speed: 0.1165s/iter; left time: 6960.3037s
	iters: 2900, epoch: 7 | loss: 0.0891747
	speed: 0.1137s/iter; left time: 6781.6957s
	iters: 3000, epoch: 7 | loss: 0.0914883
	speed: 0.1150s/iter; left time: 6848.7837s
	iters: 3100, epoch: 7 | loss: 0.0926042
	speed: 0.1167s/iter; left time: 6940.1020s
	iters: 3200, epoch: 7 | loss: 0.0622337
	speed: 0.1151s/iter; left time: 6832.7122s
	iters: 3300, epoch: 7 | loss: 0.0735094
	speed: 0.1146s/iter; left time: 6793.1364s
	iters: 3400, epoch: 7 | loss: 0.0951522
	speed: 0.1152s/iter; left time: 6813.5322s
	iters: 3500, epoch: 7 | loss: 0.0720976
	speed: 0.1153s/iter; left time: 6807.6841s
	iters: 3600, epoch: 7 | loss: 0.0690883
	speed: 0.1146s/iter; left time: 6753.2053s
	iters: 3700, epoch: 7 | loss: 0.0841284
	speed: 0.1187s/iter; left time: 6985.1423s
	iters: 3800, epoch: 7 | loss: 0.0866462
	speed: 0.1156s/iter; left time: 6790.0288s
	iters: 3900, epoch: 7 | loss: 0.0677450
	speed: 0.1156s/iter; left time: 6780.3658s
	iters: 4000, epoch: 7 | loss: 0.0808895
	speed: 0.1148s/iter; left time: 6723.6332s
	iters: 4100, epoch: 7 | loss: 0.0839261
	speed: 0.1135s/iter; left time: 6633.9557s
	iters: 4200, epoch: 7 | loss: 0.0723493
	speed: 0.1171s/iter; left time: 6835.8888s
	iters: 4300, epoch: 7 | loss: 0.0775747
	speed: 0.1183s/iter; left time: 6893.1300s
	iters: 4400, epoch: 7 | loss: 0.0767770
	speed: 0.1166s/iter; left time: 6778.6296s
Epoch: 7 cost time: 00h:08m:40.24s
Epoch: 7 | Train Loss: 0.0794193 Vali Loss: 0.0901961 Test Loss: 0.1045509
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0895511
	speed: 1.6001s/iter; left time: 92783.0760s
	iters: 200, epoch: 8 | loss: 0.0866904
	speed: 0.1176s/iter; left time: 6804.9920s
	iters: 300, epoch: 8 | loss: 0.0797954
	speed: 0.1173s/iter; left time: 6778.7685s
	iters: 400, epoch: 8 | loss: 0.0820298
	speed: 0.1157s/iter; left time: 6671.7858s
	iters: 500, epoch: 8 | loss: 0.0783670
	speed: 0.1153s/iter; left time: 6637.8132s
	iters: 600, epoch: 8 | loss: 0.0902877
	speed: 0.1160s/iter; left time: 6667.4776s
	iters: 700, epoch: 8 | loss: 0.0648628
	speed: 0.1193s/iter; left time: 6846.3671s
	iters: 800, epoch: 8 | loss: 0.0814682
	speed: 0.1170s/iter; left time: 6705.1745s
	iters: 900, epoch: 8 | loss: 0.0808761
	speed: 0.1179s/iter; left time: 6740.2376s
	iters: 1000, epoch: 8 | loss: 0.0752130
	speed: 0.1156s/iter; left time: 6597.0368s
	iters: 1100, epoch: 8 | loss: 0.0748815
	speed: 0.1141s/iter; left time: 6500.1897s
	iters: 1200, epoch: 8 | loss: 0.0795547
	speed: 0.1146s/iter; left time: 6521.2980s
	iters: 1300, epoch: 8 | loss: 0.0994396
	speed: 0.1153s/iter; left time: 6548.6293s
	iters: 1400, epoch: 8 | loss: 0.0792517
	speed: 0.1165s/iter; left time: 6602.8411s
	iters: 1500, epoch: 8 | loss: 0.0784374
	speed: 0.1173s/iter; left time: 6636.2352s
	iters: 1600, epoch: 8 | loss: 0.0859944
	speed: 0.1158s/iter; left time: 6538.8571s
	iters: 1700, epoch: 8 | loss: 0.0819602
	speed: 0.1172s/iter; left time: 6609.0135s
	iters: 1800, epoch: 8 | loss: 0.0977695
	speed: 0.1156s/iter; left time: 6505.3635s
	iters: 1900, epoch: 8 | loss: 0.0645730
	speed: 0.1171s/iter; left time: 6578.6172s
	iters: 2000, epoch: 8 | loss: 0.0558155
	speed: 0.1168s/iter; left time: 6549.4902s
	iters: 2100, epoch: 8 | loss: 0.0748824
	speed: 0.1157s/iter; left time: 6478.2495s
	iters: 2200, epoch: 8 | loss: 0.0751968
	speed: 0.1162s/iter; left time: 6494.5979s
	iters: 2300, epoch: 8 | loss: 0.0775747
	speed: 0.1148s/iter; left time: 6404.6842s
	iters: 2400, epoch: 8 | loss: 0.0743494
	speed: 0.1139s/iter; left time: 6342.7048s
	iters: 2500, epoch: 8 | loss: 0.0847968
	speed: 0.1157s/iter; left time: 6433.2662s
	iters: 2600, epoch: 8 | loss: 0.0757934
	speed: 0.1164s/iter; left time: 6456.4094s
	iters: 2700, epoch: 8 | loss: 0.0962444
	speed: 0.1137s/iter; left time: 6297.2839s
	iters: 2800, epoch: 8 | loss: 0.0798034
	speed: 0.1155s/iter; left time: 6386.9256s
	iters: 2900, epoch: 8 | loss: 0.0616579
	speed: 0.1153s/iter; left time: 6360.0942s
	iters: 3000, epoch: 8 | loss: 0.0749053
	speed: 0.1160s/iter; left time: 6388.2991s
	iters: 3100, epoch: 8 | loss: 0.0779971
	speed: 0.1161s/iter; left time: 6384.3218s
	iters: 3200, epoch: 8 | loss: 0.0703546
	speed: 0.1156s/iter; left time: 6344.9051s
	iters: 3300, epoch: 8 | loss: 0.0924814
	speed: 0.1184s/iter; left time: 6485.7043s
	iters: 3400, epoch: 8 | loss: 0.0760914
	speed: 0.1151s/iter; left time: 6293.5055s
	iters: 3500, epoch: 8 | loss: 0.0540513
	speed: 0.1156s/iter; left time: 6309.0888s
	iters: 3600, epoch: 8 | loss: 0.0791183
	speed: 0.1166s/iter; left time: 6350.9989s
	iters: 3700, epoch: 8 | loss: 0.0715009
	speed: 0.1170s/iter; left time: 6365.5592s
	iters: 3800, epoch: 8 | loss: 0.0779355
	speed: 0.1161s/iter; left time: 6304.4201s
	iters: 3900, epoch: 8 | loss: 0.0706417
	speed: 0.1178s/iter; left time: 6382.4899s
	iters: 4000, epoch: 8 | loss: 0.0706924
	speed: 0.1169s/iter; left time: 6324.4682s
	iters: 4100, epoch: 8 | loss: 0.0704471
	speed: 0.1175s/iter; left time: 6342.1722s
	iters: 4200, epoch: 8 | loss: 0.0729290
	speed: 0.1144s/iter; left time: 6166.8255s
	iters: 4300, epoch: 8 | loss: 0.0735274
	speed: 0.1167s/iter; left time: 6279.3577s
	iters: 4400, epoch: 8 | loss: 0.0819775
	speed: 0.1163s/iter; left time: 6245.3451s
Epoch: 8 cost time: 00h:08m:39.75s
Epoch: 8 | Train Loss: 0.0784829 Vali Loss: 0.0906655 Test Loss: 0.1073768
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0807247
	speed: 1.5920s/iter; left time: 85200.9096s
	iters: 200, epoch: 9 | loss: 0.0876306
	speed: 0.1159s/iter; left time: 6188.4256s
	iters: 300, epoch: 9 | loss: 0.0690702
	speed: 0.1141s/iter; left time: 6083.2244s
	iters: 400, epoch: 9 | loss: 0.0685977
	speed: 0.1155s/iter; left time: 6144.9507s
	iters: 500, epoch: 9 | loss: 0.1049898
	speed: 0.1168s/iter; left time: 6202.2266s
	iters: 600, epoch: 9 | loss: 0.0862811
	speed: 0.1132s/iter; left time: 5999.1441s
	iters: 700, epoch: 9 | loss: 0.0700331
	speed: 0.1152s/iter; left time: 6093.7406s
	iters: 800, epoch: 9 | loss: 0.0694490
	speed: 0.1144s/iter; left time: 6041.9345s
	iters: 900, epoch: 9 | loss: 0.0769776
	speed: 0.1146s/iter; left time: 6043.7254s
	iters: 1000, epoch: 9 | loss: 0.0690558
	speed: 0.1141s/iter; left time: 6005.1500s
	iters: 1100, epoch: 9 | loss: 0.0718805
	speed: 0.1166s/iter; left time: 6125.6806s
	iters: 1200, epoch: 9 | loss: 0.0790950
	speed: 0.1166s/iter; left time: 6113.3885s
	iters: 1300, epoch: 9 | loss: 0.0878323
	speed: 0.1139s/iter; left time: 5957.3476s
	iters: 1400, epoch: 9 | loss: 0.0601362
	speed: 0.1162s/iter; left time: 6066.5406s
	iters: 1500, epoch: 9 | loss: 0.0813463
	speed: 0.1156s/iter; left time: 6026.6967s
	iters: 1600, epoch: 9 | loss: 0.0808004
	speed: 0.1173s/iter; left time: 6101.3994s
	iters: 1700, epoch: 9 | loss: 0.0846742
	speed: 0.1160s/iter; left time: 6021.5311s
	iters: 1800, epoch: 9 | loss: 0.0694577
	speed: 0.1165s/iter; left time: 6037.4243s
	iters: 1900, epoch: 9 | loss: 0.0717922
	speed: 0.1162s/iter; left time: 6010.5074s
	iters: 2000, epoch: 9 | loss: 0.0688320
	speed: 0.1155s/iter; left time: 5960.9380s
	iters: 2100, epoch: 9 | loss: 0.0924541
	speed: 0.1158s/iter; left time: 5965.4880s
	iters: 2200, epoch: 9 | loss: 0.0821416
	speed: 0.1134s/iter; left time: 5831.2938s
	iters: 2300, epoch: 9 | loss: 0.0760271
	speed: 0.1136s/iter; left time: 5831.3681s
	iters: 2400, epoch: 9 | loss: 0.0767931
	speed: 0.1146s/iter; left time: 5867.6329s
	iters: 2500, epoch: 9 | loss: 0.0697705
	speed: 0.1166s/iter; left time: 5959.7000s
	iters: 2600, epoch: 9 | loss: 0.0924100
	speed: 0.1174s/iter; left time: 5988.3751s
	iters: 2700, epoch: 9 | loss: 0.0637605
	speed: 0.1151s/iter; left time: 5862.7900s
	iters: 2800, epoch: 9 | loss: 0.0797227
	speed: 0.1144s/iter; left time: 5814.0759s
	iters: 2900, epoch: 9 | loss: 0.0813500
	speed: 0.1136s/iter; left time: 5762.7865s
	iters: 3000, epoch: 9 | loss: 0.0780612
	speed: 0.1135s/iter; left time: 5746.4798s
	iters: 3100, epoch: 9 | loss: 0.0720700
	speed: 0.1135s/iter; left time: 5735.5167s
	iters: 3200, epoch: 9 | loss: 0.0765664
	speed: 0.1161s/iter; left time: 5855.5431s
	iters: 3300, epoch: 9 | loss: 0.0852109
	speed: 0.1160s/iter; left time: 5839.0464s
	iters: 3400, epoch: 9 | loss: 0.0872862
	speed: 0.1130s/iter; left time: 5674.4628s
	iters: 3500, epoch: 9 | loss: 0.0673751
	speed: 0.1135s/iter; left time: 5689.5537s
	iters: 3600, epoch: 9 | loss: 0.0731839
	speed: 0.1136s/iter; left time: 5680.6715s
	iters: 3700, epoch: 9 | loss: 0.0864574
	speed: 0.1145s/iter; left time: 5713.9607s
	iters: 3800, epoch: 9 | loss: 0.0817628
	speed: 0.1132s/iter; left time: 5638.7590s
	iters: 3900, epoch: 9 | loss: 0.0986147
	speed: 0.1148s/iter; left time: 5706.3174s
	iters: 4000, epoch: 9 | loss: 0.0703890
	speed: 0.1135s/iter; left time: 5632.6065s
	iters: 4100, epoch: 9 | loss: 0.0744173
	speed: 0.1171s/iter; left time: 5796.8049s
	iters: 4200, epoch: 9 | loss: 0.0785395
	speed: 0.1150s/iter; left time: 5681.7597s
	iters: 4300, epoch: 9 | loss: 0.0744364
	speed: 0.1147s/iter; left time: 5655.6415s
	iters: 4400, epoch: 9 | loss: 0.0595877
	speed: 0.1140s/iter; left time: 5610.7776s
Epoch: 9 cost time: 00h:08m:34.31s
Epoch: 9 | Train Loss: 0.0773867 Vali Loss: 0.0910278 Test Loss: 0.1069496
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0671151
	speed: 1.5785s/iter; left time: 77423.5353s
	iters: 200, epoch: 10 | loss: 0.0828441
	speed: 0.1145s/iter; left time: 5605.6839s
	iters: 300, epoch: 10 | loss: 0.0783897
	speed: 0.1136s/iter; left time: 5546.8106s
	iters: 400, epoch: 10 | loss: 0.0834453
	speed: 0.1153s/iter; left time: 5620.6085s
	iters: 500, epoch: 10 | loss: 0.0739451
	speed: 0.1143s/iter; left time: 5561.1659s
	iters: 600, epoch: 10 | loss: 0.0635547
	speed: 0.1166s/iter; left time: 5660.8866s
	iters: 700, epoch: 10 | loss: 0.0789368
	speed: 0.1144s/iter; left time: 5543.8684s
	iters: 800, epoch: 10 | loss: 0.0980061
	speed: 0.1155s/iter; left time: 5582.6527s
	iters: 900, epoch: 10 | loss: 0.0827744
	speed: 0.1135s/iter; left time: 5478.4677s
	iters: 1000, epoch: 10 | loss: 0.0858516
	speed: 0.1160s/iter; left time: 5586.9409s
	iters: 1100, epoch: 10 | loss: 0.0609591
	speed: 0.1159s/iter; left time: 5570.3575s
	iters: 1200, epoch: 10 | loss: 0.0810569
	speed: 0.1169s/iter; left time: 5603.0406s
	iters: 1300, epoch: 10 | loss: 0.0937729
	speed: 0.1171s/iter; left time: 5602.3511s
	iters: 1400, epoch: 10 | loss: 0.0835219
	speed: 0.1161s/iter; left time: 5545.6390s
	iters: 1500, epoch: 10 | loss: 0.0743610
	speed: 0.1172s/iter; left time: 5584.3104s
	iters: 1600, epoch: 10 | loss: 0.0712053
	speed: 0.1170s/iter; left time: 5562.3177s
	iters: 1700, epoch: 10 | loss: 0.0691880
	speed: 0.1129s/iter; left time: 5357.6994s
	iters: 1800, epoch: 10 | loss: 0.0734778
	speed: 0.1141s/iter; left time: 5404.1841s
	iters: 1900, epoch: 10 | loss: 0.0740059
	speed: 0.1151s/iter; left time: 5439.5805s
	iters: 2000, epoch: 10 | loss: 0.0803476
	speed: 0.1189s/iter; left time: 5607.9472s
	iters: 2100, epoch: 10 | loss: 0.0573778
	speed: 0.1133s/iter; left time: 5331.1378s
	iters: 2200, epoch: 10 | loss: 0.0633182
	speed: 0.1135s/iter; left time: 5330.4922s
	iters: 2300, epoch: 10 | loss: 0.0607398
	speed: 0.1139s/iter; left time: 5334.9009s
	iters: 2400, epoch: 10 | loss: 0.0995448
	speed: 0.1147s/iter; left time: 5363.4710s
	iters: 2500, epoch: 10 | loss: 0.0664814
	speed: 0.1141s/iter; left time: 5324.1224s
	iters: 2600, epoch: 10 | loss: 0.0725956
	speed: 0.1151s/iter; left time: 5357.9144s
	iters: 2700, epoch: 10 | loss: 0.0891252
	speed: 0.1147s/iter; left time: 5329.2590s
	iters: 2800, epoch: 10 | loss: 0.0708456
	speed: 0.1129s/iter; left time: 5231.2750s
	iters: 2900, epoch: 10 | loss: 0.0679720
	speed: 0.1145s/iter; left time: 5294.0154s
	iters: 3000, epoch: 10 | loss: 0.0656617
	speed: 0.1147s/iter; left time: 5293.4144s
	iters: 3100, epoch: 10 | loss: 0.0661887
	speed: 0.1137s/iter; left time: 5235.6263s
	iters: 3200, epoch: 10 | loss: 0.0758295
	speed: 0.1158s/iter; left time: 5322.2497s
	iters: 3300, epoch: 10 | loss: 0.0698776
	speed: 0.1148s/iter; left time: 5263.9330s
	iters: 3400, epoch: 10 | loss: 0.0789215
	speed: 0.1148s/iter; left time: 5251.9707s
	iters: 3500, epoch: 10 | loss: 0.0749588
	speed: 0.1140s/iter; left time: 5202.1299s
	iters: 3600, epoch: 10 | loss: 0.1019792
	speed: 0.1160s/iter; left time: 5285.0743s
	iters: 3700, epoch: 10 | loss: 0.0910538
	speed: 0.1161s/iter; left time: 5275.2146s
	iters: 3800, epoch: 10 | loss: 0.0882741
	speed: 0.1137s/iter; left time: 5154.9439s
	iters: 3900, epoch: 10 | loss: 0.0684295
	speed: 0.1169s/iter; left time: 5291.0654s
	iters: 4000, epoch: 10 | loss: 0.0834578
	speed: 0.1151s/iter; left time: 5197.8577s
	iters: 4100, epoch: 10 | loss: 0.0795520
	speed: 0.1142s/iter; left time: 5146.1165s
	iters: 4200, epoch: 10 | loss: 0.0775932
	speed: 0.1176s/iter; left time: 5286.7117s
	iters: 4300, epoch: 10 | loss: 0.0749520
	speed: 0.1152s/iter; left time: 5168.5459s
	iters: 4400, epoch: 10 | loss: 0.0773880
	speed: 0.1140s/iter; left time: 5103.3444s
Epoch: 10 cost time: 00h:08m:34.73s
Epoch: 10 | Train Loss: 0.0764753 Vali Loss: 0.0915059 Test Loss: 0.1088750
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.025583267211914062, rmse:0.1599477082490921, mae:0.10403311252593994, rse:0.5514940619468689
success delete checkpoints
Intermediate time for GB and pred_len 24: 01h:52m:46.62s

=== Starting experiments for pred_len: 96 ===

--- Running model for GB, pred_len=96 ---
train 142645
val 30725
test 30725
[2024-11-03 07:57:52,023] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 07:57:53,303] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 07:57:53,303] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 07:57:53,303] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 07:57:53,403] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 07:57:53,403] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 07:57:54,256] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 07:57:54,257] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 07:57:54,257] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 07:57:54,258] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 07:57:54,259] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 07:57:54,259] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 07:57:54,259] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 07:57:54,259] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 07:57:54,259] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 07:57:54,259] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 07:57:54,707] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 07:57:54,708] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 07:57:54,708] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.75 GB, percent = 20.2%
[2024-11-03 07:57:54,878] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 07:57:54,879] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 07:57:54,879] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.77 GB, percent = 20.2%
[2024-11-03 07:57:54,879] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 07:57:55,059] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 07:57:55,060] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-03 07:57:55,060] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 152.72 GB, percent = 20.2%
[2024-11-03 07:57:55,061] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 07:57:55,061] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 07:57:55,061] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 07:57:55,061] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 07:57:55,062] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7a74e9add0>
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 07:57:55,063] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 07:57:55,064] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 07:57:55,065] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 07:57:55,065] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1688266
	speed: 0.1785s/iter; left time: 15893.5365s
	iters: 200, epoch: 1 | loss: 0.1466758
	speed: 0.1255s/iter; left time: 11163.3362s
	iters: 300, epoch: 1 | loss: 0.1657802
	speed: 0.1288s/iter; left time: 11443.9814s
	iters: 400, epoch: 1 | loss: 0.1365485
	speed: 0.1305s/iter; left time: 11583.9117s
	iters: 500, epoch: 1 | loss: 0.1343239
	speed: 0.1286s/iter; left time: 11396.9528s
	iters: 600, epoch: 1 | loss: 0.1273262
	speed: 0.1305s/iter; left time: 11555.1903s
	iters: 700, epoch: 1 | loss: 0.1142251
	speed: 0.1300s/iter; left time: 11495.5934s
	iters: 800, epoch: 1 | loss: 0.1129106
	speed: 0.1282s/iter; left time: 11327.4622s
	iters: 900, epoch: 1 | loss: 0.1081580
	speed: 0.1301s/iter; left time: 11483.9961s
	iters: 1000, epoch: 1 | loss: 0.1082976
	speed: 0.1288s/iter; left time: 11355.2133s
	iters: 1100, epoch: 1 | loss: 0.1104180
	speed: 0.1282s/iter; left time: 11289.5287s
	iters: 1200, epoch: 1 | loss: 0.1293156
	speed: 0.1285s/iter; left time: 11304.2771s
	iters: 1300, epoch: 1 | loss: 0.1199676
	speed: 0.1286s/iter; left time: 11298.3167s
	iters: 1400, epoch: 1 | loss: 0.0853492
	speed: 0.1277s/iter; left time: 11204.6884s
	iters: 1500, epoch: 1 | loss: 0.1185155
	speed: 0.1289s/iter; left time: 11294.9506s
	iters: 1600, epoch: 1 | loss: 0.1091379
	speed: 0.1280s/iter; left time: 11201.8787s
	iters: 1700, epoch: 1 | loss: 0.1387339
	speed: 0.1293s/iter; left time: 11306.8202s
	iters: 1800, epoch: 1 | loss: 0.1115096
	speed: 0.1266s/iter; left time: 11058.3400s
	iters: 1900, epoch: 1 | loss: 0.1182949
	speed: 0.1303s/iter; left time: 11364.1194s
	iters: 2000, epoch: 1 | loss: 0.1110286
	speed: 0.1287s/iter; left time: 11218.9095s
	iters: 2100, epoch: 1 | loss: 0.1118804
	speed: 0.1277s/iter; left time: 11113.0769s
	iters: 2200, epoch: 1 | loss: 0.1165919
	speed: 0.1274s/iter; left time: 11074.5511s
	iters: 2300, epoch: 1 | loss: 0.1117706
	speed: 0.1301s/iter; left time: 11299.2092s
	iters: 2400, epoch: 1 | loss: 0.1129438
	speed: 0.1294s/iter; left time: 11222.3812s
	iters: 2500, epoch: 1 | loss: 0.1135126
	speed: 0.1281s/iter; left time: 11096.9533s
	iters: 2600, epoch: 1 | loss: 0.1112166
	speed: 0.1286s/iter; left time: 11128.1423s
	iters: 2700, epoch: 1 | loss: 0.1203404
	speed: 0.1266s/iter; left time: 10943.4566s
	iters: 2800, epoch: 1 | loss: 0.1182374
	speed: 0.1295s/iter; left time: 11184.3534s
	iters: 2900, epoch: 1 | loss: 0.1069434
	speed: 0.1288s/iter; left time: 11103.8088s
	iters: 3000, epoch: 1 | loss: 0.1128676
	speed: 0.1270s/iter; left time: 10942.3124s
	iters: 3100, epoch: 1 | loss: 0.1112418
	speed: 0.1259s/iter; left time: 10836.4119s
	iters: 3200, epoch: 1 | loss: 0.1109535
	speed: 0.1280s/iter; left time: 11004.6363s
	iters: 3300, epoch: 1 | loss: 0.1022410
	speed: 0.1280s/iter; left time: 10991.1581s
	iters: 3400, epoch: 1 | loss: 0.1067109
	speed: 0.1288s/iter; left time: 11039.7652s
	iters: 3500, epoch: 1 | loss: 0.1093592
	speed: 0.1301s/iter; left time: 11142.3125s
	iters: 3600, epoch: 1 | loss: 0.1050644
	speed: 0.1300s/iter; left time: 11120.9045s
	iters: 3700, epoch: 1 | loss: 0.1453399
	speed: 0.1292s/iter; left time: 11037.9253s
	iters: 3800, epoch: 1 | loss: 0.1064153
	speed: 0.1306s/iter; left time: 11142.7100s
	iters: 3900, epoch: 1 | loss: 0.1275871
	speed: 0.1284s/iter; left time: 10940.9372s
	iters: 4000, epoch: 1 | loss: 0.1056856
	speed: 0.1266s/iter; left time: 10782.8795s
	iters: 4100, epoch: 1 | loss: 0.1163018
	speed: 0.1286s/iter; left time: 10939.7400s
	iters: 4200, epoch: 1 | loss: 0.1195716
	speed: 0.1284s/iter; left time: 10907.8794s
	iters: 4300, epoch: 1 | loss: 0.1011549
	speed: 0.1282s/iter; left time: 10878.4997s
	iters: 4400, epoch: 1 | loss: 0.1301714
	speed: 0.1273s/iter; left time: 10789.5248s
Epoch: 1 cost time: 00h:09m:34.14s
Epoch: 1 | Train Loss: 0.1159376 Vali Loss: 0.1171800 Test Loss: 0.1386980
Validation loss decreased (inf --> 0.117180).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1323460
	speed: 1.8177s/iter; left time: 153750.1873s
	iters: 200, epoch: 2 | loss: 0.0998212
	speed: 0.1151s/iter; left time: 9726.5930s
	iters: 300, epoch: 2 | loss: 0.1072860
	speed: 0.1144s/iter; left time: 9650.6818s
	iters: 400, epoch: 2 | loss: 0.1047579
	speed: 0.1165s/iter; left time: 9817.5607s
	iters: 500, epoch: 2 | loss: 0.0988569
	speed: 0.1131s/iter; left time: 9518.1567s
	iters: 600, epoch: 2 | loss: 0.1400726
	speed: 0.1153s/iter; left time: 9696.2221s
	iters: 700, epoch: 2 | loss: 0.1279359
	speed: 0.1146s/iter; left time: 9621.8230s
	iters: 800, epoch: 2 | loss: 0.1120330
	speed: 0.1140s/iter; left time: 9561.5629s
	iters: 900, epoch: 2 | loss: 0.1051929
	speed: 0.1129s/iter; left time: 9458.3001s
	iters: 1000, epoch: 2 | loss: 0.1209462
	speed: 0.1157s/iter; left time: 9681.0412s
	iters: 1100, epoch: 2 | loss: 0.1275426
	speed: 0.1137s/iter; left time: 9505.8381s
	iters: 1200, epoch: 2 | loss: 0.1159983
	speed: 0.1157s/iter; left time: 9656.7284s
	iters: 1300, epoch: 2 | loss: 0.1053278
	speed: 0.1147s/iter; left time: 9564.5253s
	iters: 1400, epoch: 2 | loss: 0.0974504
	speed: 0.1146s/iter; left time: 9545.8152s
	iters: 1500, epoch: 2 | loss: 0.0961491
	speed: 0.1162s/iter; left time: 9668.4279s
	iters: 1600, epoch: 2 | loss: 0.1127011
	speed: 0.1150s/iter; left time: 9551.3628s
	iters: 1700, epoch: 2 | loss: 0.1136763
	speed: 0.1160s/iter; left time: 9629.7080s
	iters: 1800, epoch: 2 | loss: 0.1032368
	speed: 0.1138s/iter; left time: 9430.6147s
	iters: 1900, epoch: 2 | loss: 0.0907084
	speed: 0.1128s/iter; left time: 9339.1341s
	iters: 2000, epoch: 2 | loss: 0.1084257
	speed: 0.1156s/iter; left time: 9560.5969s
	iters: 2100, epoch: 2 | loss: 0.1318485
	speed: 0.1146s/iter; left time: 9465.4027s
	iters: 2200, epoch: 2 | loss: 0.1092268
	speed: 0.1150s/iter; left time: 9482.2905s
	iters: 2300, epoch: 2 | loss: 0.0971450
	speed: 0.1159s/iter; left time: 9546.3702s
	iters: 2400, epoch: 2 | loss: 0.1082254
	speed: 0.1141s/iter; left time: 9386.9575s
	iters: 2500, epoch: 2 | loss: 0.1057774
	speed: 0.1130s/iter; left time: 9288.2027s
	iters: 2600, epoch: 2 | loss: 0.1233867
	speed: 0.1132s/iter; left time: 9294.7662s
	iters: 2700, epoch: 2 | loss: 0.1121541
	speed: 0.1137s/iter; left time: 9322.9370s
	iters: 2800, epoch: 2 | loss: 0.1023491
	speed: 0.1140s/iter; left time: 9334.0303s
	iters: 2900, epoch: 2 | loss: 0.1325897
	speed: 0.1140s/iter; left time: 9320.0574s
	iters: 3000, epoch: 2 | loss: 0.0932151
	speed: 0.1154s/iter; left time: 9425.6305s
	iters: 3100, epoch: 2 | loss: 0.1183982
	speed: 0.1155s/iter; left time: 9426.6047s
	iters: 3200, epoch: 2 | loss: 0.1071068
	speed: 0.1148s/iter; left time: 9355.3898s
	iters: 3300, epoch: 2 | loss: 0.0916324
	speed: 0.1159s/iter; left time: 9432.0369s
	iters: 3400, epoch: 2 | loss: 0.0934265
	speed: 0.1107s/iter; left time: 8998.8114s
	iters: 3500, epoch: 2 | loss: 0.1121869
	speed: 0.1131s/iter; left time: 9182.5247s
	iters: 3600, epoch: 2 | loss: 0.1178536
	speed: 0.1135s/iter; left time: 9204.1838s
	iters: 3700, epoch: 2 | loss: 0.1048463
	speed: 0.1135s/iter; left time: 9189.4847s
	iters: 3800, epoch: 2 | loss: 0.1119690
	speed: 0.1135s/iter; left time: 9180.8183s
	iters: 3900, epoch: 2 | loss: 0.1302823
	speed: 0.1146s/iter; left time: 9255.9061s
	iters: 4000, epoch: 2 | loss: 0.1027673
	speed: 0.1133s/iter; left time: 9141.1086s
	iters: 4100, epoch: 2 | loss: 0.1058483
	speed: 0.1124s/iter; left time: 9057.8689s
	iters: 4200, epoch: 2 | loss: 0.1003960
	speed: 0.1139s/iter; left time: 9169.8420s
	iters: 4300, epoch: 2 | loss: 0.0997679
	speed: 0.1143s/iter; left time: 9190.6403s
	iters: 4400, epoch: 2 | loss: 0.1080339
	speed: 0.1127s/iter; left time: 9048.9508s
Epoch: 2 cost time: 00h:08m:30.12s
Epoch: 2 | Train Loss: 0.1063434 Vali Loss: 0.1159233 Test Loss: 0.1404574
Validation loss decreased (0.117180 --> 0.115923).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0953313
	speed: 1.5298s/iter; left time: 122579.7741s
	iters: 200, epoch: 3 | loss: 0.0960641
	speed: 0.1129s/iter; left time: 9037.5760s
	iters: 300, epoch: 3 | loss: 0.1168496
	speed: 0.1128s/iter; left time: 9018.4111s
	iters: 400, epoch: 3 | loss: 0.1128009
	speed: 0.1139s/iter; left time: 9091.4012s
	iters: 500, epoch: 3 | loss: 0.1003084
	speed: 0.1134s/iter; left time: 9037.9726s
	iters: 600, epoch: 3 | loss: 0.1153115
	speed: 0.1150s/iter; left time: 9153.9593s
	iters: 700, epoch: 3 | loss: 0.1167073
	speed: 0.1128s/iter; left time: 8969.6655s
	iters: 800, epoch: 3 | loss: 0.1098146
	speed: 0.1131s/iter; left time: 8983.1531s
	iters: 900, epoch: 3 | loss: 0.0888241
	speed: 0.1131s/iter; left time: 8970.7544s
	iters: 1000, epoch: 3 | loss: 0.0963814
	speed: 0.1139s/iter; left time: 9022.4195s
	iters: 1100, epoch: 3 | loss: 0.1247230
	speed: 0.1133s/iter; left time: 8968.2897s
	iters: 1200, epoch: 3 | loss: 0.1112344
	speed: 0.1125s/iter; left time: 8891.8323s
	iters: 1300, epoch: 3 | loss: 0.1090816
	speed: 0.1131s/iter; left time: 8923.5137s
	iters: 1400, epoch: 3 | loss: 0.1014220
	speed: 0.1129s/iter; left time: 8897.4957s
	iters: 1500, epoch: 3 | loss: 0.1205137
	speed: 0.1142s/iter; left time: 8989.3578s
	iters: 1600, epoch: 3 | loss: 0.0969793
	speed: 0.1143s/iter; left time: 8985.5839s
	iters: 1700, epoch: 3 | loss: 0.1139035
	speed: 0.1153s/iter; left time: 9057.3622s
	iters: 1800, epoch: 3 | loss: 0.1128580
	speed: 0.1135s/iter; left time: 8903.3702s
	iters: 1900, epoch: 3 | loss: 0.1043471
	speed: 0.1139s/iter; left time: 8917.9254s
	iters: 2000, epoch: 3 | loss: 0.0987270
	speed: 0.1139s/iter; left time: 8912.4455s
	iters: 2100, epoch: 3 | loss: 0.0881278
	speed: 0.1126s/iter; left time: 8796.8159s
	iters: 2200, epoch: 3 | loss: 0.1081288
	speed: 0.1120s/iter; left time: 8738.4418s
	iters: 2300, epoch: 3 | loss: 0.0976076
	speed: 0.1126s/iter; left time: 8772.7511s
	iters: 2400, epoch: 3 | loss: 0.0961220
	speed: 0.1128s/iter; left time: 8775.3532s
	iters: 2500, epoch: 3 | loss: 0.0965293
	speed: 0.1127s/iter; left time: 8760.7689s
	iters: 2600, epoch: 3 | loss: 0.1095369
	speed: 0.1120s/iter; left time: 8697.7938s
	iters: 2700, epoch: 3 | loss: 0.1212904
	speed: 0.1144s/iter; left time: 8865.4812s
	iters: 2800, epoch: 3 | loss: 0.1003948
	speed: 0.1133s/iter; left time: 8775.0465s
	iters: 2900, epoch: 3 | loss: 0.1081474
	speed: 0.1133s/iter; left time: 8761.8701s
	iters: 3000, epoch: 3 | loss: 0.1015081
	speed: 0.1129s/iter; left time: 8715.9515s
	iters: 3100, epoch: 3 | loss: 0.0989254
	speed: 0.1135s/iter; left time: 8754.3035s
	iters: 3200, epoch: 3 | loss: 0.1039556
	speed: 0.1128s/iter; left time: 8692.0616s
	iters: 3300, epoch: 3 | loss: 0.0903572
	speed: 0.1132s/iter; left time: 8709.2199s
	iters: 3400, epoch: 3 | loss: 0.0759418
	speed: 0.1130s/iter; left time: 8682.8255s
	iters: 3500, epoch: 3 | loss: 0.1176762
	speed: 0.1120s/iter; left time: 8595.1412s
	iters: 3600, epoch: 3 | loss: 0.0941180
	speed: 0.1109s/iter; left time: 8494.2782s
	iters: 3700, epoch: 3 | loss: 0.1044800
	speed: 0.1118s/iter; left time: 8553.7069s
	iters: 3800, epoch: 3 | loss: 0.1119280
	speed: 0.1118s/iter; left time: 8543.0616s
	iters: 3900, epoch: 3 | loss: 0.1174034
	speed: 0.1113s/iter; left time: 8495.1171s
	iters: 4000, epoch: 3 | loss: 0.0906112
	speed: 0.1126s/iter; left time: 8584.3571s
	iters: 4100, epoch: 3 | loss: 0.1110326
	speed: 0.1132s/iter; left time: 8617.3934s
	iters: 4200, epoch: 3 | loss: 0.1211934
	speed: 0.1132s/iter; left time: 8603.3143s
	iters: 4300, epoch: 3 | loss: 0.1134209
	speed: 0.1138s/iter; left time: 8643.2430s
	iters: 4400, epoch: 3 | loss: 0.0881434
	speed: 0.1132s/iter; left time: 8582.5215s
Epoch: 3 cost time: 00h:08m:24.63s
Epoch: 3 | Train Loss: 0.1022726 Vali Loss: 0.1180037 Test Loss: 0.1440704
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0873546
	speed: 1.5100s/iter; left time: 114263.3071s
	iters: 200, epoch: 4 | loss: 0.1036950
	speed: 0.1139s/iter; left time: 8609.2430s
	iters: 300, epoch: 4 | loss: 0.0934119
	speed: 0.1139s/iter; left time: 8593.5786s
	iters: 400, epoch: 4 | loss: 0.1056632
	speed: 0.1150s/iter; left time: 8664.7593s
	iters: 500, epoch: 4 | loss: 0.0883508
	speed: 0.1135s/iter; left time: 8540.5182s
	iters: 600, epoch: 4 | loss: 0.0899846
	speed: 0.1128s/iter; left time: 8478.9874s
	iters: 700, epoch: 4 | loss: 0.0998617
	speed: 0.1132s/iter; left time: 8494.6099s
	iters: 800, epoch: 4 | loss: 0.0895698
	speed: 0.1122s/iter; left time: 8408.1319s
	iters: 900, epoch: 4 | loss: 0.1108057
	speed: 0.1133s/iter; left time: 8481.2006s
	iters: 1000, epoch: 4 | loss: 0.1005503
	speed: 0.1139s/iter; left time: 8514.6839s
	iters: 1100, epoch: 4 | loss: 0.0851609
	speed: 0.1138s/iter; left time: 8497.9852s
	iters: 1200, epoch: 4 | loss: 0.0922965
	speed: 0.1133s/iter; left time: 8452.3653s
	iters: 1300, epoch: 4 | loss: 0.0940839
	speed: 0.1130s/iter; left time: 8413.9763s
	iters: 1400, epoch: 4 | loss: 0.0969528
	speed: 0.1134s/iter; left time: 8436.9304s
	iters: 1500, epoch: 4 | loss: 0.0909017
	speed: 0.1125s/iter; left time: 8358.9278s
	iters: 1600, epoch: 4 | loss: 0.0886021
	speed: 0.1141s/iter; left time: 8463.9709s
	iters: 1700, epoch: 4 | loss: 0.0961353
	speed: 0.1132s/iter; left time: 8384.6226s
	iters: 1800, epoch: 4 | loss: 0.0882971
	speed: 0.1139s/iter; left time: 8427.3077s
	iters: 1900, epoch: 4 | loss: 0.0977799
	speed: 0.1143s/iter; left time: 8446.6530s
	iters: 2000, epoch: 4 | loss: 0.0880991
	speed: 0.1126s/iter; left time: 8309.3337s
	iters: 2100, epoch: 4 | loss: 0.0910579
	speed: 0.1132s/iter; left time: 8340.1650s
	iters: 2200, epoch: 4 | loss: 0.0977751
	speed: 0.1129s/iter; left time: 8305.7125s
	iters: 2300, epoch: 4 | loss: 0.0931557
	speed: 0.1141s/iter; left time: 8380.7850s
	iters: 2400, epoch: 4 | loss: 0.1089414
	speed: 0.1128s/iter; left time: 8275.7434s
	iters: 2500, epoch: 4 | loss: 0.1060289
	speed: 0.1136s/iter; left time: 8326.6336s
	iters: 2600, epoch: 4 | loss: 0.0834869
	speed: 0.1109s/iter; left time: 8113.2451s
	iters: 2700, epoch: 4 | loss: 0.1122872
	speed: 0.1139s/iter; left time: 8325.9781s
	iters: 2800, epoch: 4 | loss: 0.0878354
	speed: 0.1136s/iter; left time: 8292.4274s
	iters: 2900, epoch: 4 | loss: 0.0907886
	speed: 0.1146s/iter; left time: 8353.3154s
	iters: 3000, epoch: 4 | loss: 0.0977618
	speed: 0.1131s/iter; left time: 8230.6683s
	iters: 3100, epoch: 4 | loss: 0.0923466
	speed: 0.1129s/iter; left time: 8204.9562s
	iters: 3200, epoch: 4 | loss: 0.0991563
	speed: 0.1173s/iter; left time: 8508.9227s
	iters: 3300, epoch: 4 | loss: 0.1049987
	speed: 0.1162s/iter; left time: 8419.4591s
	iters: 3400, epoch: 4 | loss: 0.0708893
	speed: 0.1140s/iter; left time: 8252.0366s
	iters: 3500, epoch: 4 | loss: 0.0792143
	speed: 0.1137s/iter; left time: 8215.6924s
	iters: 3600, epoch: 4 | loss: 0.0895646
	speed: 0.1126s/iter; left time: 8129.8788s
	iters: 3700, epoch: 4 | loss: 0.1049187
	speed: 0.1127s/iter; left time: 8124.3975s
	iters: 3800, epoch: 4 | loss: 0.0842904
	speed: 0.1129s/iter; left time: 8126.8559s
	iters: 3900, epoch: 4 | loss: 0.0941178
	speed: 0.1108s/iter; left time: 7961.7936s
	iters: 4000, epoch: 4 | loss: 0.1109897
	speed: 0.1139s/iter; left time: 8177.1761s
	iters: 4100, epoch: 4 | loss: 0.1001586
	speed: 0.1125s/iter; left time: 8065.4055s
	iters: 4200, epoch: 4 | loss: 0.1093832
	speed: 0.1127s/iter; left time: 8068.1410s
	iters: 4300, epoch: 4 | loss: 0.0876529
	speed: 0.1123s/iter; left time: 8028.4879s
	iters: 4400, epoch: 4 | loss: 0.0952323
	speed: 0.1132s/iter; left time: 8081.8479s
Epoch: 4 cost time: 00h:08m:25.73s
Epoch: 4 | Train Loss: 0.0973941 Vali Loss: 0.1181420 Test Loss: 0.1481285
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0899206
	speed: 1.5235s/iter; left time: 108491.2324s
	iters: 200, epoch: 5 | loss: 0.1038604
	speed: 0.1154s/iter; left time: 8205.3218s
	iters: 300, epoch: 5 | loss: 0.1103195
	speed: 0.1156s/iter; left time: 8207.7192s
	iters: 400, epoch: 5 | loss: 0.0988987
	speed: 0.1153s/iter; left time: 8173.8791s
	iters: 500, epoch: 5 | loss: 0.1051342
	speed: 0.1136s/iter; left time: 8046.3911s
	iters: 600, epoch: 5 | loss: 0.0994484
	speed: 0.1174s/iter; left time: 8298.3677s
	iters: 700, epoch: 5 | loss: 0.0807362
	speed: 0.1152s/iter; left time: 8132.8384s
	iters: 800, epoch: 5 | loss: 0.1006454
	speed: 0.1152s/iter; left time: 8125.9078s
	iters: 900, epoch: 5 | loss: 0.1117228
	speed: 0.1140s/iter; left time: 8025.7115s
	iters: 1000, epoch: 5 | loss: 0.0958334
	speed: 0.1154s/iter; left time: 8114.8124s
	iters: 1100, epoch: 5 | loss: 0.0945488
	speed: 0.1149s/iter; left time: 8068.0753s
	iters: 1200, epoch: 5 | loss: 0.0999299
	speed: 0.1168s/iter; left time: 8190.4201s
	iters: 1300, epoch: 5 | loss: 0.0833874
	speed: 0.1151s/iter; left time: 8061.9571s
	iters: 1400, epoch: 5 | loss: 0.0800731
	speed: 0.1166s/iter; left time: 8150.3149s
	iters: 1500, epoch: 5 | loss: 0.0873000
	speed: 0.1170s/iter; left time: 8169.8289s
	iters: 1600, epoch: 5 | loss: 0.0974982
	speed: 0.1148s/iter; left time: 8005.9197s
	iters: 1700, epoch: 5 | loss: 0.0832424
	speed: 0.1148s/iter; left time: 7990.4724s
	iters: 1800, epoch: 5 | loss: 0.0964874
	speed: 0.1142s/iter; left time: 7938.4620s
	iters: 1900, epoch: 5 | loss: 0.1015488
	speed: 0.1148s/iter; left time: 7971.9532s
	iters: 2000, epoch: 5 | loss: 0.0962706
	speed: 0.1139s/iter; left time: 7893.5208s
	iters: 2100, epoch: 5 | loss: 0.0944651
	speed: 0.1158s/iter; left time: 8014.9157s
	iters: 2200, epoch: 5 | loss: 0.0883529
	speed: 0.1142s/iter; left time: 7892.4674s
	iters: 2300, epoch: 5 | loss: 0.0954471
	speed: 0.1152s/iter; left time: 7952.3328s
	iters: 2400, epoch: 5 | loss: 0.0827175
	speed: 0.1146s/iter; left time: 7899.6119s
	iters: 2500, epoch: 5 | loss: 0.1006347
	speed: 0.1144s/iter; left time: 7870.0949s
	iters: 2600, epoch: 5 | loss: 0.0951255
	speed: 0.1165s/iter; left time: 8005.8141s
	iters: 2700, epoch: 5 | loss: 0.1033527
	speed: 0.1175s/iter; left time: 8060.1569s
	iters: 2800, epoch: 5 | loss: 0.0756043
	speed: 0.1147s/iter; left time: 7858.7596s
	iters: 2900, epoch: 5 | loss: 0.0850169
	speed: 0.1152s/iter; left time: 7882.4580s
	iters: 3000, epoch: 5 | loss: 0.1090293
	speed: 0.1144s/iter; left time: 7814.8763s
	iters: 3100, epoch: 5 | loss: 0.0975026
	speed: 0.1145s/iter; left time: 7813.4333s
	iters: 3200, epoch: 5 | loss: 0.0954872
	speed: 0.1149s/iter; left time: 7823.0406s
	iters: 3300, epoch: 5 | loss: 0.0834685
	speed: 0.1166s/iter; left time: 7931.9783s
	iters: 3400, epoch: 5 | loss: 0.0841382
	speed: 0.1164s/iter; left time: 7902.3602s
	iters: 3500, epoch: 5 | loss: 0.0745072
	speed: 0.1160s/iter; left time: 7863.0053s
	iters: 3600, epoch: 5 | loss: 0.1053615
	speed: 0.1157s/iter; left time: 7837.6776s
	iters: 3700, epoch: 5 | loss: 0.0791975
	speed: 0.1165s/iter; left time: 7879.8089s
	iters: 3800, epoch: 5 | loss: 0.0998375
	speed: 0.1157s/iter; left time: 7814.3196s
	iters: 3900, epoch: 5 | loss: 0.0949914
	speed: 0.1157s/iter; left time: 7801.0721s
	iters: 4000, epoch: 5 | loss: 0.0968361
	speed: 0.1149s/iter; left time: 7735.8557s
	iters: 4100, epoch: 5 | loss: 0.0942416
	speed: 0.1143s/iter; left time: 7685.6907s
	iters: 4200, epoch: 5 | loss: 0.1008289
	speed: 0.1138s/iter; left time: 7634.2870s
	iters: 4300, epoch: 5 | loss: 0.0779671
	speed: 0.1151s/iter; left time: 7711.2709s
	iters: 4400, epoch: 5 | loss: 0.0973403
	speed: 0.1155s/iter; left time: 7725.3286s
Epoch: 5 cost time: 00h:08m:34.07s
Epoch: 5 | Train Loss: 0.0930669 Vali Loss: 0.1177695 Test Loss: 0.1494393
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0950565
	speed: 1.5478s/iter; left time: 103326.1281s
	iters: 200, epoch: 6 | loss: 0.0880194
	speed: 0.1140s/iter; left time: 7598.5819s
	iters: 300, epoch: 6 | loss: 0.0845609
	speed: 0.1146s/iter; left time: 7628.5804s
	iters: 400, epoch: 6 | loss: 0.0856797
	speed: 0.1171s/iter; left time: 7784.0110s
	iters: 500, epoch: 6 | loss: 0.0811084
	speed: 0.1152s/iter; left time: 7641.6682s
	iters: 600, epoch: 6 | loss: 0.1066922
	speed: 0.1153s/iter; left time: 7640.4823s
	iters: 700, epoch: 6 | loss: 0.0946200
	speed: 0.1154s/iter; left time: 7632.8492s
	iters: 800, epoch: 6 | loss: 0.1000760
	speed: 0.1148s/iter; left time: 7581.1448s
	iters: 900, epoch: 6 | loss: 0.0695545
	speed: 0.1170s/iter; left time: 7717.6166s
	iters: 1000, epoch: 6 | loss: 0.1009072
	speed: 0.1155s/iter; left time: 7606.8553s
	iters: 1100, epoch: 6 | loss: 0.0820811
	speed: 0.1148s/iter; left time: 7547.9258s
	iters: 1200, epoch: 6 | loss: 0.1012075
	speed: 0.1142s/iter; left time: 7495.7848s
	iters: 1300, epoch: 6 | loss: 0.0863402
	speed: 0.1158s/iter; left time: 7588.2879s
	iters: 1400, epoch: 6 | loss: 0.0826545
	speed: 0.1159s/iter; left time: 7587.4863s
	iters: 1500, epoch: 6 | loss: 0.0777465
	speed: 0.1156s/iter; left time: 7557.8843s
	iters: 1600, epoch: 6 | loss: 0.1057802
	speed: 0.1166s/iter; left time: 7611.9507s
	iters: 1700, epoch: 6 | loss: 0.0942861
	speed: 0.1162s/iter; left time: 7569.9625s
	iters: 1800, epoch: 6 | loss: 0.0920153
	speed: 0.1164s/iter; left time: 7574.8956s
	iters: 1900, epoch: 6 | loss: 0.0782236
	speed: 0.1161s/iter; left time: 7542.9847s
	iters: 2000, epoch: 6 | loss: 0.0907045
	speed: 0.1116s/iter; left time: 7237.2041s
	iters: 2100, epoch: 6 | loss: 0.0759282
	speed: 0.1137s/iter; left time: 7359.8177s
	iters: 2200, epoch: 6 | loss: 0.1017066
	speed: 0.1148s/iter; left time: 7422.9566s
	iters: 2300, epoch: 6 | loss: 0.0679502
	speed: 0.1181s/iter; left time: 7621.3176s
	iters: 2400, epoch: 6 | loss: 0.0776927
	speed: 0.1167s/iter; left time: 7525.2174s
	iters: 2500, epoch: 6 | loss: 0.0888472
	speed: 0.1147s/iter; left time: 7383.1680s
	iters: 2600, epoch: 6 | loss: 0.0768875
	speed: 0.1166s/iter; left time: 7491.8912s
	iters: 2700, epoch: 6 | loss: 0.0782935
	speed: 0.1167s/iter; left time: 7489.6762s
	iters: 2800, epoch: 6 | loss: 0.0903737
	speed: 0.1143s/iter; left time: 7319.0551s
	iters: 2900, epoch: 6 | loss: 0.1004810
	speed: 0.1151s/iter; left time: 7362.3392s
	iters: 3000, epoch: 6 | loss: 0.0948790
	speed: 0.1163s/iter; left time: 7428.4829s
	iters: 3100, epoch: 6 | loss: 0.0886455
	speed: 0.1128s/iter; left time: 7194.6490s
	iters: 3200, epoch: 6 | loss: 0.0854608
	speed: 0.1158s/iter; left time: 7370.2266s
	iters: 3300, epoch: 6 | loss: 0.0769016
	speed: 0.1162s/iter; left time: 7384.1257s
	iters: 3400, epoch: 6 | loss: 0.0817375
	speed: 0.1164s/iter; left time: 7384.1548s
	iters: 3500, epoch: 6 | loss: 0.0888851
	speed: 0.1152s/iter; left time: 7295.7853s
	iters: 3600, epoch: 6 | loss: 0.0727457
	speed: 0.1156s/iter; left time: 7311.4228s
	iters: 3700, epoch: 6 | loss: 0.0903441
	speed: 0.1161s/iter; left time: 7334.4639s
	iters: 3800, epoch: 6 | loss: 0.0950212
	speed: 0.1164s/iter; left time: 7338.4941s
	iters: 3900, epoch: 6 | loss: 0.0870087
	speed: 0.1164s/iter; left time: 7330.3570s
	iters: 4000, epoch: 6 | loss: 0.0871792
	speed: 0.1141s/iter; left time: 7170.3075s
	iters: 4100, epoch: 6 | loss: 0.0932686
	speed: 0.1145s/iter; left time: 7187.2149s
	iters: 4200, epoch: 6 | loss: 0.0874465
	speed: 0.1179s/iter; left time: 7389.2674s
	iters: 4300, epoch: 6 | loss: 0.0889675
	speed: 0.1146s/iter; left time: 7171.8204s
	iters: 4400, epoch: 6 | loss: 0.0926063
	speed: 0.1141s/iter; left time: 7129.0473s
Epoch: 6 cost time: 00h:08m:35.30s
Epoch: 6 | Train Loss: 0.0893757 Vali Loss: 0.1196648 Test Loss: 0.1541289
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.1048594
	speed: 1.5670s/iter; left time: 97624.5618s
	iters: 200, epoch: 7 | loss: 0.0843566
	speed: 0.1158s/iter; left time: 7202.4942s
	iters: 300, epoch: 7 | loss: 0.0917804
	speed: 0.1159s/iter; left time: 7197.7076s
	iters: 400, epoch: 7 | loss: 0.0795149
	speed: 0.1163s/iter; left time: 7208.8362s
	iters: 500, epoch: 7 | loss: 0.0842911
	speed: 0.1164s/iter; left time: 7204.4799s
	iters: 600, epoch: 7 | loss: 0.0841490
	speed: 0.1165s/iter; left time: 7197.0453s
	iters: 700, epoch: 7 | loss: 0.1009502
	speed: 0.1176s/iter; left time: 7256.1310s
	iters: 800, epoch: 7 | loss: 0.0739675
	speed: 0.1168s/iter; left time: 7195.5046s
	iters: 900, epoch: 7 | loss: 0.0888571
	speed: 0.1167s/iter; left time: 7176.0577s
	iters: 1000, epoch: 7 | loss: 0.0870971
	speed: 0.1167s/iter; left time: 7162.7047s
	iters: 1100, epoch: 7 | loss: 0.0928913
	speed: 0.1164s/iter; left time: 7136.7999s
	iters: 1200, epoch: 7 | loss: 0.0886939
	speed: 0.1136s/iter; left time: 6953.2413s
	iters: 1300, epoch: 7 | loss: 0.0893422
	speed: 0.1159s/iter; left time: 7082.8468s
	iters: 1400, epoch: 7 | loss: 0.0847866
	speed: 0.1163s/iter; left time: 7092.0799s
	iters: 1500, epoch: 7 | loss: 0.0769473
	speed: 0.1159s/iter; left time: 7060.6891s
	iters: 1600, epoch: 7 | loss: 0.0924601
	speed: 0.1148s/iter; left time: 6981.6211s
	iters: 1700, epoch: 7 | loss: 0.0808676
	speed: 0.1129s/iter; left time: 6850.2870s
	iters: 1800, epoch: 7 | loss: 0.0922723
	speed: 0.1167s/iter; left time: 7071.4805s
	iters: 1900, epoch: 7 | loss: 0.0814242
	speed: 0.1156s/iter; left time: 6992.7185s
	iters: 2000, epoch: 7 | loss: 0.0870774
	speed: 0.1151s/iter; left time: 6950.2598s
	iters: 2100, epoch: 7 | loss: 0.0811431
	speed: 0.1156s/iter; left time: 6970.0987s
	iters: 2200, epoch: 7 | loss: 0.0951526
	speed: 0.1132s/iter; left time: 6812.4758s
	iters: 2300, epoch: 7 | loss: 0.0774082
	speed: 0.1148s/iter; left time: 6898.2062s
	iters: 2400, epoch: 7 | loss: 0.0838267
	speed: 0.1152s/iter; left time: 6909.5983s
	iters: 2500, epoch: 7 | loss: 0.0840728
	speed: 0.1140s/iter; left time: 6825.7495s
	iters: 2600, epoch: 7 | loss: 0.0857305
	speed: 0.1154s/iter; left time: 6900.0571s
	iters: 2700, epoch: 7 | loss: 0.0911212
	speed: 0.1161s/iter; left time: 6931.8133s
	iters: 2800, epoch: 7 | loss: 0.0788338
	speed: 0.1136s/iter; left time: 6770.5995s
	iters: 2900, epoch: 7 | loss: 0.0812203
	speed: 0.1129s/iter; left time: 6717.0057s
	iters: 3000, epoch: 7 | loss: 0.0968771
	speed: 0.1153s/iter; left time: 6846.5521s
	iters: 3100, epoch: 7 | loss: 0.0815360
	speed: 0.1158s/iter; left time: 6866.4748s
	iters: 3200, epoch: 7 | loss: 0.0820606
	speed: 0.1159s/iter; left time: 6862.3245s
	iters: 3300, epoch: 7 | loss: 0.0775566
	speed: 0.1134s/iter; left time: 6703.6955s
	iters: 3400, epoch: 7 | loss: 0.1014951
	speed: 0.1149s/iter; left time: 6777.4195s
	iters: 3500, epoch: 7 | loss: 0.0893218
	speed: 0.1148s/iter; left time: 6759.9584s
	iters: 3600, epoch: 7 | loss: 0.0940796
	speed: 0.1172s/iter; left time: 6888.9346s
	iters: 3700, epoch: 7 | loss: 0.0836638
	speed: 0.1131s/iter; left time: 6636.1693s
	iters: 3800, epoch: 7 | loss: 0.1027704
	speed: 0.1150s/iter; left time: 6736.3065s
	iters: 3900, epoch: 7 | loss: 0.0680492
	speed: 0.1139s/iter; left time: 6663.9134s
	iters: 4000, epoch: 7 | loss: 0.1034615
	speed: 0.1145s/iter; left time: 6683.8426s
	iters: 4100, epoch: 7 | loss: 0.0949323
	speed: 0.1138s/iter; left time: 6632.1384s
	iters: 4200, epoch: 7 | loss: 0.0865043
	speed: 0.1150s/iter; left time: 6693.9101s
	iters: 4300, epoch: 7 | loss: 0.0960433
	speed: 0.1149s/iter; left time: 6677.9859s
	iters: 4400, epoch: 7 | loss: 0.0965981
	speed: 0.1142s/iter; left time: 6624.5261s
Epoch: 7 cost time: 00h:08m:34.14s
Epoch: 7 | Train Loss: 0.0862290 Vali Loss: 0.1190629 Test Loss: 0.1528910
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.04200141876935959, rmse:0.2049424797296524, mae:0.14045733213424683, rse:0.7086868286132812
success delete checkpoints
Intermediate time for GB and pred_len 96: 01h:18m:33.66s

=== Starting experiments for pred_len: 168 ===

--- Running model for GB, pred_len=168 ---
train 142285
val 30365
test 30365
[2024-11-03 09:16:27,227] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-03 09:16:28,647] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-03 09:16:28,647] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-03 09:16:28,648] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-03 09:16:28,773] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-03 09:16:28,773] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-03 09:16:29,576] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-03 09:16:29,577] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-03 09:16:29,577] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-03 09:16:29,579] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-03 09:16:29,579] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-03 09:16:29,579] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-03 09:16:29,579] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-03 09:16:29,579] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-03 09:16:29,579] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-03 09:16:29,579] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-03 09:16:29,986] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-03 09:16:29,987] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-03 09:16:29,988] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 161.5 GB, percent = 21.4%
[2024-11-03 09:16:30,171] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-03 09:16:30,172] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-03 09:16:30,172] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 161.51 GB, percent = 21.4%
[2024-11-03 09:16:30,172] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-03 09:16:30,348] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-03 09:16:30,349] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-03 09:16:30,349] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 161.51 GB, percent = 21.4%
[2024-11-03 09:16:30,350] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-03 09:16:30,351] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-03 09:16:30,351] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-03 09:16:30,351] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-03 09:16:30,352] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-03 09:16:30,352] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-03 09:16:30,352] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-03 09:16:30,352] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-03 09:16:30,352] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f80738ae1d0>
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-03 09:16:30,353] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-03 09:16:30,354] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-03 09:16:30,355] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-03 09:16:30,356] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-03 09:16:30,356] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1482348
	speed: 0.1806s/iter; left time: 16043.0744s
	iters: 200, epoch: 1 | loss: 0.1453139
	speed: 0.1298s/iter; left time: 11516.6845s
	iters: 300, epoch: 1 | loss: 0.1553313
	speed: 0.1296s/iter; left time: 11486.2147s
	iters: 400, epoch: 1 | loss: 0.1554058
	speed: 0.1298s/iter; left time: 11493.2830s
	iters: 500, epoch: 1 | loss: 0.1471658
	speed: 0.1276s/iter; left time: 11279.4548s
	iters: 600, epoch: 1 | loss: 0.1542638
	speed: 0.1299s/iter; left time: 11473.4496s
	iters: 700, epoch: 1 | loss: 0.1336013
	speed: 0.1302s/iter; left time: 11485.4159s
	iters: 800, epoch: 1 | loss: 0.1162374
	speed: 0.1307s/iter; left time: 11521.5088s
	iters: 900, epoch: 1 | loss: 0.1247154
	speed: 0.1290s/iter; left time: 11358.7186s
	iters: 1000, epoch: 1 | loss: 0.1020275
	speed: 0.1299s/iter; left time: 11422.7040s
	iters: 1100, epoch: 1 | loss: 0.1375454
	speed: 0.1282s/iter; left time: 11259.6940s
	iters: 1200, epoch: 1 | loss: 0.1161896
	speed: 0.1314s/iter; left time: 11523.9214s
	iters: 1300, epoch: 1 | loss: 0.1136029
	speed: 0.1286s/iter; left time: 11267.5807s
	iters: 1400, epoch: 1 | loss: 0.1167578
	speed: 0.1286s/iter; left time: 11253.9748s
	iters: 1500, epoch: 1 | loss: 0.1177376
	speed: 0.1304s/iter; left time: 11401.8118s
	iters: 1600, epoch: 1 | loss: 0.1085610
	speed: 0.1304s/iter; left time: 11385.5133s
	iters: 1700, epoch: 1 | loss: 0.1154755
	speed: 0.1287s/iter; left time: 11223.4444s
	iters: 1800, epoch: 1 | loss: 0.0951475
	speed: 0.1291s/iter; left time: 11248.3587s
	iters: 1900, epoch: 1 | loss: 0.1343727
	speed: 0.1315s/iter; left time: 11440.2881s
	iters: 2000, epoch: 1 | loss: 0.1305830
	speed: 0.1288s/iter; left time: 11194.6836s
	iters: 2100, epoch: 1 | loss: 0.1169467
	speed: 0.1273s/iter; left time: 11050.9776s
	iters: 2200, epoch: 1 | loss: 0.1000786
	speed: 0.1265s/iter; left time: 10966.5075s
	iters: 2300, epoch: 1 | loss: 0.0901878
	speed: 0.1276s/iter; left time: 11055.7600s
	iters: 2400, epoch: 1 | loss: 0.1336366
	speed: 0.1273s/iter; left time: 11016.1030s
	iters: 2500, epoch: 1 | loss: 0.1131255
	speed: 0.1289s/iter; left time: 11142.5916s
	iters: 2600, epoch: 1 | loss: 0.1157848
	speed: 0.1275s/iter; left time: 11003.2673s
	iters: 2700, epoch: 1 | loss: 0.1087803
	speed: 0.1296s/iter; left time: 11171.4330s
	iters: 2800, epoch: 1 | loss: 0.1142708
	speed: 0.1293s/iter; left time: 11135.9459s
	iters: 2900, epoch: 1 | loss: 0.1243213
	speed: 0.1301s/iter; left time: 11193.6051s
	iters: 3000, epoch: 1 | loss: 0.0919846
	speed: 0.1320s/iter; left time: 11342.2288s
	iters: 3100, epoch: 1 | loss: 0.1445014
	speed: 0.1291s/iter; left time: 11081.8479s
	iters: 3200, epoch: 1 | loss: 0.0993669
	speed: 0.1289s/iter; left time: 11046.5269s
	iters: 3300, epoch: 1 | loss: 0.1163438
	speed: 0.1293s/iter; left time: 11069.4295s
	iters: 3400, epoch: 1 | loss: 0.1209128
	speed: 0.1283s/iter; left time: 10975.8670s
	iters: 3500, epoch: 1 | loss: 0.0993587
	speed: 0.1268s/iter; left time: 10831.2122s
	iters: 3600, epoch: 1 | loss: 0.1136707
	speed: 0.1281s/iter; left time: 10929.0588s
	iters: 3700, epoch: 1 | loss: 0.1139015
	speed: 0.1290s/iter; left time: 10996.0999s
	iters: 3800, epoch: 1 | loss: 0.1168825
	speed: 0.1306s/iter; left time: 11112.7088s
	iters: 3900, epoch: 1 | loss: 0.1059878
	speed: 0.1280s/iter; left time: 10882.4153s
	iters: 4000, epoch: 1 | loss: 0.1127900
	speed: 0.1280s/iter; left time: 10865.7985s
	iters: 4100, epoch: 1 | loss: 0.1130453
	speed: 0.1272s/iter; left time: 10787.6265s
	iters: 4200, epoch: 1 | loss: 0.1120209
	speed: 0.1293s/iter; left time: 10953.2413s
	iters: 4300, epoch: 1 | loss: 0.1165368
	speed: 0.1280s/iter; left time: 10831.6520s
	iters: 4400, epoch: 1 | loss: 0.1169618
	speed: 0.1292s/iter; left time: 10917.5637s
Epoch: 1 cost time: 00h:09m:35.04s
Epoch: 1 | Train Loss: 0.1205897 Vali Loss: 0.1209952 Test Loss: 0.1438364
Validation loss decreased (inf --> 0.120995).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1197857
	speed: 1.8114s/iter; left time: 152836.4726s
	iters: 200, epoch: 2 | loss: 0.1099122
	speed: 0.1168s/iter; left time: 9845.0516s
	iters: 300, epoch: 2 | loss: 0.1050249
	speed: 0.1172s/iter; left time: 9866.8842s
	iters: 400, epoch: 2 | loss: 0.1127598
	speed: 0.1170s/iter; left time: 9837.4411s
	iters: 500, epoch: 2 | loss: 0.0847004
	speed: 0.1180s/iter; left time: 9909.6726s
	iters: 600, epoch: 2 | loss: 0.1266375
	speed: 0.1166s/iter; left time: 9776.1746s
	iters: 700, epoch: 2 | loss: 0.1209411
	speed: 0.1175s/iter; left time: 9841.5933s
	iters: 800, epoch: 2 | loss: 0.1068922
	speed: 0.1167s/iter; left time: 9763.5481s
	iters: 900, epoch: 2 | loss: 0.0993572
	speed: 0.1166s/iter; left time: 9743.6605s
	iters: 1000, epoch: 2 | loss: 0.1088792
	speed: 0.1193s/iter; left time: 9954.9116s
	iters: 1100, epoch: 2 | loss: 0.1103762
	speed: 0.1184s/iter; left time: 9871.9279s
	iters: 1200, epoch: 2 | loss: 0.1110987
	speed: 0.1178s/iter; left time: 9809.1376s
	iters: 1300, epoch: 2 | loss: 0.0816215
	speed: 0.1163s/iter; left time: 9669.8693s
	iters: 1400, epoch: 2 | loss: 0.1149543
	speed: 0.1170s/iter; left time: 9723.7857s
	iters: 1500, epoch: 2 | loss: 0.1127167
	speed: 0.1155s/iter; left time: 9583.8694s
	iters: 1600, epoch: 2 | loss: 0.1143629
	speed: 0.1171s/iter; left time: 9706.3140s
	iters: 1700, epoch: 2 | loss: 0.1134126
	speed: 0.1158s/iter; left time: 9581.8043s
	iters: 1800, epoch: 2 | loss: 0.1078830
	speed: 0.1166s/iter; left time: 9640.7901s
	iters: 1900, epoch: 2 | loss: 0.0992961
	speed: 0.1160s/iter; left time: 9576.2030s
	iters: 2000, epoch: 2 | loss: 0.1067948
	speed: 0.1166s/iter; left time: 9617.4982s
	iters: 2100, epoch: 2 | loss: 0.1038578
	speed: 0.1145s/iter; left time: 9432.7129s
	iters: 2200, epoch: 2 | loss: 0.1177262
	speed: 0.1165s/iter; left time: 9584.8832s
	iters: 2300, epoch: 2 | loss: 0.1152344
	speed: 0.1140s/iter; left time: 9365.2021s
	iters: 2400, epoch: 2 | loss: 0.1077954
	speed: 0.1157s/iter; left time: 9498.0317s
	iters: 2500, epoch: 2 | loss: 0.1127032
	speed: 0.1171s/iter; left time: 9602.6803s
	iters: 2600, epoch: 2 | loss: 0.1118686
	speed: 0.1122s/iter; left time: 9184.2086s
	iters: 2700, epoch: 2 | loss: 0.1096208
	speed: 0.1129s/iter; left time: 9234.7673s
	iters: 2800, epoch: 2 | loss: 0.0965174
	speed: 0.1125s/iter; left time: 9190.5343s
	iters: 2900, epoch: 2 | loss: 0.1007073
	speed: 0.1129s/iter; left time: 9208.9160s
	iters: 3000, epoch: 2 | loss: 0.0923950
	speed: 0.1153s/iter; left time: 9395.5281s
	iters: 3100, epoch: 2 | loss: 0.1115430
	speed: 0.1138s/iter; left time: 9260.0025s
	iters: 3200, epoch: 2 | loss: 0.1126868
	speed: 0.1146s/iter; left time: 9311.4516s
	iters: 3300, epoch: 2 | loss: 0.1034839
	speed: 0.1118s/iter; left time: 9072.6644s
	iters: 3400, epoch: 2 | loss: 0.1078405
	speed: 0.1113s/iter; left time: 9022.3053s
	iters: 3500, epoch: 2 | loss: 0.1037599
	speed: 0.1137s/iter; left time: 9208.3424s
	iters: 3600, epoch: 2 | loss: 0.0952058
	speed: 0.1122s/iter; left time: 9076.4295s
	iters: 3700, epoch: 2 | loss: 0.1051804
	speed: 0.1120s/iter; left time: 9045.5504s
	iters: 3800, epoch: 2 | loss: 0.1044087
	speed: 0.1130s/iter; left time: 9113.2990s
	iters: 3900, epoch: 2 | loss: 0.1066130
	speed: 0.1147s/iter; left time: 9241.7066s
	iters: 4000, epoch: 2 | loss: 0.1092677
	speed: 0.1133s/iter; left time: 9121.1625s
	iters: 4100, epoch: 2 | loss: 0.1083696
	speed: 0.1133s/iter; left time: 9110.3547s
	iters: 4200, epoch: 2 | loss: 0.1197105
	speed: 0.1132s/iter; left time: 9089.6904s
	iters: 4300, epoch: 2 | loss: 0.1068081
	speed: 0.1117s/iter; left time: 8954.9869s
	iters: 4400, epoch: 2 | loss: 0.1261329
	speed: 0.1128s/iter; left time: 9030.0277s
Epoch: 2 cost time: 00h:08m:32.27s
Epoch: 2 | Train Loss: 0.1098766 Vali Loss: 0.1225332 Test Loss: 0.1477604
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0998430
	speed: 1.5405s/iter; left time: 123129.9321s
	iters: 200, epoch: 3 | loss: 0.1029584
	speed: 0.1128s/iter; left time: 9008.1590s
	iters: 300, epoch: 3 | loss: 0.0965041
	speed: 0.1161s/iter; left time: 9253.1586s
	iters: 400, epoch: 3 | loss: 0.1077358
	speed: 0.1167s/iter; left time: 9291.2182s
	iters: 500, epoch: 3 | loss: 0.1056079
	speed: 0.1153s/iter; left time: 9165.7626s
	iters: 600, epoch: 3 | loss: 0.1190159
	speed: 0.1167s/iter; left time: 9271.6581s
	iters: 700, epoch: 3 | loss: 0.1028953
	speed: 0.1166s/iter; left time: 9248.6437s
	iters: 800, epoch: 3 | loss: 0.1252995
	speed: 0.1160s/iter; left time: 9193.5876s
	iters: 900, epoch: 3 | loss: 0.0910322
	speed: 0.1143s/iter; left time: 9045.1347s
	iters: 1000, epoch: 3 | loss: 0.1096593
	speed: 0.1166s/iter; left time: 9214.4819s
	iters: 1100, epoch: 3 | loss: 0.0958329
	speed: 0.1161s/iter; left time: 9163.4822s
	iters: 1200, epoch: 3 | loss: 0.1051666
	speed: 0.1139s/iter; left time: 8978.8459s
	iters: 1300, epoch: 3 | loss: 0.1145009
	speed: 0.1157s/iter; left time: 9111.8886s
	iters: 1400, epoch: 3 | loss: 0.1089370
	speed: 0.1166s/iter; left time: 9170.4829s
	iters: 1500, epoch: 3 | loss: 0.0982486
	speed: 0.1153s/iter; left time: 9055.8982s
	iters: 1600, epoch: 3 | loss: 0.1116064
	speed: 0.1162s/iter; left time: 9112.0542s
	iters: 1700, epoch: 3 | loss: 0.1152646
	speed: 0.1147s/iter; left time: 8981.9711s
	iters: 1800, epoch: 3 | loss: 0.1033108
	speed: 0.1157s/iter; left time: 9047.4058s
	iters: 1900, epoch: 3 | loss: 0.1160483
	speed: 0.1145s/iter; left time: 8942.6018s
	iters: 2000, epoch: 3 | loss: 0.1133725
	speed: 0.1152s/iter; left time: 8988.5962s
	iters: 2100, epoch: 3 | loss: 0.0946887
	speed: 0.1162s/iter; left time: 9056.8138s
	iters: 2200, epoch: 3 | loss: 0.1068842
	speed: 0.1158s/iter; left time: 9008.9040s
	iters: 2300, epoch: 3 | loss: 0.1091909
	speed: 0.1141s/iter; left time: 8869.8343s
	iters: 2400, epoch: 3 | loss: 0.0988755
	speed: 0.1144s/iter; left time: 8880.5515s
	iters: 2500, epoch: 3 | loss: 0.0938124
	speed: 0.1152s/iter; left time: 8929.7448s
	iters: 2600, epoch: 3 | loss: 0.1091160
	speed: 0.1153s/iter; left time: 8929.1321s
	iters: 2700, epoch: 3 | loss: 0.1095193
	speed: 0.1152s/iter; left time: 8908.6028s
	iters: 2800, epoch: 3 | loss: 0.1060785
	speed: 0.1142s/iter; left time: 8823.2657s
	iters: 2900, epoch: 3 | loss: 0.0896944
	speed: 0.1151s/iter; left time: 8875.4527s
	iters: 3000, epoch: 3 | loss: 0.0934717
	speed: 0.1164s/iter; left time: 8969.1079s
	iters: 3100, epoch: 3 | loss: 0.1221983
	speed: 0.1152s/iter; left time: 8861.5937s
	iters: 3200, epoch: 3 | loss: 0.0963738
	speed: 0.1147s/iter; left time: 8815.4265s
	iters: 3300, epoch: 3 | loss: 0.1190489
	speed: 0.1161s/iter; left time: 8908.4538s
	iters: 3400, epoch: 3 | loss: 0.1036496
	speed: 0.1165s/iter; left time: 8928.5374s
	iters: 3500, epoch: 3 | loss: 0.1124387
	speed: 0.1168s/iter; left time: 8939.4267s
	iters: 3600, epoch: 3 | loss: 0.1170041
	speed: 0.1155s/iter; left time: 8827.6652s
	iters: 3700, epoch: 3 | loss: 0.1089111
	speed: 0.1159s/iter; left time: 8850.0768s
	iters: 3800, epoch: 3 | loss: 0.0951907
	speed: 0.1147s/iter; left time: 8746.3940s
	iters: 3900, epoch: 3 | loss: 0.0979321
	speed: 0.1144s/iter; left time: 8706.1174s
	iters: 4000, epoch: 3 | loss: 0.0999806
	speed: 0.1163s/iter; left time: 8842.1246s
	iters: 4100, epoch: 3 | loss: 0.0940368
	speed: 0.1148s/iter; left time: 8719.9476s
	iters: 4200, epoch: 3 | loss: 0.0999659
	speed: 0.1162s/iter; left time: 8810.3419s
	iters: 4300, epoch: 3 | loss: 0.0951753
	speed: 0.1153s/iter; left time: 8732.1293s
	iters: 4400, epoch: 3 | loss: 0.0947775
	speed: 0.1145s/iter; left time: 8662.4110s
Epoch: 3 cost time: 00h:08m:33.85s
Epoch: 3 | Train Loss: 0.1043304 Vali Loss: 0.1245715 Test Loss: 0.1501074
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0944092
	speed: 1.5497s/iter; left time: 116975.3279s
	iters: 200, epoch: 4 | loss: 0.0867483
	speed: 0.1149s/iter; left time: 8658.0705s
	iters: 300, epoch: 4 | loss: 0.1064334
	speed: 0.1155s/iter; left time: 8698.3918s
	iters: 400, epoch: 4 | loss: 0.0956620
	speed: 0.1158s/iter; left time: 8705.6986s
	iters: 500, epoch: 4 | loss: 0.1117885
	speed: 0.1166s/iter; left time: 8758.2921s
	iters: 600, epoch: 4 | loss: 0.1063067
	speed: 0.1150s/iter; left time: 8626.7746s
	iters: 700, epoch: 4 | loss: 0.0915639
	speed: 0.1156s/iter; left time: 8655.7974s
	iters: 800, epoch: 4 | loss: 0.1026455
	speed: 0.1153s/iter; left time: 8624.9928s
	iters: 900, epoch: 4 | loss: 0.1035407
	speed: 0.1159s/iter; left time: 8652.7572s
	iters: 1000, epoch: 4 | loss: 0.1075997
	speed: 0.1163s/iter; left time: 8675.9252s
	iters: 1100, epoch: 4 | loss: 0.0891981
	speed: 0.1140s/iter; left time: 8491.5195s
	iters: 1200, epoch: 4 | loss: 0.1041374
	speed: 0.1134s/iter; left time: 8438.0519s
	iters: 1300, epoch: 4 | loss: 0.1022310
	speed: 0.1133s/iter; left time: 8418.8444s
	iters: 1400, epoch: 4 | loss: 0.1072065
	speed: 0.1122s/iter; left time: 8324.7086s
	iters: 1500, epoch: 4 | loss: 0.0838472
	speed: 0.1134s/iter; left time: 8403.0457s
	iters: 1600, epoch: 4 | loss: 0.0923450
	speed: 0.1137s/iter; left time: 8410.4056s
	iters: 1700, epoch: 4 | loss: 0.1015804
	speed: 0.1152s/iter; left time: 8511.1904s
	iters: 1800, epoch: 4 | loss: 0.1218250
	speed: 0.1150s/iter; left time: 8486.1731s
	iters: 1900, epoch: 4 | loss: 0.1150391
	speed: 0.1155s/iter; left time: 8510.3849s
	iters: 2000, epoch: 4 | loss: 0.1164713
	speed: 0.1148s/iter; left time: 8449.4671s
	iters: 2100, epoch: 4 | loss: 0.1034276
	speed: 0.1131s/iter; left time: 8312.4625s
	iters: 2200, epoch: 4 | loss: 0.0898664
	speed: 0.1181s/iter; left time: 8665.1293s
	iters: 2300, epoch: 4 | loss: 0.0815171
	speed: 0.1187s/iter; left time: 8698.5061s
	iters: 2400, epoch: 4 | loss: 0.1059342
	speed: 0.1173s/iter; left time: 8586.7144s
	iters: 2500, epoch: 4 | loss: 0.1042058
	speed: 0.1165s/iter; left time: 8515.5548s
	iters: 2600, epoch: 4 | loss: 0.0878983
	speed: 0.1162s/iter; left time: 8481.3466s
	iters: 2700, epoch: 4 | loss: 0.0832504
	speed: 0.1187s/iter; left time: 8649.1016s
	iters: 2800, epoch: 4 | loss: 0.0833858
	speed: 0.1179s/iter; left time: 8580.0004s
	iters: 2900, epoch: 4 | loss: 0.1033833
	speed: 0.1149s/iter; left time: 8354.4193s
	iters: 3000, epoch: 4 | loss: 0.0952015
	speed: 0.1168s/iter; left time: 8477.1869s
	iters: 3100, epoch: 4 | loss: 0.0781978
	speed: 0.1149s/iter; left time: 8326.1763s
	iters: 3200, epoch: 4 | loss: 0.1017636
	speed: 0.1138s/iter; left time: 8238.4425s
	iters: 3300, epoch: 4 | loss: 0.1010068
	speed: 0.1156s/iter; left time: 8357.3458s
	iters: 3400, epoch: 4 | loss: 0.1017999
	speed: 0.1184s/iter; left time: 8548.1644s
	iters: 3500, epoch: 4 | loss: 0.0878085
	speed: 0.1168s/iter; left time: 8419.6193s
	iters: 3600, epoch: 4 | loss: 0.0985364
	speed: 0.1170s/iter; left time: 8422.9713s
	iters: 3700, epoch: 4 | loss: 0.0910970
	speed: 0.1139s/iter; left time: 8190.7131s
	iters: 3800, epoch: 4 | loss: 0.0913839
	speed: 0.1141s/iter; left time: 8192.0792s
	iters: 3900, epoch: 4 | loss: 0.0918390
	speed: 0.1143s/iter; left time: 8189.9435s
	iters: 4000, epoch: 4 | loss: 0.1008365
	speed: 0.1174s/iter; left time: 8401.5474s
	iters: 4100, epoch: 4 | loss: 0.0926459
	speed: 0.1177s/iter; left time: 8410.5593s
	iters: 4200, epoch: 4 | loss: 0.0991397
	speed: 0.1154s/iter; left time: 8239.6806s
	iters: 4300, epoch: 4 | loss: 0.0954166
	speed: 0.1142s/iter; left time: 8141.7228s
	iters: 4400, epoch: 4 | loss: 0.0878920
	speed: 0.1161s/iter; left time: 8266.2998s
Epoch: 4 cost time: 00h:08m:34.28s
Epoch: 4 | Train Loss: 0.0984264 Vali Loss: 0.1281532 Test Loss: 0.1525455
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.1027972
	speed: 1.5516s/iter; left time: 110220.2287s
	iters: 200, epoch: 5 | loss: 0.1047456
	speed: 0.1157s/iter; left time: 8208.4461s
	iters: 300, epoch: 5 | loss: 0.0907510
	speed: 0.1167s/iter; left time: 8265.7405s
	iters: 400, epoch: 5 | loss: 0.0943936
	speed: 0.1172s/iter; left time: 8292.2366s
	iters: 500, epoch: 5 | loss: 0.0821496
	speed: 0.1161s/iter; left time: 8200.0644s
	iters: 600, epoch: 5 | loss: 0.0936060
	speed: 0.1160s/iter; left time: 8185.4850s
	iters: 700, epoch: 5 | loss: 0.0996595
	speed: 0.1171s/iter; left time: 8250.5821s
	iters: 800, epoch: 5 | loss: 0.0979459
	speed: 0.1154s/iter; left time: 8119.3812s
	iters: 900, epoch: 5 | loss: 0.1001264
	speed: 0.1133s/iter; left time: 7958.2826s
	iters: 1000, epoch: 5 | loss: 0.1090219
	speed: 0.1141s/iter; left time: 8005.5584s
	iters: 1100, epoch: 5 | loss: 0.1011967
	speed: 0.1139s/iter; left time: 7978.4549s
	iters: 1200, epoch: 5 | loss: 0.0915010
	speed: 0.1158s/iter; left time: 8096.2294s
	iters: 1300, epoch: 5 | loss: 0.1061302
	speed: 0.1162s/iter; left time: 8116.5520s
	iters: 1400, epoch: 5 | loss: 0.1118270
	speed: 0.1164s/iter; left time: 8118.4551s
	iters: 1500, epoch: 5 | loss: 0.0901711
	speed: 0.1157s/iter; left time: 8055.1593s
	iters: 1600, epoch: 5 | loss: 0.0990031
	speed: 0.1164s/iter; left time: 8095.2933s
	iters: 1700, epoch: 5 | loss: 0.1073154
	speed: 0.1151s/iter; left time: 7990.1939s
	iters: 1800, epoch: 5 | loss: 0.0957215
	speed: 0.1146s/iter; left time: 7948.0382s
	iters: 1900, epoch: 5 | loss: 0.0969568
	speed: 0.1147s/iter; left time: 7938.2746s
	iters: 2000, epoch: 5 | loss: 0.1063399
	speed: 0.1152s/iter; left time: 7965.5585s
	iters: 2100, epoch: 5 | loss: 0.1092876
	speed: 0.1184s/iter; left time: 8170.8366s
	iters: 2200, epoch: 5 | loss: 0.0891375
	speed: 0.1147s/iter; left time: 7910.2817s
	iters: 2300, epoch: 5 | loss: 0.0779103
	speed: 0.1175s/iter; left time: 8087.8896s
	iters: 2400, epoch: 5 | loss: 0.0807228
	speed: 0.1168s/iter; left time: 8025.9800s
	iters: 2500, epoch: 5 | loss: 0.0742790
	speed: 0.1168s/iter; left time: 8016.6586s
	iters: 2600, epoch: 5 | loss: 0.0908970
	speed: 0.1147s/iter; left time: 7858.3526s
	iters: 2700, epoch: 5 | loss: 0.1129368
	speed: 0.1143s/iter; left time: 7820.8059s
	iters: 2800, epoch: 5 | loss: 0.0733277
	speed: 0.1184s/iter; left time: 8090.8699s
	iters: 2900, epoch: 5 | loss: 0.1080936
	speed: 0.1183s/iter; left time: 8070.8115s
	iters: 3000, epoch: 5 | loss: 0.0774377
	speed: 0.1167s/iter; left time: 7949.2214s
	iters: 3100, epoch: 5 | loss: 0.0847868
	speed: 0.1155s/iter; left time: 7861.0918s
	iters: 3200, epoch: 5 | loss: 0.0902236
	speed: 0.1149s/iter; left time: 7805.2258s
	iters: 3300, epoch: 5 | loss: 0.0947069
	speed: 0.1163s/iter; left time: 7886.0970s
	iters: 3400, epoch: 5 | loss: 0.0958610
	speed: 0.1161s/iter; left time: 7863.7970s
	iters: 3500, epoch: 5 | loss: 0.0908997
	speed: 0.1148s/iter; left time: 7767.2626s
	iters: 3600, epoch: 5 | loss: 0.0939663
	speed: 0.1141s/iter; left time: 7708.7375s
	iters: 3700, epoch: 5 | loss: 0.0827342
	speed: 0.1151s/iter; left time: 7761.5226s
	iters: 3800, epoch: 5 | loss: 0.1009660
	speed: 0.1139s/iter; left time: 7667.6180s
	iters: 3900, epoch: 5 | loss: 0.0889867
	speed: 0.1142s/iter; left time: 7681.4587s
	iters: 4000, epoch: 5 | loss: 0.0949150
	speed: 0.1134s/iter; left time: 7613.2535s
	iters: 4100, epoch: 5 | loss: 0.1014487
	speed: 0.1142s/iter; left time: 7656.9560s
	iters: 4200, epoch: 5 | loss: 0.0968869
	speed: 0.1153s/iter; left time: 7716.1146s
	iters: 4300, epoch: 5 | loss: 0.0901529
	speed: 0.1157s/iter; left time: 7732.6608s
	iters: 4400, epoch: 5 | loss: 0.0915154
	speed: 0.1180s/iter; left time: 7871.9444s
Epoch: 5 cost time: 00h:08m:34.78s
Epoch: 5 | Train Loss: 0.0934047 Vali Loss: 0.1274233 Test Loss: 0.1514446
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0924059
	speed: 1.5476s/iter; left time: 103055.2063s
	iters: 200, epoch: 6 | loss: 0.0953507
	speed: 0.1191s/iter; left time: 7915.8442s
	iters: 300, epoch: 6 | loss: 0.0743414
	speed: 0.1163s/iter; left time: 7718.9871s
	iters: 400, epoch: 6 | loss: 0.0888031
	speed: 0.1185s/iter; left time: 7852.1903s
	iters: 500, epoch: 6 | loss: 0.1043609
	speed: 0.1168s/iter; left time: 7733.2412s
	iters: 600, epoch: 6 | loss: 0.0847825
	speed: 0.1188s/iter; left time: 7854.5862s
	iters: 700, epoch: 6 | loss: 0.1001649
	speed: 0.1176s/iter; left time: 7758.1293s
	iters: 800, epoch: 6 | loss: 0.1008426
	speed: 0.1162s/iter; left time: 7657.0937s
	iters: 900, epoch: 6 | loss: 0.0914951
	speed: 0.1168s/iter; left time: 7683.7625s
	iters: 1000, epoch: 6 | loss: 0.0961552
	speed: 0.1188s/iter; left time: 7801.7333s
	iters: 1100, epoch: 6 | loss: 0.0863231
	speed: 0.1186s/iter; left time: 7781.1236s
	iters: 1200, epoch: 6 | loss: 0.0925186
	speed: 0.1202s/iter; left time: 7871.2631s
	iters: 1300, epoch: 6 | loss: 0.0857735
	speed: 0.1174s/iter; left time: 7675.7391s
	iters: 1400, epoch: 6 | loss: 0.0983386
	speed: 0.1202s/iter; left time: 7851.0174s
	iters: 1500, epoch: 6 | loss: 0.0876124
	speed: 0.1204s/iter; left time: 7846.9987s
	iters: 1600, epoch: 6 | loss: 0.0781590
	speed: 0.1156s/iter; left time: 7526.7923s
	iters: 1700, epoch: 6 | loss: 0.0933763
	speed: 0.1205s/iter; left time: 7832.0395s
	iters: 1800, epoch: 6 | loss: 0.0982791
	speed: 0.1149s/iter; left time: 7454.8488s
	iters: 1900, epoch: 6 | loss: 0.0728418
	speed: 0.1143s/iter; left time: 7402.4854s
	iters: 2000, epoch: 6 | loss: 0.0914764
	speed: 0.1159s/iter; left time: 7497.4194s
	iters: 2100, epoch: 6 | loss: 0.0815687
	speed: 0.1173s/iter; left time: 7575.4451s
	iters: 2200, epoch: 6 | loss: 0.0897236
	speed: 0.1172s/iter; left time: 7557.0015s
	iters: 2300, epoch: 6 | loss: 0.0844050
	speed: 0.1166s/iter; left time: 7508.0284s
	iters: 2400, epoch: 6 | loss: 0.0881767
	speed: 0.1161s/iter; left time: 7461.0308s
	iters: 2500, epoch: 6 | loss: 0.0834182
	speed: 0.1222s/iter; left time: 7841.6178s
	iters: 2600, epoch: 6 | loss: 0.0942059
	speed: 0.1146s/iter; left time: 7342.8139s
	iters: 2700, epoch: 6 | loss: 0.0970327
	speed: 0.1168s/iter; left time: 7472.0707s
	iters: 2800, epoch: 6 | loss: 0.0989593
	speed: 0.1172s/iter; left time: 7486.8818s
	iters: 2900, epoch: 6 | loss: 0.0968164
	speed: 0.1192s/iter; left time: 7603.9717s
	iters: 3000, epoch: 6 | loss: 0.0916561
	speed: 0.1167s/iter; left time: 7429.6563s
	iters: 3100, epoch: 6 | loss: 0.0938281
	speed: 0.1172s/iter; left time: 7455.4710s
	iters: 3200, epoch: 6 | loss: 0.0751842
	speed: 0.1199s/iter; left time: 7613.1808s
	iters: 3300, epoch: 6 | loss: 0.0846767
	speed: 0.1195s/iter; left time: 7572.9081s
	iters: 3400, epoch: 6 | loss: 0.0979014
	speed: 0.1223s/iter; left time: 7737.9127s
	iters: 3500, epoch: 6 | loss: 0.0967091
	speed: 0.1144s/iter; left time: 7230.6336s
	iters: 3600, epoch: 6 | loss: 0.0888710
	speed: 0.1178s/iter; left time: 7430.2501s
	iters: 3700, epoch: 6 | loss: 0.0812877
	speed: 0.1143s/iter; left time: 7198.5841s
	iters: 3800, epoch: 6 | loss: 0.0757051
	speed: 0.1140s/iter; left time: 7168.3648s
	iters: 3900, epoch: 6 | loss: 0.0898106
	speed: 0.1154s/iter; left time: 7244.5771s
	iters: 4000, epoch: 6 | loss: 0.1019688
	speed: 0.1157s/iter; left time: 7252.7306s
	iters: 4100, epoch: 6 | loss: 0.0886026
	speed: 0.1212s/iter; left time: 7585.3348s
	iters: 4200, epoch: 6 | loss: 0.0841476
	speed: 0.1170s/iter; left time: 7309.4672s
	iters: 4300, epoch: 6 | loss: 0.0868416
	speed: 0.1157s/iter; left time: 7217.7561s
	iters: 4400, epoch: 6 | loss: 0.0976313
	speed: 0.1141s/iter; left time: 7107.8399s
Epoch: 6 cost time: 00h:08m:42.56s
Epoch: 6 | Train Loss: 0.0896105 Vali Loss: 0.1277131 Test Loss: 0.1531950
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.04277150332927704, rmse:0.20681272447109222, mae:0.14383640885353088, rse:0.7167763113975525
success delete checkpoints
Intermediate time for GB and pred_len 168: 01h:08m:23.04s
Intermediate time for GB: 04h:19m:43.32s

=== Starting experiments for country: DE ===

=== Starting experiments for pred_len: 24 ===

--- Running model for ES, pred_len=24 ---
train 85803
val 18651
test 18651
[2024-11-12 16:19:27,434] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 16:19:28,412] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 16:19:28,412] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 16:19:28,412] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 16:19:28,522] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 16:19:28,523] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 16:19:29,170] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 16:19:29,171] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 16:19:29,171] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 16:19:29,172] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 16:19:29,172] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 16:19:29,173] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 16:19:29,173] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 16:19:29,173] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 16:19:29,173] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 16:19:29,173] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 16:19:29,363] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 16:19:29,363] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 16:19:29,418] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.32 GB, percent = 2.7%
[2024-11-12 16:19:29,524] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 16:19:29,525] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 16:19:29,525] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.26 GB, percent = 2.7%
[2024-11-12 16:19:29,525] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 16:19:29,621] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 16:19:29,621] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 16:19:29,621] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.25 GB, percent = 2.7%
[2024-11-12 16:19:29,622] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 16:19:29,622] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 16:19:29,622] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 16:19:29,622] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 16:19:29,622] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe7b603f5d0>
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 16:19:29,623] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 16:19:29,624] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 16:19:29,624] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0545830
	speed: 0.1616s/iter; left time: 4316.4985s
	iters: 200, epoch: 1 | loss: 0.0524177
	speed: 0.1232s/iter; left time: 3278.4706s
	iters: 300, epoch: 1 | loss: 0.0306460
	speed: 0.1237s/iter; left time: 3279.9896s
	iters: 400, epoch: 1 | loss: 0.0289302
	speed: 0.1242s/iter; left time: 3279.3330s
	iters: 500, epoch: 1 | loss: 0.0238862
	speed: 0.1232s/iter; left time: 3240.5742s
	iters: 600, epoch: 1 | loss: 0.0211351
	speed: 0.1234s/iter; left time: 3233.6568s
	iters: 700, epoch: 1 | loss: 0.0179487
	speed: 0.1237s/iter; left time: 3229.5367s
	iters: 800, epoch: 1 | loss: 0.0147842
	speed: 0.1240s/iter; left time: 3226.3185s
	iters: 900, epoch: 1 | loss: 0.0156694
	speed: 0.1240s/iter; left time: 3212.9988s
	iters: 1000, epoch: 1 | loss: 0.0168096
	speed: 0.1238s/iter; left time: 3194.1992s
	iters: 1100, epoch: 1 | loss: 0.0131386
	speed: 0.1237s/iter; left time: 3181.3627s
	iters: 1200, epoch: 1 | loss: 0.0158540
	speed: 0.1244s/iter; left time: 3185.2983s
	iters: 1300, epoch: 1 | loss: 0.0143935
	speed: 0.1211s/iter; left time: 3090.3891s
	iters: 1400, epoch: 1 | loss: 0.0187579
	speed: 0.1235s/iter; left time: 3138.2874s
	iters: 1500, epoch: 1 | loss: 0.0147546
	speed: 0.1238s/iter; left time: 3132.9402s
	iters: 1600, epoch: 1 | loss: 0.0141143
	speed: 0.1241s/iter; left time: 3129.5655s
	iters: 1700, epoch: 1 | loss: 0.0153522
	speed: 0.1245s/iter; left time: 3125.7567s
	iters: 1800, epoch: 1 | loss: 0.0165686
	speed: 0.1250s/iter; left time: 3126.7399s
	iters: 1900, epoch: 1 | loss: 0.0149150
	speed: 0.1245s/iter; left time: 3101.0133s
	iters: 2000, epoch: 1 | loss: 0.0139012
	speed: 0.1245s/iter; left time: 3090.1747s
	iters: 2100, epoch: 1 | loss: 0.0128072
	speed: 0.1247s/iter; left time: 3082.2526s
	iters: 2200, epoch: 1 | loss: 0.0128131
	speed: 0.1239s/iter; left time: 3048.5152s
	iters: 2300, epoch: 1 | loss: 0.0175276
	speed: 0.1258s/iter; left time: 3083.1036s
	iters: 2400, epoch: 1 | loss: 0.0129875
	speed: 0.1243s/iter; left time: 3033.6402s
	iters: 2500, epoch: 1 | loss: 0.0118990
	speed: 0.1239s/iter; left time: 3011.8072s
	iters: 2600, epoch: 1 | loss: 0.0176947
	speed: 0.1242s/iter; left time: 3006.3918s
Epoch: 1 cost time: 00h:05m:33.61s
Epoch: 1 | Train Loss: 0.0226912 Vali Loss: 0.0103871 Test Loss: 0.0140691
Validation loss decreased (inf --> 0.010387).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0205152
	speed: 0.9334s/iter; left time: 22428.4132s
	iters: 200, epoch: 2 | loss: 0.0203009
	speed: 0.1180s/iter; left time: 2822.7882s
	iters: 300, epoch: 2 | loss: 0.0151824
	speed: 0.1194s/iter; left time: 2844.4418s
	iters: 400, epoch: 2 | loss: 0.0177140
	speed: 0.1194s/iter; left time: 2833.8397s
	iters: 500, epoch: 2 | loss: 0.0142296
	speed: 0.1198s/iter; left time: 2831.6257s
	iters: 600, epoch: 2 | loss: 0.0179271
	speed: 0.1185s/iter; left time: 2787.2891s
	iters: 700, epoch: 2 | loss: 0.0098558
	speed: 0.1194s/iter; left time: 2797.3130s
	iters: 800, epoch: 2 | loss: 0.0136821
	speed: 0.1187s/iter; left time: 2768.5765s
	iters: 900, epoch: 2 | loss: 0.0110614
	speed: 0.1186s/iter; left time: 2754.2433s
	iters: 1000, epoch: 2 | loss: 0.0143228
	speed: 0.1180s/iter; left time: 2728.7448s
	iters: 1100, epoch: 2 | loss: 0.0152571
	speed: 0.1185s/iter; left time: 2729.2009s
	iters: 1200, epoch: 2 | loss: 0.0116525
	speed: 0.1195s/iter; left time: 2740.9362s
	iters: 1300, epoch: 2 | loss: 0.0108315
	speed: 0.1184s/iter; left time: 2701.9565s
	iters: 1400, epoch: 2 | loss: 0.0112984
	speed: 0.1185s/iter; left time: 2693.8155s
	iters: 1500, epoch: 2 | loss: 0.0174003
	speed: 0.1196s/iter; left time: 2705.4401s
	iters: 1600, epoch: 2 | loss: 0.0209794
	speed: 0.1186s/iter; left time: 2672.1285s
	iters: 1700, epoch: 2 | loss: 0.0115302
	speed: 0.1200s/iter; left time: 2691.9011s
	iters: 1800, epoch: 2 | loss: 0.0119710
	speed: 0.1207s/iter; left time: 2695.6083s
	iters: 1900, epoch: 2 | loss: 0.0138560
	speed: 0.1207s/iter; left time: 2683.0841s
	iters: 2000, epoch: 2 | loss: 0.0142983
	speed: 0.1191s/iter; left time: 2635.8028s
	iters: 2100, epoch: 2 | loss: 0.0135131
	speed: 0.1185s/iter; left time: 2611.5795s
	iters: 2200, epoch: 2 | loss: 0.0116738
	speed: 0.1200s/iter; left time: 2631.2689s
	iters: 2300, epoch: 2 | loss: 0.0148960
	speed: 0.1192s/iter; left time: 2602.9964s
	iters: 2400, epoch: 2 | loss: 0.0159042
	speed: 0.1190s/iter; left time: 2586.8703s
	iters: 2500, epoch: 2 | loss: 0.0098822
	speed: 0.1203s/iter; left time: 2602.9451s
	iters: 2600, epoch: 2 | loss: 0.0133203
	speed: 0.1186s/iter; left time: 2553.7292s
Epoch: 2 cost time: 00h:05m:19.87s
Epoch: 2 | Train Loss: 0.0138356 Vali Loss: 0.0099448 Test Loss: 0.0131996
Validation loss decreased (0.010387 --> 0.009945).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0100902
	speed: 0.8714s/iter; left time: 18602.5200s
	iters: 200, epoch: 3 | loss: 0.0134872
	speed: 0.1178s/iter; left time: 2503.1782s
	iters: 300, epoch: 3 | loss: 0.0159289
	speed: 0.1215s/iter; left time: 2569.2366s
	iters: 400, epoch: 3 | loss: 0.0137253
	speed: 0.1197s/iter; left time: 2518.6229s
	iters: 500, epoch: 3 | loss: 0.0111006
	speed: 0.1183s/iter; left time: 2478.4422s
	iters: 600, epoch: 3 | loss: 0.0095436
	speed: 0.1189s/iter; left time: 2478.1832s
	iters: 700, epoch: 3 | loss: 0.0130041
	speed: 0.1192s/iter; left time: 2473.2162s
	iters: 800, epoch: 3 | loss: 0.0167347
	speed: 0.1195s/iter; left time: 2467.7931s
	iters: 900, epoch: 3 | loss: 0.0127512
	speed: 0.1207s/iter; left time: 2480.1491s
	iters: 1000, epoch: 3 | loss: 0.0110394
	speed: 0.1176s/iter; left time: 2404.8211s
	iters: 1100, epoch: 3 | loss: 0.0102398
	speed: 0.1174s/iter; left time: 2388.9892s
	iters: 1200, epoch: 3 | loss: 0.0169201
	speed: 0.1182s/iter; left time: 2393.7030s
	iters: 1300, epoch: 3 | loss: 0.0113823
	speed: 0.1199s/iter; left time: 2414.9841s
	iters: 1400, epoch: 3 | loss: 0.0151350
	speed: 0.1201s/iter; left time: 2407.8636s
	iters: 1500, epoch: 3 | loss: 0.0148839
	speed: 0.1183s/iter; left time: 2360.5041s
	iters: 1600, epoch: 3 | loss: 0.0100247
	speed: 0.1191s/iter; left time: 2363.1162s
	iters: 1700, epoch: 3 | loss: 0.0106432
	speed: 0.1207s/iter; left time: 2383.9432s
	iters: 1800, epoch: 3 | loss: 0.0109489
	speed: 0.1213s/iter; left time: 2384.1478s
	iters: 1900, epoch: 3 | loss: 0.0138631
	speed: 0.1197s/iter; left time: 2339.2285s
	iters: 2000, epoch: 3 | loss: 0.0116591
	speed: 0.1189s/iter; left time: 2312.7173s
	iters: 2100, epoch: 3 | loss: 0.0118185
	speed: 0.1200s/iter; left time: 2321.3218s
	iters: 2200, epoch: 3 | loss: 0.0165041
	speed: 0.1208s/iter; left time: 2325.9834s
	iters: 2300, epoch: 3 | loss: 0.0137983
	speed: 0.1202s/iter; left time: 2301.7010s
	iters: 2400, epoch: 3 | loss: 0.0186460
	speed: 0.1199s/iter; left time: 2284.8347s
	iters: 2500, epoch: 3 | loss: 0.0103766
	speed: 0.1189s/iter; left time: 2253.6668s
	iters: 2600, epoch: 3 | loss: 0.0119668
	speed: 0.1196s/iter; left time: 2254.0494s
Epoch: 3 cost time: 00h:05m:20.84s
Epoch: 3 | Train Loss: 0.0130627 Vali Loss: 0.0089921 Test Loss: 0.0120798
Validation loss decreased (0.009945 --> 0.008992).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0146747
	speed: 0.8691s/iter; left time: 16224.4939s
	iters: 200, epoch: 4 | loss: 0.0153105
	speed: 0.1188s/iter; left time: 2206.7334s
	iters: 300, epoch: 4 | loss: 0.0100770
	speed: 0.1202s/iter; left time: 2219.4635s
	iters: 400, epoch: 4 | loss: 0.0178037
	speed: 0.1186s/iter; left time: 2177.8376s
	iters: 500, epoch: 4 | loss: 0.0127377
	speed: 0.1198s/iter; left time: 2188.6028s
	iters: 600, epoch: 4 | loss: 0.0111179
	speed: 0.1191s/iter; left time: 2164.0672s
	iters: 700, epoch: 4 | loss: 0.0087008
	speed: 0.1185s/iter; left time: 2140.8619s
	iters: 800, epoch: 4 | loss: 0.0141666
	speed: 0.1192s/iter; left time: 2141.9142s
	iters: 900, epoch: 4 | loss: 0.0116692
	speed: 0.1202s/iter; left time: 2148.1007s
	iters: 1000, epoch: 4 | loss: 0.0144764
	speed: 0.1201s/iter; left time: 2133.4238s
	iters: 1100, epoch: 4 | loss: 0.0140510
	speed: 0.1189s/iter; left time: 2101.1521s
	iters: 1200, epoch: 4 | loss: 0.0130727
	speed: 0.1191s/iter; left time: 2091.9280s
	iters: 1300, epoch: 4 | loss: 0.0121976
	speed: 0.1191s/iter; left time: 2081.0868s
	iters: 1400, epoch: 4 | loss: 0.0091759
	speed: 0.1200s/iter; left time: 2084.0963s
	iters: 1500, epoch: 4 | loss: 0.0110257
	speed: 0.1194s/iter; left time: 2061.7547s
	iters: 1600, epoch: 4 | loss: 0.0118888
	speed: 0.1182s/iter; left time: 2029.2229s
	iters: 1700, epoch: 4 | loss: 0.0131193
	speed: 0.1190s/iter; left time: 2031.2273s
	iters: 1800, epoch: 4 | loss: 0.0137166
	speed: 0.1203s/iter; left time: 2041.1375s
	iters: 1900, epoch: 4 | loss: 0.0155586
	speed: 0.1201s/iter; left time: 2025.3767s
	iters: 2000, epoch: 4 | loss: 0.0153784
	speed: 0.1197s/iter; left time: 2007.7582s
	iters: 2100, epoch: 4 | loss: 0.0150797
	speed: 0.1200s/iter; left time: 2000.0128s
	iters: 2200, epoch: 4 | loss: 0.0131411
	speed: 0.1195s/iter; left time: 1980.1827s
	iters: 2300, epoch: 4 | loss: 0.0105560
	speed: 0.1201s/iter; left time: 1977.0541s
	iters: 2400, epoch: 4 | loss: 0.0119651
	speed: 0.1192s/iter; left time: 1950.2923s
	iters: 2500, epoch: 4 | loss: 0.0126801
	speed: 0.1185s/iter; left time: 1927.4271s
	iters: 2600, epoch: 4 | loss: 0.0122480
	speed: 0.1191s/iter; left time: 1925.6175s
Epoch: 4 cost time: 00h:05m:20.61s
Epoch: 4 | Train Loss: 0.0124224 Vali Loss: 0.0087640 Test Loss: 0.0116099
Validation loss decreased (0.008992 --> 0.008764).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0099333
	speed: 0.8647s/iter; left time: 13824.3762s
	iters: 200, epoch: 5 | loss: 0.0109573
	speed: 0.1192s/iter; left time: 1894.3610s
	iters: 300, epoch: 5 | loss: 0.0131027
	speed: 0.1193s/iter; left time: 1883.3690s
	iters: 400, epoch: 5 | loss: 0.0098820
	speed: 0.1195s/iter; left time: 1875.2156s
	iters: 500, epoch: 5 | loss: 0.0135142
	speed: 0.1190s/iter; left time: 1855.3954s
	iters: 600, epoch: 5 | loss: 0.0152880
	speed: 0.1203s/iter; left time: 1862.5248s
	iters: 700, epoch: 5 | loss: 0.0121359
	speed: 0.1199s/iter; left time: 1844.6621s
	iters: 800, epoch: 5 | loss: 0.0106622
	speed: 0.1188s/iter; left time: 1816.8354s
	iters: 900, epoch: 5 | loss: 0.0117534
	speed: 0.1199s/iter; left time: 1820.8394s
	iters: 1000, epoch: 5 | loss: 0.0137955
	speed: 0.1187s/iter; left time: 1790.6354s
	iters: 1100, epoch: 5 | loss: 0.0135695
	speed: 0.1196s/iter; left time: 1792.3449s
	iters: 1200, epoch: 5 | loss: 0.0122368
	speed: 0.1197s/iter; left time: 1782.2673s
	iters: 1300, epoch: 5 | loss: 0.0120961
	speed: 0.1193s/iter; left time: 1764.2227s
	iters: 1400, epoch: 5 | loss: 0.0096146
	speed: 0.1188s/iter; left time: 1745.4933s
	iters: 1500, epoch: 5 | loss: 0.0135736
	speed: 0.1191s/iter; left time: 1737.0268s
	iters: 1600, epoch: 5 | loss: 0.0118207
	speed: 0.1184s/iter; left time: 1715.6756s
	iters: 1700, epoch: 5 | loss: 0.0116144
	speed: 0.1197s/iter; left time: 1721.9163s
	iters: 1800, epoch: 5 | loss: 0.0153641
	speed: 0.1188s/iter; left time: 1696.6883s
	iters: 1900, epoch: 5 | loss: 0.0104821
	speed: 0.1190s/iter; left time: 1688.7215s
	iters: 2000, epoch: 5 | loss: 0.0124981
	speed: 0.1192s/iter; left time: 1679.7131s
	iters: 2100, epoch: 5 | loss: 0.0090783
	speed: 0.1197s/iter; left time: 1673.7470s
	iters: 2200, epoch: 5 | loss: 0.0103755
	speed: 0.1202s/iter; left time: 1669.6869s
	iters: 2300, epoch: 5 | loss: 0.0143221
	speed: 0.1204s/iter; left time: 1659.9116s
	iters: 2400, epoch: 5 | loss: 0.0115179
	speed: 0.1222s/iter; left time: 1672.7690s
	iters: 2500, epoch: 5 | loss: 0.0138639
	speed: 0.1200s/iter; left time: 1630.4015s
	iters: 2600, epoch: 5 | loss: 0.0118041
	speed: 0.1175s/iter; left time: 1584.5738s
Epoch: 5 cost time: 00h:05m:20.51s
Epoch: 5 | Train Loss: 0.0120566 Vali Loss: 0.0087508 Test Loss: 0.0116617
Validation loss decreased (0.008764 --> 0.008751).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0077944
	speed: 0.8574s/iter; left time: 11408.9212s
	iters: 200, epoch: 6 | loss: 0.0136503
	speed: 0.1180s/iter; left time: 1558.2167s
	iters: 300, epoch: 6 | loss: 0.0145998
	speed: 0.1186s/iter; left time: 1553.7207s
	iters: 400, epoch: 6 | loss: 0.0109427
	speed: 0.1190s/iter; left time: 1547.7695s
	iters: 500, epoch: 6 | loss: 0.0103924
	speed: 0.1187s/iter; left time: 1531.4102s
	iters: 600, epoch: 6 | loss: 0.0118544
	speed: 0.1177s/iter; left time: 1507.7028s
	iters: 700, epoch: 6 | loss: 0.0072835
	speed: 0.1183s/iter; left time: 1503.3968s
	iters: 800, epoch: 6 | loss: 0.0094917
	speed: 0.1174s/iter; left time: 1479.7004s
	iters: 900, epoch: 6 | loss: 0.0155689
	speed: 0.1187s/iter; left time: 1484.6866s
	iters: 1000, epoch: 6 | loss: 0.0105897
	speed: 0.1183s/iter; left time: 1467.0329s
	iters: 1100, epoch: 6 | loss: 0.0129377
	speed: 0.1170s/iter; left time: 1440.1100s
	iters: 1200, epoch: 6 | loss: 0.0119803
	speed: 0.1185s/iter; left time: 1446.5803s
	iters: 1300, epoch: 6 | loss: 0.0124778
	speed: 0.1186s/iter; left time: 1435.4083s
	iters: 1400, epoch: 6 | loss: 0.0118653
	speed: 0.1192s/iter; left time: 1431.6987s
	iters: 1500, epoch: 6 | loss: 0.0136589
	speed: 0.1194s/iter; left time: 1422.1186s
	iters: 1600, epoch: 6 | loss: 0.0110335
	speed: 0.1197s/iter; left time: 1413.4791s
	iters: 1700, epoch: 6 | loss: 0.0109264
	speed: 0.1189s/iter; left time: 1391.8562s
	iters: 1800, epoch: 6 | loss: 0.0141481
	speed: 0.1187s/iter; left time: 1377.0768s
	iters: 1900, epoch: 6 | loss: 0.0107703
	speed: 0.1184s/iter; left time: 1362.3616s
	iters: 2000, epoch: 6 | loss: 0.0117767
	speed: 0.1186s/iter; left time: 1352.3381s
	iters: 2100, epoch: 6 | loss: 0.0127800
	speed: 0.1186s/iter; left time: 1340.7195s
	iters: 2200, epoch: 6 | loss: 0.0089541
	speed: 0.1188s/iter; left time: 1331.0873s
	iters: 2300, epoch: 6 | loss: 0.0124707
	speed: 0.1186s/iter; left time: 1316.7185s
	iters: 2400, epoch: 6 | loss: 0.0082773
	speed: 0.1187s/iter; left time: 1306.8215s
	iters: 2500, epoch: 6 | loss: 0.0091436
	speed: 0.1200s/iter; left time: 1308.1771s
	iters: 2600, epoch: 6 | loss: 0.0112877
	speed: 0.1187s/iter; left time: 1282.6506s
Epoch: 6 cost time: 00h:05m:18.32s
Epoch: 6 | Train Loss: 0.0117904 Vali Loss: 0.0084753 Test Loss: 0.0111235
Validation loss decreased (0.008751 --> 0.008475).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0109215
	speed: 0.8517s/iter; left time: 9049.4171s
	iters: 200, epoch: 7 | loss: 0.0126030
	speed: 0.1179s/iter; left time: 1240.5187s
	iters: 300, epoch: 7 | loss: 0.0113944
	speed: 0.1178s/iter; left time: 1228.3050s
	iters: 400, epoch: 7 | loss: 0.0095302
	speed: 0.1181s/iter; left time: 1218.9817s
	iters: 500, epoch: 7 | loss: 0.0166103
	speed: 0.1179s/iter; left time: 1205.5783s
	iters: 600, epoch: 7 | loss: 0.0112385
	speed: 0.1188s/iter; left time: 1202.5796s
	iters: 700, epoch: 7 | loss: 0.0177693
	speed: 0.1179s/iter; left time: 1182.0126s
	iters: 800, epoch: 7 | loss: 0.0132485
	speed: 0.1179s/iter; left time: 1169.6666s
	iters: 900, epoch: 7 | loss: 0.0122021
	speed: 0.1177s/iter; left time: 1156.1017s
	iters: 1000, epoch: 7 | loss: 0.0141721
	speed: 0.1177s/iter; left time: 1144.3241s
	iters: 1100, epoch: 7 | loss: 0.0123870
	speed: 0.1172s/iter; left time: 1127.7412s
	iters: 1200, epoch: 7 | loss: 0.0111623
	speed: 0.1180s/iter; left time: 1123.6591s
	iters: 1300, epoch: 7 | loss: 0.0121417
	speed: 0.1178s/iter; left time: 1110.3975s
	iters: 1400, epoch: 7 | loss: 0.0126506
	speed: 0.1180s/iter; left time: 1100.0527s
	iters: 1500, epoch: 7 | loss: 0.0120803
	speed: 0.1178s/iter; left time: 1086.3105s
	iters: 1600, epoch: 7 | loss: 0.0116117
	speed: 0.1178s/iter; left time: 1074.9168s
	iters: 1700, epoch: 7 | loss: 0.0117655
	speed: 0.1178s/iter; left time: 1062.8966s
	iters: 1800, epoch: 7 | loss: 0.0078291
	speed: 0.1177s/iter; left time: 1050.0442s
	iters: 1900, epoch: 7 | loss: 0.0121750
	speed: 0.1177s/iter; left time: 1039.1318s
	iters: 2000, epoch: 7 | loss: 0.0129528
	speed: 0.1175s/iter; left time: 1025.2399s
	iters: 2100, epoch: 7 | loss: 0.0115843
	speed: 0.1174s/iter; left time: 1012.5316s
	iters: 2200, epoch: 7 | loss: 0.0159705
	speed: 0.1188s/iter; left time: 1012.4937s
	iters: 2300, epoch: 7 | loss: 0.0142493
	speed: 0.1189s/iter; left time: 1001.5653s
	iters: 2400, epoch: 7 | loss: 0.0106964
	speed: 0.1186s/iter; left time: 987.5312s
	iters: 2500, epoch: 7 | loss: 0.0094670
	speed: 0.1179s/iter; left time: 970.0979s
	iters: 2600, epoch: 7 | loss: 0.0131341
	speed: 0.1174s/iter; left time: 953.4874s
Epoch: 7 cost time: 00h:05m:16.45s
Epoch: 7 | Train Loss: 0.0115988 Vali Loss: 0.0084970 Test Loss: 0.0114120
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0191265
	speed: 0.8158s/iter; left time: 6481.0678s
	iters: 200, epoch: 8 | loss: 0.0117542
	speed: 0.1178s/iter; left time: 924.1769s
	iters: 300, epoch: 8 | loss: 0.0118873
	speed: 0.1177s/iter; left time: 911.5064s
	iters: 400, epoch: 8 | loss: 0.0084380
	speed: 0.1180s/iter; left time: 902.3018s
	iters: 500, epoch: 8 | loss: 0.0124220
	speed: 0.1179s/iter; left time: 889.0856s
	iters: 600, epoch: 8 | loss: 0.0109508
	speed: 0.1177s/iter; left time: 875.9866s
	iters: 700, epoch: 8 | loss: 0.0078423
	speed: 0.1179s/iter; left time: 865.8108s
	iters: 800, epoch: 8 | loss: 0.0108486
	speed: 0.1196s/iter; left time: 866.1193s
	iters: 900, epoch: 8 | loss: 0.0082394
	speed: 0.1193s/iter; left time: 852.4319s
	iters: 1000, epoch: 8 | loss: 0.0138884
	speed: 0.1182s/iter; left time: 832.4729s
	iters: 1100, epoch: 8 | loss: 0.0106513
	speed: 0.1182s/iter; left time: 820.9609s
	iters: 1200, epoch: 8 | loss: 0.0116432
	speed: 0.1186s/iter; left time: 811.7206s
	iters: 1300, epoch: 8 | loss: 0.0080303
	speed: 0.1179s/iter; left time: 794.9923s
	iters: 1400, epoch: 8 | loss: 0.0084128
	speed: 0.1180s/iter; left time: 784.3168s
	iters: 1500, epoch: 8 | loss: 0.0101146
	speed: 0.1180s/iter; left time: 772.0312s
	iters: 1600, epoch: 8 | loss: 0.0125243
	speed: 0.1181s/iter; left time: 760.8584s
	iters: 1700, epoch: 8 | loss: 0.0074849
	speed: 0.1188s/iter; left time: 753.7009s
	iters: 1800, epoch: 8 | loss: 0.0094907
	speed: 0.1190s/iter; left time: 743.0184s
	iters: 1900, epoch: 8 | loss: 0.0126217
	speed: 0.1197s/iter; left time: 735.3316s
	iters: 2000, epoch: 8 | loss: 0.0133219
	speed: 0.1178s/iter; left time: 712.1529s
	iters: 2100, epoch: 8 | loss: 0.0104638
	speed: 0.1187s/iter; left time: 705.5664s
	iters: 2200, epoch: 8 | loss: 0.0088677
	speed: 0.1181s/iter; left time: 690.0636s
	iters: 2300, epoch: 8 | loss: 0.0109687
	speed: 0.1188s/iter; left time: 682.2640s
	iters: 2400, epoch: 8 | loss: 0.0094333
	speed: 0.1168s/iter; left time: 659.4962s
	iters: 2500, epoch: 8 | loss: 0.0135891
	speed: 0.1184s/iter; left time: 656.3103s
	iters: 2600, epoch: 8 | loss: 0.0104805
	speed: 0.1186s/iter; left time: 645.6796s
Epoch: 8 cost time: 00h:05m:17.52s
Epoch: 8 | Train Loss: 0.0114108 Vali Loss: 0.0085304 Test Loss: 0.0112045
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0129170
	speed: 0.8173s/iter; left time: 4301.3760s
	iters: 200, epoch: 9 | loss: 0.0134936
	speed: 0.1179s/iter; left time: 608.6839s
	iters: 300, epoch: 9 | loss: 0.0096854
	speed: 0.1186s/iter; left time: 600.3740s
	iters: 400, epoch: 9 | loss: 0.0109904
	speed: 0.1180s/iter; left time: 585.8107s
	iters: 500, epoch: 9 | loss: 0.0082483
	speed: 0.1177s/iter; left time: 572.3777s
	iters: 600, epoch: 9 | loss: 0.0090961
	speed: 0.1168s/iter; left time: 556.4075s
	iters: 700, epoch: 9 | loss: 0.0129327
	speed: 0.1188s/iter; left time: 553.8567s
	iters: 800, epoch: 9 | loss: 0.0103495
	speed: 0.1184s/iter; left time: 540.3189s
	iters: 900, epoch: 9 | loss: 0.0121629
	speed: 0.1188s/iter; left time: 530.2714s
	iters: 1000, epoch: 9 | loss: 0.0082204
	speed: 0.1172s/iter; left time: 511.5463s
	iters: 1100, epoch: 9 | loss: 0.0094257
	speed: 0.1178s/iter; left time: 502.3288s
	iters: 1200, epoch: 9 | loss: 0.0132612
	speed: 0.1190s/iter; left time: 495.5718s
	iters: 1300, epoch: 9 | loss: 0.0077047
	speed: 0.1183s/iter; left time: 480.7140s
	iters: 1400, epoch: 9 | loss: 0.0120918
	speed: 0.1178s/iter; left time: 466.6769s
	iters: 1500, epoch: 9 | loss: 0.0130780
	speed: 0.1193s/iter; left time: 461.0019s
	iters: 1600, epoch: 9 | loss: 0.0103472
	speed: 0.1176s/iter; left time: 442.3447s
	iters: 1700, epoch: 9 | loss: 0.0085749
	speed: 0.1197s/iter; left time: 438.4042s
	iters: 1800, epoch: 9 | loss: 0.0122015
	speed: 0.1189s/iter; left time: 423.7798s
	iters: 1900, epoch: 9 | loss: 0.0145958
	speed: 0.1184s/iter; left time: 409.9510s
	iters: 2000, epoch: 9 | loss: 0.0118772
	speed: 0.1184s/iter; left time: 398.2628s
	iters: 2100, epoch: 9 | loss: 0.0115369
	speed: 0.1193s/iter; left time: 389.4227s
	iters: 2200, epoch: 9 | loss: 0.0083781
	speed: 0.1200s/iter; left time: 379.5846s
	iters: 2300, epoch: 9 | loss: 0.0116395
	speed: 0.1194s/iter; left time: 365.8267s
	iters: 2400, epoch: 9 | loss: 0.0096427
	speed: 0.1185s/iter; left time: 351.1815s
	iters: 2500, epoch: 9 | loss: 0.0095673
	speed: 0.1182s/iter; left time: 338.2745s
	iters: 2600, epoch: 9 | loss: 0.0096083
	speed: 0.1192s/iter; left time: 329.3200s
Epoch: 9 cost time: 00h:05m:17.76s
Epoch: 9 | Train Loss: 0.0113057 Vali Loss: 0.0088317 Test Loss: 0.0119234
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.011123491451144218, rmse:0.10546796768903732, mae:0.06871083378791809, rse:0.3096562623977661
Intermediate time for ES and pred_len 24: 00h:58m:26.67s

=== Starting experiments for pred_len: 96 ===

--- Running model for ES, pred_len=96 ---
train 85587
val 18435
test 18435
[2024-11-12 17:17:54,907] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:17:56,300] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 17:17:56,300] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 17:17:56,300] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 17:17:56,431] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 17:17:56,431] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 17:17:57,276] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 17:17:57,277] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 17:17:57,278] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 17:17:57,279] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 17:17:57,279] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 17:17:57,279] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 17:17:57,279] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 17:17:57,279] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 17:17:57,279] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 17:17:57,279] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 17:17:57,499] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 17:17:57,499] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 17:17:57,522] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.27 GB, percent = 2.7%
[2024-11-12 17:17:57,603] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 17:17:57,603] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 17:17:57,603] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.27 GB, percent = 2.7%
[2024-11-12 17:17:57,603] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 17:17:57,678] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 17:17:57,679] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 17:17:57,679] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.27 GB, percent = 2.7%
[2024-11-12 17:17:57,680] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 17:17:57,680] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 17:17:57,680] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 17:17:57,680] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 17:17:57,680] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 17:17:57,680] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 17:17:57,680] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 17:17:57,680] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 17:17:57,680] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fccc62b0c90>
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 17:17:57,681] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 17:17:57,682] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 17:17:57,682] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0562205
	speed: 0.1666s/iter; left time: 4437.9411s
	iters: 200, epoch: 1 | loss: 0.0615411
	speed: 0.1229s/iter; left time: 3262.7771s
	iters: 300, epoch: 1 | loss: 0.0496566
	speed: 0.1230s/iter; left time: 3252.0225s
	iters: 400, epoch: 1 | loss: 0.0480501
	speed: 0.1231s/iter; left time: 3243.3070s
	iters: 500, epoch: 1 | loss: 0.0273459
	speed: 0.1232s/iter; left time: 3232.6316s
	iters: 600, epoch: 1 | loss: 0.0255595
	speed: 0.1236s/iter; left time: 3230.3057s
	iters: 700, epoch: 1 | loss: 0.0255974
	speed: 0.1234s/iter; left time: 3212.6665s
	iters: 800, epoch: 1 | loss: 0.0210241
	speed: 0.1235s/iter; left time: 3204.0184s
	iters: 900, epoch: 1 | loss: 0.0281095
	speed: 0.1237s/iter; left time: 3197.2116s
	iters: 1000, epoch: 1 | loss: 0.0249985
	speed: 0.1241s/iter; left time: 3195.6060s
	iters: 1100, epoch: 1 | loss: 0.0248241
	speed: 0.1230s/iter; left time: 3154.4955s
	iters: 1200, epoch: 1 | loss: 0.0176695
	speed: 0.1204s/iter; left time: 3074.8345s
	iters: 1300, epoch: 1 | loss: 0.0228380
	speed: 0.1235s/iter; left time: 3141.3046s
	iters: 1400, epoch: 1 | loss: 0.0220132
	speed: 0.1236s/iter; left time: 3130.9032s
	iters: 1500, epoch: 1 | loss: 0.0217820
	speed: 0.1236s/iter; left time: 3118.7233s
	iters: 1600, epoch: 1 | loss: 0.0208520
	speed: 0.1243s/iter; left time: 3126.2422s
	iters: 1700, epoch: 1 | loss: 0.0255393
	speed: 0.1242s/iter; left time: 3110.1159s
	iters: 1800, epoch: 1 | loss: 0.0229215
	speed: 0.1254s/iter; left time: 3126.4015s
	iters: 1900, epoch: 1 | loss: 0.0277365
	speed: 0.1250s/iter; left time: 3105.4852s
	iters: 2000, epoch: 1 | loss: 0.0169817
	speed: 0.1252s/iter; left time: 3096.6532s
	iters: 2100, epoch: 1 | loss: 0.0212673
	speed: 0.1228s/iter; left time: 3026.1554s
	iters: 2200, epoch: 1 | loss: 0.0152157
	speed: 0.1225s/iter; left time: 3006.5885s
	iters: 2300, epoch: 1 | loss: 0.0253563
	speed: 0.1235s/iter; left time: 3017.8597s
	iters: 2400, epoch: 1 | loss: 0.0144782
	speed: 0.1234s/iter; left time: 3002.8863s
	iters: 2500, epoch: 1 | loss: 0.0202419
	speed: 0.1230s/iter; left time: 2980.8270s
	iters: 2600, epoch: 1 | loss: 0.0236767
	speed: 0.1239s/iter; left time: 2992.2338s
Epoch: 1 cost time: 00h:05m:31.31s
Epoch: 1 | Train Loss: 0.0279895 Vali Loss: 0.0162857 Test Loss: 0.0221774
Validation loss decreased (inf --> 0.016286).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0233489
	speed: 0.8849s/iter; left time: 21208.0040s
	iters: 200, epoch: 2 | loss: 0.0238727
	speed: 0.1186s/iter; left time: 2830.0055s
	iters: 300, epoch: 2 | loss: 0.0188106
	speed: 0.1183s/iter; left time: 2811.9231s
	iters: 400, epoch: 2 | loss: 0.0178056
	speed: 0.1168s/iter; left time: 2764.2094s
	iters: 500, epoch: 2 | loss: 0.0179673
	speed: 0.1170s/iter; left time: 2756.7140s
	iters: 600, epoch: 2 | loss: 0.0194389
	speed: 0.1180s/iter; left time: 2769.8411s
	iters: 700, epoch: 2 | loss: 0.0172730
	speed: 0.1180s/iter; left time: 2758.2273s
	iters: 800, epoch: 2 | loss: 0.0206717
	speed: 0.1175s/iter; left time: 2733.9353s
	iters: 900, epoch: 2 | loss: 0.0163230
	speed: 0.1184s/iter; left time: 2743.9020s
	iters: 1000, epoch: 2 | loss: 0.0172873
	speed: 0.1188s/iter; left time: 2741.0415s
	iters: 1100, epoch: 2 | loss: 0.0158728
	speed: 0.1191s/iter; left time: 2736.4587s
	iters: 1200, epoch: 2 | loss: 0.0228843
	speed: 0.1179s/iter; left time: 2696.4611s
	iters: 1300, epoch: 2 | loss: 0.0178757
	speed: 0.1177s/iter; left time: 2680.3184s
	iters: 1400, epoch: 2 | loss: 0.0154823
	speed: 0.1181s/iter; left time: 2677.2383s
	iters: 1500, epoch: 2 | loss: 0.0186933
	speed: 0.1183s/iter; left time: 2669.5409s
	iters: 1600, epoch: 2 | loss: 0.0156614
	speed: 0.1189s/iter; left time: 2670.6355s
	iters: 1700, epoch: 2 | loss: 0.0269292
	speed: 0.1181s/iter; left time: 2640.9991s
	iters: 1800, epoch: 2 | loss: 0.0205998
	speed: 0.1181s/iter; left time: 2629.6470s
	iters: 1900, epoch: 2 | loss: 0.0165224
	speed: 0.1181s/iter; left time: 2617.3967s
	iters: 2000, epoch: 2 | loss: 0.0198831
	speed: 0.1187s/iter; left time: 2619.6575s
	iters: 2100, epoch: 2 | loss: 0.0175092
	speed: 0.1184s/iter; left time: 2601.5009s
	iters: 2200, epoch: 2 | loss: 0.0193105
	speed: 0.1184s/iter; left time: 2589.7392s
	iters: 2300, epoch: 2 | loss: 0.0158157
	speed: 0.1187s/iter; left time: 2584.0218s
	iters: 2400, epoch: 2 | loss: 0.0190078
	speed: 0.1181s/iter; left time: 2558.6817s
	iters: 2500, epoch: 2 | loss: 0.0142906
	speed: 0.1179s/iter; left time: 2543.2930s
	iters: 2600, epoch: 2 | loss: 0.0173382
	speed: 0.1179s/iter; left time: 2530.0321s
Epoch: 2 cost time: 00h:05m:16.32s
Epoch: 2 | Train Loss: 0.0188001 Vali Loss: 0.0155285 Test Loss: 0.0209162
Validation loss decreased (0.016286 --> 0.015528).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0177140
	speed: 0.8416s/iter; left time: 17920.7836s
	iters: 200, epoch: 3 | loss: 0.0196787
	speed: 0.1177s/iter; left time: 2494.9457s
	iters: 300, epoch: 3 | loss: 0.0188081
	speed: 0.1181s/iter; left time: 2490.5147s
	iters: 400, epoch: 3 | loss: 0.0183770
	speed: 0.1180s/iter; left time: 2477.3454s
	iters: 500, epoch: 3 | loss: 0.0175956
	speed: 0.1178s/iter; left time: 2462.0997s
	iters: 600, epoch: 3 | loss: 0.0203164
	speed: 0.1181s/iter; left time: 2455.4090s
	iters: 700, epoch: 3 | loss: 0.0214823
	speed: 0.1168s/iter; left time: 2416.5487s
	iters: 800, epoch: 3 | loss: 0.0185821
	speed: 0.1177s/iter; left time: 2422.8392s
	iters: 900, epoch: 3 | loss: 0.0175205
	speed: 0.1183s/iter; left time: 2423.3668s
	iters: 1000, epoch: 3 | loss: 0.0216272
	speed: 0.1187s/iter; left time: 2421.6122s
	iters: 1100, epoch: 3 | loss: 0.0181549
	speed: 0.1183s/iter; left time: 2400.3742s
	iters: 1200, epoch: 3 | loss: 0.0184777
	speed: 0.1182s/iter; left time: 2387.4054s
	iters: 1300, epoch: 3 | loss: 0.0182787
	speed: 0.1190s/iter; left time: 2391.9697s
	iters: 1400, epoch: 3 | loss: 0.0148450
	speed: 0.1184s/iter; left time: 2366.9604s
	iters: 1500, epoch: 3 | loss: 0.0185719
	speed: 0.1182s/iter; left time: 2352.0284s
	iters: 1600, epoch: 3 | loss: 0.0238936
	speed: 0.1181s/iter; left time: 2336.7643s
	iters: 1700, epoch: 3 | loss: 0.0209816
	speed: 0.1189s/iter; left time: 2341.9524s
	iters: 1800, epoch: 3 | loss: 0.0160317
	speed: 0.1190s/iter; left time: 2332.1289s
	iters: 1900, epoch: 3 | loss: 0.0230464
	speed: 0.1186s/iter; left time: 2311.9086s
	iters: 2000, epoch: 3 | loss: 0.0154415
	speed: 0.1186s/iter; left time: 2300.1311s
	iters: 2100, epoch: 3 | loss: 0.0259799
	speed: 0.1188s/iter; left time: 2291.3574s
	iters: 2200, epoch: 3 | loss: 0.0223718
	speed: 0.1186s/iter; left time: 2276.3903s
	iters: 2300, epoch: 3 | loss: 0.0149282
	speed: 0.1186s/iter; left time: 2264.1633s
	iters: 2400, epoch: 3 | loss: 0.0149720
	speed: 0.1182s/iter; left time: 2245.7500s
	iters: 2500, epoch: 3 | loss: 0.0186536
	speed: 0.1179s/iter; left time: 2227.9261s
	iters: 2600, epoch: 3 | loss: 0.0159037
	speed: 0.1194s/iter; left time: 2243.4022s
Epoch: 3 cost time: 00h:05m:16.77s
Epoch: 3 | Train Loss: 0.0178578 Vali Loss: 0.0147861 Test Loss: 0.0201043
Validation loss decreased (0.015528 --> 0.014786).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0156282
	speed: 0.8238s/iter; left time: 15337.4997s
	iters: 200, epoch: 4 | loss: 0.0179232
	speed: 0.1170s/iter; left time: 2167.1841s
	iters: 300, epoch: 4 | loss: 0.0139722
	speed: 0.1181s/iter; left time: 2175.4024s
	iters: 400, epoch: 4 | loss: 0.0160886
	speed: 0.1186s/iter; left time: 2171.8512s
	iters: 500, epoch: 4 | loss: 0.0219021
	speed: 0.1185s/iter; left time: 2159.5564s
	iters: 600, epoch: 4 | loss: 0.0160224
	speed: 0.1180s/iter; left time: 2137.9910s
	iters: 700, epoch: 4 | loss: 0.0190574
	speed: 0.1178s/iter; left time: 2123.3011s
	iters: 800, epoch: 4 | loss: 0.0162646
	speed: 0.1180s/iter; left time: 2113.9964s
	iters: 900, epoch: 4 | loss: 0.0151715
	speed: 0.1178s/iter; left time: 2098.8193s
	iters: 1000, epoch: 4 | loss: 0.0161191
	speed: 0.1165s/iter; left time: 2065.0858s
	iters: 1100, epoch: 4 | loss: 0.0185219
	speed: 0.1179s/iter; left time: 2077.8344s
	iters: 1200, epoch: 4 | loss: 0.0181180
	speed: 0.1169s/iter; left time: 2047.2558s
	iters: 1300, epoch: 4 | loss: 0.0156713
	speed: 0.1185s/iter; left time: 2064.2798s
	iters: 1400, epoch: 4 | loss: 0.0189912
	speed: 0.1189s/iter; left time: 2058.5864s
	iters: 1500, epoch: 4 | loss: 0.0157091
	speed: 0.1194s/iter; left time: 2056.1028s
	iters: 1600, epoch: 4 | loss: 0.0179429
	speed: 0.1189s/iter; left time: 2034.7169s
	iters: 1700, epoch: 4 | loss: 0.0189502
	speed: 0.1188s/iter; left time: 2021.2511s
	iters: 1800, epoch: 4 | loss: 0.0136407
	speed: 0.1186s/iter; left time: 2006.9146s
	iters: 1900, epoch: 4 | loss: 0.0182259
	speed: 0.1182s/iter; left time: 1987.2078s
	iters: 2000, epoch: 4 | loss: 0.0210587
	speed: 0.1184s/iter; left time: 1978.7604s
	iters: 2100, epoch: 4 | loss: 0.0209161
	speed: 0.1183s/iter; left time: 1965.7442s
	iters: 2200, epoch: 4 | loss: 0.0143668
	speed: 0.1170s/iter; left time: 1932.5544s
	iters: 2300, epoch: 4 | loss: 0.0166738
	speed: 0.1178s/iter; left time: 1933.9576s
	iters: 2400, epoch: 4 | loss: 0.0210513
	speed: 0.1172s/iter; left time: 1912.9111s
	iters: 2500, epoch: 4 | loss: 0.0150934
	speed: 0.1169s/iter; left time: 1896.5542s
	iters: 2600, epoch: 4 | loss: 0.0159758
	speed: 0.1175s/iter; left time: 1893.6409s
Epoch: 4 cost time: 00h:05m:15.83s
Epoch: 4 | Train Loss: 0.0171844 Vali Loss: 0.0148527 Test Loss: 0.0205019
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0164564
	speed: 0.8089s/iter; left time: 12898.3397s
	iters: 200, epoch: 5 | loss: 0.0232456
	speed: 0.1187s/iter; left time: 1880.0776s
	iters: 300, epoch: 5 | loss: 0.0143200
	speed: 0.1186s/iter; left time: 1867.2551s
	iters: 400, epoch: 5 | loss: 0.0119979
	speed: 0.1182s/iter; left time: 1849.9386s
	iters: 500, epoch: 5 | loss: 0.0154182
	speed: 0.1180s/iter; left time: 1834.7602s
	iters: 600, epoch: 5 | loss: 0.0172274
	speed: 0.1168s/iter; left time: 1803.5917s
	iters: 700, epoch: 5 | loss: 0.0155693
	speed: 0.1193s/iter; left time: 1831.0214s
	iters: 800, epoch: 5 | loss: 0.0174366
	speed: 0.1183s/iter; left time: 1803.1188s
	iters: 900, epoch: 5 | loss: 0.0182169
	speed: 0.1190s/iter; left time: 1802.6044s
	iters: 1000, epoch: 5 | loss: 0.0161281
	speed: 0.1180s/iter; left time: 1775.4184s
	iters: 1100, epoch: 5 | loss: 0.0165226
	speed: 0.1180s/iter; left time: 1763.6820s
	iters: 1200, epoch: 5 | loss: 0.0199898
	speed: 0.1176s/iter; left time: 1745.5717s
	iters: 1300, epoch: 5 | loss: 0.0103930
	speed: 0.1178s/iter; left time: 1736.5485s
	iters: 1400, epoch: 5 | loss: 0.0212616
	speed: 0.1186s/iter; left time: 1737.2714s
	iters: 1500, epoch: 5 | loss: 0.0157672
	speed: 0.1188s/iter; left time: 1727.5973s
	iters: 1600, epoch: 5 | loss: 0.0173533
	speed: 0.1189s/iter; left time: 1716.9214s
	iters: 1700, epoch: 5 | loss: 0.0115727
	speed: 0.1200s/iter; left time: 1722.0483s
	iters: 1800, epoch: 5 | loss: 0.0136951
	speed: 0.1182s/iter; left time: 1683.7876s
	iters: 1900, epoch: 5 | loss: 0.0184059
	speed: 0.1185s/iter; left time: 1675.6718s
	iters: 2000, epoch: 5 | loss: 0.0125891
	speed: 0.1184s/iter; left time: 1662.7249s
	iters: 2100, epoch: 5 | loss: 0.0189931
	speed: 0.1179s/iter; left time: 1644.4952s
	iters: 2200, epoch: 5 | loss: 0.0154729
	speed: 0.1178s/iter; left time: 1630.9708s
	iters: 2300, epoch: 5 | loss: 0.0149517
	speed: 0.1177s/iter; left time: 1618.4238s
	iters: 2400, epoch: 5 | loss: 0.0133085
	speed: 0.1181s/iter; left time: 1611.7200s
	iters: 2500, epoch: 5 | loss: 0.0149594
	speed: 0.1188s/iter; left time: 1609.7117s
	iters: 2600, epoch: 5 | loss: 0.0149752
	speed: 0.1174s/iter; left time: 1578.3938s
Epoch: 5 cost time: 00h:05m:16.58s
Epoch: 5 | Train Loss: 0.0166053 Vali Loss: 0.0153127 Test Loss: 0.0214258
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0223485
	speed: 0.8000s/iter; left time: 10616.1517s
	iters: 200, epoch: 6 | loss: 0.0121768
	speed: 0.1178s/iter; left time: 1551.6269s
	iters: 300, epoch: 6 | loss: 0.0126217
	speed: 0.1185s/iter; left time: 1548.7992s
	iters: 400, epoch: 6 | loss: 0.0139260
	speed: 0.1179s/iter; left time: 1529.6608s
	iters: 500, epoch: 6 | loss: 0.0171338
	speed: 0.1182s/iter; left time: 1521.1395s
	iters: 600, epoch: 6 | loss: 0.0149041
	speed: 0.1175s/iter; left time: 1500.2834s
	iters: 700, epoch: 6 | loss: 0.0175755
	speed: 0.1170s/iter; left time: 1482.6186s
	iters: 800, epoch: 6 | loss: 0.0145324
	speed: 0.1172s/iter; left time: 1473.6181s
	iters: 900, epoch: 6 | loss: 0.0171111
	speed: 0.1167s/iter; left time: 1455.8475s
	iters: 1000, epoch: 6 | loss: 0.0146363
	speed: 0.1173s/iter; left time: 1451.3341s
	iters: 1100, epoch: 6 | loss: 0.0150884
	speed: 0.1166s/iter; left time: 1430.5942s
	iters: 1200, epoch: 6 | loss: 0.0143555
	speed: 0.1178s/iter; left time: 1433.9907s
	iters: 1300, epoch: 6 | loss: 0.0188446
	speed: 0.1182s/iter; left time: 1426.8920s
	iters: 1400, epoch: 6 | loss: 0.0166732
	speed: 0.1181s/iter; left time: 1413.5783s
	iters: 1500, epoch: 6 | loss: 0.0156958
	speed: 0.1189s/iter; left time: 1411.6659s
	iters: 1600, epoch: 6 | loss: 0.0139390
	speed: 0.1182s/iter; left time: 1391.4093s
	iters: 1700, epoch: 6 | loss: 0.0142860
	speed: 0.1177s/iter; left time: 1373.9553s
	iters: 1800, epoch: 6 | loss: 0.0155759
	speed: 0.1195s/iter; left time: 1382.7811s
	iters: 1900, epoch: 6 | loss: 0.0164216
	speed: 0.1184s/iter; left time: 1358.3143s
	iters: 2000, epoch: 6 | loss: 0.0164557
	speed: 0.1186s/iter; left time: 1348.1671s
	iters: 2100, epoch: 6 | loss: 0.0135262
	speed: 0.1163s/iter; left time: 1311.1888s
	iters: 2200, epoch: 6 | loss: 0.0157910
	speed: 0.1182s/iter; left time: 1320.4871s
	iters: 2300, epoch: 6 | loss: 0.0160504
	speed: 0.1177s/iter; left time: 1302.9435s
	iters: 2400, epoch: 6 | loss: 0.0174849
	speed: 0.1180s/iter; left time: 1294.2419s
	iters: 2500, epoch: 6 | loss: 0.0164651
	speed: 0.1180s/iter; left time: 1283.1895s
	iters: 2600, epoch: 6 | loss: 0.0133010
	speed: 0.1182s/iter; left time: 1272.9705s
Epoch: 6 cost time: 00h:05m:15.46s
Epoch: 6 | Train Loss: 0.0159895 Vali Loss: 0.0162522 Test Loss: 0.0233178
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.02010430209338665, rmse:0.14178964495658875, mae:0.09643717110157013, rse:0.41650381684303284
Intermediate time for ES and pred_len 96: 00h:38m:52.80s

=== Starting experiments for pred_len: 168 ===

--- Running model for ES, pred_len=168 ---
train 85371
val 18219
test 18219
[2024-11-12 17:56:46,934] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 17:56:47,952] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 17:56:47,952] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 17:56:47,952] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 17:56:48,069] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 17:56:48,069] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 17:56:48,989] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 17:56:48,990] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 17:56:48,990] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 17:56:48,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 17:56:48,991] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 17:56:48,991] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 17:56:48,991] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 17:56:48,991] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 17:56:48,991] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 17:56:48,991] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 17:56:49,200] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 17:56:49,201] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 17:56:49,230] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.65 GB, percent = 2.7%
[2024-11-12 17:56:49,312] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 17:56:49,312] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 17:56:49,313] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.65 GB, percent = 2.7%
[2024-11-12 17:56:49,313] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 17:56:49,384] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 17:56:49,384] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 17:56:49,384] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 27.65 GB, percent = 2.7%
[2024-11-12 17:56:49,384] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 17:56:49,385] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 17:56:49,385] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 17:56:49,385] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 17:56:49,385] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3a2c8f3790>
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 17:56:49,385] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 17:56:49,386] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 17:56:49,386] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0667607
	speed: 0.1632s/iter; left time: 4336.6251s
	iters: 200, epoch: 1 | loss: 0.0647801
	speed: 0.1229s/iter; left time: 3254.5416s
	iters: 300, epoch: 1 | loss: 0.0477799
	speed: 0.1220s/iter; left time: 3218.3779s
	iters: 400, epoch: 1 | loss: 0.0545483
	speed: 0.1229s/iter; left time: 3229.1619s
	iters: 500, epoch: 1 | loss: 0.0587163
	speed: 0.1232s/iter; left time: 3225.1612s
	iters: 600, epoch: 1 | loss: 0.0502290
	speed: 0.1233s/iter; left time: 3214.8226s
	iters: 700, epoch: 1 | loss: 0.0262464
	speed: 0.1232s/iter; left time: 3200.2894s
	iters: 800, epoch: 1 | loss: 0.0290788
	speed: 0.1231s/iter; left time: 3184.7234s
	iters: 900, epoch: 1 | loss: 0.0317928
	speed: 0.1246s/iter; left time: 3209.8712s
	iters: 1000, epoch: 1 | loss: 0.0281496
	speed: 0.1239s/iter; left time: 3179.8947s
	iters: 1100, epoch: 1 | loss: 0.0204535
	speed: 0.1218s/iter; left time: 3114.0214s
	iters: 1200, epoch: 1 | loss: 0.0259826
	speed: 0.1231s/iter; left time: 3136.1018s
	iters: 1300, epoch: 1 | loss: 0.0238629
	speed: 0.1235s/iter; left time: 3132.2769s
	iters: 1400, epoch: 1 | loss: 0.0234594
	speed: 0.1229s/iter; left time: 3104.6009s
	iters: 1500, epoch: 1 | loss: 0.0263001
	speed: 0.1233s/iter; left time: 3104.6554s
	iters: 1600, epoch: 1 | loss: 0.0232118
	speed: 0.1240s/iter; left time: 3109.4820s
	iters: 1700, epoch: 1 | loss: 0.0200240
	speed: 0.1246s/iter; left time: 3111.1812s
	iters: 1800, epoch: 1 | loss: 0.0255148
	speed: 0.1230s/iter; left time: 3059.3099s
	iters: 1900, epoch: 1 | loss: 0.0210648
	speed: 0.1234s/iter; left time: 3057.1488s
	iters: 2000, epoch: 1 | loss: 0.0221414
	speed: 0.1245s/iter; left time: 3070.5787s
	iters: 2100, epoch: 1 | loss: 0.0192121
	speed: 0.1236s/iter; left time: 3037.5319s
	iters: 2200, epoch: 1 | loss: 0.0171362
	speed: 0.1236s/iter; left time: 3024.8261s
	iters: 2300, epoch: 1 | loss: 0.0202530
	speed: 0.1231s/iter; left time: 2999.5523s
	iters: 2400, epoch: 1 | loss: 0.0246680
	speed: 0.1219s/iter; left time: 2957.5271s
	iters: 2500, epoch: 1 | loss: 0.0196966
	speed: 0.1236s/iter; left time: 2988.6726s
	iters: 2600, epoch: 1 | loss: 0.0254166
	speed: 0.1247s/iter; left time: 3001.3103s
Epoch: 1 cost time: 00h:05m:30.07s
Epoch: 1 | Train Loss: 0.0319512 Vali Loss: 0.0181582 Test Loss: 0.0240126
Validation loss decreased (inf --> 0.018158).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0194376
	speed: 0.9184s/iter; left time: 21953.2976s
	iters: 200, epoch: 2 | loss: 0.0190713
	speed: 0.1178s/iter; left time: 2805.2188s
	iters: 300, epoch: 2 | loss: 0.0243947
	speed: 0.1177s/iter; left time: 2788.8932s
	iters: 400, epoch: 2 | loss: 0.0185748
	speed: 0.1176s/iter; left time: 2776.0729s
	iters: 500, epoch: 2 | loss: 0.0251139
	speed: 0.1173s/iter; left time: 2757.4459s
	iters: 600, epoch: 2 | loss: 0.0186687
	speed: 0.1172s/iter; left time: 2742.1655s
	iters: 700, epoch: 2 | loss: 0.0184233
	speed: 0.1185s/iter; left time: 2760.7513s
	iters: 800, epoch: 2 | loss: 0.0201159
	speed: 0.1179s/iter; left time: 2734.8896s
	iters: 900, epoch: 2 | loss: 0.0221073
	speed: 0.1183s/iter; left time: 2732.6111s
	iters: 1000, epoch: 2 | loss: 0.0207406
	speed: 0.1177s/iter; left time: 2707.6848s
	iters: 1100, epoch: 2 | loss: 0.0195115
	speed: 0.1178s/iter; left time: 2698.2652s
	iters: 1200, epoch: 2 | loss: 0.0222875
	speed: 0.1188s/iter; left time: 2708.5535s
	iters: 1300, epoch: 2 | loss: 0.0243909
	speed: 0.1178s/iter; left time: 2673.4086s
	iters: 1400, epoch: 2 | loss: 0.0181278
	speed: 0.1174s/iter; left time: 2653.7444s
	iters: 1500, epoch: 2 | loss: 0.0217748
	speed: 0.1180s/iter; left time: 2655.9170s
	iters: 1600, epoch: 2 | loss: 0.0201805
	speed: 0.1174s/iter; left time: 2629.3216s
	iters: 1700, epoch: 2 | loss: 0.0213851
	speed: 0.1190s/iter; left time: 2654.6299s
	iters: 1800, epoch: 2 | loss: 0.0188240
	speed: 0.1184s/iter; left time: 2628.8722s
	iters: 1900, epoch: 2 | loss: 0.0202289
	speed: 0.1182s/iter; left time: 2613.4081s
	iters: 2000, epoch: 2 | loss: 0.0190315
	speed: 0.1193s/iter; left time: 2624.7080s
	iters: 2100, epoch: 2 | loss: 0.0236717
	speed: 0.1186s/iter; left time: 2597.3438s
	iters: 2200, epoch: 2 | loss: 0.0170608
	speed: 0.1183s/iter; left time: 2579.2916s
	iters: 2300, epoch: 2 | loss: 0.0158485
	speed: 0.1179s/iter; left time: 2559.2699s
	iters: 2400, epoch: 2 | loss: 0.0226687
	speed: 0.1178s/iter; left time: 2544.0586s
	iters: 2500, epoch: 2 | loss: 0.0172871
	speed: 0.1185s/iter; left time: 2548.5726s
	iters: 2600, epoch: 2 | loss: 0.0202338
	speed: 0.1184s/iter; left time: 2534.0215s
Epoch: 2 cost time: 00h:05m:15.23s
Epoch: 2 | Train Loss: 0.0203841 Vali Loss: 0.0179391 Test Loss: 0.0229153
Validation loss decreased (0.018158 --> 0.017939).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0193680
	speed: 0.8070s/iter; left time: 17137.8533s
	iters: 200, epoch: 3 | loss: 0.0121227
	speed: 0.1176s/iter; left time: 2485.0639s
	iters: 300, epoch: 3 | loss: 0.0174387
	speed: 0.1186s/iter; left time: 2494.9651s
	iters: 400, epoch: 3 | loss: 0.0227722
	speed: 0.1180s/iter; left time: 2470.0942s
	iters: 500, epoch: 3 | loss: 0.0166070
	speed: 0.1172s/iter; left time: 2442.1831s
	iters: 600, epoch: 3 | loss: 0.0221936
	speed: 0.1178s/iter; left time: 2443.1420s
	iters: 700, epoch: 3 | loss: 0.0160178
	speed: 0.1183s/iter; left time: 2440.4893s
	iters: 800, epoch: 3 | loss: 0.0227847
	speed: 0.1173s/iter; left time: 2408.6429s
	iters: 900, epoch: 3 | loss: 0.0167493
	speed: 0.1179s/iter; left time: 2408.7605s
	iters: 1000, epoch: 3 | loss: 0.0210526
	speed: 0.1182s/iter; left time: 2404.3344s
	iters: 1100, epoch: 3 | loss: 0.0223127
	speed: 0.1179s/iter; left time: 2385.5123s
	iters: 1200, epoch: 3 | loss: 0.0235141
	speed: 0.1185s/iter; left time: 2387.0457s
	iters: 1300, epoch: 3 | loss: 0.0188325
	speed: 0.1179s/iter; left time: 2363.0085s
	iters: 1400, epoch: 3 | loss: 0.0204581
	speed: 0.1182s/iter; left time: 2357.2105s
	iters: 1500, epoch: 3 | loss: 0.0177237
	speed: 0.1178s/iter; left time: 2335.8888s
	iters: 1600, epoch: 3 | loss: 0.0202699
	speed: 0.1182s/iter; left time: 2332.5838s
	iters: 1700, epoch: 3 | loss: 0.0218207
	speed: 0.1184s/iter; left time: 2324.9928s
	iters: 1800, epoch: 3 | loss: 0.0194628
	speed: 0.1182s/iter; left time: 2309.9816s
	iters: 1900, epoch: 3 | loss: 0.0180804
	speed: 0.1181s/iter; left time: 2294.6968s
	iters: 2000, epoch: 3 | loss: 0.0179418
	speed: 0.1188s/iter; left time: 2297.7200s
	iters: 2100, epoch: 3 | loss: 0.0266515
	speed: 0.1190s/iter; left time: 2289.1929s
	iters: 2200, epoch: 3 | loss: 0.0168945
	speed: 0.1187s/iter; left time: 2271.1368s
	iters: 2300, epoch: 3 | loss: 0.0167936
	speed: 0.1182s/iter; left time: 2249.3002s
	iters: 2400, epoch: 3 | loss: 0.0180226
	speed: 0.1183s/iter; left time: 2240.8459s
	iters: 2500, epoch: 3 | loss: 0.0177396
	speed: 0.1170s/iter; left time: 2204.4213s
	iters: 2600, epoch: 3 | loss: 0.0216624
	speed: 0.1171s/iter; left time: 2194.2616s
Epoch: 3 cost time: 00h:05m:15.10s
Epoch: 3 | Train Loss: 0.0191922 Vali Loss: 0.0174912 Test Loss: 0.0217524
Validation loss decreased (0.017939 --> 0.017491).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0197114
	speed: 0.8130s/iter; left time: 15097.8171s
	iters: 200, epoch: 4 | loss: 0.0157281
	speed: 0.1177s/iter; left time: 2173.0645s
	iters: 300, epoch: 4 | loss: 0.0173862
	speed: 0.1181s/iter; left time: 2169.0379s
	iters: 400, epoch: 4 | loss: 0.0214945
	speed: 0.1181s/iter; left time: 2158.2216s
	iters: 500, epoch: 4 | loss: 0.0179972
	speed: 0.1174s/iter; left time: 2134.0199s
	iters: 600, epoch: 4 | loss: 0.0244034
	speed: 0.1182s/iter; left time: 2135.6793s
	iters: 700, epoch: 4 | loss: 0.0205954
	speed: 0.1190s/iter; left time: 2138.6474s
	iters: 800, epoch: 4 | loss: 0.0168051
	speed: 0.1180s/iter; left time: 2109.0248s
	iters: 900, epoch: 4 | loss: 0.0156627
	speed: 0.1191s/iter; left time: 2115.9773s
	iters: 1000, epoch: 4 | loss: 0.0150014
	speed: 0.1185s/iter; left time: 2093.8602s
	iters: 1100, epoch: 4 | loss: 0.0196936
	speed: 0.1187s/iter; left time: 2085.2078s
	iters: 1200, epoch: 4 | loss: 0.0162599
	speed: 0.1181s/iter; left time: 2063.1241s
	iters: 1300, epoch: 4 | loss: 0.0157100
	speed: 0.1637s/iter; left time: 2842.8910s
	iters: 1400, epoch: 4 | loss: 0.0163708
	speed: 0.2175s/iter; left time: 3756.5008s
	iters: 1500, epoch: 4 | loss: 0.0184773
	speed: 0.1171s/iter; left time: 2010.1331s
	iters: 1600, epoch: 4 | loss: 0.0178051
	speed: 0.1179s/iter; left time: 2013.3931s
	iters: 1700, epoch: 4 | loss: 0.0146827
	speed: 0.1186s/iter; left time: 2012.1632s
	iters: 1800, epoch: 4 | loss: 0.0199797
	speed: 0.1177s/iter; left time: 1985.1764s
	iters: 1900, epoch: 4 | loss: 0.0219427
	speed: 0.1181s/iter; left time: 1980.6564s
	iters: 2000, epoch: 4 | loss: 0.0172931
	speed: 0.1182s/iter; left time: 1970.8105s
	iters: 2100, epoch: 4 | loss: 0.0249441
	speed: 0.1187s/iter; left time: 1966.5472s
	iters: 2200, epoch: 4 | loss: 0.0137533
	speed: 0.1173s/iter; left time: 1931.5018s
	iters: 2300, epoch: 4 | loss: 0.0201245
	speed: 0.1172s/iter; left time: 1918.3426s
	iters: 2400, epoch: 4 | loss: 0.0179501
	speed: 0.1188s/iter; left time: 1933.0041s
	iters: 2500, epoch: 4 | loss: 0.0201867
	speed: 0.1173s/iter; left time: 1897.0598s
	iters: 2600, epoch: 4 | loss: 0.0167003
	speed: 0.1171s/iter; left time: 1881.6582s
Epoch: 4 cost time: 00h:05m:29.65s
Epoch: 4 | Train Loss: 0.0182527 Vali Loss: 0.0173162 Test Loss: 0.0225081
Validation loss decreased (0.017491 --> 0.017316).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0200314
	speed: 0.8082s/iter; left time: 12853.3632s
	iters: 200, epoch: 5 | loss: 0.0179361
	speed: 0.1177s/iter; left time: 1860.2239s
	iters: 300, epoch: 5 | loss: 0.0198960
	speed: 0.1185s/iter; left time: 1860.1479s
	iters: 400, epoch: 5 | loss: 0.0163527
	speed: 0.1169s/iter; left time: 1824.2823s
	iters: 500, epoch: 5 | loss: 0.0205075
	speed: 0.1176s/iter; left time: 1823.8173s
	iters: 600, epoch: 5 | loss: 0.0179766
	speed: 0.1174s/iter; left time: 1808.3802s
	iters: 700, epoch: 5 | loss: 0.0176956
	speed: 0.1181s/iter; left time: 1807.5243s
	iters: 800, epoch: 5 | loss: 0.0171347
	speed: 0.1192s/iter; left time: 1811.4759s
	iters: 900, epoch: 5 | loss: 0.0197008
	speed: 0.1183s/iter; left time: 1787.3294s
	iters: 1000, epoch: 5 | loss: 0.0161437
	speed: 0.1182s/iter; left time: 1773.0945s
	iters: 1100, epoch: 5 | loss: 0.0157670
	speed: 0.1181s/iter; left time: 1759.6408s
	iters: 1200, epoch: 5 | loss: 0.0174743
	speed: 0.1177s/iter; left time: 1741.5752s
	iters: 1300, epoch: 5 | loss: 0.0173994
	speed: 0.1180s/iter; left time: 1735.2992s
	iters: 1400, epoch: 5 | loss: 0.0178414
	speed: 0.1182s/iter; left time: 1725.7536s
	iters: 1500, epoch: 5 | loss: 0.0156718
	speed: 0.1183s/iter; left time: 1716.0461s
	iters: 1600, epoch: 5 | loss: 0.0229516
	speed: 0.1181s/iter; left time: 1700.7650s
	iters: 1700, epoch: 5 | loss: 0.0207339
	speed: 0.1189s/iter; left time: 1700.7933s
	iters: 1800, epoch: 5 | loss: 0.0168245
	speed: 0.1186s/iter; left time: 1684.8331s
	iters: 1900, epoch: 5 | loss: 0.0168168
	speed: 0.1192s/iter; left time: 1680.9545s
	iters: 2000, epoch: 5 | loss: 0.0133681
	speed: 0.1174s/iter; left time: 1643.4702s
	iters: 2100, epoch: 5 | loss: 0.0198422
	speed: 0.1169s/iter; left time: 1625.5910s
	iters: 2200, epoch: 5 | loss: 0.0165978
	speed: 0.1180s/iter; left time: 1628.4821s
	iters: 2300, epoch: 5 | loss: 0.0154563
	speed: 0.1182s/iter; left time: 1619.6566s
	iters: 2400, epoch: 5 | loss: 0.0174232
	speed: 0.1188s/iter; left time: 1615.4339s
	iters: 2500, epoch: 5 | loss: 0.0147960
	speed: 0.1192s/iter; left time: 1609.2460s
	iters: 2600, epoch: 5 | loss: 0.0185831
	speed: 0.1182s/iter; left time: 1583.7089s
Epoch: 5 cost time: 00h:05m:15.40s
Epoch: 5 | Train Loss: 0.0175474 Vali Loss: 0.0173207 Test Loss: 0.0230904
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0134064
	speed: 0.7871s/iter; left time: 10418.1306s
	iters: 200, epoch: 6 | loss: 0.0215653
	speed: 0.1184s/iter; left time: 1554.8739s
	iters: 300, epoch: 6 | loss: 0.0164681
	speed: 0.1188s/iter; left time: 1548.9519s
	iters: 400, epoch: 6 | loss: 0.0167478
	speed: 0.1178s/iter; left time: 1524.4756s
	iters: 500, epoch: 6 | loss: 0.0182057
	speed: 0.1189s/iter; left time: 1525.6303s
	iters: 600, epoch: 6 | loss: 0.0186282
	speed: 0.1180s/iter; left time: 1502.3207s
	iters: 700, epoch: 6 | loss: 0.0166893
	speed: 0.1176s/iter; left time: 1485.8864s
	iters: 800, epoch: 6 | loss: 0.0223045
	speed: 0.1177s/iter; left time: 1475.3988s
	iters: 900, epoch: 6 | loss: 0.0178537
	speed: 0.1180s/iter; left time: 1467.1709s
	iters: 1000, epoch: 6 | loss: 0.0236684
	speed: 0.1164s/iter; left time: 1436.1879s
	iters: 1100, epoch: 6 | loss: 0.0190349
	speed: 0.1188s/iter; left time: 1453.6551s
	iters: 1200, epoch: 6 | loss: 0.0180589
	speed: 0.1183s/iter; left time: 1435.4167s
	iters: 1300, epoch: 6 | loss: 0.0161074
	speed: 0.1190s/iter; left time: 1432.4422s
	iters: 1400, epoch: 6 | loss: 0.0120870
	speed: 0.1178s/iter; left time: 1406.1309s
	iters: 1500, epoch: 6 | loss: 0.0148896
	speed: 0.1172s/iter; left time: 1387.7033s
	iters: 1600, epoch: 6 | loss: 0.0173568
	speed: 0.1196s/iter; left time: 1403.2309s
	iters: 1700, epoch: 6 | loss: 0.0191535
	speed: 0.1178s/iter; left time: 1371.2970s
	iters: 1800, epoch: 6 | loss: 0.0163945
	speed: 0.1164s/iter; left time: 1342.4194s
	iters: 1900, epoch: 6 | loss: 0.0169746
	speed: 0.1172s/iter; left time: 1340.2614s
	iters: 2000, epoch: 6 | loss: 0.0157028
	speed: 0.1176s/iter; left time: 1332.5739s
	iters: 2100, epoch: 6 | loss: 0.0154276
	speed: 0.1175s/iter; left time: 1319.8241s
	iters: 2200, epoch: 6 | loss: 0.0156748
	speed: 0.1180s/iter; left time: 1314.2257s
	iters: 2300, epoch: 6 | loss: 0.0185000
	speed: 0.1177s/iter; left time: 1298.6110s
	iters: 2400, epoch: 6 | loss: 0.0123806
	speed: 0.1178s/iter; left time: 1287.8039s
	iters: 2500, epoch: 6 | loss: 0.0169220
	speed: 0.1174s/iter; left time: 1272.5997s
	iters: 2600, epoch: 6 | loss: 0.0163204
	speed: 0.1171s/iter; left time: 1256.6723s
Epoch: 6 cost time: 00h:05m:14.59s
Epoch: 6 | Train Loss: 0.0166633 Vali Loss: 0.0181887 Test Loss: 0.0242044
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0168511
	speed: 0.8037s/iter; left time: 8494.8262s
	iters: 200, epoch: 7 | loss: 0.0155326
	speed: 0.1181s/iter; left time: 1235.9952s
	iters: 300, epoch: 7 | loss: 0.0165381
	speed: 0.1187s/iter; left time: 1230.8126s
	iters: 400, epoch: 7 | loss: 0.0137137
	speed: 0.1171s/iter; left time: 1202.5307s
	iters: 500, epoch: 7 | loss: 0.0194662
	speed: 0.1183s/iter; left time: 1202.8434s
	iters: 600, epoch: 7 | loss: 0.0215308
	speed: 0.1181s/iter; left time: 1189.0884s
	iters: 700, epoch: 7 | loss: 0.0155118
	speed: 0.1181s/iter; left time: 1176.9503s
	iters: 800, epoch: 7 | loss: 0.0160412
	speed: 0.1181s/iter; left time: 1165.0546s
	iters: 900, epoch: 7 | loss: 0.0167252
	speed: 0.1179s/iter; left time: 1152.0667s
	iters: 1000, epoch: 7 | loss: 0.0198276
	speed: 0.1177s/iter; left time: 1137.6924s
	iters: 1100, epoch: 7 | loss: 0.0160068
	speed: 0.1175s/iter; left time: 1124.7975s
	iters: 1200, epoch: 7 | loss: 0.0173708
	speed: 0.1180s/iter; left time: 1117.0463s
	iters: 1300, epoch: 7 | loss: 0.0135569
	speed: 0.1185s/iter; left time: 1110.5485s
	iters: 1400, epoch: 7 | loss: 0.0157510
	speed: 0.1179s/iter; left time: 1092.8768s
	iters: 1500, epoch: 7 | loss: 0.0136087
	speed: 0.1178s/iter; left time: 1079.9605s
	iters: 1600, epoch: 7 | loss: 0.0147208
	speed: 0.1183s/iter; left time: 1072.5617s
	iters: 1700, epoch: 7 | loss: 0.0187485
	speed: 0.1190s/iter; left time: 1066.8704s
	iters: 1800, epoch: 7 | loss: 0.0158146
	speed: 0.1188s/iter; left time: 1053.3040s
	iters: 1900, epoch: 7 | loss: 0.0147903
	speed: 0.1183s/iter; left time: 1037.4941s
	iters: 2000, epoch: 7 | loss: 0.0110969
	speed: 0.1178s/iter; left time: 1021.5648s
	iters: 2100, epoch: 7 | loss: 0.0155053
	speed: 0.1182s/iter; left time: 1012.9945s
	iters: 2200, epoch: 7 | loss: 0.0184283
	speed: 0.1184s/iter; left time: 1002.3877s
	iters: 2300, epoch: 7 | loss: 0.0142109
	speed: 0.1183s/iter; left time: 990.2640s
	iters: 2400, epoch: 7 | loss: 0.0151944
	speed: 0.1177s/iter; left time: 973.5470s
	iters: 2500, epoch: 7 | loss: 0.0184856
	speed: 0.1178s/iter; left time: 962.3483s
	iters: 2600, epoch: 7 | loss: 0.0145762
	speed: 0.1185s/iter; left time: 956.2792s
Epoch: 7 cost time: 00h:05m:15.16s
Epoch: 7 | Train Loss: 0.0158829 Vali Loss: 0.0191553 Test Loss: 0.0257859
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.022508107125759125, rmse:0.15002702176570892, mae:0.10180532187223434, rse:0.440519779920578
Intermediate time for ES and pred_len 168: 00h:45m:15.40s
Intermediate time for ES: 02h:22m:34.88s

=== Starting experiments for country: FR ===

=== Starting experiments for pred_len: 24 ===

--- Running model for FR, pred_len=24 ---
train 85803
val 18651
test 18651
[2024-11-12 18:42:02,326] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 18:42:03,314] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 18:42:03,314] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 18:42:03,314] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 18:42:03,405] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 18:42:03,406] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 18:42:03,845] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 18:42:03,846] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 18:42:03,846] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 18:42:03,848] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 18:42:03,848] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 18:42:03,848] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 18:42:03,848] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 18:42:03,848] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 18:42:03,848] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 18:42:03,848] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 18:42:04,025] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 18:42:04,026] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 18:42:04,042] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 26.51 GB, percent = 2.6%
[2024-11-12 18:42:04,127] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 18:42:04,128] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 18:42:04,128] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 26.51 GB, percent = 2.6%
[2024-11-12 18:42:04,128] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 18:42:04,208] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 18:42:04,209] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 18:42:04,209] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 26.51 GB, percent = 2.6%
[2024-11-12 18:42:04,209] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 18:42:04,209] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 18:42:04,209] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 18:42:04,209] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 18:42:04,210] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f309d733110>
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 18:42:04,210] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 18:42:04,211] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 18:42:04,211] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0444962
	speed: 0.1573s/iter; left time: 4201.4335s
	iters: 200, epoch: 1 | loss: 0.0322137
	speed: 0.1220s/iter; left time: 3245.2603s
	iters: 300, epoch: 1 | loss: 0.0260007
	speed: 0.1235s/iter; left time: 3274.0954s
	iters: 400, epoch: 1 | loss: 0.0229708
	speed: 0.1232s/iter; left time: 3252.9537s
	iters: 500, epoch: 1 | loss: 0.0172196
	speed: 0.1232s/iter; left time: 3240.3936s
	iters: 600, epoch: 1 | loss: 0.0131601
	speed: 0.1230s/iter; left time: 3224.9327s
	iters: 700, epoch: 1 | loss: 0.0154212
	speed: 0.1231s/iter; left time: 3214.4310s
	iters: 800, epoch: 1 | loss: 0.0082462
	speed: 0.1234s/iter; left time: 3210.8266s
	iters: 900, epoch: 1 | loss: 0.0102866
	speed: 0.1231s/iter; left time: 3190.2669s
	iters: 1000, epoch: 1 | loss: 0.0180272
	speed: 0.1233s/iter; left time: 3182.2283s
	iters: 1100, epoch: 1 | loss: 0.0058429
	speed: 0.1231s/iter; left time: 3164.7459s
	iters: 1200, epoch: 1 | loss: 0.0124263
	speed: 0.1237s/iter; left time: 3167.5803s
	iters: 1300, epoch: 1 | loss: 0.0098113
	speed: 0.1230s/iter; left time: 3136.9992s
	iters: 1400, epoch: 1 | loss: 0.0096488
	speed: 0.1230s/iter; left time: 3125.0103s
	iters: 1500, epoch: 1 | loss: 0.0112721
	speed: 0.1230s/iter; left time: 3113.4618s
	iters: 1600, epoch: 1 | loss: 0.0067157
	speed: 0.1228s/iter; left time: 3095.2286s
	iters: 1700, epoch: 1 | loss: 0.0133950
	speed: 0.1225s/iter; left time: 3077.1308s
	iters: 1800, epoch: 1 | loss: 0.0064615
	speed: 0.1217s/iter; left time: 3043.8273s
	iters: 1900, epoch: 1 | loss: 0.0078250
	speed: 0.1233s/iter; left time: 3071.5778s
	iters: 2000, epoch: 1 | loss: 0.0104470
	speed: 0.1223s/iter; left time: 3033.2443s
	iters: 2100, epoch: 1 | loss: 0.0059813
	speed: 0.1231s/iter; left time: 3042.7230s
	iters: 2200, epoch: 1 | loss: 0.0102676
	speed: 0.1229s/iter; left time: 3025.4167s
	iters: 2300, epoch: 1 | loss: 0.0117478
	speed: 0.1229s/iter; left time: 3012.0458s
	iters: 2400, epoch: 1 | loss: 0.0072785
	speed: 0.1230s/iter; left time: 3002.9440s
	iters: 2500, epoch: 1 | loss: 0.0127181
	speed: 0.1231s/iter; left time: 2993.0053s
	iters: 2600, epoch: 1 | loss: 0.0094498
	speed: 0.1215s/iter; left time: 2940.5839s
Epoch: 1 cost time: 00h:05m:30.61s
Epoch: 1 | Train Loss: 0.0153905 Vali Loss: 0.0103031 Test Loss: 0.0123303
Validation loss decreased (inf --> 0.010303).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0085017
	speed: 0.9419s/iter; left time: 22635.0155s
	iters: 200, epoch: 2 | loss: 0.0186106
	speed: 0.1194s/iter; left time: 2857.3399s
	iters: 300, epoch: 2 | loss: 0.0121583
	speed: 0.1192s/iter; left time: 2839.8626s
	iters: 400, epoch: 2 | loss: 0.0157024
	speed: 0.1204s/iter; left time: 2856.7835s
	iters: 500, epoch: 2 | loss: 0.0091020
	speed: 0.1197s/iter; left time: 2829.0098s
	iters: 600, epoch: 2 | loss: 0.0099834
	speed: 0.1357s/iter; left time: 3194.0647s
	iters: 700, epoch: 2 | loss: 0.0058643
	speed: 0.1191s/iter; left time: 2790.9231s
	iters: 800, epoch: 2 | loss: 0.0085307
	speed: 0.1199s/iter; left time: 2797.1782s
	iters: 900, epoch: 2 | loss: 0.0073949
	speed: 0.1176s/iter; left time: 2732.1667s
	iters: 1000, epoch: 2 | loss: 0.0051499
	speed: 0.1201s/iter; left time: 2777.2088s
	iters: 1100, epoch: 2 | loss: 0.0080156
	speed: 0.1201s/iter; left time: 2766.1863s
	iters: 1200, epoch: 2 | loss: 0.0144322
	speed: 0.1188s/iter; left time: 2724.3725s
	iters: 1300, epoch: 2 | loss: 0.0107730
	speed: 0.1185s/iter; left time: 2704.9540s
	iters: 1400, epoch: 2 | loss: 0.0059757
	speed: 0.1200s/iter; left time: 2728.0709s
	iters: 1500, epoch: 2 | loss: 0.0105960
	speed: 0.1188s/iter; left time: 2687.8788s
	iters: 1600, epoch: 2 | loss: 0.0108737
	speed: 0.1189s/iter; left time: 2677.7066s
	iters: 1700, epoch: 2 | loss: 0.0048201
	speed: 0.1195s/iter; left time: 2681.0910s
	iters: 1800, epoch: 2 | loss: 0.0090435
	speed: 0.1190s/iter; left time: 2657.1134s
	iters: 1900, epoch: 2 | loss: 0.0124431
	speed: 0.1192s/iter; left time: 2650.2937s
	iters: 2000, epoch: 2 | loss: 0.0078362
	speed: 0.1190s/iter; left time: 2633.7970s
	iters: 2100, epoch: 2 | loss: 0.0067583
	speed: 0.1186s/iter; left time: 2613.6855s
	iters: 2200, epoch: 2 | loss: 0.0141461
	speed: 0.1196s/iter; left time: 2623.6617s
	iters: 2300, epoch: 2 | loss: 0.0102704
	speed: 0.1186s/iter; left time: 2588.8704s
	iters: 2400, epoch: 2 | loss: 0.0092546
	speed: 0.1198s/iter; left time: 2602.8768s
	iters: 2500, epoch: 2 | loss: 0.0064699
	speed: 0.1217s/iter; left time: 2632.6361s
	iters: 2600, epoch: 2 | loss: 0.0081176
	speed: 0.1194s/iter; left time: 2569.7127s
Epoch: 2 cost time: 00h:05m:21.97s
Epoch: 2 | Train Loss: 0.0091760 Vali Loss: 0.0096819 Test Loss: 0.0112116
Validation loss decreased (0.010303 --> 0.009682).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0106176
	speed: 0.8651s/iter; left time: 18468.5117s
	iters: 200, epoch: 3 | loss: 0.0104928
	speed: 0.1191s/iter; left time: 2530.0656s
	iters: 300, epoch: 3 | loss: 0.0096982
	speed: 0.1192s/iter; left time: 2521.6983s
	iters: 400, epoch: 3 | loss: 0.0107002
	speed: 0.1198s/iter; left time: 2522.4475s
	iters: 500, epoch: 3 | loss: 0.0050922
	speed: 0.1187s/iter; left time: 2486.2886s
	iters: 600, epoch: 3 | loss: 0.0071053
	speed: 0.1182s/iter; left time: 2464.3875s
	iters: 700, epoch: 3 | loss: 0.0081983
	speed: 0.1189s/iter; left time: 2467.9337s
	iters: 800, epoch: 3 | loss: 0.0078431
	speed: 0.1192s/iter; left time: 2460.4467s
	iters: 900, epoch: 3 | loss: 0.0084672
	speed: 0.1204s/iter; left time: 2474.7421s
	iters: 1000, epoch: 3 | loss: 0.0076965
	speed: 0.1201s/iter; left time: 2456.5279s
	iters: 1100, epoch: 3 | loss: 0.0033199
	speed: 0.1210s/iter; left time: 2463.0454s
	iters: 1200, epoch: 3 | loss: 0.0122402
	speed: 0.1210s/iter; left time: 2449.6674s
	iters: 1300, epoch: 3 | loss: 0.0057300
	speed: 0.1189s/iter; left time: 2395.3961s
	iters: 1400, epoch: 3 | loss: 0.0072302
	speed: 0.1197s/iter; left time: 2400.1009s
	iters: 1500, epoch: 3 | loss: 0.0128537
	speed: 0.1204s/iter; left time: 2401.0207s
	iters: 1600, epoch: 3 | loss: 0.0078604
	speed: 0.1194s/iter; left time: 2370.0790s
	iters: 1700, epoch: 3 | loss: 0.0065746
	speed: 0.1201s/iter; left time: 2371.0148s
	iters: 1800, epoch: 3 | loss: 0.0067097
	speed: 0.1206s/iter; left time: 2370.5239s
	iters: 1900, epoch: 3 | loss: 0.0090133
	speed: 0.1197s/iter; left time: 2340.9100s
	iters: 2000, epoch: 3 | loss: 0.0061281
	speed: 0.1186s/iter; left time: 2306.7584s
	iters: 2100, epoch: 3 | loss: 0.0045120
	speed: 0.1193s/iter; left time: 2309.1822s
	iters: 2200, epoch: 3 | loss: 0.0076447
	speed: 0.1198s/iter; left time: 2305.9860s
	iters: 2300, epoch: 3 | loss: 0.0080694
	speed: 0.1359s/iter; left time: 2601.7501s
	iters: 2400, epoch: 3 | loss: 0.0048762
	speed: 0.1194s/iter; left time: 2274.6516s
	iters: 2500, epoch: 3 | loss: 0.0112840
	speed: 0.1186s/iter; left time: 2247.8425s
	iters: 2600, epoch: 3 | loss: 0.0123261
	speed: 0.1194s/iter; left time: 2250.6599s
Epoch: 3 cost time: 00h:05m:22.63s
Epoch: 3 | Train Loss: 0.0087474 Vali Loss: 0.0099604 Test Loss: 0.0116793
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0085789
	speed: 0.8461s/iter; left time: 15795.8758s
	iters: 200, epoch: 4 | loss: 0.0139824
	speed: 0.1190s/iter; left time: 2210.4174s
	iters: 300, epoch: 4 | loss: 0.0049015
	speed: 0.1203s/iter; left time: 2221.8464s
	iters: 400, epoch: 4 | loss: 0.0097717
	speed: 0.1194s/iter; left time: 2192.3090s
	iters: 500, epoch: 4 | loss: 0.0062868
	speed: 0.1190s/iter; left time: 2174.3231s
	iters: 600, epoch: 4 | loss: 0.0052928
	speed: 0.1199s/iter; left time: 2179.1452s
	iters: 700, epoch: 4 | loss: 0.0079444
	speed: 0.1200s/iter; left time: 2168.1768s
	iters: 800, epoch: 4 | loss: 0.0084604
	speed: 0.1192s/iter; left time: 2141.3376s
	iters: 900, epoch: 4 | loss: 0.0061194
	speed: 0.1226s/iter; left time: 2189.8917s
	iters: 1000, epoch: 4 | loss: 0.0085348
	speed: 0.1193s/iter; left time: 2119.8731s
	iters: 1100, epoch: 4 | loss: 0.0092854
	speed: 0.1204s/iter; left time: 2126.7613s
	iters: 1200, epoch: 4 | loss: 0.0093839
	speed: 0.1192s/iter; left time: 2094.5767s
	iters: 1300, epoch: 4 | loss: 0.0080101
	speed: 0.1201s/iter; left time: 2097.5708s
	iters: 1400, epoch: 4 | loss: 0.0062446
	speed: 0.1191s/iter; left time: 2067.8797s
	iters: 1500, epoch: 4 | loss: 0.0097147
	speed: 0.1179s/iter; left time: 2036.0572s
	iters: 1600, epoch: 4 | loss: 0.0088930
	speed: 0.1197s/iter; left time: 2055.5062s
	iters: 1700, epoch: 4 | loss: 0.0071742
	speed: 0.1206s/iter; left time: 2059.2418s
	iters: 1800, epoch: 4 | loss: 0.0085443
	speed: 0.1220s/iter; left time: 2069.7578s
	iters: 1900, epoch: 4 | loss: 0.0061091
	speed: 0.1205s/iter; left time: 2032.2087s
	iters: 2000, epoch: 4 | loss: 0.0056131
	speed: 0.1194s/iter; left time: 2002.5241s
	iters: 2100, epoch: 4 | loss: 0.0124798
	speed: 0.1196s/iter; left time: 1993.7562s
	iters: 2200, epoch: 4 | loss: 0.0103136
	speed: 0.1199s/iter; left time: 1987.0250s
	iters: 2300, epoch: 4 | loss: 0.0067623
	speed: 0.1195s/iter; left time: 1968.0909s
	iters: 2400, epoch: 4 | loss: 0.0059178
	speed: 0.1193s/iter; left time: 1953.4698s
	iters: 2500, epoch: 4 | loss: 0.0050894
	speed: 0.1214s/iter; left time: 1975.6150s
	iters: 2600, epoch: 4 | loss: 0.0083984
	speed: 0.1205s/iter; left time: 1948.7737s
Epoch: 4 cost time: 00h:05m:21.73s
Epoch: 4 | Train Loss: 0.0084747 Vali Loss: 0.0094833 Test Loss: 0.0110422
Validation loss decreased (0.009682 --> 0.009483).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0082026
	speed: 0.8559s/iter; left time: 13682.8304s
	iters: 200, epoch: 5 | loss: 0.0066821
	speed: 0.1188s/iter; left time: 1887.1593s
	iters: 300, epoch: 5 | loss: 0.0117661
	speed: 0.1211s/iter; left time: 1911.7179s
	iters: 400, epoch: 5 | loss: 0.0055167
	speed: 0.1187s/iter; left time: 1862.1305s
	iters: 500, epoch: 5 | loss: 0.0147786
	speed: 0.1185s/iter; left time: 1846.6278s
	iters: 600, epoch: 5 | loss: 0.0090691
	speed: 0.1195s/iter; left time: 1851.4253s
	iters: 700, epoch: 5 | loss: 0.0085299
	speed: 0.1189s/iter; left time: 1830.1970s
	iters: 800, epoch: 5 | loss: 0.0092835
	speed: 0.1183s/iter; left time: 1808.5057s
	iters: 900, epoch: 5 | loss: 0.0144290
	speed: 0.1186s/iter; left time: 1801.7886s
	iters: 1000, epoch: 5 | loss: 0.0057977
	speed: 0.1187s/iter; left time: 1790.5969s
	iters: 1100, epoch: 5 | loss: 0.0072538
	speed: 0.1189s/iter; left time: 1782.6373s
	iters: 1200, epoch: 5 | loss: 0.0055248
	speed: 0.1185s/iter; left time: 1763.8397s
	iters: 1300, epoch: 5 | loss: 0.0123671
	speed: 0.1174s/iter; left time: 1735.6951s
	iters: 1400, epoch: 5 | loss: 0.0067170
	speed: 0.1153s/iter; left time: 1692.7462s
	iters: 1500, epoch: 5 | loss: 0.0113062
	speed: 0.1174s/iter; left time: 1712.5350s
	iters: 1600, epoch: 5 | loss: 0.0062030
	speed: 0.1183s/iter; left time: 1713.4916s
	iters: 1700, epoch: 5 | loss: 0.0073668
	speed: 0.1207s/iter; left time: 1736.2221s
	iters: 1800, epoch: 5 | loss: 0.0072769
	speed: 0.1213s/iter; left time: 1733.6664s
	iters: 1900, epoch: 5 | loss: 0.0128810
	speed: 0.1191s/iter; left time: 1689.7713s
	iters: 2000, epoch: 5 | loss: 0.0108227
	speed: 0.1186s/iter; left time: 1671.2174s
	iters: 2100, epoch: 5 | loss: 0.0068438
	speed: 0.1189s/iter; left time: 1662.6476s
	iters: 2200, epoch: 5 | loss: 0.0089800
	speed: 0.1190s/iter; left time: 1652.5528s
	iters: 2300, epoch: 5 | loss: 0.0078216
	speed: 0.1176s/iter; left time: 1621.3891s
	iters: 2400, epoch: 5 | loss: 0.0104458
	speed: 0.1185s/iter; left time: 1621.8556s
	iters: 2500, epoch: 5 | loss: 0.0108531
	speed: 0.1195s/iter; left time: 1623.2137s
	iters: 2600, epoch: 5 | loss: 0.0074144
	speed: 0.1185s/iter; left time: 1598.3200s
Epoch: 5 cost time: 00h:05m:18.57s
Epoch: 5 | Train Loss: 0.0081867 Vali Loss: 0.0096661 Test Loss: 0.0112585
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0068791
	speed: 0.8344s/iter; left time: 11102.5269s
	iters: 200, epoch: 6 | loss: 0.0129260
	speed: 0.1185s/iter; left time: 1565.3440s
	iters: 300, epoch: 6 | loss: 0.0127757
	speed: 0.1195s/iter; left time: 1566.2525s
	iters: 400, epoch: 6 | loss: 0.0065614
	speed: 0.1191s/iter; left time: 1549.3013s
	iters: 500, epoch: 6 | loss: 0.0055619
	speed: 0.1183s/iter; left time: 1526.2527s
	iters: 600, epoch: 6 | loss: 0.0065307
	speed: 0.1191s/iter; left time: 1524.8617s
	iters: 700, epoch: 6 | loss: 0.0035814
	speed: 0.1153s/iter; left time: 1465.2353s
	iters: 800, epoch: 6 | loss: 0.0113507
	speed: 0.1168s/iter; left time: 1472.5385s
	iters: 900, epoch: 6 | loss: 0.0102819
	speed: 0.1186s/iter; left time: 1482.9687s
	iters: 1000, epoch: 6 | loss: 0.0124274
	speed: 0.1187s/iter; left time: 1472.2692s
	iters: 1100, epoch: 6 | loss: 0.0075018
	speed: 0.1184s/iter; left time: 1456.8116s
	iters: 1200, epoch: 6 | loss: 0.0114392
	speed: 0.1182s/iter; left time: 1443.2508s
	iters: 1300, epoch: 6 | loss: 0.0065461
	speed: 0.1162s/iter; left time: 1406.4837s
	iters: 1400, epoch: 6 | loss: 0.0055617
	speed: 0.1173s/iter; left time: 1408.8241s
	iters: 1500, epoch: 6 | loss: 0.0098405
	speed: 0.1186s/iter; left time: 1412.2717s
	iters: 1600, epoch: 6 | loss: 0.0102533
	speed: 0.1203s/iter; left time: 1420.3052s
	iters: 1700, epoch: 6 | loss: 0.0054765
	speed: 0.1194s/iter; left time: 1397.7352s
	iters: 1800, epoch: 6 | loss: 0.0106227
	speed: 0.1192s/iter; left time: 1383.4443s
	iters: 1900, epoch: 6 | loss: 0.0062775
	speed: 0.1191s/iter; left time: 1370.6864s
	iters: 2000, epoch: 6 | loss: 0.0068300
	speed: 0.1192s/iter; left time: 1359.5386s
	iters: 2100, epoch: 6 | loss: 0.0078323
	speed: 0.1185s/iter; left time: 1339.1999s
	iters: 2200, epoch: 6 | loss: 0.0088947
	speed: 0.1197s/iter; left time: 1341.3545s
	iters: 2300, epoch: 6 | loss: 0.0041810
	speed: 0.1190s/iter; left time: 1321.3224s
	iters: 2400, epoch: 6 | loss: 0.0048208
	speed: 0.1183s/iter; left time: 1302.0067s
	iters: 2500, epoch: 6 | loss: 0.0056515
	speed: 0.1182s/iter; left time: 1289.5240s
	iters: 2600, epoch: 6 | loss: 0.0076506
	speed: 0.1193s/iter; left time: 1289.1202s
Epoch: 6 cost time: 00h:05m:18.06s
Epoch: 6 | Train Loss: 0.0079494 Vali Loss: 0.0091909 Test Loss: 0.0107529
Validation loss decreased (0.009483 --> 0.009191).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0143468
	speed: 0.8496s/iter; left time: 9026.9684s
	iters: 200, epoch: 7 | loss: 0.0084022
	speed: 0.1189s/iter; left time: 1251.5589s
	iters: 300, epoch: 7 | loss: 0.0066824
	speed: 0.1192s/iter; left time: 1243.0220s
	iters: 400, epoch: 7 | loss: 0.0081792
	speed: 0.1185s/iter; left time: 1223.4369s
	iters: 500, epoch: 7 | loss: 0.0074039
	speed: 0.1192s/iter; left time: 1219.1257s
	iters: 600, epoch: 7 | loss: 0.0060807
	speed: 0.1192s/iter; left time: 1207.0384s
	iters: 700, epoch: 7 | loss: 0.0078752
	speed: 0.1192s/iter; left time: 1195.4552s
	iters: 800, epoch: 7 | loss: 0.0106734
	speed: 0.1194s/iter; left time: 1184.9399s
	iters: 900, epoch: 7 | loss: 0.0053014
	speed: 0.1179s/iter; left time: 1158.7439s
	iters: 1000, epoch: 7 | loss: 0.0093736
	speed: 0.1188s/iter; left time: 1155.7287s
	iters: 1100, epoch: 7 | loss: 0.0074351
	speed: 0.1200s/iter; left time: 1155.3358s
	iters: 1200, epoch: 7 | loss: 0.0103754
	speed: 0.1192s/iter; left time: 1135.5651s
	iters: 1300, epoch: 7 | loss: 0.0050626
	speed: 0.1192s/iter; left time: 1123.3193s
	iters: 1400, epoch: 7 | loss: 0.0063779
	speed: 0.1204s/iter; left time: 1122.4662s
	iters: 1500, epoch: 7 | loss: 0.0081218
	speed: 0.1190s/iter; left time: 1097.3953s
	iters: 1600, epoch: 7 | loss: 0.0084652
	speed: 0.1191s/iter; left time: 1086.8467s
	iters: 1700, epoch: 7 | loss: 0.0063734
	speed: 0.1188s/iter; left time: 1072.5150s
	iters: 1800, epoch: 7 | loss: 0.0070088
	speed: 0.1206s/iter; left time: 1076.3766s
	iters: 1900, epoch: 7 | loss: 0.0081773
	speed: 0.1193s/iter; left time: 1052.6970s
	iters: 2000, epoch: 7 | loss: 0.0104023
	speed: 0.1188s/iter; left time: 1036.7921s
	iters: 2100, epoch: 7 | loss: 0.0082982
	speed: 0.1196s/iter; left time: 1031.4943s
	iters: 2200, epoch: 7 | loss: 0.0080761
	speed: 0.1197s/iter; left time: 1020.2795s
	iters: 2300, epoch: 7 | loss: 0.0103042
	speed: 0.1189s/iter; left time: 1001.7898s
	iters: 2400, epoch: 7 | loss: 0.0109918
	speed: 0.1191s/iter; left time: 991.5219s
	iters: 2500, epoch: 7 | loss: 0.0065413
	speed: 0.1190s/iter; left time: 978.4973s
	iters: 2600, epoch: 7 | loss: 0.0080837
	speed: 0.1189s/iter; left time: 965.9768s
Epoch: 7 cost time: 00h:05m:19.92s
Epoch: 7 | Train Loss: 0.0077676 Vali Loss: 0.0092396 Test Loss: 0.0109264
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0145342
	speed: 0.8430s/iter; left time: 6697.0581s
	iters: 200, epoch: 8 | loss: 0.0050922
	speed: 0.1205s/iter; left time: 944.8156s
	iters: 300, epoch: 8 | loss: 0.0105490
	speed: 0.1194s/iter; left time: 924.6926s
	iters: 400, epoch: 8 | loss: 0.0073536
	speed: 0.1203s/iter; left time: 919.3431s
	iters: 500, epoch: 8 | loss: 0.0075059
	speed: 0.1209s/iter; left time: 912.2485s
	iters: 600, epoch: 8 | loss: 0.0066650
	speed: 0.1198s/iter; left time: 892.0919s
	iters: 700, epoch: 8 | loss: 0.0072620
	speed: 0.1195s/iter; left time: 877.8306s
	iters: 800, epoch: 8 | loss: 0.0089689
	speed: 0.1189s/iter; left time: 861.2522s
	iters: 900, epoch: 8 | loss: 0.0076963
	speed: 0.1198s/iter; left time: 855.7440s
	iters: 1000, epoch: 8 | loss: 0.0081367
	speed: 0.1197s/iter; left time: 843.1442s
	iters: 1100, epoch: 8 | loss: 0.0055714
	speed: 0.1192s/iter; left time: 827.5685s
	iters: 1200, epoch: 8 | loss: 0.0088810
	speed: 0.1194s/iter; left time: 817.4813s
	iters: 1300, epoch: 8 | loss: 0.0076921
	speed: 0.1186s/iter; left time: 799.9099s
	iters: 1400, epoch: 8 | loss: 0.0078052
	speed: 0.1175s/iter; left time: 780.4206s
	iters: 1500, epoch: 8 | loss: 0.0069064
	speed: 0.1194s/iter; left time: 781.4263s
	iters: 1600, epoch: 8 | loss: 0.0089180
	speed: 0.1189s/iter; left time: 766.0942s
	iters: 1700, epoch: 8 | loss: 0.0098277
	speed: 0.1187s/iter; left time: 753.0525s
	iters: 1800, epoch: 8 | loss: 0.0097571
	speed: 0.1201s/iter; left time: 750.0584s
	iters: 1900, epoch: 8 | loss: 0.0076540
	speed: 0.1215s/iter; left time: 746.6747s
	iters: 2000, epoch: 8 | loss: 0.0066878
	speed: 0.1190s/iter; left time: 719.2204s
	iters: 2100, epoch: 8 | loss: 0.0051629
	speed: 0.1197s/iter; left time: 711.5669s
	iters: 2200, epoch: 8 | loss: 0.0060304
	speed: 0.1205s/iter; left time: 704.1403s
	iters: 2300, epoch: 8 | loss: 0.0112157
	speed: 0.1192s/iter; left time: 684.8316s
	iters: 2400, epoch: 8 | loss: 0.0062966
	speed: 0.1190s/iter; left time: 671.8634s
	iters: 2500, epoch: 8 | loss: 0.0067169
	speed: 0.1194s/iter; left time: 661.7387s
	iters: 2600, epoch: 8 | loss: 0.0074308
	speed: 0.1184s/iter; left time: 644.8389s
Epoch: 8 cost time: 00h:05m:20.52s
Epoch: 8 | Train Loss: 0.0076511 Vali Loss: 0.0093917 Test Loss: 0.0110719
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0063627
	speed: 0.8441s/iter; left time: 4442.6898s
	iters: 200, epoch: 9 | loss: 0.0081278
	speed: 0.1177s/iter; left time: 607.8514s
	iters: 300, epoch: 9 | loss: 0.0049066
	speed: 0.1185s/iter; left time: 599.7612s
	iters: 400, epoch: 9 | loss: 0.0069859
	speed: 0.1197s/iter; left time: 594.3020s
	iters: 500, epoch: 9 | loss: 0.0059178
	speed: 0.1193s/iter; left time: 580.1887s
	iters: 600, epoch: 9 | loss: 0.0046414
	speed: 0.1186s/iter; left time: 564.8682s
	iters: 700, epoch: 9 | loss: 0.0070652
	speed: 0.1196s/iter; left time: 557.6605s
	iters: 800, epoch: 9 | loss: 0.0058564
	speed: 0.1193s/iter; left time: 544.3545s
	iters: 900, epoch: 9 | loss: 0.0121706
	speed: 0.1183s/iter; left time: 527.8719s
	iters: 1000, epoch: 9 | loss: 0.0047649
	speed: 0.1185s/iter; left time: 516.9304s
	iters: 1100, epoch: 9 | loss: 0.0070160
	speed: 0.1188s/iter; left time: 506.6098s
	iters: 1200, epoch: 9 | loss: 0.0055626
	speed: 0.1184s/iter; left time: 493.0936s
	iters: 1300, epoch: 9 | loss: 0.0044197
	speed: 0.1185s/iter; left time: 481.4364s
	iters: 1400, epoch: 9 | loss: 0.0083944
	speed: 0.1190s/iter; left time: 471.7193s
	iters: 1500, epoch: 9 | loss: 0.0081034
	speed: 0.1182s/iter; left time: 456.6608s
	iters: 1600, epoch: 9 | loss: 0.0059178
	speed: 0.1175s/iter; left time: 442.1777s
	iters: 1700, epoch: 9 | loss: 0.0043409
	speed: 0.1182s/iter; left time: 433.1121s
	iters: 1800, epoch: 9 | loss: 0.0073731
	speed: 0.1212s/iter; left time: 431.7087s
	iters: 1900, epoch: 9 | loss: 0.0054103
	speed: 0.1190s/iter; left time: 411.9469s
	iters: 2000, epoch: 9 | loss: 0.0077524
	speed: 0.1186s/iter; left time: 398.7655s
	iters: 2100, epoch: 9 | loss: 0.0083913
	speed: 0.1194s/iter; left time: 389.5559s
	iters: 2200, epoch: 9 | loss: 0.0083011
	speed: 0.1179s/iter; left time: 372.8144s
	iters: 2300, epoch: 9 | loss: 0.0051046
	speed: 0.1182s/iter; left time: 362.0299s
	iters: 2400, epoch: 9 | loss: 0.0048293
	speed: 0.1199s/iter; left time: 355.2815s
	iters: 2500, epoch: 9 | loss: 0.0046664
	speed: 0.1185s/iter; left time: 339.2371s
	iters: 2600, epoch: 9 | loss: 0.0062383
	speed: 0.1187s/iter; left time: 327.8890s
Epoch: 9 cost time: 00h:05m:18.70s
Epoch: 9 | Train Loss: 0.0074667 Vali Loss: 0.0092518 Test Loss: 0.0108834
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.010752849280834198, rmse:0.10369594395160675, mae:0.06316586583852768, rse:0.40005412697792053
Intermediate time for FR and pred_len 24: 00h:58m:36.24s

=== Starting experiments for pred_len: 96 ===

--- Running model for FR, pred_len=96 ---
train 85587
val 18435
test 18435
[2024-11-12 19:40:39,903] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 19:40:40,879] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 19:40:40,879] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 19:40:40,879] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 19:40:40,967] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 19:40:40,967] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 19:40:41,421] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 19:40:41,422] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 19:40:41,423] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 19:40:41,424] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 19:40:41,424] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 19:40:41,424] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 19:40:41,424] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 19:40:41,424] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 19:40:41,424] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 19:40:41,424] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 19:40:42,027] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 19:40:42,028] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 19:40:42,042] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 22.2 GB, percent = 2.2%
[2024-11-12 19:40:42,124] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 19:40:42,125] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 19:40:42,125] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 22.2 GB, percent = 2.2%
[2024-11-12 19:40:42,125] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 19:40:42,203] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 19:40:42,203] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 19:40:42,204] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 22.2 GB, percent = 2.2%
[2024-11-12 19:40:42,204] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 19:40:42,204] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 19:40:42,204] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 19:40:42,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 19:40:42,205] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd90533e790>
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 19:40:42,205] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 19:40:42,206] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 19:40:42,206] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0450392
	speed: 0.1628s/iter; left time: 4337.3849s
	iters: 200, epoch: 1 | loss: 0.0411741
	speed: 0.1244s/iter; left time: 3300.7929s
	iters: 300, epoch: 1 | loss: 0.0245169
	speed: 0.1258s/iter; left time: 3327.4208s
	iters: 400, epoch: 1 | loss: 0.0257455
	speed: 0.1253s/iter; left time: 3301.4227s
	iters: 500, epoch: 1 | loss: 0.0221113
	speed: 0.1257s/iter; left time: 3297.9165s
	iters: 600, epoch: 1 | loss: 0.0234084
	speed: 0.1245s/iter; left time: 3254.6448s
	iters: 700, epoch: 1 | loss: 0.0310447
	speed: 0.1262s/iter; left time: 3287.1346s
	iters: 800, epoch: 1 | loss: 0.0166334
	speed: 0.1235s/iter; left time: 3203.8028s
	iters: 900, epoch: 1 | loss: 0.0154001
	speed: 0.1240s/iter; left time: 3204.2683s
	iters: 1000, epoch: 1 | loss: 0.0179012
	speed: 0.1247s/iter; left time: 3210.6706s
	iters: 1100, epoch: 1 | loss: 0.0106971
	speed: 0.1242s/iter; left time: 3184.1694s
	iters: 1200, epoch: 1 | loss: 0.0100931
	speed: 0.1238s/iter; left time: 3161.9546s
	iters: 1300, epoch: 1 | loss: 0.0116561
	speed: 0.1245s/iter; left time: 3168.4548s
	iters: 1400, epoch: 1 | loss: 0.0133071
	speed: 0.1255s/iter; left time: 3181.0361s
	iters: 1500, epoch: 1 | loss: 0.0142755
	speed: 0.1239s/iter; left time: 3126.7784s
	iters: 1600, epoch: 1 | loss: 0.0116211
	speed: 0.1232s/iter; left time: 3096.3543s
	iters: 1700, epoch: 1 | loss: 0.0150364
	speed: 0.1234s/iter; left time: 3089.1415s
	iters: 1800, epoch: 1 | loss: 0.0159214
	speed: 0.1254s/iter; left time: 3127.7773s
	iters: 1900, epoch: 1 | loss: 0.0203218
	speed: 0.1258s/iter; left time: 3125.5841s
	iters: 2000, epoch: 1 | loss: 0.0085747
	speed: 0.1253s/iter; left time: 3098.9239s
	iters: 2100, epoch: 1 | loss: 0.0166121
	speed: 0.1238s/iter; left time: 3049.8196s
	iters: 2200, epoch: 1 | loss: 0.0126489
	speed: 0.1253s/iter; left time: 3074.8359s
	iters: 2300, epoch: 1 | loss: 0.0141676
	speed: 0.1229s/iter; left time: 3002.9730s
	iters: 2400, epoch: 1 | loss: 0.0099115
	speed: 0.1246s/iter; left time: 3033.5939s
	iters: 2500, epoch: 1 | loss: 0.0119989
	speed: 0.1251s/iter; left time: 3031.5260s
	iters: 2600, epoch: 1 | loss: 0.0158081
	speed: 0.1256s/iter; left time: 3031.9404s
Epoch: 1 cost time: 00h:05m:34.44s
Epoch: 1 | Train Loss: 0.0189805 Vali Loss: 0.0153633 Test Loss: 0.0191843
Validation loss decreased (inf --> 0.015363).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0158058
	speed: 0.8957s/iter; left time: 21466.6493s
	iters: 200, epoch: 2 | loss: 0.0109375
	speed: 0.1195s/iter; left time: 2851.1903s
	iters: 300, epoch: 2 | loss: 0.0166918
	speed: 0.1208s/iter; left time: 2870.7968s
	iters: 400, epoch: 2 | loss: 0.0167429
	speed: 0.1210s/iter; left time: 2862.8784s
	iters: 500, epoch: 2 | loss: 0.0134452
	speed: 0.1213s/iter; left time: 2857.5218s
	iters: 600, epoch: 2 | loss: 0.0162765
	speed: 0.1209s/iter; left time: 2836.9441s
	iters: 700, epoch: 2 | loss: 0.0107006
	speed: 0.1183s/iter; left time: 2764.1770s
	iters: 800, epoch: 2 | loss: 0.0130153
	speed: 0.1187s/iter; left time: 2762.3340s
	iters: 900, epoch: 2 | loss: 0.0123563
	speed: 0.1195s/iter; left time: 2767.6794s
	iters: 1000, epoch: 2 | loss: 0.0131076
	speed: 0.1212s/iter; left time: 2796.8612s
	iters: 1100, epoch: 2 | loss: 0.0114845
	speed: 0.1203s/iter; left time: 2762.5459s
	iters: 1200, epoch: 2 | loss: 0.0235055
	speed: 0.1201s/iter; left time: 2745.4787s
	iters: 1300, epoch: 2 | loss: 0.0117841
	speed: 0.1203s/iter; left time: 2739.8163s
	iters: 1400, epoch: 2 | loss: 0.0162855
	speed: 0.1206s/iter; left time: 2732.7811s
	iters: 1500, epoch: 2 | loss: 0.0190913
	speed: 0.1190s/iter; left time: 2684.4730s
	iters: 1600, epoch: 2 | loss: 0.0117552
	speed: 0.1207s/iter; left time: 2711.1629s
	iters: 1700, epoch: 2 | loss: 0.0112715
	speed: 0.1199s/iter; left time: 2682.6962s
	iters: 1800, epoch: 2 | loss: 0.0119107
	speed: 0.1213s/iter; left time: 2700.6043s
	iters: 1900, epoch: 2 | loss: 0.0103170
	speed: 0.1187s/iter; left time: 2631.8887s
	iters: 2000, epoch: 2 | loss: 0.0100007
	speed: 0.1182s/iter; left time: 2607.4691s
	iters: 2100, epoch: 2 | loss: 0.0131170
	speed: 0.1200s/iter; left time: 2635.7590s
	iters: 2200, epoch: 2 | loss: 0.0085825
	speed: 0.1189s/iter; left time: 2599.3641s
	iters: 2300, epoch: 2 | loss: 0.0119522
	speed: 0.1175s/iter; left time: 2557.4687s
	iters: 2400, epoch: 2 | loss: 0.0139331
	speed: 0.1212s/iter; left time: 2626.0874s
	iters: 2500, epoch: 2 | loss: 0.0112488
	speed: 0.1196s/iter; left time: 2578.9247s
	iters: 2600, epoch: 2 | loss: 0.0097716
	speed: 0.1191s/iter; left time: 2556.3474s
Epoch: 2 cost time: 00h:05m:20.74s
Epoch: 2 | Train Loss: 0.0127849 Vali Loss: 0.0151459 Test Loss: 0.0192785
Validation loss decreased (0.015363 --> 0.015146).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0118803
	speed: 0.8360s/iter; left time: 17801.9071s
	iters: 200, epoch: 3 | loss: 0.0101367
	speed: 0.1195s/iter; left time: 2532.5289s
	iters: 300, epoch: 3 | loss: 0.0121341
	speed: 0.1211s/iter; left time: 2554.5729s
	iters: 400, epoch: 3 | loss: 0.0125734
	speed: 0.1207s/iter; left time: 2534.8409s
	iters: 500, epoch: 3 | loss: 0.0117910
	speed: 0.1201s/iter; left time: 2509.0806s
	iters: 600, epoch: 3 | loss: 0.0094285
	speed: 0.1207s/iter; left time: 2509.3871s
	iters: 700, epoch: 3 | loss: 0.0180131
	speed: 0.1199s/iter; left time: 2481.9053s
	iters: 800, epoch: 3 | loss: 0.0114065
	speed: 0.1212s/iter; left time: 2495.3422s
	iters: 900, epoch: 3 | loss: 0.0092815
	speed: 0.1209s/iter; left time: 2477.0132s
	iters: 1000, epoch: 3 | loss: 0.0106002
	speed: 0.1188s/iter; left time: 2423.3346s
	iters: 1100, epoch: 3 | loss: 0.0078716
	speed: 0.1182s/iter; left time: 2398.5532s
	iters: 1200, epoch: 3 | loss: 0.0125098
	speed: 0.1181s/iter; left time: 2385.2883s
	iters: 1300, epoch: 3 | loss: 0.0134287
	speed: 0.1183s/iter; left time: 2377.3831s
	iters: 1400, epoch: 3 | loss: 0.0103850
	speed: 0.1179s/iter; left time: 2356.3399s
	iters: 1500, epoch: 3 | loss: 0.0132194
	speed: 0.1173s/iter; left time: 2334.1790s
	iters: 1600, epoch: 3 | loss: 0.0194716
	speed: 0.1182s/iter; left time: 2340.5047s
	iters: 1700, epoch: 3 | loss: 0.0143841
	speed: 0.1184s/iter; left time: 2331.2709s
	iters: 1800, epoch: 3 | loss: 0.0078925
	speed: 0.1182s/iter; left time: 2315.5402s
	iters: 1900, epoch: 3 | loss: 0.0163695
	speed: 0.1187s/iter; left time: 2312.9457s
	iters: 2000, epoch: 3 | loss: 0.0090255
	speed: 0.1179s/iter; left time: 2286.1785s
	iters: 2100, epoch: 3 | loss: 0.0191625
	speed: 0.1171s/iter; left time: 2259.2336s
	iters: 2200, epoch: 3 | loss: 0.0125433
	speed: 0.1187s/iter; left time: 2277.9032s
	iters: 2300, epoch: 3 | loss: 0.0098431
	speed: 0.1177s/iter; left time: 2247.4287s
	iters: 2400, epoch: 3 | loss: 0.0109958
	speed: 0.1177s/iter; left time: 2236.1202s
	iters: 2500, epoch: 3 | loss: 0.0140541
	speed: 0.1177s/iter; left time: 2222.9321s
	iters: 2600, epoch: 3 | loss: 0.0097000
	speed: 0.1176s/iter; left time: 2210.9723s
Epoch: 3 cost time: 00h:05m:18.07s
Epoch: 3 | Train Loss: 0.0120224 Vali Loss: 0.0148805 Test Loss: 0.0193639
Validation loss decreased (0.015146 --> 0.014880).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0104348
	speed: 0.8081s/iter; left time: 15046.3058s
	iters: 200, epoch: 4 | loss: 0.0147447
	speed: 0.1181s/iter; left time: 2186.8513s
	iters: 300, epoch: 4 | loss: 0.0095480
	speed: 0.1179s/iter; left time: 2171.9370s
	iters: 400, epoch: 4 | loss: 0.0170453
	speed: 0.1179s/iter; left time: 2160.2485s
	iters: 500, epoch: 4 | loss: 0.0128944
	speed: 0.1176s/iter; left time: 2142.6745s
	iters: 600, epoch: 4 | loss: 0.0129001
	speed: 0.1180s/iter; left time: 2137.6708s
	iters: 700, epoch: 4 | loss: 0.0104098
	speed: 0.1177s/iter; left time: 2121.1607s
	iters: 800, epoch: 4 | loss: 0.0118125
	speed: 0.1165s/iter; left time: 2087.6058s
	iters: 900, epoch: 4 | loss: 0.0092582
	speed: 0.1174s/iter; left time: 2091.6082s
	iters: 1000, epoch: 4 | loss: 0.0090673
	speed: 0.1178s/iter; left time: 2087.4177s
	iters: 1100, epoch: 4 | loss: 0.0109682
	speed: 0.1176s/iter; left time: 2071.7221s
	iters: 1200, epoch: 4 | loss: 0.0087824
	speed: 0.1177s/iter; left time: 2062.6426s
	iters: 1300, epoch: 4 | loss: 0.0174996
	speed: 0.1181s/iter; left time: 2057.0563s
	iters: 1400, epoch: 4 | loss: 0.0118741
	speed: 0.1180s/iter; left time: 2042.9643s
	iters: 1500, epoch: 4 | loss: 0.0090260
	speed: 0.1178s/iter; left time: 2028.8658s
	iters: 1600, epoch: 4 | loss: 0.0084460
	speed: 0.1180s/iter; left time: 2019.5231s
	iters: 1700, epoch: 4 | loss: 0.0096923
	speed: 0.1156s/iter; left time: 1967.8242s
	iters: 1800, epoch: 4 | loss: 0.0119153
	speed: 0.1165s/iter; left time: 1970.5643s
	iters: 1900, epoch: 4 | loss: 0.0101682
	speed: 0.1158s/iter; left time: 1947.9222s
	iters: 2000, epoch: 4 | loss: 0.0143250
	speed: 0.1175s/iter; left time: 1964.8570s
	iters: 2100, epoch: 4 | loss: 0.0126696
	speed: 0.1188s/iter; left time: 1973.7100s
	iters: 2200, epoch: 4 | loss: 0.0086834
	speed: 0.1182s/iter; left time: 1952.4159s
	iters: 2300, epoch: 4 | loss: 0.0121239
	speed: 0.1185s/iter; left time: 1946.1728s
	iters: 2400, epoch: 4 | loss: 0.0087830
	speed: 0.1201s/iter; left time: 1959.5909s
	iters: 2500, epoch: 4 | loss: 0.0114819
	speed: 0.1184s/iter; left time: 1920.3726s
	iters: 2600, epoch: 4 | loss: 0.0077992
	speed: 0.1179s/iter; left time: 1900.8033s
Epoch: 4 cost time: 00h:05m:15.12s
Epoch: 4 | Train Loss: 0.0113246 Vali Loss: 0.0157741 Test Loss: 0.0208361
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0117146
	speed: 0.7908s/iter; left time: 12609.7681s
	iters: 200, epoch: 5 | loss: 0.0141664
	speed: 0.1180s/iter; left time: 1870.0043s
	iters: 300, epoch: 5 | loss: 0.0105971
	speed: 0.1178s/iter; left time: 1854.9453s
	iters: 400, epoch: 5 | loss: 0.0068634
	speed: 0.1179s/iter; left time: 1843.8859s
	iters: 500, epoch: 5 | loss: 0.0113078
	speed: 0.1178s/iter; left time: 1831.5613s
	iters: 600, epoch: 5 | loss: 0.0122250
	speed: 0.1177s/iter; left time: 1817.7285s
	iters: 700, epoch: 5 | loss: 0.0110457
	speed: 0.1177s/iter; left time: 1806.7614s
	iters: 800, epoch: 5 | loss: 0.0107314
	speed: 0.1177s/iter; left time: 1793.7555s
	iters: 900, epoch: 5 | loss: 0.0124267
	speed: 0.1178s/iter; left time: 1784.0839s
	iters: 1000, epoch: 5 | loss: 0.0073952
	speed: 0.1180s/iter; left time: 1775.4236s
	iters: 1100, epoch: 5 | loss: 0.0145061
	speed: 0.1177s/iter; left time: 1759.5746s
	iters: 1200, epoch: 5 | loss: 0.0089259
	speed: 0.1178s/iter; left time: 1749.2352s
	iters: 1300, epoch: 5 | loss: 0.0098448
	speed: 0.1177s/iter; left time: 1735.5120s
	iters: 1400, epoch: 5 | loss: 0.0111989
	speed: 0.1177s/iter; left time: 1724.3116s
	iters: 1500, epoch: 5 | loss: 0.0060225
	speed: 0.1177s/iter; left time: 1711.8343s
	iters: 1600, epoch: 5 | loss: 0.0105162
	speed: 0.1181s/iter; left time: 1705.8011s
	iters: 1700, epoch: 5 | loss: 0.0075380
	speed: 0.1179s/iter; left time: 1691.7756s
	iters: 1800, epoch: 5 | loss: 0.0110643
	speed: 0.1181s/iter; left time: 1682.7715s
	iters: 1900, epoch: 5 | loss: 0.0108197
	speed: 0.1178s/iter; left time: 1666.7391s
	iters: 2000, epoch: 5 | loss: 0.0077852
	speed: 0.1180s/iter; left time: 1657.2124s
	iters: 2100, epoch: 5 | loss: 0.0108914
	speed: 0.1184s/iter; left time: 1651.3645s
	iters: 2200, epoch: 5 | loss: 0.0142116
	speed: 0.1183s/iter; left time: 1638.1299s
	iters: 2300, epoch: 5 | loss: 0.0143057
	speed: 0.1190s/iter; left time: 1635.7217s
	iters: 2400, epoch: 5 | loss: 0.0085773
	speed: 0.1198s/iter; left time: 1635.0826s
	iters: 2500, epoch: 5 | loss: 0.0131593
	speed: 0.1200s/iter; left time: 1625.4093s
	iters: 2600, epoch: 5 | loss: 0.0088603
	speed: 0.1200s/iter; left time: 1613.7231s
Epoch: 5 cost time: 00h:05m:16.52s
Epoch: 5 | Train Loss: 0.0106526 Vali Loss: 0.0168246 Test Loss: 0.0207549
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0121528
	speed: 0.7919s/iter; left time: 10509.1597s
	iters: 200, epoch: 6 | loss: 0.0100930
	speed: 0.1150s/iter; left time: 1514.1130s
	iters: 300, epoch: 6 | loss: 0.0089551
	speed: 0.1149s/iter; left time: 1502.1871s
	iters: 400, epoch: 6 | loss: 0.0081247
	speed: 0.1150s/iter; left time: 1491.4002s
	iters: 500, epoch: 6 | loss: 0.0075258
	speed: 0.1150s/iter; left time: 1480.1567s
	iters: 600, epoch: 6 | loss: 0.0097040
	speed: 0.1151s/iter; left time: 1469.6264s
	iters: 700, epoch: 6 | loss: 0.0137501
	speed: 0.1164s/iter; left time: 1474.6490s
	iters: 800, epoch: 6 | loss: 0.0117516
	speed: 0.1196s/iter; left time: 1503.2350s
	iters: 900, epoch: 6 | loss: 0.0123034
	speed: 0.1202s/iter; left time: 1498.6262s
	iters: 1000, epoch: 6 | loss: 0.0107576
	speed: 0.1197s/iter; left time: 1480.5264s
	iters: 1100, epoch: 6 | loss: 0.0081077
	speed: 0.1198s/iter; left time: 1469.8049s
	iters: 1200, epoch: 6 | loss: 0.0071426
	speed: 0.1184s/iter; left time: 1440.5441s
	iters: 1300, epoch: 6 | loss: 0.0137052
	speed: 0.1179s/iter; left time: 1423.2973s
	iters: 1400, epoch: 6 | loss: 0.0106240
	speed: 0.1182s/iter; left time: 1414.8075s
	iters: 1500, epoch: 6 | loss: 0.0077702
	speed: 0.1180s/iter; left time: 1401.1017s
	iters: 1600, epoch: 6 | loss: 0.0083429
	speed: 0.1180s/iter; left time: 1389.3397s
	iters: 1700, epoch: 6 | loss: 0.0093484
	speed: 0.1180s/iter; left time: 1377.4317s
	iters: 1800, epoch: 6 | loss: 0.0094698
	speed: 0.1180s/iter; left time: 1365.2938s
	iters: 1900, epoch: 6 | loss: 0.0096716
	speed: 0.1182s/iter; left time: 1356.3881s
	iters: 2000, epoch: 6 | loss: 0.0091432
	speed: 0.1179s/iter; left time: 1340.4306s
	iters: 2100, epoch: 6 | loss: 0.0100183
	speed: 0.1181s/iter; left time: 1331.1194s
	iters: 2200, epoch: 6 | loss: 0.0133788
	speed: 0.1180s/iter; left time: 1317.9794s
	iters: 2300, epoch: 6 | loss: 0.0078084
	speed: 0.1180s/iter; left time: 1305.8324s
	iters: 2400, epoch: 6 | loss: 0.0149702
	speed: 0.1198s/iter; left time: 1313.8929s
	iters: 2500, epoch: 6 | loss: 0.0117440
	speed: 0.1198s/iter; left time: 1302.2538s
	iters: 2600, epoch: 6 | loss: 0.0068400
	speed: 0.1199s/iter; left time: 1291.1852s
Epoch: 6 cost time: 00h:05m:15.28s
Epoch: 6 | Train Loss: 0.0102449 Vali Loss: 0.0165088 Test Loss: 0.0200477
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.019363928586244583, rmse:0.1391543298959732, mae:0.08860348165035248, rse:0.5383290648460388
Intermediate time for FR and pred_len 96: 00h:38m:54.02s

=== Starting experiments for pred_len: 168 ===

--- Running model for FR, pred_len=168 ---
train 85371
val 18219
test 18219
[2024-11-12 20:19:35,003] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 20:19:36,038] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 20:19:36,038] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 20:19:36,038] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 20:19:36,142] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 20:19:36,142] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 20:19:36,991] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 20:19:36,992] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 20:19:36,993] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 20:19:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 20:19:36,994] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 20:19:36,994] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 20:19:36,994] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 20:19:36,994] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 20:19:36,994] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 20:19:36,994] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 20:19:37,295] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 20:19:37,295] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 20:19:37,334] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.45 GB, percent = 2.1%
[2024-11-12 20:19:37,469] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 20:19:37,470] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 20:19:37,470] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.46 GB, percent = 2.1%
[2024-11-12 20:19:37,470] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 20:19:37,592] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 20:19:37,593] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 20:19:37,593] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.46 GB, percent = 2.1%
[2024-11-12 20:19:37,594] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 20:19:37,594] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 20:19:37,594] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 20:19:37,594] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 20:19:37,594] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f20b0ef9010>
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 20:19:37,595] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 20:19:37,596] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 20:19:37,596] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0396952
	speed: 0.1685s/iter; left time: 4477.9704s
	iters: 200, epoch: 1 | loss: 0.0389226
	speed: 0.1247s/iter; left time: 3300.2672s
	iters: 300, epoch: 1 | loss: 0.0310403
	speed: 0.1218s/iter; left time: 3212.3858s
	iters: 400, epoch: 1 | loss: 0.0277982
	speed: 0.1225s/iter; left time: 3218.6011s
	iters: 500, epoch: 1 | loss: 0.0317462
	speed: 0.1225s/iter; left time: 3206.2763s
	iters: 600, epoch: 1 | loss: 0.0256130
	speed: 0.1240s/iter; left time: 3232.8671s
	iters: 700, epoch: 1 | loss: 0.0215947
	speed: 0.1236s/iter; left time: 3210.5235s
	iters: 800, epoch: 1 | loss: 0.0171741
	speed: 0.1232s/iter; left time: 3187.2256s
	iters: 900, epoch: 1 | loss: 0.0206746
	speed: 0.1231s/iter; left time: 3173.2325s
	iters: 1000, epoch: 1 | loss: 0.0213943
	speed: 0.1232s/iter; left time: 3161.8055s
	iters: 1100, epoch: 1 | loss: 0.0193485
	speed: 0.1232s/iter; left time: 3149.6344s
	iters: 1200, epoch: 1 | loss: 0.0158454
	speed: 0.1233s/iter; left time: 3140.2688s
	iters: 1300, epoch: 1 | loss: 0.0171117
	speed: 0.1226s/iter; left time: 3111.1649s
	iters: 1400, epoch: 1 | loss: 0.0130843
	speed: 0.1236s/iter; left time: 3124.2809s
	iters: 1500, epoch: 1 | loss: 0.0180633
	speed: 0.1230s/iter; left time: 3095.2423s
	iters: 1600, epoch: 1 | loss: 0.0168951
	speed: 0.1238s/iter; left time: 3104.2830s
	iters: 1700, epoch: 1 | loss: 0.0139916
	speed: 0.1235s/iter; left time: 3082.7564s
	iters: 1800, epoch: 1 | loss: 0.0174757
	speed: 0.1238s/iter; left time: 3079.1866s
	iters: 1900, epoch: 1 | loss: 0.0154291
	speed: 0.1230s/iter; left time: 3047.2841s
	iters: 2000, epoch: 1 | loss: 0.0142539
	speed: 0.1240s/iter; left time: 3059.4644s
	iters: 2100, epoch: 1 | loss: 0.0161299
	speed: 0.1232s/iter; left time: 3027.4888s
	iters: 2200, epoch: 1 | loss: 0.0133327
	speed: 0.1222s/iter; left time: 2989.6244s
	iters: 2300, epoch: 1 | loss: 0.0161266
	speed: 0.1228s/iter; left time: 2993.8688s
	iters: 2400, epoch: 1 | loss: 0.0131675
	speed: 0.1194s/iter; left time: 2896.9647s
	iters: 2500, epoch: 1 | loss: 0.0135283
	speed: 0.1178s/iter; left time: 2846.9921s
	iters: 2600, epoch: 1 | loss: 0.0187028
	speed: 0.1182s/iter; left time: 2845.4065s
Epoch: 1 cost time: 00h:05m:27.99s
Epoch: 1 | Train Loss: 0.0202631 Vali Loss: 0.0165594 Test Loss: 0.0204801
Validation loss decreased (inf --> 0.016559).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0129171
	speed: 0.8516s/iter; left time: 20355.5284s
	iters: 200, epoch: 2 | loss: 0.0131390
	speed: 0.1177s/iter; left time: 2802.3975s
	iters: 300, epoch: 2 | loss: 0.0138626
	speed: 0.1179s/iter; left time: 2795.7981s
	iters: 400, epoch: 2 | loss: 0.0153124
	speed: 0.1207s/iter; left time: 2848.1697s
	iters: 500, epoch: 2 | loss: 0.0152978
	speed: 0.1202s/iter; left time: 2824.2953s
	iters: 600, epoch: 2 | loss: 0.0140348
	speed: 0.1192s/iter; left time: 2789.7276s
	iters: 700, epoch: 2 | loss: 0.0110302
	speed: 0.1192s/iter; left time: 2776.7331s
	iters: 800, epoch: 2 | loss: 0.0132397
	speed: 0.1185s/iter; left time: 2749.8542s
	iters: 900, epoch: 2 | loss: 0.0165772
	speed: 0.1189s/iter; left time: 2746.6931s
	iters: 1000, epoch: 2 | loss: 0.0107874
	speed: 0.1194s/iter; left time: 2746.9823s
	iters: 1100, epoch: 2 | loss: 0.0108129
	speed: 0.1182s/iter; left time: 2707.6997s
	iters: 1200, epoch: 2 | loss: 0.0124151
	speed: 0.1190s/iter; left time: 2712.8458s
	iters: 1300, epoch: 2 | loss: 0.0126634
	speed: 0.1185s/iter; left time: 2691.1953s
	iters: 1400, epoch: 2 | loss: 0.0145478
	speed: 0.1184s/iter; left time: 2676.6090s
	iters: 1500, epoch: 2 | loss: 0.0183479
	speed: 0.1193s/iter; left time: 2684.9241s
	iters: 1600, epoch: 2 | loss: 0.0120110
	speed: 0.1186s/iter; left time: 2656.5862s
	iters: 1700, epoch: 2 | loss: 0.0155398
	speed: 0.1188s/iter; left time: 2648.9310s
	iters: 1800, epoch: 2 | loss: 0.0138124
	speed: 0.1182s/iter; left time: 2625.1133s
	iters: 1900, epoch: 2 | loss: 0.0101457
	speed: 0.1190s/iter; left time: 2629.5281s
	iters: 2000, epoch: 2 | loss: 0.0139180
	speed: 0.1200s/iter; left time: 2641.1108s
	iters: 2100, epoch: 2 | loss: 0.0154408
	speed: 0.1183s/iter; left time: 2590.7665s
	iters: 2200, epoch: 2 | loss: 0.0114625
	speed: 0.1185s/iter; left time: 2584.0049s
	iters: 2300, epoch: 2 | loss: 0.0090657
	speed: 0.1190s/iter; left time: 2583.8454s
	iters: 2400, epoch: 2 | loss: 0.0156299
	speed: 0.1183s/iter; left time: 2555.5540s
	iters: 2500, epoch: 2 | loss: 0.0100604
	speed: 0.1182s/iter; left time: 2541.2647s
	iters: 2600, epoch: 2 | loss: 0.0139504
	speed: 0.1184s/iter; left time: 2533.5534s
Epoch: 2 cost time: 00h:05m:17.00s
Epoch: 2 | Train Loss: 0.0138196 Vali Loss: 0.0159975 Test Loss: 0.0202182
Validation loss decreased (0.016559 --> 0.015998).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0114765
	speed: 0.8033s/iter; left time: 17058.8026s
	iters: 200, epoch: 3 | loss: 0.0066154
	speed: 0.1165s/iter; left time: 2462.7286s
	iters: 300, epoch: 3 | loss: 0.0107835
	speed: 0.1177s/iter; left time: 2477.0272s
	iters: 400, epoch: 3 | loss: 0.0146891
	speed: 0.1174s/iter; left time: 2459.0399s
	iters: 500, epoch: 3 | loss: 0.0108149
	speed: 0.1184s/iter; left time: 2466.6896s
	iters: 600, epoch: 3 | loss: 0.0132746
	speed: 0.1178s/iter; left time: 2443.2844s
	iters: 700, epoch: 3 | loss: 0.0123814
	speed: 0.1178s/iter; left time: 2430.7580s
	iters: 800, epoch: 3 | loss: 0.0191005
	speed: 0.1166s/iter; left time: 2395.1066s
	iters: 900, epoch: 3 | loss: 0.0097550
	speed: 0.1178s/iter; left time: 2406.7074s
	iters: 1000, epoch: 3 | loss: 0.0135984
	speed: 0.1189s/iter; left time: 2418.1158s
	iters: 1100, epoch: 3 | loss: 0.0107341
	speed: 0.1182s/iter; left time: 2392.1066s
	iters: 1200, epoch: 3 | loss: 0.0200791
	speed: 0.1186s/iter; left time: 2388.2466s
	iters: 1300, epoch: 3 | loss: 0.0127794
	speed: 0.1182s/iter; left time: 2367.5918s
	iters: 1400, epoch: 3 | loss: 0.0146894
	speed: 0.1184s/iter; left time: 2360.9638s
	iters: 1500, epoch: 3 | loss: 0.0103463
	speed: 0.1183s/iter; left time: 2346.0991s
	iters: 1600, epoch: 3 | loss: 0.0168719
	speed: 0.1185s/iter; left time: 2338.2357s
	iters: 1700, epoch: 3 | loss: 0.0171323
	speed: 0.1182s/iter; left time: 2320.2419s
	iters: 1800, epoch: 3 | loss: 0.0145011
	speed: 0.1181s/iter; left time: 2306.5821s
	iters: 1900, epoch: 3 | loss: 0.0188756
	speed: 0.1189s/iter; left time: 2310.8129s
	iters: 2000, epoch: 3 | loss: 0.0091586
	speed: 0.1183s/iter; left time: 2287.9680s
	iters: 2100, epoch: 3 | loss: 0.0192016
	speed: 0.1181s/iter; left time: 2272.7466s
	iters: 2200, epoch: 3 | loss: 0.0112405
	speed: 0.1181s/iter; left time: 2260.4885s
	iters: 2300, epoch: 3 | loss: 0.0101469
	speed: 0.1168s/iter; left time: 2223.0860s
	iters: 2400, epoch: 3 | loss: 0.0168996
	speed: 0.1179s/iter; left time: 2232.1071s
	iters: 2500, epoch: 3 | loss: 0.0111361
	speed: 0.1180s/iter; left time: 2221.9775s
	iters: 2600, epoch: 3 | loss: 0.0105551
	speed: 0.1178s/iter; left time: 2207.1803s
Epoch: 3 cost time: 00h:05m:14.89s
Epoch: 3 | Train Loss: 0.0130641 Vali Loss: 0.0159669 Test Loss: 0.0205408
Validation loss decreased (0.015998 --> 0.015967).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0116718
	speed: 0.7965s/iter; left time: 14791.5457s
	iters: 200, epoch: 4 | loss: 0.0151844
	speed: 0.1156s/iter; left time: 2135.2812s
	iters: 300, epoch: 4 | loss: 0.0079109
	speed: 0.1179s/iter; left time: 2166.5296s
	iters: 400, epoch: 4 | loss: 0.0141269
	speed: 0.1190s/iter; left time: 2174.0490s
	iters: 500, epoch: 4 | loss: 0.0094832
	speed: 0.1177s/iter; left time: 2139.1194s
	iters: 600, epoch: 4 | loss: 0.0137519
	speed: 0.1191s/iter; left time: 2152.7267s
	iters: 700, epoch: 4 | loss: 0.0168084
	speed: 0.1205s/iter; left time: 2165.8159s
	iters: 800, epoch: 4 | loss: 0.0125084
	speed: 0.1180s/iter; left time: 2108.9306s
	iters: 900, epoch: 4 | loss: 0.0086926
	speed: 0.1182s/iter; left time: 2100.3122s
	iters: 1000, epoch: 4 | loss: 0.0132476
	speed: 0.1179s/iter; left time: 2082.4516s
	iters: 1100, epoch: 4 | loss: 0.0159796
	speed: 0.1193s/iter; left time: 2095.5586s
	iters: 1200, epoch: 4 | loss: 0.0104252
	speed: 0.1191s/iter; left time: 2080.2930s
	iters: 1300, epoch: 4 | loss: 0.0091218
	speed: 0.1192s/iter; left time: 2070.1097s
	iters: 1400, epoch: 4 | loss: 0.0086782
	speed: 0.1195s/iter; left time: 2064.1052s
	iters: 1500, epoch: 4 | loss: 0.0108831
	speed: 0.1185s/iter; left time: 2033.9562s
	iters: 1600, epoch: 4 | loss: 0.0112142
	speed: 0.1198s/iter; left time: 2044.2904s
	iters: 1700, epoch: 4 | loss: 0.0103915
	speed: 0.1182s/iter; left time: 2005.0109s
	iters: 1800, epoch: 4 | loss: 0.0119966
	speed: 0.1182s/iter; left time: 1993.8686s
	iters: 1900, epoch: 4 | loss: 0.0121508
	speed: 0.1185s/iter; left time: 1986.5689s
	iters: 2000, epoch: 4 | loss: 0.0122203
	speed: 0.1193s/iter; left time: 1988.6701s
	iters: 2100, epoch: 4 | loss: 0.0186522
	speed: 0.1181s/iter; left time: 1956.3363s
	iters: 2200, epoch: 4 | loss: 0.0069003
	speed: 0.1183s/iter; left time: 1947.8644s
	iters: 2300, epoch: 4 | loss: 0.0162952
	speed: 0.1181s/iter; left time: 1933.7886s
	iters: 2400, epoch: 4 | loss: 0.0083642
	speed: 0.1165s/iter; left time: 1895.7223s
	iters: 2500, epoch: 4 | loss: 0.0148449
	speed: 0.1164s/iter; left time: 1882.9317s
	iters: 2600, epoch: 4 | loss: 0.0146008
	speed: 0.1186s/iter; left time: 1906.0389s
Epoch: 4 cost time: 00h:05m:15.71s
Epoch: 4 | Train Loss: 0.0121474 Vali Loss: 0.0184361 Test Loss: 0.0216450
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0117050
	speed: 0.7876s/iter; left time: 12525.0011s
	iters: 200, epoch: 5 | loss: 0.0124682
	speed: 0.1178s/iter; left time: 1861.8302s
	iters: 300, epoch: 5 | loss: 0.0164941
	speed: 0.1178s/iter; left time: 1850.1476s
	iters: 400, epoch: 5 | loss: 0.0101517
	speed: 0.1181s/iter; left time: 1842.8756s
	iters: 500, epoch: 5 | loss: 0.0105157
	speed: 0.1183s/iter; left time: 1833.2692s
	iters: 600, epoch: 5 | loss: 0.0126912
	speed: 0.1177s/iter; left time: 1813.5357s
	iters: 700, epoch: 5 | loss: 0.0112557
	speed: 0.1177s/iter; left time: 1800.6878s
	iters: 800, epoch: 5 | loss: 0.0098161
	speed: 0.1177s/iter; left time: 1789.8621s
	iters: 900, epoch: 5 | loss: 0.0123347
	speed: 0.1178s/iter; left time: 1778.6737s
	iters: 1000, epoch: 5 | loss: 0.0095558
	speed: 0.1177s/iter; left time: 1765.2888s
	iters: 1100, epoch: 5 | loss: 0.0113308
	speed: 0.1170s/iter; left time: 1744.0548s
	iters: 1200, epoch: 5 | loss: 0.0097510
	speed: 0.1179s/iter; left time: 1745.5381s
	iters: 1300, epoch: 5 | loss: 0.0127526
	speed: 0.1184s/iter; left time: 1741.5237s
	iters: 1400, epoch: 5 | loss: 0.0135294
	speed: 0.1185s/iter; left time: 1730.5548s
	iters: 1500, epoch: 5 | loss: 0.0099966
	speed: 0.1188s/iter; left time: 1723.0880s
	iters: 1600, epoch: 5 | loss: 0.0116613
	speed: 0.1182s/iter; left time: 1701.8966s
	iters: 1700, epoch: 5 | loss: 0.0098514
	speed: 0.1178s/iter; left time: 1685.1197s
	iters: 1800, epoch: 5 | loss: 0.0152843
	speed: 0.1179s/iter; left time: 1674.2915s
	iters: 1900, epoch: 5 | loss: 0.0102675
	speed: 0.1191s/iter; left time: 1679.0493s
	iters: 2000, epoch: 5 | loss: 0.0063129
	speed: 0.1187s/iter; left time: 1661.9780s
	iters: 2100, epoch: 5 | loss: 0.0110215
	speed: 0.1187s/iter; left time: 1649.6010s
	iters: 2200, epoch: 5 | loss: 0.0123013
	speed: 0.1182s/iter; left time: 1631.2583s
	iters: 2300, epoch: 5 | loss: 0.0091697
	speed: 0.1186s/iter; left time: 1624.8205s
	iters: 2400, epoch: 5 | loss: 0.0125893
	speed: 0.1181s/iter; left time: 1606.4311s
	iters: 2500, epoch: 5 | loss: 0.0099446
	speed: 0.1163s/iter; left time: 1570.7085s
	iters: 2600, epoch: 5 | loss: 0.0099037
	speed: 0.1176s/iter; left time: 1576.6022s
Epoch: 5 cost time: 00h:05m:14.95s
Epoch: 5 | Train Loss: 0.0112968 Vali Loss: 0.0192150 Test Loss: 0.0222385
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0083948
	speed: 0.7934s/iter; left time: 10500.7879s
	iters: 200, epoch: 6 | loss: 0.0114102
	speed: 0.1178s/iter; left time: 1547.9484s
	iters: 300, epoch: 6 | loss: 0.0126769
	speed: 0.1183s/iter; left time: 1542.1948s
	iters: 400, epoch: 6 | loss: 0.0070735
	speed: 0.1183s/iter; left time: 1530.3602s
	iters: 500, epoch: 6 | loss: 0.0132286
	speed: 0.1182s/iter; left time: 1516.9562s
	iters: 600, epoch: 6 | loss: 0.0129638
	speed: 0.1181s/iter; left time: 1504.6649s
	iters: 700, epoch: 6 | loss: 0.0114016
	speed: 0.1185s/iter; left time: 1497.4432s
	iters: 800, epoch: 6 | loss: 0.0118810
	speed: 0.1184s/iter; left time: 1484.0799s
	iters: 900, epoch: 6 | loss: 0.0099573
	speed: 0.1183s/iter; left time: 1470.6660s
	iters: 1000, epoch: 6 | loss: 0.0111742
	speed: 0.1184s/iter; left time: 1460.9898s
	iters: 1100, epoch: 6 | loss: 0.0098476
	speed: 0.1197s/iter; left time: 1464.6604s
	iters: 1200, epoch: 6 | loss: 0.0120334
	speed: 0.1181s/iter; left time: 1432.9069s
	iters: 1300, epoch: 6 | loss: 0.0091077
	speed: 0.1157s/iter; left time: 1392.5772s
	iters: 1400, epoch: 6 | loss: 0.0091187
	speed: 0.1174s/iter; left time: 1401.0206s
	iters: 1500, epoch: 6 | loss: 0.0132843
	speed: 0.1196s/iter; left time: 1415.8919s
	iters: 1600, epoch: 6 | loss: 0.0111342
	speed: 0.1188s/iter; left time: 1393.9551s
	iters: 1700, epoch: 6 | loss: 0.0126997
	speed: 0.1187s/iter; left time: 1381.5333s
	iters: 1800, epoch: 6 | loss: 0.0110824
	speed: 0.1188s/iter; left time: 1370.5389s
	iters: 1900, epoch: 6 | loss: 0.0110937
	speed: 0.1182s/iter; left time: 1352.2722s
	iters: 2000, epoch: 6 | loss: 0.0125104
	speed: 0.1193s/iter; left time: 1352.3544s
	iters: 2100, epoch: 6 | loss: 0.0105919
	speed: 0.1187s/iter; left time: 1333.8035s
	iters: 2200, epoch: 6 | loss: 0.0128826
	speed: 0.1189s/iter; left time: 1323.7300s
	iters: 2300, epoch: 6 | loss: 0.0118229
	speed: 0.1187s/iter; left time: 1309.4344s
	iters: 2400, epoch: 6 | loss: 0.0080874
	speed: 0.1182s/iter; left time: 1293.0923s
	iters: 2500, epoch: 6 | loss: 0.0096906
	speed: 0.1186s/iter; left time: 1284.9719s
	iters: 2600, epoch: 6 | loss: 0.0080078
	speed: 0.1190s/iter; left time: 1277.0896s
Epoch: 6 cost time: 00h:05m:16.11s
Epoch: 6 | Train Loss: 0.0105383 Vali Loss: 0.0200892 Test Loss: 0.0229573
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.02054085023701191, rmse:0.14332079887390137, mae:0.092493437230587, rse:0.5552412271499634
Intermediate time for FR and pred_len 168: 00h:38m:38.62s
Intermediate time for FR: 02h:16m:08.88s

=== Starting experiments for country: IT ===

=== Starting experiments for pred_len: 24 ===

--- Running model for IT, pred_len=24 ---
train 85803
val 18651
test 18651
[2024-11-12 20:58:11,723] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 20:58:12,747] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 20:58:12,747] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 20:58:12,747] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 20:58:12,860] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 20:58:12,860] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 20:58:13,309] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 20:58:13,310] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 20:58:13,310] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 20:58:13,311] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 20:58:13,311] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 20:58:13,312] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 20:58:13,312] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 20:58:13,312] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 20:58:13,312] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 20:58:13,312] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 20:58:13,490] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 20:58:13,490] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 20:58:13,514] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.23 GB, percent = 2.1%
[2024-11-12 20:58:13,597] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 20:58:13,597] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 20:58:13,597] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.23 GB, percent = 2.1%
[2024-11-12 20:58:13,598] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 20:58:13,675] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 20:58:13,675] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 20:58:13,675] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.23 GB, percent = 2.1%
[2024-11-12 20:58:13,676] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 20:58:13,676] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 20:58:13,676] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 20:58:13,676] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 20:58:13,676] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdcb1201290>
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 20:58:13,677] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 20:58:13,678] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 20:58:13,678] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0685159
	speed: 0.1554s/iter; left time: 4151.1054s
	iters: 200, epoch: 1 | loss: 0.0538229
	speed: 0.1230s/iter; left time: 3272.3076s
	iters: 300, epoch: 1 | loss: 0.0390279
	speed: 0.1229s/iter; left time: 3257.0245s
	iters: 400, epoch: 1 | loss: 0.0401875
	speed: 0.1228s/iter; left time: 3242.9719s
	iters: 500, epoch: 1 | loss: 0.0369417
	speed: 0.1229s/iter; left time: 3234.6613s
	iters: 600, epoch: 1 | loss: 0.0201956
	speed: 0.1240s/iter; left time: 3250.2776s
	iters: 700, epoch: 1 | loss: 0.0222709
	speed: 0.1232s/iter; left time: 3215.8722s
	iters: 800, epoch: 1 | loss: 0.0147822
	speed: 0.1227s/iter; left time: 3192.3373s
	iters: 900, epoch: 1 | loss: 0.0152446
	speed: 0.1249s/iter; left time: 3236.0705s
	iters: 1000, epoch: 1 | loss: 0.0305286
	speed: 0.1237s/iter; left time: 3191.7944s
	iters: 1100, epoch: 1 | loss: 0.0163214
	speed: 0.1230s/iter; left time: 3163.1207s
	iters: 1200, epoch: 1 | loss: 0.0225284
	speed: 0.1243s/iter; left time: 3182.9806s
	iters: 1300, epoch: 1 | loss: 0.0239459
	speed: 0.1253s/iter; left time: 3196.5962s
	iters: 1400, epoch: 1 | loss: 0.0129569
	speed: 0.1255s/iter; left time: 3187.8977s
	iters: 1500, epoch: 1 | loss: 0.0161033
	speed: 0.1252s/iter; left time: 3169.9240s
	iters: 1600, epoch: 1 | loss: 0.0124472
	speed: 0.1254s/iter; left time: 3162.2742s
	iters: 1700, epoch: 1 | loss: 0.0221302
	speed: 0.1254s/iter; left time: 3148.7033s
	iters: 1800, epoch: 1 | loss: 0.0147295
	speed: 0.1260s/iter; left time: 3150.3607s
	iters: 1900, epoch: 1 | loss: 0.0138965
	speed: 0.1260s/iter; left time: 3139.0637s
	iters: 2000, epoch: 1 | loss: 0.0210741
	speed: 0.1249s/iter; left time: 3099.6419s
	iters: 2100, epoch: 1 | loss: 0.0109980
	speed: 0.1259s/iter; left time: 3111.0640s
	iters: 2200, epoch: 1 | loss: 0.0166170
	speed: 0.1261s/iter; left time: 3103.2336s
	iters: 2300, epoch: 1 | loss: 0.0213830
	speed: 0.1259s/iter; left time: 3085.5705s
	iters: 2400, epoch: 1 | loss: 0.0159447
	speed: 0.1260s/iter; left time: 3076.9058s
	iters: 2500, epoch: 1 | loss: 0.0190932
	speed: 0.1261s/iter; left time: 3066.1934s
	iters: 2600, epoch: 1 | loss: 0.0130107
	speed: 0.1259s/iter; left time: 3047.2841s
Epoch: 1 cost time: 00h:05m:35.03s
Epoch: 1 | Train Loss: 0.0261947 Vali Loss: 0.0112806 Test Loss: 0.0123892
Validation loss decreased (inf --> 0.011281).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0180760
	speed: 0.8937s/iter; left time: 21474.9994s
	iters: 200, epoch: 2 | loss: 0.0170357
	speed: 0.1204s/iter; left time: 2880.4178s
	iters: 300, epoch: 2 | loss: 0.0192865
	speed: 0.1207s/iter; left time: 2875.8773s
	iters: 400, epoch: 2 | loss: 0.0218281
	speed: 0.1189s/iter; left time: 2821.8017s
	iters: 500, epoch: 2 | loss: 0.0176938
	speed: 0.1196s/iter; left time: 2825.8062s
	iters: 600, epoch: 2 | loss: 0.0105074
	speed: 0.1202s/iter; left time: 2828.2062s
	iters: 700, epoch: 2 | loss: 0.0117768
	speed: 0.1201s/iter; left time: 2813.2084s
	iters: 800, epoch: 2 | loss: 0.0202356
	speed: 0.1203s/iter; left time: 2806.8166s
	iters: 900, epoch: 2 | loss: 0.0135544
	speed: 0.1206s/iter; left time: 2801.3560s
	iters: 1000, epoch: 2 | loss: 0.0144304
	speed: 0.1201s/iter; left time: 2778.4250s
	iters: 1100, epoch: 2 | loss: 0.0137108
	speed: 0.1206s/iter; left time: 2777.7409s
	iters: 1200, epoch: 2 | loss: 0.0173497
	speed: 0.1191s/iter; left time: 2730.4346s
	iters: 1300, epoch: 2 | loss: 0.0125586
	speed: 0.1199s/iter; left time: 2736.9054s
	iters: 1400, epoch: 2 | loss: 0.0098957
	speed: 0.1202s/iter; left time: 2731.1818s
	iters: 1500, epoch: 2 | loss: 0.0119272
	speed: 0.1200s/iter; left time: 2715.4306s
	iters: 1600, epoch: 2 | loss: 0.0197336
	speed: 0.1202s/iter; left time: 2708.1449s
	iters: 1700, epoch: 2 | loss: 0.0113639
	speed: 0.1205s/iter; left time: 2703.2397s
	iters: 1800, epoch: 2 | loss: 0.0173805
	speed: 0.1203s/iter; left time: 2685.3732s
	iters: 1900, epoch: 2 | loss: 0.0161114
	speed: 0.1202s/iter; left time: 2671.7260s
	iters: 2000, epoch: 2 | loss: 0.0148994
	speed: 0.1197s/iter; left time: 2648.2162s
	iters: 2100, epoch: 2 | loss: 0.0123345
	speed: 0.1191s/iter; left time: 2623.7329s
	iters: 2200, epoch: 2 | loss: 0.0184167
	speed: 0.1200s/iter; left time: 2630.6261s
	iters: 2300, epoch: 2 | loss: 0.0131563
	speed: 0.1190s/iter; left time: 2597.7941s
	iters: 2400, epoch: 2 | loss: 0.0118702
	speed: 0.1188s/iter; left time: 2580.9865s
	iters: 2500, epoch: 2 | loss: 0.0114197
	speed: 0.1188s/iter; left time: 2570.1727s
	iters: 2600, epoch: 2 | loss: 0.0149896
	speed: 0.1188s/iter; left time: 2558.1333s
Epoch: 2 cost time: 00h:05m:21.46s
Epoch: 2 | Train Loss: 0.0157138 Vali Loss: 0.0104916 Test Loss: 0.0118753
Validation loss decreased (0.011281 --> 0.010492).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0153372
	speed: 0.8314s/iter; left time: 17749.4456s
	iters: 200, epoch: 3 | loss: 0.0124282
	speed: 0.1179s/iter; left time: 2504.3574s
	iters: 300, epoch: 3 | loss: 0.0157643
	speed: 0.1178s/iter; left time: 2491.3909s
	iters: 400, epoch: 3 | loss: 0.0142025
	speed: 0.1183s/iter; left time: 2489.7729s
	iters: 500, epoch: 3 | loss: 0.0147544
	speed: 0.1187s/iter; left time: 2487.1174s
	iters: 600, epoch: 3 | loss: 0.0149589
	speed: 0.1190s/iter; left time: 2480.6781s
	iters: 700, epoch: 3 | loss: 0.0128942
	speed: 0.1187s/iter; left time: 2463.9090s
	iters: 800, epoch: 3 | loss: 0.0125250
	speed: 0.1179s/iter; left time: 2434.6541s
	iters: 900, epoch: 3 | loss: 0.0136606
	speed: 0.1181s/iter; left time: 2426.5778s
	iters: 1000, epoch: 3 | loss: 0.0145725
	speed: 0.1180s/iter; left time: 2413.5385s
	iters: 1100, epoch: 3 | loss: 0.0148923
	speed: 0.1192s/iter; left time: 2425.4421s
	iters: 1200, epoch: 3 | loss: 0.0150868
	speed: 0.1198s/iter; left time: 2425.8863s
	iters: 1300, epoch: 3 | loss: 0.0126438
	speed: 0.1196s/iter; left time: 2409.2322s
	iters: 1400, epoch: 3 | loss: 0.0156644
	speed: 0.1182s/iter; left time: 2370.7402s
	iters: 1500, epoch: 3 | loss: 0.0119611
	speed: 0.1196s/iter; left time: 2385.4826s
	iters: 1600, epoch: 3 | loss: 0.0131140
	speed: 0.1193s/iter; left time: 2367.4778s
	iters: 1700, epoch: 3 | loss: 0.0125348
	speed: 0.1179s/iter; left time: 2327.5777s
	iters: 1800, epoch: 3 | loss: 0.0107881
	speed: 0.1179s/iter; left time: 2315.9244s
	iters: 1900, epoch: 3 | loss: 0.0143829
	speed: 0.1180s/iter; left time: 2307.5371s
	iters: 2000, epoch: 3 | loss: 0.0107815
	speed: 0.1179s/iter; left time: 2292.1191s
	iters: 2100, epoch: 3 | loss: 0.0135317
	speed: 0.1181s/iter; left time: 2284.4862s
	iters: 2200, epoch: 3 | loss: 0.0147034
	speed: 0.1184s/iter; left time: 2279.9223s
	iters: 2300, epoch: 3 | loss: 0.0107541
	speed: 0.1177s/iter; left time: 2254.4099s
	iters: 2400, epoch: 3 | loss: 0.0142104
	speed: 0.1199s/iter; left time: 2283.8968s
	iters: 2500, epoch: 3 | loss: 0.0132395
	speed: 0.1198s/iter; left time: 2269.6824s
	iters: 2600, epoch: 3 | loss: 0.0184456
	speed: 0.1200s/iter; left time: 2261.0284s
Epoch: 3 cost time: 00h:05m:18.55s
Epoch: 3 | Train Loss: 0.0147667 Vali Loss: 0.0100522 Test Loss: 0.0114825
Validation loss decreased (0.010492 --> 0.010052).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0118942
	speed: 0.8253s/iter; left time: 15406.7826s
	iters: 200, epoch: 4 | loss: 0.0180542
	speed: 0.1200s/iter; left time: 2228.7729s
	iters: 300, epoch: 4 | loss: 0.0142920
	speed: 0.1201s/iter; left time: 2218.4380s
	iters: 400, epoch: 4 | loss: 0.0160521
	speed: 0.1200s/iter; left time: 2204.6821s
	iters: 500, epoch: 4 | loss: 0.0134479
	speed: 0.1202s/iter; left time: 2194.9311s
	iters: 600, epoch: 4 | loss: 0.0134335
	speed: 0.1202s/iter; left time: 2183.9542s
	iters: 700, epoch: 4 | loss: 0.0118842
	speed: 0.1189s/iter; left time: 2147.5954s
	iters: 800, epoch: 4 | loss: 0.0208306
	speed: 0.1200s/iter; left time: 2156.3645s
	iters: 900, epoch: 4 | loss: 0.0112594
	speed: 0.1205s/iter; left time: 2152.4081s
	iters: 1000, epoch: 4 | loss: 0.0140814
	speed: 0.1205s/iter; left time: 2140.4335s
	iters: 1100, epoch: 4 | loss: 0.0124276
	speed: 0.1205s/iter; left time: 2128.1858s
	iters: 1200, epoch: 4 | loss: 0.0146648
	speed: 0.1202s/iter; left time: 2111.1394s
	iters: 1300, epoch: 4 | loss: 0.0163111
	speed: 0.1205s/iter; left time: 2104.1059s
	iters: 1400, epoch: 4 | loss: 0.0085672
	speed: 0.1207s/iter; left time: 2095.9538s
	iters: 1500, epoch: 4 | loss: 0.0122171
	speed: 0.1188s/iter; left time: 2052.2739s
	iters: 1600, epoch: 4 | loss: 0.0151807
	speed: 0.1197s/iter; left time: 2054.4962s
	iters: 1700, epoch: 4 | loss: 0.0155126
	speed: 0.1205s/iter; left time: 2057.1456s
	iters: 1800, epoch: 4 | loss: 0.0173740
	speed: 0.1206s/iter; left time: 2046.1838s
	iters: 1900, epoch: 4 | loss: 0.0195048
	speed: 0.1206s/iter; left time: 2034.5439s
	iters: 2000, epoch: 4 | loss: 0.0105157
	speed: 0.1205s/iter; left time: 2021.3755s
	iters: 2100, epoch: 4 | loss: 0.0181404
	speed: 0.1205s/iter; left time: 2008.0910s
	iters: 2200, epoch: 4 | loss: 0.0115145
	speed: 0.1209s/iter; left time: 2003.7059s
	iters: 2300, epoch: 4 | loss: 0.0101383
	speed: 0.1203s/iter; left time: 1980.7197s
	iters: 2400, epoch: 4 | loss: 0.0154869
	speed: 0.1183s/iter; left time: 1936.8589s
	iters: 2500, epoch: 4 | loss: 0.0147908
	speed: 0.1199s/iter; left time: 1950.6263s
	iters: 2600, epoch: 4 | loss: 0.0160828
	speed: 0.1202s/iter; left time: 1942.8396s
Epoch: 4 cost time: 00h:05m:22.14s
Epoch: 4 | Train Loss: 0.0141236 Vali Loss: 0.0095772 Test Loss: 0.0109636
Validation loss decreased (0.010052 --> 0.009577).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0147402
	speed: 0.8261s/iter; left time: 13206.3729s
	iters: 200, epoch: 5 | loss: 0.0125004
	speed: 0.1203s/iter; left time: 1910.5542s
	iters: 300, epoch: 5 | loss: 0.0193345
	speed: 0.1202s/iter; left time: 1897.8378s
	iters: 400, epoch: 5 | loss: 0.0155532
	speed: 0.1202s/iter; left time: 1886.0482s
	iters: 500, epoch: 5 | loss: 0.0122477
	speed: 0.1200s/iter; left time: 1870.1009s
	iters: 600, epoch: 5 | loss: 0.0131593
	speed: 0.1202s/iter; left time: 1861.4496s
	iters: 700, epoch: 5 | loss: 0.0101924
	speed: 0.1202s/iter; left time: 1848.8866s
	iters: 800, epoch: 5 | loss: 0.0183173
	speed: 0.1210s/iter; left time: 1849.1986s
	iters: 900, epoch: 5 | loss: 0.0157056
	speed: 0.1192s/iter; left time: 1810.6653s
	iters: 1000, epoch: 5 | loss: 0.0098225
	speed: 0.1204s/iter; left time: 1816.7627s
	iters: 1100, epoch: 5 | loss: 0.0163749
	speed: 0.1206s/iter; left time: 1806.7866s
	iters: 1200, epoch: 5 | loss: 0.0121770
	speed: 0.1204s/iter; left time: 1792.2976s
	iters: 1300, epoch: 5 | loss: 0.0124330
	speed: 0.1205s/iter; left time: 1781.2798s
	iters: 1400, epoch: 5 | loss: 0.0112678
	speed: 0.1204s/iter; left time: 1767.8343s
	iters: 1500, epoch: 5 | loss: 0.0169907
	speed: 0.1204s/iter; left time: 1755.5591s
	iters: 1600, epoch: 5 | loss: 0.0119197
	speed: 0.1200s/iter; left time: 1739.0957s
	iters: 1700, epoch: 5 | loss: 0.0173833
	speed: 0.1189s/iter; left time: 1710.4743s
	iters: 1800, epoch: 5 | loss: 0.0114593
	speed: 0.1208s/iter; left time: 1725.9493s
	iters: 1900, epoch: 5 | loss: 0.0092829
	speed: 0.1204s/iter; left time: 1708.1171s
	iters: 2000, epoch: 5 | loss: 0.0180667
	speed: 0.1204s/iter; left time: 1695.6895s
	iters: 2100, epoch: 5 | loss: 0.0138387
	speed: 0.1208s/iter; left time: 1689.1067s
	iters: 2200, epoch: 5 | loss: 0.0123920
	speed: 0.1210s/iter; left time: 1680.3552s
	iters: 2300, epoch: 5 | loss: 0.0184100
	speed: 0.1206s/iter; left time: 1663.3467s
	iters: 2400, epoch: 5 | loss: 0.0186482
	speed: 0.1205s/iter; left time: 1649.7610s
	iters: 2500, epoch: 5 | loss: 0.0142829
	speed: 0.1192s/iter; left time: 1618.8911s
	iters: 2600, epoch: 5 | loss: 0.0095593
	speed: 0.1195s/iter; left time: 1611.4371s
Epoch: 5 cost time: 00h:05m:22.66s
Epoch: 5 | Train Loss: 0.0137007 Vali Loss: 0.0093594 Test Loss: 0.0110088
Validation loss decreased (0.009577 --> 0.009359).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0162855
	speed: 0.8323s/iter; left time: 11074.0988s
	iters: 200, epoch: 6 | loss: 0.0118459
	speed: 0.1193s/iter; left time: 1574.9906s
	iters: 300, epoch: 6 | loss: 0.0183465
	speed: 0.1200s/iter; left time: 1573.2081s
	iters: 400, epoch: 6 | loss: 0.0150153
	speed: 0.1202s/iter; left time: 1563.5565s
	iters: 500, epoch: 6 | loss: 0.0135609
	speed: 0.1201s/iter; left time: 1550.5209s
	iters: 600, epoch: 6 | loss: 0.0151215
	speed: 0.1200s/iter; left time: 1537.0412s
	iters: 700, epoch: 6 | loss: 0.0136610
	speed: 0.1201s/iter; left time: 1525.4068s
	iters: 800, epoch: 6 | loss: 0.0088490
	speed: 0.1200s/iter; left time: 1513.1624s
	iters: 900, epoch: 6 | loss: 0.0130130
	speed: 0.1203s/iter; left time: 1504.0797s
	iters: 1000, epoch: 6 | loss: 0.0120274
	speed: 0.1192s/iter; left time: 1478.2945s
	iters: 1100, epoch: 6 | loss: 0.0119894
	speed: 0.1192s/iter; left time: 1467.1302s
	iters: 1200, epoch: 6 | loss: 0.0142841
	speed: 0.1201s/iter; left time: 1466.4697s
	iters: 1300, epoch: 6 | loss: 0.0106065
	speed: 0.1202s/iter; left time: 1455.6035s
	iters: 1400, epoch: 6 | loss: 0.0108036
	speed: 0.1204s/iter; left time: 1445.1101s
	iters: 1500, epoch: 6 | loss: 0.0158543
	speed: 0.1203s/iter; left time: 1432.1820s
	iters: 1600, epoch: 6 | loss: 0.0113087
	speed: 0.1205s/iter; left time: 1422.1355s
	iters: 1700, epoch: 6 | loss: 0.0104489
	speed: 0.1205s/iter; left time: 1410.7813s
	iters: 1800, epoch: 6 | loss: 0.0163415
	speed: 0.1187s/iter; left time: 1377.9044s
	iters: 1900, epoch: 6 | loss: 0.0127612
	speed: 0.1194s/iter; left time: 1373.6984s
	iters: 2000, epoch: 6 | loss: 0.0125977
	speed: 0.1198s/iter; left time: 1366.8531s
	iters: 2100, epoch: 6 | loss: 0.0094394
	speed: 0.1204s/iter; left time: 1361.6124s
	iters: 2200, epoch: 6 | loss: 0.0116437
	speed: 0.1204s/iter; left time: 1348.6531s
	iters: 2300, epoch: 6 | loss: 0.0175751
	speed: 0.1202s/iter; left time: 1335.4079s
	iters: 2400, epoch: 6 | loss: 0.0131951
	speed: 0.1205s/iter; left time: 1326.5677s
	iters: 2500, epoch: 6 | loss: 0.0133101
	speed: 0.1205s/iter; left time: 1313.6399s
	iters: 2600, epoch: 6 | loss: 0.0134975
	speed: 0.1205s/iter; left time: 1301.7682s
Epoch: 6 cost time: 00h:05m:22.09s
Epoch: 6 | Train Loss: 0.0133536 Vali Loss: 0.0096058 Test Loss: 0.0108095
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0174152
	speed: 0.8111s/iter; left time: 8617.9770s
	iters: 200, epoch: 7 | loss: 0.0187489
	speed: 0.1197s/iter; left time: 1259.9829s
	iters: 300, epoch: 7 | loss: 0.0117891
	speed: 0.1191s/iter; left time: 1241.3385s
	iters: 400, epoch: 7 | loss: 0.0127354
	speed: 0.1191s/iter; left time: 1229.1952s
	iters: 500, epoch: 7 | loss: 0.0156042
	speed: 0.1190s/iter; left time: 1216.8018s
	iters: 600, epoch: 7 | loss: 0.0127855
	speed: 0.1190s/iter; left time: 1205.3399s
	iters: 700, epoch: 7 | loss: 0.0155036
	speed: 0.1198s/iter; left time: 1201.0888s
	iters: 800, epoch: 7 | loss: 0.0158274
	speed: 0.1200s/iter; left time: 1190.8708s
	iters: 900, epoch: 7 | loss: 0.0142470
	speed: 0.1198s/iter; left time: 1177.5186s
	iters: 1000, epoch: 7 | loss: 0.0126780
	speed: 0.1196s/iter; left time: 1162.7707s
	iters: 1100, epoch: 7 | loss: 0.0155426
	speed: 0.1191s/iter; left time: 1146.6305s
	iters: 1200, epoch: 7 | loss: 0.0122411
	speed: 0.1193s/iter; left time: 1135.9645s
	iters: 1300, epoch: 7 | loss: 0.0121622
	speed: 0.1191s/iter; left time: 1122.4522s
	iters: 1400, epoch: 7 | loss: 0.0209989
	speed: 0.1200s/iter; left time: 1118.8953s
	iters: 1500, epoch: 7 | loss: 0.0120442
	speed: 0.1201s/iter; left time: 1107.9887s
	iters: 1600, epoch: 7 | loss: 0.0133398
	speed: 0.1202s/iter; left time: 1096.5887s
	iters: 1700, epoch: 7 | loss: 0.0172512
	speed: 0.1202s/iter; left time: 1085.0974s
	iters: 1800, epoch: 7 | loss: 0.0082703
	speed: 0.1199s/iter; left time: 1070.0857s
	iters: 1900, epoch: 7 | loss: 0.0117215
	speed: 0.1200s/iter; left time: 1058.7095s
	iters: 2000, epoch: 7 | loss: 0.0137244
	speed: 0.1201s/iter; left time: 1048.2518s
	iters: 2100, epoch: 7 | loss: 0.0107342
	speed: 0.1199s/iter; left time: 1034.4944s
	iters: 2200, epoch: 7 | loss: 0.0122395
	speed: 0.1202s/iter; left time: 1024.8229s
	iters: 2300, epoch: 7 | loss: 0.0135718
	speed: 0.1201s/iter; left time: 1012.1244s
	iters: 2400, epoch: 7 | loss: 0.0122959
	speed: 0.1201s/iter; left time: 1000.0535s
	iters: 2500, epoch: 7 | loss: 0.0172985
	speed: 0.1201s/iter; left time: 987.5034s
	iters: 2600, epoch: 7 | loss: 0.0115662
	speed: 0.1201s/iter; left time: 976.0949s
Epoch: 7 cost time: 00h:05m:21.23s
Epoch: 7 | Train Loss: 0.0131364 Vali Loss: 0.0095241 Test Loss: 0.0112181
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0174437
	speed: 0.8085s/iter; left time: 6422.4737s
	iters: 200, epoch: 8 | loss: 0.0134988
	speed: 0.1202s/iter; left time: 942.8455s
	iters: 300, epoch: 8 | loss: 0.0170489
	speed: 0.1200s/iter; left time: 929.5295s
	iters: 400, epoch: 8 | loss: 0.0129379
	speed: 0.1201s/iter; left time: 917.8684s
	iters: 500, epoch: 8 | loss: 0.0102210
	speed: 0.1200s/iter; left time: 905.2302s
	iters: 600, epoch: 8 | loss: 0.0139757
	speed: 0.1206s/iter; left time: 897.4772s
	iters: 700, epoch: 8 | loss: 0.0119929
	speed: 0.1204s/iter; left time: 884.2207s
	iters: 800, epoch: 8 | loss: 0.0110905
	speed: 0.1204s/iter; left time: 872.2214s
	iters: 900, epoch: 8 | loss: 0.0137277
	speed: 0.1206s/iter; left time: 861.3250s
	iters: 1000, epoch: 8 | loss: 0.0219177
	speed: 0.1211s/iter; left time: 853.0112s
	iters: 1100, epoch: 8 | loss: 0.0145128
	speed: 0.1190s/iter; left time: 826.5624s
	iters: 1200, epoch: 8 | loss: 0.0135163
	speed: 0.1182s/iter; left time: 808.7203s
	iters: 1300, epoch: 8 | loss: 0.0157765
	speed: 0.1183s/iter; left time: 797.6816s
	iters: 1400, epoch: 8 | loss: 0.0105938
	speed: 0.1182s/iter; left time: 785.1341s
	iters: 1500, epoch: 8 | loss: 0.0121265
	speed: 0.1183s/iter; left time: 774.3613s
	iters: 1600, epoch: 8 | loss: 0.0109979
	speed: 0.1183s/iter; left time: 762.2344s
	iters: 1700, epoch: 8 | loss: 0.0091685
	speed: 0.1183s/iter; left time: 750.3004s
	iters: 1800, epoch: 8 | loss: 0.0130774
	speed: 0.1184s/iter; left time: 739.0950s
	iters: 1900, epoch: 8 | loss: 0.0130881
	speed: 0.1182s/iter; left time: 726.4977s
	iters: 2000, epoch: 8 | loss: 0.0100635
	speed: 0.1181s/iter; left time: 714.0469s
	iters: 2100, epoch: 8 | loss: 0.0101380
	speed: 0.1181s/iter; left time: 702.2399s
	iters: 2200, epoch: 8 | loss: 0.0156024
	speed: 0.1181s/iter; left time: 690.0025s
	iters: 2300, epoch: 8 | loss: 0.0158889
	speed: 0.1181s/iter; left time: 678.3497s
	iters: 2400, epoch: 8 | loss: 0.0133793
	speed: 0.1180s/iter; left time: 666.1634s
	iters: 2500, epoch: 8 | loss: 0.0136103
	speed: 0.1182s/iter; left time: 655.4105s
	iters: 2600, epoch: 8 | loss: 0.0112722
	speed: 0.1167s/iter; left time: 635.3967s
Epoch: 8 cost time: 00h:05m:19.03s
Epoch: 8 | Train Loss: 0.0127839 Vali Loss: 0.0096197 Test Loss: 0.0115933
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.011008788831532001, rmse:0.10492277890443802, mae:0.06483417749404907, rse:0.3964286744594574
Intermediate time for IT and pred_len 24: 00h:51m:57.23s

=== Starting experiments for pred_len: 96 ===

--- Running model for IT, pred_len=96 ---
train 85587
val 18435
test 18435
[2024-11-12 21:50:08,881] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 21:50:09,837] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 21:50:09,837] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 21:50:09,837] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 21:50:09,928] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 21:50:09,928] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 21:50:10,695] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 21:50:10,696] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 21:50:10,696] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 21:50:10,697] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 21:50:10,697] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 21:50:10,697] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 21:50:10,697] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 21:50:10,697] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 21:50:10,697] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 21:50:10,697] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 21:50:10,879] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 21:50:10,880] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 21:50:10,910] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.95 GB, percent = 2.2%
[2024-11-12 21:50:11,003] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 21:50:11,003] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 21:50:11,003] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.95 GB, percent = 2.2%
[2024-11-12 21:50:11,003] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 21:50:11,084] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 21:50:11,085] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-12 21:50:11,085] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 21.95 GB, percent = 2.2%
[2024-11-12 21:50:11,085] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 21:50:11,085] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 21:50:11,085] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 21:50:11,085] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 21:50:11,086] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7feff21a7dd0>
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 21:50:11,086] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 21:50:11,087] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 21:50:11,087] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0694929
	speed: 0.1597s/iter; left time: 4255.8455s
	iters: 200, epoch: 1 | loss: 0.0610348
	speed: 0.1228s/iter; left time: 3258.4021s
	iters: 300, epoch: 1 | loss: 0.0476903
	speed: 0.1228s/iter; left time: 3247.3533s
	iters: 400, epoch: 1 | loss: 0.0505114
	speed: 0.1230s/iter; left time: 3240.1252s
	iters: 500, epoch: 1 | loss: 0.0433032
	speed: 0.1230s/iter; left time: 3227.5404s
	iters: 600, epoch: 1 | loss: 0.0304012
	speed: 0.1228s/iter; left time: 3211.1643s
	iters: 700, epoch: 1 | loss: 0.0364681
	speed: 0.1231s/iter; left time: 3206.1691s
	iters: 800, epoch: 1 | loss: 0.0261162
	speed: 0.1229s/iter; left time: 3189.3040s
	iters: 900, epoch: 1 | loss: 0.0270577
	speed: 0.1232s/iter; left time: 3184.3817s
	iters: 1000, epoch: 1 | loss: 0.0294577
	speed: 0.1230s/iter; left time: 3166.6685s
	iters: 1100, epoch: 1 | loss: 0.0201637
	speed: 0.1231s/iter; left time: 3156.3052s
	iters: 1200, epoch: 1 | loss: 0.0176084
	speed: 0.1228s/iter; left time: 3137.0386s
	iters: 1300, epoch: 1 | loss: 0.0223269
	speed: 0.1228s/iter; left time: 3124.6374s
	iters: 1400, epoch: 1 | loss: 0.0243765
	speed: 0.1230s/iter; left time: 3116.9031s
	iters: 1500, epoch: 1 | loss: 0.0224690
	speed: 0.1230s/iter; left time: 3103.9199s
	iters: 1600, epoch: 1 | loss: 0.0207021
	speed: 0.1231s/iter; left time: 3094.8356s
	iters: 1700, epoch: 1 | loss: 0.0317803
	speed: 0.1232s/iter; left time: 3084.8389s
	iters: 1800, epoch: 1 | loss: 0.0221975
	speed: 0.1229s/iter; left time: 3065.1373s
	iters: 1900, epoch: 1 | loss: 0.0269790
	speed: 0.1230s/iter; left time: 3055.5620s
	iters: 2000, epoch: 1 | loss: 0.0139412
	speed: 0.1227s/iter; left time: 3036.1740s
	iters: 2100, epoch: 1 | loss: 0.0323963
	speed: 0.1228s/iter; left time: 3025.2229s
	iters: 2200, epoch: 1 | loss: 0.0290040
	speed: 0.1230s/iter; left time: 3018.7172s
	iters: 2300, epoch: 1 | loss: 0.0271860
	speed: 0.1228s/iter; left time: 3001.8760s
	iters: 2400, epoch: 1 | loss: 0.0241206
	speed: 0.1230s/iter; left time: 2993.6573s
	iters: 2500, epoch: 1 | loss: 0.0267963
	speed: 0.1230s/iter; left time: 2980.7541s
	iters: 2600, epoch: 1 | loss: 0.0236994
	speed: 0.1230s/iter; left time: 2970.2180s
Epoch: 1 cost time: 00h:05m:29.75s
Epoch: 1 | Train Loss: 0.0329653 Vali Loss: 0.0173980 Test Loss: 0.0185405
Validation loss decreased (inf --> 0.017398).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0272199
	speed: 0.8636s/iter; left time: 20697.1179s
	iters: 200, epoch: 2 | loss: 0.0186267
	speed: 0.1182s/iter; left time: 2820.7139s
	iters: 300, epoch: 2 | loss: 0.0172441
	speed: 0.1183s/iter; left time: 2812.6035s
	iters: 400, epoch: 2 | loss: 0.0219970
	speed: 0.1182s/iter; left time: 2798.4981s
	iters: 500, epoch: 2 | loss: 0.0220297
	speed: 0.1180s/iter; left time: 2780.2725s
	iters: 600, epoch: 2 | loss: 0.0182760
	speed: 0.1179s/iter; left time: 2766.4975s
	iters: 700, epoch: 2 | loss: 0.0163294
	speed: 0.1183s/iter; left time: 2765.0484s
	iters: 800, epoch: 2 | loss: 0.0196641
	speed: 0.1181s/iter; left time: 2747.8187s
	iters: 900, epoch: 2 | loss: 0.0217072
	speed: 0.1185s/iter; left time: 2744.7595s
	iters: 1000, epoch: 2 | loss: 0.0205294
	speed: 0.1182s/iter; left time: 2727.4708s
	iters: 1100, epoch: 2 | loss: 0.0178053
	speed: 0.1186s/iter; left time: 2724.2658s
	iters: 1200, epoch: 2 | loss: 0.0288649
	speed: 0.1184s/iter; left time: 2706.5646s
	iters: 1300, epoch: 2 | loss: 0.0228808
	speed: 0.1182s/iter; left time: 2691.3795s
	iters: 1400, epoch: 2 | loss: 0.0265501
	speed: 0.1183s/iter; left time: 2681.8233s
	iters: 1500, epoch: 2 | loss: 0.0183873
	speed: 0.1187s/iter; left time: 2678.1726s
	iters: 1600, epoch: 2 | loss: 0.0218808
	speed: 0.1183s/iter; left time: 2658.1281s
	iters: 1700, epoch: 2 | loss: 0.0172726
	speed: 0.1184s/iter; left time: 2648.9653s
	iters: 1800, epoch: 2 | loss: 0.0233337
	speed: 0.1183s/iter; left time: 2635.2476s
	iters: 1900, epoch: 2 | loss: 0.0162270
	speed: 0.1187s/iter; left time: 2631.1614s
	iters: 2000, epoch: 2 | loss: 0.0202406
	speed: 0.1184s/iter; left time: 2611.8779s
	iters: 2100, epoch: 2 | loss: 0.0162637
	speed: 0.1187s/iter; left time: 2607.7887s
	iters: 2200, epoch: 2 | loss: 0.0172571
	speed: 0.1183s/iter; left time: 2587.6457s
	iters: 2300, epoch: 2 | loss: 0.0168581
	speed: 0.1189s/iter; left time: 2588.2661s
	iters: 2400, epoch: 2 | loss: 0.0216656
	speed: 0.1184s/iter; left time: 2565.4624s
	iters: 2500, epoch: 2 | loss: 0.0180421
	speed: 0.1183s/iter; left time: 2552.2348s
	iters: 2600, epoch: 2 | loss: 0.0151496
	speed: 0.1183s/iter; left time: 2538.5195s
Epoch: 2 cost time: 00h:05m:16.64s
Epoch: 2 | Train Loss: 0.0215529 Vali Loss: 0.0163842 Test Loss: 0.0182444
Validation loss decreased (0.017398 --> 0.016384).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0224957
	speed: 0.8166s/iter; left time: 17387.7593s
	iters: 200, epoch: 3 | loss: 0.0211753
	speed: 0.1180s/iter; left time: 2500.7697s
	iters: 300, epoch: 3 | loss: 0.0205996
	speed: 0.1183s/iter; left time: 2495.0626s
	iters: 400, epoch: 3 | loss: 0.0235345
	speed: 0.1183s/iter; left time: 2483.9907s
	iters: 500, epoch: 3 | loss: 0.0213881
	speed: 0.1181s/iter; left time: 2467.6234s
	iters: 600, epoch: 3 | loss: 0.0243180
	speed: 0.1198s/iter; left time: 2491.9166s
	iters: 700, epoch: 3 | loss: 0.0170536
	speed: 0.1184s/iter; left time: 2450.2782s
	iters: 800, epoch: 3 | loss: 0.0176462
	speed: 0.1182s/iter; left time: 2434.3755s
	iters: 900, epoch: 3 | loss: 0.0263926
	speed: 0.1183s/iter; left time: 2424.7038s
	iters: 1000, epoch: 3 | loss: 0.0257920
	speed: 0.1183s/iter; left time: 2413.4871s
	iters: 1100, epoch: 3 | loss: 0.0206364
	speed: 0.1183s/iter; left time: 2401.6369s
	iters: 1200, epoch: 3 | loss: 0.0214906
	speed: 0.1182s/iter; left time: 2386.2585s
	iters: 1300, epoch: 3 | loss: 0.0209809
	speed: 0.1184s/iter; left time: 2378.1020s
	iters: 1400, epoch: 3 | loss: 0.0199022
	speed: 0.1183s/iter; left time: 2364.4796s
	iters: 1500, epoch: 3 | loss: 0.0249380
	speed: 0.1182s/iter; left time: 2351.3140s
	iters: 1600, epoch: 3 | loss: 0.0257526
	speed: 0.1188s/iter; left time: 2351.5647s
	iters: 1700, epoch: 3 | loss: 0.0227259
	speed: 0.1182s/iter; left time: 2327.4298s
	iters: 1800, epoch: 3 | loss: 0.0224461
	speed: 0.1183s/iter; left time: 2317.6166s
	iters: 1900, epoch: 3 | loss: 0.0214821
	speed: 0.1187s/iter; left time: 2312.8798s
	iters: 2000, epoch: 3 | loss: 0.0147600
	speed: 0.1189s/iter; left time: 2305.7141s
	iters: 2100, epoch: 3 | loss: 0.0277608
	speed: 0.1190s/iter; left time: 2296.0822s
	iters: 2200, epoch: 3 | loss: 0.0255291
	speed: 0.1184s/iter; left time: 2273.1209s
	iters: 2300, epoch: 3 | loss: 0.0175065
	speed: 0.1189s/iter; left time: 2269.5172s
	iters: 2400, epoch: 3 | loss: 0.0161644
	speed: 0.1186s/iter; left time: 2251.9233s
	iters: 2500, epoch: 3 | loss: 0.0179975
	speed: 0.1183s/iter; left time: 2235.8886s
	iters: 2600, epoch: 3 | loss: 0.0164614
	speed: 0.1184s/iter; left time: 2224.8797s
Epoch: 3 cost time: 00h:05m:17.04s
Epoch: 3 | Train Loss: 0.0201874 Vali Loss: 0.0163050 Test Loss: 0.0187278
Validation loss decreased (0.016384 --> 0.016305).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0149462
	speed: 0.8124s/iter; left time: 15126.3220s
	iters: 200, epoch: 4 | loss: 0.0306469
	speed: 0.1179s/iter; left time: 2184.0401s
	iters: 300, epoch: 4 | loss: 0.0155472
	speed: 0.1187s/iter; left time: 2187.0869s
	iters: 400, epoch: 4 | loss: 0.0248012
	speed: 0.1183s/iter; left time: 2167.4540s
	iters: 500, epoch: 4 | loss: 0.0196272
	speed: 0.1184s/iter; left time: 2157.6122s
	iters: 600, epoch: 4 | loss: 0.0183685
	speed: 0.1191s/iter; left time: 2157.3634s
	iters: 700, epoch: 4 | loss: 0.0231034
	speed: 0.1182s/iter; left time: 2130.7450s
	iters: 800, epoch: 4 | loss: 0.0170192
	speed: 0.1184s/iter; left time: 2122.0650s
	iters: 900, epoch: 4 | loss: 0.0153297
	speed: 0.1176s/iter; left time: 2094.8546s
	iters: 1000, epoch: 4 | loss: 0.0158371
	speed: 0.1171s/iter; left time: 2074.6059s
	iters: 1100, epoch: 4 | loss: 0.0187040
	speed: 0.1170s/iter; left time: 2061.1650s
	iters: 1200, epoch: 4 | loss: 0.0171206
	speed: 0.1169s/iter; left time: 2048.0068s
	iters: 1300, epoch: 4 | loss: 0.0239391
	speed: 0.1170s/iter; left time: 2038.6232s
	iters: 1400, epoch: 4 | loss: 0.0179229
	speed: 0.1170s/iter; left time: 2026.3795s
	iters: 1500, epoch: 4 | loss: 0.0170190
	speed: 0.1169s/iter; left time: 2013.4624s
	iters: 1600, epoch: 4 | loss: 0.0202631
	speed: 0.1181s/iter; left time: 2022.0767s
	iters: 1700, epoch: 4 | loss: 0.0166972
	speed: 0.1183s/iter; left time: 2013.0458s
	iters: 1800, epoch: 4 | loss: 0.0236535
	speed: 0.1180s/iter; left time: 1997.1093s
	iters: 1900, epoch: 4 | loss: 0.0150460
	speed: 0.1185s/iter; left time: 1993.0640s
	iters: 2000, epoch: 4 | loss: 0.0202106
	speed: 0.1186s/iter; left time: 1982.4519s
	iters: 2100, epoch: 4 | loss: 0.0208280
	speed: 0.1185s/iter; left time: 1969.3867s
	iters: 2200, epoch: 4 | loss: 0.0161798
	speed: 0.1183s/iter; left time: 1953.6045s
	iters: 2300, epoch: 4 | loss: 0.0242665
	speed: 0.1182s/iter; left time: 1941.0652s
	iters: 2400, epoch: 4 | loss: 0.0195169
	speed: 0.1183s/iter; left time: 1930.7342s
	iters: 2500, epoch: 4 | loss: 0.0205073
	speed: 0.1185s/iter; left time: 1921.2851s
	iters: 2600, epoch: 4 | loss: 0.0158916
	speed: 0.1182s/iter; left time: 1905.0018s
Epoch: 4 cost time: 00h:05m:15.90s
Epoch: 4 | Train Loss: 0.0189348 Vali Loss: 0.0173067 Test Loss: 0.0214344
EarlyStopping counter: 1 out of 3
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0180995
	speed: 0.7971s/iter; left time: 12709.6100s
	iters: 200, epoch: 5 | loss: 0.0197095
	speed: 0.1193s/iter; left time: 1890.2538s
	iters: 300, epoch: 5 | loss: 0.0229675
	speed: 0.1193s/iter; left time: 1878.7932s
	iters: 400, epoch: 5 | loss: 0.0197423
	speed: 0.1189s/iter; left time: 1859.6279s
	iters: 500, epoch: 5 | loss: 0.0158846
	speed: 0.1184s/iter; left time: 1840.5696s
	iters: 600, epoch: 5 | loss: 0.0230835
	speed: 0.1183s/iter; left time: 1827.1478s
	iters: 700, epoch: 5 | loss: 0.0135149
	speed: 0.1183s/iter; left time: 1814.7125s
	iters: 800, epoch: 5 | loss: 0.0152504
	speed: 0.1185s/iter; left time: 1806.9985s
	iters: 900, epoch: 5 | loss: 0.0175985
	speed: 0.1181s/iter; left time: 1789.2561s
	iters: 1000, epoch: 5 | loss: 0.0131963
	speed: 0.1182s/iter; left time: 1777.9647s
	iters: 1100, epoch: 5 | loss: 0.0131689
	speed: 0.1190s/iter; left time: 1778.3791s
	iters: 1200, epoch: 5 | loss: 0.0162168
	speed: 0.1185s/iter; left time: 1759.5020s
	iters: 1300, epoch: 5 | loss: 0.0161144
	speed: 0.1185s/iter; left time: 1746.6002s
	iters: 1400, epoch: 5 | loss: 0.0195949
	speed: 0.1182s/iter; left time: 1731.6302s
	iters: 1500, epoch: 5 | loss: 0.0137905
	speed: 0.1191s/iter; left time: 1732.1514s
	iters: 1600, epoch: 5 | loss: 0.0177529
	speed: 0.1183s/iter; left time: 1709.0969s
	iters: 1700, epoch: 5 | loss: 0.0135930
	speed: 0.1182s/iter; left time: 1694.8908s
	iters: 1800, epoch: 5 | loss: 0.0197266
	speed: 0.1182s/iter; left time: 1683.2083s
	iters: 1900, epoch: 5 | loss: 0.0125901
	speed: 0.1187s/iter; left time: 1679.6688s
	iters: 2000, epoch: 5 | loss: 0.0140697
	speed: 0.1184s/iter; left time: 1662.6591s
	iters: 2100, epoch: 5 | loss: 0.0179224
	speed: 0.1183s/iter; left time: 1649.1034s
	iters: 2200, epoch: 5 | loss: 0.0175040
	speed: 0.1183s/iter; left time: 1637.7414s
	iters: 2300, epoch: 5 | loss: 0.0234317
	speed: 0.1193s/iter; left time: 1639.2919s
	iters: 2400, epoch: 5 | loss: 0.0175250
	speed: 0.1182s/iter; left time: 1613.1258s
	iters: 2500, epoch: 5 | loss: 0.0212564
	speed: 0.1182s/iter; left time: 1600.9923s
	iters: 2600, epoch: 5 | loss: 0.0128027
	speed: 0.1181s/iter; left time: 1588.4114s
Epoch: 5 cost time: 00h:05m:16.94s
Epoch: 5 | Train Loss: 0.0178580 Vali Loss: 0.0170211 Test Loss: 0.0205465
EarlyStopping counter: 2 out of 3
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0274220
	speed: 0.7991s/iter; left time: 10605.3862s
	iters: 200, epoch: 6 | loss: 0.0163231
	speed: 0.1189s/iter; left time: 1565.9895s
	iters: 300, epoch: 6 | loss: 0.0157869
	speed: 0.1194s/iter; left time: 1560.6201s
	iters: 400, epoch: 6 | loss: 0.0136238
	speed: 0.1184s/iter; left time: 1535.6623s
	iters: 500, epoch: 6 | loss: 0.0148876
	speed: 0.1184s/iter; left time: 1523.4229s
	iters: 600, epoch: 6 | loss: 0.0199551
	speed: 0.1181s/iter; left time: 1507.8738s
	iters: 700, epoch: 6 | loss: 0.0159899
	speed: 0.1180s/iter; left time: 1495.5629s
	iters: 800, epoch: 6 | loss: 0.0183493
	speed: 0.1185s/iter; left time: 1489.6627s
	iters: 900, epoch: 6 | loss: 0.0222189
	speed: 0.1183s/iter; left time: 1475.4458s
	iters: 1000, epoch: 6 | loss: 0.0180203
	speed: 0.1184s/iter; left time: 1464.1826s
	iters: 1100, epoch: 6 | loss: 0.0162416
	speed: 0.1183s/iter; left time: 1451.0638s
	iters: 1200, epoch: 6 | loss: 0.0110515
	speed: 0.1181s/iter; left time: 1436.9564s
	iters: 1300, epoch: 6 | loss: 0.0166524
	speed: 0.1180s/iter; left time: 1423.8569s
	iters: 1400, epoch: 6 | loss: 0.0200620
	speed: 0.1200s/iter; left time: 1435.9932s
	iters: 1500, epoch: 6 | loss: 0.0139170
	speed: 0.1181s/iter; left time: 1401.8972s
	iters: 1600, epoch: 6 | loss: 0.0194305
	speed: 0.1184s/iter; left time: 1393.9447s
	iters: 1700, epoch: 6 | loss: 0.0135993
	speed: 0.1193s/iter; left time: 1391.8636s
	iters: 1800, epoch: 6 | loss: 0.0147370
	speed: 0.1205s/iter; left time: 1394.1119s
	iters: 1900, epoch: 6 | loss: 0.0136333
	speed: 0.1186s/iter; left time: 1360.0710s
	iters: 2000, epoch: 6 | loss: 0.0175431
	speed: 0.1183s/iter; left time: 1345.2756s
	iters: 2100, epoch: 6 | loss: 0.0169017
	speed: 0.1186s/iter; left time: 1336.7683s
	iters: 2200, epoch: 6 | loss: 0.0220713
	speed: 0.1180s/iter; left time: 1318.4192s
	iters: 2300, epoch: 6 | loss: 0.0187113
	speed: 0.1180s/iter; left time: 1306.7620s
	iters: 2400, epoch: 6 | loss: 0.0154803
	speed: 0.1183s/iter; left time: 1297.4570s
	iters: 2500, epoch: 6 | loss: 0.0192516
	speed: 0.1183s/iter; left time: 1285.7295s
	iters: 2600, epoch: 6 | loss: 0.0095078
	speed: 0.1183s/iter; left time: 1274.3960s
Epoch: 6 cost time: 00h:05m:17.02s
Epoch: 6 | Train Loss: 0.0168697 Vali Loss: 0.0163503 Test Loss: 0.0207182
EarlyStopping counter: 3 out of 3
Early stopping
loading model...
Scaled mse:0.018727777525782585, rmse:0.13684946298599243, mae:0.08752837032079697, rse:0.5174592137336731
Intermediate time for IT and pred_len 96: 00h:38m:44.72s

=== Starting experiments for pred_len: 168 ===

--- Running model for IT, pred_len=168 ---
train 85371
val 18219
test 18219
[2024-11-12 22:28:53,484] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-12 22:28:54,435] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-12 22:28:54,436] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-12 22:28:54,436] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-12 22:28:54,551] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.41, master_port=29500
[2024-11-12 22:28:54,551] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-12 22:28:55,356] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-12 22:28:55,357] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-12 22:28:55,357] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-12 22:28:55,359] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-12 22:28:55,359] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-12 22:28:55,359] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-12 22:28:55,359] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-12 22:28:55,359] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-12 22:28:55,359] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-12 22:28:55,359] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-12 22:28:55,607] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-12 22:28:55,607] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-12 22:28:55,638] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 23.43 GB, percent = 2.3%
[2024-11-12 22:28:55,726] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-12 22:28:55,727] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 22:28:55,727] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 23.43 GB, percent = 2.3%
[2024-11-12 22:28:55,727] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-12 22:28:55,807] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-12 22:28:55,808] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-12 22:28:55,808] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 23.43 GB, percent = 2.3%
[2024-11-12 22:28:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-12 22:28:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-12 22:28:55,808] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-12 22:28:55,809] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-12 22:28:55,809] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f05323b1750>
[2024-11-12 22:28:55,809] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-12 22:28:55,810] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-12 22:28:55,811] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.0760096
	speed: 0.1628s/iter; left time: 4326.5772s
	iters: 200, epoch: 1 | loss: 0.0683317
	speed: 0.1231s/iter; left time: 3257.9985s
	iters: 300, epoch: 1 | loss: 0.0582088
	speed: 0.1232s/iter; left time: 3249.5221s
	iters: 400, epoch: 1 | loss: 0.0557995
	speed: 0.1234s/iter; left time: 3243.0774s
	iters: 500, epoch: 1 | loss: 0.0632301
	speed: 0.1234s/iter; left time: 3228.7350s
	iters: 600, epoch: 1 | loss: 0.0534293
	speed: 0.1238s/iter; left time: 3227.4907s
	iters: 700, epoch: 1 | loss: 0.0340961
	speed: 0.1234s/iter; left time: 3205.8056s
	iters: 800, epoch: 1 | loss: 0.0320352
	speed: 0.1236s/iter; left time: 3196.5368s
	iters: 900, epoch: 1 | loss: 0.0340186
	speed: 0.1238s/iter; left time: 3191.6352s
	iters: 1000, epoch: 1 | loss: 0.0326719
	speed: 0.1235s/iter; left time: 3169.3546s
	iters: 1100, epoch: 1 | loss: 0.0272844
	speed: 0.1235s/iter; left time: 3157.9121s
	iters: 1200, epoch: 1 | loss: 0.0302438
	speed: 0.1239s/iter; left time: 3156.6755s
	iters: 1300, epoch: 1 | loss: 0.0325096
	speed: 0.1234s/iter; left time: 3130.3771s
	iters: 1400, epoch: 1 | loss: 0.0196911
	speed: 0.1234s/iter; left time: 3118.9268s
	iters: 1500, epoch: 1 | loss: 0.0312060
	speed: 0.1234s/iter; left time: 3106.6331s
	iters: 1600, epoch: 1 | loss: 0.0235252
	speed: 0.1233s/iter; left time: 3092.0756s
	iters: 1700, epoch: 1 | loss: 0.0227258
	speed: 0.1235s/iter; left time: 3084.2070s
	iters: 1800, epoch: 1 | loss: 0.0232675
	speed: 0.1246s/iter; left time: 3100.0136s
	iters: 1900, epoch: 1 | loss: 0.0205666
	speed: 0.1238s/iter; left time: 3066.5812s
	iters: 2000, epoch: 1 | loss: 0.0264083
	speed: 0.1235s/iter; left time: 3046.0472s
	iters: 2100, epoch: 1 | loss: 0.0245590
	speed: 0.1239s/iter; left time: 3044.2935s
	iters: 2200, epoch: 1 | loss: 0.0214975
	speed: 0.1239s/iter; left time: 3030.9344s
	iters: 2300, epoch: 1 | loss: 0.0258007
	speed: 0.1237s/iter; left time: 3013.9791s
	iters: 2400, epoch: 1 | loss: 0.0280242
	speed: 0.1234s/iter; left time: 2993.8956s
	iters: 2500, epoch: 1 | loss: 0.0244646
	speed: 0.1234s/iter; left time: 2982.5577s
	iters: 2600, epoch: 1 | loss: 0.0239128
	speed: 0.1235s/iter; left time: 2973.7824s
Epoch: 1 cost time: 00h:05m:30.67s
Epoch: 1 | Train Loss: 0.0353952 Vali Loss: 0.0196393 Test Loss: 0.0204068
Validation loss decreased (inf --> 0.019639).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0263953
	speed: 0.8551s/iter; left time: 20440.0253s
	iters: 200, epoch: 2 | loss: 0.0198965
	speed: 0.1190s/iter; left time: 2832.0463s
	iters: 300, epoch: 2 | loss: 0.0203417
	speed: 0.1193s/iter; left time: 2828.2689s
	iters: 400, epoch: 2 | loss: 0.0276644
	speed: 0.1183s/iter; left time: 2793.4299s
	iters: 500, epoch: 2 | loss: 0.0272038
	speed: 0.1183s/iter; left time: 2781.1242s
	iters: 600, epoch: 2 | loss: 0.0221428
	speed: 0.1184s/iter; left time: 2770.4737s
	iters: 700, epoch: 2 | loss: 0.0161491
	speed: 0.1182s/iter; left time: 2755.4914s
	iters: 800, epoch: 2 | loss: 0.0181733
	speed: 0.1183s/iter; left time: 2743.9207s
	iters: 900, epoch: 2 | loss: 0.0261556
	speed: 0.1183s/iter; left time: 2733.0377s
	iters: 1000, epoch: 2 | loss: 0.0217823
	speed: 0.1182s/iter; left time: 2719.4380s
	iters: 1100, epoch: 2 | loss: 0.0208404
	speed: 0.1182s/iter; left time: 2707.7373s
	iters: 1200, epoch: 2 | loss: 0.0209133
	speed: 0.1182s/iter; left time: 2695.5905s
	iters: 1300, epoch: 2 | loss: 0.0225888
	speed: 0.1184s/iter; left time: 2687.1767s
	iters: 1400, epoch: 2 | loss: 0.0221134
	speed: 0.1184s/iter; left time: 2676.9334s
	iters: 1500, epoch: 2 | loss: 0.0255033
	speed: 0.1185s/iter; left time: 2667.4127s
	iters: 1600, epoch: 2 | loss: 0.0263712
	speed: 0.1187s/iter; left time: 2658.2578s
	iters: 1700, epoch: 2 | loss: 0.0352424
	speed: 0.1183s/iter; left time: 2638.5782s
	iters: 1800, epoch: 2 | loss: 0.0185599
	speed: 0.1184s/iter; left time: 2628.3033s
	iters: 1900, epoch: 2 | loss: 0.0221422
	speed: 0.1183s/iter; left time: 2615.2145s
	iters: 2000, epoch: 2 | loss: 0.0187020
	speed: 0.1188s/iter; left time: 2613.8517s
	iters: 2100, epoch: 2 | loss: 0.0245078
	speed: 0.1184s/iter; left time: 2593.3544s
	iters: 2200, epoch: 2 | loss: 0.0227937
	speed: 0.1187s/iter; left time: 2588.1540s
	iters: 2300, epoch: 2 | loss: 0.0164198
	speed: 0.1187s/iter; left time: 2575.2856s
	iters: 2400, epoch: 2 | loss: 0.0204691
	speed: 0.1187s/iter; left time: 2564.7479s
	iters: 2500, epoch: 2 | loss: 0.0170244
	speed: 0.1186s/iter; left time: 2551.3612s
	iters: 2600, epoch: 2 | loss: 0.0233706
	speed: 0.1186s/iter; left time: 2537.5105s
Epoch: 2 cost time: 00h:05m:16.46s
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1067, in <module>
    main()
  File "/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1063, in main
    launch_command(args)
  File "/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1057, in launch_command
    simple_launcher(args)
  File "/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/accelerate/commands/launch.py", line 673, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/bin/python', './Time-LLM/run_main.py', '--task_name', 'long_term_forecast', '--is_training', '1', '--root_path', './datasets/', '--data_path', 'IT_data.csv', '--model_id', '3', '--model', 'TimeLLM', '--data', 'IT', '--features', 'M', '--seq_len', '512', '--pred_len', '168', '--factor', '3', '--enc_in', '3', '--c_out', '3', '--des', 'Exp', '--itr', '1', '--d_model', '16', '--d_ff', '64', '--batch_size', '32', '--learning_rate', '0.001', '--llm_model', 'GPT2', '--llm_dim', '768', '--llm_layers', '12', '--train_epochs', '10', '--patience', '3', '--model_comment', 'TimeLLM+IT']' died with <Signals.SIGTERM: 15>.
