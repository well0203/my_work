=== Starting experiments for country: DE ===


=== Starting experiments for pred_len: 24 ===

train 143005
val 31085
test 31085
[2024-10-31 18:51:32,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-31 18:51:33,723] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-10-31 18:51:33,723] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-31 18:51:33,723] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-10-31 18:51:33,820] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-10-31 18:51:33,820] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-10-31 18:51:34,483] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-10-31 18:51:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-10-31 18:51:34,485] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-10-31 18:51:34,487] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-10-31 18:51:34,487] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-10-31 18:51:34,487] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-10-31 18:51:34,487] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-10-31 18:51:34,487] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-10-31 18:51:34,487] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-10-31 18:51:34,487] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-10-31 18:51:34,818] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-10-31 18:51:34,819] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-10-31 18:51:34,819] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 189.54 GB, percent = 25.1%
[2024-10-31 18:51:34,942] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-10-31 18:51:34,943] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-10-31 18:51:34,943] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 189.54 GB, percent = 25.1%
[2024-10-31 18:51:34,943] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-10-31 18:51:35,065] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-10-31 18:51:35,066] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-10-31 18:51:35,066] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 189.55 GB, percent = 25.1%
[2024-10-31 18:51:35,066] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-10-31 18:51:35,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-10-31 18:51:35,067] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-10-31 18:51:35,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-10-31 18:51:35,067] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1ea4446f50>
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-10-31 18:51:35,068] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-10-31 18:51:35,069] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-10-31 18:51:35,070] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-10-31 18:51:35,070] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1688982
	speed: 0.1791s/iter; left time: 15989.3211s
	iters: 200, epoch: 1 | loss: 0.1398762
	speed: 0.1294s/iter; left time: 11539.6838s
	iters: 300, epoch: 1 | loss: 0.1594033
	speed: 0.1311s/iter; left time: 11677.8295s
	iters: 400, epoch: 1 | loss: 0.1548022
	speed: 0.1310s/iter; left time: 11656.5472s
	iters: 500, epoch: 1 | loss: 0.1380969
	speed: 0.1315s/iter; left time: 11684.6241s
	iters: 600, epoch: 1 | loss: 0.1172558
	speed: 0.1323s/iter; left time: 11739.0538s
	iters: 700, epoch: 1 | loss: 0.1290968
	speed: 0.1308s/iter; left time: 11594.0061s
	iters: 800, epoch: 1 | loss: 0.1323915
	speed: 0.1329s/iter; left time: 11770.4203s
	iters: 900, epoch: 1 | loss: 0.0968730
	speed: 0.1277s/iter; left time: 11300.4754s
	iters: 1000, epoch: 1 | loss: 0.1262417
	speed: 0.1316s/iter; left time: 11632.1686s
	iters: 1100, epoch: 1 | loss: 0.1081160
	speed: 0.1356s/iter; left time: 11970.7201s
	iters: 1200, epoch: 1 | loss: 0.1055638
	speed: 0.1331s/iter; left time: 11730.6617s
	iters: 1300, epoch: 1 | loss: 0.0805435
	speed: 0.1369s/iter; left time: 12054.2612s
	iters: 1400, epoch: 1 | loss: 0.1116071
	speed: 0.1331s/iter; left time: 11708.0232s
	iters: 1500, epoch: 1 | loss: 0.0692826
	speed: 0.1312s/iter; left time: 11525.5610s
	iters: 1600, epoch: 1 | loss: 0.0953681
	speed: 0.1314s/iter; left time: 11534.2266s
	iters: 1700, epoch: 1 | loss: 0.1187560
	speed: 0.1339s/iter; left time: 11734.4818s
	iters: 1800, epoch: 1 | loss: 0.0991687
	speed: 0.1323s/iter; left time: 11580.5760s
	iters: 1900, epoch: 1 | loss: 0.1227836
	speed: 0.1332s/iter; left time: 11649.9697s
	iters: 2000, epoch: 1 | loss: 0.0913499
	speed: 0.1337s/iter; left time: 11679.2783s
	iters: 2100, epoch: 1 | loss: 0.0831885
	speed: 0.1334s/iter; left time: 11637.0635s
	iters: 2200, epoch: 1 | loss: 0.1006144
	speed: 0.1364s/iter; left time: 11886.0099s
	iters: 2300, epoch: 1 | loss: 0.1002881
	speed: 0.1335s/iter; left time: 11620.8915s
	iters: 2400, epoch: 1 | loss: 0.0858188
	speed: 0.1340s/iter; left time: 11654.4340s
	iters: 2500, epoch: 1 | loss: 0.0878481
	speed: 0.1335s/iter; left time: 11597.6234s
	iters: 2600, epoch: 1 | loss: 0.0938092
	speed: 0.1338s/iter; left time: 11606.9596s
	iters: 2700, epoch: 1 | loss: 0.1014624
	speed: 0.1318s/iter; left time: 11421.9672s
	iters: 2800, epoch: 1 | loss: 0.0828544
	speed: 0.1350s/iter; left time: 11683.1755s
	iters: 2900, epoch: 1 | loss: 0.0846184
	speed: 0.1345s/iter; left time: 11625.8710s
	iters: 3000, epoch: 1 | loss: 0.0732674
	speed: 0.1340s/iter; left time: 11576.0296s
	iters: 3100, epoch: 1 | loss: 0.0863261
	speed: 0.1352s/iter; left time: 11664.6405s
	iters: 3200, epoch: 1 | loss: 0.1145399
	speed: 0.1356s/iter; left time: 11679.6337s
	iters: 3300, epoch: 1 | loss: 0.0950736
	speed: 0.1355s/iter; left time: 11657.5350s
	iters: 3400, epoch: 1 | loss: 0.1013337
	speed: 0.1339s/iter; left time: 11513.0333s
	iters: 3500, epoch: 1 | loss: 0.0962714
	speed: 0.1331s/iter; left time: 11427.8403s
	iters: 3600, epoch: 1 | loss: 0.1045466
	speed: 0.1349s/iter; left time: 11566.6417s
	iters: 3700, epoch: 1 | loss: 0.0921188
	speed: 0.1335s/iter; left time: 11433.4074s
	iters: 3800, epoch: 1 | loss: 0.0915671
	speed: 0.1355s/iter; left time: 11592.4753s
	iters: 3900, epoch: 1 | loss: 0.1059835
	speed: 0.1325s/iter; left time: 11325.1041s
	iters: 4000, epoch: 1 | loss: 0.0626834
	speed: 0.1316s/iter; left time: 11231.4829s
	iters: 4100, epoch: 1 | loss: 0.0807726
	speed: 0.1325s/iter; left time: 11297.5527s
	iters: 4200, epoch: 1 | loss: 0.1075011
	speed: 0.1329s/iter; left time: 11314.6568s
	iters: 4300, epoch: 1 | loss: 0.0953812
	speed: 0.1341s/iter; left time: 11408.2906s
	iters: 4400, epoch: 1 | loss: 0.0955328
	speed: 0.1288s/iter; left time: 10939.1918s
Epoch: 1 cost time: 00h:09m:55.39s
Epoch: 1 | Train Loss: 0.1053388 Vali Loss: 0.0971123 Test Loss: 0.0994308
Validation loss decreased (inf --> 0.097112).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0704475
	speed: 1.8558s/iter; left time: 157362.1844s
	iters: 200, epoch: 2 | loss: 0.0855533
	speed: 0.1220s/iter; left time: 10333.3626s
	iters: 300, epoch: 2 | loss: 0.0774946
	speed: 0.1217s/iter; left time: 10297.2518s
	iters: 400, epoch: 2 | loss: 0.0883429
	speed: 0.1213s/iter; left time: 10250.4496s
	iters: 500, epoch: 2 | loss: 0.0867326
	speed: 0.1210s/iter; left time: 10214.0189s
	iters: 600, epoch: 2 | loss: 0.0939545
	speed: 0.1217s/iter; left time: 10255.0841s
	iters: 700, epoch: 2 | loss: 0.0739971
	speed: 0.1213s/iter; left time: 10214.2973s
	iters: 800, epoch: 2 | loss: 0.0977335
	speed: 0.1212s/iter; left time: 10195.2114s
	iters: 900, epoch: 2 | loss: 0.0857365
	speed: 0.1200s/iter; left time: 10078.9321s
	iters: 1000, epoch: 2 | loss: 0.0865258
	speed: 0.1203s/iter; left time: 10092.8555s
	iters: 1100, epoch: 2 | loss: 0.0972862
	speed: 0.1210s/iter; left time: 10141.7496s
	iters: 1200, epoch: 2 | loss: 0.0832878
	speed: 0.1161s/iter; left time: 9713.4101s
	iters: 1300, epoch: 2 | loss: 0.0947991
	speed: 0.1188s/iter; left time: 9932.6039s
	iters: 1400, epoch: 2 | loss: 0.0940965
	speed: 0.1221s/iter; left time: 10194.7167s
	iters: 1500, epoch: 2 | loss: 0.0825809
	speed: 0.1215s/iter; left time: 10131.3893s
	iters: 1600, epoch: 2 | loss: 0.0861147
	speed: 0.1211s/iter; left time: 10086.6144s
	iters: 1700, epoch: 2 | loss: 0.1065482
	speed: 0.1218s/iter; left time: 10135.6613s
	iters: 1800, epoch: 2 | loss: 0.0846911
	speed: 0.1217s/iter; left time: 10114.7992s
	iters: 1900, epoch: 2 | loss: 0.1024258
	speed: 0.1209s/iter; left time: 10031.5488s
	iters: 2000, epoch: 2 | loss: 0.0896808
	speed: 0.1142s/iter; left time: 9465.1164s
	iters: 2100, epoch: 2 | loss: 0.1056611
	speed: 0.1147s/iter; left time: 9493.9302s
	iters: 2200, epoch: 2 | loss: 0.0911830
	speed: 0.1199s/iter; left time: 9918.0093s
	iters: 2300, epoch: 2 | loss: 0.0980409
	speed: 0.1217s/iter; left time: 10054.1998s
	iters: 2400, epoch: 2 | loss: 0.0799288
	speed: 0.1208s/iter; left time: 9965.6891s
	iters: 2500, epoch: 2 | loss: 0.0872002
	speed: 0.1214s/iter; left time: 10005.7893s
	iters: 2600, epoch: 2 | loss: 0.0915525
	speed: 0.1214s/iter; left time: 9992.6488s
	iters: 2700, epoch: 2 | loss: 0.1013657
	speed: 0.1204s/iter; left time: 9893.4991s
	iters: 2800, epoch: 2 | loss: 0.0794303
	speed: 0.1214s/iter; left time: 9969.3309s
	iters: 2900, epoch: 2 | loss: 0.0900755
	speed: 0.1211s/iter; left time: 9931.5008s
	iters: 3000, epoch: 2 | loss: 0.0776787
	speed: 0.1201s/iter; left time: 9834.1956s
	iters: 3100, epoch: 2 | loss: 0.1028968
	speed: 0.1210s/iter; left time: 9894.1738s
	iters: 3200, epoch: 2 | loss: 0.0771540
	speed: 0.1213s/iter; left time: 9907.8363s
	iters: 3300, epoch: 2 | loss: 0.0871339
	speed: 0.1201s/iter; left time: 9797.4496s
	iters: 3400, epoch: 2 | loss: 0.1009780
	speed: 0.1191s/iter; left time: 9704.0939s
	iters: 3500, epoch: 2 | loss: 0.0891745
	speed: 0.1209s/iter; left time: 9843.4291s
	iters: 3600, epoch: 2 | loss: 0.0985909
	speed: 0.1209s/iter; left time: 9828.8051s
	iters: 3700, epoch: 2 | loss: 0.1067271
	speed: 0.1216s/iter; left time: 9872.4539s
	iters: 3800, epoch: 2 | loss: 0.0852604
	speed: 0.1212s/iter; left time: 9831.6632s
	iters: 3900, epoch: 2 | loss: 0.0817025
	speed: 0.1201s/iter; left time: 9726.3672s
	iters: 4000, epoch: 2 | loss: 0.0846763
	speed: 0.1180s/iter; left time: 9546.4893s
	iters: 4100, epoch: 2 | loss: 0.0871173
	speed: 0.1224s/iter; left time: 9890.0109s
	iters: 4200, epoch: 2 | loss: 0.0959664
	speed: 0.1205s/iter; left time: 9726.6420s
	iters: 4300, epoch: 2 | loss: 0.0784686
	speed: 0.1211s/iter; left time: 9758.9479s
	iters: 4400, epoch: 2 | loss: 0.0950680
	speed: 0.1192s/iter; left time: 9592.5268s
Epoch: 2 cost time: 00h:08m:57.87s
Epoch: 2 | Train Loss: 0.0889246 Vali Loss: 0.0918921 Test Loss: 0.0945349
Validation loss decreased (0.097112 --> 0.091892).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1014844
	speed: 1.5141s/iter; left time: 121619.0808s
	iters: 200, epoch: 3 | loss: 0.0968780
	speed: 0.1158s/iter; left time: 9289.6890s
	iters: 300, epoch: 3 | loss: 0.0694327
	speed: 0.1210s/iter; left time: 9692.1908s
	iters: 400, epoch: 3 | loss: 0.0818534
	speed: 0.1156s/iter; left time: 9247.1254s
	iters: 500, epoch: 3 | loss: 0.1179019
	speed: 0.1204s/iter; left time: 9623.2367s
	iters: 600, epoch: 3 | loss: 0.0902409
	speed: 0.1103s/iter; left time: 8803.9714s
	iters: 700, epoch: 3 | loss: 0.0945199
	speed: 0.1035s/iter; left time: 8248.9447s
	iters: 800, epoch: 3 | loss: 0.0943223
	speed: 0.1221s/iter; left time: 9718.7403s
	iters: 900, epoch: 3 | loss: 0.0608129
	speed: 0.1214s/iter; left time: 9657.6133s
	iters: 1000, epoch: 3 | loss: 0.0815312
	speed: 0.1182s/iter; left time: 9385.8022s
	iters: 1100, epoch: 3 | loss: 0.0903181
	speed: 0.1226s/iter; left time: 9724.1524s
	iters: 1200, epoch: 3 | loss: 0.0806858
	speed: 0.1208s/iter; left time: 9574.0678s
	iters: 1300, epoch: 3 | loss: 0.0762755
	speed: 0.1218s/iter; left time: 9639.2127s
	iters: 1400, epoch: 3 | loss: 0.0923751
	speed: 0.1191s/iter; left time: 9412.3550s
	iters: 1500, epoch: 3 | loss: 0.0904863
	speed: 0.1223s/iter; left time: 9650.4761s
	iters: 1600, epoch: 3 | loss: 0.0592667
	speed: 0.1207s/iter; left time: 9516.3772s
	iters: 1700, epoch: 3 | loss: 0.0708085
	speed: 0.1211s/iter; left time: 9532.3051s
	iters: 1800, epoch: 3 | loss: 0.0865551
	speed: 0.1149s/iter; left time: 9032.1334s
	iters: 1900, epoch: 3 | loss: 0.0666124
	speed: 0.1169s/iter; left time: 9183.4101s
	iters: 2000, epoch: 3 | loss: 0.0717531
	speed: 0.1183s/iter; left time: 9278.7156s
	iters: 2100, epoch: 3 | loss: 0.1037164
	speed: 0.1188s/iter; left time: 9307.1539s
	iters: 2200, epoch: 3 | loss: 0.0819335
	speed: 0.1215s/iter; left time: 9506.6379s
	iters: 2300, epoch: 3 | loss: 0.0837101
	speed: 0.1161s/iter; left time: 9072.8121s
	iters: 2400, epoch: 3 | loss: 0.0792184
	speed: 0.1213s/iter; left time: 9461.5369s
	iters: 2500, epoch: 3 | loss: 0.0968816
	speed: 0.1127s/iter; left time: 8785.1067s
	iters: 2600, epoch: 3 | loss: 0.0933213
	speed: 0.1143s/iter; left time: 8891.6723s
	iters: 2700, epoch: 3 | loss: 0.0743180
	speed: 0.1117s/iter; left time: 8679.7168s
	iters: 2800, epoch: 3 | loss: 0.0937308
	speed: 0.1136s/iter; left time: 8819.0185s
	iters: 2900, epoch: 3 | loss: 0.0838305
	speed: 0.1198s/iter; left time: 9287.5529s
	iters: 3000, epoch: 3 | loss: 0.0647273
	speed: 0.1210s/iter; left time: 9367.6214s
	iters: 3100, epoch: 3 | loss: 0.0913395
	speed: 0.1199s/iter; left time: 9272.2949s
	iters: 3200, epoch: 3 | loss: 0.0819122
	speed: 0.1212s/iter; left time: 9360.1298s
	iters: 3300, epoch: 3 | loss: 0.0788185
	speed: 0.1197s/iter; left time: 9234.5851s
	iters: 3400, epoch: 3 | loss: 0.0784381
	speed: 0.1210s/iter; left time: 9321.6544s
	iters: 3500, epoch: 3 | loss: 0.0678186
	speed: 0.1212s/iter; left time: 9321.3068s
	iters: 3600, epoch: 3 | loss: 0.0698414
	speed: 0.1212s/iter; left time: 9314.4010s
	iters: 3700, epoch: 3 | loss: 0.0900844
	speed: 0.1216s/iter; left time: 9332.3040s
	iters: 3800, epoch: 3 | loss: 0.0756922
	speed: 0.1220s/iter; left time: 9349.3109s
	iters: 3900, epoch: 3 | loss: 0.0685307
	speed: 0.1207s/iter; left time: 9237.0347s
	iters: 4000, epoch: 3 | loss: 0.0735308
	speed: 0.1149s/iter; left time: 8783.5225s
	iters: 4100, epoch: 3 | loss: 0.0800254
	speed: 0.1215s/iter; left time: 9274.1045s
	iters: 4200, epoch: 3 | loss: 0.0855180
	speed: 0.1197s/iter; left time: 9127.2369s
	iters: 4300, epoch: 3 | loss: 0.0667157
	speed: 0.1188s/iter; left time: 9043.9897s
	iters: 4400, epoch: 3 | loss: 0.0843554
	speed: 0.1210s/iter; left time: 9199.0788s
Epoch: 3 cost time: 00h:08m:51.03s
Epoch: 3 | Train Loss: 0.0853331 Vali Loss: 0.0911640 Test Loss: 0.0942841
Validation loss decreased (0.091892 --> 0.091164).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0739329
	speed: 1.5751s/iter; left time: 119485.9570s
	iters: 200, epoch: 4 | loss: 0.1006263
	speed: 0.1209s/iter; left time: 9162.6537s
	iters: 300, epoch: 4 | loss: 0.0738416
	speed: 0.1219s/iter; left time: 9221.1973s
	iters: 400, epoch: 4 | loss: 0.0781351
	speed: 0.1209s/iter; left time: 9134.3896s
	iters: 500, epoch: 4 | loss: 0.0675929
	speed: 0.1616s/iter; left time: 12192.9210s
	iters: 600, epoch: 4 | loss: 0.0722866
	speed: 0.1212s/iter; left time: 9137.0161s
	iters: 700, epoch: 4 | loss: 0.0852794
	speed: 0.1158s/iter; left time: 8716.6295s
	iters: 800, epoch: 4 | loss: 0.0830615
	speed: 0.1210s/iter; left time: 9092.4862s
	iters: 900, epoch: 4 | loss: 0.0746369
	speed: 0.1613s/iter; left time: 12107.7911s
	iters: 1000, epoch: 4 | loss: 0.0714534
	speed: 0.1234s/iter; left time: 9251.8166s
	iters: 1100, epoch: 4 | loss: 0.0721987
	speed: 0.1207s/iter; left time: 9035.8895s
	iters: 1200, epoch: 4 | loss: 0.0848372
	speed: 0.1205s/iter; left time: 9010.3220s
	iters: 1300, epoch: 4 | loss: 0.0901184
	speed: 0.1573s/iter; left time: 11743.9495s
	iters: 1400, epoch: 4 | loss: 0.0873635
	speed: 0.1285s/iter; left time: 9583.9484s
	iters: 1500, epoch: 4 | loss: 0.0672005
	speed: 0.1224s/iter; left time: 9114.7411s
	iters: 1600, epoch: 4 | loss: 0.0815371
	speed: 0.1203s/iter; left time: 8943.0981s
	iters: 1700, epoch: 4 | loss: 0.0967667
	speed: 0.1208s/iter; left time: 8973.0430s
	iters: 1800, epoch: 4 | loss: 0.1003437
	speed: 0.1211s/iter; left time: 8980.7266s
	iters: 1900, epoch: 4 | loss: 0.0772678
	speed: 0.1542s/iter; left time: 11423.2844s
	iters: 2000, epoch: 4 | loss: 0.1023371
	speed: 0.1282s/iter; left time: 9481.5764s
	iters: 2100, epoch: 4 | loss: 0.0959407
	speed: 0.1217s/iter; left time: 8984.7863s
	iters: 2200, epoch: 4 | loss: 0.0707141
	speed: 0.1211s/iter; left time: 8928.6897s
	iters: 2300, epoch: 4 | loss: 0.1181110
	speed: 0.1264s/iter; left time: 9308.8616s
	iters: 2400, epoch: 4 | loss: 0.0988108
	speed: 0.1570s/iter; left time: 11546.0326s
	iters: 2500, epoch: 4 | loss: 0.1022194
	speed: 0.1148s/iter; left time: 8433.7342s
	iters: 2600, epoch: 4 | loss: 0.0755848
	speed: 0.1217s/iter; left time: 8929.4115s
	iters: 2700, epoch: 4 | loss: 0.0852136
	speed: 0.1394s/iter; left time: 10214.4611s
	iters: 2800, epoch: 4 | loss: 0.1073938
	speed: 0.1217s/iter; left time: 8905.8013s
	iters: 2900, epoch: 4 | loss: 0.0776819
	speed: 0.1183s/iter; left time: 8640.5381s
	iters: 3000, epoch: 4 | loss: 0.0915424
	speed: 0.1195s/iter; left time: 8721.6179s
	iters: 3100, epoch: 4 | loss: 0.0914509
	speed: 0.1557s/iter; left time: 11345.9065s
	iters: 3200, epoch: 4 | loss: 0.0769955
	speed: 0.1204s/iter; left time: 8761.4653s
	iters: 3300, epoch: 4 | loss: 0.0912195
	speed: 0.1214s/iter; left time: 8822.1983s
	iters: 3400, epoch: 4 | loss: 0.0864609
	speed: 0.1212s/iter; left time: 8793.5615s
	iters: 3500, epoch: 4 | loss: 0.0855569
	speed: 0.1217s/iter; left time: 8819.5937s
	iters: 3600, epoch: 4 | loss: 0.0880700
	speed: 0.1445s/iter; left time: 10453.5241s
	iters: 3700, epoch: 4 | loss: 0.0775939
	speed: 0.1287s/iter; left time: 9298.6587s
	iters: 3800, epoch: 4 | loss: 0.0855137
	speed: 0.1210s/iter; left time: 8732.5153s
	iters: 3900, epoch: 4 | loss: 0.0877626
	speed: 0.1311s/iter; left time: 9447.9111s
	iters: 4000, epoch: 4 | loss: 0.0802846
	speed: 0.1531s/iter; left time: 11019.7332s
	iters: 4100, epoch: 4 | loss: 0.0870235
	speed: 0.1202s/iter; left time: 8638.0521s
	iters: 4200, epoch: 4 | loss: 0.0716099
	speed: 0.1345s/iter; left time: 9651.9577s
	iters: 4300, epoch: 4 | loss: 0.0780072
	speed: 0.1451s/iter; left time: 10396.8526s
	iters: 4400, epoch: 4 | loss: 0.0948033
	speed: 0.1208s/iter; left time: 8646.7113s
Epoch: 4 cost time: 00h:09m:41.36s
Epoch: 4 | Train Loss: 0.0836256 Vali Loss: 0.0897763 Test Loss: 0.0933365
Validation loss decreased (0.091164 --> 0.089776).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0797964
	speed: 1.6825s/iter; left time: 120113.0804s
	iters: 200, epoch: 5 | loss: 0.0838478
	speed: 0.1207s/iter; left time: 8605.6644s
	iters: 300, epoch: 5 | loss: 0.0742453
	speed: 0.1548s/iter; left time: 11019.3590s
	iters: 400, epoch: 5 | loss: 0.0888728
	speed: 0.1216s/iter; left time: 8646.1914s
	iters: 500, epoch: 5 | loss: 0.0898506
	speed: 0.1207s/iter; left time: 8569.6621s
	iters: 600, epoch: 5 | loss: 0.0773116
	speed: 0.1457s/iter; left time: 10326.1741s
	iters: 700, epoch: 5 | loss: 0.0626944
	speed: 0.1284s/iter; left time: 9086.7536s
	iters: 800, epoch: 5 | loss: 0.0781008
	speed: 0.1147s/iter; left time: 8110.4766s
	iters: 900, epoch: 5 | loss: 0.0825634
	speed: 0.1206s/iter; left time: 8514.5172s
	iters: 1000, epoch: 5 | loss: 0.0848518
	speed: 0.1509s/iter; left time: 10635.2940s
	iters: 1100, epoch: 5 | loss: 0.0829829
	speed: 0.1326s/iter; left time: 9335.2717s
	iters: 1200, epoch: 5 | loss: 0.0997171
	speed: 0.1181s/iter; left time: 8299.2913s
	iters: 1300, epoch: 5 | loss: 0.0798143
	speed: 0.1196s/iter; left time: 8395.6304s
	iters: 1400, epoch: 5 | loss: 0.0764720
	speed: 0.1530s/iter; left time: 10727.0176s
	iters: 1500, epoch: 5 | loss: 0.0732888
	speed: 0.1260s/iter; left time: 8821.3736s
	iters: 1600, epoch: 5 | loss: 0.0836849
	speed: 0.1204s/iter; left time: 8415.5389s
	iters: 1700, epoch: 5 | loss: 0.0724503
	speed: 0.1406s/iter; left time: 9809.6076s
	iters: 1800, epoch: 5 | loss: 0.0894237
	speed: 0.1403s/iter; left time: 9779.9427s
	iters: 1900, epoch: 5 | loss: 0.0685364
	speed: 0.1195s/iter; left time: 8316.1751s
	iters: 2000, epoch: 5 | loss: 0.0697801
	speed: 0.1171s/iter; left time: 8135.1213s
	iters: 2100, epoch: 5 | loss: 0.0814900
	speed: 0.1078s/iter; left time: 7481.2610s
	iters: 2200, epoch: 5 | loss: 0.0934933
	speed: 0.1019s/iter; left time: 7062.4884s
	iters: 2300, epoch: 5 | loss: 0.0861936
	speed: 0.1025s/iter; left time: 7088.5370s
	iters: 2400, epoch: 5 | loss: 0.0938417
	speed: 0.1554s/iter; left time: 10735.7135s
	iters: 2500, epoch: 5 | loss: 0.0799977
	speed: 0.1214s/iter; left time: 8373.0285s
	iters: 2600, epoch: 5 | loss: 0.0855416
	speed: 0.1211s/iter; left time: 8341.9388s
	iters: 2700, epoch: 5 | loss: 0.0920220
	speed: 0.1405s/iter; left time: 9663.2917s
	iters: 2800, epoch: 5 | loss: 0.0856894
	speed: 0.1414s/iter; left time: 9714.7333s
	iters: 2900, epoch: 5 | loss: 0.0774287
	speed: 0.1193s/iter; left time: 8185.5089s
	iters: 3000, epoch: 5 | loss: 0.0683412
	speed: 0.1201s/iter; left time: 8226.2273s
	iters: 3100, epoch: 5 | loss: 0.0973268
	speed: 0.1302s/iter; left time: 8900.9362s
	iters: 3200, epoch: 5 | loss: 0.0831058
	speed: 0.1522s/iter; left time: 10392.6295s
	iters: 3300, epoch: 5 | loss: 0.0682414
	speed: 0.1210s/iter; left time: 8250.6529s
	iters: 3400, epoch: 5 | loss: 0.0845700
	speed: 0.1202s/iter; left time: 8186.1621s
	iters: 3500, epoch: 5 | loss: 0.0771565
	speed: 0.1234s/iter; left time: 8387.2050s
	iters: 3600, epoch: 5 | loss: 0.0795133
	speed: 0.1561s/iter; left time: 10595.3193s
	iters: 3700, epoch: 5 | loss: 0.0733312
	speed: 0.1199s/iter; left time: 8130.2394s
	iters: 3800, epoch: 5 | loss: 0.0908493
	speed: 0.1191s/iter; left time: 8063.4771s
	iters: 3900, epoch: 5 | loss: 0.0670330
	speed: 0.1192s/iter; left time: 8059.2152s
	iters: 4000, epoch: 5 | loss: 0.0631396
	speed: 0.1589s/iter; left time: 10721.2013s
	iters: 4100, epoch: 5 | loss: 0.0828409
	speed: 0.1196s/iter; left time: 8061.6134s
	iters: 4200, epoch: 5 | loss: 0.0800139
	speed: 0.1210s/iter; left time: 8140.4813s
	iters: 4300, epoch: 5 | loss: 0.0884054
	speed: 0.1562s/iter; left time: 10492.0341s
	iters: 4400, epoch: 5 | loss: 0.0831661
	speed: 0.1185s/iter; left time: 7947.1889s
Epoch: 5 cost time: 00h:09m:33.96s
Epoch: 5 | Train Loss: 0.0823728 Vali Loss: 0.0899557 Test Loss: 0.0942943
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1001324
	speed: 1.6708s/iter; left time: 111810.1650s
	iters: 200, epoch: 6 | loss: 0.0886922
	speed: 0.1318s/iter; left time: 8803.8995s
	iters: 300, epoch: 6 | loss: 0.0843214
	speed: 0.1528s/iter; left time: 10197.6064s
	iters: 400, epoch: 6 | loss: 0.0734667
	speed: 0.1210s/iter; left time: 8060.7556s
	iters: 500, epoch: 6 | loss: 0.0924280
	speed: 0.1455s/iter; left time: 9680.0229s
	iters: 600, epoch: 6 | loss: 0.0591974
	speed: 0.1367s/iter; left time: 9079.1461s
	iters: 700, epoch: 6 | loss: 0.0633274
	speed: 0.1209s/iter; left time: 8018.2186s
	iters: 800, epoch: 6 | loss: 0.0738303
	speed: 0.1202s/iter; left time: 7959.3180s
	iters: 900, epoch: 6 | loss: 0.1071520
	speed: 0.1158s/iter; left time: 7656.4232s
	iters: 1000, epoch: 6 | loss: 0.0735545
	speed: 0.1233s/iter; left time: 8140.8660s
	iters: 1100, epoch: 6 | loss: 0.0729964
	speed: 0.1556s/iter; left time: 10255.7375s
	iters: 1200, epoch: 6 | loss: 0.0962333
	speed: 0.1186s/iter; left time: 7806.7293s
	iters: 1300, epoch: 6 | loss: 0.0923874
	speed: 0.1213s/iter; left time: 7969.9441s
	iters: 1400, epoch: 6 | loss: 0.0971264
	speed: 0.1160s/iter; left time: 7614.2612s
	iters: 1500, epoch: 6 | loss: 0.0751228
	speed: 0.1507s/iter; left time: 9875.4807s
	iters: 1600, epoch: 6 | loss: 0.0779485
	speed: 0.1091s/iter; left time: 7135.3030s
	iters: 1700, epoch: 6 | loss: 0.0823796
	speed: 0.1208s/iter; left time: 7892.8797s
	iters: 1800, epoch: 6 | loss: 0.0782527
	speed: 0.1473s/iter; left time: 9604.4940s
	iters: 1900, epoch: 6 | loss: 0.0854593
	speed: 0.1331s/iter; left time: 8666.9516s
	iters: 2000, epoch: 6 | loss: 0.0940582
	speed: 0.1176s/iter; left time: 7644.1771s
	iters: 2100, epoch: 6 | loss: 0.0806722
	speed: 0.1544s/iter; left time: 10026.9168s
	iters: 2200, epoch: 6 | loss: 0.0820966
	speed: 0.1203s/iter; left time: 7796.4247s
	iters: 2300, epoch: 6 | loss: 0.0738427
	speed: 0.1197s/iter; left time: 7747.7731s
	iters: 2400, epoch: 6 | loss: 0.0772219
	speed: 0.1564s/iter; left time: 10104.9567s
	iters: 2500, epoch: 6 | loss: 0.0898360
	speed: 0.1205s/iter; left time: 7774.9168s
	iters: 2600, epoch: 6 | loss: 0.0820411
	speed: 0.1266s/iter; left time: 8154.3153s
	iters: 2700, epoch: 6 | loss: 0.0796860
	speed: 0.1542s/iter; left time: 9920.2409s
	iters: 2800, epoch: 6 | loss: 0.0989802
	speed: 0.1162s/iter; left time: 7460.3102s
	iters: 2900, epoch: 6 | loss: 0.0941869
	speed: 0.1145s/iter; left time: 7343.4061s
	iters: 3000, epoch: 6 | loss: 0.0823741
	speed: 0.1236s/iter; left time: 7915.9428s
	iters: 3100, epoch: 6 | loss: 0.0726927
	speed: 0.1581s/iter; left time: 10105.1874s
	iters: 3200, epoch: 6 | loss: 0.0867132
	speed: 0.1213s/iter; left time: 7743.3463s
	iters: 3300, epoch: 6 | loss: 0.0877910
	speed: 0.1177s/iter; left time: 7498.0555s
	iters: 3400, epoch: 6 | loss: 0.1008532
	speed: 0.1493s/iter; left time: 9499.9750s
	iters: 3500, epoch: 6 | loss: 0.0882527
	speed: 0.1319s/iter; left time: 8376.0138s
	iters: 3600, epoch: 6 | loss: 0.0798398
	speed: 0.1200s/iter; left time: 7610.1461s
	iters: 3700, epoch: 6 | loss: 0.0708239
	speed: 0.1251s/iter; left time: 7920.3229s
	iters: 3800, epoch: 6 | loss: 0.0720952
	speed: 0.1517s/iter; left time: 9590.4479s
	iters: 3900, epoch: 6 | loss: 0.0832081
	speed: 0.1141s/iter; left time: 7201.5126s
	iters: 4000, epoch: 6 | loss: 0.0772891
	speed: 0.1192s/iter; left time: 7513.3598s
	iters: 4100, epoch: 6 | loss: 0.0615834
	speed: 0.1415s/iter; left time: 8903.2743s
	iters: 4200, epoch: 6 | loss: 0.0647544
	speed: 0.1340s/iter; left time: 8415.5606s
	iters: 4300, epoch: 6 | loss: 0.0650132
	speed: 0.1066s/iter; left time: 6687.0348s
	iters: 4400, epoch: 6 | loss: 0.0766972
	speed: 0.1067s/iter; left time: 6681.0852s
Epoch: 6 cost time: 00h:09m:37.26s
Epoch: 6 | Train Loss: 0.0813646 Vali Loss: 0.0895673 Test Loss: 0.0940461
Validation loss decreased (0.089776 --> 0.089567).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0841343
	speed: 1.6971s/iter; left time: 105990.2438s
	iters: 200, epoch: 7 | loss: 0.0774401
	speed: 0.1453s/iter; left time: 9059.3249s
	iters: 300, epoch: 7 | loss: 0.0646475
	speed: 0.1302s/iter; left time: 8104.1409s
	iters: 400, epoch: 7 | loss: 0.0766103
	speed: 0.1208s/iter; left time: 7509.1848s
	iters: 500, epoch: 7 | loss: 0.0919630
	speed: 0.1410s/iter; left time: 8748.9815s
	iters: 600, epoch: 7 | loss: 0.0806891
	speed: 0.1334s/iter; left time: 8263.3842s
	iters: 700, epoch: 7 | loss: 0.0947759
	speed: 0.1209s/iter; left time: 7479.3932s
	iters: 800, epoch: 7 | loss: 0.0886568
	speed: 0.1441s/iter; left time: 8898.4921s
	iters: 900, epoch: 7 | loss: 0.0786587
	speed: 0.1364s/iter; left time: 8409.6439s
	iters: 1000, epoch: 7 | loss: 0.0800228
	speed: 0.1187s/iter; left time: 7307.6731s
	iters: 1100, epoch: 7 | loss: 0.0899325
	speed: 0.1234s/iter; left time: 7583.9053s
	iters: 1200, epoch: 7 | loss: 0.0851249
	speed: 0.1509s/iter; left time: 9257.0258s
	iters: 1300, epoch: 7 | loss: 0.0694570
	speed: 0.1199s/iter; left time: 7345.7630s
	iters: 1400, epoch: 7 | loss: 0.0889620
	speed: 0.1271s/iter; left time: 7771.9487s
	iters: 1500, epoch: 7 | loss: 0.0885222
	speed: 0.1511s/iter; left time: 9226.0427s
	iters: 1600, epoch: 7 | loss: 0.0703967
	speed: 0.1193s/iter; left time: 7268.7828s
	iters: 1700, epoch: 7 | loss: 0.0967138
	speed: 0.1283s/iter; left time: 7804.6455s
	iters: 1800, epoch: 7 | loss: 0.0742753
	speed: 0.1533s/iter; left time: 9311.5068s
	iters: 1900, epoch: 7 | loss: 0.0714891
	speed: 0.1197s/iter; left time: 7258.1470s
	iters: 2000, epoch: 7 | loss: 0.0690335
	speed: 0.1208s/iter; left time: 7316.2707s
	iters: 2100, epoch: 7 | loss: 0.0778978
	speed: 0.1536s/iter; left time: 9286.0480s
	iters: 2200, epoch: 7 | loss: 0.0716214
	speed: 0.1047s/iter; left time: 6317.3215s
	iters: 2300, epoch: 7 | loss: 0.0747692
	speed: 0.1207s/iter; left time: 7274.7034s
	iters: 2400, epoch: 7 | loss: 0.0834282
	speed: 0.1451s/iter; left time: 8730.6239s
	iters: 2500, epoch: 7 | loss: 0.0855097
	speed: 0.1285s/iter; left time: 7719.3942s
	iters: 2600, epoch: 7 | loss: 0.0906422
	speed: 0.1209s/iter; left time: 7248.9929s
	iters: 2700, epoch: 7 | loss: 0.0708709
	speed: 0.1379s/iter; left time: 8252.6684s
	iters: 2800, epoch: 7 | loss: 0.0859929
	speed: 0.1377s/iter; left time: 8230.1849s
	iters: 2900, epoch: 7 | loss: 0.0687493
	speed: 0.1206s/iter; left time: 7194.0892s
	iters: 3000, epoch: 7 | loss: 0.0796787
	speed: 0.1326s/iter; left time: 7899.1205s
	iters: 3100, epoch: 7 | loss: 0.0671332
	speed: 0.1472s/iter; left time: 8753.9574s
	iters: 3200, epoch: 7 | loss: 0.0683739
	speed: 0.1200s/iter; left time: 7125.1924s
	iters: 3300, epoch: 7 | loss: 0.0691068
	speed: 0.1379s/iter; left time: 8169.7836s
	iters: 3400, epoch: 7 | loss: 0.0798232
	speed: 0.1398s/iter; left time: 8270.7923s
	iters: 3500, epoch: 7 | loss: 0.0687565
	speed: 0.1051s/iter; left time: 6207.9130s
	iters: 3600, epoch: 7 | loss: 0.0730739
	speed: 0.1269s/iter; left time: 7482.7341s
	iters: 3700, epoch: 7 | loss: 0.0768365
	speed: 0.1406s/iter; left time: 8277.6120s
	iters: 3800, epoch: 7 | loss: 0.0917242
	speed: 0.1198s/iter; left time: 7040.4023s
	iters: 3900, epoch: 7 | loss: 0.0721889
	speed: 0.1491s/iter; left time: 8746.6480s
	iters: 4000, epoch: 7 | loss: 0.1057147
	speed: 0.1304s/iter; left time: 7634.8557s
	iters: 4100, epoch: 7 | loss: 0.0877508
	speed: 0.1103s/iter; left time: 6445.3567s
	iters: 4200, epoch: 7 | loss: 0.0842020
	speed: 0.1505s/iter; left time: 8784.2172s
	iters: 4300, epoch: 7 | loss: 0.0788388
	speed: 0.1296s/iter; left time: 7551.2531s
	iters: 4400, epoch: 7 | loss: 0.0780672
	speed: 0.1202s/iter; left time: 6990.5437s
Epoch: 7 cost time: 00h:09m:46.16s
Epoch: 7 | Train Loss: 0.0802900 Vali Loss: 0.0892569 Test Loss: 0.0938624
Validation loss decreased (0.089567 --> 0.089257).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0878868
	speed: 1.6872s/iter; left time: 97831.4956s
	iters: 200, epoch: 8 | loss: 0.0819466
	speed: 0.1205s/iter; left time: 6976.1434s
	iters: 300, epoch: 8 | loss: 0.0872314
	speed: 0.1211s/iter; left time: 6995.2544s
	iters: 400, epoch: 8 | loss: 0.0871727
	speed: 0.1210s/iter; left time: 6979.9712s
	iters: 500, epoch: 8 | loss: 0.0690386
	speed: 0.1410s/iter; left time: 8119.3008s
	iters: 600, epoch: 8 | loss: 0.0786107
	speed: 0.1349s/iter; left time: 7752.5776s
	iters: 700, epoch: 8 | loss: 0.0654001
	speed: 0.1192s/iter; left time: 6840.1877s
	iters: 800, epoch: 8 | loss: 0.0706811
	speed: 0.1149s/iter; left time: 6583.8160s
	iters: 900, epoch: 8 | loss: 0.0823400
	speed: 0.1549s/iter; left time: 8857.3411s
	iters: 1000, epoch: 8 | loss: 0.0656414
	speed: 0.1250s/iter; left time: 7134.1351s
	iters: 1100, epoch: 8 | loss: 0.0717802
	speed: 0.1201s/iter; left time: 6844.8365s
	iters: 1200, epoch: 8 | loss: 0.0914649
	speed: 0.1264s/iter; left time: 7191.4123s
	iters: 1300, epoch: 8 | loss: 0.0788195
	speed: 0.1518s/iter; left time: 8619.8951s
	iters: 1400, epoch: 8 | loss: 0.0938862
	speed: 0.1210s/iter; left time: 6857.0610s
	iters: 1500, epoch: 8 | loss: 0.0883940
	speed: 0.1207s/iter; left time: 6827.9290s
	iters: 1600, epoch: 8 | loss: 0.0923529
	speed: 0.1416s/iter; left time: 7999.9330s
	iters: 1700, epoch: 8 | loss: 0.1006962
	speed: 0.1328s/iter; left time: 7488.5343s
	iters: 1800, epoch: 8 | loss: 0.0933289
	speed: 0.1191s/iter; left time: 6702.1349s
	iters: 1900, epoch: 8 | loss: 0.0580641
	speed: 0.1212s/iter; left time: 6810.4715s
	iters: 2000, epoch: 8 | loss: 0.0778803
	speed: 0.1564s/iter; left time: 8771.1030s
	iters: 2100, epoch: 8 | loss: 0.0813645
	speed: 0.1214s/iter; left time: 6794.5474s
	iters: 2200, epoch: 8 | loss: 0.0837200
	speed: 0.1197s/iter; left time: 6688.4300s
	iters: 2300, epoch: 8 | loss: 0.0852636
	speed: 0.1273s/iter; left time: 7103.4942s
	iters: 2400, epoch: 8 | loss: 0.0721436
	speed: 0.1512s/iter; left time: 8417.9630s
	iters: 2500, epoch: 8 | loss: 0.0740744
	speed: 0.1191s/iter; left time: 6618.6066s
	iters: 2600, epoch: 8 | loss: 0.0824070
	speed: 0.1290s/iter; left time: 7158.7539s
	iters: 2700, epoch: 8 | loss: 0.0793054
	speed: 0.1516s/iter; left time: 8396.6055s
	iters: 2800, epoch: 8 | loss: 0.0864588
	speed: 0.1050s/iter; left time: 5804.8515s
	iters: 2900, epoch: 8 | loss: 0.0741376
	speed: 0.1051s/iter; left time: 5800.5858s
	iters: 3000, epoch: 8 | loss: 0.0899623
	speed: 0.1102s/iter; left time: 6072.9682s
	iters: 3100, epoch: 8 | loss: 0.0805951
	speed: 0.1538s/iter; left time: 8459.3076s
	iters: 3200, epoch: 8 | loss: 0.0612919
	speed: 0.1160s/iter; left time: 6367.2286s
	iters: 3300, epoch: 8 | loss: 0.0753164
	speed: 0.1196s/iter; left time: 6550.9213s
	iters: 3400, epoch: 8 | loss: 0.0797729
	speed: 0.1448s/iter; left time: 7920.2862s
	iters: 3500, epoch: 8 | loss: 0.0591326
	speed: 0.1337s/iter; left time: 7298.2519s
	iters: 3600, epoch: 8 | loss: 0.0769536
	speed: 0.1211s/iter; left time: 6598.1463s
	iters: 3700, epoch: 8 | loss: 0.0768749
	speed: 0.1197s/iter; left time: 6509.4649s
	iters: 3800, epoch: 8 | loss: 0.0756438
	speed: 0.1584s/iter; left time: 8597.5746s
	iters: 3900, epoch: 8 | loss: 0.0782435
	speed: 0.1152s/iter; left time: 6242.1408s
	iters: 4000, epoch: 8 | loss: 0.0735168
	speed: 0.1213s/iter; left time: 6559.2425s
	iters: 4100, epoch: 8 | loss: 0.0852071
	speed: 0.1311s/iter; left time: 7078.2596s
	iters: 4200, epoch: 8 | loss: 0.0820105
	speed: 0.1423s/iter; left time: 7665.8085s
	iters: 4300, epoch: 8 | loss: 0.0806806
	speed: 0.1109s/iter; left time: 5962.9593s
	iters: 4400, epoch: 8 | loss: 0.0883520
	speed: 0.1045s/iter; left time: 5609.5571s
Epoch: 8 cost time: 00h:09m:34.58s
Epoch: 8 | Train Loss: 0.0793348 Vali Loss: 0.0892188 Test Loss: 0.0953779
Validation loss decreased (0.089257 --> 0.089219).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0749750
	speed: 1.6773s/iter; left time: 89764.7265s
	iters: 200, epoch: 9 | loss: 0.0862554
	speed: 0.1135s/iter; left time: 6065.2316s
	iters: 300, epoch: 9 | loss: 0.0647535
	speed: 0.1344s/iter; left time: 7165.1353s
	iters: 400, epoch: 9 | loss: 0.0730983
	speed: 0.1320s/iter; left time: 7024.5095s
	iters: 500, epoch: 9 | loss: 0.0695380
	speed: 0.1122s/iter; left time: 5960.2705s
	iters: 600, epoch: 9 | loss: 0.0691377
	speed: 0.1210s/iter; left time: 6417.0322s
	iters: 700, epoch: 9 | loss: 0.0765528
	speed: 0.1578s/iter; left time: 8351.9232s
	iters: 800, epoch: 9 | loss: 0.0613169
	speed: 0.1209s/iter; left time: 6385.8888s
	iters: 900, epoch: 9 | loss: 0.0732772
	speed: 0.1164s/iter; left time: 6135.6456s
	iters: 1000, epoch: 9 | loss: 0.0607491
	speed: 0.1489s/iter; left time: 7832.2444s
	iters: 1100, epoch: 9 | loss: 0.0597287
	speed: 0.1216s/iter; left time: 6385.4394s
	iters: 1200, epoch: 9 | loss: 0.0944503
	speed: 0.1198s/iter; left time: 6278.5210s
	iters: 1300, epoch: 9 | loss: 0.0612135
	speed: 0.1364s/iter; left time: 7136.6241s
	iters: 1400, epoch: 9 | loss: 0.0633327
	speed: 0.1396s/iter; left time: 7288.1260s
	iters: 1500, epoch: 9 | loss: 0.0837415
	speed: 0.1143s/iter; left time: 5954.7379s
	iters: 1600, epoch: 9 | loss: 0.0839318
	speed: 0.1176s/iter; left time: 6115.8891s
	iters: 1700, epoch: 9 | loss: 0.0879491
	speed: 0.1477s/iter; left time: 7670.7071s
	iters: 1800, epoch: 9 | loss: 0.0665905
	speed: 0.1292s/iter; left time: 6695.1245s
	iters: 1900, epoch: 9 | loss: 0.0713467
	speed: 0.1193s/iter; left time: 6170.6154s
	iters: 2000, epoch: 9 | loss: 0.0669027
	speed: 0.1151s/iter; left time: 5941.0115s
	iters: 2100, epoch: 9 | loss: 0.0749533
	speed: 0.1541s/iter; left time: 7941.1463s
	iters: 2200, epoch: 9 | loss: 0.0823501
	speed: 0.1139s/iter; left time: 5855.2614s
	iters: 2300, epoch: 9 | loss: 0.0919251
	speed: 0.1204s/iter; left time: 6180.4084s
	iters: 2400, epoch: 9 | loss: 0.0902282
	speed: 0.1537s/iter; left time: 7869.5237s
	iters: 2500, epoch: 9 | loss: 0.0695416
	speed: 0.1191s/iter; left time: 6088.7717s
	iters: 2600, epoch: 9 | loss: 0.0872029
	speed: 0.1158s/iter; left time: 5910.0955s
	iters: 2700, epoch: 9 | loss: 0.0668999
	speed: 0.1503s/iter; left time: 7651.5917s
	iters: 2800, epoch: 9 | loss: 0.0708064
	speed: 0.1022s/iter; left time: 5191.8166s
	iters: 2900, epoch: 9 | loss: 0.0776473
	speed: 0.1030s/iter; left time: 5223.8619s
	iters: 3000, epoch: 9 | loss: 0.0897343
	speed: 0.1531s/iter; left time: 7748.4527s
	iters: 3100, epoch: 9 | loss: 0.0689395
	speed: 0.1170s/iter; left time: 5912.9757s
	iters: 3200, epoch: 9 | loss: 0.0872946
	speed: 0.1195s/iter; left time: 6024.1047s
	iters: 3300, epoch: 9 | loss: 0.0869129
	speed: 0.1420s/iter; left time: 7144.3381s
	iters: 3400, epoch: 9 | loss: 0.0875106
	speed: 0.1223s/iter; left time: 6140.0551s
	iters: 3500, epoch: 9 | loss: 0.0698793
	speed: 0.1173s/iter; left time: 5876.5451s
	iters: 3600, epoch: 9 | loss: 0.0638036
	speed: 0.1303s/iter; left time: 6515.6347s
	iters: 3700, epoch: 9 | loss: 0.0692865
	speed: 0.1507s/iter; left time: 7524.7252s
	iters: 3800, epoch: 9 | loss: 0.0771837
	speed: 0.1186s/iter; left time: 5909.1991s
	iters: 3900, epoch: 9 | loss: 0.0842480
	speed: 0.1195s/iter; left time: 5941.2705s
	iters: 4000, epoch: 9 | loss: 0.0725595
	speed: 0.1591s/iter; left time: 7892.0822s
	iters: 4100, epoch: 9 | loss: 0.0908936
	speed: 0.1193s/iter; left time: 5907.0966s
	iters: 4200, epoch: 9 | loss: 0.0893085
	speed: 0.1202s/iter; left time: 5940.5455s
	iters: 4300, epoch: 9 | loss: 0.0930462
	speed: 0.1522s/iter; left time: 7507.5584s
	iters: 4400, epoch: 9 | loss: 0.0681519
	speed: 0.1307s/iter; left time: 6434.3234s
Epoch: 9 cost time: 00h:09m:32.08s
Epoch: 9 | Train Loss: 0.0783692 Vali Loss: 0.0899408 Test Loss: 0.0950079
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0844053
	speed: 1.6820s/iter; left time: 82500.9715s
	iters: 200, epoch: 10 | loss: 0.1195817
	speed: 0.1220s/iter; left time: 5973.9608s
	iters: 300, epoch: 10 | loss: 0.0776654
	speed: 0.1599s/iter; left time: 7809.4879s
	iters: 400, epoch: 10 | loss: 0.0721945
	speed: 0.1211s/iter; left time: 5904.7809s
	iters: 500, epoch: 10 | loss: 0.0767422
	speed: 0.1216s/iter; left time: 5917.7887s
	iters: 600, epoch: 10 | loss: 0.0819118
	speed: 0.1581s/iter; left time: 7674.0386s
	iters: 700, epoch: 10 | loss: 0.0688704
	speed: 0.1237s/iter; left time: 5992.1816s
	iters: 800, epoch: 10 | loss: 0.1010805
	speed: 0.1214s/iter; left time: 5871.1173s
	iters: 900, epoch: 10 | loss: 0.0890266
	speed: 0.1314s/iter; left time: 6341.3654s
	iters: 1000, epoch: 10 | loss: 0.0743395
	speed: 0.1494s/iter; left time: 7193.9878s
	iters: 1100, epoch: 10 | loss: 0.0623439
	speed: 0.1205s/iter; left time: 5787.8720s
	iters: 1200, epoch: 10 | loss: 0.0886193
	speed: 0.1126s/iter; left time: 5400.9335s
	iters: 1300, epoch: 10 | loss: 0.0903579
	speed: 0.1496s/iter; left time: 7157.8160s
	iters: 1400, epoch: 10 | loss: 0.0970001
	speed: 0.1310s/iter; left time: 6257.2289s
	iters: 1500, epoch: 10 | loss: 0.0763897
	speed: 0.1210s/iter; left time: 5763.8773s
	iters: 1600, epoch: 10 | loss: 0.0659897
	speed: 0.1204s/iter; left time: 5725.3021s
	iters: 1700, epoch: 10 | loss: 0.0725043
	speed: 0.1306s/iter; left time: 6196.2052s
	iters: 1800, epoch: 10 | loss: 0.0614413
	speed: 0.1510s/iter; left time: 7151.3524s
	iters: 1900, epoch: 10 | loss: 0.0763310
	speed: 0.1200s/iter; left time: 5670.7051s
	iters: 2000, epoch: 10 | loss: 0.0819842
	speed: 0.1210s/iter; left time: 5702.9646s
	iters: 2100, epoch: 10 | loss: 0.0654081
	speed: 0.1416s/iter; left time: 6663.6799s
	iters: 2200, epoch: 10 | loss: 0.0653410
	speed: 0.1365s/iter; left time: 6409.5470s
	iters: 2300, epoch: 10 | loss: 0.0690481
	speed: 0.1202s/iter; left time: 5631.1843s
	iters: 2400, epoch: 10 | loss: 0.0936227
	speed: 0.1329s/iter; left time: 6214.4770s
	iters: 2500, epoch: 10 | loss: 0.0709767
	speed: 0.1484s/iter; left time: 6922.3963s
	iters: 2600, epoch: 10 | loss: 0.0593837
	speed: 0.1213s/iter; left time: 5647.1096s
	iters: 2700, epoch: 10 | loss: 0.1029781
	speed: 0.1414s/iter; left time: 6567.3338s
	iters: 2800, epoch: 10 | loss: 0.0660925
	speed: 0.1360s/iter; left time: 6301.7741s
	iters: 2900, epoch: 10 | loss: 0.0810724
	speed: 0.1210s/iter; left time: 5594.4079s
	iters: 3000, epoch: 10 | loss: 0.0861325
	speed: 0.1209s/iter; left time: 5577.3804s
	iters: 3100, epoch: 10 | loss: 0.0749175
	speed: 0.1580s/iter; left time: 7275.6342s
	iters: 3200, epoch: 10 | loss: 0.0772474
	speed: 0.1222s/iter; left time: 5613.8471s
	iters: 3300, epoch: 10 | loss: 0.0663424
	speed: 0.1203s/iter; left time: 5514.8633s
	iters: 3400, epoch: 10 | loss: 0.0681792
	speed: 0.1209s/iter; left time: 5531.8550s
	iters: 3500, epoch: 10 | loss: 0.0826567
	speed: 0.1595s/iter; left time: 7279.9395s
	iters: 3600, epoch: 10 | loss: 0.0750645
	speed: 0.1197s/iter; left time: 5451.1942s
	iters: 3700, epoch: 10 | loss: 0.0935027
	speed: 0.1208s/iter; left time: 5488.5839s
	iters: 3800, epoch: 10 | loss: 0.0815245
	speed: 0.1224s/iter; left time: 5550.5173s
	iters: 3900, epoch: 10 | loss: 0.0724220
	speed: 0.1588s/iter; left time: 7186.9221s
	iters: 4000, epoch: 10 | loss: 0.0900971
	speed: 0.1210s/iter; left time: 5464.2632s
	iters: 4100, epoch: 10 | loss: 0.0711545
	speed: 0.1205s/iter; left time: 5427.1613s
	iters: 4200, epoch: 10 | loss: 0.0712163
	speed: 0.1206s/iter; left time: 5421.5202s
	iters: 4300, epoch: 10 | loss: 0.0879692
	speed: 0.1413s/iter; left time: 6335.4571s
	iters: 4400, epoch: 10 | loss: 0.0614536
	speed: 0.1445s/iter; left time: 6464.5598s
Epoch: 10 cost time: 00h:09m:45.63s
Epoch: 10 | Train Loss: 0.0775587 Vali Loss: 0.0896562 Test Loss: 0.0955003
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 11 | loss: 0.0843296
	speed: 1.6467s/iter; left time: 73410.8944s
	iters: 200, epoch: 11 | loss: 0.0733311
	speed: 0.1372s/iter; left time: 6103.6812s
	iters: 300, epoch: 11 | loss: 0.0601665
	speed: 0.1466s/iter; left time: 6507.9786s
	iters: 400, epoch: 11 | loss: 0.0716488
	speed: 0.1204s/iter; left time: 5331.1016s
	iters: 500, epoch: 11 | loss: 0.0750899
	speed: 0.1204s/iter; left time: 5320.8064s
	iters: 600, epoch: 11 | loss: 0.0896189
	speed: 0.1297s/iter; left time: 5717.7175s
	iters: 700, epoch: 11 | loss: 0.0716856
	speed: 0.1524s/iter; left time: 6701.6404s
	iters: 800, epoch: 11 | loss: 0.0796735
	speed: 0.1199s/iter; left time: 5261.2863s
	iters: 900, epoch: 11 | loss: 0.0532320
	speed: 0.1202s/iter; left time: 5262.5064s
	iters: 1000, epoch: 11 | loss: 0.0739114
	speed: 0.1305s/iter; left time: 5700.7252s
	iters: 1100, epoch: 11 | loss: 0.0947660
	speed: 0.1521s/iter; left time: 6630.5899s
	iters: 1200, epoch: 11 | loss: 0.0835808
	speed: 0.1210s/iter; left time: 5262.6226s
	iters: 1300, epoch: 11 | loss: 0.0754700
	speed: 0.1211s/iter; left time: 5255.3562s
	iters: 1400, epoch: 11 | loss: 0.0658226
	speed: 0.1310s/iter; left time: 5670.0127s
	iters: 1500, epoch: 11 | loss: 0.0543421
	speed: 0.1489s/iter; left time: 6430.0778s
	iters: 1600, epoch: 11 | loss: 0.0710039
	speed: 0.1189s/iter; left time: 5122.7165s
	iters: 1700, epoch: 11 | loss: 0.0833827
	speed: 0.1207s/iter; left time: 5188.3997s
	iters: 1800, epoch: 11 | loss: 0.0674744
	speed: 0.1274s/iter; left time: 5463.6391s
	iters: 1900, epoch: 11 | loss: 0.0692966
	speed: 0.1558s/iter; left time: 6665.8844s
	iters: 2000, epoch: 11 | loss: 0.0941740
	speed: 0.1207s/iter; left time: 5151.5496s
	iters: 2100, epoch: 11 | loss: 0.0860964
	speed: 0.1289s/iter; left time: 5490.4012s
	iters: 2200, epoch: 11 | loss: 0.0810799
	speed: 0.1574s/iter; left time: 6684.8249s
	iters: 2300, epoch: 11 | loss: 0.0745259
	speed: 0.1204s/iter; left time: 5104.0232s
	iters: 2400, epoch: 11 | loss: 0.0968850
	speed: 0.1188s/iter; left time: 5021.7642s
	iters: 2500, epoch: 11 | loss: 0.0774877
	speed: 0.1575s/iter; left time: 6642.8301s
	iters: 2600, epoch: 11 | loss: 0.0719790
	speed: 0.1300s/iter; left time: 5469.4454s
	iters: 2700, epoch: 11 | loss: 0.0613416
	speed: 0.1201s/iter; left time: 5042.2762s
	iters: 2800, epoch: 11 | loss: 0.0705149
	speed: 0.1430s/iter; left time: 5988.1750s
	iters: 2900, epoch: 11 | loss: 0.0600997
	speed: 0.1413s/iter; left time: 5901.9280s
	iters: 3000, epoch: 11 | loss: 0.0838152
	speed: 0.1188s/iter; left time: 4952.1183s
	iters: 3100, epoch: 11 | loss: 0.0801776
	speed: 0.1384s/iter; left time: 5754.3264s
	iters: 3200, epoch: 11 | loss: 0.0818057
	speed: 0.1461s/iter; left time: 6059.3046s
	iters: 3300, epoch: 11 | loss: 0.0967920
	speed: 0.1119s/iter; left time: 4630.3169s
	iters: 3400, epoch: 11 | loss: 0.0851540
	speed: 0.1232s/iter; left time: 5085.6712s
	iters: 3500, epoch: 11 | loss: 0.0771672
	speed: 0.1522s/iter; left time: 6266.4869s
	iters: 3600, epoch: 11 | loss: 0.0722381
	speed: 0.1202s/iter; left time: 4939.0617s
	iters: 3700, epoch: 11 | loss: 0.0777316
	speed: 0.1207s/iter; left time: 4946.3759s
	iters: 3800, epoch: 11 | loss: 0.0811023
	speed: 0.1317s/iter; left time: 5382.7297s
	iters: 3900, epoch: 11 | loss: 0.0592589
	speed: 0.1534s/iter; left time: 6254.9859s
	iters: 4000, epoch: 11 | loss: 0.0921532
	speed: 0.1206s/iter; left time: 4906.7445s
	iters: 4100, epoch: 11 | loss: 0.0703947
	speed: 0.1207s/iter; left time: 4896.7554s
	iters: 4200, epoch: 11 | loss: 0.0643912
	speed: 0.1311s/iter; left time: 5307.3984s
	iters: 4300, epoch: 11 | loss: 0.0791592
	speed: 0.1530s/iter; left time: 6176.6614s
	iters: 4400, epoch: 11 | loss: 0.0683983
	speed: 0.1197s/iter; left time: 4820.4603s
Epoch: 11 cost time: 00h:09m:48.09s
Epoch: 11 | Train Loss: 0.0766384 Vali Loss: 0.0910036 Test Loss: 0.0970744
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 12 | loss: 0.0710792
	speed: 1.6707s/iter; left time: 67015.0552s
	iters: 200, epoch: 12 | loss: 0.0842273
	speed: 0.1495s/iter; left time: 5981.4013s
	iters: 300, epoch: 12 | loss: 0.0629760
	speed: 0.1316s/iter; left time: 5251.1875s
	iters: 400, epoch: 12 | loss: 0.0810391
	speed: 0.1248s/iter; left time: 4969.6130s
	iters: 500, epoch: 12 | loss: 0.1013014
	speed: 0.1573s/iter; left time: 6248.7412s
	iters: 600, epoch: 12 | loss: 0.0584819
	speed: 0.1200s/iter; left time: 4752.4750s
	iters: 700, epoch: 12 | loss: 0.0732251
	speed: 0.1216s/iter; left time: 4806.4958s
	iters: 800, epoch: 12 | loss: 0.0754556
	speed: 0.1612s/iter; left time: 6353.0455s
	iters: 900, epoch: 12 | loss: 0.0640929
	speed: 0.1205s/iter; left time: 4736.1670s
	iters: 1000, epoch: 12 | loss: 0.0760040
	speed: 0.1204s/iter; left time: 4723.1559s
	iters: 1100, epoch: 12 | loss: 0.0927217
	speed: 0.1297s/iter; left time: 5072.2115s
	iters: 1200, epoch: 12 | loss: 0.0876345
	speed: 0.1495s/iter; left time: 5831.9006s
	iters: 1300, epoch: 12 | loss: 0.0746380
	speed: 0.1206s/iter; left time: 4692.0863s
	iters: 1400, epoch: 12 | loss: 0.0757993
	speed: 0.1268s/iter; left time: 4921.5610s
	iters: 1500, epoch: 12 | loss: 0.0810570
	speed: 0.1479s/iter; left time: 5724.7103s
	iters: 1600, epoch: 12 | loss: 0.0619826
	speed: 0.1203s/iter; left time: 4646.6936s
	iters: 1700, epoch: 12 | loss: 0.0746262
	speed: 0.1200s/iter; left time: 4622.0712s
	iters: 1800, epoch: 12 | loss: 0.0823452
	speed: 0.1614s/iter; left time: 6199.2091s
	iters: 1900, epoch: 12 | loss: 0.0711706
	speed: 0.1201s/iter; left time: 4601.9353s
	iters: 2000, epoch: 12 | loss: 0.0654976
	speed: 0.1210s/iter; left time: 4622.7126s
	iters: 2100, epoch: 12 | loss: 0.0801418
	speed: 0.1308s/iter; left time: 4984.0991s
	iters: 2200, epoch: 12 | loss: 0.0796125
	speed: 0.1504s/iter; left time: 5718.2610s
	iters: 2300, epoch: 12 | loss: 0.0880586
	speed: 0.1189s/iter; left time: 4508.4351s
	iters: 2400, epoch: 12 | loss: 0.0664747
	speed: 0.1262s/iter; left time: 4773.4783s
	iters: 2500, epoch: 12 | loss: 0.0685178
	speed: 0.1502s/iter; left time: 5662.9363s
	iters: 2600, epoch: 12 | loss: 0.0550742
	speed: 0.1200s/iter; left time: 4513.6858s
	iters: 2700, epoch: 12 | loss: 0.0827314
	speed: 0.1201s/iter; left time: 4504.8870s
	iters: 2800, epoch: 12 | loss: 0.0665130
	speed: 0.1199s/iter; left time: 4486.0242s
	iters: 2900, epoch: 12 | loss: 0.0725770
	speed: 0.1475s/iter; left time: 5504.8553s
	iters: 3000, epoch: 12 | loss: 0.0761487
	speed: 0.1300s/iter; left time: 4838.5814s
	iters: 3100, epoch: 12 | loss: 0.0791091
	speed: 0.1203s/iter; left time: 4464.0211s
	iters: 3200, epoch: 12 | loss: 0.0671570
	speed: 0.1300s/iter; left time: 4812.7943s
	iters: 3300, epoch: 12 | loss: 0.0749104
	speed: 0.1507s/iter; left time: 5562.8798s
	iters: 3400, epoch: 12 | loss: 0.0909807
	speed: 0.1207s/iter; left time: 4441.6935s
	iters: 3500, epoch: 12 | loss: 0.0923854
	speed: 0.1210s/iter; left time: 4440.7868s
	iters: 3600, epoch: 12 | loss: 0.0831650
	speed: 0.1379s/iter; left time: 5050.0754s
	iters: 3700, epoch: 12 | loss: 0.0813926
	speed: 0.1450s/iter; left time: 5294.5065s
	iters: 3800, epoch: 12 | loss: 0.0719712
	speed: 0.1202s/iter; left time: 4378.0491s
	iters: 3900, epoch: 12 | loss: 0.0697064
	speed: 0.1287s/iter; left time: 4674.5955s
	iters: 4000, epoch: 12 | loss: 0.0884542
	speed: 0.1493s/iter; left time: 5408.3420s
	iters: 4100, epoch: 12 | loss: 0.0673367
	speed: 0.1197s/iter; left time: 4323.2589s
	iters: 4200, epoch: 12 | loss: 0.0795303
	speed: 0.1374s/iter; left time: 4948.3719s
	iters: 4300, epoch: 12 | loss: 0.0724135
	speed: 0.1409s/iter; left time: 5058.9675s
	iters: 4400, epoch: 12 | loss: 0.0837259
	speed: 0.1208s/iter; left time: 4324.9559s
Epoch: 12 cost time: 00h:09m:50.33s
Epoch: 12 | Train Loss: 0.0758073 Vali Loss: 0.0911360 Test Loss: 0.0977819
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 13 | loss: 0.0696547
	speed: 1.6608s/iter; left time: 59200.1284s
	iters: 200, epoch: 13 | loss: 0.0783792
	speed: 0.1404s/iter; left time: 4990.2061s
	iters: 300, epoch: 13 | loss: 0.0612777
	speed: 0.1444s/iter; left time: 5119.4555s
	iters: 400, epoch: 13 | loss: 0.0669738
	speed: 0.1203s/iter; left time: 4253.0101s
	iters: 500, epoch: 13 | loss: 0.0753981
	speed: 0.1297s/iter; left time: 4570.3097s
	iters: 600, epoch: 13 | loss: 0.0703675
	speed: 0.1517s/iter; left time: 5330.7711s
	iters: 700, epoch: 13 | loss: 0.0807081
	speed: 0.1123s/iter; left time: 3935.5227s
	iters: 800, epoch: 13 | loss: 0.0631655
	speed: 0.1207s/iter; left time: 4216.9096s
	iters: 900, epoch: 13 | loss: 0.0665464
	speed: 0.1192s/iter; left time: 4154.5910s
	iters: 1000, epoch: 13 | loss: 0.0889466
	speed: 0.1203s/iter; left time: 4179.3517s
	iters: 1100, epoch: 13 | loss: 0.0937114
	speed: 0.1206s/iter; left time: 4178.0988s
	iters: 1200, epoch: 13 | loss: 0.0855564
	speed: 0.1508s/iter; left time: 5210.7291s
	iters: 1300, epoch: 13 | loss: 0.0802188
	speed: 0.1318s/iter; left time: 4540.1601s
	iters: 1400, epoch: 13 | loss: 0.0752418
	speed: 0.1199s/iter; left time: 4118.0372s
	iters: 1500, epoch: 13 | loss: 0.0920139
	speed: 0.1202s/iter; left time: 4115.9709s
	iters: 1600, epoch: 13 | loss: 0.0802863
	speed: 0.1212s/iter; left time: 4138.8403s
	iters: 1700, epoch: 13 | loss: 0.0784608
	speed: 0.1204s/iter; left time: 4100.0962s
	iters: 1800, epoch: 13 | loss: 0.0880799
	speed: 0.1304s/iter; left time: 4426.9758s
	iters: 1900, epoch: 13 | loss: 0.0902761
	speed: 0.1517s/iter; left time: 5134.8778s
	iters: 2000, epoch: 13 | loss: 0.0855317
	speed: 0.1213s/iter; left time: 4093.7911s
	iters: 2100, epoch: 13 | loss: 0.0778534
	speed: 0.1204s/iter; left time: 4051.0211s
	iters: 2200, epoch: 13 | loss: 0.0732491
	speed: 0.1322s/iter; left time: 4435.5935s
	iters: 2300, epoch: 13 | loss: 0.0718696
	speed: 0.1537s/iter; left time: 5138.8353s
	iters: 2400, epoch: 13 | loss: 0.0643891
	speed: 0.1208s/iter; left time: 4027.9035s
	iters: 2500, epoch: 13 | loss: 0.0634482
	speed: 0.1201s/iter; left time: 3992.3590s
	iters: 2600, epoch: 13 | loss: 0.0696910
	speed: 0.1249s/iter; left time: 4138.7601s
	iters: 2700, epoch: 13 | loss: 0.0817821
	speed: 0.1544s/iter; left time: 5103.6425s
	iters: 2800, epoch: 13 | loss: 0.0640855
	speed: 0.1089s/iter; left time: 3588.5954s
	iters: 2900, epoch: 13 | loss: 0.0694307
	speed: 0.1201s/iter; left time: 3943.2079s
	iters: 3000, epoch: 13 | loss: 0.0864336
	speed: 0.1605s/iter; left time: 5255.3800s
	iters: 3100, epoch: 13 | loss: 0.0733568
	speed: 0.1202s/iter; left time: 3925.5034s
	iters: 3200, epoch: 13 | loss: 0.0625381
	speed: 0.1208s/iter; left time: 3931.4236s
	iters: 3300, epoch: 13 | loss: 0.0875661
	speed: 0.1379s/iter; left time: 4473.3903s
	iters: 3400, epoch: 13 | loss: 0.0675188
	speed: 0.1411s/iter; left time: 4562.7165s
	iters: 3500, epoch: 13 | loss: 0.0647626
	speed: 0.1119s/iter; left time: 3609.2749s
	iters: 3600, epoch: 13 | loss: 0.0939891
	speed: 0.1211s/iter; left time: 3893.5604s
	iters: 3700, epoch: 13 | loss: 0.0905394
	speed: 0.1586s/iter; left time: 5083.0744s
	iters: 3800, epoch: 13 | loss: 0.0685588
	speed: 0.1151s/iter; left time: 3675.9945s
	iters: 3900, epoch: 13 | loss: 0.0648391
	speed: 0.1203s/iter; left time: 3830.9470s
	iters: 4000, epoch: 13 | loss: 0.0833651
	speed: 0.1406s/iter; left time: 4463.2430s
	iters: 4100, epoch: 13 | loss: 0.0707878
	speed: 0.1389s/iter; left time: 4396.1421s
	iters: 4200, epoch: 13 | loss: 0.0837740
	speed: 0.1203s/iter; left time: 3793.8077s
	iters: 4300, epoch: 13 | loss: 0.0526903
	speed: 0.1211s/iter; left time: 3808.3084s
	iters: 4400, epoch: 13 | loss: 0.0681901
	speed: 0.1538s/iter; left time: 4820.6832s
Epoch: 13 cost time: 00h:09m:39.16s
Epoch: 13 | Train Loss: 0.0749393 Vali Loss: 0.0928503 Test Loss: 0.1000453
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.02273400127887726, rmse:0.15077798068523407, mae:0.09537788480520248, rse:0.5325193405151367
success delete checkpoints
Intermediate time for DE and pred_len 24: 02h:37m:43.65s


=== Starting experiments for pred_len: 96 ===

train 142645
val 30725
test 30725
[2024-10-31 21:29:15,883] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-31 21:29:18,388] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-10-31 21:29:18,388] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-31 21:29:18,388] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-10-31 21:29:18,489] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-10-31 21:29:18,490] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-10-31 21:29:19,157] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-10-31 21:29:19,159] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-10-31 21:29:19,159] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-10-31 21:29:19,160] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-10-31 21:29:19,161] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-10-31 21:29:19,161] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-10-31 21:29:19,161] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-10-31 21:29:19,161] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-10-31 21:29:19,161] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-10-31 21:29:19,161] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-10-31 21:29:19,477] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-10-31 21:29:19,478] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-10-31 21:29:19,479] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 193.8 GB, percent = 25.7%
[2024-10-31 21:29:19,625] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-10-31 21:29:19,626] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-10-31 21:29:19,626] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 193.8 GB, percent = 25.7%
[2024-10-31 21:29:19,626] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-10-31 21:29:19,757] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-10-31 21:29:19,758] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-10-31 21:29:19,758] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 193.8 GB, percent = 25.7%
[2024-10-31 21:29:19,759] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-10-31 21:29:19,759] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-10-31 21:29:19,759] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-10-31 21:29:19,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-10-31 21:29:19,760] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-10-31 21:29:19,760] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f61c49bb950>
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-10-31 21:29:19,761] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-10-31 21:29:19,762] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-10-31 21:29:19,763] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1857200
	speed: 0.2228s/iter; left time: 19837.2706s
	iters: 200, epoch: 1 | loss: 0.1687170
	speed: 0.1312s/iter; left time: 11665.3898s
	iters: 300, epoch: 1 | loss: 0.1724844
	speed: 0.1275s/iter; left time: 11331.5341s
	iters: 400, epoch: 1 | loss: 0.1656757
	speed: 0.1212s/iter; left time: 10756.0390s
	iters: 500, epoch: 1 | loss: 0.1675965
	speed: 0.1678s/iter; left time: 14876.8321s
	iters: 600, epoch: 1 | loss: 0.1443687
	speed: 0.1311s/iter; left time: 11606.1350s
	iters: 700, epoch: 1 | loss: 0.1422241
	speed: 0.1259s/iter; left time: 11137.4794s
	iters: 800, epoch: 1 | loss: 0.1226619
	speed: 0.1298s/iter; left time: 11469.6908s
	iters: 900, epoch: 1 | loss: 0.1330729
	speed: 0.1671s/iter; left time: 14744.7505s
	iters: 1000, epoch: 1 | loss: 0.1138731
	speed: 0.1311s/iter; left time: 11554.9099s
	iters: 1100, epoch: 1 | loss: 0.1071478
	speed: 0.1303s/iter; left time: 11474.9060s
	iters: 1200, epoch: 1 | loss: 0.1303404
	speed: 0.1307s/iter; left time: 11498.1139s
	iters: 1300, epoch: 1 | loss: 0.1238685
	speed: 0.1538s/iter; left time: 13508.1174s
	iters: 1400, epoch: 1 | loss: 0.1032463
	speed: 0.1380s/iter; left time: 12110.8463s
	iters: 1500, epoch: 1 | loss: 0.1194469
	speed: 0.1145s/iter; left time: 10035.8265s
	iters: 1600, epoch: 1 | loss: 0.1207578
	speed: 0.1304s/iter; left time: 11418.6313s
	iters: 1700, epoch: 1 | loss: 0.1394709
	speed: 0.1281s/iter; left time: 11197.9367s
	iters: 1800, epoch: 1 | loss: 0.1160002
	speed: 0.1662s/iter; left time: 14516.4179s
	iters: 1900, epoch: 1 | loss: 0.1103131
	speed: 0.1309s/iter; left time: 11420.3830s
	iters: 2000, epoch: 1 | loss: 0.1130958
	speed: 0.1310s/iter; left time: 11414.7452s
	iters: 2100, epoch: 1 | loss: 0.1089309
	speed: 0.1301s/iter; left time: 11319.7440s
	iters: 2200, epoch: 1 | loss: 0.1244033
	speed: 0.1622s/iter; left time: 14101.9482s
	iters: 2300, epoch: 1 | loss: 0.1284142
	speed: 0.1302s/iter; left time: 11303.5399s
	iters: 2400, epoch: 1 | loss: 0.1186614
	speed: 0.1285s/iter; left time: 11144.5636s
	iters: 2500, epoch: 1 | loss: 0.1169964
	speed: 0.1513s/iter; left time: 13112.9964s
	iters: 2600, epoch: 1 | loss: 0.1132365
	speed: 0.1498s/iter; left time: 12964.2629s
	iters: 2700, epoch: 1 | loss: 0.1326390
	speed: 0.1309s/iter; left time: 11312.5818s
	iters: 2800, epoch: 1 | loss: 0.1291778
	speed: 0.1304s/iter; left time: 11259.8777s
	iters: 2900, epoch: 1 | loss: 0.1308049
	speed: 0.1543s/iter; left time: 13302.8517s
	iters: 3000, epoch: 1 | loss: 0.1142576
	speed: 0.1470s/iter; left time: 12664.1308s
	iters: 3100, epoch: 1 | loss: 0.0980470
	speed: 0.1287s/iter; left time: 11074.7031s
	iters: 3200, epoch: 1 | loss: 0.1026124
	speed: 0.1332s/iter; left time: 11449.7419s
	iters: 3300, epoch: 1 | loss: 0.1019026
	speed: 0.1523s/iter; left time: 13070.4958s
	iters: 3400, epoch: 1 | loss: 0.1156720
	speed: 0.1310s/iter; left time: 11231.8749s
	iters: 3500, epoch: 1 | loss: 0.1253485
	speed: 0.1365s/iter; left time: 11686.2320s
	iters: 3600, epoch: 1 | loss: 0.1046039
	speed: 0.1621s/iter; left time: 13865.5288s
	iters: 3700, epoch: 1 | loss: 0.1413063
	speed: 0.1310s/iter; left time: 11190.4438s
	iters: 3800, epoch: 1 | loss: 0.1070143
	speed: 0.1311s/iter; left time: 11189.2488s
	iters: 3900, epoch: 1 | loss: 0.1359391
	speed: 0.1530s/iter; left time: 13041.6953s
	iters: 4000, epoch: 1 | loss: 0.1120188
	speed: 0.1468s/iter; left time: 12498.3120s
	iters: 4100, epoch: 1 | loss: 0.1373022
	speed: 0.1311s/iter; left time: 11149.5429s
	iters: 4200, epoch: 1 | loss: 0.1048007
	speed: 0.1308s/iter; left time: 11107.2007s
	iters: 4300, epoch: 1 | loss: 0.1046956
	speed: 0.1675s/iter; left time: 14207.4128s
	iters: 4400, epoch: 1 | loss: 0.1285643
	speed: 0.1248s/iter; left time: 10572.0927s
Epoch: 1 cost time: 00h:10m:20.69s
Epoch: 1 | Train Loss: 0.1245267 Vali Loss: 0.1197564 Test Loss: 0.1277876
Validation loss decreased (inf --> 0.119756).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1362824
	speed: 1.8524s/iter; left time: 156681.6822s
	iters: 200, epoch: 2 | loss: 0.1034659
	speed: 0.1208s/iter; left time: 10204.3256s
	iters: 300, epoch: 2 | loss: 0.1078680
	speed: 0.1487s/iter; left time: 12544.5177s
	iters: 400, epoch: 2 | loss: 0.1090891
	speed: 0.1182s/iter; left time: 9959.3467s
	iters: 500, epoch: 2 | loss: 0.0995298
	speed: 0.1208s/iter; left time: 10172.0625s
	iters: 600, epoch: 2 | loss: 0.1253273
	speed: 0.1207s/iter; left time: 10147.1868s
	iters: 700, epoch: 2 | loss: 0.1308996
	speed: 0.1441s/iter; left time: 12104.9090s
	iters: 800, epoch: 2 | loss: 0.1199580
	speed: 0.1386s/iter; left time: 11625.7887s
	iters: 900, epoch: 2 | loss: 0.1126412
	speed: 0.1194s/iter; left time: 10005.2187s
	iters: 1000, epoch: 2 | loss: 0.1188750
	speed: 0.1207s/iter; left time: 10099.1701s
	iters: 1100, epoch: 2 | loss: 0.1189725
	speed: 0.1205s/iter; left time: 10072.3692s
	iters: 1200, epoch: 2 | loss: 0.1217855
	speed: 0.1526s/iter; left time: 12735.5070s
	iters: 1300, epoch: 2 | loss: 0.1159035
	speed: 0.1205s/iter; left time: 10047.4742s
	iters: 1400, epoch: 2 | loss: 0.0984060
	speed: 0.1204s/iter; left time: 10030.3748s
	iters: 1500, epoch: 2 | loss: 0.0966178
	speed: 0.1515s/iter; left time: 12604.9615s
	iters: 1600, epoch: 2 | loss: 0.1044325
	speed: 0.1246s/iter; left time: 10350.6445s
	iters: 1700, epoch: 2 | loss: 0.1260282
	speed: 0.1199s/iter; left time: 9949.7037s
	iters: 1800, epoch: 2 | loss: 0.1024257
	speed: 0.1463s/iter; left time: 12126.9851s
	iters: 1900, epoch: 2 | loss: 0.0874435
	speed: 0.1357s/iter; left time: 11233.2718s
	iters: 2000, epoch: 2 | loss: 0.1199540
	speed: 0.1201s/iter; left time: 9928.8380s
	iters: 2100, epoch: 2 | loss: 0.1297425
	speed: 0.1142s/iter; left time: 9433.2969s
	iters: 2200, epoch: 2 | loss: 0.1000140
	speed: 0.1206s/iter; left time: 9949.4777s
	iters: 2300, epoch: 2 | loss: 0.1035635
	speed: 0.1299s/iter; left time: 10699.4000s
	iters: 2400, epoch: 2 | loss: 0.1033574
	speed: 0.1532s/iter; left time: 12607.5039s
	iters: 2500, epoch: 2 | loss: 0.1072888
	speed: 0.1206s/iter; left time: 9911.3347s
	iters: 2600, epoch: 2 | loss: 0.1190963
	speed: 0.1207s/iter; left time: 9909.1189s
	iters: 2700, epoch: 2 | loss: 0.1066877
	speed: 0.1327s/iter; left time: 10882.7715s
	iters: 2800, epoch: 2 | loss: 0.1129730
	speed: 0.1430s/iter; left time: 11706.3079s
	iters: 2900, epoch: 2 | loss: 0.1384397
	speed: 0.1200s/iter; left time: 9812.6067s
	iters: 3000, epoch: 2 | loss: 0.1114533
	speed: 0.1212s/iter; left time: 9902.3464s
	iters: 3100, epoch: 2 | loss: 0.1163946
	speed: 0.1294s/iter; left time: 10558.4800s
	iters: 3200, epoch: 2 | loss: 0.1102893
	speed: 0.1514s/iter; left time: 12340.3496s
	iters: 3300, epoch: 2 | loss: 0.0999768
	speed: 0.1203s/iter; left time: 9790.7820s
	iters: 3400, epoch: 2 | loss: 0.0817148
	speed: 0.1197s/iter; left time: 9728.3412s
	iters: 3500, epoch: 2 | loss: 0.1148444
	speed: 0.1301s/iter; left time: 10565.0041s
	iters: 3600, epoch: 2 | loss: 0.1212692
	speed: 0.1506s/iter; left time: 12214.7543s
	iters: 3700, epoch: 2 | loss: 0.1155532
	speed: 0.1165s/iter; left time: 9432.7674s
	iters: 3800, epoch: 2 | loss: 0.1284737
	speed: 0.1087s/iter; left time: 8793.7912s
	iters: 3900, epoch: 2 | loss: 0.1278360
	speed: 0.1203s/iter; left time: 9720.8441s
	iters: 4000, epoch: 2 | loss: 0.1092012
	speed: 0.1496s/iter; left time: 12069.2576s
	iters: 4100, epoch: 2 | loss: 0.0933397
	speed: 0.1213s/iter; left time: 9776.7060s
	iters: 4200, epoch: 2 | loss: 0.1042761
	speed: 0.1345s/iter; left time: 10827.5039s
	iters: 4300, epoch: 2 | loss: 0.1036103
	speed: 0.1416s/iter; left time: 11379.9974s
	iters: 4400, epoch: 2 | loss: 0.0886638
	speed: 0.1202s/iter; left time: 9648.6005s
Epoch: 2 cost time: 00h:09m:35.58s
Epoch: 2 | Train Loss: 0.1098625 Vali Loss: 0.1185164 Test Loss: 0.1282422
Validation loss decreased (0.119756 --> 0.118516).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1121855
	speed: 1.7050s/iter; left time: 136619.0496s
	iters: 200, epoch: 3 | loss: 0.0993601
	speed: 0.1205s/iter; left time: 9644.2246s
	iters: 300, epoch: 3 | loss: 0.0954742
	speed: 0.1202s/iter; left time: 9608.0875s
	iters: 400, epoch: 3 | loss: 0.1022189
	speed: 0.1494s/iter; left time: 11926.4749s
	iters: 500, epoch: 3 | loss: 0.1028623
	speed: 0.1324s/iter; left time: 10555.7552s
	iters: 600, epoch: 3 | loss: 0.1073780
	speed: 0.1204s/iter; left time: 9584.3099s
	iters: 700, epoch: 3 | loss: 0.1252172
	speed: 0.1237s/iter; left time: 9840.4985s
	iters: 800, epoch: 3 | loss: 0.0985473
	speed: 0.1530s/iter; left time: 12150.8329s
	iters: 900, epoch: 3 | loss: 0.1068274
	speed: 0.1206s/iter; left time: 9567.2498s
	iters: 1000, epoch: 3 | loss: 0.1010967
	speed: 0.1209s/iter; left time: 9575.6321s
	iters: 1100, epoch: 3 | loss: 0.1209155
	speed: 0.1105s/iter; left time: 8746.5421s
	iters: 1200, epoch: 3 | loss: 0.1471111
	speed: 0.1433s/iter; left time: 11326.1966s
	iters: 1300, epoch: 3 | loss: 0.0935464
	speed: 0.1372s/iter; left time: 10828.0251s
	iters: 1400, epoch: 3 | loss: 0.1135274
	speed: 0.1209s/iter; left time: 9530.2177s
	iters: 1500, epoch: 3 | loss: 0.0995740
	speed: 0.1210s/iter; left time: 9529.0338s
	iters: 1600, epoch: 3 | loss: 0.0949781
	speed: 0.1232s/iter; left time: 9683.4409s
	iters: 1700, epoch: 3 | loss: 0.1161713
	speed: 0.1593s/iter; left time: 12508.0138s
	iters: 1800, epoch: 3 | loss: 0.1313455
	speed: 0.1191s/iter; left time: 9337.7773s
	iters: 1900, epoch: 3 | loss: 0.1055434
	speed: 0.1207s/iter; left time: 9451.0232s
	iters: 2000, epoch: 3 | loss: 0.1189179
	speed: 0.1203s/iter; left time: 9407.9386s
	iters: 2100, epoch: 3 | loss: 0.0911239
	speed: 0.1327s/iter; left time: 10368.4362s
	iters: 2200, epoch: 3 | loss: 0.1390544
	speed: 0.1516s/iter; left time: 11826.2533s
	iters: 2300, epoch: 3 | loss: 0.0976654
	speed: 0.1208s/iter; left time: 9415.9381s
	iters: 2400, epoch: 3 | loss: 0.1079981
	speed: 0.1210s/iter; left time: 9415.5823s
	iters: 2500, epoch: 3 | loss: 0.1111981
	speed: 0.1201s/iter; left time: 9334.2331s
	iters: 2600, epoch: 3 | loss: 0.1110975
	speed: 0.1345s/iter; left time: 10439.3863s
	iters: 2700, epoch: 3 | loss: 0.1392076
	speed: 0.1426s/iter; left time: 11057.4100s
	iters: 2800, epoch: 3 | loss: 0.1271442
	speed: 0.1205s/iter; left time: 9332.4976s
	iters: 2900, epoch: 3 | loss: 0.1141754
	speed: 0.1203s/iter; left time: 9299.8072s
	iters: 3000, epoch: 3 | loss: 0.1144832
	speed: 0.1566s/iter; left time: 12092.3239s
	iters: 3100, epoch: 3 | loss: 0.0868490
	speed: 0.1093s/iter; left time: 8432.0423s
	iters: 3200, epoch: 3 | loss: 0.1013458
	speed: 0.1202s/iter; left time: 9256.8049s
	iters: 3300, epoch: 3 | loss: 0.0867222
	speed: 0.1395s/iter; left time: 10732.6274s
	iters: 3400, epoch: 3 | loss: 0.0821788
	speed: 0.1474s/iter; left time: 11327.6568s
	iters: 3500, epoch: 3 | loss: 0.1050519
	speed: 0.1206s/iter; left time: 9251.8680s
	iters: 3600, epoch: 3 | loss: 0.1225686
	speed: 0.1208s/iter; left time: 9258.2205s
	iters: 3700, epoch: 3 | loss: 0.1083653
	speed: 0.1528s/iter; left time: 11694.7361s
	iters: 3800, epoch: 3 | loss: 0.0852168
	speed: 0.1330s/iter; left time: 10166.8387s
	iters: 3900, epoch: 3 | loss: 0.1460541
	speed: 0.1179s/iter; left time: 9002.2864s
	iters: 4000, epoch: 3 | loss: 0.0892489
	speed: 0.1331s/iter; left time: 10148.4013s
	iters: 4100, epoch: 3 | loss: 0.1043740
	speed: 0.1374s/iter; left time: 10456.2352s
	iters: 4200, epoch: 3 | loss: 0.1233985
	speed: 0.1204s/iter; left time: 9153.7200s
	iters: 4300, epoch: 3 | loss: 0.1201573
	speed: 0.1397s/iter; left time: 10608.1815s
	iters: 4400, epoch: 3 | loss: 0.0884113
	speed: 0.1377s/iter; left time: 10442.3643s
Epoch: 3 cost time: 00h:09m:41.98s
Epoch: 3 | Train Loss: 0.1059200 Vali Loss: 0.1199043 Test Loss: 0.1320190
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.1017862
	speed: 1.6342s/iter; left time: 123657.6602s
	iters: 200, epoch: 4 | loss: 0.1054816
	speed: 0.1542s/iter; left time: 11651.7391s
	iters: 300, epoch: 4 | loss: 0.1008089
	speed: 0.1224s/iter; left time: 9236.6989s
	iters: 400, epoch: 4 | loss: 0.1103006
	speed: 0.1194s/iter; left time: 8996.2846s
	iters: 500, epoch: 4 | loss: 0.1008416
	speed: 0.1383s/iter; left time: 10411.2531s
	iters: 600, epoch: 4 | loss: 0.0872107
	speed: 0.1379s/iter; left time: 10362.9206s
	iters: 700, epoch: 4 | loss: 0.1059361
	speed: 0.1167s/iter; left time: 8759.3240s
	iters: 800, epoch: 4 | loss: 0.1094390
	speed: 0.1202s/iter; left time: 9011.6328s
	iters: 900, epoch: 4 | loss: 0.1180137
	speed: 0.1328s/iter; left time: 9941.5273s
	iters: 1000, epoch: 4 | loss: 0.1055246
	speed: 0.1364s/iter; left time: 10198.2564s
	iters: 1100, epoch: 4 | loss: 0.1000077
	speed: 0.1184s/iter; left time: 8841.7538s
	iters: 1200, epoch: 4 | loss: 0.0994589
	speed: 0.1135s/iter; left time: 8464.5988s
	iters: 1300, epoch: 4 | loss: 0.1067580
	speed: 0.1197s/iter; left time: 8914.2984s
	iters: 1400, epoch: 4 | loss: 0.0998731
	speed: 0.1529s/iter; left time: 11370.8496s
	iters: 1500, epoch: 4 | loss: 0.1033912
	speed: 0.1206s/iter; left time: 8957.6547s
	iters: 1600, epoch: 4 | loss: 0.0937374
	speed: 0.1239s/iter; left time: 9187.1257s
	iters: 1700, epoch: 4 | loss: 0.0970818
	speed: 0.1504s/iter; left time: 11137.6893s
	iters: 1800, epoch: 4 | loss: 0.1050920
	speed: 0.1199s/iter; left time: 8872.5141s
	iters: 1900, epoch: 4 | loss: 0.1291669
	speed: 0.1299s/iter; left time: 9593.7135s
	iters: 2000, epoch: 4 | loss: 0.0771152
	speed: 0.1468s/iter; left time: 10826.0734s
	iters: 2100, epoch: 4 | loss: 0.0940207
	speed: 0.1206s/iter; left time: 8883.7334s
	iters: 2200, epoch: 4 | loss: 0.0884763
	speed: 0.1387s/iter; left time: 10200.9555s
	iters: 2300, epoch: 4 | loss: 0.0902145
	speed: 0.1388s/iter; left time: 10197.5674s
	iters: 2400, epoch: 4 | loss: 0.1145035
	speed: 0.1198s/iter; left time: 8791.5591s
	iters: 2500, epoch: 4 | loss: 0.1050488
	speed: 0.1514s/iter; left time: 11092.3122s
	iters: 2600, epoch: 4 | loss: 0.0954266
	speed: 0.1254s/iter; left time: 9174.1143s
	iters: 2700, epoch: 4 | loss: 0.0995934
	speed: 0.1203s/iter; left time: 8790.7084s
	iters: 2800, epoch: 4 | loss: 0.1045068
	speed: 0.1397s/iter; left time: 10192.5030s
	iters: 2900, epoch: 4 | loss: 0.0896091
	speed: 0.1361s/iter; left time: 9915.2674s
	iters: 3000, epoch: 4 | loss: 0.1133813
	speed: 0.1201s/iter; left time: 8743.1096s
	iters: 3100, epoch: 4 | loss: 0.1004615
	speed: 0.1384s/iter; left time: 10054.6553s
	iters: 3200, epoch: 4 | loss: 0.1033023
	speed: 0.1403s/iter; left time: 10184.3969s
	iters: 3300, epoch: 4 | loss: 0.1076910
	speed: 0.1207s/iter; left time: 8749.9764s
	iters: 3400, epoch: 4 | loss: 0.0782520
	speed: 0.1558s/iter; left time: 11277.2845s
	iters: 3500, epoch: 4 | loss: 0.0946225
	speed: 0.1152s/iter; left time: 8325.9921s
	iters: 3600, epoch: 4 | loss: 0.1047806
	speed: 0.1208s/iter; left time: 8718.2807s
	iters: 3700, epoch: 4 | loss: 0.0901383
	speed: 0.1502s/iter; left time: 10823.3012s
	iters: 3800, epoch: 4 | loss: 0.0860445
	speed: 0.1151s/iter; left time: 8282.3806s
	iters: 3900, epoch: 4 | loss: 0.0885248
	speed: 0.1199s/iter; left time: 8616.3890s
	iters: 4000, epoch: 4 | loss: 0.1189710
	speed: 0.1451s/iter; left time: 10416.0725s
	iters: 4100, epoch: 4 | loss: 0.0907215
	speed: 0.1325s/iter; left time: 9492.8908s
	iters: 4200, epoch: 4 | loss: 0.1236514
	speed: 0.1208s/iter; left time: 8645.1304s
	iters: 4300, epoch: 4 | loss: 0.1064944
	speed: 0.1203s/iter; left time: 8600.3627s
	iters: 4400, epoch: 4 | loss: 0.0968458
	speed: 0.1471s/iter; left time: 10501.9215s
Epoch: 4 cost time: 00h:09m:42.82s
Epoch: 4 | Train Loss: 0.1021763 Vali Loss: 0.1203913 Test Loss: 0.1309304
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0960487
	speed: 1.6037s/iter; left time: 114204.3345s
	iters: 200, epoch: 5 | loss: 0.0997009
	speed: 0.1234s/iter; left time: 8772.1768s
	iters: 300, epoch: 5 | loss: 0.1327493
	speed: 0.1391s/iter; left time: 9878.2791s
	iters: 400, epoch: 5 | loss: 0.1110552
	speed: 0.1349s/iter; left time: 9564.9740s
	iters: 500, epoch: 5 | loss: 0.0997856
	speed: 0.1203s/iter; left time: 8521.7706s
	iters: 600, epoch: 5 | loss: 0.1085910
	speed: 0.1272s/iter; left time: 8991.9604s
	iters: 700, epoch: 5 | loss: 0.0906752
	speed: 0.1519s/iter; left time: 10724.1571s
	iters: 800, epoch: 5 | loss: 0.0881957
	speed: 0.1205s/iter; left time: 8496.3136s
	iters: 900, epoch: 5 | loss: 0.1219619
	speed: 0.1268s/iter; left time: 8929.7758s
	iters: 1000, epoch: 5 | loss: 0.1071277
	speed: 0.1546s/iter; left time: 10873.3255s
	iters: 1100, epoch: 5 | loss: 0.1084025
	speed: 0.1202s/iter; left time: 8439.8887s
	iters: 1200, epoch: 5 | loss: 0.0964981
	speed: 0.1231s/iter; left time: 8628.2586s
	iters: 1300, epoch: 5 | loss: 0.0842596
	speed: 0.1593s/iter; left time: 11155.4025s
	iters: 1400, epoch: 5 | loss: 0.0926249
	speed: 0.1211s/iter; left time: 8464.9976s
	iters: 1500, epoch: 5 | loss: 0.0907346
	speed: 0.1210s/iter; left time: 8450.7858s
	iters: 1600, epoch: 5 | loss: 0.1106110
	speed: 0.1451s/iter; left time: 10117.1060s
	iters: 1700, epoch: 5 | loss: 0.0988417
	speed: 0.1361s/iter; left time: 9476.6170s
	iters: 1800, epoch: 5 | loss: 0.0920804
	speed: 0.1208s/iter; left time: 8399.7770s
	iters: 1900, epoch: 5 | loss: 0.0919630
	speed: 0.1401s/iter; left time: 9722.5162s
	iters: 2000, epoch: 5 | loss: 0.1004907
	speed: 0.1395s/iter; left time: 9667.2462s
	iters: 2100, epoch: 5 | loss: 0.1181042
	speed: 0.1204s/iter; left time: 8334.4255s
	iters: 2200, epoch: 5 | loss: 0.0876759
	speed: 0.1283s/iter; left time: 8864.4635s
	iters: 2300, epoch: 5 | loss: 0.1073024
	speed: 0.1503s/iter; left time: 10369.9535s
	iters: 2400, epoch: 5 | loss: 0.0821408
	speed: 0.1207s/iter; left time: 8317.9456s
	iters: 2500, epoch: 5 | loss: 0.0953626
	speed: 0.1179s/iter; left time: 8111.5827s
	iters: 2600, epoch: 5 | loss: 0.1104295
	speed: 0.1307s/iter; left time: 8981.4432s
	iters: 2700, epoch: 5 | loss: 0.1122409
	speed: 0.1480s/iter; left time: 10152.3862s
	iters: 2800, epoch: 5 | loss: 0.0743636
	speed: 0.1210s/iter; left time: 8290.2840s
	iters: 2900, epoch: 5 | loss: 0.0947080
	speed: 0.1208s/iter; left time: 8264.4572s
	iters: 3000, epoch: 5 | loss: 0.1082617
	speed: 0.1337s/iter; left time: 9136.1067s
	iters: 3100, epoch: 5 | loss: 0.0972924
	speed: 0.1453s/iter; left time: 9909.9216s
	iters: 3200, epoch: 5 | loss: 0.1161426
	speed: 0.1209s/iter; left time: 8235.7296s
	iters: 3300, epoch: 5 | loss: 0.0934898
	speed: 0.1205s/iter; left time: 8194.0800s
	iters: 3400, epoch: 5 | loss: 0.0890894
	speed: 0.1386s/iter; left time: 9415.6284s
	iters: 3500, epoch: 5 | loss: 0.0774576
	speed: 0.1468s/iter; left time: 9955.6319s
	iters: 3600, epoch: 5 | loss: 0.1041150
	speed: 0.1208s/iter; left time: 8178.9483s
	iters: 3700, epoch: 5 | loss: 0.0764355
	speed: 0.1206s/iter; left time: 8157.0534s
	iters: 3800, epoch: 5 | loss: 0.0967276
	speed: 0.1447s/iter; left time: 9767.2221s
	iters: 3900, epoch: 5 | loss: 0.1057422
	speed: 0.1354s/iter; left time: 9129.7903s
	iters: 4000, epoch: 5 | loss: 0.1008978
	speed: 0.1208s/iter; left time: 8128.2820s
	iters: 4100, epoch: 5 | loss: 0.1179423
	speed: 0.1208s/iter; left time: 8118.3224s
	iters: 4200, epoch: 5 | loss: 0.1178501
	speed: 0.1427s/iter; left time: 9575.1051s
	iters: 4300, epoch: 5 | loss: 0.0911569
	speed: 0.1290s/iter; left time: 8643.8998s
	iters: 4400, epoch: 5 | loss: 0.0975429
	speed: 0.1170s/iter; left time: 7830.1215s
Epoch: 5 cost time: 00h:09m:42.32s
Epoch: 5 | Train Loss: 0.0987026 Vali Loss: 0.1216048 Test Loss: 0.1345417
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1011339
	speed: 1.6048s/iter; left time: 107127.3740s
	iters: 200, epoch: 6 | loss: 0.0883259
	speed: 0.1163s/iter; left time: 7753.0863s
	iters: 300, epoch: 6 | loss: 0.1075289
	speed: 0.1029s/iter; left time: 6848.7057s
	iters: 400, epoch: 6 | loss: 0.0989359
	speed: 0.1220s/iter; left time: 8109.9106s
	iters: 500, epoch: 6 | loss: 0.0862649
	speed: 0.1379s/iter; left time: 9147.6659s
	iters: 600, epoch: 6 | loss: 0.1002253
	speed: 0.1120s/iter; left time: 7420.9720s
	iters: 700, epoch: 6 | loss: 0.1083656
	speed: 0.1196s/iter; left time: 7913.3557s
	iters: 800, epoch: 6 | loss: 0.0928279
	speed: 0.1310s/iter; left time: 8653.9960s
	iters: 900, epoch: 6 | loss: 0.0807987
	speed: 0.1508s/iter; left time: 9943.9008s
	iters: 1000, epoch: 6 | loss: 0.0948872
	speed: 0.1199s/iter; left time: 7894.3091s
	iters: 1100, epoch: 6 | loss: 0.0827360
	speed: 0.1199s/iter; left time: 7885.3003s
	iters: 1200, epoch: 6 | loss: 0.1174165
	speed: 0.1297s/iter; left time: 8514.0891s
	iters: 1300, epoch: 6 | loss: 0.0992087
	speed: 0.1508s/iter; left time: 9887.6720s
	iters: 1400, epoch: 6 | loss: 0.0848289
	speed: 0.1175s/iter; left time: 7691.5387s
	iters: 1500, epoch: 6 | loss: 0.0922957
	speed: 0.1208s/iter; left time: 7896.2571s
	iters: 1600, epoch: 6 | loss: 0.1061229
	speed: 0.1203s/iter; left time: 7849.6662s
	iters: 1700, epoch: 6 | loss: 0.0937682
	speed: 0.1396s/iter; left time: 9098.3824s
	iters: 1800, epoch: 6 | loss: 0.1026462
	speed: 0.1311s/iter; left time: 8529.0044s
	iters: 1900, epoch: 6 | loss: 0.0818370
	speed: 0.1283s/iter; left time: 8332.6380s
	iters: 2000, epoch: 6 | loss: 0.1049387
	speed: 0.1408s/iter; left time: 9134.2236s
	iters: 2100, epoch: 6 | loss: 0.0856962
	speed: 0.1174s/iter; left time: 7604.1086s
	iters: 2200, epoch: 6 | loss: 0.1132535
	speed: 0.1507s/iter; left time: 9746.5224s
	iters: 2300, epoch: 6 | loss: 0.0780297
	speed: 0.1217s/iter; left time: 7855.3381s
	iters: 2400, epoch: 6 | loss: 0.0942708
	speed: 0.1310s/iter; left time: 8445.3675s
	iters: 2500, epoch: 6 | loss: 0.0917941
	speed: 0.1501s/iter; left time: 9659.0142s
	iters: 2600, epoch: 6 | loss: 0.0872721
	speed: 0.1201s/iter; left time: 7718.7537s
	iters: 2700, epoch: 6 | loss: 0.0825186
	speed: 0.1230s/iter; left time: 7892.4193s
	iters: 2800, epoch: 6 | loss: 0.0905587
	speed: 0.1488s/iter; left time: 9529.8986s
	iters: 2900, epoch: 6 | loss: 0.0887696
	speed: 0.1205s/iter; left time: 7706.0768s
	iters: 3000, epoch: 6 | loss: 0.1022261
	speed: 0.1208s/iter; left time: 7712.0089s
	iters: 3100, epoch: 6 | loss: 0.1016905
	speed: 0.1310s/iter; left time: 8349.7578s
	iters: 3200, epoch: 6 | loss: 0.0889834
	speed: 0.1464s/iter; left time: 9318.9635s
	iters: 3300, epoch: 6 | loss: 0.0868730
	speed: 0.1206s/iter; left time: 7662.5306s
	iters: 3400, epoch: 6 | loss: 0.0905508
	speed: 0.1394s/iter; left time: 8848.0028s
	iters: 3500, epoch: 6 | loss: 0.0885148
	speed: 0.1385s/iter; left time: 8773.3326s
	iters: 3600, epoch: 6 | loss: 0.0922447
	speed: 0.1204s/iter; left time: 7617.3406s
	iters: 3700, epoch: 6 | loss: 0.0886584
	speed: 0.1511s/iter; left time: 9541.6918s
	iters: 3800, epoch: 6 | loss: 0.0922629
	speed: 0.1305s/iter; left time: 8231.6898s
	iters: 3900, epoch: 6 | loss: 0.0939470
	speed: 0.1208s/iter; left time: 7602.0121s
	iters: 4000, epoch: 6 | loss: 0.0905015
	speed: 0.1538s/iter; left time: 9667.6786s
	iters: 4100, epoch: 6 | loss: 0.0758674
	speed: 0.1298s/iter; left time: 8147.0458s
	iters: 4200, epoch: 6 | loss: 0.0957208
	speed: 0.1210s/iter; left time: 7578.2761s
	iters: 4300, epoch: 6 | loss: 0.1053216
	speed: 0.1543s/iter; left time: 9652.4183s
	iters: 4400, epoch: 6 | loss: 0.0906008
	speed: 0.1260s/iter; left time: 7870.1056s
Epoch: 6 cost time: 00h:09m:41.71s
Epoch: 6 | Train Loss: 0.0954798 Vali Loss: 0.1227273 Test Loss: 0.1344287
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.1033562
	speed: 1.6175s/iter; left time: 100767.6528s
	iters: 200, epoch: 7 | loss: 0.0896851
	speed: 0.1532s/iter; left time: 9526.4070s
	iters: 300, epoch: 7 | loss: 0.0913225
	speed: 0.1040s/iter; left time: 6456.4733s
	iters: 400, epoch: 7 | loss: 0.0853823
	speed: 0.1185s/iter; left time: 7346.5372s
	iters: 500, epoch: 7 | loss: 0.0857644
	speed: 0.1308s/iter; left time: 8095.6350s
	iters: 600, epoch: 7 | loss: 0.0806916
	speed: 0.1518s/iter; left time: 9381.2032s
	iters: 700, epoch: 7 | loss: 0.1021493
	speed: 0.1204s/iter; left time: 7426.3761s
	iters: 800, epoch: 7 | loss: 0.0732420
	speed: 0.1204s/iter; left time: 7417.3480s
	iters: 900, epoch: 7 | loss: 0.0850529
	speed: 0.1564s/iter; left time: 9618.4855s
	iters: 1000, epoch: 7 | loss: 0.0993610
	speed: 0.1221s/iter; left time: 7493.9789s
	iters: 1100, epoch: 7 | loss: 0.1097831
	speed: 0.1193s/iter; left time: 7315.4069s
	iters: 1200, epoch: 7 | loss: 0.1054772
	speed: 0.1606s/iter; left time: 9829.1026s
	iters: 1300, epoch: 7 | loss: 0.0870716
	speed: 0.1201s/iter; left time: 7338.9015s
	iters: 1400, epoch: 7 | loss: 0.0907186
	speed: 0.1200s/iter; left time: 7320.6886s
	iters: 1500, epoch: 7 | loss: 0.0836305
	speed: 0.1294s/iter; left time: 7883.2776s
	iters: 1600, epoch: 7 | loss: 0.0796124
	speed: 0.1456s/iter; left time: 8849.8643s
	iters: 1700, epoch: 7 | loss: 0.0783959
	speed: 0.1163s/iter; left time: 7062.2697s
	iters: 1800, epoch: 7 | loss: 0.1006658
	speed: 0.1280s/iter; left time: 7754.5098s
	iters: 1900, epoch: 7 | loss: 0.0884392
	speed: 0.1511s/iter; left time: 9141.8232s
	iters: 2000, epoch: 7 | loss: 0.0906714
	speed: 0.1157s/iter; left time: 6985.2262s
	iters: 2100, epoch: 7 | loss: 0.0930545
	speed: 0.1201s/iter; left time: 7241.6238s
	iters: 2200, epoch: 7 | loss: 0.0999339
	speed: 0.1395s/iter; left time: 8397.4509s
	iters: 2300, epoch: 7 | loss: 0.0763448
	speed: 0.1401s/iter; left time: 8417.9997s
	iters: 2400, epoch: 7 | loss: 0.0873501
	speed: 0.1187s/iter; left time: 7120.0993s
	iters: 2500, epoch: 7 | loss: 0.0835626
	speed: 0.1289s/iter; left time: 7721.4880s
	iters: 2600, epoch: 7 | loss: 0.0899396
	speed: 0.1481s/iter; left time: 8858.1208s
	iters: 2700, epoch: 7 | loss: 0.0973071
	speed: 0.1207s/iter; left time: 7202.7669s
	iters: 2800, epoch: 7 | loss: 0.0889941
	speed: 0.1356s/iter; left time: 8083.4355s
	iters: 2900, epoch: 7 | loss: 0.0885513
	speed: 0.1428s/iter; left time: 8495.3955s
	iters: 3000, epoch: 7 | loss: 0.0899405
	speed: 0.1200s/iter; left time: 7127.5966s
	iters: 3100, epoch: 7 | loss: 0.0913069
	speed: 0.1330s/iter; left time: 7889.6326s
	iters: 3200, epoch: 7 | loss: 0.0929181
	speed: 0.1523s/iter; left time: 9018.8924s
	iters: 3300, epoch: 7 | loss: 0.0748527
	speed: 0.1211s/iter; left time: 7153.9634s
	iters: 3400, epoch: 7 | loss: 0.0883430
	speed: 0.1414s/iter; left time: 8344.8554s
	iters: 3500, epoch: 7 | loss: 0.0995779
	speed: 0.1405s/iter; left time: 8277.4893s
	iters: 3600, epoch: 7 | loss: 0.0879578
	speed: 0.1200s/iter; left time: 7057.2977s
	iters: 3700, epoch: 7 | loss: 0.0936343
	speed: 0.1535s/iter; left time: 9008.6502s
	iters: 3800, epoch: 7 | loss: 0.0912004
	speed: 0.1298s/iter; left time: 7604.4086s
	iters: 3900, epoch: 7 | loss: 0.0808091
	speed: 0.1142s/iter; left time: 6681.9484s
	iters: 4000, epoch: 7 | loss: 0.1068037
	speed: 0.1476s/iter; left time: 8621.1588s
	iters: 4100, epoch: 7 | loss: 0.0853559
	speed: 0.1207s/iter; left time: 7038.4170s
	iters: 4200, epoch: 7 | loss: 0.1038158
	speed: 0.1275s/iter; left time: 7419.9829s
	iters: 4300, epoch: 7 | loss: 0.1103765
	speed: 0.1555s/iter; left time: 9036.6214s
	iters: 4400, epoch: 7 | loss: 0.0968011
	speed: 0.1202s/iter; left time: 6971.9976s
Epoch: 7 cost time: 00h:09m:46.95s
Epoch: 7 | Train Loss: 0.0925967 Vali Loss: 0.1245577 Test Loss: 0.1345884
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.03578183427453041, rmse:0.18916086852550507, mae:0.12824216485023499, rse:0.6698496341705322
success delete checkpoints
Intermediate time for DE and pred_len 96: 01h:27m:14.27s


=== Starting experiments for pred_len: 168 ===

train 142285
val 30365
test 30365
[2024-10-31 22:56:28,867] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-10-31 22:56:30,027] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-10-31 22:56:30,027] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-10-31 22:56:30,027] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-10-31 22:56:30,130] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-10-31 22:56:30,130] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-10-31 22:56:30,769] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-10-31 22:56:30,770] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-10-31 22:56:30,770] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-10-31 22:56:30,772] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-10-31 22:56:30,772] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-10-31 22:56:30,772] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-10-31 22:56:30,772] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-10-31 22:56:30,772] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-10-31 22:56:30,772] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-10-31 22:56:30,772] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-10-31 22:56:31,058] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-10-31 22:56:31,059] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-10-31 22:56:31,060] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.82 GB, percent = 25.8%
[2024-10-31 22:56:31,178] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-10-31 22:56:31,179] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-10-31 22:56:31,179] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.82 GB, percent = 25.8%
[2024-10-31 22:56:31,179] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-10-31 22:56:31,293] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-10-31 22:56:31,294] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-10-31 22:56:31,294] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 194.82 GB, percent = 25.8%
[2024-10-31 22:56:31,295] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-10-31 22:56:31,295] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-10-31 22:56:31,295] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-10-31 22:56:31,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-10-31 22:56:31,296] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-10-31 22:56:31,296] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-10-31 22:56:31,296] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fbcee22a5d0>
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-10-31 22:56:31,297] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-10-31 22:56:31,298] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-10-31 22:56:31,299] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-10-31 22:56:31,299] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1492427
	speed: 0.1759s/iter; left time: 15624.6134s
	iters: 200, epoch: 1 | loss: 0.1605359
	speed: 0.1582s/iter; left time: 14036.4255s
	iters: 300, epoch: 1 | loss: 0.1671229
	speed: 0.1309s/iter; left time: 11600.1030s
	iters: 400, epoch: 1 | loss: 0.1654047
	speed: 0.1342s/iter; left time: 11882.6741s
	iters: 500, epoch: 1 | loss: 0.1528231
	speed: 0.1695s/iter; left time: 14991.4997s
	iters: 600, epoch: 1 | loss: 0.1641308
	speed: 0.1315s/iter; left time: 11610.8218s
	iters: 700, epoch: 1 | loss: 0.1460070
	speed: 0.1287s/iter; left time: 11351.6210s
	iters: 800, epoch: 1 | loss: 0.1177307
	speed: 0.1677s/iter; left time: 14777.8589s
	iters: 900, epoch: 1 | loss: 0.1349947
	speed: 0.1359s/iter; left time: 11964.0729s
	iters: 1000, epoch: 1 | loss: 0.1090521
	speed: 0.1300s/iter; left time: 11426.6714s
	iters: 1100, epoch: 1 | loss: 0.1334336
	speed: 0.1518s/iter; left time: 13327.7829s
	iters: 1200, epoch: 1 | loss: 0.1300411
	speed: 0.1510s/iter; left time: 13248.9572s
	iters: 1300, epoch: 1 | loss: 0.1205211
	speed: 0.1298s/iter; left time: 11370.3772s
	iters: 1400, epoch: 1 | loss: 0.1304281
	speed: 0.1299s/iter; left time: 11365.7661s
	iters: 1500, epoch: 1 | loss: 0.1271410
	speed: 0.1502s/iter; left time: 13134.8476s
	iters: 1600, epoch: 1 | loss: 0.1058479
	speed: 0.1536s/iter; left time: 13409.6358s
	iters: 1700, epoch: 1 | loss: 0.1209870
	speed: 0.1308s/iter; left time: 11406.5693s
	iters: 1800, epoch: 1 | loss: 0.1023959
	speed: 0.1303s/iter; left time: 11349.5125s
	iters: 1900, epoch: 1 | loss: 0.1413429
	speed: 0.1686s/iter; left time: 14669.8994s
	iters: 2000, epoch: 1 | loss: 0.1427599
	speed: 0.1309s/iter; left time: 11374.1668s
	iters: 2100, epoch: 1 | loss: 0.1329999
	speed: 0.1308s/iter; left time: 11354.7346s
	iters: 2200, epoch: 1 | loss: 0.1120558
	speed: 0.1701s/iter; left time: 14750.0173s
	iters: 2300, epoch: 1 | loss: 0.0989436
	speed: 0.1307s/iter; left time: 11320.3556s
	iters: 2400, epoch: 1 | loss: 0.1160462
	speed: 0.1310s/iter; left time: 11335.3124s
	iters: 2500, epoch: 1 | loss: 0.1234167
	speed: 0.1594s/iter; left time: 13775.9303s
	iters: 2600, epoch: 1 | loss: 0.1299602
	speed: 0.1338s/iter; left time: 11547.6114s
	iters: 2700, epoch: 1 | loss: 0.1306166
	speed: 0.1310s/iter; left time: 11295.8846s
	iters: 2800, epoch: 1 | loss: 0.1211876
	speed: 0.1307s/iter; left time: 11256.8811s
	iters: 2900, epoch: 1 | loss: 0.1157711
	speed: 0.1633s/iter; left time: 14049.9520s
	iters: 3000, epoch: 1 | loss: 0.0999164
	speed: 0.1307s/iter; left time: 11230.1418s
	iters: 3100, epoch: 1 | loss: 0.1516199
	speed: 0.1308s/iter; left time: 11228.7954s
	iters: 3200, epoch: 1 | loss: 0.1097987
	speed: 0.1388s/iter; left time: 11901.9006s
	iters: 3300, epoch: 1 | loss: 0.1195762
	speed: 0.1584s/iter; left time: 13565.2455s
	iters: 3400, epoch: 1 | loss: 0.1289778
	speed: 0.1312s/iter; left time: 11221.4390s
	iters: 3500, epoch: 1 | loss: 0.1021916
	speed: 0.1305s/iter; left time: 11144.0033s
	iters: 3600, epoch: 1 | loss: 0.1183287
	speed: 0.1430s/iter; left time: 12197.8004s
	iters: 3700, epoch: 1 | loss: 0.1355938
	speed: 0.1580s/iter; left time: 13463.0375s
	iters: 3800, epoch: 1 | loss: 0.1252127
	speed: 0.1308s/iter; left time: 11133.9495s
	iters: 3900, epoch: 1 | loss: 0.1068365
	speed: 0.1579s/iter; left time: 13422.0564s
	iters: 4000, epoch: 1 | loss: 0.1084060
	speed: 0.1434s/iter; left time: 12179.0360s
	iters: 4100, epoch: 1 | loss: 0.1262050
	speed: 0.1297s/iter; left time: 11004.6816s
	iters: 4200, epoch: 1 | loss: 0.1099667
	speed: 0.1386s/iter; left time: 11745.8015s
	iters: 4300, epoch: 1 | loss: 0.1208501
	speed: 0.1580s/iter; left time: 13368.3783s
	iters: 4400, epoch: 1 | loss: 0.1325888
	speed: 0.1305s/iter; left time: 11026.9726s
Epoch: 1 cost time: 00h:10m:31.01s
Epoch: 1 | Train Loss: 0.1270849 Vali Loss: 0.1233267 Test Loss: 0.1336193
Validation loss decreased (inf --> 0.123327).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1183373
	speed: 1.8820s/iter; left time: 158796.6472s
	iters: 200, epoch: 2 | loss: 0.1098894
	speed: 0.1173s/iter; left time: 9884.7211s
	iters: 300, epoch: 2 | loss: 0.1131674
	speed: 0.1078s/iter; left time: 9076.5730s
	iters: 400, epoch: 2 | loss: 0.1160400
	speed: 0.1478s/iter; left time: 12425.9262s
	iters: 500, epoch: 2 | loss: 0.0886714
	speed: 0.1332s/iter; left time: 11188.8918s
	iters: 600, epoch: 2 | loss: 0.1193221
	speed: 0.1204s/iter; left time: 10100.7859s
	iters: 700, epoch: 2 | loss: 0.1303138
	speed: 0.1333s/iter; left time: 11167.4743s
	iters: 800, epoch: 2 | loss: 0.1092902
	speed: 0.1460s/iter; left time: 12215.6480s
	iters: 900, epoch: 2 | loss: 0.0996466
	speed: 0.1081s/iter; left time: 9037.1343s
	iters: 1000, epoch: 2 | loss: 0.1157148
	speed: 0.1077s/iter; left time: 8986.4920s
	iters: 1100, epoch: 2 | loss: 0.1112141
	speed: 0.1562s/iter; left time: 13026.5717s
	iters: 1200, epoch: 2 | loss: 0.1180607
	speed: 0.1179s/iter; left time: 9818.2311s
	iters: 1300, epoch: 2 | loss: 0.0878751
	speed: 0.1091s/iter; left time: 9070.2974s
	iters: 1400, epoch: 2 | loss: 0.1204318
	speed: 0.1312s/iter; left time: 10903.2790s
	iters: 1500, epoch: 2 | loss: 0.1055659
	speed: 0.1453s/iter; left time: 12053.7195s
	iters: 1600, epoch: 2 | loss: 0.1180415
	speed: 0.1200s/iter; left time: 9945.1464s
	iters: 1700, epoch: 2 | loss: 0.1256569
	speed: 0.1194s/iter; left time: 9880.5806s
	iters: 1800, epoch: 2 | loss: 0.1117147
	speed: 0.1552s/iter; left time: 12831.9240s
	iters: 1900, epoch: 2 | loss: 0.1046314
	speed: 0.1204s/iter; left time: 9941.5590s
	iters: 2000, epoch: 2 | loss: 0.1071824
	speed: 0.1159s/iter; left time: 9555.0635s
	iters: 2100, epoch: 2 | loss: 0.1128184
	speed: 0.1525s/iter; left time: 12563.1475s
	iters: 2200, epoch: 2 | loss: 0.1227209
	speed: 0.1254s/iter; left time: 10320.2536s
	iters: 2300, epoch: 2 | loss: 0.1197821
	speed: 0.1193s/iter; left time: 9801.2546s
	iters: 2400, epoch: 2 | loss: 0.1249823
	speed: 0.1435s/iter; left time: 11777.6256s
	iters: 2500, epoch: 2 | loss: 0.1261758
	speed: 0.1356s/iter; left time: 11117.5660s
	iters: 2600, epoch: 2 | loss: 0.1112454
	speed: 0.1205s/iter; left time: 9867.7948s
	iters: 2700, epoch: 2 | loss: 0.1138095
	speed: 0.1210s/iter; left time: 9894.6377s
	iters: 2800, epoch: 2 | loss: 0.0994604
	speed: 0.1531s/iter; left time: 12504.5200s
	iters: 2900, epoch: 2 | loss: 0.1096554
	speed: 0.1264s/iter; left time: 10313.9280s
	iters: 3000, epoch: 2 | loss: 0.1068463
	speed: 0.1203s/iter; left time: 9802.4262s
	iters: 3100, epoch: 2 | loss: 0.1206979
	speed: 0.1309s/iter; left time: 10655.5039s
	iters: 3200, epoch: 2 | loss: 0.1085434
	speed: 0.1472s/iter; left time: 11961.7991s
	iters: 3300, epoch: 2 | loss: 0.1045549
	speed: 0.1198s/iter; left time: 9723.8775s
	iters: 3400, epoch: 2 | loss: 0.1207838
	speed: 0.1294s/iter; left time: 10491.5027s
	iters: 3500, epoch: 2 | loss: 0.1154747
	speed: 0.1443s/iter; left time: 11684.4159s
	iters: 3600, epoch: 2 | loss: 0.1074588
	speed: 0.1055s/iter; left time: 8529.5609s
	iters: 3700, epoch: 2 | loss: 0.1014723
	speed: 0.1022s/iter; left time: 8258.6511s
	iters: 3800, epoch: 2 | loss: 0.0964471
	speed: 0.1439s/iter; left time: 11610.0558s
	iters: 3900, epoch: 2 | loss: 0.1228269
	speed: 0.1314s/iter; left time: 10588.3093s
	iters: 4000, epoch: 2 | loss: 0.1099236
	speed: 0.1203s/iter; left time: 9678.3293s
	iters: 4100, epoch: 2 | loss: 0.1171050
	speed: 0.1278s/iter; left time: 10270.6826s
	iters: 4200, epoch: 2 | loss: 0.1104717
	speed: 0.1539s/iter; left time: 12351.8433s
	iters: 4300, epoch: 2 | loss: 0.1126500
	speed: 0.1208s/iter; left time: 9686.3134s
	iters: 4400, epoch: 2 | loss: 0.1323302
	speed: 0.1197s/iter; left time: 9585.9130s
Epoch: 2 cost time: 00h:09m:34.51s
Epoch: 2 | Train Loss: 0.1139773 Vali Loss: 0.1234052 Test Loss: 0.1342462
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.1082153
	speed: 1.6554s/iter; left time: 132316.4182s
	iters: 200, epoch: 3 | loss: 0.1202841
	speed: 0.1341s/iter; left time: 10705.9098s
	iters: 300, epoch: 3 | loss: 0.0996917
	speed: 0.1199s/iter; left time: 9563.1093s
	iters: 400, epoch: 3 | loss: 0.1064174
	speed: 0.1231s/iter; left time: 9802.1911s
	iters: 500, epoch: 3 | loss: 0.1139071
	speed: 0.1543s/iter; left time: 12272.7726s
	iters: 600, epoch: 3 | loss: 0.1215968
	speed: 0.1196s/iter; left time: 9499.0769s
	iters: 700, epoch: 3 | loss: 0.1096018
	speed: 0.1176s/iter; left time: 9327.3303s
	iters: 800, epoch: 3 | loss: 0.1310975
	speed: 0.1276s/iter; left time: 10111.7013s
	iters: 900, epoch: 3 | loss: 0.1056969
	speed: 0.1388s/iter; left time: 10985.5605s
	iters: 1000, epoch: 3 | loss: 0.1081555
	speed: 0.1203s/iter; left time: 9509.5447s
	iters: 1100, epoch: 3 | loss: 0.0982659
	speed: 0.1199s/iter; left time: 9462.5662s
	iters: 1200, epoch: 3 | loss: 0.1056586
	speed: 0.1561s/iter; left time: 12307.2165s
	iters: 1300, epoch: 3 | loss: 0.1162706
	speed: 0.1237s/iter; left time: 9737.6174s
	iters: 1400, epoch: 3 | loss: 0.1264145
	speed: 0.1206s/iter; left time: 9484.5916s
	iters: 1500, epoch: 3 | loss: 0.1110645
	speed: 0.1285s/iter; left time: 10088.6308s
	iters: 1600, epoch: 3 | loss: 0.1157964
	speed: 0.1517s/iter; left time: 11899.6495s
	iters: 1700, epoch: 3 | loss: 0.1245955
	speed: 0.1197s/iter; left time: 9372.7378s
	iters: 1800, epoch: 3 | loss: 0.1219978
	speed: 0.1198s/iter; left time: 9374.2244s
	iters: 1900, epoch: 3 | loss: 0.1215639
	speed: 0.1205s/iter; left time: 9412.8991s
	iters: 2000, epoch: 3 | loss: 0.1222039
	speed: 0.1306s/iter; left time: 10189.2829s
	iters: 2100, epoch: 3 | loss: 0.0978573
	speed: 0.1453s/iter; left time: 11324.5459s
	iters: 2200, epoch: 3 | loss: 0.1149430
	speed: 0.1081s/iter; left time: 8413.9151s
	iters: 2300, epoch: 3 | loss: 0.1145440
	speed: 0.1199s/iter; left time: 9316.2933s
	iters: 2400, epoch: 3 | loss: 0.0993142
	speed: 0.1195s/iter; left time: 9279.1915s
	iters: 2500, epoch: 3 | loss: 0.0932033
	speed: 0.1389s/iter; left time: 10772.0812s
	iters: 2600, epoch: 3 | loss: 0.1083821
	speed: 0.1368s/iter; left time: 10593.8662s
	iters: 2700, epoch: 3 | loss: 0.1158013
	speed: 0.1200s/iter; left time: 9281.2553s
	iters: 2800, epoch: 3 | loss: 0.1378757
	speed: 0.1197s/iter; left time: 9242.0563s
	iters: 2900, epoch: 3 | loss: 0.0924771
	speed: 0.1498s/iter; left time: 11556.8977s
	iters: 3000, epoch: 3 | loss: 0.1077057
	speed: 0.1285s/iter; left time: 9896.0885s
	iters: 3100, epoch: 3 | loss: 0.1156989
	speed: 0.1200s/iter; left time: 9233.9198s
	iters: 3200, epoch: 3 | loss: 0.1000350
	speed: 0.1201s/iter; left time: 9228.5345s
	iters: 3300, epoch: 3 | loss: 0.1146565
	speed: 0.1473s/iter; left time: 11305.8013s
	iters: 3400, epoch: 3 | loss: 0.1231436
	speed: 0.1330s/iter; left time: 10191.1905s
	iters: 3500, epoch: 3 | loss: 0.1224817
	speed: 0.1205s/iter; left time: 9221.3954s
	iters: 3600, epoch: 3 | loss: 0.1114092
	speed: 0.1202s/iter; left time: 9187.1481s
	iters: 3700, epoch: 3 | loss: 0.1154894
	speed: 0.1499s/iter; left time: 11442.6472s
	iters: 3800, epoch: 3 | loss: 0.0983998
	speed: 0.1279s/iter; left time: 9751.5659s
	iters: 3900, epoch: 3 | loss: 0.1058075
	speed: 0.1201s/iter; left time: 9140.8716s
	iters: 4000, epoch: 3 | loss: 0.1094842
	speed: 0.1188s/iter; left time: 9030.7883s
	iters: 4100, epoch: 3 | loss: 0.1029801
	speed: 0.1496s/iter; left time: 11357.4676s
	iters: 4200, epoch: 3 | loss: 0.1099910
	speed: 0.1292s/iter; left time: 9793.8597s
	iters: 4300, epoch: 3 | loss: 0.1054428
	speed: 0.1187s/iter; left time: 8986.8338s
	iters: 4400, epoch: 3 | loss: 0.0913317
	speed: 0.1405s/iter; left time: 10629.0923s
Epoch: 3 cost time: 00h:09m:37.25s
Epoch: 3 | Train Loss: 0.1093807 Vali Loss: 0.1236754 Test Loss: 0.1367024
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0959466
	speed: 1.5961s/iter; left time: 120480.5884s
	iters: 200, epoch: 4 | loss: 0.0858854
	speed: 0.1543s/iter; left time: 11629.1013s
	iters: 300, epoch: 4 | loss: 0.0893636
	speed: 0.1205s/iter; left time: 9073.3773s
	iters: 400, epoch: 4 | loss: 0.1088450
	speed: 0.1207s/iter; left time: 9075.5081s
	iters: 500, epoch: 4 | loss: 0.1087373
	speed: 0.1387s/iter; left time: 10416.5456s
	iters: 600, epoch: 4 | loss: 0.1005550
	speed: 0.1415s/iter; left time: 10609.1024s
	iters: 700, epoch: 4 | loss: 0.0969683
	speed: 0.1145s/iter; left time: 8576.0083s
	iters: 800, epoch: 4 | loss: 0.1045174
	speed: 0.1025s/iter; left time: 7662.7301s
	iters: 900, epoch: 4 | loss: 0.1086594
	speed: 0.1154s/iter; left time: 8615.0976s
	iters: 1000, epoch: 4 | loss: 0.1303164
	speed: 0.1521s/iter; left time: 11344.3107s
	iters: 1100, epoch: 4 | loss: 0.1121879
	speed: 0.1202s/iter; left time: 8954.6761s
	iters: 1200, epoch: 4 | loss: 0.1189122
	speed: 0.1201s/iter; left time: 8934.2357s
	iters: 1300, epoch: 4 | loss: 0.1055549
	speed: 0.1206s/iter; left time: 8956.1861s
	iters: 1400, epoch: 4 | loss: 0.1178071
	speed: 0.1569s/iter; left time: 11641.5839s
	iters: 1500, epoch: 4 | loss: 0.1012621
	speed: 0.1245s/iter; left time: 9221.5964s
	iters: 1600, epoch: 4 | loss: 0.1049342
	speed: 0.1203s/iter; left time: 8899.0036s
	iters: 1700, epoch: 4 | loss: 0.1118138
	speed: 0.1496s/iter; left time: 11049.9114s
	iters: 1800, epoch: 4 | loss: 0.1249317
	speed: 0.1324s/iter; left time: 9766.9226s
	iters: 1900, epoch: 4 | loss: 0.1314284
	speed: 0.1204s/iter; left time: 8874.2336s
	iters: 2000, epoch: 4 | loss: 0.1265800
	speed: 0.1206s/iter; left time: 8874.9240s
	iters: 2100, epoch: 4 | loss: 0.1018833
	speed: 0.1621s/iter; left time: 11909.6924s
	iters: 2200, epoch: 4 | loss: 0.1211214
	speed: 0.1193s/iter; left time: 8756.7578s
	iters: 2300, epoch: 4 | loss: 0.0848068
	speed: 0.1206s/iter; left time: 8839.2830s
	iters: 2400, epoch: 4 | loss: 0.1038890
	speed: 0.1304s/iter; left time: 9545.4433s
	iters: 2500, epoch: 4 | loss: 0.1123954
	speed: 0.1508s/iter; left time: 11020.1195s
	iters: 2600, epoch: 4 | loss: 0.0989040
	speed: 0.1197s/iter; left time: 8736.5010s
	iters: 2700, epoch: 4 | loss: 0.1005402
	speed: 0.1203s/iter; left time: 8764.7511s
	iters: 2800, epoch: 4 | loss: 0.1054526
	speed: 0.1378s/iter; left time: 10027.8447s
	iters: 2900, epoch: 4 | loss: 0.1114677
	speed: 0.1345s/iter; left time: 9773.2574s
	iters: 3000, epoch: 4 | loss: 0.1075196
	speed: 0.1193s/iter; left time: 8657.4846s
	iters: 3100, epoch: 4 | loss: 0.0856683
	speed: 0.1209s/iter; left time: 8765.6871s
	iters: 3200, epoch: 4 | loss: 0.1058800
	speed: 0.1562s/iter; left time: 11306.6176s
	iters: 3300, epoch: 4 | loss: 0.1083319
	speed: 0.1199s/iter; left time: 8668.2359s
	iters: 3400, epoch: 4 | loss: 0.0981609
	speed: 0.1197s/iter; left time: 8641.1723s
	iters: 3500, epoch: 4 | loss: 0.0921983
	speed: 0.1209s/iter; left time: 8717.5124s
	iters: 3600, epoch: 4 | loss: 0.1049358
	speed: 0.1384s/iter; left time: 9961.4236s
	iters: 3700, epoch: 4 | loss: 0.0929390
	speed: 0.1358s/iter; left time: 9760.2594s
	iters: 3800, epoch: 4 | loss: 0.0982588
	speed: 0.1064s/iter; left time: 7638.2370s
	iters: 3900, epoch: 4 | loss: 0.0918985
	speed: 0.1196s/iter; left time: 8573.8076s
	iters: 4000, epoch: 4 | loss: 0.1195650
	speed: 0.1472s/iter; left time: 10534.3494s
	iters: 4100, epoch: 4 | loss: 0.1090801
	speed: 0.1351s/iter; left time: 9656.4173s
	iters: 4200, epoch: 4 | loss: 0.1110307
	speed: 0.1204s/iter; left time: 8595.5347s
	iters: 4300, epoch: 4 | loss: 0.1110436
	speed: 0.1208s/iter; left time: 8612.0902s
	iters: 4400, epoch: 4 | loss: 0.1014118
	speed: 0.1569s/iter; left time: 11168.4169s
Epoch: 4 cost time: 00h:09m:36.15s
Epoch: 4 | Train Loss: 0.1046495 Vali Loss: 0.1247817 Test Loss: 0.1472365
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.1008341
	speed: 1.5868s/iter; left time: 112723.0239s
	iters: 200, epoch: 5 | loss: 0.1144764
	speed: 0.1347s/iter; left time: 9557.0615s
	iters: 300, epoch: 5 | loss: 0.1179324
	speed: 0.1203s/iter; left time: 8521.7536s
	iters: 400, epoch: 5 | loss: 0.1061344
	speed: 0.1192s/iter; left time: 8433.2988s
	iters: 500, epoch: 5 | loss: 0.0869319
	speed: 0.1572s/iter; left time: 11104.2545s
	iters: 600, epoch: 5 | loss: 0.0929676
	speed: 0.1174s/iter; left time: 8280.7519s
	iters: 700, epoch: 5 | loss: 0.1068786
	speed: 0.1180s/iter; left time: 8309.6225s
	iters: 800, epoch: 5 | loss: 0.0935982
	speed: 0.1290s/iter; left time: 9072.0218s
	iters: 900, epoch: 5 | loss: 0.1054375
	speed: 0.1483s/iter; left time: 10413.6047s
	iters: 1000, epoch: 5 | loss: 0.1086309
	speed: 0.1199s/iter; left time: 8410.4937s
	iters: 1100, epoch: 5 | loss: 0.1122420
	speed: 0.1166s/iter; left time: 8165.4214s
	iters: 1200, epoch: 5 | loss: 0.1004656
	speed: 0.1519s/iter; left time: 10622.2138s
	iters: 1300, epoch: 5 | loss: 0.0959615
	speed: 0.1260s/iter; left time: 8802.5739s
	iters: 1400, epoch: 5 | loss: 0.1126448
	speed: 0.1200s/iter; left time: 8370.1891s
	iters: 1500, epoch: 5 | loss: 0.0902287
	speed: 0.1274s/iter; left time: 8868.4050s
	iters: 1600, epoch: 5 | loss: 0.0997650
	speed: 0.1420s/iter; left time: 9872.1772s
	iters: 1700, epoch: 5 | loss: 0.1175994
	speed: 0.1029s/iter; left time: 7146.6681s
	iters: 1800, epoch: 5 | loss: 0.1059145
	speed: 0.1023s/iter; left time: 7089.9715s
	iters: 1900, epoch: 5 | loss: 0.0982435
	speed: 0.1357s/iter; left time: 9394.3629s
	iters: 2000, epoch: 5 | loss: 0.1148793
	speed: 0.1326s/iter; left time: 9165.0599s
	iters: 2100, epoch: 5 | loss: 0.1237828
	speed: 0.1190s/iter; left time: 8216.2611s
	iters: 2200, epoch: 5 | loss: 0.0931523
	speed: 0.1202s/iter; left time: 8283.0429s
	iters: 2300, epoch: 5 | loss: 0.0861305
	speed: 0.1595s/iter; left time: 10981.7679s
	iters: 2400, epoch: 5 | loss: 0.0990851
	speed: 0.1225s/iter; left time: 8422.9487s
	iters: 2500, epoch: 5 | loss: 0.0847341
	speed: 0.1206s/iter; left time: 8277.0872s
	iters: 2600, epoch: 5 | loss: 0.1076903
	speed: 0.1197s/iter; left time: 8204.3958s
	iters: 2700, epoch: 5 | loss: 0.1186636
	speed: 0.1238s/iter; left time: 8473.0081s
	iters: 2800, epoch: 5 | loss: 0.0813073
	speed: 0.1583s/iter; left time: 10818.1232s
	iters: 2900, epoch: 5 | loss: 0.0954584
	speed: 0.1203s/iter; left time: 8206.0969s
	iters: 3000, epoch: 5 | loss: 0.0905743
	speed: 0.1205s/iter; left time: 8209.1790s
	iters: 3100, epoch: 5 | loss: 0.1002901
	speed: 0.1210s/iter; left time: 8232.3391s
	iters: 3200, epoch: 5 | loss: 0.0847461
	speed: 0.1468s/iter; left time: 9974.2529s
	iters: 3300, epoch: 5 | loss: 0.1024117
	speed: 0.1299s/iter; left time: 8810.8269s
	iters: 3400, epoch: 5 | loss: 0.0998646
	speed: 0.1202s/iter; left time: 8141.5231s
	iters: 3500, epoch: 5 | loss: 0.0978041
	speed: 0.1402s/iter; left time: 9480.9619s
	iters: 3600, epoch: 5 | loss: 0.1110223
	speed: 0.1419s/iter; left time: 9581.4196s
	iters: 3700, epoch: 5 | loss: 0.0857197
	speed: 0.1206s/iter; left time: 8131.9129s
	iters: 3800, epoch: 5 | loss: 0.0900995
	speed: 0.1198s/iter; left time: 8067.1218s
	iters: 3900, epoch: 5 | loss: 0.0950421
	speed: 0.1274s/iter; left time: 8566.8646s
	iters: 4000, epoch: 5 | loss: 0.1002941
	speed: 0.1552s/iter; left time: 10422.8892s
	iters: 4100, epoch: 5 | loss: 0.1072492
	speed: 0.1198s/iter; left time: 8032.6979s
	iters: 4200, epoch: 5 | loss: 0.0923533
	speed: 0.1203s/iter; left time: 8053.6159s
	iters: 4300, epoch: 5 | loss: 0.0978186
	speed: 0.1201s/iter; left time: 8027.4373s
	iters: 4400, epoch: 5 | loss: 0.0912306
	speed: 0.1469s/iter; left time: 9801.0463s
Epoch: 5 cost time: 00h:09m:34.51s
Epoch: 5 | Train Loss: 0.1001263 Vali Loss: 0.1304869 Test Loss: 0.1511040
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1040925
	speed: 1.5384s/iter; left time: 102441.9456s
	iters: 200, epoch: 6 | loss: 0.1047199
	speed: 0.1204s/iter; left time: 8007.8539s
	iters: 300, epoch: 6 | loss: 0.0804931
	speed: 0.1299s/iter; left time: 8622.9246s
	iters: 400, epoch: 6 | loss: 0.0875467
	speed: 0.1518s/iter; left time: 10065.5801s
	iters: 500, epoch: 6 | loss: 0.0984672
	speed: 0.1201s/iter; left time: 7947.5729s
	iters: 600, epoch: 6 | loss: 0.1009006
	speed: 0.1207s/iter; left time: 7977.4011s
	iters: 700, epoch: 6 | loss: 0.0918718
	speed: 0.1205s/iter; left time: 7952.0579s
	iters: 800, epoch: 6 | loss: 0.1056673
	speed: 0.1408s/iter; left time: 9279.4978s
	iters: 900, epoch: 6 | loss: 0.0862563
	speed: 0.1413s/iter; left time: 9293.7271s
	iters: 1000, epoch: 6 | loss: 0.0999702
	speed: 0.1204s/iter; left time: 7908.6448s
	iters: 1100, epoch: 6 | loss: 0.0961189
	speed: 0.1181s/iter; left time: 7746.1876s
	iters: 1200, epoch: 6 | loss: 0.1147054
	speed: 0.1191s/iter; left time: 7801.8267s
	iters: 1300, epoch: 6 | loss: 0.0912160
	speed: 0.1550s/iter; left time: 10137.3324s
	iters: 1400, epoch: 6 | loss: 0.0981800
	speed: 0.1254s/iter; left time: 8187.2322s
	iters: 1500, epoch: 6 | loss: 0.0838766
	speed: 0.1200s/iter; left time: 7823.5905s
	iters: 1600, epoch: 6 | loss: 0.0883116
	speed: 0.1342s/iter; left time: 8733.6978s
	iters: 1700, epoch: 6 | loss: 0.0896513
	speed: 0.1454s/iter; left time: 9449.1071s
	iters: 1800, epoch: 6 | loss: 0.0974333
	speed: 0.1194s/iter; left time: 7748.9081s
	iters: 1900, epoch: 6 | loss: 0.0899982
	speed: 0.1225s/iter; left time: 7936.1282s
	iters: 2000, epoch: 6 | loss: 0.0925732
	speed: 0.1552s/iter; left time: 10042.4806s
	iters: 2100, epoch: 6 | loss: 0.0867949
	speed: 0.1167s/iter; left time: 7534.8939s
	iters: 2200, epoch: 6 | loss: 0.1011756
	speed: 0.1209s/iter; left time: 7796.6268s
	iters: 2300, epoch: 6 | loss: 0.0931246
	speed: 0.1462s/iter; left time: 9411.2734s
	iters: 2400, epoch: 6 | loss: 0.0912003
	speed: 0.1327s/iter; left time: 8528.8997s
	iters: 2500, epoch: 6 | loss: 0.0813842
	speed: 0.1197s/iter; left time: 7682.4912s
	iters: 2600, epoch: 6 | loss: 0.0974265
	speed: 0.1393s/iter; left time: 8927.2236s
	iters: 2700, epoch: 6 | loss: 0.1037935
	speed: 0.1413s/iter; left time: 9044.8802s
	iters: 2800, epoch: 6 | loss: 0.0945832
	speed: 0.1192s/iter; left time: 7614.9697s
	iters: 2900, epoch: 6 | loss: 0.0993364
	speed: 0.1460s/iter; left time: 9314.7197s
	iters: 3000, epoch: 6 | loss: 0.0983878
	speed: 0.1345s/iter; left time: 8568.9704s
	iters: 3100, epoch: 6 | loss: 0.0967573
	speed: 0.1196s/iter; left time: 7606.3067s
	iters: 3200, epoch: 6 | loss: 0.0809352
	speed: 0.1518s/iter; left time: 9636.8706s
	iters: 3300, epoch: 6 | loss: 0.0907727
	speed: 0.1130s/iter; left time: 7164.3198s
	iters: 3400, epoch: 6 | loss: 0.1019389
	speed: 0.1173s/iter; left time: 7423.1448s
	iters: 3500, epoch: 6 | loss: 0.1059106
	speed: 0.1601s/iter; left time: 10113.9241s
	iters: 3600, epoch: 6 | loss: 0.0917989
	speed: 0.1216s/iter; left time: 7671.2563s
	iters: 3700, epoch: 6 | loss: 0.0842525
	speed: 0.1309s/iter; left time: 8247.1992s
	iters: 3800, epoch: 6 | loss: 0.0876396
	speed: 0.1517s/iter; left time: 9541.4374s
	iters: 3900, epoch: 6 | loss: 0.1118588
	speed: 0.1196s/iter; left time: 7510.1725s
	iters: 4000, epoch: 6 | loss: 0.0991682
	speed: 0.1202s/iter; left time: 7538.5674s
	iters: 4100, epoch: 6 | loss: 0.0930842
	speed: 0.1509s/iter; left time: 9446.4604s
	iters: 4200, epoch: 6 | loss: 0.0981919
	speed: 0.1290s/iter; left time: 8064.3315s
	iters: 4300, epoch: 6 | loss: 0.0870969
	speed: 0.1197s/iter; left time: 7467.3843s
	iters: 4400, epoch: 6 | loss: 0.0964762
	speed: 0.1617s/iter; left time: 10072.3223s
Epoch: 6 cost time: 00h:09m:42.76s
Epoch: 6 | Train Loss: 0.0960726 Vali Loss: 0.1291619 Test Loss: 0.1511165
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.03767301142215729, rmse:0.19409537315368652, mae:0.1336192935705185, rse:0.6876434087753296
success delete checkpoints
Intermediate time for DE and pred_len 168: 01h:14m:40.58s

Intermediate time for DE: 05h:19m:38.50s


=== Starting experiments for country: GB ===


=== Starting experiments for pred_len: 24 ===

train 143005
val 31085
test 31085
[2024-11-01 01:13:46,535] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 01:13:47,624] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 01:13:47,624] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 01:13:47,624] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 01:13:47,724] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 01:13:47,724] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 01:13:48,374] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 01:13:48,375] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 01:13:48,375] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 01:13:48,376] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 01:13:48,377] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 01:13:48,377] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 01:13:48,377] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 01:13:48,377] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 01:13:48,377] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 01:13:48,377] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 01:13:48,644] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 01:13:48,645] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 01:13:48,682] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 192.76 GB, percent = 25.5%
[2024-11-01 01:13:48,811] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 01:13:48,811] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 01:13:48,812] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 192.76 GB, percent = 25.5%
[2024-11-01 01:13:48,812] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 01:13:48,929] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 01:13:48,930] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 01:13:48,930] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 192.76 GB, percent = 25.5%
[2024-11-01 01:13:48,931] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 01:13:48,931] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 01:13:48,931] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 01:13:48,931] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 01:13:48,932] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 01:13:48,932] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f61b02f71d0>
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 01:13:48,933] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 01:13:48,934] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 01:13:48,935] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 01:13:48,935] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1466742
	speed: 0.1720s/iter; left time: 15348.9424s
	iters: 200, epoch: 1 | loss: 0.1377795
	speed: 0.1311s/iter; left time: 11686.5654s
	iters: 300, epoch: 1 | loss: 0.1637115
	speed: 0.1304s/iter; left time: 11613.8875s
	iters: 400, epoch: 1 | loss: 0.1077301
	speed: 0.1311s/iter; left time: 11662.3304s
	iters: 500, epoch: 1 | loss: 0.1226833
	speed: 0.1490s/iter; left time: 13243.5812s
	iters: 600, epoch: 1 | loss: 0.1199201
	speed: 0.1737s/iter; left time: 15417.1514s
	iters: 700, epoch: 1 | loss: 0.1068131
	speed: 0.1768s/iter; left time: 15673.9475s
	iters: 800, epoch: 1 | loss: 0.1092960
	speed: 0.1741s/iter; left time: 15420.1731s
	iters: 900, epoch: 1 | loss: 0.0919815
	speed: 0.1720s/iter; left time: 15217.7282s
	iters: 1000, epoch: 1 | loss: 0.1038064
	speed: 0.1746s/iter; left time: 15426.0227s
	iters: 1100, epoch: 1 | loss: 0.0846845
	speed: 0.1755s/iter; left time: 15488.9210s
	iters: 1200, epoch: 1 | loss: 0.0949691
	speed: 0.1752s/iter; left time: 15447.5047s
	iters: 1300, epoch: 1 | loss: 0.0737247
	speed: 0.1758s/iter; left time: 15483.7817s
	iters: 1400, epoch: 1 | loss: 0.1031198
	speed: 0.1752s/iter; left time: 15409.8681s
	iters: 1500, epoch: 1 | loss: 0.0780963
	speed: 0.1729s/iter; left time: 15193.3389s
	iters: 1600, epoch: 1 | loss: 0.0978673
	speed: 0.1702s/iter; left time: 14935.5128s
	iters: 1700, epoch: 1 | loss: 0.1247796
	speed: 0.1683s/iter; left time: 14752.5401s
	iters: 1800, epoch: 1 | loss: 0.1062685
	speed: 0.1733s/iter; left time: 15175.1279s
	iters: 1900, epoch: 1 | loss: 0.1049088
	speed: 0.1714s/iter; left time: 14991.8066s
	iters: 2000, epoch: 1 | loss: 0.0870789
	speed: 0.1742s/iter; left time: 15216.7327s
	iters: 2100, epoch: 1 | loss: 0.0814199
	speed: 0.1740s/iter; left time: 15187.6068s
	iters: 2200, epoch: 1 | loss: 0.0885388
	speed: 0.1741s/iter; left time: 15175.2167s
	iters: 2300, epoch: 1 | loss: 0.0876981
	speed: 0.1725s/iter; left time: 15021.8698s
	iters: 2400, epoch: 1 | loss: 0.0750865
	speed: 0.1877s/iter; left time: 16318.7573s
	iters: 2500, epoch: 1 | loss: 0.0770076
	speed: 0.1822s/iter; left time: 15829.1500s
	iters: 2600, epoch: 1 | loss: 0.0930856
	speed: 0.1850s/iter; left time: 16051.4728s
	iters: 2700, epoch: 1 | loss: 0.0914229
	speed: 0.1959s/iter; left time: 16975.7173s
	iters: 2800, epoch: 1 | loss: 0.0742800
	speed: 0.1348s/iter; left time: 11667.3887s
	iters: 2900, epoch: 1 | loss: 0.0699159
	speed: 0.1304s/iter; left time: 11276.7654s
	iters: 3000, epoch: 1 | loss: 0.0888919
	speed: 0.1307s/iter; left time: 11287.1111s
	iters: 3100, epoch: 1 | loss: 0.0732918
	speed: 0.1297s/iter; left time: 11186.5664s
	iters: 3200, epoch: 1 | loss: 0.0881244
	speed: 0.1321s/iter; left time: 11378.9437s
	iters: 3300, epoch: 1 | loss: 0.0822907
	speed: 0.1372s/iter; left time: 11808.7004s
	iters: 3400, epoch: 1 | loss: 0.0753193
	speed: 0.1238s/iter; left time: 10642.4978s
	iters: 3500, epoch: 1 | loss: 0.0816539
	speed: 0.1299s/iter; left time: 11152.7013s
	iters: 3600, epoch: 1 | loss: 0.0759263
	speed: 0.1258s/iter; left time: 10787.0354s
	iters: 3700, epoch: 1 | loss: 0.0969475
	speed: 0.1373s/iter; left time: 11765.1133s
	iters: 3800, epoch: 1 | loss: 0.0810152
	speed: 0.1361s/iter; left time: 11648.9178s
	iters: 3900, epoch: 1 | loss: 0.0943139
	speed: 0.1311s/iter; left time: 11205.3676s
	iters: 4000, epoch: 1 | loss: 0.0698772
	speed: 0.1250s/iter; left time: 10668.8025s
	iters: 4100, epoch: 1 | loss: 0.0704658
	speed: 0.1298s/iter; left time: 11069.3625s
	iters: 4200, epoch: 1 | loss: 0.1035011
	speed: 0.1351s/iter; left time: 11506.7142s
	iters: 4300, epoch: 1 | loss: 0.0949263
	speed: 0.1367s/iter; left time: 11631.9644s
	iters: 4400, epoch: 1 | loss: 0.0885897
	speed: 0.1369s/iter; left time: 11630.9999s
Epoch: 1 cost time: 00h:11m:28.65s
Epoch: 1 | Train Loss: 0.0973537 Vali Loss: 0.0928246 Test Loss: 0.1050737
Validation loss decreased (inf --> 0.092825).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0701588
	speed: 1.8397s/iter; left time: 155997.6031s
	iters: 200, epoch: 2 | loss: 0.1044648
	speed: 0.1250s/iter; left time: 10582.6015s
	iters: 300, epoch: 2 | loss: 0.0884274
	speed: 0.1254s/iter; left time: 10605.1158s
	iters: 400, epoch: 2 | loss: 0.1147017
	speed: 0.1229s/iter; left time: 10383.1679s
	iters: 500, epoch: 2 | loss: 0.0937675
	speed: 0.1190s/iter; left time: 10038.6051s
	iters: 600, epoch: 2 | loss: 0.0921706
	speed: 0.1236s/iter; left time: 10418.2877s
	iters: 700, epoch: 2 | loss: 0.0930738
	speed: 0.1196s/iter; left time: 10069.0209s
	iters: 800, epoch: 2 | loss: 0.1000150
	speed: 0.1253s/iter; left time: 10534.2938s
	iters: 900, epoch: 2 | loss: 0.0975661
	speed: 0.1206s/iter; left time: 10128.7696s
	iters: 1000, epoch: 2 | loss: 0.0700671
	speed: 0.1173s/iter; left time: 9844.4580s
	iters: 1100, epoch: 2 | loss: 0.0929756
	speed: 0.1198s/iter; left time: 10037.0371s
	iters: 1200, epoch: 2 | loss: 0.0745666
	speed: 0.1220s/iter; left time: 10210.0538s
	iters: 1300, epoch: 2 | loss: 0.0924439
	speed: 0.1261s/iter; left time: 10538.2378s
	iters: 1400, epoch: 2 | loss: 0.1111560
	speed: 0.1260s/iter; left time: 10518.7261s
	iters: 1500, epoch: 2 | loss: 0.0793124
	speed: 0.1235s/iter; left time: 10302.7127s
	iters: 1600, epoch: 2 | loss: 0.0794686
	speed: 0.1160s/iter; left time: 9666.0832s
	iters: 1700, epoch: 2 | loss: 0.0875069
	speed: 0.1223s/iter; left time: 10177.9038s
	iters: 1800, epoch: 2 | loss: 0.0863800
	speed: 0.1234s/iter; left time: 10251.4920s
	iters: 1900, epoch: 2 | loss: 0.0864655
	speed: 0.1239s/iter; left time: 10280.0741s
	iters: 2000, epoch: 2 | loss: 0.0874661
	speed: 0.1196s/iter; left time: 9915.6803s
	iters: 2100, epoch: 2 | loss: 0.0986785
	speed: 0.1241s/iter; left time: 10272.4187s
	iters: 2200, epoch: 2 | loss: 0.0935980
	speed: 0.1261s/iter; left time: 10429.9927s
	iters: 2300, epoch: 2 | loss: 0.0926060
	speed: 0.1229s/iter; left time: 10149.4789s
	iters: 2400, epoch: 2 | loss: 0.0731041
	speed: 0.1211s/iter; left time: 9988.3056s
	iters: 2500, epoch: 2 | loss: 0.0878800
	speed: 0.1199s/iter; left time: 9879.4931s
	iters: 2600, epoch: 2 | loss: 0.1000494
	speed: 0.1190s/iter; left time: 9788.7570s
	iters: 2700, epoch: 2 | loss: 0.0909730
	speed: 0.1166s/iter; left time: 9583.3741s
	iters: 2800, epoch: 2 | loss: 0.1120826
	speed: 0.1257s/iter; left time: 10318.9937s
	iters: 2900, epoch: 2 | loss: 0.0753991
	speed: 0.1164s/iter; left time: 9544.3258s
	iters: 3000, epoch: 2 | loss: 0.0918223
	speed: 0.1264s/iter; left time: 10348.4450s
	iters: 3100, epoch: 2 | loss: 0.1169008
	speed: 0.1260s/iter; left time: 10307.7682s
	iters: 3200, epoch: 2 | loss: 0.0799625
	speed: 0.1254s/iter; left time: 10244.0151s
	iters: 3300, epoch: 2 | loss: 0.0924724
	speed: 0.1149s/iter; left time: 9378.4254s
	iters: 3400, epoch: 2 | loss: 0.0893005
	speed: 0.1160s/iter; left time: 9451.9056s
	iters: 3500, epoch: 2 | loss: 0.0870048
	speed: 0.1199s/iter; left time: 9758.8241s
	iters: 3600, epoch: 2 | loss: 0.0749805
	speed: 0.1230s/iter; left time: 9996.5343s
	iters: 3700, epoch: 2 | loss: 0.0773853
	speed: 0.1240s/iter; left time: 10068.0629s
	iters: 3800, epoch: 2 | loss: 0.0819646
	speed: 0.1187s/iter; left time: 9625.2425s
	iters: 3900, epoch: 2 | loss: 0.0823601
	speed: 0.1251s/iter; left time: 10135.1473s
	iters: 4000, epoch: 2 | loss: 0.0686158
	speed: 0.1269s/iter; left time: 10268.6608s
	iters: 4100, epoch: 2 | loss: 0.0982631
	speed: 0.1246s/iter; left time: 10064.8182s
	iters: 4200, epoch: 2 | loss: 0.0787107
	speed: 0.1241s/iter; left time: 10011.1850s
	iters: 4300, epoch: 2 | loss: 0.0879422
	speed: 0.1264s/iter; left time: 10188.8222s
	iters: 4400, epoch: 2 | loss: 0.0896147
	speed: 0.1248s/iter; left time: 10042.9961s
Epoch: 2 cost time: 00h:09m:07.39s
Epoch: 2 | Train Loss: 0.0860910 Vali Loss: 0.0922121 Test Loss: 0.1065872
Validation loss decreased (0.092825 --> 0.092212).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0907432
	speed: 1.6384s/iter; left time: 131605.7640s
	iters: 200, epoch: 3 | loss: 0.0779589
	speed: 0.1243s/iter; left time: 9973.0253s
	iters: 300, epoch: 3 | loss: 0.0885364
	speed: 0.1280s/iter; left time: 10258.0784s
	iters: 400, epoch: 3 | loss: 0.0848934
	speed: 0.1285s/iter; left time: 10280.3919s
	iters: 500, epoch: 3 | loss: 0.0842507
	speed: 0.1276s/iter; left time: 10200.6627s
	iters: 600, epoch: 3 | loss: 0.0788545
	speed: 0.1253s/iter; left time: 10004.4945s
	iters: 700, epoch: 3 | loss: 0.0803074
	speed: 0.1196s/iter; left time: 9535.5871s
	iters: 800, epoch: 3 | loss: 0.0902780
	speed: 0.1201s/iter; left time: 9563.2326s
	iters: 900, epoch: 3 | loss: 0.0700542
	speed: 0.1224s/iter; left time: 9735.4265s
	iters: 1000, epoch: 3 | loss: 0.0909660
	speed: 0.1252s/iter; left time: 9940.5088s
	iters: 1100, epoch: 3 | loss: 0.0937846
	speed: 0.1263s/iter; left time: 10015.3475s
	iters: 1200, epoch: 3 | loss: 0.0607558
	speed: 0.1257s/iter; left time: 9956.2601s
	iters: 1300, epoch: 3 | loss: 0.0803862
	speed: 0.1181s/iter; left time: 9347.7165s
	iters: 1400, epoch: 3 | loss: 0.0932646
	speed: 0.1252s/iter; left time: 9894.9792s
	iters: 1500, epoch: 3 | loss: 0.0733327
	speed: 0.1247s/iter; left time: 9838.8822s
	iters: 1600, epoch: 3 | loss: 0.0595024
	speed: 0.1254s/iter; left time: 9886.6863s
	iters: 1700, epoch: 3 | loss: 0.0652814
	speed: 0.1227s/iter; left time: 9660.1343s
	iters: 1800, epoch: 3 | loss: 0.0982525
	speed: 0.1231s/iter; left time: 9681.7754s
	iters: 1900, epoch: 3 | loss: 0.0716447
	speed: 0.1248s/iter; left time: 9796.1519s
	iters: 2000, epoch: 3 | loss: 0.0835190
	speed: 0.1258s/iter; left time: 9868.0218s
	iters: 2100, epoch: 3 | loss: 0.0834547
	speed: 0.1270s/iter; left time: 9949.3213s
	iters: 2200, epoch: 3 | loss: 0.0948817
	speed: 0.1164s/iter; left time: 9103.7785s
	iters: 2300, epoch: 3 | loss: 0.0844729
	speed: 0.1279s/iter; left time: 9989.2713s
	iters: 2400, epoch: 3 | loss: 0.0765860
	speed: 0.1258s/iter; left time: 9811.6570s
	iters: 2500, epoch: 3 | loss: 0.0919627
	speed: 0.1261s/iter; left time: 9822.4583s
	iters: 2600, epoch: 3 | loss: 0.0797675
	speed: 0.1143s/iter; left time: 8895.3972s
	iters: 2700, epoch: 3 | loss: 0.0741416
	speed: 0.1279s/iter; left time: 9941.6814s
	iters: 2800, epoch: 3 | loss: 0.0829531
	speed: 0.1251s/iter; left time: 9711.3739s
	iters: 2900, epoch: 3 | loss: 0.0889192
	speed: 0.1251s/iter; left time: 9700.0550s
	iters: 3000, epoch: 3 | loss: 0.0789738
	speed: 0.1224s/iter; left time: 9473.5702s
	iters: 3100, epoch: 3 | loss: 0.0949245
	speed: 0.1221s/iter; left time: 9440.9616s
	iters: 3200, epoch: 3 | loss: 0.0981605
	speed: 0.1252s/iter; left time: 9671.0077s
	iters: 3300, epoch: 3 | loss: 0.0789458
	speed: 0.1261s/iter; left time: 9728.1743s
	iters: 3400, epoch: 3 | loss: 0.0741549
	speed: 0.1245s/iter; left time: 9588.6716s
	iters: 3500, epoch: 3 | loss: 0.0773597
	speed: 0.1183s/iter; left time: 9103.3499s
	iters: 3600, epoch: 3 | loss: 0.0935745
	speed: 0.1284s/iter; left time: 9864.8752s
	iters: 3700, epoch: 3 | loss: 0.0769829
	speed: 0.1281s/iter; left time: 9825.4101s
	iters: 3800, epoch: 3 | loss: 0.0949859
	speed: 0.1258s/iter; left time: 9636.4106s
	iters: 3900, epoch: 3 | loss: 0.0808080
	speed: 0.1166s/iter; left time: 8924.0939s
	iters: 4000, epoch: 3 | loss: 0.0665414
	speed: 0.1208s/iter; left time: 9233.4311s
	iters: 4100, epoch: 3 | loss: 0.0754559
	speed: 0.1209s/iter; left time: 9228.2114s
	iters: 4200, epoch: 3 | loss: 0.0699142
	speed: 0.1190s/iter; left time: 9073.9133s
	iters: 4300, epoch: 3 | loss: 0.0632910
	speed: 0.1174s/iter; left time: 8933.8075s
	iters: 4400, epoch: 3 | loss: 0.0808305
	speed: 0.1207s/iter; left time: 9177.2720s
Epoch: 3 cost time: 00h:09m:13.14s
Epoch: 3 | Train Loss: 0.0838997 Vali Loss: 0.0905142 Test Loss: 0.1035439
Validation loss decreased (0.092212 --> 0.090514).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0914321
	speed: 1.7845s/iter; left time: 135367.9697s
	iters: 200, epoch: 4 | loss: 0.0923484
	speed: 0.1205s/iter; left time: 9127.9675s
	iters: 300, epoch: 4 | loss: 0.0886503
	speed: 0.1287s/iter; left time: 9735.5612s
	iters: 400, epoch: 4 | loss: 0.0890385
	speed: 0.1726s/iter; left time: 13043.6124s
	iters: 500, epoch: 4 | loss: 0.0889764
	speed: 0.1765s/iter; left time: 13315.6297s
	iters: 600, epoch: 4 | loss: 0.0682504
	speed: 0.1695s/iter; left time: 12770.4607s
	iters: 700, epoch: 4 | loss: 0.0858520
	speed: 0.1698s/iter; left time: 12780.1781s
	iters: 800, epoch: 4 | loss: 0.0807579
	speed: 0.1719s/iter; left time: 12917.0464s
	iters: 900, epoch: 4 | loss: 0.0771627
	speed: 0.1724s/iter; left time: 12938.1110s
	iters: 1000, epoch: 4 | loss: 0.0891313
	speed: 0.1711s/iter; left time: 12828.5135s
	iters: 1100, epoch: 4 | loss: 0.0808600
	speed: 0.1704s/iter; left time: 12755.0142s
	iters: 1200, epoch: 4 | loss: 0.1001335
	speed: 0.1724s/iter; left time: 12889.6694s
	iters: 1300, epoch: 4 | loss: 0.1131133
	speed: 0.1690s/iter; left time: 12617.0767s
	iters: 1400, epoch: 4 | loss: 0.0778967
	speed: 0.1738s/iter; left time: 12960.3054s
	iters: 1500, epoch: 4 | loss: 0.0659208
	speed: 0.1754s/iter; left time: 13062.3332s
	iters: 1600, epoch: 4 | loss: 0.0821595
	speed: 0.1746s/iter; left time: 12984.3965s
	iters: 1700, epoch: 4 | loss: 0.0919877
	speed: 0.1753s/iter; left time: 13017.2381s
	iters: 1800, epoch: 4 | loss: 0.0923949
	speed: 0.1717s/iter; left time: 12729.9337s
	iters: 1900, epoch: 4 | loss: 0.0738678
	speed: 0.1756s/iter; left time: 13001.3578s
	iters: 2000, epoch: 4 | loss: 0.0819451
	speed: 0.1712s/iter; left time: 12662.4492s
	iters: 2100, epoch: 4 | loss: 0.0814312
	speed: 0.1725s/iter; left time: 12738.3235s
	iters: 2200, epoch: 4 | loss: 0.0888639
	speed: 0.1821s/iter; left time: 13434.7490s
	iters: 2300, epoch: 4 | loss: 0.1003453
	speed: 0.1787s/iter; left time: 13162.4271s
	iters: 2400, epoch: 4 | loss: 0.0999414
	speed: 0.1737s/iter; left time: 12780.3083s
	iters: 2500, epoch: 4 | loss: 0.0742211
	speed: 0.1878s/iter; left time: 13797.4448s
	iters: 2600, epoch: 4 | loss: 0.0718067
	speed: 0.1666s/iter; left time: 12220.5034s
	iters: 2700, epoch: 4 | loss: 0.0911036
	speed: 0.1212s/iter; left time: 8879.4585s
	iters: 2800, epoch: 4 | loss: 0.0877281
	speed: 0.1215s/iter; left time: 8890.9273s
	iters: 2900, epoch: 4 | loss: 0.0797919
	speed: 0.1266s/iter; left time: 9250.0594s
	iters: 3000, epoch: 4 | loss: 0.0775673
	speed: 0.1285s/iter; left time: 9372.9094s
	iters: 3100, epoch: 4 | loss: 0.0879129
	speed: 0.1283s/iter; left time: 9344.0534s
	iters: 3200, epoch: 4 | loss: 0.0780287
	speed: 0.1246s/iter; left time: 9064.0367s
	iters: 3300, epoch: 4 | loss: 0.0876071
	speed: 0.1190s/iter; left time: 8643.3071s
	iters: 3400, epoch: 4 | loss: 0.0757971
	speed: 0.1193s/iter; left time: 8656.3878s
	iters: 3500, epoch: 4 | loss: 0.0894305
	speed: 0.1222s/iter; left time: 8851.0792s
	iters: 3600, epoch: 4 | loss: 0.0851934
	speed: 0.1271s/iter; left time: 9194.9322s
	iters: 3700, epoch: 4 | loss: 0.0877569
	speed: 0.1245s/iter; left time: 8992.5078s
	iters: 3800, epoch: 4 | loss: 0.0781913
	speed: 0.1270s/iter; left time: 9161.1854s
	iters: 3900, epoch: 4 | loss: 0.0874085
	speed: 0.1189s/iter; left time: 8567.3724s
	iters: 4000, epoch: 4 | loss: 0.0781264
	speed: 0.1261s/iter; left time: 9070.3929s
	iters: 4100, epoch: 4 | loss: 0.0745134
	speed: 0.1265s/iter; left time: 9088.8993s
	iters: 4200, epoch: 4 | loss: 0.0732169
	speed: 0.1278s/iter; left time: 9169.5542s
	iters: 4300, epoch: 4 | loss: 0.0699919
	speed: 0.1165s/iter; left time: 8348.1299s
	iters: 4400, epoch: 4 | loss: 0.0951408
	speed: 0.1180s/iter; left time: 8444.8277s
Epoch: 4 cost time: 00h:11m:07.66s
Epoch: 4 | Train Loss: 0.0825824 Vali Loss: 0.0908698 Test Loss: 0.1047861
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0933834
	speed: 1.5809s/iter; left time: 112857.3726s
	iters: 200, epoch: 5 | loss: 0.0743399
	speed: 0.1287s/iter; left time: 9176.5420s
	iters: 300, epoch: 5 | loss: 0.0725531
	speed: 0.1256s/iter; left time: 8940.3673s
	iters: 400, epoch: 5 | loss: 0.0881155
	speed: 0.1193s/iter; left time: 8482.6711s
	iters: 500, epoch: 5 | loss: 0.0945252
	speed: 0.1248s/iter; left time: 8856.8884s
	iters: 600, epoch: 5 | loss: 0.0865966
	speed: 0.1248s/iter; left time: 8849.4854s
	iters: 700, epoch: 5 | loss: 0.0829508
	speed: 0.1289s/iter; left time: 9123.6575s
	iters: 800, epoch: 5 | loss: 0.0887444
	speed: 0.1229s/iter; left time: 8691.1113s
	iters: 900, epoch: 5 | loss: 0.1051521
	speed: 0.1201s/iter; left time: 8479.9401s
	iters: 1000, epoch: 5 | loss: 0.0809733
	speed: 0.1213s/iter; left time: 8551.3112s
	iters: 1100, epoch: 5 | loss: 0.0754441
	speed: 0.1210s/iter; left time: 8515.9684s
	iters: 1200, epoch: 5 | loss: 0.0971770
	speed: 0.1260s/iter; left time: 8853.3758s
	iters: 1300, epoch: 5 | loss: 0.0774984
	speed: 0.1166s/iter; left time: 8184.2796s
	iters: 1400, epoch: 5 | loss: 0.0693193
	speed: 0.1253s/iter; left time: 8778.7467s
	iters: 1500, epoch: 5 | loss: 0.0622493
	speed: 0.1241s/iter; left time: 8687.4124s
	iters: 1600, epoch: 5 | loss: 0.0728563
	speed: 0.1194s/iter; left time: 8345.2309s
	iters: 1700, epoch: 5 | loss: 0.0667490
	speed: 0.1237s/iter; left time: 8632.1543s
	iters: 1800, epoch: 5 | loss: 0.0948240
	speed: 0.1240s/iter; left time: 8643.1353s
	iters: 1900, epoch: 5 | loss: 0.0625855
	speed: 0.1237s/iter; left time: 8608.3545s
	iters: 2000, epoch: 5 | loss: 0.0731169
	speed: 0.1184s/iter; left time: 8230.8268s
	iters: 2100, epoch: 5 | loss: 0.0691220
	speed: 0.1185s/iter; left time: 8224.5671s
	iters: 2200, epoch: 5 | loss: 0.0799258
	speed: 0.1181s/iter; left time: 8184.1160s
	iters: 2300, epoch: 5 | loss: 0.0892581
	speed: 0.1237s/iter; left time: 8557.2416s
	iters: 2400, epoch: 5 | loss: 0.0849659
	speed: 0.1247s/iter; left time: 8617.8482s
	iters: 2500, epoch: 5 | loss: 0.0802421
	speed: 0.1268s/iter; left time: 8744.4843s
	iters: 2600, epoch: 5 | loss: 0.0774631
	speed: 0.1246s/iter; left time: 8584.8164s
	iters: 2700, epoch: 5 | loss: 0.0812496
	speed: 0.1194s/iter; left time: 8212.6434s
	iters: 2800, epoch: 5 | loss: 0.0752958
	speed: 0.1158s/iter; left time: 7955.0540s
	iters: 2900, epoch: 5 | loss: 0.0816401
	speed: 0.1073s/iter; left time: 7356.2214s
	iters: 3000, epoch: 5 | loss: 0.0708815
	speed: 0.1225s/iter; left time: 8393.1949s
	iters: 3100, epoch: 5 | loss: 0.1038611
	speed: 0.1237s/iter; left time: 8462.9521s
	iters: 3200, epoch: 5 | loss: 0.0952071
	speed: 0.1139s/iter; left time: 7778.7730s
	iters: 3300, epoch: 5 | loss: 0.0748858
	speed: 0.1165s/iter; left time: 7945.0654s
	iters: 3400, epoch: 5 | loss: 0.0783696
	speed: 0.1253s/iter; left time: 8530.7660s
	iters: 3500, epoch: 5 | loss: 0.0848109
	speed: 0.1268s/iter; left time: 8620.5989s
	iters: 3600, epoch: 5 | loss: 0.0840811
	speed: 0.1270s/iter; left time: 8622.5168s
	iters: 3700, epoch: 5 | loss: 0.0691066
	speed: 0.1197s/iter; left time: 8112.3051s
	iters: 3800, epoch: 5 | loss: 0.0793731
	speed: 0.1260s/iter; left time: 8526.7072s
	iters: 3900, epoch: 5 | loss: 0.0673810
	speed: 0.1276s/iter; left time: 8627.6479s
	iters: 4000, epoch: 5 | loss: 0.0856006
	speed: 0.1283s/iter; left time: 8657.7051s
	iters: 4100, epoch: 5 | loss: 0.0628996
	speed: 0.1236s/iter; left time: 8327.4982s
	iters: 4200, epoch: 5 | loss: 0.0903348
	speed: 0.1198s/iter; left time: 8057.8724s
	iters: 4300, epoch: 5 | loss: 0.0866672
	speed: 0.1236s/iter; left time: 8304.4123s
	iters: 4400, epoch: 5 | loss: 0.0803752
	speed: 0.1273s/iter; left time: 8538.5735s
Epoch: 5 cost time: 00h:09m:08.81s
Epoch: 5 | Train Loss: 0.0813836 Vali Loss: 0.0900973 Test Loss: 0.1040331
Validation loss decreased (0.090514 --> 0.090097).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0863184
	speed: 1.6468s/iter; left time: 110205.6878s
	iters: 200, epoch: 6 | loss: 0.0890369
	speed: 0.1240s/iter; left time: 8282.9836s
	iters: 300, epoch: 6 | loss: 0.0835939
	speed: 0.1260s/iter; left time: 8407.2603s
	iters: 400, epoch: 6 | loss: 0.0703793
	speed: 0.1282s/iter; left time: 8540.9462s
	iters: 500, epoch: 6 | loss: 0.0827197
	speed: 0.1267s/iter; left time: 8430.6563s
	iters: 600, epoch: 6 | loss: 0.0714470
	speed: 0.1202s/iter; left time: 7983.0282s
	iters: 700, epoch: 6 | loss: 0.0747727
	speed: 0.1253s/iter; left time: 8311.4229s
	iters: 800, epoch: 6 | loss: 0.0732784
	speed: 0.1237s/iter; left time: 8193.5322s
	iters: 900, epoch: 6 | loss: 0.0771534
	speed: 0.1245s/iter; left time: 8229.0321s
	iters: 1000, epoch: 6 | loss: 0.0741465
	speed: 0.1205s/iter; left time: 7956.5036s
	iters: 1100, epoch: 6 | loss: 0.0746656
	speed: 0.1213s/iter; left time: 7996.0624s
	iters: 1200, epoch: 6 | loss: 0.0931855
	speed: 0.1270s/iter; left time: 8360.6905s
	iters: 1300, epoch: 6 | loss: 0.0977927
	speed: 0.1267s/iter; left time: 8329.5985s
	iters: 1400, epoch: 6 | loss: 0.0876032
	speed: 0.1272s/iter; left time: 8346.7622s
	iters: 1500, epoch: 6 | loss: 0.0801408
	speed: 0.1260s/iter; left time: 8256.7073s
	iters: 1600, epoch: 6 | loss: 0.0721369
	speed: 0.1277s/iter; left time: 8353.4044s
	iters: 1700, epoch: 6 | loss: 0.0922342
	speed: 0.1279s/iter; left time: 8351.4377s
	iters: 1800, epoch: 6 | loss: 0.0814926
	speed: 0.1248s/iter; left time: 8138.1314s
	iters: 1900, epoch: 6 | loss: 0.0799462
	speed: 0.1195s/iter; left time: 7780.9491s
	iters: 2000, epoch: 6 | loss: 0.0895512
	speed: 0.1301s/iter; left time: 8456.1306s
	iters: 2100, epoch: 6 | loss: 0.0853165
	speed: 0.1288s/iter; left time: 8362.0493s
	iters: 2200, epoch: 6 | loss: 0.1018588
	speed: 0.1284s/iter; left time: 8322.9629s
	iters: 2300, epoch: 6 | loss: 0.0753619
	speed: 0.1235s/iter; left time: 7990.5506s
	iters: 2400, epoch: 6 | loss: 0.0675035
	speed: 0.1303s/iter; left time: 8418.4006s
	iters: 2500, epoch: 6 | loss: 0.0995846
	speed: 0.1285s/iter; left time: 8290.4280s
	iters: 2600, epoch: 6 | loss: 0.0759167
	speed: 0.1251s/iter; left time: 8059.7831s
	iters: 2700, epoch: 6 | loss: 0.0709326
	speed: 0.1229s/iter; left time: 7904.4154s
	iters: 2800, epoch: 6 | loss: 0.1127540
	speed: 0.1243s/iter; left time: 7985.0156s
	iters: 2900, epoch: 6 | loss: 0.0813409
	speed: 0.1256s/iter; left time: 8055.5400s
	iters: 3000, epoch: 6 | loss: 0.0786561
	speed: 0.1249s/iter; left time: 7995.1135s
	iters: 3100, epoch: 6 | loss: 0.0826245
	speed: 0.1231s/iter; left time: 7867.7223s
	iters: 3200, epoch: 6 | loss: 0.0986693
	speed: 0.1262s/iter; left time: 8053.2830s
	iters: 3300, epoch: 6 | loss: 0.0849674
	speed: 0.1282s/iter; left time: 8166.3516s
	iters: 3400, epoch: 6 | loss: 0.0744465
	speed: 0.1275s/iter; left time: 8113.8172s
	iters: 3500, epoch: 6 | loss: 0.0913548
	speed: 0.1244s/iter; left time: 7900.0867s
	iters: 3600, epoch: 6 | loss: 0.0656657
	speed: 0.1278s/iter; left time: 8105.7430s
	iters: 3700, epoch: 6 | loss: 0.0794955
	speed: 0.1291s/iter; left time: 8175.8079s
	iters: 3800, epoch: 6 | loss: 0.0760554
	speed: 0.1251s/iter; left time: 7911.0424s
	iters: 3900, epoch: 6 | loss: 0.0779494
	speed: 0.1106s/iter; left time: 6983.7378s
	iters: 4000, epoch: 6 | loss: 0.0917149
	speed: 0.1165s/iter; left time: 7339.0169s
	iters: 4100, epoch: 6 | loss: 0.0724742
	speed: 0.1165s/iter; left time: 7333.1419s
	iters: 4200, epoch: 6 | loss: 0.0769409
	speed: 0.1162s/iter; left time: 7299.6282s
	iters: 4300, epoch: 6 | loss: 0.0667945
	speed: 0.1145s/iter; left time: 7184.5724s
	iters: 4400, epoch: 6 | loss: 0.0704586
	speed: 0.1219s/iter; left time: 7630.4354s
Epoch: 6 cost time: 00h:09m:16.56s
Epoch: 6 | Train Loss: 0.0803718 Vali Loss: 0.0905898 Test Loss: 0.1044702
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0694771
	speed: 1.7982s/iter; left time: 112300.2155s
	iters: 200, epoch: 7 | loss: 0.0701124
	speed: 0.1209s/iter; left time: 7538.2893s
	iters: 300, epoch: 7 | loss: 0.0611065
	speed: 0.1209s/iter; left time: 7528.2949s
	iters: 400, epoch: 7 | loss: 0.0853083
	speed: 0.1209s/iter; left time: 7515.4190s
	iters: 500, epoch: 7 | loss: 0.0865817
	speed: 0.1206s/iter; left time: 7480.9827s
	iters: 600, epoch: 7 | loss: 0.0731895
	speed: 0.1207s/iter; left time: 7474.7410s
	iters: 700, epoch: 7 | loss: 0.1010686
	speed: 0.1211s/iter; left time: 7489.8926s
	iters: 800, epoch: 7 | loss: 0.0807473
	speed: 0.1215s/iter; left time: 7500.0067s
	iters: 900, epoch: 7 | loss: 0.0729549
	speed: 0.1211s/iter; left time: 7467.4319s
	iters: 1000, epoch: 7 | loss: 0.0784136
	speed: 0.1209s/iter; left time: 7440.1999s
	iters: 1100, epoch: 7 | loss: 0.0915089
	speed: 0.1163s/iter; left time: 7145.1830s
	iters: 1200, epoch: 7 | loss: 0.0813137
	speed: 0.1210s/iter; left time: 7424.2265s
	iters: 1300, epoch: 7 | loss: 0.0710811
	speed: 0.1213s/iter; left time: 7431.4419s
	iters: 1400, epoch: 7 | loss: 0.0674738
	speed: 0.1212s/iter; left time: 7412.9268s
	iters: 1500, epoch: 7 | loss: 0.0731219
	speed: 0.1209s/iter; left time: 7378.7334s
	iters: 1600, epoch: 7 | loss: 0.0795863
	speed: 0.1209s/iter; left time: 7366.8095s
	iters: 1700, epoch: 7 | loss: 0.0768837
	speed: 0.1152s/iter; left time: 7009.1558s
	iters: 1800, epoch: 7 | loss: 0.0973881
	speed: 0.1211s/iter; left time: 7358.9135s
	iters: 1900, epoch: 7 | loss: 0.0784142
	speed: 0.1210s/iter; left time: 7336.4699s
	iters: 2000, epoch: 7 | loss: 0.0736109
	speed: 0.1209s/iter; left time: 7321.6983s
	iters: 2100, epoch: 7 | loss: 0.0847631
	speed: 0.1210s/iter; left time: 7316.8136s
	iters: 2200, epoch: 7 | loss: 0.0700621
	speed: 0.1212s/iter; left time: 7314.8792s
	iters: 2300, epoch: 7 | loss: 0.0826743
	speed: 0.1100s/iter; left time: 6625.1468s
	iters: 2400, epoch: 7 | loss: 0.0855349
	speed: 0.1199s/iter; left time: 7213.0936s
	iters: 2500, epoch: 7 | loss: 0.0894471
	speed: 0.1207s/iter; left time: 7249.1864s
	iters: 2600, epoch: 7 | loss: 0.0709336
	speed: 0.1206s/iter; left time: 7231.8714s
	iters: 2700, epoch: 7 | loss: 0.0635979
	speed: 0.1209s/iter; left time: 7236.3565s
	iters: 2800, epoch: 7 | loss: 0.0727365
	speed: 0.1204s/iter; left time: 7192.1700s
	iters: 2900, epoch: 7 | loss: 0.0891747
	speed: 0.1210s/iter; left time: 7219.6751s
	iters: 3000, epoch: 7 | loss: 0.0914883
	speed: 0.1206s/iter; left time: 7180.0788s
	iters: 3100, epoch: 7 | loss: 0.0926042
	speed: 0.1197s/iter; left time: 7118.3800s
	iters: 3200, epoch: 7 | loss: 0.0622337
	speed: 0.1205s/iter; left time: 7150.8150s
	iters: 3300, epoch: 7 | loss: 0.0735094
	speed: 0.1214s/iter; left time: 7194.1479s
	iters: 3400, epoch: 7 | loss: 0.0951522
	speed: 0.1210s/iter; left time: 7156.0428s
	iters: 3500, epoch: 7 | loss: 0.0720976
	speed: 0.1208s/iter; left time: 7133.6626s
	iters: 3600, epoch: 7 | loss: 0.0690883
	speed: 0.1202s/iter; left time: 7087.2836s
	iters: 3700, epoch: 7 | loss: 0.0841284
	speed: 0.1194s/iter; left time: 7028.5145s
	iters: 3800, epoch: 7 | loss: 0.0866462
	speed: 0.1210s/iter; left time: 7109.4341s
	iters: 3900, epoch: 7 | loss: 0.0677450
	speed: 0.1198s/iter; left time: 7026.1268s
	iters: 4000, epoch: 7 | loss: 0.0808895
	speed: 0.1212s/iter; left time: 7093.7075s
	iters: 4100, epoch: 7 | loss: 0.0839261
	speed: 0.1209s/iter; left time: 7067.3073s
	iters: 4200, epoch: 7 | loss: 0.0723493
	speed: 0.1192s/iter; left time: 6955.4562s
	iters: 4300, epoch: 7 | loss: 0.0775747
	speed: 0.1204s/iter; left time: 7015.1342s
	iters: 4400, epoch: 7 | loss: 0.0767770
	speed: 0.1201s/iter; left time: 6985.1360s
Epoch: 7 cost time: 00h:08m:58.02s
Epoch: 7 | Train Loss: 0.0794193 Vali Loss: 0.0901961 Test Loss: 0.1045509
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0895511
	speed: 1.5212s/iter; left time: 88207.1003s
	iters: 200, epoch: 8 | loss: 0.0866904
	speed: 0.1204s/iter; left time: 6970.8545s
	iters: 300, epoch: 8 | loss: 0.0797954
	speed: 0.1215s/iter; left time: 7018.0655s
	iters: 400, epoch: 8 | loss: 0.0820298
	speed: 0.1207s/iter; left time: 6963.7742s
	iters: 500, epoch: 8 | loss: 0.0783670
	speed: 0.1217s/iter; left time: 7005.3954s
	iters: 600, epoch: 8 | loss: 0.0902877
	speed: 0.1212s/iter; left time: 6966.0031s
	iters: 700, epoch: 8 | loss: 0.0648628
	speed: 0.1219s/iter; left time: 6994.9089s
	iters: 800, epoch: 8 | loss: 0.0814682
	speed: 0.1212s/iter; left time: 6945.0145s
	iters: 900, epoch: 8 | loss: 0.0808761
	speed: 0.1215s/iter; left time: 6947.2596s
	iters: 1000, epoch: 8 | loss: 0.0752130
	speed: 0.1207s/iter; left time: 6890.7967s
	iters: 1100, epoch: 8 | loss: 0.0748815
	speed: 0.1198s/iter; left time: 6826.0007s
	iters: 1200, epoch: 8 | loss: 0.0795547
	speed: 0.1193s/iter; left time: 6787.2986s
	iters: 1300, epoch: 8 | loss: 0.0994396
	speed: 0.1217s/iter; left time: 6912.5380s
	iters: 1400, epoch: 8 | loss: 0.0792517
	speed: 0.1210s/iter; left time: 6860.9223s
	iters: 1500, epoch: 8 | loss: 0.0784374
	speed: 0.1215s/iter; left time: 6875.3035s
	iters: 1600, epoch: 8 | loss: 0.0859944
	speed: 0.1213s/iter; left time: 6854.1435s
	iters: 1700, epoch: 8 | loss: 0.0819602
	speed: 0.1210s/iter; left time: 6823.7614s
	iters: 1800, epoch: 8 | loss: 0.0977695
	speed: 0.1209s/iter; left time: 6806.1989s
	iters: 1900, epoch: 8 | loss: 0.0645730
	speed: 0.1204s/iter; left time: 6765.9107s
	iters: 2000, epoch: 8 | loss: 0.0558155
	speed: 0.1209s/iter; left time: 6781.5572s
	iters: 2100, epoch: 8 | loss: 0.0748824
	speed: 0.1208s/iter; left time: 6763.3492s
	iters: 2200, epoch: 8 | loss: 0.0751968
	speed: 0.1212s/iter; left time: 6773.9601s
	iters: 2300, epoch: 8 | loss: 0.0775747
	speed: 0.1210s/iter; left time: 6750.0608s
	iters: 2400, epoch: 8 | loss: 0.0743494
	speed: 0.1207s/iter; left time: 6723.3804s
	iters: 2500, epoch: 8 | loss: 0.0847968
	speed: 0.1211s/iter; left time: 6728.9237s
	iters: 2600, epoch: 8 | loss: 0.0757934
	speed: 0.1209s/iter; left time: 6707.4027s
	iters: 2700, epoch: 8 | loss: 0.0962444
	speed: 0.1205s/iter; left time: 6676.6244s
	iters: 2800, epoch: 8 | loss: 0.0798034
	speed: 0.1213s/iter; left time: 6704.1033s
	iters: 2900, epoch: 8 | loss: 0.0616579
	speed: 0.1204s/iter; left time: 6643.6597s
	iters: 3000, epoch: 8 | loss: 0.0749053
	speed: 0.1200s/iter; left time: 6610.7084s
	iters: 3100, epoch: 8 | loss: 0.0779971
	speed: 0.1204s/iter; left time: 6618.3640s
	iters: 3200, epoch: 8 | loss: 0.0703546
	speed: 0.1613s/iter; left time: 8852.6133s
	iters: 3300, epoch: 8 | loss: 0.0924814
	speed: 0.1661s/iter; left time: 9102.5012s
	iters: 3400, epoch: 8 | loss: 0.0760914
	speed: 0.1659s/iter; left time: 9073.4357s
	iters: 3500, epoch: 8 | loss: 0.0540513
	speed: 0.1661s/iter; left time: 9068.4956s
	iters: 3600, epoch: 8 | loss: 0.0791183
	speed: 0.1644s/iter; left time: 8957.7017s
	iters: 3700, epoch: 8 | loss: 0.0715009
	speed: 0.1651s/iter; left time: 8978.4116s
	iters: 3800, epoch: 8 | loss: 0.0779355
	speed: 0.1633s/iter; left time: 8865.3051s
	iters: 3900, epoch: 8 | loss: 0.0706417
	speed: 0.1629s/iter; left time: 8825.7888s
	iters: 4000, epoch: 8 | loss: 0.0706924
	speed: 0.1641s/iter; left time: 8873.0921s
	iters: 4100, epoch: 8 | loss: 0.0704471
	speed: 0.1785s/iter; left time: 9634.0532s
	iters: 4200, epoch: 8 | loss: 0.0729290
	speed: 0.2067s/iter; left time: 11136.7974s
	iters: 4300, epoch: 8 | loss: 0.0735274
	speed: 0.1271s/iter; left time: 6834.2211s
	iters: 4400, epoch: 8 | loss: 0.0819775
	speed: 0.1223s/iter; left time: 6564.5279s
Epoch: 8 cost time: 00h:09m:55.42s
Epoch: 8 | Train Loss: 0.0784829 Vali Loss: 0.0906655 Test Loss: 0.1073768
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0807247
	speed: 1.5940s/iter; left time: 85304.2874s
	iters: 200, epoch: 9 | loss: 0.0876306
	speed: 0.1179s/iter; left time: 6300.3524s
	iters: 300, epoch: 9 | loss: 0.0690702
	speed: 0.1253s/iter; left time: 6681.5234s
	iters: 400, epoch: 9 | loss: 0.0685977
	speed: 0.1225s/iter; left time: 6521.2911s
	iters: 500, epoch: 9 | loss: 0.1049898
	speed: 0.1206s/iter; left time: 6404.2369s
	iters: 600, epoch: 9 | loss: 0.0862811
	speed: 0.1230s/iter; left time: 6522.3767s
	iters: 700, epoch: 9 | loss: 0.0700331
	speed: 0.1261s/iter; left time: 6673.5633s
	iters: 800, epoch: 9 | loss: 0.0694490
	speed: 0.1274s/iter; left time: 6728.0138s
	iters: 900, epoch: 9 | loss: 0.0769776
	speed: 0.1298s/iter; left time: 6845.0558s
	iters: 1000, epoch: 9 | loss: 0.0690558
	speed: 0.1256s/iter; left time: 6607.6701s
	iters: 1100, epoch: 9 | loss: 0.0718805
	speed: 0.1291s/iter; left time: 6781.6749s
	iters: 1200, epoch: 9 | loss: 0.0790950
	speed: 0.1299s/iter; left time: 6807.3502s
	iters: 1300, epoch: 9 | loss: 0.0878323
	speed: 0.1274s/iter; left time: 6665.4423s
	iters: 1400, epoch: 9 | loss: 0.0601362
	speed: 0.1173s/iter; left time: 6126.5728s
	iters: 1500, epoch: 9 | loss: 0.0813463
	speed: 0.1201s/iter; left time: 6260.5145s
	iters: 1600, epoch: 9 | loss: 0.0808004
	speed: 0.1260s/iter; left time: 6554.7038s
	iters: 1700, epoch: 9 | loss: 0.0846742
	speed: 0.1268s/iter; left time: 6582.9410s
	iters: 1800, epoch: 9 | loss: 0.0694577
	speed: 0.1111s/iter; left time: 5758.8993s
	iters: 1900, epoch: 9 | loss: 0.0717922
	speed: 0.1279s/iter; left time: 6613.0082s
	iters: 2000, epoch: 9 | loss: 0.0688320
	speed: 0.1304s/iter; left time: 6728.5997s
	iters: 2100, epoch: 9 | loss: 0.0924541
	speed: 0.1244s/iter; left time: 6409.6553s
	iters: 2200, epoch: 9 | loss: 0.0821416
	speed: 0.1162s/iter; left time: 5974.0566s
	iters: 2300, epoch: 9 | loss: 0.0760271
	speed: 0.1305s/iter; left time: 6696.3125s
	iters: 2400, epoch: 9 | loss: 0.0767931
	speed: 0.1291s/iter; left time: 6614.2296s
	iters: 2500, epoch: 9 | loss: 0.0697705
	speed: 0.1180s/iter; left time: 6030.9660s
	iters: 2600, epoch: 9 | loss: 0.0924100
	speed: 0.1255s/iter; left time: 6402.4300s
	iters: 2700, epoch: 9 | loss: 0.0637605
	speed: 0.1300s/iter; left time: 6616.9880s
	iters: 2800, epoch: 9 | loss: 0.0797227
	speed: 0.1213s/iter; left time: 6161.8290s
	iters: 2900, epoch: 9 | loss: 0.0813500
	speed: 0.1302s/iter; left time: 6602.2529s
	iters: 3000, epoch: 9 | loss: 0.0780612
	speed: 0.1283s/iter; left time: 6494.6933s
	iters: 3100, epoch: 9 | loss: 0.0720700
	speed: 0.1147s/iter; left time: 5795.3900s
	iters: 3200, epoch: 9 | loss: 0.0765664
	speed: 0.1155s/iter; left time: 5822.8621s
	iters: 3300, epoch: 9 | loss: 0.0852109
	speed: 0.1283s/iter; left time: 6456.4421s
	iters: 3400, epoch: 9 | loss: 0.0872862
	speed: 0.1218s/iter; left time: 6118.5373s
	iters: 3500, epoch: 9 | loss: 0.0673751
	speed: 0.1239s/iter; left time: 6209.2619s
	iters: 3600, epoch: 9 | loss: 0.0731839
	speed: 0.1135s/iter; left time: 5679.0106s
	iters: 3700, epoch: 9 | loss: 0.0864574
	speed: 0.1150s/iter; left time: 5742.7550s
	iters: 3800, epoch: 9 | loss: 0.0817628
	speed: 0.1164s/iter; left time: 5796.6027s
	iters: 3900, epoch: 9 | loss: 0.0986147
	speed: 0.1272s/iter; left time: 6324.3863s
	iters: 4000, epoch: 9 | loss: 0.0703890
	speed: 0.1221s/iter; left time: 6059.2363s
	iters: 4100, epoch: 9 | loss: 0.0744173
	speed: 0.1171s/iter; left time: 5796.8956s
	iters: 4200, epoch: 9 | loss: 0.0785395
	speed: 0.1130s/iter; left time: 5583.3218s
	iters: 4300, epoch: 9 | loss: 0.0744364
	speed: 0.1254s/iter; left time: 6184.5594s
	iters: 4400, epoch: 9 | loss: 0.0595877
	speed: 0.1156s/iter; left time: 5688.7236s
Epoch: 9 cost time: 00h:09m:09.99s
Epoch: 9 | Train Loss: 0.0773867 Vali Loss: 0.0910278 Test Loss: 0.1069496
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0671151
	speed: 1.5389s/iter; left time: 75480.2256s
	iters: 200, epoch: 10 | loss: 0.0828441
	speed: 0.1204s/iter; left time: 5895.5535s
	iters: 300, epoch: 10 | loss: 0.0783897
	speed: 0.1096s/iter; left time: 5353.1622s
	iters: 400, epoch: 10 | loss: 0.0834453
	speed: 0.1255s/iter; left time: 6120.1368s
	iters: 500, epoch: 10 | loss: 0.0739451
	speed: 0.1267s/iter; left time: 6162.5482s
	iters: 600, epoch: 10 | loss: 0.0635547
	speed: 0.1131s/iter; left time: 5489.5249s
	iters: 700, epoch: 10 | loss: 0.0789368
	speed: 0.1179s/iter; left time: 5712.6613s
	iters: 800, epoch: 10 | loss: 0.0980061
	speed: 0.1237s/iter; left time: 5980.6908s
	iters: 900, epoch: 10 | loss: 0.0827744
	speed: 0.1120s/iter; left time: 5401.5866s
	iters: 1000, epoch: 10 | loss: 0.0858516
	speed: 0.1206s/iter; left time: 5808.9077s
	iters: 1100, epoch: 10 | loss: 0.0609591
	speed: 0.1193s/iter; left time: 5732.8090s
	iters: 1200, epoch: 10 | loss: 0.0810569
	speed: 0.1074s/iter; left time: 5149.8732s
	iters: 1300, epoch: 10 | loss: 0.0937729
	speed: 0.1254s/iter; left time: 5999.7811s
	iters: 1400, epoch: 10 | loss: 0.0835219
	speed: 0.1246s/iter; left time: 5950.7140s
	iters: 1500, epoch: 10 | loss: 0.0743610
	speed: 0.1144s/iter; left time: 5450.3609s
	iters: 1600, epoch: 10 | loss: 0.0712053
	speed: 0.1164s/iter; left time: 5534.1431s
	iters: 1700, epoch: 10 | loss: 0.0691880
	speed: 0.1250s/iter; left time: 5929.3824s
	iters: 1800, epoch: 10 | loss: 0.0734778
	speed: 0.1118s/iter; left time: 5292.0153s
	iters: 1900, epoch: 10 | loss: 0.0740059
	speed: 0.1257s/iter; left time: 5939.9027s
	iters: 2000, epoch: 10 | loss: 0.0803476
	speed: 0.1137s/iter; left time: 5360.6308s
	iters: 2100, epoch: 10 | loss: 0.0573778
	speed: 0.1160s/iter; left time: 5459.6980s
	iters: 2200, epoch: 10 | loss: 0.0633182
	speed: 0.1258s/iter; left time: 5905.7278s
	iters: 2300, epoch: 10 | loss: 0.0607398
	speed: 0.1252s/iter; left time: 5867.4105s
	iters: 2400, epoch: 10 | loss: 0.0995448
	speed: 0.1049s/iter; left time: 4903.4606s
	iters: 2500, epoch: 10 | loss: 0.0664814
	speed: 0.1198s/iter; left time: 5586.6849s
	iters: 2600, epoch: 10 | loss: 0.0725956
	speed: 0.1246s/iter; left time: 5800.8275s
	iters: 2700, epoch: 10 | loss: 0.0891252
	speed: 0.1145s/iter; left time: 5319.7502s
	iters: 2800, epoch: 10 | loss: 0.0708456
	speed: 0.1203s/iter; left time: 5574.2059s
	iters: 2900, epoch: 10 | loss: 0.0679720
	speed: 0.1191s/iter; left time: 5508.8572s
	iters: 3000, epoch: 10 | loss: 0.0656617
	speed: 0.1145s/iter; left time: 5284.7287s
	iters: 3100, epoch: 10 | loss: 0.0661887
	speed: 0.1271s/iter; left time: 5854.3015s
	iters: 3200, epoch: 10 | loss: 0.0758295
	speed: 0.1172s/iter; left time: 5387.0060s
	iters: 3300, epoch: 10 | loss: 0.0698776
	speed: 0.1091s/iter; left time: 5002.7150s
	iters: 3400, epoch: 10 | loss: 0.0789215
	speed: 0.1250s/iter; left time: 5719.3431s
	iters: 3500, epoch: 10 | loss: 0.0749588
	speed: 0.1241s/iter; left time: 5664.3148s
	iters: 3600, epoch: 10 | loss: 0.1019792
	speed: 0.1162s/iter; left time: 5292.5549s
	iters: 3700, epoch: 10 | loss: 0.0910538
	speed: 0.1122s/iter; left time: 5100.5829s
	iters: 3800, epoch: 10 | loss: 0.0882741
	speed: 0.1146s/iter; left time: 5196.1296s
	iters: 3900, epoch: 10 | loss: 0.0684295
	speed: 0.1176s/iter; left time: 5319.9542s
	iters: 4000, epoch: 10 | loss: 0.0834578
	speed: 0.1258s/iter; left time: 5678.2564s
	iters: 4100, epoch: 10 | loss: 0.0795520
	speed: 0.1127s/iter; left time: 5077.6624s
	iters: 4200, epoch: 10 | loss: 0.0775932
	speed: 0.1112s/iter; left time: 4997.2488s
	iters: 4300, epoch: 10 | loss: 0.0749520
	speed: 0.1146s/iter; left time: 5138.2708s
	iters: 4400, epoch: 10 | loss: 0.0773880
	speed: 0.1211s/iter; left time: 5417.2335s
Epoch: 10 cost time: 00h:08m:49.31s
Epoch: 10 | Train Loss: 0.0764753 Vali Loss: 0.0915059 Test Loss: 0.1088750
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.025583267211914062, rmse:0.1599477082490921, mae:0.10403311252593994, rse:0.5514940619468689
success delete checkpoints
Intermediate time for GB and pred_len 24: 02h:01m:51.92s


=== Starting experiments for pred_len: 96 ===

train 142645
val 30725
test 30725
[2024-11-01 03:15:39,128] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 03:15:40,279] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 03:15:40,280] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 03:15:40,280] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 03:15:40,382] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 03:15:40,382] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 03:15:41,057] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 03:15:41,059] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 03:15:41,059] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 03:15:41,061] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 03:15:41,061] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 03:15:41,061] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 03:15:41,061] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 03:15:41,061] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 03:15:41,061] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 03:15:41,061] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 03:15:41,369] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 03:15:41,370] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 03:15:41,370] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 94.66 GB, percent = 12.5%
[2024-11-01 03:15:41,486] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 03:15:41,487] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 03:15:41,488] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 94.66 GB, percent = 12.5%
[2024-11-01 03:15:41,488] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 03:15:41,599] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 03:15:41,600] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 03:15:41,600] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 94.67 GB, percent = 12.5%
[2024-11-01 03:15:41,601] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 03:15:41,601] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 03:15:41,601] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 03:15:41,601] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 03:15:41,602] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 03:15:41,602] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f82fbfd9390>
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 03:15:41,603] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 03:15:41,604] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 03:15:41,605] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 03:15:41,605] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1688266
	speed: 0.1575s/iter; left time: 14027.7250s
	iters: 200, epoch: 1 | loss: 0.1466758
	speed: 0.1311s/iter; left time: 11661.9554s
	iters: 300, epoch: 1 | loss: 0.1657802
	speed: 0.1262s/iter; left time: 11207.3371s
	iters: 400, epoch: 1 | loss: 0.1365485
	speed: 0.1167s/iter; left time: 10354.2093s
	iters: 500, epoch: 1 | loss: 0.1343239
	speed: 0.1302s/iter; left time: 11544.6879s
	iters: 600, epoch: 1 | loss: 0.1273262
	speed: 0.1200s/iter; left time: 10623.4214s
	iters: 700, epoch: 1 | loss: 0.1142251
	speed: 0.1274s/iter; left time: 11268.7681s
	iters: 800, epoch: 1 | loss: 0.1129106
	speed: 0.1305s/iter; left time: 11527.7212s
	iters: 900, epoch: 1 | loss: 0.1081580
	speed: 0.1186s/iter; left time: 10464.9944s
	iters: 1000, epoch: 1 | loss: 0.1082976
	speed: 0.1309s/iter; left time: 11535.9366s
	iters: 1100, epoch: 1 | loss: 0.1104180
	speed: 0.1225s/iter; left time: 10788.7691s
	iters: 1200, epoch: 1 | loss: 0.1293156
	speed: 0.1270s/iter; left time: 11165.4803s
	iters: 1300, epoch: 1 | loss: 0.1199676
	speed: 0.1310s/iter; left time: 11503.7325s
	iters: 1400, epoch: 1 | loss: 0.0853492
	speed: 0.1188s/iter; left time: 10422.3720s
	iters: 1500, epoch: 1 | loss: 0.1185155
	speed: 0.1312s/iter; left time: 11494.4435s
	iters: 1600, epoch: 1 | loss: 0.1091379
	speed: 0.1228s/iter; left time: 10747.2676s
	iters: 1700, epoch: 1 | loss: 0.1387339
	speed: 0.1318s/iter; left time: 11527.8781s
	iters: 1800, epoch: 1 | loss: 0.1115096
	speed: 0.1271s/iter; left time: 11097.5765s
	iters: 1900, epoch: 1 | loss: 0.1182949
	speed: 0.1220s/iter; left time: 10647.1327s
	iters: 2000, epoch: 1 | loss: 0.1110286
	speed: 0.1310s/iter; left time: 11412.6244s
	iters: 2100, epoch: 1 | loss: 0.1118804
	speed: 0.1251s/iter; left time: 10885.5706s
	iters: 2200, epoch: 1 | loss: 0.1165919
	speed: 0.1309s/iter; left time: 11377.4827s
	iters: 2300, epoch: 1 | loss: 0.1117706
	speed: 0.1196s/iter; left time: 10384.6279s
	iters: 2400, epoch: 1 | loss: 0.1129438
	speed: 0.1147s/iter; left time: 9951.7706s
	iters: 2500, epoch: 1 | loss: 0.1135126
	speed: 0.1151s/iter; left time: 9968.6266s
	iters: 2600, epoch: 1 | loss: 0.1112166
	speed: 0.1302s/iter; left time: 11265.9500s
	iters: 2700, epoch: 1 | loss: 0.1203404
	speed: 0.1311s/iter; left time: 11335.0066s
	iters: 2800, epoch: 1 | loss: 0.1182374
	speed: 0.1301s/iter; left time: 11235.6324s
	iters: 2900, epoch: 1 | loss: 0.1069434
	speed: 0.1311s/iter; left time: 11305.8249s
	iters: 3000, epoch: 1 | loss: 0.1128676
	speed: 0.1308s/iter; left time: 11267.1700s
	iters: 3100, epoch: 1 | loss: 0.1112418
	speed: 0.1273s/iter; left time: 10948.9477s
	iters: 3200, epoch: 1 | loss: 0.1109535
	speed: 0.1203s/iter; left time: 10337.3559s
	iters: 3300, epoch: 1 | loss: 0.1022410
	speed: 0.1307s/iter; left time: 11217.8769s
	iters: 3400, epoch: 1 | loss: 0.1067109
	speed: 0.1301s/iter; left time: 11151.0671s
	iters: 3500, epoch: 1 | loss: 0.1093592
	speed: 0.1305s/iter; left time: 11176.0767s
	iters: 3600, epoch: 1 | loss: 0.1050644
	speed: 0.1239s/iter; left time: 10595.1182s
	iters: 3700, epoch: 1 | loss: 0.1453399
	speed: 0.1148s/iter; left time: 9809.7097s
	iters: 3800, epoch: 1 | loss: 0.1064153
	speed: 0.1129s/iter; left time: 9631.0546s
	iters: 3900, epoch: 1 | loss: 0.1275871
	speed: 0.1254s/iter; left time: 10689.2496s
	iters: 4000, epoch: 1 | loss: 0.1056856
	speed: 0.1307s/iter; left time: 11127.3856s
	iters: 4100, epoch: 1 | loss: 0.1163018
	speed: 0.1308s/iter; left time: 11127.0224s
	iters: 4200, epoch: 1 | loss: 0.1195716
	speed: 0.1308s/iter; left time: 11107.5034s
	iters: 4300, epoch: 1 | loss: 0.1011549
	speed: 0.1305s/iter; left time: 11070.0554s
	iters: 4400, epoch: 1 | loss: 0.1301714
	speed: 0.1309s/iter; left time: 11092.3154s
Epoch: 1 cost time: 00h:09m:22.60s
Epoch: 1 | Train Loss: 0.1159376 Vali Loss: 0.1171800 Test Loss: 0.1386980
Validation loss decreased (inf --> 0.117180).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1323460
	speed: 1.7094s/iter; left time: 144586.5191s
	iters: 200, epoch: 2 | loss: 0.0998212
	speed: 0.1195s/iter; left time: 10095.7532s
	iters: 300, epoch: 2 | loss: 0.1072860
	speed: 0.1192s/iter; left time: 10055.0768s
	iters: 400, epoch: 2 | loss: 0.1047579
	speed: 0.1188s/iter; left time: 10015.5315s
	iters: 500, epoch: 2 | loss: 0.0988569
	speed: 0.1134s/iter; left time: 9544.0556s
	iters: 600, epoch: 2 | loss: 0.1400726
	speed: 0.1184s/iter; left time: 9956.6535s
	iters: 700, epoch: 2 | loss: 0.1279359
	speed: 0.1191s/iter; left time: 9998.9267s
	iters: 800, epoch: 2 | loss: 0.1120330
	speed: 0.1184s/iter; left time: 9932.6729s
	iters: 900, epoch: 2 | loss: 0.1051929
	speed: 0.1191s/iter; left time: 9979.4613s
	iters: 1000, epoch: 2 | loss: 0.1209462
	speed: 0.1189s/iter; left time: 9950.7809s
	iters: 1100, epoch: 2 | loss: 0.1275426
	speed: 0.1189s/iter; left time: 9941.4127s
	iters: 1200, epoch: 2 | loss: 0.1159983
	speed: 0.1199s/iter; left time: 10010.0811s
	iters: 1300, epoch: 2 | loss: 0.1053278
	speed: 0.1180s/iter; left time: 9838.4378s
	iters: 1400, epoch: 2 | loss: 0.0974504
	speed: 0.1190s/iter; left time: 9912.5643s
	iters: 1500, epoch: 2 | loss: 0.0961491
	speed: 0.1184s/iter; left time: 9850.9704s
	iters: 1600, epoch: 2 | loss: 0.1127011
	speed: 0.1177s/iter; left time: 9781.9858s
	iters: 1700, epoch: 2 | loss: 0.1136763
	speed: 0.1191s/iter; left time: 9883.4609s
	iters: 1800, epoch: 2 | loss: 0.1032368
	speed: 0.1201s/iter; left time: 9958.1969s
	iters: 1900, epoch: 2 | loss: 0.0907084
	speed: 0.1094s/iter; left time: 9058.9709s
	iters: 2000, epoch: 2 | loss: 0.1084257
	speed: 0.1198s/iter; left time: 9908.8980s
	iters: 2100, epoch: 2 | loss: 0.1318485
	speed: 0.1198s/iter; left time: 9891.9861s
	iters: 2200, epoch: 2 | loss: 0.1092268
	speed: 0.1192s/iter; left time: 9831.4260s
	iters: 2300, epoch: 2 | loss: 0.0971450
	speed: 0.1203s/iter; left time: 9909.0084s
	iters: 2400, epoch: 2 | loss: 0.1082254
	speed: 0.1206s/iter; left time: 9920.9096s
	iters: 2500, epoch: 2 | loss: 0.1057774
	speed: 0.1203s/iter; left time: 9883.1622s
	iters: 2600, epoch: 2 | loss: 0.1233867
	speed: 0.1204s/iter; left time: 9881.9210s
	iters: 2700, epoch: 2 | loss: 0.1121541
	speed: 0.1193s/iter; left time: 9781.9166s
	iters: 2800, epoch: 2 | loss: 0.1023491
	speed: 0.1193s/iter; left time: 9767.0038s
	iters: 2900, epoch: 2 | loss: 0.1325897
	speed: 0.1192s/iter; left time: 9749.1633s
	iters: 3000, epoch: 2 | loss: 0.0932151
	speed: 0.1208s/iter; left time: 9868.1327s
	iters: 3100, epoch: 2 | loss: 0.1183982
	speed: 0.1206s/iter; left time: 9840.5462s
	iters: 3200, epoch: 2 | loss: 0.1071068
	speed: 0.1188s/iter; left time: 9681.4000s
	iters: 3300, epoch: 2 | loss: 0.0916324
	speed: 0.1203s/iter; left time: 9793.1775s
	iters: 3400, epoch: 2 | loss: 0.0934265
	speed: 0.1191s/iter; left time: 9682.0646s
	iters: 3500, epoch: 2 | loss: 0.1121869
	speed: 0.1198s/iter; left time: 9726.2179s
	iters: 3600, epoch: 2 | loss: 0.1178536
	speed: 0.1197s/iter; left time: 9706.3992s
	iters: 3700, epoch: 2 | loss: 0.1048463
	speed: 0.1175s/iter; left time: 9513.6224s
	iters: 3800, epoch: 2 | loss: 0.1119690
	speed: 0.1202s/iter; left time: 9722.2820s
	iters: 3900, epoch: 2 | loss: 0.1302823
	speed: 0.1197s/iter; left time: 9666.3038s
	iters: 4000, epoch: 2 | loss: 0.1027673
	speed: 0.1209s/iter; left time: 9753.9588s
	iters: 4100, epoch: 2 | loss: 0.1058483
	speed: 0.1199s/iter; left time: 9659.0734s
	iters: 4200, epoch: 2 | loss: 0.1003960
	speed: 0.1182s/iter; left time: 9511.6928s
	iters: 4300, epoch: 2 | loss: 0.0997679
	speed: 0.1432s/iter; left time: 11511.5047s
	iters: 4400, epoch: 2 | loss: 0.1080339
	speed: 0.1341s/iter; left time: 10766.9849s
Epoch: 2 cost time: 00h:08m:54.86s
Epoch: 2 | Train Loss: 0.1063434 Vali Loss: 0.1159233 Test Loss: 0.1404574
Validation loss decreased (0.117180 --> 0.115923).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0953313
	speed: 1.4749s/iter; left time: 118179.3408s
	iters: 200, epoch: 3 | loss: 0.0960641
	speed: 0.1141s/iter; left time: 9134.8983s
	iters: 300, epoch: 3 | loss: 0.1168496
	speed: 0.1184s/iter; left time: 9462.1697s
	iters: 400, epoch: 3 | loss: 0.1128009
	speed: 0.1200s/iter; left time: 9581.9245s
	iters: 500, epoch: 3 | loss: 0.1003084
	speed: 0.1202s/iter; left time: 9583.5408s
	iters: 600, epoch: 3 | loss: 0.1153115
	speed: 0.1191s/iter; left time: 9484.1723s
	iters: 700, epoch: 3 | loss: 0.1167073
	speed: 0.1201s/iter; left time: 9553.4735s
	iters: 800, epoch: 3 | loss: 0.1098146
	speed: 0.1201s/iter; left time: 9539.8277s
	iters: 900, epoch: 3 | loss: 0.0888241
	speed: 0.1194s/iter; left time: 9472.3830s
	iters: 1000, epoch: 3 | loss: 0.0963814
	speed: 0.1203s/iter; left time: 9529.0400s
	iters: 1100, epoch: 3 | loss: 0.1247230
	speed: 0.1189s/iter; left time: 9410.9381s
	iters: 1200, epoch: 3 | loss: 0.1112344
	speed: 0.1206s/iter; left time: 9531.5513s
	iters: 1300, epoch: 3 | loss: 0.1090816
	speed: 0.1180s/iter; left time: 9314.3980s
	iters: 1400, epoch: 3 | loss: 0.1014220
	speed: 0.1165s/iter; left time: 9180.6156s
	iters: 1500, epoch: 3 | loss: 0.1205137
	speed: 0.1189s/iter; left time: 9362.2127s
	iters: 1600, epoch: 3 | loss: 0.0969793
	speed: 0.1195s/iter; left time: 9392.4116s
	iters: 1700, epoch: 3 | loss: 0.1139035
	speed: 0.1185s/iter; left time: 9307.1855s
	iters: 1800, epoch: 3 | loss: 0.1128580
	speed: 0.1196s/iter; left time: 9382.3632s
	iters: 1900, epoch: 3 | loss: 0.1043471
	speed: 0.1200s/iter; left time: 9395.4582s
	iters: 2000, epoch: 3 | loss: 0.0987270
	speed: 0.1203s/iter; left time: 9409.0469s
	iters: 2100, epoch: 3 | loss: 0.0881278
	speed: 0.1206s/iter; left time: 9423.5255s
	iters: 2200, epoch: 3 | loss: 0.1081288
	speed: 0.1207s/iter; left time: 9418.0676s
	iters: 2300, epoch: 3 | loss: 0.0976076
	speed: 0.1191s/iter; left time: 9283.4718s
	iters: 2400, epoch: 3 | loss: 0.0961220
	speed: 0.1199s/iter; left time: 9331.3736s
	iters: 2500, epoch: 3 | loss: 0.0965293
	speed: 0.1174s/iter; left time: 9122.0139s
	iters: 2600, epoch: 3 | loss: 0.1095369
	speed: 0.1161s/iter; left time: 9015.4675s
	iters: 2700, epoch: 3 | loss: 0.1212904
	speed: 0.1127s/iter; left time: 8739.1714s
	iters: 2800, epoch: 3 | loss: 0.1003948
	speed: 0.1206s/iter; left time: 9338.7340s
	iters: 2900, epoch: 3 | loss: 0.1081474
	speed: 0.1042s/iter; left time: 8061.2092s
	iters: 3000, epoch: 3 | loss: 0.1015081
	speed: 0.1070s/iter; left time: 8264.3555s
	iters: 3100, epoch: 3 | loss: 0.0989254
	speed: 0.1555s/iter; left time: 11992.9539s
	iters: 3200, epoch: 3 | loss: 0.1039556
	speed: 0.1541s/iter; left time: 11869.2753s
	iters: 3300, epoch: 3 | loss: 0.0903572
	speed: 0.1196s/iter; left time: 9199.9572s
	iters: 3400, epoch: 3 | loss: 0.0759418
	speed: 0.1216s/iter; left time: 9340.2991s
	iters: 3500, epoch: 3 | loss: 0.1176762
	speed: 0.1202s/iter; left time: 9225.8803s
	iters: 3600, epoch: 3 | loss: 0.0941180
	speed: 0.1194s/iter; left time: 9151.1134s
	iters: 3700, epoch: 3 | loss: 0.1044800
	speed: 0.1174s/iter; left time: 8981.4854s
	iters: 3800, epoch: 3 | loss: 0.1119280
	speed: 0.1162s/iter; left time: 8880.4155s
	iters: 3900, epoch: 3 | loss: 0.1174034
	speed: 0.1197s/iter; left time: 9134.6322s
	iters: 4000, epoch: 3 | loss: 0.0906112
	speed: 0.1202s/iter; left time: 9163.5647s
	iters: 4100, epoch: 3 | loss: 0.1110326
	speed: 0.1207s/iter; left time: 9187.3950s
	iters: 4200, epoch: 3 | loss: 0.1211934
	speed: 0.1201s/iter; left time: 9131.0203s
	iters: 4300, epoch: 3 | loss: 0.1134209
	speed: 0.1160s/iter; left time: 8806.9903s
	iters: 4400, epoch: 3 | loss: 0.0881434
	speed: 0.1209s/iter; left time: 9169.2010s
Epoch: 3 cost time: 00h:08m:54.67s
Epoch: 3 | Train Loss: 0.1022726 Vali Loss: 0.1180037 Test Loss: 0.1440704
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0873546
	speed: 1.4664s/iter; left time: 110965.8672s
	iters: 200, epoch: 4 | loss: 0.1036950
	speed: 0.1208s/iter; left time: 9131.8373s
	iters: 300, epoch: 4 | loss: 0.0934119
	speed: 0.1203s/iter; left time: 9080.9209s
	iters: 400, epoch: 4 | loss: 0.1056632
	speed: 0.1200s/iter; left time: 9041.9870s
	iters: 500, epoch: 4 | loss: 0.0883508
	speed: 0.1200s/iter; left time: 9033.3314s
	iters: 600, epoch: 4 | loss: 0.0899846
	speed: 0.1200s/iter; left time: 9016.7647s
	iters: 700, epoch: 4 | loss: 0.0998617
	speed: 0.1198s/iter; left time: 8990.9683s
	iters: 800, epoch: 4 | loss: 0.0895698
	speed: 0.1119s/iter; left time: 8385.5677s
	iters: 900, epoch: 4 | loss: 0.1108057
	speed: 0.1028s/iter; left time: 7695.6481s
	iters: 1000, epoch: 4 | loss: 0.1005503
	speed: 0.1206s/iter; left time: 9016.9386s
	iters: 1100, epoch: 4 | loss: 0.0851609
	speed: 0.1203s/iter; left time: 8983.5150s
	iters: 1200, epoch: 4 | loss: 0.0922965
	speed: 0.1184s/iter; left time: 8829.7198s
	iters: 1300, epoch: 4 | loss: 0.0940839
	speed: 0.1205s/iter; left time: 8974.1140s
	iters: 1400, epoch: 4 | loss: 0.0969528
	speed: 0.1214s/iter; left time: 9027.9595s
	iters: 1500, epoch: 4 | loss: 0.0909017
	speed: 0.1211s/iter; left time: 8994.6806s
	iters: 1600, epoch: 4 | loss: 0.0886021
	speed: 0.1202s/iter; left time: 8918.6701s
	iters: 1700, epoch: 4 | loss: 0.0961353
	speed: 0.1192s/iter; left time: 8826.5497s
	iters: 1800, epoch: 4 | loss: 0.0882971
	speed: 0.1193s/iter; left time: 8827.9789s
	iters: 1900, epoch: 4 | loss: 0.0977799
	speed: 0.1206s/iter; left time: 8906.6594s
	iters: 2000, epoch: 4 | loss: 0.0880991
	speed: 0.1205s/iter; left time: 8887.7536s
	iters: 2100, epoch: 4 | loss: 0.0910579
	speed: 0.1210s/iter; left time: 8911.9773s
	iters: 2200, epoch: 4 | loss: 0.0977751
	speed: 0.1170s/iter; left time: 8604.0962s
	iters: 2300, epoch: 4 | loss: 0.0931557
	speed: 0.1198s/iter; left time: 8799.9978s
	iters: 2400, epoch: 4 | loss: 0.1089414
	speed: 0.1203s/iter; left time: 8825.1518s
	iters: 2500, epoch: 4 | loss: 0.1060289
	speed: 0.1206s/iter; left time: 8836.8375s
	iters: 2600, epoch: 4 | loss: 0.0834869
	speed: 0.1204s/iter; left time: 8806.9357s
	iters: 2700, epoch: 4 | loss: 0.1122872
	speed: 0.1202s/iter; left time: 8783.7626s
	iters: 2800, epoch: 4 | loss: 0.0878354
	speed: 0.1203s/iter; left time: 8781.8364s
	iters: 2900, epoch: 4 | loss: 0.0907886
	speed: 0.1205s/iter; left time: 8780.7849s
	iters: 3000, epoch: 4 | loss: 0.0977618
	speed: 0.1203s/iter; left time: 8753.5562s
	iters: 3100, epoch: 4 | loss: 0.0923466
	speed: 0.1210s/iter; left time: 8794.0598s
	iters: 3200, epoch: 4 | loss: 0.0991563
	speed: 0.1208s/iter; left time: 8768.5507s
	iters: 3300, epoch: 4 | loss: 0.1049987
	speed: 0.1179s/iter; left time: 8543.1184s
	iters: 3400, epoch: 4 | loss: 0.0708893
	speed: 0.1199s/iter; left time: 8678.8664s
	iters: 3500, epoch: 4 | loss: 0.0792143
	speed: 0.1207s/iter; left time: 8723.7831s
	iters: 3600, epoch: 4 | loss: 0.0895646
	speed: 0.1204s/iter; left time: 8691.0389s
	iters: 3700, epoch: 4 | loss: 0.1049187
	speed: 0.1090s/iter; left time: 7857.3492s
	iters: 3800, epoch: 4 | loss: 0.0842904
	speed: 0.1201s/iter; left time: 8640.4468s
	iters: 3900, epoch: 4 | loss: 0.0941178
	speed: 0.1195s/iter; left time: 8584.9143s
	iters: 4000, epoch: 4 | loss: 0.1109897
	speed: 0.1204s/iter; left time: 8640.2160s
	iters: 4100, epoch: 4 | loss: 0.1001586
	speed: 0.1204s/iter; left time: 8631.5231s
	iters: 4200, epoch: 4 | loss: 0.1093832
	speed: 0.1193s/iter; left time: 8534.7834s
	iters: 4300, epoch: 4 | loss: 0.0876529
	speed: 0.1214s/iter; left time: 8674.4360s
	iters: 4400, epoch: 4 | loss: 0.0952323
	speed: 0.1204s/iter; left time: 8591.1841s
Epoch: 4 cost time: 00h:08m:52.29s
Epoch: 4 | Train Loss: 0.0973941 Vali Loss: 0.1181420 Test Loss: 0.1481285
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0899206
	speed: 1.4706s/iter; left time: 104726.4150s
	iters: 200, epoch: 5 | loss: 0.1038604
	speed: 0.1200s/iter; left time: 8533.3901s
	iters: 300, epoch: 5 | loss: 0.1103195
	speed: 0.1129s/iter; left time: 8018.8887s
	iters: 400, epoch: 5 | loss: 0.0988987
	speed: 0.1047s/iter; left time: 7425.3580s
	iters: 500, epoch: 5 | loss: 0.1051342
	speed: 0.1194s/iter; left time: 8454.0719s
	iters: 600, epoch: 5 | loss: 0.0994484
	speed: 0.1204s/iter; left time: 8516.0204s
	iters: 700, epoch: 5 | loss: 0.0807362
	speed: 0.1187s/iter; left time: 8379.2261s
	iters: 800, epoch: 5 | loss: 0.1006454
	speed: 0.1196s/iter; left time: 8432.8799s
	iters: 900, epoch: 5 | loss: 0.1117228
	speed: 0.1183s/iter; left time: 8329.6994s
	iters: 1000, epoch: 5 | loss: 0.0958334
	speed: 0.1198s/iter; left time: 8422.4688s
	iters: 1100, epoch: 5 | loss: 0.0945488
	speed: 0.1204s/iter; left time: 8453.1215s
	iters: 1200, epoch: 5 | loss: 0.0999299
	speed: 0.1191s/iter; left time: 8349.4524s
	iters: 1300, epoch: 5 | loss: 0.0833874
	speed: 0.1166s/iter; left time: 8166.5798s
	iters: 1400, epoch: 5 | loss: 0.0800731
	speed: 0.1130s/iter; left time: 7903.1613s
	iters: 1500, epoch: 5 | loss: 0.0873000
	speed: 0.1197s/iter; left time: 8356.3277s
	iters: 1600, epoch: 5 | loss: 0.0974982
	speed: 0.1198s/iter; left time: 8352.9471s
	iters: 1700, epoch: 5 | loss: 0.0832424
	speed: 0.1187s/iter; left time: 8260.3997s
	iters: 1800, epoch: 5 | loss: 0.0964874
	speed: 0.1192s/iter; left time: 8282.9744s
	iters: 1900, epoch: 5 | loss: 0.1015488
	speed: 0.1194s/iter; left time: 8287.9705s
	iters: 2000, epoch: 5 | loss: 0.0962706
	speed: 0.1193s/iter; left time: 8271.0642s
	iters: 2100, epoch: 5 | loss: 0.0944651
	speed: 0.1206s/iter; left time: 8346.2935s
	iters: 2200, epoch: 5 | loss: 0.0883529
	speed: 0.1199s/iter; left time: 8290.0272s
	iters: 2300, epoch: 5 | loss: 0.0954471
	speed: 0.1188s/iter; left time: 8195.5945s
	iters: 2400, epoch: 5 | loss: 0.0827175
	speed: 0.1209s/iter; left time: 8334.5616s
	iters: 2500, epoch: 5 | loss: 0.1006347
	speed: 0.1178s/iter; left time: 8105.8780s
	iters: 2600, epoch: 5 | loss: 0.0951255
	speed: 0.1197s/iter; left time: 8222.8002s
	iters: 2700, epoch: 5 | loss: 0.1033527
	speed: 0.1204s/iter; left time: 8260.3845s
	iters: 2800, epoch: 5 | loss: 0.0756043
	speed: 0.1163s/iter; left time: 7968.6201s
	iters: 2900, epoch: 5 | loss: 0.0850169
	speed: 0.1187s/iter; left time: 8120.8543s
	iters: 3000, epoch: 5 | loss: 0.1090293
	speed: 0.1196s/iter; left time: 8167.7409s
	iters: 3100, epoch: 5 | loss: 0.0975026
	speed: 0.1199s/iter; left time: 8181.5988s
	iters: 3200, epoch: 5 | loss: 0.0954872
	speed: 0.1187s/iter; left time: 8087.5449s
	iters: 3300, epoch: 5 | loss: 0.0834685
	speed: 0.1203s/iter; left time: 8179.5385s
	iters: 3400, epoch: 5 | loss: 0.0841382
	speed: 0.1204s/iter; left time: 8177.8860s
	iters: 3500, epoch: 5 | loss: 0.0745072
	speed: 0.1192s/iter; left time: 8084.6962s
	iters: 3600, epoch: 5 | loss: 0.1053615
	speed: 0.1205s/iter; left time: 8158.0915s
	iters: 3700, epoch: 5 | loss: 0.0791975
	speed: 0.1213s/iter; left time: 8200.6674s
	iters: 3800, epoch: 5 | loss: 0.0998375
	speed: 0.1203s/iter; left time: 8124.2779s
	iters: 3900, epoch: 5 | loss: 0.0949914
	speed: 0.1201s/iter; left time: 8095.8593s
	iters: 4000, epoch: 5 | loss: 0.0968361
	speed: 0.1206s/iter; left time: 8117.6828s
	iters: 4100, epoch: 5 | loss: 0.0942416
	speed: 0.1200s/iter; left time: 8063.4474s
	iters: 4200, epoch: 5 | loss: 0.1008289
	speed: 0.1210s/iter; left time: 8119.0893s
	iters: 4300, epoch: 5 | loss: 0.0779671
	speed: 0.1203s/iter; left time: 8060.7706s
	iters: 4400, epoch: 5 | loss: 0.0973403
	speed: 0.1206s/iter; left time: 8068.7534s
Epoch: 5 cost time: 00h:08m:50.76s
Epoch: 5 | Train Loss: 0.0930669 Vali Loss: 0.1177695 Test Loss: 0.1494393
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0950565
	speed: 1.4622s/iter; left time: 97612.0649s
	iters: 200, epoch: 6 | loss: 0.0880194
	speed: 0.1204s/iter; left time: 8026.5113s
	iters: 300, epoch: 6 | loss: 0.0845609
	speed: 0.1156s/iter; left time: 7694.1706s
	iters: 400, epoch: 6 | loss: 0.0856797
	speed: 0.1174s/iter; left time: 7800.8841s
	iters: 500, epoch: 6 | loss: 0.0811084
	speed: 0.1203s/iter; left time: 7985.1788s
	iters: 600, epoch: 6 | loss: 0.1066922
	speed: 0.1205s/iter; left time: 7987.0147s
	iters: 700, epoch: 6 | loss: 0.0946200
	speed: 0.1204s/iter; left time: 7965.1051s
	iters: 800, epoch: 6 | loss: 0.1000760
	speed: 0.1203s/iter; left time: 7945.8868s
	iters: 900, epoch: 6 | loss: 0.0695545
	speed: 0.1019s/iter; left time: 6722.8686s
	iters: 1000, epoch: 6 | loss: 0.1009072
	speed: 0.1085s/iter; left time: 7143.8240s
	iters: 1100, epoch: 6 | loss: 0.0820811
	speed: 0.1197s/iter; left time: 7870.3069s
	iters: 1200, epoch: 6 | loss: 0.1012075
	speed: 0.1202s/iter; left time: 7888.6042s
	iters: 1300, epoch: 6 | loss: 0.0863402
	speed: 0.1106s/iter; left time: 7252.1631s
	iters: 1400, epoch: 6 | loss: 0.0826545
	speed: 0.1201s/iter; left time: 7863.2727s
	iters: 1500, epoch: 6 | loss: 0.0777465
	speed: 0.1194s/iter; left time: 7806.4292s
	iters: 1600, epoch: 6 | loss: 0.1057802
	speed: 0.1206s/iter; left time: 7867.1432s
	iters: 1700, epoch: 6 | loss: 0.0942861
	speed: 0.1203s/iter; left time: 7839.3424s
	iters: 1800, epoch: 6 | loss: 0.0920153
	speed: 0.1203s/iter; left time: 7826.2045s
	iters: 1900, epoch: 6 | loss: 0.0782236
	speed: 0.1194s/iter; left time: 7755.3000s
	iters: 2000, epoch: 6 | loss: 0.0907045
	speed: 0.1198s/iter; left time: 7766.6119s
	iters: 2100, epoch: 6 | loss: 0.0759282
	speed: 0.1202s/iter; left time: 7781.8083s
	iters: 2200, epoch: 6 | loss: 0.1017066
	speed: 0.1197s/iter; left time: 7738.4182s
	iters: 2300, epoch: 6 | loss: 0.0679502
	speed: 0.1206s/iter; left time: 7782.3964s
	iters: 2400, epoch: 6 | loss: 0.0776927
	speed: 0.1170s/iter; left time: 7540.0842s
	iters: 2500, epoch: 6 | loss: 0.0888472
	speed: 0.1206s/iter; left time: 7761.8660s
	iters: 2600, epoch: 6 | loss: 0.0768875
	speed: 0.1207s/iter; left time: 7752.5761s
	iters: 2700, epoch: 6 | loss: 0.0782935
	speed: 0.1201s/iter; left time: 7703.7262s
	iters: 2800, epoch: 6 | loss: 0.0903737
	speed: 0.1206s/iter; left time: 7726.5885s
	iters: 2900, epoch: 6 | loss: 0.1004810
	speed: 0.1199s/iter; left time: 7665.9887s
	iters: 3000, epoch: 6 | loss: 0.0948790
	speed: 0.1196s/iter; left time: 7634.2215s
	iters: 3100, epoch: 6 | loss: 0.0886455
	speed: 0.1193s/iter; left time: 7604.0567s
	iters: 3200, epoch: 6 | loss: 0.0854608
	speed: 0.1187s/iter; left time: 7553.4596s
	iters: 3300, epoch: 6 | loss: 0.0769016
	speed: 0.1201s/iter; left time: 7633.0253s
	iters: 3400, epoch: 6 | loss: 0.0817375
	speed: 0.1205s/iter; left time: 7648.3160s
	iters: 3500, epoch: 6 | loss: 0.0888851
	speed: 0.1208s/iter; left time: 7653.4108s
	iters: 3600, epoch: 6 | loss: 0.0727457
	speed: 0.1206s/iter; left time: 7629.6762s
	iters: 3700, epoch: 6 | loss: 0.0903441
	speed: 0.1199s/iter; left time: 7571.0870s
	iters: 3800, epoch: 6 | loss: 0.0950212
	speed: 0.1203s/iter; left time: 7583.9066s
	iters: 3900, epoch: 6 | loss: 0.0870087
	speed: 0.1201s/iter; left time: 7563.2798s
	iters: 4000, epoch: 6 | loss: 0.0871792
	speed: 0.1198s/iter; left time: 7530.5665s
	iters: 4100, epoch: 6 | loss: 0.0932686
	speed: 0.1189s/iter; left time: 7461.3394s
	iters: 4200, epoch: 6 | loss: 0.0874465
	speed: 0.1190s/iter; left time: 7458.8442s
	iters: 4300, epoch: 6 | loss: 0.0889675
	speed: 0.1196s/iter; left time: 7480.2658s
	iters: 4400, epoch: 6 | loss: 0.0926063
	speed: 0.1193s/iter; left time: 7450.3856s
Epoch: 6 cost time: 00h:08m:50.39s
Epoch: 6 | Train Loss: 0.0893757 Vali Loss: 0.1196648 Test Loss: 0.1541289
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.1048594
	speed: 1.4631s/iter; left time: 91147.4115s
	iters: 200, epoch: 7 | loss: 0.0843566
	speed: 0.1206s/iter; left time: 7498.7482s
	iters: 300, epoch: 7 | loss: 0.0917804
	speed: 0.1201s/iter; left time: 7458.6207s
	iters: 400, epoch: 7 | loss: 0.0795149
	speed: 0.1198s/iter; left time: 7427.3699s
	iters: 500, epoch: 7 | loss: 0.0842911
	speed: 0.1204s/iter; left time: 7452.7693s
	iters: 600, epoch: 7 | loss: 0.0841490
	speed: 0.1189s/iter; left time: 7348.1628s
	iters: 700, epoch: 7 | loss: 0.1009502
	speed: 0.1201s/iter; left time: 7412.9278s
	iters: 800, epoch: 7 | loss: 0.0739675
	speed: 0.1198s/iter; left time: 7380.0387s
	iters: 900, epoch: 7 | loss: 0.0888571
	speed: 0.1189s/iter; left time: 7312.4949s
	iters: 1000, epoch: 7 | loss: 0.0870971
	speed: 0.1203s/iter; left time: 7386.9845s
	iters: 1100, epoch: 7 | loss: 0.0928913
	speed: 0.1201s/iter; left time: 7362.1718s
	iters: 1200, epoch: 7 | loss: 0.0886939
	speed: 0.1201s/iter; left time: 7351.5318s
	iters: 1300, epoch: 7 | loss: 0.0893422
	speed: 0.1201s/iter; left time: 7339.4798s
	iters: 1400, epoch: 7 | loss: 0.0847866
	speed: 0.1201s/iter; left time: 7323.7716s
	iters: 1500, epoch: 7 | loss: 0.0769473
	speed: 0.1117s/iter; left time: 6799.5656s
	iters: 1600, epoch: 7 | loss: 0.0924601
	speed: 0.1051s/iter; left time: 6388.3946s
	iters: 1700, epoch: 7 | loss: 0.0808676
	speed: 0.1201s/iter; left time: 7292.0577s
	iters: 1800, epoch: 7 | loss: 0.0922723
	speed: 0.1195s/iter; left time: 7240.8977s
	iters: 1900, epoch: 7 | loss: 0.0814242
	speed: 0.1200s/iter; left time: 7259.2358s
	iters: 2000, epoch: 7 | loss: 0.0870774
	speed: 0.1194s/iter; left time: 7209.0168s
	iters: 2100, epoch: 7 | loss: 0.0811431
	speed: 0.1191s/iter; left time: 7182.9229s
	iters: 2200, epoch: 7 | loss: 0.0951526
	speed: 0.1194s/iter; left time: 7185.1179s
	iters: 2300, epoch: 7 | loss: 0.0774082
	speed: 0.1194s/iter; left time: 7174.9913s
	iters: 2400, epoch: 7 | loss: 0.0838267
	speed: 0.1189s/iter; left time: 7136.0462s
	iters: 2500, epoch: 7 | loss: 0.0840728
	speed: 0.1187s/iter; left time: 7109.2061s
	iters: 2600, epoch: 7 | loss: 0.0857305
	speed: 0.1201s/iter; left time: 7183.3663s
	iters: 2700, epoch: 7 | loss: 0.0911212
	speed: 0.1199s/iter; left time: 7155.4635s
	iters: 2800, epoch: 7 | loss: 0.0788338
	speed: 0.1205s/iter; left time: 7180.6713s
	iters: 2900, epoch: 7 | loss: 0.0812203
	speed: 0.1189s/iter; left time: 7074.7929s
	iters: 3000, epoch: 7 | loss: 0.0968771
	speed: 0.1194s/iter; left time: 7094.9477s
	iters: 3100, epoch: 7 | loss: 0.0815360
	speed: 0.1197s/iter; left time: 7098.6095s
	iters: 3200, epoch: 7 | loss: 0.0820606
	speed: 0.1195s/iter; left time: 7076.6017s
	iters: 3300, epoch: 7 | loss: 0.0775566
	speed: 0.1202s/iter; left time: 7104.0119s
	iters: 3400, epoch: 7 | loss: 0.1014951
	speed: 0.1096s/iter; left time: 6464.7371s
	iters: 3500, epoch: 7 | loss: 0.0893218
	speed: 0.1114s/iter; left time: 6561.6180s
	iters: 3600, epoch: 7 | loss: 0.0940796
	speed: 0.1200s/iter; left time: 7057.5390s
	iters: 3700, epoch: 7 | loss: 0.0836638
	speed: 0.1205s/iter; left time: 7071.3557s
	iters: 3800, epoch: 7 | loss: 0.1027704
	speed: 0.1201s/iter; left time: 7036.9115s
	iters: 3900, epoch: 7 | loss: 0.0680492
	speed: 0.1197s/iter; left time: 7000.7407s
	iters: 4000, epoch: 7 | loss: 0.1034615
	speed: 0.1201s/iter; left time: 7014.2495s
	iters: 4100, epoch: 7 | loss: 0.0949323
	speed: 0.1202s/iter; left time: 7007.5574s
	iters: 4200, epoch: 7 | loss: 0.0865043
	speed: 0.1194s/iter; left time: 6948.3949s
	iters: 4300, epoch: 7 | loss: 0.0960433
	speed: 0.1170s/iter; left time: 6795.0164s
	iters: 4400, epoch: 7 | loss: 0.0965981
	speed: 0.1204s/iter; left time: 6983.1908s
Epoch: 7 cost time: 00h:08m:50.02s
Epoch: 7 | Train Loss: 0.0862290 Vali Loss: 0.1190629 Test Loss: 0.1528910
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.04200141876935959, rmse:0.2049424797296524, mae:0.14045733213424683, rse:0.7086868286132812
success delete checkpoints
Intermediate time for GB and pred_len 96: 01h:19m:23.87s


=== Starting experiments for pred_len: 168 ===

train 142285
val 30365
test 30365
[2024-11-01 04:35:03,380] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 04:35:04,528] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 04:35:04,529] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 04:35:04,529] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 04:35:04,633] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 04:35:04,634] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 04:35:05,322] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 04:35:05,324] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 04:35:05,324] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 04:35:05,325] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 04:35:05,326] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 04:35:05,326] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 04:35:05,326] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 04:35:05,326] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 04:35:05,326] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 04:35:05,326] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 04:35:05,638] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 04:35:05,639] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 04:35:05,662] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.48 GB, percent = 9.9%
[2024-11-01 04:35:05,788] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 04:35:05,789] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 04:35:05,790] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.48 GB, percent = 9.9%
[2024-11-01 04:35:05,790] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 04:35:05,901] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 04:35:05,902] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 04:35:05,902] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.46 GB, percent = 9.9%
[2024-11-01 04:35:05,903] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 04:35:05,903] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 04:35:05,903] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 04:35:05,903] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 04:35:05,904] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 04:35:05,904] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f77c544cf50>
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 04:35:05,905] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 04:35:05,906] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 04:35:05,907] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 04:35:05,907] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1482348
	speed: 0.1744s/iter; left time: 15489.3728s
	iters: 200, epoch: 1 | loss: 0.1453139
	speed: 0.1312s/iter; left time: 11643.9785s
	iters: 300, epoch: 1 | loss: 0.1553313
	speed: 0.1308s/iter; left time: 11590.6256s
	iters: 400, epoch: 1 | loss: 0.1554058
	speed: 0.1312s/iter; left time: 11615.4949s
	iters: 500, epoch: 1 | loss: 0.1471658
	speed: 0.1310s/iter; left time: 11580.9007s
	iters: 600, epoch: 1 | loss: 0.1542638
	speed: 0.1308s/iter; left time: 11553.6236s
	iters: 700, epoch: 1 | loss: 0.1336013
	speed: 0.1310s/iter; left time: 11560.6945s
	iters: 800, epoch: 1 | loss: 0.1162374
	speed: 0.1310s/iter; left time: 11544.3222s
	iters: 900, epoch: 1 | loss: 0.1247154
	speed: 0.1272s/iter; left time: 11198.4237s
	iters: 1000, epoch: 1 | loss: 0.1020275
	speed: 0.1307s/iter; left time: 11495.2002s
	iters: 1100, epoch: 1 | loss: 0.1375454
	speed: 0.1309s/iter; left time: 11492.3153s
	iters: 1200, epoch: 1 | loss: 0.1161896
	speed: 0.1309s/iter; left time: 11481.4712s
	iters: 1300, epoch: 1 | loss: 0.1136029
	speed: 0.1313s/iter; left time: 11502.8437s
	iters: 1400, epoch: 1 | loss: 0.1167578
	speed: 0.1307s/iter; left time: 11437.7022s
	iters: 1500, epoch: 1 | loss: 0.1177376
	speed: 0.1309s/iter; left time: 11440.1571s
	iters: 1600, epoch: 1 | loss: 0.1085610
	speed: 0.1306s/iter; left time: 11407.6720s
	iters: 1700, epoch: 1 | loss: 0.1154755
	speed: 0.1309s/iter; left time: 11415.4095s
	iters: 1800, epoch: 1 | loss: 0.0951475
	speed: 0.1305s/iter; left time: 11371.7059s
	iters: 1900, epoch: 1 | loss: 0.1343727
	speed: 0.1309s/iter; left time: 11395.1983s
	iters: 2000, epoch: 1 | loss: 0.1305830
	speed: 0.1307s/iter; left time: 11363.3162s
	iters: 2100, epoch: 1 | loss: 0.1169467
	speed: 0.1310s/iter; left time: 11369.7142s
	iters: 2200, epoch: 1 | loss: 0.1000786
	speed: 0.1309s/iter; left time: 11349.3600s
	iters: 2300, epoch: 1 | loss: 0.0901878
	speed: 0.1305s/iter; left time: 11300.0338s
	iters: 2400, epoch: 1 | loss: 0.1336366
	speed: 0.1311s/iter; left time: 11340.2752s
	iters: 2500, epoch: 1 | loss: 0.1131255
	speed: 0.1310s/iter; left time: 11319.2071s
	iters: 2600, epoch: 1 | loss: 0.1157848
	speed: 0.1310s/iter; left time: 11307.8601s
	iters: 2700, epoch: 1 | loss: 0.1087803
	speed: 0.1308s/iter; left time: 11273.9040s
	iters: 2800, epoch: 1 | loss: 0.1142708
	speed: 0.1305s/iter; left time: 11241.0230s
	iters: 2900, epoch: 1 | loss: 0.1243213
	speed: 0.1309s/iter; left time: 11256.8672s
	iters: 3000, epoch: 1 | loss: 0.0919846
	speed: 0.1310s/iter; left time: 11254.4900s
	iters: 3100, epoch: 1 | loss: 0.1445014
	speed: 0.1310s/iter; left time: 11239.6106s
	iters: 3200, epoch: 1 | loss: 0.0993669
	speed: 0.1284s/iter; left time: 11004.5878s
	iters: 3300, epoch: 1 | loss: 0.1163438
	speed: 0.1308s/iter; left time: 11200.4105s
	iters: 3400, epoch: 1 | loss: 0.1209128
	speed: 0.1309s/iter; left time: 11194.1330s
	iters: 3500, epoch: 1 | loss: 0.0993587
	speed: 0.1307s/iter; left time: 11167.2156s
	iters: 3600, epoch: 1 | loss: 0.1136707
	speed: 0.1310s/iter; left time: 11173.5448s
	iters: 3700, epoch: 1 | loss: 0.1139015
	speed: 0.1307s/iter; left time: 11141.4003s
	iters: 3800, epoch: 1 | loss: 0.1168825
	speed: 0.1308s/iter; left time: 11134.4358s
	iters: 3900, epoch: 1 | loss: 0.1059878
	speed: 0.1311s/iter; left time: 11146.6503s
	iters: 4000, epoch: 1 | loss: 0.1127900
	speed: 0.1264s/iter; left time: 10732.3464s
	iters: 4100, epoch: 1 | loss: 0.1130453
	speed: 0.1310s/iter; left time: 11109.8603s
	iters: 4200, epoch: 1 | loss: 0.1120209
	speed: 0.1307s/iter; left time: 11077.2114s
	iters: 4300, epoch: 1 | loss: 0.1165368
	speed: 0.1230s/iter; left time: 10406.4833s
	iters: 4400, epoch: 1 | loss: 0.1169618
	speed: 0.1286s/iter; left time: 10870.6954s
Epoch: 1 cost time: 00h:09m:40.98s
Epoch: 1 | Train Loss: 0.1205897 Vali Loss: 0.1209952 Test Loss: 0.1438364
Validation loss decreased (inf --> 0.120995).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1197857
	speed: 1.6567s/iter; left time: 139784.7019s
	iters: 200, epoch: 2 | loss: 0.1099122
	speed: 0.1205s/iter; left time: 10154.5353s
	iters: 300, epoch: 2 | loss: 0.1050249
	speed: 0.1205s/iter; left time: 10146.0552s
	iters: 400, epoch: 2 | loss: 0.1127598
	speed: 0.1205s/iter; left time: 10130.8889s
	iters: 500, epoch: 2 | loss: 0.0847004
	speed: 0.1204s/iter; left time: 10111.1450s
	iters: 600, epoch: 2 | loss: 0.1266375
	speed: 0.1208s/iter; left time: 10128.8954s
	iters: 700, epoch: 2 | loss: 0.1209411
	speed: 0.1182s/iter; left time: 9904.0936s
	iters: 800, epoch: 2 | loss: 0.1068922
	speed: 0.1208s/iter; left time: 10108.1544s
	iters: 900, epoch: 2 | loss: 0.0993572
	speed: 0.1209s/iter; left time: 10106.5541s
	iters: 1000, epoch: 2 | loss: 0.1088792
	speed: 0.1205s/iter; left time: 10060.7808s
	iters: 1100, epoch: 2 | loss: 0.1103762
	speed: 0.1207s/iter; left time: 10062.2417s
	iters: 1200, epoch: 2 | loss: 0.1110987
	speed: 0.1207s/iter; left time: 10052.5846s
	iters: 1300, epoch: 2 | loss: 0.0816215
	speed: 0.1204s/iter; left time: 10014.7473s
	iters: 1400, epoch: 2 | loss: 0.1149543
	speed: 0.1204s/iter; left time: 10006.1057s
	iters: 1500, epoch: 2 | loss: 0.1127167
	speed: 0.1203s/iter; left time: 9984.3990s
	iters: 1600, epoch: 2 | loss: 0.1143629
	speed: 0.1201s/iter; left time: 9955.6109s
	iters: 1700, epoch: 2 | loss: 0.1134126
	speed: 0.1205s/iter; left time: 9977.8425s
	iters: 1800, epoch: 2 | loss: 0.1078830
	speed: 0.1199s/iter; left time: 9912.9619s
	iters: 1900, epoch: 2 | loss: 0.0992961
	speed: 0.1200s/iter; left time: 9909.9458s
	iters: 2000, epoch: 2 | loss: 0.1067948
	speed: 0.1193s/iter; left time: 9837.7826s
	iters: 2100, epoch: 2 | loss: 0.1038578
	speed: 0.1199s/iter; left time: 9877.5514s
	iters: 2200, epoch: 2 | loss: 0.1177262
	speed: 0.1052s/iter; left time: 8654.4739s
	iters: 2300, epoch: 2 | loss: 0.1152344
	speed: 0.1019s/iter; left time: 8370.5519s
	iters: 2400, epoch: 2 | loss: 0.1077954
	speed: 0.1082s/iter; left time: 8879.6234s
	iters: 2500, epoch: 2 | loss: 0.1127032
	speed: 0.1193s/iter; left time: 9776.4222s
	iters: 2600, epoch: 2 | loss: 0.1118686
	speed: 0.1203s/iter; left time: 9850.6207s
	iters: 2700, epoch: 2 | loss: 0.1096208
	speed: 0.1202s/iter; left time: 9829.3320s
	iters: 2800, epoch: 2 | loss: 0.0965174
	speed: 0.1206s/iter; left time: 9851.1311s
	iters: 2900, epoch: 2 | loss: 0.1007073
	speed: 0.1207s/iter; left time: 9846.7172s
	iters: 3000, epoch: 2 | loss: 0.0923950
	speed: 0.1071s/iter; left time: 8724.0858s
	iters: 3100, epoch: 2 | loss: 0.1115430
	speed: 0.1022s/iter; left time: 8315.6496s
	iters: 3200, epoch: 2 | loss: 0.1126868
	speed: 0.1034s/iter; left time: 8403.7845s
	iters: 3300, epoch: 2 | loss: 0.1034839
	speed: 0.1206s/iter; left time: 9790.7659s
	iters: 3400, epoch: 2 | loss: 0.1078405
	speed: 0.1207s/iter; left time: 9786.1077s
	iters: 3500, epoch: 2 | loss: 0.1037599
	speed: 0.1209s/iter; left time: 9791.7455s
	iters: 3600, epoch: 2 | loss: 0.0952058
	speed: 0.1208s/iter; left time: 9769.1219s
	iters: 3700, epoch: 2 | loss: 0.1051804
	speed: 0.1209s/iter; left time: 9766.6777s
	iters: 3800, epoch: 2 | loss: 0.1044087
	speed: 0.1207s/iter; left time: 9735.7998s
	iters: 3900, epoch: 2 | loss: 0.1066130
	speed: 0.1202s/iter; left time: 9688.5349s
	iters: 4000, epoch: 2 | loss: 0.1092677
	speed: 0.1209s/iter; left time: 9728.5880s
	iters: 4100, epoch: 2 | loss: 0.1083696
	speed: 0.1206s/iter; left time: 9691.7563s
	iters: 4200, epoch: 2 | loss: 0.1197105
	speed: 0.1203s/iter; left time: 9656.6568s
	iters: 4300, epoch: 2 | loss: 0.1068081
	speed: 0.1204s/iter; left time: 9655.2676s
	iters: 4400, epoch: 2 | loss: 0.1261329
	speed: 0.1204s/iter; left time: 9641.9087s
Epoch: 2 cost time: 00h:08m:46.40s
Epoch: 2 | Train Loss: 0.1098766 Vali Loss: 0.1225332 Test Loss: 0.1477604
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0998430
	speed: 1.4317s/iter; left time: 114430.4912s
	iters: 200, epoch: 3 | loss: 0.1029584
	speed: 0.1174s/iter; left time: 9370.8466s
	iters: 300, epoch: 3 | loss: 0.0965041
	speed: 0.1203s/iter; left time: 9590.3716s
	iters: 400, epoch: 3 | loss: 0.1077358
	speed: 0.1205s/iter; left time: 9593.7343s
	iters: 500, epoch: 3 | loss: 0.1056079
	speed: 0.1209s/iter; left time: 9617.2400s
	iters: 600, epoch: 3 | loss: 0.1190159
	speed: 0.1206s/iter; left time: 9580.5925s
	iters: 700, epoch: 3 | loss: 0.1028953
	speed: 0.1207s/iter; left time: 9574.9051s
	iters: 800, epoch: 3 | loss: 0.1252995
	speed: 0.1209s/iter; left time: 9575.2761s
	iters: 900, epoch: 3 | loss: 0.0910322
	speed: 0.1206s/iter; left time: 9542.7023s
	iters: 1000, epoch: 3 | loss: 0.1096593
	speed: 0.1206s/iter; left time: 9532.5357s
	iters: 1100, epoch: 3 | loss: 0.0958329
	speed: 0.1205s/iter; left time: 9514.7747s
	iters: 1200, epoch: 3 | loss: 0.1051666
	speed: 0.1203s/iter; left time: 9482.3237s
	iters: 1300, epoch: 3 | loss: 0.1145009
	speed: 0.1209s/iter; left time: 9518.8913s
	iters: 1400, epoch: 3 | loss: 0.1089370
	speed: 0.1209s/iter; left time: 9505.3003s
	iters: 1500, epoch: 3 | loss: 0.0982486
	speed: 0.1207s/iter; left time: 9478.7850s
	iters: 1600, epoch: 3 | loss: 0.1116064
	speed: 0.1203s/iter; left time: 9433.2706s
	iters: 1700, epoch: 3 | loss: 0.1152646
	speed: 0.1203s/iter; left time: 9421.5386s
	iters: 1800, epoch: 3 | loss: 0.1033108
	speed: 0.1208s/iter; left time: 9447.6685s
	iters: 1900, epoch: 3 | loss: 0.1160483
	speed: 0.1199s/iter; left time: 9370.0343s
	iters: 2000, epoch: 3 | loss: 0.1133725
	speed: 0.1022s/iter; left time: 7972.7087s
	iters: 2100, epoch: 3 | loss: 0.0946887
	speed: 0.1019s/iter; left time: 7937.1427s
	iters: 2200, epoch: 3 | loss: 0.1068842
	speed: 0.1165s/iter; left time: 9068.9008s
	iters: 2300, epoch: 3 | loss: 0.1091909
	speed: 0.1202s/iter; left time: 9345.0775s
	iters: 2400, epoch: 3 | loss: 0.0988755
	speed: 0.1210s/iter; left time: 9396.1780s
	iters: 2500, epoch: 3 | loss: 0.0938124
	speed: 0.1208s/iter; left time: 9368.8664s
	iters: 2600, epoch: 3 | loss: 0.1091160
	speed: 0.1207s/iter; left time: 9346.1320s
	iters: 2700, epoch: 3 | loss: 0.1095193
	speed: 0.1204s/iter; left time: 9307.8747s
	iters: 2800, epoch: 3 | loss: 0.1060785
	speed: 0.1204s/iter; left time: 9295.9643s
	iters: 2900, epoch: 3 | loss: 0.0896944
	speed: 0.1204s/iter; left time: 9284.3652s
	iters: 3000, epoch: 3 | loss: 0.0934717
	speed: 0.1201s/iter; left time: 9249.8228s
	iters: 3100, epoch: 3 | loss: 0.1221983
	speed: 0.1204s/iter; left time: 9260.0851s
	iters: 3200, epoch: 3 | loss: 0.0963738
	speed: 0.1202s/iter; left time: 9233.4493s
	iters: 3300, epoch: 3 | loss: 0.1190489
	speed: 0.1205s/iter; left time: 9245.6127s
	iters: 3400, epoch: 3 | loss: 0.1036496
	speed: 0.1205s/iter; left time: 9230.7809s
	iters: 3500, epoch: 3 | loss: 0.1124387
	speed: 0.1206s/iter; left time: 9230.4399s
	iters: 3600, epoch: 3 | loss: 0.1170041
	speed: 0.1207s/iter; left time: 9225.7649s
	iters: 3700, epoch: 3 | loss: 0.1089111
	speed: 0.1208s/iter; left time: 9219.6902s
	iters: 3800, epoch: 3 | loss: 0.0951907
	speed: 0.1207s/iter; left time: 9198.5566s
	iters: 3900, epoch: 3 | loss: 0.0979321
	speed: 0.1207s/iter; left time: 9191.6299s
	iters: 4000, epoch: 3 | loss: 0.0999806
	speed: 0.1198s/iter; left time: 9108.5758s
	iters: 4100, epoch: 3 | loss: 0.0940368
	speed: 0.1203s/iter; left time: 9132.9958s
	iters: 4200, epoch: 3 | loss: 0.0999659
	speed: 0.1208s/iter; left time: 9160.1375s
	iters: 4300, epoch: 3 | loss: 0.0951753
	speed: 0.1197s/iter; left time: 9064.6799s
	iters: 4400, epoch: 3 | loss: 0.0947775
	speed: 0.1207s/iter; left time: 9129.6460s
Epoch: 3 cost time: 00h:08m:50.81s
Epoch: 3 | Train Loss: 0.1043304 Vali Loss: 0.1245715 Test Loss: 0.1501074
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0944092
	speed: 1.4326s/iter; left time: 108140.5465s
	iters: 200, epoch: 4 | loss: 0.0867483
	speed: 0.1208s/iter; left time: 9104.9022s
	iters: 300, epoch: 4 | loss: 0.1064334
	speed: 0.1207s/iter; left time: 9085.1943s
	iters: 400, epoch: 4 | loss: 0.0956620
	speed: 0.1202s/iter; left time: 9038.9481s
	iters: 500, epoch: 4 | loss: 0.1117885
	speed: 0.1206s/iter; left time: 9055.4508s
	iters: 600, epoch: 4 | loss: 0.1063067
	speed: 0.1041s/iter; left time: 7809.3217s
	iters: 700, epoch: 4 | loss: 0.0915639
	speed: 0.1019s/iter; left time: 7631.2419s
	iters: 800, epoch: 4 | loss: 0.1026455
	speed: 0.1020s/iter; left time: 7630.4242s
	iters: 900, epoch: 4 | loss: 0.1035407
	speed: 0.1019s/iter; left time: 7613.0623s
	iters: 1000, epoch: 4 | loss: 0.1075997
	speed: 0.1025s/iter; left time: 7641.4298s
	iters: 1100, epoch: 4 | loss: 0.0891981
	speed: 0.1157s/iter; left time: 8614.0021s
	iters: 1200, epoch: 4 | loss: 0.1041374
	speed: 0.1202s/iter; left time: 8944.0972s
	iters: 1300, epoch: 4 | loss: 0.1022310
	speed: 0.1204s/iter; left time: 8944.2167s
	iters: 1400, epoch: 4 | loss: 0.1072065
	speed: 0.1204s/iter; left time: 8930.9287s
	iters: 1500, epoch: 4 | loss: 0.0838472
	speed: 0.1208s/iter; left time: 8950.5413s
	iters: 1600, epoch: 4 | loss: 0.0923450
	speed: 0.1196s/iter; left time: 8848.8683s
	iters: 1700, epoch: 4 | loss: 0.1015804
	speed: 0.1200s/iter; left time: 8867.8344s
	iters: 1800, epoch: 4 | loss: 0.1218250
	speed: 0.1203s/iter; left time: 8876.8024s
	iters: 1900, epoch: 4 | loss: 0.1150391
	speed: 0.1202s/iter; left time: 8855.6591s
	iters: 2000, epoch: 4 | loss: 0.1164713
	speed: 0.1200s/iter; left time: 8832.7249s
	iters: 2100, epoch: 4 | loss: 0.1034276
	speed: 0.1202s/iter; left time: 8830.5942s
	iters: 2200, epoch: 4 | loss: 0.0898664
	speed: 0.1203s/iter; left time: 8827.5469s
	iters: 2300, epoch: 4 | loss: 0.0815171
	speed: 0.1206s/iter; left time: 8835.4872s
	iters: 2400, epoch: 4 | loss: 0.1059342
	speed: 0.1205s/iter; left time: 8817.6487s
	iters: 2500, epoch: 4 | loss: 0.1042058
	speed: 0.1208s/iter; left time: 8827.8275s
	iters: 2600, epoch: 4 | loss: 0.0878983
	speed: 0.1206s/iter; left time: 8798.4687s
	iters: 2700, epoch: 4 | loss: 0.0832504
	speed: 0.1204s/iter; left time: 8774.4080s
	iters: 2800, epoch: 4 | loss: 0.0833858
	speed: 0.1202s/iter; left time: 8747.0164s
	iters: 2900, epoch: 4 | loss: 0.1033833
	speed: 0.1205s/iter; left time: 8758.2982s
	iters: 3000, epoch: 4 | loss: 0.0952015
	speed: 0.1206s/iter; left time: 8754.3077s
	iters: 3100, epoch: 4 | loss: 0.0781978
	speed: 0.1200s/iter; left time: 8696.0727s
	iters: 3200, epoch: 4 | loss: 0.1017636
	speed: 0.1196s/iter; left time: 8658.4880s
	iters: 3300, epoch: 4 | loss: 0.1010068
	speed: 0.1199s/iter; left time: 8663.6760s
	iters: 3400, epoch: 4 | loss: 0.1017999
	speed: 0.1203s/iter; left time: 8685.3873s
	iters: 3500, epoch: 4 | loss: 0.0878085
	speed: 0.1203s/iter; left time: 8674.7251s
	iters: 3600, epoch: 4 | loss: 0.0985364
	speed: 0.1204s/iter; left time: 8668.3959s
	iters: 3700, epoch: 4 | loss: 0.0910970
	speed: 0.1204s/iter; left time: 8654.5903s
	iters: 3800, epoch: 4 | loss: 0.0913839
	speed: 0.1207s/iter; left time: 8662.8658s
	iters: 3900, epoch: 4 | loss: 0.0918390
	speed: 0.1199s/iter; left time: 8595.0173s
	iters: 4000, epoch: 4 | loss: 0.1008365
	speed: 0.1201s/iter; left time: 8596.1364s
	iters: 4100, epoch: 4 | loss: 0.0926459
	speed: 0.1206s/iter; left time: 8622.4651s
	iters: 4200, epoch: 4 | loss: 0.0991397
	speed: 0.1197s/iter; left time: 8546.1725s
	iters: 4300, epoch: 4 | loss: 0.0954166
	speed: 0.1205s/iter; left time: 8587.7673s
	iters: 4400, epoch: 4 | loss: 0.0878920
	speed: 0.1206s/iter; left time: 8586.9872s
Epoch: 4 cost time: 00h:08m:45.93s
Epoch: 4 | Train Loss: 0.0984264 Vali Loss: 0.1281532 Test Loss: 0.1525455
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.1027972
	speed: 1.4323s/iter; left time: 101743.8017s
	iters: 200, epoch: 5 | loss: 0.1047456
	speed: 0.1204s/iter; left time: 8539.9559s
	iters: 300, epoch: 5 | loss: 0.0907510
	speed: 0.1207s/iter; left time: 8549.4724s
	iters: 400, epoch: 5 | loss: 0.0943936
	speed: 0.1208s/iter; left time: 8542.8848s
	iters: 500, epoch: 5 | loss: 0.0821496
	speed: 0.1206s/iter; left time: 8521.0863s
	iters: 600, epoch: 5 | loss: 0.0936060
	speed: 0.1201s/iter; left time: 8470.2102s
	iters: 700, epoch: 5 | loss: 0.0996595
	speed: 0.1208s/iter; left time: 8508.2723s
	iters: 800, epoch: 5 | loss: 0.0979459
	speed: 0.1206s/iter; left time: 8482.4131s
	iters: 900, epoch: 5 | loss: 0.1001264
	speed: 0.1202s/iter; left time: 8445.8160s
	iters: 1000, epoch: 5 | loss: 0.1090219
	speed: 0.1204s/iter; left time: 8447.3211s
	iters: 1100, epoch: 5 | loss: 0.1011967
	speed: 0.1205s/iter; left time: 8440.3294s
	iters: 1200, epoch: 5 | loss: 0.0915010
	speed: 0.1203s/iter; left time: 8414.2945s
	iters: 1300, epoch: 5 | loss: 0.1061302
	speed: 0.1205s/iter; left time: 8418.3765s
	iters: 1400, epoch: 5 | loss: 0.1118270
	speed: 0.1199s/iter; left time: 8359.0774s
	iters: 1500, epoch: 5 | loss: 0.0901711
	speed: 0.1205s/iter; left time: 8389.0106s
	iters: 1600, epoch: 5 | loss: 0.0990031
	speed: 0.1199s/iter; left time: 8340.3583s
	iters: 1700, epoch: 5 | loss: 0.1073154
	speed: 0.1205s/iter; left time: 8370.5610s
	iters: 1800, epoch: 5 | loss: 0.0957215
	speed: 0.1208s/iter; left time: 8375.3749s
	iters: 1900, epoch: 5 | loss: 0.0969568
	speed: 0.1204s/iter; left time: 8337.6589s
	iters: 2000, epoch: 5 | loss: 0.1063399
	speed: 0.1204s/iter; left time: 8324.2537s
	iters: 2100, epoch: 5 | loss: 0.1092876
	speed: 0.1202s/iter; left time: 8296.8827s
	iters: 2200, epoch: 5 | loss: 0.0891375
	speed: 0.1197s/iter; left time: 8251.7040s
	iters: 2300, epoch: 5 | loss: 0.0779103
	speed: 0.1196s/iter; left time: 8235.1469s
	iters: 2400, epoch: 5 | loss: 0.0807228
	speed: 0.1204s/iter; left time: 8276.7003s
	iters: 2500, epoch: 5 | loss: 0.0742790
	speed: 0.1200s/iter; left time: 8237.0216s
	iters: 2600, epoch: 5 | loss: 0.0908970
	speed: 0.1200s/iter; left time: 8222.8659s
	iters: 2700, epoch: 5 | loss: 0.1129368
	speed: 0.1202s/iter; left time: 8228.0971s
	iters: 2800, epoch: 5 | loss: 0.0733277
	speed: 0.1203s/iter; left time: 8220.7651s
	iters: 2900, epoch: 5 | loss: 0.1080936
	speed: 0.1207s/iter; left time: 8237.3385s
	iters: 3000, epoch: 5 | loss: 0.0774377
	speed: 0.1202s/iter; left time: 8188.8571s
	iters: 3100, epoch: 5 | loss: 0.0847868
	speed: 0.1197s/iter; left time: 8142.6788s
	iters: 3200, epoch: 5 | loss: 0.0902236
	speed: 0.1199s/iter; left time: 8145.1479s
	iters: 3300, epoch: 5 | loss: 0.0947069
	speed: 0.1199s/iter; left time: 8136.4458s
	iters: 3400, epoch: 5 | loss: 0.0958610
	speed: 0.1202s/iter; left time: 8141.4599s
	iters: 3500, epoch: 5 | loss: 0.0908997
	speed: 0.1189s/iter; left time: 8041.8481s
	iters: 3600, epoch: 5 | loss: 0.0939663
	speed: 0.1187s/iter; left time: 8019.7759s
	iters: 3700, epoch: 5 | loss: 0.0827342
	speed: 0.1202s/iter; left time: 8108.7739s
	iters: 3800, epoch: 5 | loss: 0.1009660
	speed: 0.1207s/iter; left time: 8127.2106s
	iters: 3900, epoch: 5 | loss: 0.0889867
	speed: 0.1202s/iter; left time: 8080.3905s
	iters: 4000, epoch: 5 | loss: 0.0949150
	speed: 0.1204s/iter; left time: 8080.9788s
	iters: 4100, epoch: 5 | loss: 0.1014487
	speed: 0.1201s/iter; left time: 8050.2590s
	iters: 4200, epoch: 5 | loss: 0.0968869
	speed: 0.1199s/iter; left time: 8023.4169s
	iters: 4300, epoch: 5 | loss: 0.0901529
	speed: 0.1205s/iter; left time: 8056.6744s
	iters: 4400, epoch: 5 | loss: 0.0915154
	speed: 0.1201s/iter; left time: 8012.8253s
Epoch: 5 cost time: 00h:08m:54.91s
Epoch: 5 | Train Loss: 0.0934047 Vali Loss: 0.1274233 Test Loss: 0.1514446
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0924059
	speed: 1.4311s/iter; left time: 95295.5926s
	iters: 200, epoch: 6 | loss: 0.0953507
	speed: 0.1173s/iter; left time: 7801.3269s
	iters: 300, epoch: 6 | loss: 0.0743414
	speed: 0.1204s/iter; left time: 7994.2597s
	iters: 400, epoch: 6 | loss: 0.0888031
	speed: 0.1205s/iter; left time: 7991.1817s
	iters: 500, epoch: 6 | loss: 0.1043609
	speed: 0.1204s/iter; left time: 7970.6442s
	iters: 600, epoch: 6 | loss: 0.0847825
	speed: 0.1201s/iter; left time: 7938.0247s
	iters: 700, epoch: 6 | loss: 0.1001649
	speed: 0.1203s/iter; left time: 7940.4229s
	iters: 800, epoch: 6 | loss: 0.1008426
	speed: 0.1203s/iter; left time: 7925.8063s
	iters: 900, epoch: 6 | loss: 0.0914951
	speed: 0.1209s/iter; left time: 7954.7739s
	iters: 1000, epoch: 6 | loss: 0.0961552
	speed: 0.1204s/iter; left time: 7906.1569s
	iters: 1100, epoch: 6 | loss: 0.0863231
	speed: 0.1204s/iter; left time: 7897.5717s
	iters: 1200, epoch: 6 | loss: 0.0925186
	speed: 0.1207s/iter; left time: 7904.2000s
	iters: 1300, epoch: 6 | loss: 0.0857735
	speed: 0.1202s/iter; left time: 7862.4778s
	iters: 1400, epoch: 6 | loss: 0.0983386
	speed: 0.1197s/iter; left time: 7814.0619s
	iters: 1500, epoch: 6 | loss: 0.0876124
	speed: 0.1194s/iter; left time: 7781.5253s
	iters: 1600, epoch: 6 | loss: 0.0781590
	speed: 0.1201s/iter; left time: 7816.9930s
	iters: 1700, epoch: 6 | loss: 0.0933763
	speed: 0.1206s/iter; left time: 7836.4507s
	iters: 1800, epoch: 6 | loss: 0.0982791
	speed: 0.1207s/iter; left time: 7830.7647s
	iters: 1900, epoch: 6 | loss: 0.0728418
	speed: 0.1201s/iter; left time: 7781.1932s
	iters: 2000, epoch: 6 | loss: 0.0914764
	speed: 0.1201s/iter; left time: 7770.7539s
	iters: 2100, epoch: 6 | loss: 0.0815687
	speed: 0.1194s/iter; left time: 7711.6663s
	iters: 2200, epoch: 6 | loss: 0.0897236
	speed: 0.1204s/iter; left time: 7765.1621s
	iters: 2300, epoch: 6 | loss: 0.0844050
	speed: 0.1204s/iter; left time: 7752.0869s
	iters: 2400, epoch: 6 | loss: 0.0881767
	speed: 0.1208s/iter; left time: 7766.4122s
	iters: 2500, epoch: 6 | loss: 0.0834182
	speed: 0.1203s/iter; left time: 7725.0040s
	iters: 2600, epoch: 6 | loss: 0.0942059
	speed: 0.1198s/iter; left time: 7678.0162s
	iters: 2700, epoch: 6 | loss: 0.0970327
	speed: 0.1199s/iter; left time: 7672.3607s
	iters: 2800, epoch: 6 | loss: 0.0989593
	speed: 0.1207s/iter; left time: 7713.4506s
	iters: 2900, epoch: 6 | loss: 0.0968164
	speed: 0.1206s/iter; left time: 7692.3892s
	iters: 3000, epoch: 6 | loss: 0.0916561
	speed: 0.1201s/iter; left time: 7649.4173s
	iters: 3100, epoch: 6 | loss: 0.0938281
	speed: 0.1203s/iter; left time: 7650.9546s
	iters: 3200, epoch: 6 | loss: 0.0751842
	speed: 0.1097s/iter; left time: 6966.2813s
	iters: 3300, epoch: 6 | loss: 0.0846767
	speed: 0.1133s/iter; left time: 7180.7382s
	iters: 3400, epoch: 6 | loss: 0.0979014
	speed: 0.1207s/iter; left time: 7639.1621s
	iters: 3500, epoch: 6 | loss: 0.0967091
	speed: 0.1209s/iter; left time: 7642.1549s
	iters: 3600, epoch: 6 | loss: 0.0888710
	speed: 0.1157s/iter; left time: 7296.9831s
	iters: 3700, epoch: 6 | loss: 0.0812877
	speed: 0.1018s/iter; left time: 6413.1401s
	iters: 3800, epoch: 6 | loss: 0.0757051
	speed: 0.1020s/iter; left time: 6414.7247s
	iters: 3900, epoch: 6 | loss: 0.0898106
	speed: 0.1018s/iter; left time: 6392.8255s
	iters: 4000, epoch: 6 | loss: 0.1019688
	speed: 0.1021s/iter; left time: 6397.8908s
	iters: 4100, epoch: 6 | loss: 0.0886026
	speed: 0.1021s/iter; left time: 6390.1358s
	iters: 4200, epoch: 6 | loss: 0.0841476
	speed: 0.1024s/iter; left time: 6397.6305s
	iters: 4300, epoch: 6 | loss: 0.0868416
	speed: 0.1119s/iter; left time: 6980.2972s
	iters: 4400, epoch: 6 | loss: 0.0976313
	speed: 0.1023s/iter; left time: 6373.2837s
Epoch: 6 cost time: 00h:08m:37.72s
Epoch: 6 | Train Loss: 0.0896105 Vali Loss: 0.1277131 Test Loss: 0.1531950
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.04277150332927704, rmse:0.20681272447109222, mae:0.14383640885353088, rse:0.7167763113975525
success delete checkpoints
Intermediate time for GB and pred_len 168: 01h:08m:01.96s

Intermediate time for GB: 04h:29m:17.75s


=== Starting experiments for country: ES ===


=== Starting experiments for pred_len: 24 ===

train 85803
val 18651
test 18651
[2024-11-01 05:43:05,597] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 05:43:06,809] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 05:43:06,810] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 05:43:06,810] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 05:43:06,912] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 05:43:06,912] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 05:43:07,552] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 05:43:07,554] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 05:43:07,554] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 05:43:07,555] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 05:43:07,555] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 05:43:07,555] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 05:43:07,556] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 05:43:07,556] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 05:43:07,556] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 05:43:07,556] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 05:43:07,840] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 05:43:07,841] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 05:43:07,841] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.62 GB, percent = 9.9%
[2024-11-01 05:43:08,005] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 05:43:08,006] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 05:43:08,007] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.62 GB, percent = 9.9%
[2024-11-01 05:43:08,007] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 05:43:08,137] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 05:43:08,138] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 05:43:08,138] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.62 GB, percent = 9.9%
[2024-11-01 05:43:08,139] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 05:43:08,139] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 05:43:08,139] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 05:43:08,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 05:43:08,140] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 05:43:08,140] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 05:43:08,140] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 05:43:08,140] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 05:43:08,140] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f5e81f8ef90>
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 05:43:08,141] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 05:43:08,142] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 05:43:08,143] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 05:43:08,143] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1790063
	speed: 0.1624s/iter; left time: 8690.7018s
	iters: 200, epoch: 1 | loss: 0.1687252
	speed: 0.1135s/iter; left time: 6063.5858s
	iters: 300, epoch: 1 | loss: 0.1309537
	speed: 0.1131s/iter; left time: 6030.1079s
	iters: 400, epoch: 1 | loss: 0.1245550
	speed: 0.1135s/iter; left time: 6038.4411s
	iters: 500, epoch: 1 | loss: 0.1051500
	speed: 0.1205s/iter; left time: 6402.1524s
	iters: 600, epoch: 1 | loss: 0.0886984
	speed: 0.1310s/iter; left time: 6945.6594s
	iters: 700, epoch: 1 | loss: 0.0941334
	speed: 0.1308s/iter; left time: 6920.4657s
	iters: 800, epoch: 1 | loss: 0.0780938
	speed: 0.1310s/iter; left time: 6919.9708s
	iters: 900, epoch: 1 | loss: 0.0840373
	speed: 0.1310s/iter; left time: 6905.6371s
	iters: 1000, epoch: 1 | loss: 0.0893998
	speed: 0.1310s/iter; left time: 6891.6378s
	iters: 1100, epoch: 1 | loss: 0.0767727
	speed: 0.1308s/iter; left time: 6869.0145s
	iters: 1200, epoch: 1 | loss: 0.0874630
	speed: 0.1307s/iter; left time: 6852.2000s
	iters: 1300, epoch: 1 | loss: 0.0802690
	speed: 0.1310s/iter; left time: 6856.4015s
	iters: 1400, epoch: 1 | loss: 0.0984690
	speed: 0.1291s/iter; left time: 6740.3281s
	iters: 1500, epoch: 1 | loss: 0.0814931
	speed: 0.1309s/iter; left time: 6821.9413s
	iters: 1600, epoch: 1 | loss: 0.0775438
	speed: 0.1310s/iter; left time: 6815.8779s
	iters: 1700, epoch: 1 | loss: 0.0801652
	speed: 0.1310s/iter; left time: 6801.1195s
	iters: 1800, epoch: 1 | loss: 0.0743842
	speed: 0.1308s/iter; left time: 6777.5319s
	iters: 1900, epoch: 1 | loss: 0.0854426
	speed: 0.1314s/iter; left time: 6796.3543s
	iters: 2000, epoch: 1 | loss: 0.0780391
	speed: 0.1310s/iter; left time: 6761.8078s
	iters: 2100, epoch: 1 | loss: 0.0724551
	speed: 0.1307s/iter; left time: 6734.6830s
	iters: 2200, epoch: 1 | loss: 0.0770094
	speed: 0.1310s/iter; left time: 6736.1966s
	iters: 2300, epoch: 1 | loss: 0.0864393
	speed: 0.1311s/iter; left time: 6726.9443s
	iters: 2400, epoch: 1 | loss: 0.0777969
	speed: 0.1310s/iter; left time: 6711.2728s
	iters: 2500, epoch: 1 | loss: 0.0745067
	speed: 0.1307s/iter; left time: 6683.6805s
	iters: 2600, epoch: 1 | loss: 0.0927263
	speed: 0.1310s/iter; left time: 6682.8800s
Epoch: 1 cost time: 00h:05m:44.41s
Epoch: 1 | Train Loss: 0.0993755 Vali Loss: 0.0662276 Test Loss: 0.0754743
Validation loss decreased (inf --> 0.066228).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0936529
	speed: 1.1660s/iter; left time: 59281.6643s
	iters: 200, epoch: 2 | loss: 0.0912237
	speed: 0.1198s/iter; left time: 6078.1371s
	iters: 300, epoch: 2 | loss: 0.0807760
	speed: 0.1211s/iter; left time: 6132.6657s
	iters: 400, epoch: 2 | loss: 0.0864775
	speed: 0.1209s/iter; left time: 6111.5642s
	iters: 500, epoch: 2 | loss: 0.0780736
	speed: 0.1206s/iter; left time: 6083.3792s
	iters: 600, epoch: 2 | loss: 0.0745789
	speed: 0.1207s/iter; left time: 6074.2224s
	iters: 700, epoch: 2 | loss: 0.0697930
	speed: 0.1209s/iter; left time: 6073.8950s
	iters: 800, epoch: 2 | loss: 0.0780450
	speed: 0.1212s/iter; left time: 6076.2172s
	iters: 900, epoch: 2 | loss: 0.0729557
	speed: 0.1199s/iter; left time: 6001.4255s
	iters: 1000, epoch: 2 | loss: 0.0800805
	speed: 0.1191s/iter; left time: 5945.6363s
	iters: 1100, epoch: 2 | loss: 0.0736994
	speed: 0.1182s/iter; left time: 5890.0203s
	iters: 1200, epoch: 2 | loss: 0.0718818
	speed: 0.1184s/iter; left time: 5891.3732s
	iters: 1300, epoch: 2 | loss: 0.0728408
	speed: 0.1186s/iter; left time: 5889.2283s
	iters: 1400, epoch: 2 | loss: 0.0732936
	speed: 0.1211s/iter; left time: 6001.6212s
	iters: 1500, epoch: 2 | loss: 0.0862661
	speed: 0.1210s/iter; left time: 5979.7951s
	iters: 1600, epoch: 2 | loss: 0.0885015
	speed: 0.1187s/iter; left time: 5854.8532s
	iters: 1700, epoch: 2 | loss: 0.0699046
	speed: 0.1182s/iter; left time: 5819.2530s
	iters: 1800, epoch: 2 | loss: 0.0673015
	speed: 0.1183s/iter; left time: 5812.3248s
	iters: 1900, epoch: 2 | loss: 0.0852279
	speed: 0.1214s/iter; left time: 5954.3076s
	iters: 2000, epoch: 2 | loss: 0.0779036
	speed: 0.1208s/iter; left time: 5912.7780s
	iters: 2100, epoch: 2 | loss: 0.0709876
	speed: 0.1209s/iter; left time: 5905.0322s
	iters: 2200, epoch: 2 | loss: 0.0774782
	speed: 0.1209s/iter; left time: 5891.9709s
	iters: 2300, epoch: 2 | loss: 0.0751852
	speed: 0.1196s/iter; left time: 5817.9519s
	iters: 2400, epoch: 2 | loss: 0.0819853
	speed: 0.1015s/iter; left time: 4926.7577s
	iters: 2500, epoch: 2 | loss: 0.0652728
	speed: 0.1038s/iter; left time: 5026.9045s
	iters: 2600, epoch: 2 | loss: 0.0770506
	speed: 0.1124s/iter; left time: 5434.5683s
Epoch: 2 cost time: 00h:05m:16.29s
Epoch: 2 | Train Loss: 0.0773266 Vali Loss: 0.0630829 Test Loss: 0.0720199
Validation loss decreased (0.066228 --> 0.063083).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0664506
	speed: 1.0032s/iter; left time: 48313.6279s
	iters: 200, epoch: 3 | loss: 0.0780226
	speed: 0.1209s/iter; left time: 5811.9929s
	iters: 300, epoch: 3 | loss: 0.0809838
	speed: 0.1209s/iter; left time: 5799.4593s
	iters: 400, epoch: 3 | loss: 0.0751593
	speed: 0.1209s/iter; left time: 5786.5951s
	iters: 500, epoch: 3 | loss: 0.0690148
	speed: 0.1214s/iter; left time: 5797.1837s
	iters: 600, epoch: 3 | loss: 0.0651948
	speed: 0.1200s/iter; left time: 5721.0269s
	iters: 700, epoch: 3 | loss: 0.0696828
	speed: 0.1212s/iter; left time: 5766.1125s
	iters: 800, epoch: 3 | loss: 0.0909723
	speed: 0.1209s/iter; left time: 5737.7699s
	iters: 900, epoch: 3 | loss: 0.0693156
	speed: 0.1213s/iter; left time: 5742.6098s
	iters: 1000, epoch: 3 | loss: 0.0763046
	speed: 0.1213s/iter; left time: 5734.0594s
	iters: 1100, epoch: 3 | loss: 0.0654815
	speed: 0.1212s/iter; left time: 5717.1370s
	iters: 1200, epoch: 3 | loss: 0.0816431
	speed: 0.1216s/iter; left time: 5723.7706s
	iters: 1300, epoch: 3 | loss: 0.0731011
	speed: 0.1213s/iter; left time: 5697.6374s
	iters: 1400, epoch: 3 | loss: 0.0798532
	speed: 0.1210s/iter; left time: 5671.0190s
	iters: 1500, epoch: 3 | loss: 0.0781588
	speed: 0.1209s/iter; left time: 5653.9723s
	iters: 1600, epoch: 3 | loss: 0.0688082
	speed: 0.1209s/iter; left time: 5642.6452s
	iters: 1700, epoch: 3 | loss: 0.0722890
	speed: 0.1216s/iter; left time: 5662.5405s
	iters: 1800, epoch: 3 | loss: 0.0578647
	speed: 0.1211s/iter; left time: 5628.1987s
	iters: 1900, epoch: 3 | loss: 0.0831098
	speed: 0.1209s/iter; left time: 5606.5359s
	iters: 2000, epoch: 3 | loss: 0.0657302
	speed: 0.1200s/iter; left time: 5548.9515s
	iters: 2100, epoch: 3 | loss: 0.0686098
	speed: 0.1208s/iter; left time: 5574.4165s
	iters: 2200, epoch: 3 | loss: 0.0793400
	speed: 0.1210s/iter; left time: 5574.9651s
	iters: 2300, epoch: 3 | loss: 0.0739723
	speed: 0.1209s/iter; left time: 5555.0098s
	iters: 2400, epoch: 3 | loss: 0.0883555
	speed: 0.1213s/iter; left time: 5561.7231s
	iters: 2500, epoch: 3 | loss: 0.0636316
	speed: 0.1209s/iter; left time: 5530.1957s
	iters: 2600, epoch: 3 | loss: 0.0704639
	speed: 0.1206s/iter; left time: 5506.7030s
Epoch: 3 cost time: 00h:05m:24.85s
Epoch: 3 | Train Loss: 0.0731855 Vali Loss: 0.0623539 Test Loss: 0.0720562
Validation loss decreased (0.063083 --> 0.062354).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0695748
	speed: 1.0186s/iter; left time: 46324.1427s
	iters: 200, epoch: 4 | loss: 0.0786053
	speed: 0.1198s/iter; left time: 5435.5754s
	iters: 300, epoch: 4 | loss: 0.0584018
	speed: 0.1187s/iter; left time: 5374.0002s
	iters: 400, epoch: 4 | loss: 0.0929034
	speed: 0.1199s/iter; left time: 5417.3815s
	iters: 500, epoch: 4 | loss: 0.0779471
	speed: 0.1213s/iter; left time: 5468.8569s
	iters: 600, epoch: 4 | loss: 0.0695291
	speed: 0.1193s/iter; left time: 5366.4642s
	iters: 700, epoch: 4 | loss: 0.0666811
	speed: 0.1190s/iter; left time: 5338.7525s
	iters: 800, epoch: 4 | loss: 0.0734229
	speed: 0.1211s/iter; left time: 5420.3805s
	iters: 900, epoch: 4 | loss: 0.0612417
	speed: 0.1208s/iter; left time: 5398.3621s
	iters: 1000, epoch: 4 | loss: 0.0748140
	speed: 0.1201s/iter; left time: 5354.0281s
	iters: 1100, epoch: 4 | loss: 0.0748632
	speed: 0.1018s/iter; left time: 4527.8624s
	iters: 1200, epoch: 4 | loss: 0.0688734
	speed: 0.1019s/iter; left time: 4519.9893s
	iters: 1300, epoch: 4 | loss: 0.0741981
	speed: 0.1162s/iter; left time: 5144.5647s
	iters: 1400, epoch: 4 | loss: 0.0658868
	speed: 0.1207s/iter; left time: 5331.3798s
	iters: 1500, epoch: 4 | loss: 0.0664924
	speed: 0.1209s/iter; left time: 5330.1389s
	iters: 1600, epoch: 4 | loss: 0.0765673
	speed: 0.1204s/iter; left time: 5294.5138s
	iters: 1700, epoch: 4 | loss: 0.0755662
	speed: 0.1186s/iter; left time: 5202.3408s
	iters: 1800, epoch: 4 | loss: 0.0777128
	speed: 0.1213s/iter; left time: 5309.3576s
	iters: 1900, epoch: 4 | loss: 0.0851511
	speed: 0.1204s/iter; left time: 5258.1519s
	iters: 2000, epoch: 4 | loss: 0.0781193
	speed: 0.1202s/iter; left time: 5236.3739s
	iters: 2100, epoch: 4 | loss: 0.0825148
	speed: 0.1209s/iter; left time: 5255.3762s
	iters: 2200, epoch: 4 | loss: 0.0718397
	speed: 0.1200s/iter; left time: 5204.7438s
	iters: 2300, epoch: 4 | loss: 0.0678933
	speed: 0.1209s/iter; left time: 5233.9092s
	iters: 2400, epoch: 4 | loss: 0.0727424
	speed: 0.1208s/iter; left time: 5214.8152s
	iters: 2500, epoch: 4 | loss: 0.0754367
	speed: 0.1191s/iter; left time: 5132.0321s
	iters: 2600, epoch: 4 | loss: 0.0694987
	speed: 0.1200s/iter; left time: 5156.4168s
Epoch: 4 cost time: 00h:05m:18.55s
Epoch: 4 | Train Loss: 0.0712121 Vali Loss: 0.0611709 Test Loss: 0.0710917
Validation loss decreased (0.062354 --> 0.061171).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0630679
	speed: 1.0193s/iter; left time: 43623.6654s
	iters: 200, epoch: 5 | loss: 0.0689823
	speed: 0.1209s/iter; left time: 5163.3937s
	iters: 300, epoch: 5 | loss: 0.0810203
	speed: 0.1192s/iter; left time: 5076.8151s
	iters: 400, epoch: 5 | loss: 0.0599910
	speed: 0.1207s/iter; left time: 5130.0472s
	iters: 500, epoch: 5 | loss: 0.0720650
	speed: 0.1208s/iter; left time: 5122.3364s
	iters: 600, epoch: 5 | loss: 0.0723064
	speed: 0.1202s/iter; left time: 5083.7421s
	iters: 700, epoch: 5 | loss: 0.0714625
	speed: 0.1202s/iter; left time: 5073.3234s
	iters: 800, epoch: 5 | loss: 0.0736922
	speed: 0.1199s/iter; left time: 5046.8219s
	iters: 900, epoch: 5 | loss: 0.0730744
	speed: 0.1208s/iter; left time: 5073.4437s
	iters: 1000, epoch: 5 | loss: 0.0762590
	speed: 0.1210s/iter; left time: 5068.3875s
	iters: 1100, epoch: 5 | loss: 0.0776123
	speed: 0.1213s/iter; left time: 5069.5665s
	iters: 1200, epoch: 5 | loss: 0.0766415
	speed: 0.1201s/iter; left time: 5005.8368s
	iters: 1300, epoch: 5 | loss: 0.0700914
	speed: 0.1220s/iter; left time: 5074.9620s
	iters: 1400, epoch: 5 | loss: 0.0647124
	speed: 0.1208s/iter; left time: 5011.9821s
	iters: 1500, epoch: 5 | loss: 0.0750828
	speed: 0.1209s/iter; left time: 5005.2576s
	iters: 1600, epoch: 5 | loss: 0.0726999
	speed: 0.1212s/iter; left time: 5007.2251s
	iters: 1700, epoch: 5 | loss: 0.0699233
	speed: 0.1209s/iter; left time: 4981.4279s
	iters: 1800, epoch: 5 | loss: 0.0737871
	speed: 0.1209s/iter; left time: 4967.9873s
	iters: 1900, epoch: 5 | loss: 0.0672794
	speed: 0.1209s/iter; left time: 4955.5860s
	iters: 2000, epoch: 5 | loss: 0.0721373
	speed: 0.1206s/iter; left time: 4932.6615s
	iters: 2100, epoch: 5 | loss: 0.0577321
	speed: 0.1192s/iter; left time: 4861.3750s
	iters: 2200, epoch: 5 | loss: 0.0599433
	speed: 0.1208s/iter; left time: 4916.6219s
	iters: 2300, epoch: 5 | loss: 0.0708436
	speed: 0.1210s/iter; left time: 4913.0122s
	iters: 2400, epoch: 5 | loss: 0.0647120
	speed: 0.1209s/iter; left time: 4894.8729s
	iters: 2500, epoch: 5 | loss: 0.0707248
	speed: 0.1202s/iter; left time: 4854.2203s
	iters: 2600, epoch: 5 | loss: 0.0699116
	speed: 0.1213s/iter; left time: 4888.7165s
Epoch: 5 cost time: 00h:05m:24.05s
Epoch: 5 | Train Loss: 0.0699275 Vali Loss: 0.0589704 Test Loss: 0.0681652
Validation loss decreased (0.061171 --> 0.058970).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0585817
	speed: 1.0192s/iter; left time: 40886.2149s
	iters: 200, epoch: 6 | loss: 0.0743628
	speed: 0.1189s/iter; left time: 4759.6888s
	iters: 300, epoch: 6 | loss: 0.0816830
	speed: 0.1211s/iter; left time: 4835.6442s
	iters: 400, epoch: 6 | loss: 0.0686249
	speed: 0.1209s/iter; left time: 4814.2293s
	iters: 500, epoch: 6 | loss: 0.0658081
	speed: 0.1211s/iter; left time: 4810.8043s
	iters: 600, epoch: 6 | loss: 0.0699370
	speed: 0.1208s/iter; left time: 4786.1248s
	iters: 700, epoch: 6 | loss: 0.0579729
	speed: 0.1207s/iter; left time: 4770.6786s
	iters: 800, epoch: 6 | loss: 0.0594627
	speed: 0.1212s/iter; left time: 4777.6334s
	iters: 900, epoch: 6 | loss: 0.0765333
	speed: 0.1212s/iter; left time: 4765.4845s
	iters: 1000, epoch: 6 | loss: 0.0679004
	speed: 0.1210s/iter; left time: 4745.3763s
	iters: 1100, epoch: 6 | loss: 0.0628908
	speed: 0.1207s/iter; left time: 4721.8951s
	iters: 1200, epoch: 6 | loss: 0.0643912
	speed: 0.1207s/iter; left time: 4707.3291s
	iters: 1300, epoch: 6 | loss: 0.0718672
	speed: 0.1209s/iter; left time: 4705.7991s
	iters: 1400, epoch: 6 | loss: 0.0650968
	speed: 0.1202s/iter; left time: 4666.9745s
	iters: 1500, epoch: 6 | loss: 0.0803147
	speed: 0.1208s/iter; left time: 4676.7782s
	iters: 1600, epoch: 6 | loss: 0.0721307
	speed: 0.1209s/iter; left time: 4669.6062s
	iters: 1700, epoch: 6 | loss: 0.0664947
	speed: 0.1213s/iter; left time: 4671.1980s
	iters: 1800, epoch: 6 | loss: 0.0713947
	speed: 0.1209s/iter; left time: 4645.8173s
	iters: 1900, epoch: 6 | loss: 0.0666180
	speed: 0.1211s/iter; left time: 4641.0913s
	iters: 2000, epoch: 6 | loss: 0.0742579
	speed: 0.1209s/iter; left time: 4620.1656s
	iters: 2100, epoch: 6 | loss: 0.0744588
	speed: 0.1205s/iter; left time: 4593.3489s
	iters: 2200, epoch: 6 | loss: 0.0583553
	speed: 0.1226s/iter; left time: 4662.3897s
	iters: 2300, epoch: 6 | loss: 0.0706729
	speed: 0.1211s/iter; left time: 4591.5552s
	iters: 2400, epoch: 6 | loss: 0.0550006
	speed: 0.1205s/iter; left time: 4556.9942s
	iters: 2500, epoch: 6 | loss: 0.0605696
	speed: 0.1210s/iter; left time: 4563.7298s
	iters: 2600, epoch: 6 | loss: 0.0701861
	speed: 0.1211s/iter; left time: 4553.7139s
Epoch: 6 cost time: 00h:05m:24.48s
Epoch: 6 | Train Loss: 0.0689073 Vali Loss: 0.0598308 Test Loss: 0.0697114
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0657653
	speed: 1.0131s/iter; left time: 37926.2136s
	iters: 200, epoch: 7 | loss: 0.0665484
	speed: 0.1206s/iter; left time: 4503.2273s
	iters: 300, epoch: 7 | loss: 0.0624240
	speed: 0.1204s/iter; left time: 4484.8498s
	iters: 400, epoch: 7 | loss: 0.0643224
	speed: 0.1207s/iter; left time: 4481.9623s
	iters: 500, epoch: 7 | loss: 0.0836057
	speed: 0.1207s/iter; left time: 4471.9528s
	iters: 600, epoch: 7 | loss: 0.0660850
	speed: 0.1210s/iter; left time: 4467.5989s
	iters: 700, epoch: 7 | loss: 0.0869880
	speed: 0.1194s/iter; left time: 4397.0291s
	iters: 800, epoch: 7 | loss: 0.0704906
	speed: 0.1212s/iter; left time: 4453.1179s
	iters: 900, epoch: 7 | loss: 0.0647015
	speed: 0.1209s/iter; left time: 4430.5611s
	iters: 1000, epoch: 7 | loss: 0.0806929
	speed: 0.1209s/iter; left time: 4417.3410s
	iters: 1100, epoch: 7 | loss: 0.0759010
	speed: 0.1204s/iter; left time: 4386.2943s
	iters: 1200, epoch: 7 | loss: 0.0615634
	speed: 0.1207s/iter; left time: 4383.8192s
	iters: 1300, epoch: 7 | loss: 0.0764042
	speed: 0.1183s/iter; left time: 4288.3717s
	iters: 1400, epoch: 7 | loss: 0.0674644
	speed: 0.1039s/iter; left time: 3753.1669s
	iters: 1500, epoch: 7 | loss: 0.0740616
	speed: 0.1043s/iter; left time: 3758.6648s
	iters: 1600, epoch: 7 | loss: 0.0792665
	speed: 0.1040s/iter; left time: 3738.7147s
	iters: 1700, epoch: 7 | loss: 0.0690767
	speed: 0.1042s/iter; left time: 3732.7651s
	iters: 1800, epoch: 7 | loss: 0.0598226
	speed: 0.1077s/iter; left time: 3847.3043s
	iters: 1900, epoch: 7 | loss: 0.0678398
	speed: 0.1063s/iter; left time: 3789.7342s
	iters: 2000, epoch: 7 | loss: 0.0747984
	speed: 0.1045s/iter; left time: 3715.1699s
	iters: 2100, epoch: 7 | loss: 0.0712984
	speed: 0.1041s/iter; left time: 3688.5869s
	iters: 2200, epoch: 7 | loss: 0.0657289
	speed: 0.1077s/iter; left time: 3807.1994s
	iters: 2300, epoch: 7 | loss: 0.0730863
	speed: 0.1216s/iter; left time: 4282.8606s
	iters: 2400, epoch: 7 | loss: 0.0687535
	speed: 0.1212s/iter; left time: 4260.1095s
	iters: 2500, epoch: 7 | loss: 0.0626324
	speed: 0.1212s/iter; left time: 4245.7969s
	iters: 2600, epoch: 7 | loss: 0.0694073
	speed: 0.1207s/iter; left time: 4217.0464s
Epoch: 7 cost time: 00h:05m:10.08s
Epoch: 7 | Train Loss: 0.0681056 Vali Loss: 0.0597853 Test Loss: 0.0696563
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0955697
	speed: 0.9884s/iter; left time: 34351.4703s
	iters: 200, epoch: 8 | loss: 0.0681316
	speed: 0.1205s/iter; left time: 4176.8794s
	iters: 300, epoch: 8 | loss: 0.0796526
	speed: 0.1206s/iter; left time: 4168.8573s
	iters: 400, epoch: 8 | loss: 0.0672699
	speed: 0.1206s/iter; left time: 4155.2464s
	iters: 500, epoch: 8 | loss: 0.0579451
	speed: 0.1211s/iter; left time: 4161.6305s
	iters: 600, epoch: 8 | loss: 0.0730144
	speed: 0.1208s/iter; left time: 4138.5426s
	iters: 700, epoch: 8 | loss: 0.0561597
	speed: 0.1208s/iter; left time: 4125.5295s
	iters: 800, epoch: 8 | loss: 0.0630030
	speed: 0.1209s/iter; left time: 4117.2168s
	iters: 900, epoch: 8 | loss: 0.0696586
	speed: 0.1208s/iter; left time: 4100.0669s
	iters: 1000, epoch: 8 | loss: 0.0760989
	speed: 0.1207s/iter; left time: 4085.5731s
	iters: 1100, epoch: 8 | loss: 0.0601159
	speed: 0.1207s/iter; left time: 4072.8285s
	iters: 1200, epoch: 8 | loss: 0.0697419
	speed: 0.1209s/iter; left time: 4069.1088s
	iters: 1300, epoch: 8 | loss: 0.0581929
	speed: 0.1207s/iter; left time: 4049.7350s
	iters: 1400, epoch: 8 | loss: 0.0630530
	speed: 0.1210s/iter; left time: 4047.8329s
	iters: 1500, epoch: 8 | loss: 0.0653922
	speed: 0.1207s/iter; left time: 4024.8266s
	iters: 1600, epoch: 8 | loss: 0.0719701
	speed: 0.1202s/iter; left time: 3996.2554s
	iters: 1700, epoch: 8 | loss: 0.0626506
	speed: 0.1187s/iter; left time: 3934.7344s
	iters: 1800, epoch: 8 | loss: 0.0601200
	speed: 0.1187s/iter; left time: 3922.0110s
	iters: 1900, epoch: 8 | loss: 0.0739461
	speed: 0.1184s/iter; left time: 3902.2806s
	iters: 2000, epoch: 8 | loss: 0.0698656
	speed: 0.1193s/iter; left time: 3921.0538s
	iters: 2100, epoch: 8 | loss: 0.0620731
	speed: 0.1195s/iter; left time: 3912.8978s
	iters: 2200, epoch: 8 | loss: 0.0645657
	speed: 0.1205s/iter; left time: 3933.9129s
	iters: 2300, epoch: 8 | loss: 0.0703310
	speed: 0.1202s/iter; left time: 3912.8405s
	iters: 2400, epoch: 8 | loss: 0.0673083
	speed: 0.1204s/iter; left time: 3906.0553s
	iters: 2500, epoch: 8 | loss: 0.0710015
	speed: 0.1207s/iter; left time: 3906.1880s
	iters: 2600, epoch: 8 | loss: 0.0631191
	speed: 0.1208s/iter; left time: 3896.6290s
Epoch: 8 cost time: 00h:05m:21.55s
Epoch: 8 | Train Loss: 0.0675166 Vali Loss: 0.0581114 Test Loss: 0.0668070
Validation loss decreased (0.058970 --> 0.058111).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0710958
	speed: 1.0242s/iter; left time: 32850.7383s
	iters: 200, epoch: 9 | loss: 0.0710134
	speed: 0.1202s/iter; left time: 3842.7428s
	iters: 300, epoch: 9 | loss: 0.0564387
	speed: 0.1201s/iter; left time: 3829.0666s
	iters: 400, epoch: 9 | loss: 0.0593314
	speed: 0.1202s/iter; left time: 3819.6406s
	iters: 500, epoch: 9 | loss: 0.0549250
	speed: 0.1214s/iter; left time: 3844.5622s
	iters: 600, epoch: 9 | loss: 0.0573312
	speed: 0.1207s/iter; left time: 3810.4766s
	iters: 700, epoch: 9 | loss: 0.0749223
	speed: 0.1187s/iter; left time: 3736.0753s
	iters: 800, epoch: 9 | loss: 0.0616827
	speed: 0.1209s/iter; left time: 3793.1171s
	iters: 900, epoch: 9 | loss: 0.0696181
	speed: 0.1209s/iter; left time: 3781.8642s
	iters: 1000, epoch: 9 | loss: 0.0527223
	speed: 0.1206s/iter; left time: 3759.6943s
	iters: 1100, epoch: 9 | loss: 0.0648112
	speed: 0.1204s/iter; left time: 3739.9555s
	iters: 1200, epoch: 9 | loss: 0.0737804
	speed: 0.1209s/iter; left time: 3744.7446s
	iters: 1300, epoch: 9 | loss: 0.0596698
	speed: 0.1209s/iter; left time: 3733.3668s
	iters: 1400, epoch: 9 | loss: 0.0660387
	speed: 0.1208s/iter; left time: 3716.3023s
	iters: 1500, epoch: 9 | loss: 0.0742668
	speed: 0.1195s/iter; left time: 3664.2769s
	iters: 1600, epoch: 9 | loss: 0.0563254
	speed: 0.1158s/iter; left time: 3541.6499s
	iters: 1700, epoch: 9 | loss: 0.0555071
	speed: 0.1204s/iter; left time: 3667.4328s
	iters: 1800, epoch: 9 | loss: 0.0757507
	speed: 0.1092s/iter; left time: 3317.3949s
	iters: 1900, epoch: 9 | loss: 0.0711249
	speed: 0.1211s/iter; left time: 3665.2564s
	iters: 2000, epoch: 9 | loss: 0.0721804
	speed: 0.1209s/iter; left time: 3647.8859s
	iters: 2100, epoch: 9 | loss: 0.0665950
	speed: 0.1208s/iter; left time: 3632.0443s
	iters: 2200, epoch: 9 | loss: 0.0581865
	speed: 0.1206s/iter; left time: 3615.4835s
	iters: 2300, epoch: 9 | loss: 0.0679084
	speed: 0.1206s/iter; left time: 3603.1639s
	iters: 2400, epoch: 9 | loss: 0.0549888
	speed: 0.1207s/iter; left time: 3593.8016s
	iters: 2500, epoch: 9 | loss: 0.0570390
	speed: 0.1216s/iter; left time: 3608.9673s
	iters: 2600, epoch: 9 | loss: 0.0600057
	speed: 0.1175s/iter; left time: 3475.3147s
Epoch: 9 cost time: 00h:05m:20.52s
Epoch: 9 | Train Loss: 0.0669224 Vali Loss: 0.0591406 Test Loss: 0.0683875
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0737776
	speed: 0.9680s/iter; left time: 28450.2405s
	iters: 200, epoch: 10 | loss: 0.0724111
	speed: 0.1086s/iter; left time: 3180.0918s
	iters: 300, epoch: 10 | loss: 0.0616018
	speed: 0.1188s/iter; left time: 3468.2310s
	iters: 400, epoch: 10 | loss: 0.0517321
	speed: 0.1200s/iter; left time: 3491.8455s
	iters: 500, epoch: 10 | loss: 0.0636202
	speed: 0.1213s/iter; left time: 3517.5174s
	iters: 600, epoch: 10 | loss: 0.0686904
	speed: 0.1209s/iter; left time: 3493.7526s
	iters: 700, epoch: 10 | loss: 0.0717656
	speed: 0.1217s/iter; left time: 3504.7039s
	iters: 800, epoch: 10 | loss: 0.0680537
	speed: 0.1205s/iter; left time: 3457.1965s
	iters: 900, epoch: 10 | loss: 0.0653778
	speed: 0.1204s/iter; left time: 3441.7255s
	iters: 1000, epoch: 10 | loss: 0.0478307
	speed: 0.1202s/iter; left time: 3426.1200s
	iters: 1100, epoch: 10 | loss: 0.0693082
	speed: 0.1209s/iter; left time: 3433.5158s
	iters: 1200, epoch: 10 | loss: 0.0719121
	speed: 0.1213s/iter; left time: 3432.1968s
	iters: 1300, epoch: 10 | loss: 0.0745866
	speed: 0.1220s/iter; left time: 3440.3871s
	iters: 1400, epoch: 10 | loss: 0.0660974
	speed: 0.1208s/iter; left time: 3393.8799s
	iters: 1500, epoch: 10 | loss: 0.0666839
	speed: 0.1211s/iter; left time: 3390.1735s
	iters: 1600, epoch: 10 | loss: 0.0883639
	speed: 0.1209s/iter; left time: 3372.3402s
	iters: 1700, epoch: 10 | loss: 0.0611924
	speed: 0.1209s/iter; left time: 3360.3830s
	iters: 1800, epoch: 10 | loss: 0.0584188
	speed: 0.1208s/iter; left time: 3345.9582s
	iters: 1900, epoch: 10 | loss: 0.0601275
	speed: 0.1208s/iter; left time: 3334.4666s
	iters: 2000, epoch: 10 | loss: 0.0625480
	speed: 0.1212s/iter; left time: 3332.7025s
	iters: 2100, epoch: 10 | loss: 0.0705743
	speed: 0.1209s/iter; left time: 3311.6721s
	iters: 2200, epoch: 10 | loss: 0.0633123
	speed: 0.1185s/iter; left time: 3235.0795s
	iters: 2300, epoch: 10 | loss: 0.0581706
	speed: 0.1110s/iter; left time: 3017.9555s
	iters: 2400, epoch: 10 | loss: 0.0554645
	speed: 0.1199s/iter; left time: 3247.2439s
	iters: 2500, epoch: 10 | loss: 0.0550835
	speed: 0.1216s/iter; left time: 3282.5404s
	iters: 2600, epoch: 10 | loss: 0.0590457
	speed: 0.1213s/iter; left time: 3261.2997s
Epoch: 10 cost time: 00h:05m:20.43s
Epoch: 10 | Train Loss: 0.0663446 Vali Loss: 0.0583170 Test Loss: 0.0684556
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 11 | loss: 0.0767739
	speed: 1.0024s/iter; left time: 26774.4833s
	iters: 200, epoch: 11 | loss: 0.0565607
	speed: 0.1212s/iter; left time: 3225.9090s
	iters: 300, epoch: 11 | loss: 0.0709955
	speed: 0.1206s/iter; left time: 3197.3566s
	iters: 400, epoch: 11 | loss: 0.0625823
	speed: 0.1199s/iter; left time: 3165.5866s
	iters: 500, epoch: 11 | loss: 0.0661458
	speed: 0.1208s/iter; left time: 3177.3516s
	iters: 600, epoch: 11 | loss: 0.0606733
	speed: 0.1199s/iter; left time: 3141.6557s
	iters: 700, epoch: 11 | loss: 0.0683432
	speed: 0.1204s/iter; left time: 3144.4046s
	iters: 800, epoch: 11 | loss: 0.0626959
	speed: 0.1209s/iter; left time: 3143.5221s
	iters: 900, epoch: 11 | loss: 0.0729644
	speed: 0.1206s/iter; left time: 3126.1173s
	iters: 1000, epoch: 11 | loss: 0.0603989
	speed: 0.1202s/iter; left time: 3102.1290s
	iters: 1100, epoch: 11 | loss: 0.0806362
	speed: 0.1209s/iter; left time: 3108.6647s
	iters: 1200, epoch: 11 | loss: 0.0656467
	speed: 0.1207s/iter; left time: 3092.4238s
	iters: 1300, epoch: 11 | loss: 0.0590451
	speed: 0.1204s/iter; left time: 3071.7247s
	iters: 1400, epoch: 11 | loss: 0.0639197
	speed: 0.1206s/iter; left time: 3063.5683s
	iters: 1500, epoch: 11 | loss: 0.0649276
	speed: 0.1213s/iter; left time: 3070.5942s
	iters: 1600, epoch: 11 | loss: 0.0672397
	speed: 0.1209s/iter; left time: 3048.3964s
	iters: 1700, epoch: 11 | loss: 0.0771958
	speed: 0.1208s/iter; left time: 3033.0554s
	iters: 1800, epoch: 11 | loss: 0.0633096
	speed: 0.1209s/iter; left time: 3024.6658s
	iters: 1900, epoch: 11 | loss: 0.0575457
	speed: 0.1208s/iter; left time: 3009.7995s
	iters: 2000, epoch: 11 | loss: 0.0709095
	speed: 0.1199s/iter; left time: 2975.9801s
	iters: 2100, epoch: 11 | loss: 0.0625228
	speed: 0.1195s/iter; left time: 2953.3664s
	iters: 2200, epoch: 11 | loss: 0.0722681
	speed: 0.1209s/iter; left time: 2976.3788s
	iters: 2300, epoch: 11 | loss: 0.0579663
	speed: 0.1210s/iter; left time: 2965.9585s
	iters: 2400, epoch: 11 | loss: 0.0612664
	speed: 0.1206s/iter; left time: 2944.2459s
	iters: 2500, epoch: 11 | loss: 0.0591755
	speed: 0.1213s/iter; left time: 2948.4781s
	iters: 2600, epoch: 11 | loss: 0.0699752
	speed: 0.1215s/iter; left time: 2942.5130s
Epoch: 11 cost time: 00h:05m:24.05s
Epoch: 11 | Train Loss: 0.0658757 Vali Loss: 0.0578032 Test Loss: 0.0670076
Validation loss decreased (0.058111 --> 0.057803).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 12 | loss: 0.0724038
	speed: 1.0214s/iter; left time: 24543.3694s
	iters: 200, epoch: 12 | loss: 0.0599244
	speed: 0.1204s/iter; left time: 2882.0146s
	iters: 300, epoch: 12 | loss: 0.0652725
	speed: 0.1205s/iter; left time: 2871.3903s
	iters: 400, epoch: 12 | loss: 0.0576787
	speed: 0.1189s/iter; left time: 2820.5972s
	iters: 500, epoch: 12 | loss: 0.0657673
	speed: 0.1195s/iter; left time: 2822.9288s
	iters: 600, epoch: 12 | loss: 0.0662366
	speed: 0.1210s/iter; left time: 2846.7848s
	iters: 700, epoch: 12 | loss: 0.0807744
	speed: 0.1211s/iter; left time: 2836.5630s
	iters: 800, epoch: 12 | loss: 0.0683301
	speed: 0.1209s/iter; left time: 2820.4726s
	iters: 900, epoch: 12 | loss: 0.0653859
	speed: 0.1208s/iter; left time: 2806.3520s
	iters: 1000, epoch: 12 | loss: 0.0721641
	speed: 0.1211s/iter; left time: 2800.9883s
	iters: 1100, epoch: 12 | loss: 0.0629323
	speed: 0.1209s/iter; left time: 2784.2518s
	iters: 1200, epoch: 12 | loss: 0.0567239
	speed: 0.1214s/iter; left time: 2782.8378s
	iters: 1300, epoch: 12 | loss: 0.0589142
	speed: 0.1211s/iter; left time: 2764.1547s
	iters: 1400, epoch: 12 | loss: 0.0682594
	speed: 0.1208s/iter; left time: 2745.5598s
	iters: 1500, epoch: 12 | loss: 0.0660052
	speed: 0.1198s/iter; left time: 2711.3688s
	iters: 1600, epoch: 12 | loss: 0.0597542
	speed: 0.1189s/iter; left time: 2679.3007s
	iters: 1700, epoch: 12 | loss: 0.0569995
	speed: 0.1182s/iter; left time: 2651.7655s
	iters: 1800, epoch: 12 | loss: 0.0621652
	speed: 0.1197s/iter; left time: 2672.1835s
	iters: 1900, epoch: 12 | loss: 0.0574851
	speed: 0.1208s/iter; left time: 2685.8105s
	iters: 2000, epoch: 12 | loss: 0.0754092
	speed: 0.1194s/iter; left time: 2642.0530s
	iters: 2100, epoch: 12 | loss: 0.0705758
	speed: 0.1209s/iter; left time: 2663.8259s
	iters: 2200, epoch: 12 | loss: 0.0638501
	speed: 0.1195s/iter; left time: 2620.6709s
	iters: 2300, epoch: 12 | loss: 0.0607917
	speed: 0.1208s/iter; left time: 2638.0143s
	iters: 2400, epoch: 12 | loss: 0.0704667
	speed: 0.1203s/iter; left time: 2614.3010s
	iters: 2500, epoch: 12 | loss: 0.0649680
	speed: 0.1187s/iter; left time: 2567.1300s
	iters: 2600, epoch: 12 | loss: 0.0622617
	speed: 0.1198s/iter; left time: 2580.3634s
Epoch: 12 cost time: 00h:05m:22.82s
Epoch: 12 | Train Loss: 0.0654141 Vali Loss: 0.0592872 Test Loss: 0.0696159
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 13 | loss: 0.0571517
	speed: 1.0020s/iter; left time: 21392.3232s
	iters: 200, epoch: 13 | loss: 0.0563359
	speed: 0.1211s/iter; left time: 2573.5299s
	iters: 300, epoch: 13 | loss: 0.0752222
	speed: 0.1202s/iter; left time: 2542.1827s
	iters: 400, epoch: 13 | loss: 0.0552250
	speed: 0.1208s/iter; left time: 2543.7394s
	iters: 500, epoch: 13 | loss: 0.0716464
	speed: 0.1211s/iter; left time: 2537.0455s
	iters: 600, epoch: 13 | loss: 0.0713721
	speed: 0.1211s/iter; left time: 2525.8000s
	iters: 700, epoch: 13 | loss: 0.0675928
	speed: 0.1124s/iter; left time: 2332.4560s
	iters: 800, epoch: 13 | loss: 0.0716297
	speed: 0.1115s/iter; left time: 2302.6765s
	iters: 900, epoch: 13 | loss: 0.0656308
	speed: 0.1212s/iter; left time: 2490.8294s
	iters: 1000, epoch: 13 | loss: 0.0822458
	speed: 0.1209s/iter; left time: 2472.6043s
	iters: 1100, epoch: 13 | loss: 0.0752804
	speed: 0.1211s/iter; left time: 2464.3106s
	iters: 1200, epoch: 13 | loss: 0.0652262
	speed: 0.1198s/iter; left time: 2426.5868s
	iters: 1300, epoch: 13 | loss: 0.0598756
	speed: 0.1194s/iter; left time: 2406.7184s
	iters: 1400, epoch: 13 | loss: 0.0691182
	speed: 0.1189s/iter; left time: 2383.9434s
	iters: 1500, epoch: 13 | loss: 0.0635491
	speed: 0.1201s/iter; left time: 2395.1932s
	iters: 1600, epoch: 13 | loss: 0.0895910
	speed: 0.1193s/iter; left time: 2368.0658s
	iters: 1700, epoch: 13 | loss: 0.0710886
	speed: 0.1086s/iter; left time: 2143.8676s
	iters: 1800, epoch: 13 | loss: 0.0558507
	speed: 0.1145s/iter; left time: 2249.9822s
	iters: 1900, epoch: 13 | loss: 0.0647579
	speed: 0.1211s/iter; left time: 2367.5407s
	iters: 2000, epoch: 13 | loss: 0.0736879
	speed: 0.1209s/iter; left time: 2351.4952s
	iters: 2100, epoch: 13 | loss: 0.0558424
	speed: 0.1209s/iter; left time: 2339.2551s
	iters: 2200, epoch: 13 | loss: 0.0630306
	speed: 0.1070s/iter; left time: 2058.7933s
	iters: 2300, epoch: 13 | loss: 0.0580184
	speed: 0.1198s/iter; left time: 2294.8957s
	iters: 2400, epoch: 13 | loss: 0.0643669
	speed: 0.1212s/iter; left time: 2309.2027s
	iters: 2500, epoch: 13 | loss: 0.0530160
	speed: 0.1209s/iter; left time: 2291.1351s
	iters: 2600, epoch: 13 | loss: 0.0617090
	speed: 0.1209s/iter; left time: 2279.3256s
Epoch: 13 cost time: 00h:05m:18.80s
Epoch: 13 | Train Loss: 0.0649905 Vali Loss: 0.0579648 Test Loss: 0.0673596
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 14 | loss: 0.0698010
	speed: 1.0080s/iter; left time: 18818.0647s
	iters: 200, epoch: 14 | loss: 0.0725076
	speed: 0.1212s/iter; left time: 2251.1916s
	iters: 300, epoch: 14 | loss: 0.0715118
	speed: 0.1214s/iter; left time: 2242.3808s
	iters: 400, epoch: 14 | loss: 0.0609961
	speed: 0.1194s/iter; left time: 2192.5082s
	iters: 500, epoch: 14 | loss: 0.0552948
	speed: 0.1204s/iter; left time: 2199.0651s
	iters: 600, epoch: 14 | loss: 0.0565410
	speed: 0.1167s/iter; left time: 2120.1241s
	iters: 700, epoch: 14 | loss: 0.0706945
	speed: 0.1040s/iter; left time: 1879.1361s
	iters: 800, epoch: 14 | loss: 0.0687059
	speed: 0.1038s/iter; left time: 1865.9370s
	iters: 900, epoch: 14 | loss: 0.0700648
	speed: 0.1039s/iter; left time: 1857.1746s
	iters: 1000, epoch: 14 | loss: 0.0679078
	speed: 0.1070s/iter; left time: 1901.8525s
	iters: 1100, epoch: 14 | loss: 0.0623200
	speed: 0.1214s/iter; left time: 2144.4022s
	iters: 1200, epoch: 14 | loss: 0.0606130
	speed: 0.1061s/iter; left time: 1863.2860s
	iters: 1300, epoch: 14 | loss: 0.0608021
	speed: 0.1040s/iter; left time: 1816.4396s
	iters: 1400, epoch: 14 | loss: 0.0654804
	speed: 0.1045s/iter; left time: 1815.0370s
	iters: 1500, epoch: 14 | loss: 0.0613914
	speed: 0.1070s/iter; left time: 1846.9774s
	iters: 1600, epoch: 14 | loss: 0.0539721
	speed: 0.1047s/iter; left time: 1797.4113s
	iters: 1700, epoch: 14 | loss: 0.0673941
	speed: 0.1043s/iter; left time: 1780.3201s
	iters: 1800, epoch: 14 | loss: 0.0644400
	speed: 0.1046s/iter; left time: 1774.5108s
	iters: 1900, epoch: 14 | loss: 0.0617564
	speed: 0.1038s/iter; left time: 1750.7404s
	iters: 2000, epoch: 14 | loss: 0.0573019
	speed: 0.1036s/iter; left time: 1737.9306s
	iters: 2100, epoch: 14 | loss: 0.0627567
	speed: 0.1035s/iter; left time: 1725.4768s
	iters: 2200, epoch: 14 | loss: 0.0622240
	speed: 0.1033s/iter; left time: 1710.6912s
	iters: 2300, epoch: 14 | loss: 0.0786616
	speed: 0.1049s/iter; left time: 1727.5067s
	iters: 2400, epoch: 14 | loss: 0.0765208
	speed: 0.1034s/iter; left time: 1692.7239s
	iters: 2500, epoch: 14 | loss: 0.0689429
	speed: 0.1039s/iter; left time: 1690.4411s
	iters: 2600, epoch: 14 | loss: 0.0559283
	speed: 0.1065s/iter; left time: 1722.1034s
Epoch: 14 cost time: 00h:04m:52.10s
Epoch: 14 | Train Loss: 0.0645770 Vali Loss: 0.0574409 Test Loss: 0.0664566
Validation loss decreased (0.057803 --> 0.057441).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 15 | loss: 0.0564922
	speed: 1.0137s/iter; left time: 16206.0672s
	iters: 200, epoch: 15 | loss: 0.0621809
	speed: 0.1215s/iter; left time: 1929.8089s
	iters: 300, epoch: 15 | loss: 0.0641433
	speed: 0.1201s/iter; left time: 1895.9220s
	iters: 400, epoch: 15 | loss: 0.0578732
	speed: 0.1190s/iter; left time: 1866.4919s
	iters: 500, epoch: 15 | loss: 0.0655350
	speed: 0.1192s/iter; left time: 1858.3363s
	iters: 600, epoch: 15 | loss: 0.0686196
	speed: 0.1209s/iter; left time: 1872.5052s
	iters: 700, epoch: 15 | loss: 0.0824154
	speed: 0.1209s/iter; left time: 1860.5507s
	iters: 800, epoch: 15 | loss: 0.0650468
	speed: 0.1194s/iter; left time: 1825.2374s
	iters: 900, epoch: 15 | loss: 0.0688387
	speed: 0.1181s/iter; left time: 1793.5052s
	iters: 1000, epoch: 15 | loss: 0.0771232
	speed: 0.1196s/iter; left time: 1804.9983s
	iters: 1100, epoch: 15 | loss: 0.0594005
	speed: 0.1209s/iter; left time: 1812.2207s
	iters: 1200, epoch: 15 | loss: 0.0690505
	speed: 0.1211s/iter; left time: 1802.8164s
	iters: 1300, epoch: 15 | loss: 0.0685179
	speed: 0.1215s/iter; left time: 1796.2036s
	iters: 1400, epoch: 15 | loss: 0.0714361
	speed: 0.1213s/iter; left time: 1781.2040s
	iters: 1500, epoch: 15 | loss: 0.0690282
	speed: 0.1216s/iter; left time: 1773.8319s
	iters: 1600, epoch: 15 | loss: 0.0619706
	speed: 0.1209s/iter; left time: 1751.6200s
	iters: 1700, epoch: 15 | loss: 0.0708041
	speed: 0.1212s/iter; left time: 1743.5116s
	iters: 1800, epoch: 15 | loss: 0.0704809
	speed: 0.1201s/iter; left time: 1715.8590s
	iters: 1900, epoch: 15 | loss: 0.0758016
	speed: 0.1212s/iter; left time: 1719.3418s
	iters: 2000, epoch: 15 | loss: 0.0559394
	speed: 0.1215s/iter; left time: 1711.7223s
	iters: 2100, epoch: 15 | loss: 0.0584624
	speed: 0.1217s/iter; left time: 1702.1276s
	iters: 2200, epoch: 15 | loss: 0.0783027
	speed: 0.1213s/iter; left time: 1684.9381s
	iters: 2300, epoch: 15 | loss: 0.0668146
	speed: 0.1207s/iter; left time: 1663.9823s
	iters: 2400, epoch: 15 | loss: 0.0637044
	speed: 0.1209s/iter; left time: 1655.2921s
	iters: 2500, epoch: 15 | loss: 0.0603980
	speed: 0.1211s/iter; left time: 1645.4828s
	iters: 2600, epoch: 15 | loss: 0.0710332
	speed: 0.1209s/iter; left time: 1631.0377s
Epoch: 15 cost time: 00h:05m:24.00s
Epoch: 15 | Train Loss: 0.0641804 Vali Loss: 0.0605943 Test Loss: 0.0706357
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 16 | loss: 0.0574767
	speed: 0.9987s/iter; left time: 13288.6371s
	iters: 200, epoch: 16 | loss: 0.0573915
	speed: 0.1210s/iter; left time: 1598.3605s
	iters: 300, epoch: 16 | loss: 0.0506497
	speed: 0.1208s/iter; left time: 1583.0926s
	iters: 400, epoch: 16 | loss: 0.0601425
	speed: 0.1205s/iter; left time: 1567.3932s
	iters: 500, epoch: 16 | loss: 0.0669079
	speed: 0.1206s/iter; left time: 1556.8002s
	iters: 600, epoch: 16 | loss: 0.0705684
	speed: 0.1208s/iter; left time: 1546.9123s
	iters: 700, epoch: 16 | loss: 0.0603802
	speed: 0.1209s/iter; left time: 1536.3318s
	iters: 800, epoch: 16 | loss: 0.0707469
	speed: 0.1206s/iter; left time: 1520.0035s
	iters: 900, epoch: 16 | loss: 0.0820457
	speed: 0.1209s/iter; left time: 1512.1507s
	iters: 1000, epoch: 16 | loss: 0.0660811
	speed: 0.1207s/iter; left time: 1497.2666s
	iters: 1100, epoch: 16 | loss: 0.0602575
	speed: 0.1205s/iter; left time: 1483.1420s
	iters: 1200, epoch: 16 | loss: 0.0644291
	speed: 0.1209s/iter; left time: 1476.2661s
	iters: 1300, epoch: 16 | loss: 0.0740635
	speed: 0.1213s/iter; left time: 1468.4957s
	iters: 1400, epoch: 16 | loss: 0.0634106
	speed: 0.1211s/iter; left time: 1453.3450s
	iters: 1500, epoch: 16 | loss: 0.0686077
	speed: 0.1210s/iter; left time: 1441.1272s
	iters: 1600, epoch: 16 | loss: 0.0558413
	speed: 0.1207s/iter; left time: 1425.5261s
	iters: 1700, epoch: 16 | loss: 0.0561398
	speed: 0.1197s/iter; left time: 1401.1049s
	iters: 1800, epoch: 16 | loss: 0.0640715
	speed: 0.1194s/iter; left time: 1386.2993s
	iters: 1900, epoch: 16 | loss: 0.0615180
	speed: 0.1189s/iter; left time: 1368.0313s
	iters: 2000, epoch: 16 | loss: 0.0579631
	speed: 0.1176s/iter; left time: 1341.7936s
	iters: 2100, epoch: 16 | loss: 0.0742498
	speed: 0.1210s/iter; left time: 1368.4452s
	iters: 2200, epoch: 16 | loss: 0.0673364
	speed: 0.1209s/iter; left time: 1354.9910s
	iters: 2300, epoch: 16 | loss: 0.0641308
	speed: 0.1201s/iter; left time: 1334.0378s
	iters: 2400, epoch: 16 | loss: 0.0701997
	speed: 0.1196s/iter; left time: 1315.8830s
	iters: 2500, epoch: 16 | loss: 0.0703389
	speed: 0.1195s/iter; left time: 1303.4728s
	iters: 2600, epoch: 16 | loss: 0.0659333
	speed: 0.1212s/iter; left time: 1309.2839s
Epoch: 16 cost time: 00h:05m:23.44s
Epoch: 16 | Train Loss: 0.0638276 Vali Loss: 0.0593083 Test Loss: 0.0686335
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 17 | loss: 0.0632415
	speed: 1.0042s/iter; left time: 10670.0459s
	iters: 200, epoch: 17 | loss: 0.0688461
	speed: 0.1210s/iter; left time: 1273.2619s
	iters: 300, epoch: 17 | loss: 0.0631828
	speed: 0.1209s/iter; left time: 1260.4342s
	iters: 400, epoch: 17 | loss: 0.0736408
	speed: 0.1209s/iter; left time: 1248.2520s
	iters: 500, epoch: 17 | loss: 0.0770576
	speed: 0.1203s/iter; left time: 1230.3587s
	iters: 600, epoch: 17 | loss: 0.0678533
	speed: 0.1207s/iter; left time: 1221.9485s
	iters: 700, epoch: 17 | loss: 0.0549429
	speed: 0.1206s/iter; left time: 1209.1622s
	iters: 800, epoch: 17 | loss: 0.0515392
	speed: 0.1201s/iter; left time: 1192.4224s
	iters: 900, epoch: 17 | loss: 0.0676008
	speed: 0.1213s/iter; left time: 1191.8200s
	iters: 1000, epoch: 17 | loss: 0.0647659
	speed: 0.1208s/iter; left time: 1174.5761s
	iters: 1100, epoch: 17 | loss: 0.0694209
	speed: 0.1201s/iter; left time: 1155.6223s
	iters: 1200, epoch: 17 | loss: 0.0576050
	speed: 0.1210s/iter; left time: 1152.5943s
	iters: 1300, epoch: 17 | loss: 0.0682291
	speed: 0.1210s/iter; left time: 1140.6939s
	iters: 1400, epoch: 17 | loss: 0.0641747
	speed: 0.1208s/iter; left time: 1126.4672s
	iters: 1500, epoch: 17 | loss: 0.0657903
	speed: 0.1209s/iter; left time: 1115.4537s
	iters: 1600, epoch: 17 | loss: 0.0568783
	speed: 0.1208s/iter; left time: 1102.2980s
	iters: 1700, epoch: 17 | loss: 0.0658871
	speed: 0.1208s/iter; left time: 1090.2853s
	iters: 1800, epoch: 17 | loss: 0.0624544
	speed: 0.1209s/iter; left time: 1079.2423s
	iters: 1900, epoch: 17 | loss: 0.0611300
	speed: 0.1211s/iter; left time: 1068.3705s
	iters: 2000, epoch: 17 | loss: 0.0487223
	speed: 0.1209s/iter; left time: 1054.9119s
	iters: 2100, epoch: 17 | loss: 0.0584179
	speed: 0.1193s/iter; left time: 1028.8500s
	iters: 2200, epoch: 17 | loss: 0.0644555
	speed: 0.1217s/iter; left time: 1037.1654s
	iters: 2300, epoch: 17 | loss: 0.0529996
	speed: 0.1208s/iter; left time: 1017.9694s
	iters: 2400, epoch: 17 | loss: 0.0567144
	speed: 0.1146s/iter; left time: 953.8380s
	iters: 2500, epoch: 17 | loss: 0.0710186
	speed: 0.1012s/iter; left time: 832.3481s
	iters: 2600, epoch: 17 | loss: 0.0712463
	speed: 0.1015s/iter; left time: 824.7488s
Epoch: 17 cost time: 00h:05m:19.68s
Epoch: 17 | Train Loss: 0.0634753 Vali Loss: 0.0594251 Test Loss: 0.0680345
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 18 | loss: 0.0608606
	speed: 1.0129s/iter; left time: 8046.1915s
	iters: 200, epoch: 18 | loss: 0.0630744
	speed: 0.1182s/iter; left time: 927.2213s
	iters: 300, epoch: 18 | loss: 0.0573201
	speed: 0.1192s/iter; left time: 923.0656s
	iters: 400, epoch: 18 | loss: 0.0669892
	speed: 0.1187s/iter; left time: 907.1523s
	iters: 500, epoch: 18 | loss: 0.0642769
	speed: 0.1179s/iter; left time: 889.2121s
	iters: 600, epoch: 18 | loss: 0.0601702
	speed: 0.1182s/iter; left time: 879.8324s
	iters: 700, epoch: 18 | loss: 0.0813551
	speed: 0.1188s/iter; left time: 872.4266s
	iters: 800, epoch: 18 | loss: 0.0769780
	speed: 0.1192s/iter; left time: 863.4640s
	iters: 900, epoch: 18 | loss: 0.0527711
	speed: 0.1195s/iter; left time: 853.8915s
	iters: 1000, epoch: 18 | loss: 0.0642087
	speed: 0.1194s/iter; left time: 840.8665s
	iters: 1100, epoch: 18 | loss: 0.0753492
	speed: 0.1177s/iter; left time: 817.1250s
	iters: 1200, epoch: 18 | loss: 0.0503302
	speed: 0.1179s/iter; left time: 806.8906s
	iters: 1300, epoch: 18 | loss: 0.0638088
	speed: 0.1182s/iter; left time: 797.1014s
	iters: 1400, epoch: 18 | loss: 0.0659324
	speed: 0.1188s/iter; left time: 789.2472s
	iters: 1500, epoch: 18 | loss: 0.0653730
	speed: 0.1194s/iter; left time: 781.2210s
	iters: 1600, epoch: 18 | loss: 0.0739145
	speed: 0.1184s/iter; left time: 763.0992s
	iters: 1700, epoch: 18 | loss: 0.0535310
	speed: 0.1191s/iter; left time: 755.4238s
	iters: 1800, epoch: 18 | loss: 0.0655848
	speed: 0.1196s/iter; left time: 746.5053s
	iters: 1900, epoch: 18 | loss: 0.0589777
	speed: 0.1195s/iter; left time: 734.3371s
	iters: 2000, epoch: 18 | loss: 0.0685786
	speed: 0.1187s/iter; left time: 717.2185s
	iters: 2100, epoch: 18 | loss: 0.0555254
	speed: 0.1193s/iter; left time: 708.8238s
	iters: 2200, epoch: 18 | loss: 0.0631094
	speed: 0.1189s/iter; left time: 695.1114s
	iters: 2300, epoch: 18 | loss: 0.0528505
	speed: 0.1196s/iter; left time: 687.0646s
	iters: 2400, epoch: 18 | loss: 0.0643650
	speed: 0.1191s/iter; left time: 672.0389s
	iters: 2500, epoch: 18 | loss: 0.0647579
	speed: 0.1181s/iter; left time: 654.7355s
	iters: 2600, epoch: 18 | loss: 0.0699769
	speed: 0.1180s/iter; left time: 642.3417s
Epoch: 18 cost time: 00h:05m:18.80s
Epoch: 18 | Train Loss: 0.0629919 Vali Loss: 0.0601041 Test Loss: 0.0698167
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 19 | loss: 0.0543833
	speed: 0.9989s/iter; left time: 5257.2623s
	iters: 200, epoch: 19 | loss: 0.0554405
	speed: 0.1198s/iter; left time: 618.7181s
	iters: 300, epoch: 19 | loss: 0.0701018
	speed: 0.1211s/iter; left time: 613.1900s
	iters: 400, epoch: 19 | loss: 0.0615413
	speed: 0.1208s/iter; left time: 599.4730s
	iters: 500, epoch: 19 | loss: 0.0614020
	speed: 0.1210s/iter; left time: 588.4562s
	iters: 600, epoch: 19 | loss: 0.0573202
	speed: 0.1186s/iter; left time: 565.1220s
	iters: 700, epoch: 19 | loss: 0.0611640
	speed: 0.1193s/iter; left time: 556.1352s
	iters: 800, epoch: 19 | loss: 0.0607653
	speed: 0.1209s/iter; left time: 551.7603s
	iters: 900, epoch: 19 | loss: 0.0566523
	speed: 0.1210s/iter; left time: 540.0489s
	iters: 1000, epoch: 19 | loss: 0.0622958
	speed: 0.1191s/iter; left time: 519.5486s
	iters: 1100, epoch: 19 | loss: 0.0550250
	speed: 0.1190s/iter; left time: 507.0982s
	iters: 1200, epoch: 19 | loss: 0.0663746
	speed: 0.1207s/iter; left time: 502.6407s
	iters: 1300, epoch: 19 | loss: 0.0650760
	speed: 0.1209s/iter; left time: 491.1242s
	iters: 1400, epoch: 19 | loss: 0.0588802
	speed: 0.1209s/iter; left time: 479.1690s
	iters: 1500, epoch: 19 | loss: 0.0603579
	speed: 0.1194s/iter; left time: 461.1579s
	iters: 1600, epoch: 19 | loss: 0.0569299
	speed: 0.1194s/iter; left time: 449.4411s
	iters: 1700, epoch: 19 | loss: 0.0491759
	speed: 0.1211s/iter; left time: 443.6634s
	iters: 1800, epoch: 19 | loss: 0.0864070
	speed: 0.1209s/iter; left time: 430.8147s
	iters: 1900, epoch: 19 | loss: 0.0639838
	speed: 0.1205s/iter; left time: 417.3587s
	iters: 2000, epoch: 19 | loss: 0.0655531
	speed: 0.1211s/iter; left time: 407.3135s
	iters: 2100, epoch: 19 | loss: 0.0550640
	speed: 0.1208s/iter; left time: 394.1868s
	iters: 2200, epoch: 19 | loss: 0.0624830
	speed: 0.1212s/iter; left time: 383.3613s
	iters: 2300, epoch: 19 | loss: 0.0577416
	speed: 0.1210s/iter; left time: 370.4737s
	iters: 2400, epoch: 19 | loss: 0.0651264
	speed: 0.1207s/iter; left time: 357.7418s
	iters: 2500, epoch: 19 | loss: 0.0614737
	speed: 0.1209s/iter; left time: 346.1169s
	iters: 2600, epoch: 19 | loss: 0.0525950
	speed: 0.1208s/iter; left time: 333.7576s
Epoch: 19 cost time: 00h:05m:23.45s
Epoch: 19 | Train Loss: 0.0626410 Vali Loss: 0.0593832 Test Loss: 0.0687746
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.010672738775610924, rmse:0.10330894589424133, mae:0.0664566159248352, rse:0.3033173382282257
success delete checkpoints
Intermediate time for ES and pred_len 24: 02h:07m:51.19s


=== Starting experiments for pred_len: 96 ===

train 85587
val 18435
test 18435
[2024-11-01 07:50:56,871] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 07:50:58,095] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 07:50:58,095] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 07:50:58,095] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 07:50:58,192] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 07:50:58,192] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 07:50:58,843] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 07:50:58,844] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 07:50:58,844] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 07:50:58,846] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 07:50:58,846] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 07:50:58,846] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 07:50:58,846] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 07:50:58,846] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 07:50:58,846] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 07:50:58,846] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 07:50:59,167] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 07:50:59,168] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 07:50:59,168] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.5 GB, percent = 9.9%
[2024-11-01 07:50:59,296] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 07:50:59,297] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 07:50:59,297] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.5 GB, percent = 9.9%
[2024-11-01 07:50:59,297] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 07:50:59,409] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 07:50:59,410] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 07:50:59,410] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.5 GB, percent = 9.9%
[2024-11-01 07:50:59,411] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 07:50:59,411] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 07:50:59,411] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 07:50:59,411] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 07:50:59,412] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2e807005d0>
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 07:50:59,412] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 07:50:59,413] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 07:50:59,414] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 07:50:59,414] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1911721
	speed: 0.1754s/iter; left time: 9360.4956s
	iters: 200, epoch: 1 | loss: 0.1927420
	speed: 0.1310s/iter; left time: 6979.3060s
	iters: 300, epoch: 1 | loss: 0.1694221
	speed: 0.1306s/iter; left time: 6943.0207s
	iters: 400, epoch: 1 | loss: 0.1720468
	speed: 0.1310s/iter; left time: 6953.3096s
	iters: 500, epoch: 1 | loss: 0.1218105
	speed: 0.1308s/iter; left time: 6927.9581s
	iters: 600, epoch: 1 | loss: 0.1114848
	speed: 0.1308s/iter; left time: 6914.9915s
	iters: 700, epoch: 1 | loss: 0.1140701
	speed: 0.1314s/iter; left time: 6936.9193s
	iters: 800, epoch: 1 | loss: 0.1041137
	speed: 0.1311s/iter; left time: 6905.2141s
	iters: 900, epoch: 1 | loss: 0.1242962
	speed: 0.1309s/iter; left time: 6882.0769s
	iters: 1000, epoch: 1 | loss: 0.1122826
	speed: 0.1304s/iter; left time: 6844.6689s
	iters: 1100, epoch: 1 | loss: 0.1078091
	speed: 0.1314s/iter; left time: 6884.2236s
	iters: 1200, epoch: 1 | loss: 0.0886153
	speed: 0.1312s/iter; left time: 6859.0208s
	iters: 1300, epoch: 1 | loss: 0.1067653
	speed: 0.1310s/iter; left time: 6836.4633s
	iters: 1400, epoch: 1 | loss: 0.1063584
	speed: 0.1314s/iter; left time: 6844.1412s
	iters: 1500, epoch: 1 | loss: 0.1006202
	speed: 0.1309s/iter; left time: 6803.2115s
	iters: 1600, epoch: 1 | loss: 0.0992378
	speed: 0.1310s/iter; left time: 6796.5774s
	iters: 1700, epoch: 1 | loss: 0.1159680
	speed: 0.1311s/iter; left time: 6788.6589s
	iters: 1800, epoch: 1 | loss: 0.0989420
	speed: 0.1313s/iter; left time: 6784.2494s
	iters: 1900, epoch: 1 | loss: 0.1210326
	speed: 0.1308s/iter; left time: 6747.6174s
	iters: 2000, epoch: 1 | loss: 0.0897738
	speed: 0.1310s/iter; left time: 6742.8906s
	iters: 2100, epoch: 1 | loss: 0.1054735
	speed: 0.1312s/iter; left time: 6741.9535s
	iters: 2200, epoch: 1 | loss: 0.0856309
	speed: 0.1312s/iter; left time: 6728.5408s
	iters: 2300, epoch: 1 | loss: 0.1068027
	speed: 0.1311s/iter; left time: 6707.7314s
	iters: 2400, epoch: 1 | loss: 0.0811701
	speed: 0.1308s/iter; left time: 6679.3676s
	iters: 2500, epoch: 1 | loss: 0.0951465
	speed: 0.1322s/iter; left time: 6741.5955s
	iters: 2600, epoch: 1 | loss: 0.1027023
	speed: 0.1318s/iter; left time: 6706.4274s
Epoch: 1 cost time: 00h:05m:51.74s
Epoch: 1 | Train Loss: 0.1174485 Vali Loss: 0.0865509 Test Loss: 0.1004628
Validation loss decreased (inf --> 0.086551).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1076370
	speed: 1.1297s/iter; left time: 57285.9966s
	iters: 200, epoch: 2 | loss: 0.1094375
	speed: 0.1085s/iter; left time: 5492.2475s
	iters: 300, epoch: 2 | loss: 0.0885852
	speed: 0.1209s/iter; left time: 6107.8326s
	iters: 400, epoch: 2 | loss: 0.0921508
	speed: 0.1208s/iter; left time: 6091.1367s
	iters: 500, epoch: 2 | loss: 0.0874121
	speed: 0.1209s/iter; left time: 6082.2267s
	iters: 600, epoch: 2 | loss: 0.0942486
	speed: 0.1206s/iter; left time: 6056.0924s
	iters: 700, epoch: 2 | loss: 0.0875211
	speed: 0.1210s/iter; left time: 6060.4486s
	iters: 800, epoch: 2 | loss: 0.0975673
	speed: 0.1205s/iter; left time: 6023.6666s
	iters: 900, epoch: 2 | loss: 0.0873782
	speed: 0.1192s/iter; left time: 5949.7093s
	iters: 1000, epoch: 2 | loss: 0.0910329
	speed: 0.1209s/iter; left time: 6021.0561s
	iters: 1100, epoch: 2 | loss: 0.0909847
	speed: 0.1182s/iter; left time: 5875.6703s
	iters: 1200, epoch: 2 | loss: 0.0977218
	speed: 0.1209s/iter; left time: 5999.6375s
	iters: 1300, epoch: 2 | loss: 0.0851496
	speed: 0.1196s/iter; left time: 5919.5161s
	iters: 1400, epoch: 2 | loss: 0.0878843
	speed: 0.1190s/iter; left time: 5880.2872s
	iters: 1500, epoch: 2 | loss: 0.0895761
	speed: 0.1194s/iter; left time: 5888.1052s
	iters: 1600, epoch: 2 | loss: 0.0866336
	speed: 0.1235s/iter; left time: 6078.7080s
	iters: 1700, epoch: 2 | loss: 0.1094462
	speed: 0.1210s/iter; left time: 5943.9146s
	iters: 1800, epoch: 2 | loss: 0.1022051
	speed: 0.1203s/iter; left time: 5896.5519s
	iters: 1900, epoch: 2 | loss: 0.0886707
	speed: 0.1209s/iter; left time: 5912.9688s
	iters: 2000, epoch: 2 | loss: 0.0902492
	speed: 0.1208s/iter; left time: 5897.6043s
	iters: 2100, epoch: 2 | loss: 0.0888425
	speed: 0.1207s/iter; left time: 5878.6715s
	iters: 2200, epoch: 2 | loss: 0.0878865
	speed: 0.1210s/iter; left time: 5882.0693s
	iters: 2300, epoch: 2 | loss: 0.0795095
	speed: 0.1209s/iter; left time: 5865.0695s
	iters: 2400, epoch: 2 | loss: 0.0914220
	speed: 0.1071s/iter; left time: 5184.0068s
	iters: 2500, epoch: 2 | loss: 0.0818894
	speed: 0.1209s/iter; left time: 5841.2454s
	iters: 2600, epoch: 2 | loss: 0.0820524
	speed: 0.1210s/iter; left time: 5834.0523s
Epoch: 2 cost time: 00h:05m:20.38s
Epoch: 2 | Train Loss: 0.0935248 Vali Loss: 0.0811140 Test Loss: 0.0944012
Validation loss decreased (0.086551 --> 0.081114).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0952333
	speed: 0.9978s/iter; left time: 47927.4442s
	iters: 200, epoch: 3 | loss: 0.0934332
	speed: 0.1195s/iter; left time: 5727.9276s
	iters: 300, epoch: 3 | loss: 0.0905903
	speed: 0.1194s/iter; left time: 5710.2731s
	iters: 400, epoch: 3 | loss: 0.0940271
	speed: 0.1184s/iter; left time: 5649.6792s
	iters: 500, epoch: 3 | loss: 0.0887500
	speed: 0.1185s/iter; left time: 5643.1274s
	iters: 600, epoch: 3 | loss: 0.0991548
	speed: 0.1205s/iter; left time: 5726.6554s
	iters: 700, epoch: 3 | loss: 0.0992021
	speed: 0.1197s/iter; left time: 5678.2305s
	iters: 800, epoch: 3 | loss: 0.0928352
	speed: 0.1191s/iter; left time: 5637.8056s
	iters: 900, epoch: 3 | loss: 0.0962132
	speed: 0.1184s/iter; left time: 5591.5248s
	iters: 1000, epoch: 3 | loss: 0.0963722
	speed: 0.1182s/iter; left time: 5571.5489s
	iters: 1100, epoch: 3 | loss: 0.0940291
	speed: 0.1189s/iter; left time: 5591.8360s
	iters: 1200, epoch: 3 | loss: 0.0946871
	speed: 0.1188s/iter; left time: 5575.5951s
	iters: 1300, epoch: 3 | loss: 0.0897035
	speed: 0.1189s/iter; left time: 5567.3215s
	iters: 1400, epoch: 3 | loss: 0.0817999
	speed: 0.1191s/iter; left time: 5565.6310s
	iters: 1500, epoch: 3 | loss: 0.0934589
	speed: 0.1190s/iter; left time: 5549.1860s
	iters: 1600, epoch: 3 | loss: 0.1075991
	speed: 0.1182s/iter; left time: 5500.5783s
	iters: 1700, epoch: 3 | loss: 0.1029885
	speed: 0.1181s/iter; left time: 5486.0548s
	iters: 1800, epoch: 3 | loss: 0.0796154
	speed: 0.1179s/iter; left time: 5460.3760s
	iters: 1900, epoch: 3 | loss: 0.1007038
	speed: 0.1183s/iter; left time: 5470.1309s
	iters: 2000, epoch: 3 | loss: 0.0810669
	speed: 0.1187s/iter; left time: 5478.1816s
	iters: 2100, epoch: 3 | loss: 0.1120119
	speed: 0.1196s/iter; left time: 5507.4934s
	iters: 2200, epoch: 3 | loss: 0.1014793
	speed: 0.1194s/iter; left time: 5482.6509s
	iters: 2300, epoch: 3 | loss: 0.0782545
	speed: 0.1198s/iter; left time: 5488.5750s
	iters: 2400, epoch: 3 | loss: 0.0805253
	speed: 0.1199s/iter; left time: 5483.4642s
	iters: 2500, epoch: 3 | loss: 0.0871867
	speed: 0.1188s/iter; left time: 5420.9702s
	iters: 2600, epoch: 3 | loss: 0.0826894
	speed: 0.1188s/iter; left time: 5409.7105s
Epoch: 3 cost time: 00h:05m:18.60s
Epoch: 3 | Train Loss: 0.0897070 Vali Loss: 0.0801801 Test Loss: 0.0940483
Validation loss decreased (0.081114 --> 0.080180).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0769089
	speed: 0.9959s/iter; left time: 45170.8816s
	iters: 200, epoch: 4 | loss: 0.0909401
	speed: 0.1204s/iter; left time: 5448.5463s
	iters: 300, epoch: 4 | loss: 0.0769373
	speed: 0.1193s/iter; left time: 5387.4849s
	iters: 400, epoch: 4 | loss: 0.0873026
	speed: 0.1199s/iter; left time: 5401.5405s
	iters: 500, epoch: 4 | loss: 0.0947193
	speed: 0.1184s/iter; left time: 5325.1860s
	iters: 600, epoch: 4 | loss: 0.0831833
	speed: 0.1189s/iter; left time: 5334.2103s
	iters: 700, epoch: 4 | loss: 0.0980527
	speed: 0.1193s/iter; left time: 5339.8231s
	iters: 800, epoch: 4 | loss: 0.0867212
	speed: 0.1173s/iter; left time: 5240.4465s
	iters: 900, epoch: 4 | loss: 0.0815352
	speed: 0.1013s/iter; left time: 4515.8182s
	iters: 1000, epoch: 4 | loss: 0.0801502
	speed: 0.1012s/iter; left time: 4498.2598s
	iters: 1100, epoch: 4 | loss: 0.0883447
	speed: 0.1014s/iter; left time: 4499.2234s
	iters: 1200, epoch: 4 | loss: 0.0877123
	speed: 0.1013s/iter; left time: 4482.7002s
	iters: 1300, epoch: 4 | loss: 0.0836246
	speed: 0.1016s/iter; left time: 4486.9680s
	iters: 1400, epoch: 4 | loss: 0.0986883
	speed: 0.1051s/iter; left time: 4630.0921s
	iters: 1500, epoch: 4 | loss: 0.0836472
	speed: 0.1186s/iter; left time: 5215.3094s
	iters: 1600, epoch: 4 | loss: 0.0853868
	speed: 0.1185s/iter; left time: 5196.0761s
	iters: 1700, epoch: 4 | loss: 0.0907262
	speed: 0.1183s/iter; left time: 5178.6856s
	iters: 1800, epoch: 4 | loss: 0.0784356
	speed: 0.1187s/iter; left time: 5184.3071s
	iters: 1900, epoch: 4 | loss: 0.0888463
	speed: 0.1174s/iter; left time: 5113.7049s
	iters: 2000, epoch: 4 | loss: 0.0986566
	speed: 0.1016s/iter; left time: 4414.9981s
	iters: 2100, epoch: 4 | loss: 0.0922876
	speed: 0.1015s/iter; left time: 4401.7449s
	iters: 2200, epoch: 4 | loss: 0.0821516
	speed: 0.1060s/iter; left time: 4584.2357s
	iters: 2300, epoch: 4 | loss: 0.0900341
	speed: 0.1184s/iter; left time: 5109.8788s
	iters: 2400, epoch: 4 | loss: 0.0951754
	speed: 0.1182s/iter; left time: 5088.1733s
	iters: 2500, epoch: 4 | loss: 0.0837031
	speed: 0.1181s/iter; left time: 5075.1864s
	iters: 2600, epoch: 4 | loss: 0.0842158
	speed: 0.1181s/iter; left time: 5062.9119s
Epoch: 4 cost time: 00h:05m:03.12s
Epoch: 4 | Train Loss: 0.0869057 Vali Loss: 0.0800106 Test Loss: 0.0955628
Validation loss decreased (0.080180 --> 0.080011).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0871619
	speed: 0.9900s/iter; left time: 42257.2283s
	iters: 200, epoch: 5 | loss: 0.1035479
	speed: 0.1042s/iter; left time: 4435.3738s
	iters: 300, epoch: 5 | loss: 0.0778850
	speed: 0.1017s/iter; left time: 4319.0314s
	iters: 400, epoch: 5 | loss: 0.0712645
	speed: 0.1015s/iter; left time: 4300.7944s
	iters: 500, epoch: 5 | loss: 0.0783551
	speed: 0.1152s/iter; left time: 4872.9946s
	iters: 600, epoch: 5 | loss: 0.0905214
	speed: 0.1152s/iter; left time: 4860.3331s
	iters: 700, epoch: 5 | loss: 0.0817809
	speed: 0.1054s/iter; left time: 4435.5948s
	iters: 800, epoch: 5 | loss: 0.0813011
	speed: 0.1014s/iter; left time: 4255.2100s
	iters: 900, epoch: 5 | loss: 0.0899853
	speed: 0.1014s/iter; left time: 4246.9693s
	iters: 1000, epoch: 5 | loss: 0.0864681
	speed: 0.1015s/iter; left time: 4242.9781s
	iters: 1100, epoch: 5 | loss: 0.0875253
	speed: 0.1107s/iter; left time: 4614.4292s
	iters: 1200, epoch: 5 | loss: 0.0901085
	speed: 0.1142s/iter; left time: 4750.1228s
	iters: 1300, epoch: 5 | loss: 0.0639921
	speed: 0.1019s/iter; left time: 4226.5821s
	iters: 1400, epoch: 5 | loss: 0.0969867
	speed: 0.1067s/iter; left time: 4416.2699s
	iters: 1500, epoch: 5 | loss: 0.0761939
	speed: 0.1180s/iter; left time: 4871.8385s
	iters: 1600, epoch: 5 | loss: 0.0842133
	speed: 0.1179s/iter; left time: 4853.7220s
	iters: 1700, epoch: 5 | loss: 0.0735740
	speed: 0.1140s/iter; left time: 4685.2370s
	iters: 1800, epoch: 5 | loss: 0.0814190
	speed: 0.1077s/iter; left time: 4412.6678s
	iters: 1900, epoch: 5 | loss: 0.0850187
	speed: 0.1198s/iter; left time: 4898.0522s
	iters: 2000, epoch: 5 | loss: 0.0746921
	speed: 0.1186s/iter; left time: 4836.3797s
	iters: 2100, epoch: 5 | loss: 0.0881317
	speed: 0.1193s/iter; left time: 4854.8966s
	iters: 2200, epoch: 5 | loss: 0.0845793
	speed: 0.1190s/iter; left time: 4827.8831s
	iters: 2300, epoch: 5 | loss: 0.0848546
	speed: 0.1175s/iter; left time: 4755.2586s
	iters: 2400, epoch: 5 | loss: 0.0750976
	speed: 0.1045s/iter; left time: 4219.6292s
	iters: 2500, epoch: 5 | loss: 0.0834830
	speed: 0.1194s/iter; left time: 4808.6567s
	iters: 2600, epoch: 5 | loss: 0.0875506
	speed: 0.1204s/iter; left time: 4840.0455s
Epoch: 5 cost time: 00h:04m:59.04s
Epoch: 5 | Train Loss: 0.0848302 Vali Loss: 0.0812559 Test Loss: 0.0953243
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1068747
	speed: 0.9808s/iter; left time: 39240.8034s
	iters: 200, epoch: 6 | loss: 0.0783328
	speed: 0.1209s/iter; left time: 4824.9128s
	iters: 300, epoch: 6 | loss: 0.0739404
	speed: 0.1204s/iter; left time: 4791.4928s
	iters: 400, epoch: 6 | loss: 0.0745426
	speed: 0.1208s/iter; left time: 4797.3489s
	iters: 500, epoch: 6 | loss: 0.0807710
	speed: 0.1188s/iter; left time: 4705.5004s
	iters: 600, epoch: 6 | loss: 0.0781820
	speed: 0.1195s/iter; left time: 4721.0329s
	iters: 700, epoch: 6 | loss: 0.0852243
	speed: 0.1194s/iter; left time: 4703.7205s
	iters: 800, epoch: 6 | loss: 0.0808892
	speed: 0.1199s/iter; left time: 4712.9422s
	iters: 900, epoch: 6 | loss: 0.0863012
	speed: 0.1196s/iter; left time: 4689.8551s
	iters: 1000, epoch: 6 | loss: 0.0845646
	speed: 0.1188s/iter; left time: 4645.4725s
	iters: 1100, epoch: 6 | loss: 0.0786446
	speed: 0.1193s/iter; left time: 4652.6836s
	iters: 1200, epoch: 6 | loss: 0.0738035
	speed: 0.1192s/iter; left time: 4638.1092s
	iters: 1300, epoch: 6 | loss: 0.0962725
	speed: 0.1193s/iter; left time: 4629.0365s
	iters: 1400, epoch: 6 | loss: 0.0873117
	speed: 0.1183s/iter; left time: 4580.8513s
	iters: 1500, epoch: 6 | loss: 0.0892730
	speed: 0.1190s/iter; left time: 4595.6594s
	iters: 1600, epoch: 6 | loss: 0.0773154
	speed: 0.1192s/iter; left time: 4589.3222s
	iters: 1700, epoch: 6 | loss: 0.0777241
	speed: 0.1191s/iter; left time: 4574.1587s
	iters: 1800, epoch: 6 | loss: 0.0818046
	speed: 0.1196s/iter; left time: 4581.6482s
	iters: 1900, epoch: 6 | loss: 0.0856868
	speed: 0.1198s/iter; left time: 4578.1556s
	iters: 2000, epoch: 6 | loss: 0.0849679
	speed: 0.1194s/iter; left time: 4551.3619s
	iters: 2100, epoch: 6 | loss: 0.0735170
	speed: 0.1197s/iter; left time: 4550.3702s
	iters: 2200, epoch: 6 | loss: 0.0838584
	speed: 0.1197s/iter; left time: 4537.3662s
	iters: 2300, epoch: 6 | loss: 0.0831294
	speed: 0.1189s/iter; left time: 4494.7647s
	iters: 2400, epoch: 6 | loss: 0.0829203
	speed: 0.1193s/iter; left time: 4497.2487s
	iters: 2500, epoch: 6 | loss: 0.0855648
	speed: 0.1192s/iter; left time: 4482.3846s
	iters: 2600, epoch: 6 | loss: 0.0735175
	speed: 0.1205s/iter; left time: 4518.4545s
Epoch: 6 cost time: 00h:05m:20.16s
Epoch: 6 | Train Loss: 0.0828304 Vali Loss: 0.0819640 Test Loss: 0.0980078
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0902265
	speed: 0.9834s/iter; left time: 36716.0617s
	iters: 200, epoch: 7 | loss: 0.0986805
	speed: 0.1201s/iter; left time: 4473.0452s
	iters: 300, epoch: 7 | loss: 0.0778703
	speed: 0.1196s/iter; left time: 4442.3417s
	iters: 400, epoch: 7 | loss: 0.0782931
	speed: 0.1204s/iter; left time: 4458.9880s
	iters: 500, epoch: 7 | loss: 0.0746187
	speed: 0.1201s/iter; left time: 4437.4885s
	iters: 600, epoch: 7 | loss: 0.0827935
	speed: 0.1059s/iter; left time: 3899.4507s
	iters: 700, epoch: 7 | loss: 0.0739331
	speed: 0.1170s/iter; left time: 4298.9803s
	iters: 800, epoch: 7 | loss: 0.0809667
	speed: 0.1199s/iter; left time: 4392.0960s
	iters: 900, epoch: 7 | loss: 0.0907432
	speed: 0.1210s/iter; left time: 4419.3239s
	iters: 1000, epoch: 7 | loss: 0.0945175
	speed: 0.1209s/iter; left time: 4406.3380s
	iters: 1100, epoch: 7 | loss: 0.0788761
	speed: 0.1209s/iter; left time: 4394.1175s
	iters: 1200, epoch: 7 | loss: 0.0823496
	speed: 0.1209s/iter; left time: 4381.3035s
	iters: 1300, epoch: 7 | loss: 0.0750478
	speed: 0.1212s/iter; left time: 4378.3511s
	iters: 1400, epoch: 7 | loss: 0.0663611
	speed: 0.1209s/iter; left time: 4357.0366s
	iters: 1500, epoch: 7 | loss: 0.0791697
	speed: 0.1209s/iter; left time: 4345.9159s
	iters: 1600, epoch: 7 | loss: 0.0843642
	speed: 0.1208s/iter; left time: 4330.2623s
	iters: 1700, epoch: 7 | loss: 0.0820326
	speed: 0.1207s/iter; left time: 4314.0233s
	iters: 1800, epoch: 7 | loss: 0.0798094
	speed: 0.1209s/iter; left time: 4307.9842s
	iters: 1900, epoch: 7 | loss: 0.0762156
	speed: 0.1209s/iter; left time: 4297.3726s
	iters: 2000, epoch: 7 | loss: 0.0743921
	speed: 0.1200s/iter; left time: 4252.7464s
	iters: 2100, epoch: 7 | loss: 0.0891102
	speed: 0.1193s/iter; left time: 4214.2596s
	iters: 2200, epoch: 7 | loss: 0.0900708
	speed: 0.1209s/iter; left time: 4259.5207s
	iters: 2300, epoch: 7 | loss: 0.0966768
	speed: 0.1208s/iter; left time: 4244.8479s
	iters: 2400, epoch: 7 | loss: 0.0648704
	speed: 0.1209s/iter; left time: 4236.0058s
	iters: 2500, epoch: 7 | loss: 0.0843473
	speed: 0.1209s/iter; left time: 4225.1824s
	iters: 2600, epoch: 7 | loss: 0.0859990
	speed: 0.1208s/iter; left time: 4208.2258s
Epoch: 7 cost time: 00h:05m:20.14s
Epoch: 7 | Train Loss: 0.0812575 Vali Loss: 0.0815965 Test Loss: 0.0964520
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0794488
	speed: 0.9819s/iter; left time: 34034.9664s
	iters: 200, epoch: 8 | loss: 0.0848540
	speed: 0.1201s/iter; left time: 4151.6897s
	iters: 300, epoch: 8 | loss: 0.0769302
	speed: 0.1194s/iter; left time: 4113.7928s
	iters: 400, epoch: 8 | loss: 0.0856332
	speed: 0.1198s/iter; left time: 4118.2853s
	iters: 500, epoch: 8 | loss: 0.0824820
	speed: 0.1197s/iter; left time: 4100.8118s
	iters: 600, epoch: 8 | loss: 0.0854290
	speed: 0.1194s/iter; left time: 4078.7769s
	iters: 700, epoch: 8 | loss: 0.0854288
	speed: 0.1204s/iter; left time: 4102.4972s
	iters: 800, epoch: 8 | loss: 0.0680083
	speed: 0.1207s/iter; left time: 4099.6089s
	iters: 900, epoch: 8 | loss: 0.0768383
	speed: 0.1200s/iter; left time: 4062.1910s
	iters: 1000, epoch: 8 | loss: 0.0693779
	speed: 0.1189s/iter; left time: 4016.0190s
	iters: 1100, epoch: 8 | loss: 0.0754587
	speed: 0.1195s/iter; left time: 4023.1921s
	iters: 1200, epoch: 8 | loss: 0.0802685
	speed: 0.1192s/iter; left time: 4000.5629s
	iters: 1300, epoch: 8 | loss: 0.0774171
	speed: 0.1195s/iter; left time: 3998.8722s
	iters: 1400, epoch: 8 | loss: 0.0754229
	speed: 0.1189s/iter; left time: 3965.7609s
	iters: 1500, epoch: 8 | loss: 0.0888831
	speed: 0.1191s/iter; left time: 3961.5468s
	iters: 1600, epoch: 8 | loss: 0.0705786
	speed: 0.1191s/iter; left time: 3949.1609s
	iters: 1700, epoch: 8 | loss: 0.0788224
	speed: 0.1195s/iter; left time: 3952.6026s
	iters: 1800, epoch: 8 | loss: 0.0689727
	speed: 0.1197s/iter; left time: 3945.4672s
	iters: 1900, epoch: 8 | loss: 0.0841972
	speed: 0.1209s/iter; left time: 3974.3977s
	iters: 2000, epoch: 8 | loss: 0.0773610
	speed: 0.1042s/iter; left time: 3413.5680s
	iters: 2100, epoch: 8 | loss: 0.0929009
	speed: 0.1015s/iter; left time: 3315.0942s
	iters: 2200, epoch: 8 | loss: 0.0882238
	speed: 0.1013s/iter; left time: 3300.0701s
	iters: 2300, epoch: 8 | loss: 0.0731173
	speed: 0.1015s/iter; left time: 3296.4591s
	iters: 2400, epoch: 8 | loss: 0.0878904
	speed: 0.1020s/iter; left time: 3301.4878s
	iters: 2500, epoch: 8 | loss: 0.0880044
	speed: 0.1016s/iter; left time: 3278.1524s
	iters: 2600, epoch: 8 | loss: 0.0914146
	speed: 0.1017s/iter; left time: 3269.9655s
Epoch: 8 cost time: 00h:05m:06.70s
Epoch: 8 | Train Loss: 0.0798089 Vali Loss: 0.0830694 Test Loss: 0.0950187
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0826529
	speed: 0.9672s/iter; left time: 30940.0481s
	iters: 200, epoch: 9 | loss: 0.0691043
	speed: 0.1201s/iter; left time: 3830.4263s
	iters: 300, epoch: 9 | loss: 0.0827234
	speed: 0.1191s/iter; left time: 3784.9011s
	iters: 400, epoch: 9 | loss: 0.0850475
	speed: 0.1197s/iter; left time: 3792.7301s
	iters: 500, epoch: 9 | loss: 0.0775021
	speed: 0.1201s/iter; left time: 3792.9018s
	iters: 600, epoch: 9 | loss: 0.0795878
	speed: 0.1207s/iter; left time: 3799.8979s
	iters: 700, epoch: 9 | loss: 0.0837808
	speed: 0.1202s/iter; left time: 3773.3191s
	iters: 800, epoch: 9 | loss: 0.0798738
	speed: 0.1201s/iter; left time: 3757.1875s
	iters: 900, epoch: 9 | loss: 0.0779057
	speed: 0.1193s/iter; left time: 3720.9957s
	iters: 1000, epoch: 9 | loss: 0.0727953
	speed: 0.1185s/iter; left time: 3685.5577s
	iters: 1100, epoch: 9 | loss: 0.0807575
	speed: 0.1183s/iter; left time: 3666.8271s
	iters: 1200, epoch: 9 | loss: 0.0787443
	speed: 0.1191s/iter; left time: 3678.8357s
	iters: 1300, epoch: 9 | loss: 0.0788000
	speed: 0.1192s/iter; left time: 3671.4641s
	iters: 1400, epoch: 9 | loss: 0.0729088
	speed: 0.1187s/iter; left time: 3643.3088s
	iters: 1500, epoch: 9 | loss: 0.0709907
	speed: 0.1190s/iter; left time: 3639.4448s
	iters: 1600, epoch: 9 | loss: 0.0749613
	speed: 0.1184s/iter; left time: 3609.1792s
	iters: 1700, epoch: 9 | loss: 0.0788948
	speed: 0.1183s/iter; left time: 3595.0639s
	iters: 1800, epoch: 9 | loss: 0.0830306
	speed: 0.1185s/iter; left time: 3590.5527s
	iters: 1900, epoch: 9 | loss: 0.0778918
	speed: 0.1192s/iter; left time: 3598.7288s
	iters: 2000, epoch: 9 | loss: 0.0789471
	speed: 0.1186s/iter; left time: 3568.9530s
	iters: 2100, epoch: 9 | loss: 0.0754702
	speed: 0.1188s/iter; left time: 3561.9679s
	iters: 2200, epoch: 9 | loss: 0.0705925
	speed: 0.1195s/iter; left time: 3571.0963s
	iters: 2300, epoch: 9 | loss: 0.0731009
	speed: 0.1182s/iter; left time: 3520.6403s
	iters: 2400, epoch: 9 | loss: 0.0785734
	speed: 0.1182s/iter; left time: 3508.0558s
	iters: 2500, epoch: 9 | loss: 0.0922928
	speed: 0.1187s/iter; left time: 3511.9756s
	iters: 2600, epoch: 9 | loss: 0.0796332
	speed: 0.1184s/iter; left time: 3492.1721s
Epoch: 9 cost time: 00h:05m:19.03s
Epoch: 9 | Train Loss: 0.0784978 Vali Loss: 0.0850671 Test Loss: 0.0985102
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.02088882215321064, rmse:0.14452965557575226, mae:0.09556279331445694, rse:0.4245525300502777
success delete checkpoints
Intermediate time for ES and pred_len 96: 01h:00m:35.28s


=== Starting experiments for pred_len: 168 ===

train 85371
val 18219
test 18219
[2024-11-01 08:51:32,150] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 08:51:33,307] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 08:51:33,308] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 08:51:33,308] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 08:51:33,412] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 08:51:33,412] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 08:51:34,111] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 08:51:34,112] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 08:51:34,112] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 08:51:34,114] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 08:51:34,114] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 08:51:34,114] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 08:51:34,114] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 08:51:34,114] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 08:51:34,114] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 08:51:34,115] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 08:51:34,425] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 08:51:34,426] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 08:51:34,426] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.51 GB, percent = 9.9%
[2024-11-01 08:51:34,545] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 08:51:34,546] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 08:51:34,546] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.51 GB, percent = 9.9%
[2024-11-01 08:51:34,546] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 08:51:34,660] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 08:51:34,661] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 08:51:34,661] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.51 GB, percent = 9.9%
[2024-11-01 08:51:34,662] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 08:51:34,662] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 08:51:34,662] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 08:51:34,662] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 08:51:34,663] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 08:51:34,663] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 08:51:34,663] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 08:51:34,663] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 08:51:34,663] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fb2655ba550>
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 08:51:34,664] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 08:51:34,665] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 08:51:34,666] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 08:51:34,666] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 08:51:34,666] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.2009432
	speed: 0.1747s/iter; left time: 9298.7261s
	iters: 200, epoch: 1 | loss: 0.2018673
	speed: 0.1310s/iter; left time: 6962.6375s
	iters: 300, epoch: 1 | loss: 0.1664647
	speed: 0.1305s/iter; left time: 6924.0238s
	iters: 400, epoch: 1 | loss: 0.1907074
	speed: 0.1314s/iter; left time: 6956.6166s
	iters: 500, epoch: 1 | loss: 0.1524435
	speed: 0.1314s/iter; left time: 6943.1725s
	iters: 600, epoch: 1 | loss: 0.1277965
	speed: 0.1310s/iter; left time: 6907.5972s
	iters: 700, epoch: 1 | loss: 0.1040149
	speed: 0.1319s/iter; left time: 6945.5219s
	iters: 800, epoch: 1 | loss: 0.1075614
	speed: 0.1324s/iter; left time: 6955.5543s
	iters: 900, epoch: 1 | loss: 0.1123559
	speed: 0.1312s/iter; left time: 6882.5495s
	iters: 1000, epoch: 1 | loss: 0.1132720
	speed: 0.1323s/iter; left time: 6923.2595s
	iters: 1100, epoch: 1 | loss: 0.0960071
	speed: 0.1341s/iter; left time: 7007.2147s
	iters: 1200, epoch: 1 | loss: 0.1164301
	speed: 0.1340s/iter; left time: 6986.4790s
	iters: 1300, epoch: 1 | loss: 0.1128735
	speed: 0.1386s/iter; left time: 7212.9009s
	iters: 1400, epoch: 1 | loss: 0.1040649
	speed: 0.1381s/iter; left time: 7172.0965s
	iters: 1500, epoch: 1 | loss: 0.1173225
	speed: 0.1367s/iter; left time: 7087.1683s
	iters: 1600, epoch: 1 | loss: 0.1031440
	speed: 0.1357s/iter; left time: 7022.7082s
	iters: 1700, epoch: 1 | loss: 0.0966299
	speed: 0.1365s/iter; left time: 7050.3313s
	iters: 1800, epoch: 1 | loss: 0.1064342
	speed: 0.1373s/iter; left time: 7074.5296s
	iters: 1900, epoch: 1 | loss: 0.0987400
	speed: 0.1397s/iter; left time: 7184.2855s
	iters: 2000, epoch: 1 | loss: 0.1042845
	speed: 0.1376s/iter; left time: 7062.8991s
	iters: 2100, epoch: 1 | loss: 0.0977351
	speed: 0.1341s/iter; left time: 6873.9340s
	iters: 2200, epoch: 1 | loss: 0.0965085
	speed: 0.1368s/iter; left time: 6997.5355s
	iters: 2300, epoch: 1 | loss: 0.0990303
	speed: 0.1378s/iter; left time: 7031.0795s
	iters: 2400, epoch: 1 | loss: 0.1100298
	speed: 0.1376s/iter; left time: 7007.4443s
	iters: 2500, epoch: 1 | loss: 0.0987217
	speed: 0.1347s/iter; left time: 6850.7436s
	iters: 2600, epoch: 1 | loss: 0.1110397
	speed: 0.1366s/iter; left time: 6930.4782s
Epoch: 1 cost time: 00h:06m:00.44s
Epoch: 1 | Train Loss: 0.1213860 Vali Loss: 0.0894020 Test Loss: 0.1034134
Validation loss decreased (inf --> 0.089402).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0940944
	speed: 1.1583s/iter; left time: 58580.2074s
	iters: 200, epoch: 2 | loss: 0.0937534
	speed: 0.1211s/iter; left time: 6113.4005s
	iters: 300, epoch: 2 | loss: 0.1080840
	speed: 0.1210s/iter; left time: 6097.1060s
	iters: 400, epoch: 2 | loss: 0.0966061
	speed: 0.1213s/iter; left time: 6099.9390s
	iters: 500, epoch: 2 | loss: 0.1093938
	speed: 0.1211s/iter; left time: 6075.9139s
	iters: 600, epoch: 2 | loss: 0.0923856
	speed: 0.1210s/iter; left time: 6059.9944s
	iters: 700, epoch: 2 | loss: 0.0916145
	speed: 0.1210s/iter; left time: 6044.4129s
	iters: 800, epoch: 2 | loss: 0.0939326
	speed: 0.1270s/iter; left time: 6334.5841s
	iters: 900, epoch: 2 | loss: 0.1001902
	speed: 0.1224s/iter; left time: 6093.3779s
	iters: 1000, epoch: 2 | loss: 0.0946725
	speed: 0.1216s/iter; left time: 6040.9823s
	iters: 1100, epoch: 2 | loss: 0.0976080
	speed: 0.1278s/iter; left time: 6333.9909s
	iters: 1200, epoch: 2 | loss: 0.1017308
	speed: 0.1228s/iter; left time: 6076.6304s
	iters: 1300, epoch: 2 | loss: 0.1020761
	speed: 0.1233s/iter; left time: 6085.5197s
	iters: 1400, epoch: 2 | loss: 0.0914178
	speed: 0.1252s/iter; left time: 6167.6726s
	iters: 1500, epoch: 2 | loss: 0.1076127
	speed: 0.1282s/iter; left time: 6305.9078s
	iters: 1600, epoch: 2 | loss: 0.0961113
	speed: 0.1237s/iter; left time: 6071.0985s
	iters: 1700, epoch: 2 | loss: 0.1049188
	speed: 0.1224s/iter; left time: 5993.4304s
	iters: 1800, epoch: 2 | loss: 0.0905886
	speed: 0.1245s/iter; left time: 6084.7285s
	iters: 1900, epoch: 2 | loss: 0.0959672
	speed: 0.1236s/iter; left time: 6026.2853s
	iters: 2000, epoch: 2 | loss: 0.0967659
	speed: 0.1231s/iter; left time: 5990.0663s
	iters: 2100, epoch: 2 | loss: 0.1091169
	speed: 0.1255s/iter; left time: 6096.4158s
	iters: 2200, epoch: 2 | loss: 0.0912857
	speed: 0.1252s/iter; left time: 6067.9433s
	iters: 2300, epoch: 2 | loss: 0.0814347
	speed: 0.1250s/iter; left time: 6044.3762s
	iters: 2400, epoch: 2 | loss: 0.1000843
	speed: 0.1259s/iter; left time: 6077.9370s
	iters: 2500, epoch: 2 | loss: 0.0908363
	speed: 0.1233s/iter; left time: 5940.1597s
	iters: 2600, epoch: 2 | loss: 0.0960613
	speed: 0.1229s/iter; left time: 5910.0111s
Epoch: 2 cost time: 00h:05m:30.20s
Epoch: 2 | Train Loss: 0.0975315 Vali Loss: 0.0867351 Test Loss: 0.0988254
Validation loss decreased (0.089402 --> 0.086735).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0956383
	speed: 1.0111s/iter; left time: 48439.5313s
	iters: 200, epoch: 3 | loss: 0.0700900
	speed: 0.1210s/iter; left time: 5785.0743s
	iters: 300, epoch: 3 | loss: 0.0907799
	speed: 0.1237s/iter; left time: 5901.0291s
	iters: 400, epoch: 3 | loss: 0.1059120
	speed: 0.1211s/iter; left time: 5764.3139s
	iters: 500, epoch: 3 | loss: 0.0847025
	speed: 0.1252s/iter; left time: 5947.8382s
	iters: 600, epoch: 3 | loss: 0.1060325
	speed: 0.1260s/iter; left time: 5973.7358s
	iters: 700, epoch: 3 | loss: 0.0842078
	speed: 0.1254s/iter; left time: 5933.6104s
	iters: 800, epoch: 3 | loss: 0.1065284
	speed: 0.1280s/iter; left time: 6044.3419s
	iters: 900, epoch: 3 | loss: 0.0883381
	speed: 0.1258s/iter; left time: 5926.1728s
	iters: 1000, epoch: 3 | loss: 0.0973774
	speed: 0.1240s/iter; left time: 5826.7167s
	iters: 1100, epoch: 3 | loss: 0.1029167
	speed: 0.1263s/iter; left time: 5924.9679s
	iters: 1200, epoch: 3 | loss: 0.1063046
	speed: 0.1249s/iter; left time: 5848.5177s
	iters: 1300, epoch: 3 | loss: 0.0910941
	speed: 0.1252s/iter; left time: 5848.2638s
	iters: 1400, epoch: 3 | loss: 0.0989402
	speed: 0.1244s/iter; left time: 5796.8497s
	iters: 1500, epoch: 3 | loss: 0.0897562
	speed: 0.1248s/iter; left time: 5806.1507s
	iters: 1600, epoch: 3 | loss: 0.1038726
	speed: 0.1234s/iter; left time: 5728.8166s
	iters: 1700, epoch: 3 | loss: 0.1029803
	speed: 0.1230s/iter; left time: 5697.1814s
	iters: 1800, epoch: 3 | loss: 0.0976344
	speed: 0.1254s/iter; left time: 5795.1136s
	iters: 1900, epoch: 3 | loss: 0.0954050
	speed: 0.1267s/iter; left time: 5840.7057s
	iters: 2000, epoch: 3 | loss: 0.0907561
	speed: 0.1243s/iter; left time: 5719.1525s
	iters: 2100, epoch: 3 | loss: 0.1184174
	speed: 0.1246s/iter; left time: 5718.2625s
	iters: 2200, epoch: 3 | loss: 0.0903510
	speed: 0.1227s/iter; left time: 5621.3098s
	iters: 2300, epoch: 3 | loss: 0.0935952
	speed: 0.1255s/iter; left time: 5734.8855s
	iters: 2400, epoch: 3 | loss: 0.0925637
	speed: 0.1246s/iter; left time: 5681.4104s
	iters: 2500, epoch: 3 | loss: 0.0878491
	speed: 0.1232s/iter; left time: 5607.6450s
	iters: 2600, epoch: 3 | loss: 0.1013690
	speed: 0.1243s/iter; left time: 5642.8874s
Epoch: 3 cost time: 00h:05m:32.53s
Epoch: 3 | Train Loss: 0.0937625 Vali Loss: 0.0846537 Test Loss: 0.0967681
Validation loss decreased (0.086735 --> 0.084654).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0943716
	speed: 1.0252s/iter; left time: 46378.2763s
	iters: 200, epoch: 4 | loss: 0.0859998
	speed: 0.1253s/iter; left time: 5655.0744s
	iters: 300, epoch: 4 | loss: 0.0874903
	speed: 0.1238s/iter; left time: 5573.7535s
	iters: 400, epoch: 4 | loss: 0.1020916
	speed: 0.1207s/iter; left time: 5425.0566s
	iters: 500, epoch: 4 | loss: 0.0874067
	speed: 0.1232s/iter; left time: 5522.5633s
	iters: 600, epoch: 4 | loss: 0.1072563
	speed: 0.1241s/iter; left time: 5553.2763s
	iters: 700, epoch: 4 | loss: 0.0964151
	speed: 0.1276s/iter; left time: 5695.1298s
	iters: 800, epoch: 4 | loss: 0.0861687
	speed: 0.1246s/iter; left time: 5549.8543s
	iters: 900, epoch: 4 | loss: 0.0826063
	speed: 0.1228s/iter; left time: 5457.9045s
	iters: 1000, epoch: 4 | loss: 0.0798693
	speed: 0.1227s/iter; left time: 5439.7553s
	iters: 1100, epoch: 4 | loss: 0.0928330
	speed: 0.1249s/iter; left time: 5523.6816s
	iters: 1200, epoch: 4 | loss: 0.0862791
	speed: 0.1213s/iter; left time: 5354.4790s
	iters: 1300, epoch: 4 | loss: 0.0830672
	speed: 0.1236s/iter; left time: 5444.9874s
	iters: 1400, epoch: 4 | loss: 0.0836192
	speed: 0.1264s/iter; left time: 5552.6533s
	iters: 1500, epoch: 4 | loss: 0.0898090
	speed: 0.1274s/iter; left time: 5586.3566s
	iters: 1600, epoch: 4 | loss: 0.0897531
	speed: 0.1289s/iter; left time: 5639.5776s
	iters: 1700, epoch: 4 | loss: 0.0794996
	speed: 0.1250s/iter; left time: 5454.2893s
	iters: 1800, epoch: 4 | loss: 0.0978874
	speed: 0.1252s/iter; left time: 5450.0811s
	iters: 1900, epoch: 4 | loss: 0.0965451
	speed: 0.1261s/iter; left time: 5476.9408s
	iters: 2000, epoch: 4 | loss: 0.0926374
	speed: 0.1249s/iter; left time: 5414.4854s
	iters: 2100, epoch: 4 | loss: 0.1069342
	speed: 0.1238s/iter; left time: 5353.9662s
	iters: 2200, epoch: 4 | loss: 0.0779019
	speed: 0.1226s/iter; left time: 5290.9306s
	iters: 2300, epoch: 4 | loss: 0.0973944
	speed: 0.1237s/iter; left time: 5324.0519s
	iters: 2400, epoch: 4 | loss: 0.0905181
	speed: 0.1245s/iter; left time: 5346.3310s
	iters: 2500, epoch: 4 | loss: 0.0938979
	speed: 0.1257s/iter; left time: 5384.2739s
	iters: 2600, epoch: 4 | loss: 0.0907974
	speed: 0.1224s/iter; left time: 5231.6316s
Epoch: 4 cost time: 00h:05m:32.69s
Epoch: 4 | Train Loss: 0.0911554 Vali Loss: 0.0860957 Test Loss: 0.0986955
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0987655
	speed: 1.0020s/iter; left time: 42659.2306s
	iters: 200, epoch: 5 | loss: 0.0867120
	speed: 0.1229s/iter; left time: 5218.8214s
	iters: 300, epoch: 5 | loss: 0.0962949
	speed: 0.1225s/iter; left time: 5188.6062s
	iters: 400, epoch: 5 | loss: 0.0800745
	speed: 0.1210s/iter; left time: 5115.4481s
	iters: 500, epoch: 5 | loss: 0.0932057
	speed: 0.1209s/iter; left time: 5099.6139s
	iters: 600, epoch: 5 | loss: 0.0953641
	speed: 0.1209s/iter; left time: 5087.6144s
	iters: 700, epoch: 5 | loss: 0.0878022
	speed: 0.1214s/iter; left time: 5097.1209s
	iters: 800, epoch: 5 | loss: 0.0875066
	speed: 0.1269s/iter; left time: 5312.8693s
	iters: 900, epoch: 5 | loss: 0.0935306
	speed: 0.1231s/iter; left time: 5142.1674s
	iters: 1000, epoch: 5 | loss: 0.0829855
	speed: 0.1220s/iter; left time: 5083.7024s
	iters: 1100, epoch: 5 | loss: 0.0839508
	speed: 0.1249s/iter; left time: 5190.4297s
	iters: 1200, epoch: 5 | loss: 0.0897008
	speed: 0.1217s/iter; left time: 5047.7393s
	iters: 1300, epoch: 5 | loss: 0.0881073
	speed: 0.1213s/iter; left time: 5016.9101s
	iters: 1400, epoch: 5 | loss: 0.0853253
	speed: 0.1221s/iter; left time: 5037.6247s
	iters: 1500, epoch: 5 | loss: 0.0889603
	speed: 0.1213s/iter; left time: 4995.7151s
	iters: 1600, epoch: 5 | loss: 0.1002251
	speed: 0.1224s/iter; left time: 5025.9293s
	iters: 1700, epoch: 5 | loss: 0.1032137
	speed: 0.1209s/iter; left time: 4953.0105s
	iters: 1800, epoch: 5 | loss: 0.0937006
	speed: 0.1179s/iter; left time: 4819.2304s
	iters: 1900, epoch: 5 | loss: 0.0855721
	speed: 0.1217s/iter; left time: 4962.4263s
	iters: 2000, epoch: 5 | loss: 0.0733401
	speed: 0.1213s/iter; left time: 4934.6589s
	iters: 2100, epoch: 5 | loss: 0.0945749
	speed: 0.1212s/iter; left time: 4915.5249s
	iters: 2200, epoch: 5 | loss: 0.0890472
	speed: 0.1216s/iter; left time: 4919.5263s
	iters: 2300, epoch: 5 | loss: 0.0819968
	speed: 0.1219s/iter; left time: 4923.2759s
	iters: 2400, epoch: 5 | loss: 0.0929638
	speed: 0.1214s/iter; left time: 4889.8668s
	iters: 2500, epoch: 5 | loss: 0.0771377
	speed: 0.1218s/iter; left time: 4892.6592s
	iters: 2600, epoch: 5 | loss: 0.0927820
	speed: 0.1209s/iter; left time: 4844.7317s
Epoch: 5 cost time: 00h:05m:25.60s
Epoch: 5 | Train Loss: 0.0889107 Vali Loss: 0.0877582 Test Loss: 0.1025786
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0778098
	speed: 0.9853s/iter; left time: 39318.8701s
	iters: 200, epoch: 6 | loss: 0.0997249
	speed: 0.1209s/iter; left time: 4812.0434s
	iters: 300, epoch: 6 | loss: 0.0860444
	speed: 0.1205s/iter; left time: 4785.6072s
	iters: 400, epoch: 6 | loss: 0.0840693
	speed: 0.1208s/iter; left time: 4784.3181s
	iters: 500, epoch: 6 | loss: 0.0925132
	speed: 0.1218s/iter; left time: 4810.5278s
	iters: 600, epoch: 6 | loss: 0.0898937
	speed: 0.1219s/iter; left time: 4801.9659s
	iters: 700, epoch: 6 | loss: 0.0814919
	speed: 0.1212s/iter; left time: 4765.3109s
	iters: 800, epoch: 6 | loss: 0.1018386
	speed: 0.1223s/iter; left time: 4796.2991s
	iters: 900, epoch: 6 | loss: 0.0892932
	speed: 0.1220s/iter; left time: 4771.4083s
	iters: 1000, epoch: 6 | loss: 0.1022972
	speed: 0.1215s/iter; left time: 4739.7651s
	iters: 1100, epoch: 6 | loss: 0.0904634
	speed: 0.1219s/iter; left time: 4743.9487s
	iters: 1200, epoch: 6 | loss: 0.0951061
	speed: 0.1215s/iter; left time: 4715.2855s
	iters: 1300, epoch: 6 | loss: 0.0853480
	speed: 0.1216s/iter; left time: 4707.4551s
	iters: 1400, epoch: 6 | loss: 0.0741242
	speed: 0.1220s/iter; left time: 4710.1310s
	iters: 1500, epoch: 6 | loss: 0.0868103
	speed: 0.1221s/iter; left time: 4703.2494s
	iters: 1600, epoch: 6 | loss: 0.0908482
	speed: 0.1210s/iter; left time: 4646.4541s
	iters: 1700, epoch: 6 | loss: 0.0931770
	speed: 0.1210s/iter; left time: 4636.3783s
	iters: 1800, epoch: 6 | loss: 0.0878102
	speed: 0.1216s/iter; left time: 4644.2799s
	iters: 1900, epoch: 6 | loss: 0.0864693
	speed: 0.1212s/iter; left time: 4619.1132s
	iters: 2000, epoch: 6 | loss: 0.0849704
	speed: 0.1215s/iter; left time: 4616.8922s
	iters: 2100, epoch: 6 | loss: 0.0827954
	speed: 0.1224s/iter; left time: 4641.5312s
	iters: 2200, epoch: 6 | loss: 0.0875449
	speed: 0.1215s/iter; left time: 4593.1797s
	iters: 2300, epoch: 6 | loss: 0.0922521
	speed: 0.1210s/iter; left time: 4562.5609s
	iters: 2400, epoch: 6 | loss: 0.0752860
	speed: 0.1224s/iter; left time: 4601.1472s
	iters: 2500, epoch: 6 | loss: 0.0840485
	speed: 0.1214s/iter; left time: 4553.4182s
	iters: 2600, epoch: 6 | loss: 0.0845857
	speed: 0.1218s/iter; left time: 4555.7339s
Epoch: 6 cost time: 00h:05m:24.67s
Epoch: 6 | Train Loss: 0.0867293 Vali Loss: 0.0884304 Test Loss: 0.1025518
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0863808
	speed: 0.9872s/iter; left time: 36762.2306s
	iters: 200, epoch: 7 | loss: 0.0894201
	speed: 0.1209s/iter; left time: 4491.5510s
	iters: 300, epoch: 7 | loss: 0.0827672
	speed: 0.1215s/iter; left time: 4501.7148s
	iters: 400, epoch: 7 | loss: 0.0769152
	speed: 0.1217s/iter; left time: 4495.2310s
	iters: 500, epoch: 7 | loss: 0.0987583
	speed: 0.1219s/iter; left time: 4492.3762s
	iters: 600, epoch: 7 | loss: 0.0983056
	speed: 0.1217s/iter; left time: 4471.4719s
	iters: 700, epoch: 7 | loss: 0.0806711
	speed: 0.1211s/iter; left time: 4437.7577s
	iters: 800, epoch: 7 | loss: 0.0801147
	speed: 0.1217s/iter; left time: 4448.3418s
	iters: 900, epoch: 7 | loss: 0.0864820
	speed: 0.1211s/iter; left time: 4413.1006s
	iters: 1000, epoch: 7 | loss: 0.0967652
	speed: 0.1211s/iter; left time: 4400.4862s
	iters: 1100, epoch: 7 | loss: 0.0854905
	speed: 0.1218s/iter; left time: 4413.8199s
	iters: 1200, epoch: 7 | loss: 0.0898021
	speed: 0.1215s/iter; left time: 4391.5048s
	iters: 1300, epoch: 7 | loss: 0.0775288
	speed: 0.1211s/iter; left time: 4364.7440s
	iters: 1400, epoch: 7 | loss: 0.0811367
	speed: 0.1220s/iter; left time: 4384.5554s
	iters: 1500, epoch: 7 | loss: 0.0821564
	speed: 0.1221s/iter; left time: 4376.5042s
	iters: 1600, epoch: 7 | loss: 0.0834867
	speed: 0.1209s/iter; left time: 4319.9650s
	iters: 1700, epoch: 7 | loss: 0.0906567
	speed: 0.1214s/iter; left time: 4325.1408s
	iters: 1800, epoch: 7 | loss: 0.0855301
	speed: 0.1215s/iter; left time: 4318.3206s
	iters: 1900, epoch: 7 | loss: 0.0763849
	speed: 0.1217s/iter; left time: 4314.5973s
	iters: 2000, epoch: 7 | loss: 0.0703013
	speed: 0.1210s/iter; left time: 4276.2867s
	iters: 2100, epoch: 7 | loss: 0.0814764
	speed: 0.1210s/iter; left time: 4264.3762s
	iters: 2200, epoch: 7 | loss: 0.0879330
	speed: 0.1218s/iter; left time: 4280.7708s
	iters: 2300, epoch: 7 | loss: 0.0835790
	speed: 0.1211s/iter; left time: 4244.9109s
	iters: 2400, epoch: 7 | loss: 0.0896361
	speed: 0.1218s/iter; left time: 4255.1946s
	iters: 2500, epoch: 7 | loss: 0.0880383
	speed: 0.1086s/iter; left time: 3781.9075s
	iters: 2600, epoch: 7 | loss: 0.0784809
	speed: 0.1211s/iter; left time: 4206.5790s
Epoch: 7 cost time: 00h:05m:23.26s
Epoch: 7 | Train Loss: 0.0847558 Vali Loss: 0.0862495 Test Loss: 0.0994056
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0741981
	speed: 0.9810s/iter; left time: 33914.3502s
	iters: 200, epoch: 8 | loss: 0.0925967
	speed: 0.1212s/iter; left time: 4178.9310s
	iters: 300, epoch: 8 | loss: 0.0885595
	speed: 0.1228s/iter; left time: 4222.0146s
	iters: 400, epoch: 8 | loss: 0.0859595
	speed: 0.1206s/iter; left time: 4133.5993s
	iters: 500, epoch: 8 | loss: 0.0826866
	speed: 0.1214s/iter; left time: 4146.8640s
	iters: 600, epoch: 8 | loss: 0.0911786
	speed: 0.1172s/iter; left time: 3994.1187s
	iters: 700, epoch: 8 | loss: 0.0777338
	speed: 0.1022s/iter; left time: 3472.4484s
	iters: 800, epoch: 8 | loss: 0.0907550
	speed: 0.1116s/iter; left time: 3780.6471s
	iters: 900, epoch: 8 | loss: 0.0851398
	speed: 0.1206s/iter; left time: 4072.8584s
	iters: 1000, epoch: 8 | loss: 0.0833690
	speed: 0.1202s/iter; left time: 4048.5154s
	iters: 1100, epoch: 8 | loss: 0.0865234
	speed: 0.1221s/iter; left time: 4098.9670s
	iters: 1200, epoch: 8 | loss: 0.0920289
	speed: 0.1208s/iter; left time: 4043.0623s
	iters: 1300, epoch: 8 | loss: 0.0871832
	speed: 0.1211s/iter; left time: 4040.1468s
	iters: 1400, epoch: 8 | loss: 0.0754475
	speed: 0.1219s/iter; left time: 4056.4614s
	iters: 1500, epoch: 8 | loss: 0.0724243
	speed: 0.1219s/iter; left time: 4043.3316s
	iters: 1600, epoch: 8 | loss: 0.0741268
	speed: 0.1235s/iter; left time: 4084.5362s
	iters: 1700, epoch: 8 | loss: 0.0789550
	speed: 0.1219s/iter; left time: 4018.3443s
	iters: 1800, epoch: 8 | loss: 0.0848181
	speed: 0.1211s/iter; left time: 3980.7807s
	iters: 1900, epoch: 8 | loss: 0.0913343
	speed: 0.1215s/iter; left time: 3982.0553s
	iters: 2000, epoch: 8 | loss: 0.0802559
	speed: 0.1212s/iter; left time: 3960.6434s
	iters: 2100, epoch: 8 | loss: 0.0726332
	speed: 0.1208s/iter; left time: 3935.0157s
	iters: 2200, epoch: 8 | loss: 0.0801809
	speed: 0.1210s/iter; left time: 3929.5657s
	iters: 2300, epoch: 8 | loss: 0.0922091
	speed: 0.1212s/iter; left time: 3922.2804s
	iters: 2400, epoch: 8 | loss: 0.0758863
	speed: 0.1217s/iter; left time: 3928.1347s
	iters: 2500, epoch: 8 | loss: 0.0947716
	speed: 0.1214s/iter; left time: 3904.1909s
	iters: 2600, epoch: 8 | loss: 0.0881028
	speed: 0.1208s/iter; left time: 3872.8132s
Epoch: 8 cost time: 00h:05m:21.09s
Epoch: 8 | Train Loss: 0.0829597 Vali Loss: 0.0875380 Test Loss: 0.1024083
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.02114104852080345, rmse:0.14539961516857147, mae:0.09676817059516907, rse:0.4269324839115143
success delete checkpoints
Intermediate time for ES and pred_len 168: 00h:56m:01.46s

Intermediate time for ES: 04h:04m:27.92s


=== Starting experiments for country: FR ===


=== Starting experiments for pred_len: 24 ===

train 85803
val 18651
test 18651
[2024-11-01 09:47:33,435] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 09:47:34,670] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 09:47:34,670] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 09:47:34,670] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 09:47:34,778] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 09:47:34,778] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 09:47:35,475] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 09:47:35,476] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 09:47:35,476] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 09:47:35,478] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 09:47:35,478] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 09:47:35,478] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 09:47:35,478] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 09:47:35,478] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 09:47:35,478] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 09:47:35,478] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 09:47:35,789] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 09:47:35,790] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 09:47:35,790] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.58 GB, percent = 9.9%
[2024-11-01 09:47:35,932] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 09:47:35,933] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 09:47:35,933] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.58 GB, percent = 9.9%
[2024-11-01 09:47:35,933] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 09:47:36,049] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 09:47:36,050] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 09:47:36,050] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.58 GB, percent = 9.9%
[2024-11-01 09:47:36,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 09:47:36,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 09:47:36,051] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 09:47:36,051] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 09:47:36,052] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 09:47:36,052] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 09:47:36,052] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 09:47:36,052] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 09:47:36,052] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fd380ca1fd0>
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 09:47:36,053] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 09:47:36,054] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 09:47:36,055] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 09:47:36,055] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 09:47:36,055] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 09:47:36,055] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 09:47:36,055] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1535002
	speed: 0.1767s/iter; left time: 9456.9561s
	iters: 200, epoch: 1 | loss: 0.1159472
	speed: 0.1306s/iter; left time: 6977.8591s
	iters: 300, epoch: 1 | loss: 0.1058322
	speed: 0.1308s/iter; left time: 6976.8535s
	iters: 400, epoch: 1 | loss: 0.0828711
	speed: 0.1309s/iter; left time: 6964.6522s
	iters: 500, epoch: 1 | loss: 0.0717254
	speed: 0.1308s/iter; left time: 6946.9785s
	iters: 600, epoch: 1 | loss: 0.0627306
	speed: 0.1309s/iter; left time: 6938.6058s
	iters: 700, epoch: 1 | loss: 0.0745939
	speed: 0.1307s/iter; left time: 6916.4001s
	iters: 800, epoch: 1 | loss: 0.0592833
	speed: 0.1309s/iter; left time: 6916.8188s
	iters: 900, epoch: 1 | loss: 0.0581057
	speed: 0.1308s/iter; left time: 6895.9582s
	iters: 1000, epoch: 1 | loss: 0.0899070
	speed: 0.1311s/iter; left time: 6898.2324s
	iters: 1100, epoch: 1 | loss: 0.0486953
	speed: 0.1308s/iter; left time: 6868.7595s
	iters: 1200, epoch: 1 | loss: 0.0688207
	speed: 0.1309s/iter; left time: 6861.1983s
	iters: 1300, epoch: 1 | loss: 0.0650532
	speed: 0.1310s/iter; left time: 6852.9696s
	iters: 1400, epoch: 1 | loss: 0.0587849
	speed: 0.1308s/iter; left time: 6832.8113s
	iters: 1500, epoch: 1 | loss: 0.0618791
	speed: 0.1308s/iter; left time: 6815.5254s
	iters: 1600, epoch: 1 | loss: 0.0509475
	speed: 0.1302s/iter; left time: 6772.8913s
	iters: 1700, epoch: 1 | loss: 0.0735843
	speed: 0.1304s/iter; left time: 6770.2498s
	iters: 1800, epoch: 1 | loss: 0.0482276
	speed: 0.1308s/iter; left time: 6777.4642s
	iters: 1900, epoch: 1 | loss: 0.0562918
	speed: 0.1304s/iter; left time: 6746.8120s
	iters: 2000, epoch: 1 | loss: 0.0636575
	speed: 0.1307s/iter; left time: 6746.6387s
	iters: 2100, epoch: 1 | loss: 0.0499355
	speed: 0.1304s/iter; left time: 6718.0000s
	iters: 2200, epoch: 1 | loss: 0.0701026
	speed: 0.1309s/iter; left time: 6729.1525s
	iters: 2300, epoch: 1 | loss: 0.0674836
	speed: 0.1308s/iter; left time: 6711.1604s
	iters: 2400, epoch: 1 | loss: 0.0581415
	speed: 0.1306s/iter; left time: 6691.8900s
	iters: 2500, epoch: 1 | loss: 0.0673574
	speed: 0.1308s/iter; left time: 6684.2609s
	iters: 2600, epoch: 1 | loss: 0.0543020
	speed: 0.1309s/iter; left time: 6676.6414s
Epoch: 1 cost time: 00h:05m:51.82s
Epoch: 1 | Train Loss: 0.0739179 Vali Loss: 0.0605835 Test Loss: 0.0654644
Validation loss decreased (inf --> 0.060583).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0619027
	speed: 1.1601s/iter; left time: 58981.6326s
	iters: 200, epoch: 2 | loss: 0.0812935
	speed: 0.1206s/iter; left time: 6117.9054s
	iters: 300, epoch: 2 | loss: 0.0682675
	speed: 0.1208s/iter; left time: 6116.1616s
	iters: 400, epoch: 2 | loss: 0.0864105
	speed: 0.1208s/iter; left time: 6103.5345s
	iters: 500, epoch: 2 | loss: 0.0529756
	speed: 0.1207s/iter; left time: 6090.2955s
	iters: 600, epoch: 2 | loss: 0.0543025
	speed: 0.1204s/iter; left time: 6062.0852s
	iters: 700, epoch: 2 | loss: 0.0502084
	speed: 0.1206s/iter; left time: 6060.1081s
	iters: 800, epoch: 2 | loss: 0.0579205
	speed: 0.1202s/iter; left time: 6026.8903s
	iters: 900, epoch: 2 | loss: 0.0560098
	speed: 0.1207s/iter; left time: 6041.6591s
	iters: 1000, epoch: 2 | loss: 0.0432923
	speed: 0.1190s/iter; left time: 5944.9101s
	iters: 1100, epoch: 2 | loss: 0.0533719
	speed: 0.1204s/iter; left time: 6002.5974s
	iters: 1200, epoch: 2 | loss: 0.0699260
	speed: 0.1210s/iter; left time: 6019.6795s
	iters: 1300, epoch: 2 | loss: 0.0667628
	speed: 0.1206s/iter; left time: 5987.4322s
	iters: 1400, epoch: 2 | loss: 0.0512179
	speed: 0.1207s/iter; left time: 5978.6194s
	iters: 1500, epoch: 2 | loss: 0.0579801
	speed: 0.1210s/iter; left time: 5984.1324s
	iters: 1600, epoch: 2 | loss: 0.0674562
	speed: 0.1212s/iter; left time: 5978.8969s
	iters: 1700, epoch: 2 | loss: 0.0445822
	speed: 0.1206s/iter; left time: 5937.7977s
	iters: 1800, epoch: 2 | loss: 0.0552087
	speed: 0.1204s/iter; left time: 5915.8043s
	iters: 1900, epoch: 2 | loss: 0.0708642
	speed: 0.1200s/iter; left time: 5886.4199s
	iters: 2000, epoch: 2 | loss: 0.0525380
	speed: 0.1209s/iter; left time: 5918.0652s
	iters: 2100, epoch: 2 | loss: 0.0523798
	speed: 0.1207s/iter; left time: 5894.2877s
	iters: 2200, epoch: 2 | loss: 0.0721295
	speed: 0.1203s/iter; left time: 5865.6717s
	iters: 2300, epoch: 2 | loss: 0.0610736
	speed: 0.1209s/iter; left time: 5880.8741s
	iters: 2400, epoch: 2 | loss: 0.0564372
	speed: 0.1208s/iter; left time: 5863.7943s
	iters: 2500, epoch: 2 | loss: 0.0445440
	speed: 0.1211s/iter; left time: 5865.4601s
	iters: 2600, epoch: 2 | loss: 0.0545508
	speed: 0.1207s/iter; left time: 5835.2821s
Epoch: 2 cost time: 00h:05m:23.84s
Epoch: 2 | Train Loss: 0.0589849 Vali Loss: 0.0589729 Test Loss: 0.0641147
Validation loss decreased (0.060583 --> 0.058973).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0636515
	speed: 1.0160s/iter; left time: 48927.5380s
	iters: 200, epoch: 3 | loss: 0.0587107
	speed: 0.1025s/iter; left time: 4924.6393s
	iters: 300, epoch: 3 | loss: 0.0566106
	speed: 0.1142s/iter; left time: 5475.7523s
	iters: 400, epoch: 3 | loss: 0.0612787
	speed: 0.1210s/iter; left time: 5788.9074s
	iters: 500, epoch: 3 | loss: 0.0468024
	speed: 0.1202s/iter; left time: 5742.4917s
	iters: 600, epoch: 3 | loss: 0.0613940
	speed: 0.1217s/iter; left time: 5797.8605s
	iters: 700, epoch: 3 | loss: 0.0506664
	speed: 0.1201s/iter; left time: 5714.1696s
	iters: 800, epoch: 3 | loss: 0.0535050
	speed: 0.1205s/iter; left time: 5719.1032s
	iters: 900, epoch: 3 | loss: 0.0552201
	speed: 0.1210s/iter; left time: 5731.9854s
	iters: 1000, epoch: 3 | loss: 0.0510626
	speed: 0.1208s/iter; left time: 5709.5338s
	iters: 1100, epoch: 3 | loss: 0.0414352
	speed: 0.1204s/iter; left time: 5676.8729s
	iters: 1200, epoch: 3 | loss: 0.0635938
	speed: 0.1203s/iter; left time: 5659.0936s
	iters: 1300, epoch: 3 | loss: 0.0423877
	speed: 0.1204s/iter; left time: 5654.3160s
	iters: 1400, epoch: 3 | loss: 0.0537974
	speed: 0.1209s/iter; left time: 5663.5680s
	iters: 1500, epoch: 3 | loss: 0.0664770
	speed: 0.1213s/iter; left time: 5671.2559s
	iters: 1600, epoch: 3 | loss: 0.0489237
	speed: 0.1210s/iter; left time: 5646.0563s
	iters: 1700, epoch: 3 | loss: 0.0435316
	speed: 0.1209s/iter; left time: 5629.9411s
	iters: 1800, epoch: 3 | loss: 0.0485576
	speed: 0.1211s/iter; left time: 5626.2829s
	iters: 1900, epoch: 3 | loss: 0.0613631
	speed: 0.1207s/iter; left time: 5595.8934s
	iters: 2000, epoch: 3 | loss: 0.0441004
	speed: 0.1205s/iter; left time: 5576.2035s
	iters: 2100, epoch: 3 | loss: 0.0450289
	speed: 0.1209s/iter; left time: 5580.6217s
	iters: 2200, epoch: 3 | loss: 0.0547356
	speed: 0.1199s/iter; left time: 5522.4641s
	iters: 2300, epoch: 3 | loss: 0.0599108
	speed: 0.1206s/iter; left time: 5543.7689s
	iters: 2400, epoch: 3 | loss: 0.0434626
	speed: 0.1202s/iter; left time: 5512.1879s
	iters: 2500, epoch: 3 | loss: 0.0669618
	speed: 0.1206s/iter; left time: 5519.0605s
	iters: 2600, epoch: 3 | loss: 0.0644993
	speed: 0.1205s/iter; left time: 5501.0091s
Epoch: 3 cost time: 00h:05m:21.19s
Epoch: 3 | Train Loss: 0.0563925 Vali Loss: 0.0578105 Test Loss: 0.0628996
Validation loss decreased (0.058973 --> 0.057811).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0500212
	speed: 1.0162s/iter; left time: 46213.7863s
	iters: 200, epoch: 4 | loss: 0.0662548
	speed: 0.1204s/iter; left time: 5464.4848s
	iters: 300, epoch: 4 | loss: 0.0432065
	speed: 0.1207s/iter; left time: 5466.1180s
	iters: 400, epoch: 4 | loss: 0.0570253
	speed: 0.1199s/iter; left time: 5415.9655s
	iters: 500, epoch: 4 | loss: 0.0514172
	speed: 0.1205s/iter; left time: 5431.6101s
	iters: 600, epoch: 4 | loss: 0.0459452
	speed: 0.1091s/iter; left time: 4908.1816s
	iters: 700, epoch: 4 | loss: 0.0489160
	speed: 0.1208s/iter; left time: 5422.1681s
	iters: 800, epoch: 4 | loss: 0.0543107
	speed: 0.1202s/iter; left time: 5381.8183s
	iters: 900, epoch: 4 | loss: 0.0444514
	speed: 0.1201s/iter; left time: 5366.4132s
	iters: 1000, epoch: 4 | loss: 0.0546588
	speed: 0.1207s/iter; left time: 5382.3771s
	iters: 1100, epoch: 4 | loss: 0.0588563
	speed: 0.1208s/iter; left time: 5374.2767s
	iters: 1200, epoch: 4 | loss: 0.0534603
	speed: 0.1149s/iter; left time: 5100.9132s
	iters: 1300, epoch: 4 | loss: 0.0535597
	speed: 0.1205s/iter; left time: 5335.0038s
	iters: 1400, epoch: 4 | loss: 0.0503390
	speed: 0.1206s/iter; left time: 5326.8381s
	iters: 1500, epoch: 4 | loss: 0.0542765
	speed: 0.1205s/iter; left time: 5311.8158s
	iters: 1600, epoch: 4 | loss: 0.0546105
	speed: 0.1213s/iter; left time: 5333.3962s
	iters: 1700, epoch: 4 | loss: 0.0538735
	speed: 0.1206s/iter; left time: 5290.2169s
	iters: 1800, epoch: 4 | loss: 0.0518390
	speed: 0.1203s/iter; left time: 5266.6494s
	iters: 1900, epoch: 4 | loss: 0.0519650
	speed: 0.1201s/iter; left time: 5244.7686s
	iters: 2000, epoch: 4 | loss: 0.0477860
	speed: 0.1195s/iter; left time: 5206.5835s
	iters: 2100, epoch: 4 | loss: 0.0585879
	speed: 0.1210s/iter; left time: 5260.3706s
	iters: 2200, epoch: 4 | loss: 0.0599166
	speed: 0.1203s/iter; left time: 5218.4697s
	iters: 2300, epoch: 4 | loss: 0.0504315
	speed: 0.1197s/iter; left time: 5179.5132s
	iters: 2400, epoch: 4 | loss: 0.0512709
	speed: 0.1201s/iter; left time: 5186.8751s
	iters: 2500, epoch: 4 | loss: 0.0432640
	speed: 0.1206s/iter; left time: 5195.3247s
	iters: 2600, epoch: 4 | loss: 0.0526977
	speed: 0.1207s/iter; left time: 5188.1003s
Epoch: 4 cost time: 00h:05m:21.74s
Epoch: 4 | Train Loss: 0.0547071 Vali Loss: 0.0565705 Test Loss: 0.0614690
Validation loss decreased (0.057811 --> 0.056570).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0500493
	speed: 1.0188s/iter; left time: 43599.9651s
	iters: 200, epoch: 5 | loss: 0.0452871
	speed: 0.1208s/iter; left time: 5158.5571s
	iters: 300, epoch: 5 | loss: 0.0708607
	speed: 0.1207s/iter; left time: 5141.8266s
	iters: 400, epoch: 5 | loss: 0.0393255
	speed: 0.1207s/iter; left time: 5129.9464s
	iters: 500, epoch: 5 | loss: 0.0584477
	speed: 0.1202s/iter; left time: 5096.1367s
	iters: 600, epoch: 5 | loss: 0.0544610
	speed: 0.1114s/iter; left time: 4710.6961s
	iters: 700, epoch: 5 | loss: 0.0538923
	speed: 0.1191s/iter; left time: 5025.2685s
	iters: 800, epoch: 5 | loss: 0.0542743
	speed: 0.1202s/iter; left time: 5060.8179s
	iters: 900, epoch: 5 | loss: 0.0646305
	speed: 0.1209s/iter; left time: 5077.8855s
	iters: 1000, epoch: 5 | loss: 0.0515460
	speed: 0.1205s/iter; left time: 5049.4144s
	iters: 1100, epoch: 5 | loss: 0.0574071
	speed: 0.1205s/iter; left time: 5036.0520s
	iters: 1200, epoch: 5 | loss: 0.0493728
	speed: 0.1209s/iter; left time: 5041.5865s
	iters: 1300, epoch: 5 | loss: 0.0618911
	speed: 0.1211s/iter; left time: 5038.3230s
	iters: 1400, epoch: 5 | loss: 0.0536328
	speed: 0.1210s/iter; left time: 5022.7344s
	iters: 1500, epoch: 5 | loss: 0.0613508
	speed: 0.1212s/iter; left time: 5016.2771s
	iters: 1600, epoch: 5 | loss: 0.0503679
	speed: 0.1211s/iter; left time: 5001.8521s
	iters: 1700, epoch: 5 | loss: 0.0521905
	speed: 0.1209s/iter; left time: 4980.1324s
	iters: 1800, epoch: 5 | loss: 0.0556836
	speed: 0.1206s/iter; left time: 4956.0639s
	iters: 1900, epoch: 5 | loss: 0.0641983
	speed: 0.1206s/iter; left time: 4944.9392s
	iters: 2000, epoch: 5 | loss: 0.0585940
	speed: 0.1207s/iter; left time: 4936.5343s
	iters: 2100, epoch: 5 | loss: 0.0435131
	speed: 0.1202s/iter; left time: 4905.7362s
	iters: 2200, epoch: 5 | loss: 0.0479925
	speed: 0.1209s/iter; left time: 4919.7308s
	iters: 2300, epoch: 5 | loss: 0.0534774
	speed: 0.1206s/iter; left time: 4897.5109s
	iters: 2400, epoch: 5 | loss: 0.0596892
	speed: 0.1208s/iter; left time: 4893.3134s
	iters: 2500, epoch: 5 | loss: 0.0679414
	speed: 0.1208s/iter; left time: 4881.2000s
	iters: 2600, epoch: 5 | loss: 0.0447534
	speed: 0.1210s/iter; left time: 4874.0178s
Epoch: 5 cost time: 00h:05m:23.01s
Epoch: 5 | Train Loss: 0.0534883 Vali Loss: 0.0565160 Test Loss: 0.0616658
Validation loss decreased (0.056570 --> 0.056516).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0517764
	speed: 1.0191s/iter; left time: 40883.5887s
	iters: 200, epoch: 6 | loss: 0.0638383
	speed: 0.1204s/iter; left time: 4818.3253s
	iters: 300, epoch: 6 | loss: 0.0642103
	speed: 0.1212s/iter; left time: 4838.7733s
	iters: 400, epoch: 6 | loss: 0.0472873
	speed: 0.1201s/iter; left time: 4781.2298s
	iters: 500, epoch: 6 | loss: 0.0434228
	speed: 0.1203s/iter; left time: 4779.3461s
	iters: 600, epoch: 6 | loss: 0.0501320
	speed: 0.1208s/iter; left time: 4786.0051s
	iters: 700, epoch: 6 | loss: 0.0372537
	speed: 0.1206s/iter; left time: 4764.8733s
	iters: 800, epoch: 6 | loss: 0.0626084
	speed: 0.1208s/iter; left time: 4761.5108s
	iters: 900, epoch: 6 | loss: 0.0585214
	speed: 0.1203s/iter; left time: 4729.6506s
	iters: 1000, epoch: 6 | loss: 0.0676461
	speed: 0.1203s/iter; left time: 4718.0472s
	iters: 1100, epoch: 6 | loss: 0.0532079
	speed: 0.1200s/iter; left time: 4694.1628s
	iters: 1200, epoch: 6 | loss: 0.0608200
	speed: 0.1206s/iter; left time: 4705.5866s
	iters: 1300, epoch: 6 | loss: 0.0481969
	speed: 0.1201s/iter; left time: 4674.5202s
	iters: 1400, epoch: 6 | loss: 0.0451223
	speed: 0.1209s/iter; left time: 4692.6621s
	iters: 1500, epoch: 6 | loss: 0.0623270
	speed: 0.1207s/iter; left time: 4674.1433s
	iters: 1600, epoch: 6 | loss: 0.0533873
	speed: 0.1198s/iter; left time: 4624.6211s
	iters: 1700, epoch: 6 | loss: 0.0445180
	speed: 0.1210s/iter; left time: 4660.9453s
	iters: 1800, epoch: 6 | loss: 0.0662053
	speed: 0.1209s/iter; left time: 4644.0757s
	iters: 1900, epoch: 6 | loss: 0.0493251
	speed: 0.1207s/iter; left time: 4626.2547s
	iters: 2000, epoch: 6 | loss: 0.0448093
	speed: 0.1208s/iter; left time: 4616.8936s
	iters: 2100, epoch: 6 | loss: 0.0606518
	speed: 0.1205s/iter; left time: 4593.2189s
	iters: 2200, epoch: 6 | loss: 0.0587236
	speed: 0.1203s/iter; left time: 4572.5865s
	iters: 2300, epoch: 6 | loss: 0.0420482
	speed: 0.1206s/iter; left time: 4574.2905s
	iters: 2400, epoch: 6 | loss: 0.0426998
	speed: 0.1205s/iter; left time: 4555.1738s
	iters: 2500, epoch: 6 | loss: 0.0466667
	speed: 0.1205s/iter; left time: 4545.8888s
	iters: 2600, epoch: 6 | loss: 0.0537168
	speed: 0.1205s/iter; left time: 4533.2946s
Epoch: 6 cost time: 00h:05m:23.72s
Epoch: 6 | Train Loss: 0.0525643 Vali Loss: 0.0556040 Test Loss: 0.0610864
Validation loss decreased (0.056516 --> 0.055604).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0668757
	speed: 1.0185s/iter; left time: 38129.1857s
	iters: 200, epoch: 7 | loss: 0.0545903
	speed: 0.1205s/iter; left time: 4498.6741s
	iters: 300, epoch: 7 | loss: 0.0470054
	speed: 0.1211s/iter; left time: 4509.3425s
	iters: 400, epoch: 7 | loss: 0.0559453
	speed: 0.1206s/iter; left time: 4478.5608s
	iters: 500, epoch: 7 | loss: 0.0481483
	speed: 0.1201s/iter; left time: 4447.6729s
	iters: 600, epoch: 7 | loss: 0.0419734
	speed: 0.1204s/iter; left time: 4446.9116s
	iters: 700, epoch: 7 | loss: 0.0507655
	speed: 0.1200s/iter; left time: 4420.6055s
	iters: 800, epoch: 7 | loss: 0.0553637
	speed: 0.1192s/iter; left time: 4379.0402s
	iters: 900, epoch: 7 | loss: 0.0417836
	speed: 0.1198s/iter; left time: 4389.8594s
	iters: 1000, epoch: 7 | loss: 0.0594274
	speed: 0.1196s/iter; left time: 4370.7764s
	iters: 1100, epoch: 7 | loss: 0.0467496
	speed: 0.1196s/iter; left time: 4358.5357s
	iters: 1200, epoch: 7 | loss: 0.0645316
	speed: 0.1208s/iter; left time: 4387.7828s
	iters: 1300, epoch: 7 | loss: 0.0443441
	speed: 0.1199s/iter; left time: 4343.4639s
	iters: 1400, epoch: 7 | loss: 0.0480593
	speed: 0.1179s/iter; left time: 4260.5835s
	iters: 1500, epoch: 7 | loss: 0.0565358
	speed: 0.1212s/iter; left time: 4366.0785s
	iters: 1600, epoch: 7 | loss: 0.0584448
	speed: 0.1209s/iter; left time: 4343.2550s
	iters: 1700, epoch: 7 | loss: 0.0491271
	speed: 0.1208s/iter; left time: 4327.7441s
	iters: 1800, epoch: 7 | loss: 0.0501366
	speed: 0.1216s/iter; left time: 4345.1652s
	iters: 1900, epoch: 7 | loss: 0.0490542
	speed: 0.1200s/iter; left time: 4276.1900s
	iters: 2000, epoch: 7 | loss: 0.0508287
	speed: 0.1203s/iter; left time: 4275.3045s
	iters: 2100, epoch: 7 | loss: 0.0515859
	speed: 0.1207s/iter; left time: 4276.9953s
	iters: 2200, epoch: 7 | loss: 0.0453970
	speed: 0.1202s/iter; left time: 4247.4094s
	iters: 2300, epoch: 7 | loss: 0.0537278
	speed: 0.1208s/iter; left time: 4258.0536s
	iters: 2400, epoch: 7 | loss: 0.0542764
	speed: 0.1068s/iter; left time: 3750.9417s
	iters: 2500, epoch: 7 | loss: 0.0465567
	speed: 0.1021s/iter; left time: 3577.9362s
	iters: 2600, epoch: 7 | loss: 0.0497594
	speed: 0.1161s/iter; left time: 4055.0245s
Epoch: 7 cost time: 00h:05m:19.43s
Epoch: 7 | Train Loss: 0.0518482 Vali Loss: 0.0550725 Test Loss: 0.0603381
Validation loss decreased (0.055604 --> 0.055073).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0724908
	speed: 1.0163s/iter; left time: 35320.0094s
	iters: 200, epoch: 8 | loss: 0.0371657
	speed: 0.1129s/iter; left time: 3911.5390s
	iters: 300, epoch: 8 | loss: 0.0593067
	speed: 0.1161s/iter; left time: 4010.1167s
	iters: 400, epoch: 8 | loss: 0.0512719
	speed: 0.1210s/iter; left time: 4169.9432s
	iters: 500, epoch: 8 | loss: 0.0472560
	speed: 0.1206s/iter; left time: 4144.2491s
	iters: 600, epoch: 8 | loss: 0.0475125
	speed: 0.1206s/iter; left time: 4132.7054s
	iters: 700, epoch: 8 | loss: 0.0528827
	speed: 0.1207s/iter; left time: 4123.3320s
	iters: 800, epoch: 8 | loss: 0.0542871
	speed: 0.1209s/iter; left time: 4117.0930s
	iters: 900, epoch: 8 | loss: 0.0525813
	speed: 0.1211s/iter; left time: 4112.3121s
	iters: 1000, epoch: 8 | loss: 0.0576860
	speed: 0.1081s/iter; left time: 3661.0480s
	iters: 1100, epoch: 8 | loss: 0.0429319
	speed: 0.1159s/iter; left time: 3910.9687s
	iters: 1200, epoch: 8 | loss: 0.0528561
	speed: 0.1208s/iter; left time: 4064.9739s
	iters: 1300, epoch: 8 | loss: 0.0534785
	speed: 0.1200s/iter; left time: 4027.1384s
	iters: 1400, epoch: 8 | loss: 0.0459838
	speed: 0.1205s/iter; left time: 4032.2009s
	iters: 1500, epoch: 8 | loss: 0.0495800
	speed: 0.1207s/iter; left time: 4026.0832s
	iters: 1600, epoch: 8 | loss: 0.0621961
	speed: 0.1207s/iter; left time: 4012.7311s
	iters: 1700, epoch: 8 | loss: 0.0502770
	speed: 0.1208s/iter; left time: 4005.7230s
	iters: 1800, epoch: 8 | loss: 0.0546408
	speed: 0.1214s/iter; left time: 4014.2178s
	iters: 1900, epoch: 8 | loss: 0.0553437
	speed: 0.1210s/iter; left time: 3987.6481s
	iters: 2000, epoch: 8 | loss: 0.0498420
	speed: 0.1210s/iter; left time: 3976.0902s
	iters: 2100, epoch: 8 | loss: 0.0456712
	speed: 0.1206s/iter; left time: 3950.6493s
	iters: 2200, epoch: 8 | loss: 0.0570142
	speed: 0.1208s/iter; left time: 3943.2124s
	iters: 2300, epoch: 8 | loss: 0.0586175
	speed: 0.1208s/iter; left time: 3933.2592s
	iters: 2400, epoch: 8 | loss: 0.0472034
	speed: 0.1135s/iter; left time: 3685.0316s
	iters: 2500, epoch: 8 | loss: 0.0537372
	speed: 0.1106s/iter; left time: 3579.6205s
	iters: 2600, epoch: 8 | loss: 0.0509919
	speed: 0.1196s/iter; left time: 3858.3864s
Epoch: 8 cost time: 00h:05m:19.32s
Epoch: 8 | Train Loss: 0.0511598 Vali Loss: 0.0561661 Test Loss: 0.0617564
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0486406
	speed: 1.0057s/iter; left time: 32254.3415s
	iters: 200, epoch: 9 | loss: 0.0556457
	speed: 0.1211s/iter; left time: 3870.9459s
	iters: 300, epoch: 9 | loss: 0.0395175
	speed: 0.1209s/iter; left time: 3854.3437s
	iters: 400, epoch: 9 | loss: 0.0557750
	speed: 0.1207s/iter; left time: 3835.9641s
	iters: 500, epoch: 9 | loss: 0.0424190
	speed: 0.1204s/iter; left time: 3813.3195s
	iters: 600, epoch: 9 | loss: 0.0351209
	speed: 0.1212s/iter; left time: 3826.9381s
	iters: 700, epoch: 9 | loss: 0.0446073
	speed: 0.1204s/iter; left time: 3788.4783s
	iters: 800, epoch: 9 | loss: 0.0384792
	speed: 0.1205s/iter; left time: 3780.1015s
	iters: 900, epoch: 9 | loss: 0.0720906
	speed: 0.1209s/iter; left time: 3780.3002s
	iters: 1000, epoch: 9 | loss: 0.0432853
	speed: 0.1209s/iter; left time: 3768.9995s
	iters: 1100, epoch: 9 | loss: 0.0520263
	speed: 0.1210s/iter; left time: 3759.5277s
	iters: 1200, epoch: 9 | loss: 0.0406994
	speed: 0.1208s/iter; left time: 3742.4004s
	iters: 1300, epoch: 9 | loss: 0.0368552
	speed: 0.1204s/iter; left time: 3717.7139s
	iters: 1400, epoch: 9 | loss: 0.0537488
	speed: 0.1211s/iter; left time: 3726.4136s
	iters: 1500, epoch: 9 | loss: 0.0565366
	speed: 0.1214s/iter; left time: 3722.9692s
	iters: 1600, epoch: 9 | loss: 0.0400267
	speed: 0.1210s/iter; left time: 3699.1753s
	iters: 1700, epoch: 9 | loss: 0.0363783
	speed: 0.1208s/iter; left time: 3681.4039s
	iters: 1800, epoch: 9 | loss: 0.0432666
	speed: 0.1210s/iter; left time: 3676.3661s
	iters: 1900, epoch: 9 | loss: 0.0467523
	speed: 0.1209s/iter; left time: 3660.5201s
	iters: 2000, epoch: 9 | loss: 0.0596244
	speed: 0.1206s/iter; left time: 3639.1054s
	iters: 2100, epoch: 9 | loss: 0.0576644
	speed: 0.1209s/iter; left time: 3635.1925s
	iters: 2200, epoch: 9 | loss: 0.0496884
	speed: 0.1208s/iter; left time: 3620.1523s
	iters: 2300, epoch: 9 | loss: 0.0494345
	speed: 0.1209s/iter; left time: 3610.2338s
	iters: 2400, epoch: 9 | loss: 0.0386619
	speed: 0.1187s/iter; left time: 3534.6992s
	iters: 2500, epoch: 9 | loss: 0.0411887
	speed: 0.1209s/iter; left time: 3587.4411s
	iters: 2600, epoch: 9 | loss: 0.0443211
	speed: 0.1205s/iter; left time: 3562.9188s
Epoch: 9 cost time: 00h:05m:24.11s
Epoch: 9 | Train Loss: 0.0506318 Vali Loss: 0.0546863 Test Loss: 0.0599749
Validation loss decreased (0.055073 --> 0.054686).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0549749
	speed: 1.0167s/iter; left time: 29882.2757s
	iters: 200, epoch: 10 | loss: 0.0383406
	speed: 0.1201s/iter; left time: 3518.4641s
	iters: 300, epoch: 10 | loss: 0.0472804
	speed: 0.1206s/iter; left time: 3520.6253s
	iters: 400, epoch: 10 | loss: 0.0422506
	speed: 0.1207s/iter; left time: 3511.2358s
	iters: 500, epoch: 10 | loss: 0.0550114
	speed: 0.1200s/iter; left time: 3479.8145s
	iters: 600, epoch: 10 | loss: 0.0441338
	speed: 0.1200s/iter; left time: 3467.7047s
	iters: 700, epoch: 10 | loss: 0.0540485
	speed: 0.1203s/iter; left time: 3464.5516s
	iters: 800, epoch: 10 | loss: 0.0546766
	speed: 0.1202s/iter; left time: 3447.9440s
	iters: 900, epoch: 10 | loss: 0.0499431
	speed: 0.1201s/iter; left time: 3434.2522s
	iters: 1000, epoch: 10 | loss: 0.0570361
	speed: 0.1205s/iter; left time: 3432.9802s
	iters: 1100, epoch: 10 | loss: 0.0438565
	speed: 0.1199s/iter; left time: 3404.0302s
	iters: 1200, epoch: 10 | loss: 0.0453070
	speed: 0.1200s/iter; left time: 3393.7573s
	iters: 1300, epoch: 10 | loss: 0.0541585
	speed: 0.1201s/iter; left time: 3386.5670s
	iters: 1400, epoch: 10 | loss: 0.0488800
	speed: 0.1202s/iter; left time: 3375.9738s
	iters: 1500, epoch: 10 | loss: 0.0653748
	speed: 0.1197s/iter; left time: 3351.8683s
	iters: 1600, epoch: 10 | loss: 0.0513718
	speed: 0.1213s/iter; left time: 3384.0512s
	iters: 1700, epoch: 10 | loss: 0.0519211
	speed: 0.1217s/iter; left time: 3383.2746s
	iters: 1800, epoch: 10 | loss: 0.0510913
	speed: 0.1208s/iter; left time: 3345.4994s
	iters: 1900, epoch: 10 | loss: 0.0787238
	speed: 0.1207s/iter; left time: 3330.2029s
	iters: 2000, epoch: 10 | loss: 0.0443497
	speed: 0.1208s/iter; left time: 3321.5760s
	iters: 2100, epoch: 10 | loss: 0.0386278
	speed: 0.1201s/iter; left time: 3289.8422s
	iters: 2200, epoch: 10 | loss: 0.0553838
	speed: 0.1198s/iter; left time: 3269.8105s
	iters: 2300, epoch: 10 | loss: 0.0513475
	speed: 0.1203s/iter; left time: 3271.4273s
	iters: 2400, epoch: 10 | loss: 0.0396648
	speed: 0.1204s/iter; left time: 3261.9901s
	iters: 2500, epoch: 10 | loss: 0.0409211
	speed: 0.1210s/iter; left time: 3267.0834s
	iters: 2600, epoch: 10 | loss: 0.0425374
	speed: 0.1205s/iter; left time: 3240.6208s
Epoch: 10 cost time: 00h:05m:23.48s
Epoch: 10 | Train Loss: 0.0501928 Vali Loss: 0.0552204 Test Loss: 0.0600623
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 11 | loss: 0.0620002
	speed: 0.9997s/iter; left time: 26701.9387s
	iters: 200, epoch: 11 | loss: 0.0374523
	speed: 0.1070s/iter; left time: 2847.6236s
	iters: 300, epoch: 11 | loss: 0.0529428
	speed: 0.1178s/iter; left time: 3121.9197s
	iters: 400, epoch: 11 | loss: 0.0386790
	speed: 0.1203s/iter; left time: 3177.4499s
	iters: 500, epoch: 11 | loss: 0.0355124
	speed: 0.1208s/iter; left time: 3177.7102s
	iters: 600, epoch: 11 | loss: 0.0515568
	speed: 0.1213s/iter; left time: 3179.3728s
	iters: 700, epoch: 11 | loss: 0.0656706
	speed: 0.1203s/iter; left time: 3141.3655s
	iters: 800, epoch: 11 | loss: 0.0524726
	speed: 0.1207s/iter; left time: 3139.5442s
	iters: 900, epoch: 11 | loss: 0.0677181
	speed: 0.1209s/iter; left time: 3132.7989s
	iters: 1000, epoch: 11 | loss: 0.0548737
	speed: 0.1204s/iter; left time: 3108.1454s
	iters: 1100, epoch: 11 | loss: 0.0569288
	speed: 0.1206s/iter; left time: 3099.7904s
	iters: 1200, epoch: 11 | loss: 0.0609900
	speed: 0.1208s/iter; left time: 3094.1036s
	iters: 1300, epoch: 11 | loss: 0.0399404
	speed: 0.1208s/iter; left time: 3080.7027s
	iters: 1400, epoch: 11 | loss: 0.0586750
	speed: 0.1070s/iter; left time: 2718.2817s
	iters: 1500, epoch: 11 | loss: 0.0501058
	speed: 0.1211s/iter; left time: 3065.4128s
	iters: 1600, epoch: 11 | loss: 0.0411009
	speed: 0.1216s/iter; left time: 3064.6042s
	iters: 1700, epoch: 11 | loss: 0.0643648
	speed: 0.1214s/iter; left time: 3048.2299s
	iters: 1800, epoch: 11 | loss: 0.0525917
	speed: 0.1207s/iter; left time: 3019.3287s
	iters: 1900, epoch: 11 | loss: 0.0451737
	speed: 0.1207s/iter; left time: 3007.2425s
	iters: 2000, epoch: 11 | loss: 0.0579281
	speed: 0.1183s/iter; left time: 2935.5011s
	iters: 2100, epoch: 11 | loss: 0.0540055
	speed: 0.1192s/iter; left time: 2945.4971s
	iters: 2200, epoch: 11 | loss: 0.0435182
	speed: 0.1205s/iter; left time: 2966.6080s
	iters: 2300, epoch: 11 | loss: 0.0541128
	speed: 0.1215s/iter; left time: 2977.8557s
	iters: 2400, epoch: 11 | loss: 0.0472108
	speed: 0.1208s/iter; left time: 2950.0345s
	iters: 2500, epoch: 11 | loss: 0.0526714
	speed: 0.1152s/iter; left time: 2801.0023s
	iters: 2600, epoch: 11 | loss: 0.0492443
	speed: 0.1211s/iter; left time: 2932.5734s
Epoch: 11 cost time: 00h:05m:20.51s
Epoch: 11 | Train Loss: 0.0496507 Vali Loss: 0.0557215 Test Loss: 0.0603047
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 12 | loss: 0.0461969
	speed: 1.0021s/iter; left time: 24079.8231s
	iters: 200, epoch: 12 | loss: 0.0482488
	speed: 0.1206s/iter; left time: 2886.3327s
	iters: 300, epoch: 12 | loss: 0.0463038
	speed: 0.1207s/iter; left time: 2876.0206s
	iters: 400, epoch: 12 | loss: 0.0601207
	speed: 0.1206s/iter; left time: 2861.6739s
	iters: 500, epoch: 12 | loss: 0.0524425
	speed: 0.1187s/iter; left time: 2806.0298s
	iters: 600, epoch: 12 | loss: 0.0494985
	speed: 0.1033s/iter; left time: 2431.4239s
	iters: 700, epoch: 12 | loss: 0.0530444
	speed: 0.1200s/iter; left time: 2812.5319s
	iters: 800, epoch: 12 | loss: 0.0502007
	speed: 0.1193s/iter; left time: 2784.1332s
	iters: 900, epoch: 12 | loss: 0.0386652
	speed: 0.1198s/iter; left time: 2782.8374s
	iters: 1000, epoch: 12 | loss: 0.0524950
	speed: 0.1205s/iter; left time: 2787.0250s
	iters: 1100, epoch: 12 | loss: 0.0360246
	speed: 0.1194s/iter; left time: 2748.7165s
	iters: 1200, epoch: 12 | loss: 0.0573246
	speed: 0.1196s/iter; left time: 2742.8701s
	iters: 1300, epoch: 12 | loss: 0.0448311
	speed: 0.1193s/iter; left time: 2724.6823s
	iters: 1400, epoch: 12 | loss: 0.0468765
	speed: 0.1200s/iter; left time: 2728.0973s
	iters: 1500, epoch: 12 | loss: 0.0427486
	speed: 0.1201s/iter; left time: 2718.5249s
	iters: 1600, epoch: 12 | loss: 0.0422873
	speed: 0.1190s/iter; left time: 2681.4113s
	iters: 1700, epoch: 12 | loss: 0.0424657
	speed: 0.1193s/iter; left time: 2675.8393s
	iters: 1800, epoch: 12 | loss: 0.0512158
	speed: 0.1196s/iter; left time: 2671.3625s
	iters: 1900, epoch: 12 | loss: 0.0482876
	speed: 0.1193s/iter; left time: 2652.0677s
	iters: 2000, epoch: 12 | loss: 0.0403065
	speed: 0.1118s/iter; left time: 2475.1210s
	iters: 2100, epoch: 12 | loss: 0.0512401
	speed: 0.1203s/iter; left time: 2650.2194s
	iters: 2200, epoch: 12 | loss: 0.0528152
	speed: 0.1028s/iter; left time: 2253.9245s
	iters: 2300, epoch: 12 | loss: 0.0479994
	speed: 0.1171s/iter; left time: 2555.5745s
	iters: 2400, epoch: 12 | loss: 0.0547172
	speed: 0.1198s/iter; left time: 2602.2258s
	iters: 2500, epoch: 12 | loss: 0.0471118
	speed: 0.1201s/iter; left time: 2598.6451s
	iters: 2600, epoch: 12 | loss: 0.0501922
	speed: 0.1203s/iter; left time: 2590.6900s
Epoch: 12 cost time: 00h:05m:17.44s
Epoch: 12 | Train Loss: 0.0491253 Vali Loss: 0.0558346 Test Loss: 0.0616492
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 13 | loss: 0.0454289
	speed: 0.9922s/iter; left time: 21183.2626s
	iters: 200, epoch: 13 | loss: 0.0566784
	speed: 0.1204s/iter; left time: 2558.8539s
	iters: 300, epoch: 13 | loss: 0.0492385
	speed: 0.1200s/iter; left time: 2538.1225s
	iters: 400, epoch: 13 | loss: 0.0413138
	speed: 0.1024s/iter; left time: 2154.6356s
	iters: 500, epoch: 13 | loss: 0.0430361
	speed: 0.1042s/iter; left time: 2183.3766s
	iters: 600, epoch: 13 | loss: 0.0513702
	speed: 0.1219s/iter; left time: 2541.8010s
	iters: 700, epoch: 13 | loss: 0.0502950
	speed: 0.1209s/iter; left time: 2509.3149s
	iters: 800, epoch: 13 | loss: 0.0534758
	speed: 0.1208s/iter; left time: 2494.9589s
	iters: 900, epoch: 13 | loss: 0.0518013
	speed: 0.1205s/iter; left time: 2476.1994s
	iters: 1000, epoch: 13 | loss: 0.0583335
	speed: 0.1199s/iter; left time: 2451.5419s
	iters: 1100, epoch: 13 | loss: 0.0650049
	speed: 0.1155s/iter; left time: 2349.3675s
	iters: 1200, epoch: 13 | loss: 0.0528312
	speed: 0.1212s/iter; left time: 2454.4293s
	iters: 1300, epoch: 13 | loss: 0.0473740
	speed: 0.1207s/iter; left time: 2432.3801s
	iters: 1400, epoch: 13 | loss: 0.0452519
	speed: 0.1197s/iter; left time: 2400.6977s
	iters: 1500, epoch: 13 | loss: 0.0424276
	speed: 0.1208s/iter; left time: 2410.4358s
	iters: 1600, epoch: 13 | loss: 0.0521983
	speed: 0.1093s/iter; left time: 2169.8448s
	iters: 1700, epoch: 13 | loss: 0.0471075
	speed: 0.1210s/iter; left time: 2390.1550s
	iters: 1800, epoch: 13 | loss: 0.0435151
	speed: 0.1203s/iter; left time: 2363.1459s
	iters: 1900, epoch: 13 | loss: 0.0494255
	speed: 0.1212s/iter; left time: 2368.5964s
	iters: 2000, epoch: 13 | loss: 0.0469670
	speed: 0.1209s/iter; left time: 2351.9989s
	iters: 2100, epoch: 13 | loss: 0.0472251
	speed: 0.1197s/iter; left time: 2316.4476s
	iters: 2200, epoch: 13 | loss: 0.0486188
	speed: 0.1211s/iter; left time: 2331.5692s
	iters: 2300, epoch: 13 | loss: 0.0509845
	speed: 0.1206s/iter; left time: 2308.8339s
	iters: 2400, epoch: 13 | loss: 0.0457661
	speed: 0.1200s/iter; left time: 2285.7200s
	iters: 2500, epoch: 13 | loss: 0.0508229
	speed: 0.1191s/iter; left time: 2256.1184s
	iters: 2600, epoch: 13 | loss: 0.0558406
	speed: 0.1207s/iter; left time: 2274.6115s
Epoch: 13 cost time: 00h:05m:17.53s
Epoch: 13 | Train Loss: 0.0487104 Vali Loss: 0.0579919 Test Loss: 0.0634963
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 14 | loss: 0.0413323
	speed: 0.9986s/iter; left time: 18641.6608s
	iters: 200, epoch: 14 | loss: 0.0421818
	speed: 0.1204s/iter; left time: 2235.6244s
	iters: 300, epoch: 14 | loss: 0.0630368
	speed: 0.1207s/iter; left time: 2228.6635s
	iters: 400, epoch: 14 | loss: 0.0455646
	speed: 0.1202s/iter; left time: 2207.3190s
	iters: 500, epoch: 14 | loss: 0.0373397
	speed: 0.1202s/iter; left time: 2195.2879s
	iters: 600, epoch: 14 | loss: 0.0462459
	speed: 0.1212s/iter; left time: 2201.5756s
	iters: 700, epoch: 14 | loss: 0.0535143
	speed: 0.1202s/iter; left time: 2171.6056s
	iters: 800, epoch: 14 | loss: 0.0559032
	speed: 0.1203s/iter; left time: 2161.3690s
	iters: 900, epoch: 14 | loss: 0.0622907
	speed: 0.1210s/iter; left time: 2161.3614s
	iters: 1000, epoch: 14 | loss: 0.0430358
	speed: 0.1142s/iter; left time: 2029.2671s
	iters: 1100, epoch: 14 | loss: 0.0412004
	speed: 0.1202s/iter; left time: 2123.7152s
	iters: 1200, epoch: 14 | loss: 0.0447963
	speed: 0.1199s/iter; left time: 2106.5802s
	iters: 1300, epoch: 14 | loss: 0.0473538
	speed: 0.1210s/iter; left time: 2114.3970s
	iters: 1400, epoch: 14 | loss: 0.0410066
	speed: 0.1206s/iter; left time: 2094.8129s
	iters: 1500, epoch: 14 | loss: 0.0531902
	speed: 0.1203s/iter; left time: 2077.9892s
	iters: 1600, epoch: 14 | loss: 0.0443050
	speed: 0.1205s/iter; left time: 2069.2638s
	iters: 1700, epoch: 14 | loss: 0.0529488
	speed: 0.1207s/iter; left time: 2059.9307s
	iters: 1800, epoch: 14 | loss: 0.0568460
	speed: 0.1202s/iter; left time: 2039.3879s
	iters: 1900, epoch: 14 | loss: 0.0442665
	speed: 0.1200s/iter; left time: 2024.2595s
	iters: 2000, epoch: 14 | loss: 0.0497327
	speed: 0.1199s/iter; left time: 2010.5553s
	iters: 2100, epoch: 14 | loss: 0.0499501
	speed: 0.1201s/iter; left time: 2002.1074s
	iters: 2200, epoch: 14 | loss: 0.0507595
	speed: 0.1204s/iter; left time: 1995.5327s
	iters: 2300, epoch: 14 | loss: 0.0538237
	speed: 0.1201s/iter; left time: 1977.4425s
	iters: 2400, epoch: 14 | loss: 0.0460961
	speed: 0.1209s/iter; left time: 1979.1287s
	iters: 2500, epoch: 14 | loss: 0.0627327
	speed: 0.1209s/iter; left time: 1967.4317s
	iters: 2600, epoch: 14 | loss: 0.0460155
	speed: 0.1210s/iter; left time: 1955.6607s
Epoch: 14 cost time: 00h:05m:22.77s
Epoch: 14 | Train Loss: 0.0482707 Vali Loss: 0.0567447 Test Loss: 0.0618993
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.011070186272263527, rmse:0.10521495342254639, mae:0.059974875301122665, rse:0.40591442584991455
success delete checkpoints
Intermediate time for FR and pred_len 24: 01h:35m:12.27s


=== Starting experiments for pred_len: 96 ===

train 85587
val 18435
test 18435
[2024-11-01 11:22:45,402] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 11:22:46,572] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 11:22:46,572] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 11:22:46,572] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 11:22:46,679] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 11:22:46,679] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 11:22:47,360] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 11:22:47,362] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 11:22:47,362] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 11:22:47,364] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 11:22:47,364] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 11:22:47,364] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 11:22:47,364] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 11:22:47,364] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 11:22:47,364] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 11:22:47,364] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 11:22:47,672] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 11:22:47,673] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 11:22:47,673] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.67 GB, percent = 9.9%
[2024-11-01 11:22:47,791] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 11:22:47,792] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 11:22:47,792] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.67 GB, percent = 9.9%
[2024-11-01 11:22:47,792] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 11:22:47,904] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 11:22:47,905] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 11:22:47,905] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 74.67 GB, percent = 9.9%
[2024-11-01 11:22:47,906] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 11:22:47,906] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 11:22:47,906] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 11:22:47,906] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 11:22:47,907] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 11:22:47,907] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 11:22:47,907] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 11:22:47,907] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 11:22:47,907] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f166ebf0710>
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 11:22:47,908] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 11:22:47,909] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 11:22:47,910] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 11:22:47,910] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 11:22:47,910] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 11:22:47,910] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1506957
	speed: 0.1751s/iter; left time: 9349.6598s
	iters: 200, epoch: 1 | loss: 0.1479850
	speed: 0.1310s/iter; left time: 6979.0771s
	iters: 300, epoch: 1 | loss: 0.1137763
	speed: 0.1308s/iter; left time: 6956.4687s
	iters: 400, epoch: 1 | loss: 0.1076533
	speed: 0.1313s/iter; left time: 6969.1401s
	iters: 500, epoch: 1 | loss: 0.0889011
	speed: 0.1306s/iter; left time: 6918.4580s
	iters: 600, epoch: 1 | loss: 0.0769084
	speed: 0.1311s/iter; left time: 6930.7115s
	iters: 700, epoch: 1 | loss: 0.0896481
	speed: 0.1306s/iter; left time: 6894.0510s
	iters: 800, epoch: 1 | loss: 0.0794844
	speed: 0.1300s/iter; left time: 6846.7115s
	iters: 900, epoch: 1 | loss: 0.0815863
	speed: 0.1303s/iter; left time: 6849.9779s
	iters: 1000, epoch: 1 | loss: 0.0779093
	speed: 0.1301s/iter; left time: 6829.4902s
	iters: 1100, epoch: 1 | loss: 0.0663487
	speed: 0.1156s/iter; left time: 6055.3742s
	iters: 1200, epoch: 1 | loss: 0.0627032
	speed: 0.1242s/iter; left time: 6493.1432s
	iters: 1300, epoch: 1 | loss: 0.0696527
	speed: 0.1296s/iter; left time: 6762.5623s
	iters: 1400, epoch: 1 | loss: 0.0784859
	speed: 0.1319s/iter; left time: 6870.0200s
	iters: 1500, epoch: 1 | loss: 0.0762833
	speed: 0.1203s/iter; left time: 6252.6836s
	iters: 1600, epoch: 1 | loss: 0.0648971
	speed: 0.1133s/iter; left time: 5876.9669s
	iters: 1700, epoch: 1 | loss: 0.0801568
	speed: 0.1134s/iter; left time: 5870.4367s
	iters: 1800, epoch: 1 | loss: 0.0775711
	speed: 0.1139s/iter; left time: 5884.7935s
	iters: 1900, epoch: 1 | loss: 0.0935053
	speed: 0.1232s/iter; left time: 6356.8452s
	iters: 2000, epoch: 1 | loss: 0.0565456
	speed: 0.1303s/iter; left time: 6710.0954s
	iters: 2100, epoch: 1 | loss: 0.0903167
	speed: 0.1304s/iter; left time: 6700.4210s
	iters: 2200, epoch: 1 | loss: 0.0752582
	speed: 0.1306s/iter; left time: 6699.3190s
	iters: 2300, epoch: 1 | loss: 0.0761704
	speed: 0.1308s/iter; left time: 6692.0513s
	iters: 2400, epoch: 1 | loss: 0.0646984
	speed: 0.1300s/iter; left time: 6638.9959s
	iters: 2500, epoch: 1 | loss: 0.0703335
	speed: 0.1303s/iter; left time: 6642.7903s
	iters: 2600, epoch: 1 | loss: 0.0783555
	speed: 0.1311s/iter; left time: 6669.5708s
Epoch: 1 cost time: 00h:05m:41.46s
Epoch: 1 | Train Loss: 0.0856850 Vali Loss: 0.0756439 Test Loss: 0.0843909
Validation loss decreased (inf --> 0.075644).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0820017
	speed: 1.1350s/iter; left time: 57551.0438s
	iters: 200, epoch: 2 | loss: 0.0687233
	speed: 0.1201s/iter; left time: 6075.4324s
	iters: 300, epoch: 2 | loss: 0.0772514
	speed: 0.1212s/iter; left time: 6119.5730s
	iters: 400, epoch: 2 | loss: 0.0848139
	speed: 0.1200s/iter; left time: 6049.9097s
	iters: 500, epoch: 2 | loss: 0.0686562
	speed: 0.1196s/iter; left time: 6016.0186s
	iters: 600, epoch: 2 | loss: 0.0745008
	speed: 0.1191s/iter; left time: 5980.6560s
	iters: 700, epoch: 2 | loss: 0.0605222
	speed: 0.1199s/iter; left time: 6008.6909s
	iters: 800, epoch: 2 | loss: 0.0737291
	speed: 0.1197s/iter; left time: 5984.8640s
	iters: 900, epoch: 2 | loss: 0.0731786
	speed: 0.1198s/iter; left time: 5977.5350s
	iters: 1000, epoch: 2 | loss: 0.0705629
	speed: 0.1191s/iter; left time: 5934.1243s
	iters: 1100, epoch: 2 | loss: 0.0684758
	speed: 0.1190s/iter; left time: 5916.1633s
	iters: 1200, epoch: 2 | loss: 0.1017207
	speed: 0.1193s/iter; left time: 5920.5217s
	iters: 1300, epoch: 2 | loss: 0.0608158
	speed: 0.1200s/iter; left time: 5942.9356s
	iters: 1400, epoch: 2 | loss: 0.0733602
	speed: 0.1187s/iter; left time: 5863.9424s
	iters: 1500, epoch: 2 | loss: 0.0823769
	speed: 0.1206s/iter; left time: 5948.0708s
	iters: 1600, epoch: 2 | loss: 0.0670033
	speed: 0.1201s/iter; left time: 5910.3427s
	iters: 1700, epoch: 2 | loss: 0.0635963
	speed: 0.1200s/iter; left time: 5891.7780s
	iters: 1800, epoch: 2 | loss: 0.0702989
	speed: 0.1201s/iter; left time: 5885.1621s
	iters: 1900, epoch: 2 | loss: 0.0682929
	speed: 0.1204s/iter; left time: 5887.8482s
	iters: 2000, epoch: 2 | loss: 0.0600829
	speed: 0.1195s/iter; left time: 5834.6618s
	iters: 2100, epoch: 2 | loss: 0.0654664
	speed: 0.1207s/iter; left time: 5879.7385s
	iters: 2200, epoch: 2 | loss: 0.0597576
	speed: 0.1205s/iter; left time: 5855.9107s
	iters: 2300, epoch: 2 | loss: 0.0667420
	speed: 0.1201s/iter; left time: 5826.0785s
	iters: 2400, epoch: 2 | loss: 0.0765030
	speed: 0.1205s/iter; left time: 5833.4914s
	iters: 2500, epoch: 2 | loss: 0.0623692
	speed: 0.1200s/iter; left time: 5796.7179s
	iters: 2600, epoch: 2 | loss: 0.0587819
	speed: 0.1186s/iter; left time: 5717.6883s
Epoch: 2 cost time: 00h:05m:21.12s
Epoch: 2 | Train Loss: 0.0710048 Vali Loss: 0.0745253 Test Loss: 0.0838230
Validation loss decreased (0.075644 --> 0.074525).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0658879
	speed: 1.0101s/iter; left time: 48519.0051s
	iters: 200, epoch: 3 | loss: 0.0615703
	speed: 0.1201s/iter; left time: 5757.7553s
	iters: 300, epoch: 3 | loss: 0.0726208
	speed: 0.1216s/iter; left time: 5817.9997s
	iters: 400, epoch: 3 | loss: 0.0762616
	speed: 0.1195s/iter; left time: 5702.2888s
	iters: 500, epoch: 3 | loss: 0.0660659
	speed: 0.1199s/iter; left time: 5710.6232s
	iters: 600, epoch: 3 | loss: 0.0651958
	speed: 0.1206s/iter; left time: 5733.7320s
	iters: 700, epoch: 3 | loss: 0.0897581
	speed: 0.1188s/iter; left time: 5636.3366s
	iters: 800, epoch: 3 | loss: 0.0652855
	speed: 0.1201s/iter; left time: 5683.1165s
	iters: 900, epoch: 3 | loss: 0.0668169
	speed: 0.1193s/iter; left time: 5636.9228s
	iters: 1000, epoch: 3 | loss: 0.0626059
	speed: 0.1187s/iter; left time: 5594.6056s
	iters: 1100, epoch: 3 | loss: 0.0549380
	speed: 0.1198s/iter; left time: 5634.8127s
	iters: 1200, epoch: 3 | loss: 0.0706437
	speed: 0.1199s/iter; left time: 5628.5179s
	iters: 1300, epoch: 3 | loss: 0.0740227
	speed: 0.1207s/iter; left time: 5651.0140s
	iters: 1400, epoch: 3 | loss: 0.0664061
	speed: 0.1199s/iter; left time: 5603.8054s
	iters: 1500, epoch: 3 | loss: 0.0757374
	speed: 0.1191s/iter; left time: 5554.4733s
	iters: 1600, epoch: 3 | loss: 0.0855467
	speed: 0.1190s/iter; left time: 5537.0620s
	iters: 1700, epoch: 3 | loss: 0.0756636
	speed: 0.1183s/iter; left time: 5492.5795s
	iters: 1800, epoch: 3 | loss: 0.0538661
	speed: 0.1195s/iter; left time: 5536.2299s
	iters: 1900, epoch: 3 | loss: 0.0783621
	speed: 0.1196s/iter; left time: 5529.0552s
	iters: 2000, epoch: 3 | loss: 0.0645575
	speed: 0.1186s/iter; left time: 5471.5984s
	iters: 2100, epoch: 3 | loss: 0.0941539
	speed: 0.1196s/iter; left time: 5505.2675s
	iters: 2200, epoch: 3 | loss: 0.0742499
	speed: 0.1183s/iter; left time: 5433.0405s
	iters: 2300, epoch: 3 | loss: 0.0604884
	speed: 0.1195s/iter; left time: 5475.9703s
	iters: 2400, epoch: 3 | loss: 0.0683079
	speed: 0.1182s/iter; left time: 5403.4890s
	iters: 2500, epoch: 3 | loss: 0.0758141
	speed: 0.1195s/iter; left time: 5452.7680s
	iters: 2600, epoch: 3 | loss: 0.0615954
	speed: 0.1201s/iter; left time: 5466.9327s
Epoch: 3 cost time: 00h:05m:20.18s
Epoch: 3 | Train Loss: 0.0687785 Vali Loss: 0.0725997 Test Loss: 0.0817405
Validation loss decreased (0.074525 --> 0.072600).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0635042
	speed: 1.0078s/iter; left time: 45711.6120s
	iters: 200, epoch: 4 | loss: 0.0766480
	speed: 0.1207s/iter; left time: 5463.4321s
	iters: 300, epoch: 4 | loss: 0.0603194
	speed: 0.1204s/iter; left time: 5437.8544s
	iters: 400, epoch: 4 | loss: 0.0879604
	speed: 0.1205s/iter; left time: 5430.1768s
	iters: 500, epoch: 4 | loss: 0.0716096
	speed: 0.1209s/iter; left time: 5436.9420s
	iters: 600, epoch: 4 | loss: 0.0661810
	speed: 0.1209s/iter; left time: 5425.1984s
	iters: 700, epoch: 4 | loss: 0.0630168
	speed: 0.1196s/iter; left time: 5354.5827s
	iters: 800, epoch: 4 | loss: 0.0750177
	speed: 0.1195s/iter; left time: 5336.1849s
	iters: 900, epoch: 4 | loss: 0.0560872
	speed: 0.1191s/iter; left time: 5306.5630s
	iters: 1000, epoch: 4 | loss: 0.0561997
	speed: 0.1202s/iter; left time: 5344.6300s
	iters: 1100, epoch: 4 | loss: 0.0634589
	speed: 0.1199s/iter; left time: 5316.7201s
	iters: 1200, epoch: 4 | loss: 0.0602584
	speed: 0.1196s/iter; left time: 5292.1789s
	iters: 1300, epoch: 4 | loss: 0.0809753
	speed: 0.1202s/iter; left time: 5308.1347s
	iters: 1400, epoch: 4 | loss: 0.0696282
	speed: 0.1201s/iter; left time: 5292.5759s
	iters: 1500, epoch: 4 | loss: 0.0582918
	speed: 0.1183s/iter; left time: 5199.8582s
	iters: 1600, epoch: 4 | loss: 0.0587403
	speed: 0.1184s/iter; left time: 5194.5858s
	iters: 1700, epoch: 4 | loss: 0.0575944
	speed: 0.1196s/iter; left time: 5233.5142s
	iters: 1800, epoch: 4 | loss: 0.0667402
	speed: 0.1204s/iter; left time: 5256.4078s
	iters: 1900, epoch: 4 | loss: 0.0664581
	speed: 0.1200s/iter; left time: 5227.1697s
	iters: 2000, epoch: 4 | loss: 0.0745811
	speed: 0.1057s/iter; left time: 4592.6947s
	iters: 2100, epoch: 4 | loss: 0.0695823
	speed: 0.1174s/iter; left time: 5090.6185s
	iters: 2200, epoch: 4 | loss: 0.0542657
	speed: 0.1201s/iter; left time: 5196.0761s
	iters: 2300, epoch: 4 | loss: 0.0670997
	speed: 0.1195s/iter; left time: 5157.0217s
	iters: 2400, epoch: 4 | loss: 0.0595331
	speed: 0.1195s/iter; left time: 5146.2626s
	iters: 2500, epoch: 4 | loss: 0.0590853
	speed: 0.1203s/iter; left time: 5169.8527s
	iters: 2600, epoch: 4 | loss: 0.0622148
	speed: 0.1173s/iter; left time: 5025.6819s
Epoch: 4 cost time: 00h:05m:19.20s
Epoch: 4 | Train Loss: 0.0669450 Vali Loss: 0.0741470 Test Loss: 0.0824094
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0655506
	speed: 0.9811s/iter; left time: 41879.6652s
	iters: 200, epoch: 5 | loss: 0.0827420
	speed: 0.1192s/iter; left time: 5075.7628s
	iters: 300, epoch: 5 | loss: 0.0619815
	speed: 0.1205s/iter; left time: 5119.3541s
	iters: 400, epoch: 5 | loss: 0.0519550
	speed: 0.1201s/iter; left time: 5090.9910s
	iters: 500, epoch: 5 | loss: 0.0678731
	speed: 0.1197s/iter; left time: 5061.8721s
	iters: 600, epoch: 5 | loss: 0.0686385
	speed: 0.1192s/iter; left time: 5029.9501s
	iters: 700, epoch: 5 | loss: 0.0715512
	speed: 0.1182s/iter; left time: 4974.5708s
	iters: 800, epoch: 5 | loss: 0.0702961
	speed: 0.1191s/iter; left time: 4999.8394s
	iters: 900, epoch: 5 | loss: 0.0748347
	speed: 0.1183s/iter; left time: 4953.3427s
	iters: 1000, epoch: 5 | loss: 0.0546004
	speed: 0.1190s/iter; left time: 4970.7516s
	iters: 1100, epoch: 5 | loss: 0.0699323
	speed: 0.1186s/iter; left time: 4942.9108s
	iters: 1200, epoch: 5 | loss: 0.0556661
	speed: 0.1196s/iter; left time: 4975.6329s
	iters: 1300, epoch: 5 | loss: 0.0645581
	speed: 0.1193s/iter; left time: 4949.8879s
	iters: 1400, epoch: 5 | loss: 0.0688608
	speed: 0.1187s/iter; left time: 4911.0268s
	iters: 1500, epoch: 5 | loss: 0.0485171
	speed: 0.1185s/iter; left time: 4893.2452s
	iters: 1600, epoch: 5 | loss: 0.0664087
	speed: 0.1189s/iter; left time: 4896.9899s
	iters: 1700, epoch: 5 | loss: 0.0548556
	speed: 0.1192s/iter; left time: 4896.7069s
	iters: 1800, epoch: 5 | loss: 0.0654618
	speed: 0.1187s/iter; left time: 4866.6101s
	iters: 1900, epoch: 5 | loss: 0.0673945
	speed: 0.1180s/iter; left time: 4826.1755s
	iters: 2000, epoch: 5 | loss: 0.0469344
	speed: 0.1187s/iter; left time: 4840.5091s
	iters: 2100, epoch: 5 | loss: 0.0672865
	speed: 0.1192s/iter; left time: 4848.7010s
	iters: 2200, epoch: 5 | loss: 0.0703256
	speed: 0.1198s/iter; left time: 4862.7784s
	iters: 2300, epoch: 5 | loss: 0.0843584
	speed: 0.1199s/iter; left time: 4853.1134s
	iters: 2400, epoch: 5 | loss: 0.0603486
	speed: 0.1193s/iter; left time: 4817.5601s
	iters: 2500, epoch: 5 | loss: 0.0761832
	speed: 0.1198s/iter; left time: 4824.4121s
	iters: 2600, epoch: 5 | loss: 0.0514573
	speed: 0.1185s/iter; left time: 4763.6939s
Epoch: 5 cost time: 00h:05m:18.86s
Epoch: 5 | Train Loss: 0.0649131 Vali Loss: 0.0754854 Test Loss: 0.0844793
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0773710
	speed: 0.9776s/iter; left time: 39113.4777s
	iters: 200, epoch: 6 | loss: 0.0613844
	speed: 0.1206s/iter; left time: 4814.1503s
	iters: 300, epoch: 6 | loss: 0.0576228
	speed: 0.1196s/iter; left time: 4761.6156s
	iters: 400, epoch: 6 | loss: 0.0596324
	speed: 0.1206s/iter; left time: 4790.4277s
	iters: 500, epoch: 6 | loss: 0.0579083
	speed: 0.1200s/iter; left time: 4754.0140s
	iters: 600, epoch: 6 | loss: 0.0726682
	speed: 0.1194s/iter; left time: 4716.1232s
	iters: 700, epoch: 6 | loss: 0.0726198
	speed: 0.1185s/iter; left time: 4669.9108s
	iters: 800, epoch: 6 | loss: 0.0645957
	speed: 0.1189s/iter; left time: 4673.2563s
	iters: 900, epoch: 6 | loss: 0.0725977
	speed: 0.1201s/iter; left time: 4708.5216s
	iters: 1000, epoch: 6 | loss: 0.0638610
	speed: 0.1196s/iter; left time: 4676.2139s
	iters: 1100, epoch: 6 | loss: 0.0556347
	speed: 0.1191s/iter; left time: 4645.1850s
	iters: 1200, epoch: 6 | loss: 0.0472695
	speed: 0.1195s/iter; left time: 4649.6084s
	iters: 1300, epoch: 6 | loss: 0.0792933
	speed: 0.1093s/iter; left time: 4241.4612s
	iters: 1400, epoch: 6 | loss: 0.0675426
	speed: 0.1108s/iter; left time: 4287.9202s
	iters: 1500, epoch: 6 | loss: 0.0533914
	speed: 0.1146s/iter; left time: 4424.1330s
	iters: 1600, epoch: 6 | loss: 0.0623400
	speed: 0.1192s/iter; left time: 4591.5030s
	iters: 1700, epoch: 6 | loss: 0.0586607
	speed: 0.1199s/iter; left time: 4607.3276s
	iters: 1800, epoch: 6 | loss: 0.0620784
	speed: 0.1191s/iter; left time: 4564.6311s
	iters: 1900, epoch: 6 | loss: 0.0596254
	speed: 0.1188s/iter; left time: 4540.4091s
	iters: 2000, epoch: 6 | loss: 0.0587260
	speed: 0.1197s/iter; left time: 4563.1867s
	iters: 2100, epoch: 6 | loss: 0.0641739
	speed: 0.1197s/iter; left time: 4550.2529s
	iters: 2200, epoch: 6 | loss: 0.0735683
	speed: 0.1195s/iter; left time: 4528.7028s
	iters: 2300, epoch: 6 | loss: 0.0535805
	speed: 0.1197s/iter; left time: 4525.2919s
	iters: 2400, epoch: 6 | loss: 0.0671832
	speed: 0.1162s/iter; left time: 4381.6351s
	iters: 2500, epoch: 6 | loss: 0.0640754
	speed: 0.1070s/iter; left time: 4022.6295s
	iters: 2600, epoch: 6 | loss: 0.0475231
	speed: 0.1158s/iter; left time: 4343.4676s
Epoch: 6 cost time: 00h:05m:15.84s
Epoch: 6 | Train Loss: 0.0630431 Vali Loss: 0.0751659 Test Loss: 0.0838745
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0737136
	speed: 0.9827s/iter; left time: 36690.7581s
	iters: 200, epoch: 7 | loss: 0.0773198
	speed: 0.1189s/iter; left time: 4428.4602s
	iters: 300, epoch: 7 | loss: 0.0562561
	speed: 0.1148s/iter; left time: 4264.7351s
	iters: 400, epoch: 7 | loss: 0.0674500
	speed: 0.1020s/iter; left time: 3777.3044s
	iters: 500, epoch: 7 | loss: 0.0538294
	speed: 0.1021s/iter; left time: 3769.8766s
	iters: 600, epoch: 7 | loss: 0.0683504
	speed: 0.1027s/iter; left time: 3782.2837s
	iters: 700, epoch: 7 | loss: 0.0571279
	speed: 0.1186s/iter; left time: 4356.7608s
	iters: 800, epoch: 7 | loss: 0.0532890
	speed: 0.1117s/iter; left time: 4093.1072s
	iters: 900, epoch: 7 | loss: 0.0591477
	speed: 0.1193s/iter; left time: 4357.2459s
	iters: 1000, epoch: 7 | loss: 0.0772009
	speed: 0.1191s/iter; left time: 4340.1853s
	iters: 1100, epoch: 7 | loss: 0.0556193
	speed: 0.1078s/iter; left time: 3918.5615s
	iters: 1200, epoch: 7 | loss: 0.0560169
	speed: 0.1193s/iter; left time: 4323.4877s
	iters: 1300, epoch: 7 | loss: 0.0597722
	speed: 0.1203s/iter; left time: 4347.9546s
	iters: 1400, epoch: 7 | loss: 0.0604149
	speed: 0.1030s/iter; left time: 3711.2144s
	iters: 1500, epoch: 7 | loss: 0.0788255
	speed: 0.1017s/iter; left time: 3655.6555s
	iters: 1600, epoch: 7 | loss: 0.0704609
	speed: 0.1097s/iter; left time: 3931.3058s
	iters: 1700, epoch: 7 | loss: 0.0629530
	speed: 0.1019s/iter; left time: 3640.2886s
	iters: 1800, epoch: 7 | loss: 0.0610598
	speed: 0.1085s/iter; left time: 3865.0256s
	iters: 1900, epoch: 7 | loss: 0.0446289
	speed: 0.1200s/iter; left time: 4263.8326s
	iters: 2000, epoch: 7 | loss: 0.0594098
	speed: 0.1202s/iter; left time: 4260.5824s
	iters: 2100, epoch: 7 | loss: 0.0708012
	speed: 0.1161s/iter; left time: 4104.2443s
	iters: 2200, epoch: 7 | loss: 0.0720370
	speed: 0.1182s/iter; left time: 4163.7099s
	iters: 2300, epoch: 7 | loss: 0.0789985
	speed: 0.1197s/iter; left time: 4205.8899s
	iters: 2400, epoch: 7 | loss: 0.0545131
	speed: 0.1126s/iter; left time: 3944.1270s
	iters: 2500, epoch: 7 | loss: 0.0678101
	speed: 0.1164s/iter; left time: 4065.8396s
	iters: 2600, epoch: 7 | loss: 0.0619310
	speed: 0.1203s/iter; left time: 4189.5843s
Epoch: 7 cost time: 00h:05m:03.66s
Epoch: 7 | Train Loss: 0.0613680 Vali Loss: 0.0761664 Test Loss: 0.0845503
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0591804
	speed: 0.9790s/iter; left time: 33934.6230s
	iters: 200, epoch: 8 | loss: 0.0601895
	speed: 0.1196s/iter; left time: 4133.0989s
	iters: 300, epoch: 8 | loss: 0.0537779
	speed: 0.1198s/iter; left time: 4128.7480s
	iters: 400, epoch: 8 | loss: 0.0596471
	speed: 0.1198s/iter; left time: 4117.4278s
	iters: 500, epoch: 8 | loss: 0.0748389
	speed: 0.1204s/iter; left time: 4124.1304s
	iters: 600, epoch: 8 | loss: 0.0619526
	speed: 0.1195s/iter; left time: 4082.4990s
	iters: 700, epoch: 8 | loss: 0.0492099
	speed: 0.1188s/iter; left time: 4045.3253s
	iters: 800, epoch: 8 | loss: 0.0553380
	speed: 0.1196s/iter; left time: 4063.0445s
	iters: 900, epoch: 8 | loss: 0.0660264
	speed: 0.1195s/iter; left time: 4047.2326s
	iters: 1000, epoch: 8 | loss: 0.0512587
	speed: 0.1194s/iter; left time: 4030.1679s
	iters: 1100, epoch: 8 | loss: 0.0606477
	speed: 0.1188s/iter; left time: 3998.5403s
	iters: 1200, epoch: 8 | loss: 0.0488810
	speed: 0.1191s/iter; left time: 3998.0484s
	iters: 1300, epoch: 8 | loss: 0.0636803
	speed: 0.1186s/iter; left time: 3967.5197s
	iters: 1400, epoch: 8 | loss: 0.0603122
	speed: 0.1175s/iter; left time: 3920.6324s
	iters: 1500, epoch: 8 | loss: 0.0753196
	speed: 0.1020s/iter; left time: 3391.2001s
	iters: 1600, epoch: 8 | loss: 0.0476781
	speed: 0.1022s/iter; left time: 3387.8970s
	iters: 1700, epoch: 8 | loss: 0.0543786
	speed: 0.1025s/iter; left time: 3389.6880s
	iters: 1800, epoch: 8 | loss: 0.0479689
	speed: 0.1025s/iter; left time: 3378.3512s
	iters: 1900, epoch: 8 | loss: 0.0567113
	speed: 0.1021s/iter; left time: 3355.2348s
	iters: 2000, epoch: 8 | loss: 0.0584764
	speed: 0.1057s/iter; left time: 3463.6862s
	iters: 2100, epoch: 8 | loss: 0.0674268
	speed: 0.1190s/iter; left time: 3886.3887s
	iters: 2200, epoch: 8 | loss: 0.0617867
	speed: 0.1192s/iter; left time: 3881.7200s
	iters: 2300, epoch: 8 | loss: 0.0588714
	speed: 0.1193s/iter; left time: 3873.9034s
	iters: 2400, epoch: 8 | loss: 0.0716897
	speed: 0.1202s/iter; left time: 3888.4492s
	iters: 2500, epoch: 8 | loss: 0.0649153
	speed: 0.1200s/iter; left time: 3872.2716s
	iters: 2600, epoch: 8 | loss: 0.0538609
	speed: 0.1197s/iter; left time: 3851.3189s
Epoch: 8 cost time: 00h:05m:09.84s
Epoch: 8 | Train Loss: 0.0601105 Vali Loss: 0.0785164 Test Loss: 0.0872316
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.018459701910614967, rmse:0.13586649298667908, mae:0.08174050599336624, rse:0.5256097912788391
success delete checkpoints
Intermediate time for FR and pred_len 96: 00h:54m:09.08s


=== Starting experiments for pred_len: 168 ===

train 85371
val 18219
test 18219
[2024-11-01 12:16:54,048] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 12:16:55,149] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 12:16:55,149] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 12:16:55,149] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 12:16:55,247] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 12:16:55,247] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 12:16:55,874] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 12:16:55,875] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 12:16:55,876] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 12:16:55,877] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 12:16:55,877] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 12:16:55,877] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 12:16:55,877] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 12:16:55,877] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 12:16:55,877] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 12:16:55,877] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 12:16:56,153] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 12:16:56,154] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 12:16:56,186] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.51 GB, percent = 11.2%
[2024-11-01 12:16:56,315] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 12:16:56,316] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 12:16:56,317] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.51 GB, percent = 11.2%
[2024-11-01 12:16:56,317] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 12:16:56,441] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 12:16:56,442] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 12:16:56,442] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 84.52 GB, percent = 11.2%
[2024-11-01 12:16:56,443] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 12:16:56,443] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 12:16:56,443] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 12:16:56,443] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 12:16:56,444] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 12:16:56,444] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f21314ff050>
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 12:16:56,445] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 12:16:56,446] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 12:16:56,447] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1461806
	speed: 0.1730s/iter; left time: 9210.0870s
	iters: 200, epoch: 1 | loss: 0.1501896
	speed: 0.1310s/iter; left time: 6959.3806s
	iters: 300, epoch: 1 | loss: 0.1255645
	speed: 0.1311s/iter; left time: 6951.9444s
	iters: 400, epoch: 1 | loss: 0.0948358
	speed: 0.1310s/iter; left time: 6934.5625s
	iters: 500, epoch: 1 | loss: 0.0860671
	speed: 0.1309s/iter; left time: 6917.5522s
	iters: 600, epoch: 1 | loss: 0.0797759
	speed: 0.1306s/iter; left time: 6885.6366s
	iters: 700, epoch: 1 | loss: 0.0779733
	speed: 0.1309s/iter; left time: 6890.0925s
	iters: 800, epoch: 1 | loss: 0.0854992
	speed: 0.1307s/iter; left time: 6867.4979s
	iters: 900, epoch: 1 | loss: 0.0824629
	speed: 0.1310s/iter; left time: 6869.6733s
	iters: 1000, epoch: 1 | loss: 0.0905522
	speed: 0.1303s/iter; left time: 6818.0561s
	iters: 1100, epoch: 1 | loss: 0.0848468
	speed: 0.1205s/iter; left time: 6294.7008s
	iters: 1200, epoch: 1 | loss: 0.0831938
	speed: 0.1180s/iter; left time: 6151.8401s
	iters: 1300, epoch: 1 | loss: 0.0840276
	speed: 0.1308s/iter; left time: 6808.4912s
	iters: 1400, epoch: 1 | loss: 0.0715065
	speed: 0.1310s/iter; left time: 6806.7839s
	iters: 1500, epoch: 1 | loss: 0.0868700
	speed: 0.1310s/iter; left time: 6789.1651s
	iters: 1600, epoch: 1 | loss: 0.0816183
	speed: 0.1308s/iter; left time: 6766.4134s
	iters: 1700, epoch: 1 | loss: 0.0746674
	speed: 0.1237s/iter; left time: 6389.0172s
	iters: 1800, epoch: 1 | loss: 0.0842547
	speed: 0.1130s/iter; left time: 5825.4907s
	iters: 1900, epoch: 1 | loss: 0.0750883
	speed: 0.1130s/iter; left time: 5814.9845s
	iters: 2000, epoch: 1 | loss: 0.0767707
	speed: 0.1150s/iter; left time: 5905.6888s
	iters: 2100, epoch: 1 | loss: 0.0823143
	speed: 0.1305s/iter; left time: 6686.9631s
	iters: 2200, epoch: 1 | loss: 0.0773541
	speed: 0.1180s/iter; left time: 6033.7108s
	iters: 2300, epoch: 1 | loss: 0.0822798
	speed: 0.1129s/iter; left time: 5764.1653s
	iters: 2400, epoch: 1 | loss: 0.0697680
	speed: 0.1214s/iter; left time: 6182.1408s
	iters: 2500, epoch: 1 | loss: 0.0781708
	speed: 0.1217s/iter; left time: 6188.2546s
	iters: 2600, epoch: 1 | loss: 0.0923201
	speed: 0.1308s/iter; left time: 6636.2513s
Epoch: 1 cost time: 00h:05m:37.03s
Epoch: 1 | Train Loss: 0.0882067 Vali Loss: 0.0789939 Test Loss: 0.0885378
Validation loss decreased (inf --> 0.078994).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0682366
	speed: 1.1204s/iter; left time: 56662.9128s
	iters: 200, epoch: 2 | loss: 0.0756340
	speed: 0.1210s/iter; left time: 6106.6466s
	iters: 300, epoch: 2 | loss: 0.0757687
	speed: 0.1207s/iter; left time: 6080.6581s
	iters: 400, epoch: 2 | loss: 0.0809062
	speed: 0.1209s/iter; left time: 6078.9142s
	iters: 500, epoch: 2 | loss: 0.0785947
	speed: 0.1196s/iter; left time: 6002.3453s
	iters: 600, epoch: 2 | loss: 0.0788290
	speed: 0.1201s/iter; left time: 6015.4931s
	iters: 700, epoch: 2 | loss: 0.0643081
	speed: 0.1208s/iter; left time: 6037.5475s
	iters: 800, epoch: 2 | loss: 0.0724190
	speed: 0.1202s/iter; left time: 5993.5757s
	iters: 900, epoch: 2 | loss: 0.0765032
	speed: 0.1199s/iter; left time: 5968.3381s
	iters: 1000, epoch: 2 | loss: 0.0680958
	speed: 0.1206s/iter; left time: 5989.3898s
	iters: 1100, epoch: 2 | loss: 0.0636572
	speed: 0.1202s/iter; left time: 5957.4190s
	iters: 1200, epoch: 2 | loss: 0.0647527
	speed: 0.1063s/iter; left time: 5257.8187s
	iters: 1300, epoch: 2 | loss: 0.0695712
	speed: 0.1167s/iter; left time: 5762.5015s
	iters: 1400, epoch: 2 | loss: 0.0781222
	speed: 0.1202s/iter; left time: 5921.1014s
	iters: 1500, epoch: 2 | loss: 0.0884119
	speed: 0.1198s/iter; left time: 5892.3395s
	iters: 1600, epoch: 2 | loss: 0.0732782
	speed: 0.1200s/iter; left time: 5890.5311s
	iters: 1700, epoch: 2 | loss: 0.0834294
	speed: 0.1196s/iter; left time: 5859.1336s
	iters: 1800, epoch: 2 | loss: 0.0762573
	speed: 0.1204s/iter; left time: 5884.8618s
	iters: 1900, epoch: 2 | loss: 0.0638730
	speed: 0.1206s/iter; left time: 5883.1452s
	iters: 2000, epoch: 2 | loss: 0.0719824
	speed: 0.1206s/iter; left time: 5872.0541s
	iters: 2100, epoch: 2 | loss: 0.0811448
	speed: 0.1202s/iter; left time: 5839.0606s
	iters: 2200, epoch: 2 | loss: 0.0702735
	speed: 0.1207s/iter; left time: 5852.4566s
	iters: 2300, epoch: 2 | loss: 0.0598425
	speed: 0.1205s/iter; left time: 5829.9909s
	iters: 2400, epoch: 2 | loss: 0.0801101
	speed: 0.1205s/iter; left time: 5815.2579s
	iters: 2500, epoch: 2 | loss: 0.0596308
	speed: 0.1193s/iter; left time: 5748.1064s
	iters: 2600, epoch: 2 | loss: 0.0712510
	speed: 0.1202s/iter; left time: 5778.9095s
Epoch: 2 cost time: 00h:05m:19.56s
Epoch: 2 | Train Loss: 0.0743254 Vali Loss: 0.0777038 Test Loss: 0.0871744
Validation loss decreased (0.078994 --> 0.077704).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0675267
	speed: 0.9816s/iter; left time: 47025.8595s
	iters: 200, epoch: 3 | loss: 0.0488273
	speed: 0.1208s/iter; left time: 5775.7888s
	iters: 300, epoch: 3 | loss: 0.0692624
	speed: 0.1202s/iter; left time: 5734.2229s
	iters: 400, epoch: 3 | loss: 0.0781940
	speed: 0.1205s/iter; left time: 5736.9944s
	iters: 500, epoch: 3 | loss: 0.0633163
	speed: 0.1205s/iter; left time: 5725.1108s
	iters: 600, epoch: 3 | loss: 0.0786292
	speed: 0.1206s/iter; left time: 5718.5994s
	iters: 700, epoch: 3 | loss: 0.0660528
	speed: 0.1204s/iter; left time: 5696.1600s
	iters: 800, epoch: 3 | loss: 0.0873496
	speed: 0.1204s/iter; left time: 5683.3864s
	iters: 900, epoch: 3 | loss: 0.0665047
	speed: 0.1204s/iter; left time: 5670.9440s
	iters: 1000, epoch: 3 | loss: 0.0717470
	speed: 0.1203s/iter; left time: 5656.4925s
	iters: 1100, epoch: 3 | loss: 0.0673361
	speed: 0.1202s/iter; left time: 5636.8146s
	iters: 1200, epoch: 3 | loss: 0.0878783
	speed: 0.1197s/iter; left time: 5603.4585s
	iters: 1300, epoch: 3 | loss: 0.0672138
	speed: 0.1200s/iter; left time: 5605.4909s
	iters: 1400, epoch: 3 | loss: 0.0739039
	speed: 0.1200s/iter; left time: 5592.3321s
	iters: 1500, epoch: 3 | loss: 0.0644442
	speed: 0.1198s/iter; left time: 5571.6100s
	iters: 1600, epoch: 3 | loss: 0.0913087
	speed: 0.1194s/iter; left time: 5541.4580s
	iters: 1700, epoch: 3 | loss: 0.0859381
	speed: 0.1200s/iter; left time: 5556.2694s
	iters: 1800, epoch: 3 | loss: 0.0756321
	speed: 0.1198s/iter; left time: 5533.6822s
	iters: 1900, epoch: 3 | loss: 0.0888247
	speed: 0.1201s/iter; left time: 5535.6990s
	iters: 2000, epoch: 3 | loss: 0.0595378
	speed: 0.1201s/iter; left time: 5526.0971s
	iters: 2100, epoch: 3 | loss: 0.0935414
	speed: 0.1204s/iter; left time: 5528.2120s
	iters: 2200, epoch: 3 | loss: 0.0669725
	speed: 0.1192s/iter; left time: 5461.0042s
	iters: 2300, epoch: 3 | loss: 0.0605008
	speed: 0.1195s/iter; left time: 5461.4934s
	iters: 2400, epoch: 3 | loss: 0.0831451
	speed: 0.1204s/iter; left time: 5491.7577s
	iters: 2500, epoch: 3 | loss: 0.0697700
	speed: 0.1205s/iter; left time: 5481.7985s
	iters: 2600, epoch: 3 | loss: 0.0661712
	speed: 0.1203s/iter; left time: 5462.8743s
Epoch: 3 cost time: 00h:05m:20.24s
Epoch: 3 | Train Loss: 0.0718358 Vali Loss: 0.0789278 Test Loss: 0.0876987
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0648829
	speed: 0.9640s/iter; left time: 43610.8468s
	iters: 200, epoch: 4 | loss: 0.0765537
	speed: 0.1204s/iter; left time: 5434.6165s
	iters: 300, epoch: 4 | loss: 0.0551690
	speed: 0.1207s/iter; left time: 5436.4927s
	iters: 400, epoch: 4 | loss: 0.0743216
	speed: 0.1201s/iter; left time: 5396.6509s
	iters: 500, epoch: 4 | loss: 0.0566139
	speed: 0.1202s/iter; left time: 5389.5299s
	iters: 600, epoch: 4 | loss: 0.0790194
	speed: 0.1199s/iter; left time: 5364.1197s
	iters: 700, epoch: 4 | loss: 0.0843454
	speed: 0.1200s/iter; left time: 5358.3731s
	iters: 800, epoch: 4 | loss: 0.0670473
	speed: 0.1202s/iter; left time: 5352.7789s
	iters: 900, epoch: 4 | loss: 0.0606182
	speed: 0.1201s/iter; left time: 5337.1590s
	iters: 1000, epoch: 4 | loss: 0.0734311
	speed: 0.1165s/iter; left time: 5164.0973s
	iters: 1100, epoch: 4 | loss: 0.0760170
	speed: 0.1200s/iter; left time: 5309.5506s
	iters: 1200, epoch: 4 | loss: 0.0643949
	speed: 0.1197s/iter; left time: 5281.7968s
	iters: 1300, epoch: 4 | loss: 0.0647174
	speed: 0.1205s/iter; left time: 5306.1273s
	iters: 1400, epoch: 4 | loss: 0.0552365
	speed: 0.1103s/iter; left time: 4847.3962s
	iters: 1500, epoch: 4 | loss: 0.0723340
	speed: 0.1026s/iter; left time: 4498.7610s
	iters: 1600, epoch: 4 | loss: 0.0671190
	speed: 0.1022s/iter; left time: 4468.8514s
	iters: 1700, epoch: 4 | loss: 0.0635535
	speed: 0.1169s/iter; left time: 5100.5782s
	iters: 1800, epoch: 4 | loss: 0.0668017
	speed: 0.1195s/iter; left time: 5201.0089s
	iters: 1900, epoch: 4 | loss: 0.0685256
	speed: 0.1197s/iter; left time: 5200.6177s
	iters: 2000, epoch: 4 | loss: 0.0721530
	speed: 0.1197s/iter; left time: 5187.0556s
	iters: 2100, epoch: 4 | loss: 0.0882780
	speed: 0.1189s/iter; left time: 5140.8255s
	iters: 2200, epoch: 4 | loss: 0.0493336
	speed: 0.1106s/iter; left time: 4771.5342s
	iters: 2300, epoch: 4 | loss: 0.0750259
	speed: 0.1025s/iter; left time: 4409.4629s
	iters: 2400, epoch: 4 | loss: 0.0622560
	speed: 0.1022s/iter; left time: 4388.7310s
	iters: 2500, epoch: 4 | loss: 0.0759433
	speed: 0.1145s/iter; left time: 4904.1385s
	iters: 2600, epoch: 4 | loss: 0.0722388
	speed: 0.1194s/iter; left time: 5102.9396s
Epoch: 4 cost time: 00h:05m:10.23s
Epoch: 4 | Train Loss: 0.0692130 Vali Loss: 0.0806310 Test Loss: 0.0891718
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0739205
	speed: 0.9680s/iter; left time: 41211.1901s
	iters: 200, epoch: 5 | loss: 0.0671281
	speed: 0.1204s/iter; left time: 5113.1638s
	iters: 300, epoch: 5 | loss: 0.0831495
	speed: 0.1204s/iter; left time: 5102.3000s
	iters: 400, epoch: 5 | loss: 0.0562803
	speed: 0.1204s/iter; left time: 5090.6244s
	iters: 500, epoch: 5 | loss: 0.0612629
	speed: 0.1205s/iter; left time: 5080.5162s
	iters: 600, epoch: 5 | loss: 0.0725645
	speed: 0.1209s/iter; left time: 5088.0638s
	iters: 700, epoch: 5 | loss: 0.0736510
	speed: 0.1196s/iter; left time: 5021.6411s
	iters: 800, epoch: 5 | loss: 0.0621689
	speed: 0.1191s/iter; left time: 4988.1594s
	iters: 900, epoch: 5 | loss: 0.0703253
	speed: 0.1074s/iter; left time: 4487.7927s
	iters: 1000, epoch: 5 | loss: 0.0583030
	speed: 0.1067s/iter; left time: 4448.5081s
	iters: 1100, epoch: 5 | loss: 0.0703888
	speed: 0.1202s/iter; left time: 4997.4951s
	iters: 1200, epoch: 5 | loss: 0.0585797
	speed: 0.1203s/iter; left time: 4989.1111s
	iters: 1300, epoch: 5 | loss: 0.0742435
	speed: 0.1202s/iter; left time: 4972.9731s
	iters: 1400, epoch: 5 | loss: 0.0719956
	speed: 0.1200s/iter; left time: 4950.8812s
	iters: 1500, epoch: 5 | loss: 0.0606002
	speed: 0.1203s/iter; left time: 4952.4289s
	iters: 1600, epoch: 5 | loss: 0.0692182
	speed: 0.1195s/iter; left time: 4907.6715s
	iters: 1700, epoch: 5 | loss: 0.0654579
	speed: 0.1191s/iter; left time: 4880.5084s
	iters: 1800, epoch: 5 | loss: 0.0808130
	speed: 0.1197s/iter; left time: 4893.6735s
	iters: 1900, epoch: 5 | loss: 0.0635292
	speed: 0.1197s/iter; left time: 4880.9477s
	iters: 2000, epoch: 5 | loss: 0.0533435
	speed: 0.1207s/iter; left time: 4908.9935s
	iters: 2100, epoch: 5 | loss: 0.0679128
	speed: 0.1208s/iter; left time: 4899.8088s
	iters: 2200, epoch: 5 | loss: 0.0734313
	speed: 0.1119s/iter; left time: 4527.1646s
	iters: 2300, epoch: 5 | loss: 0.0613091
	speed: 0.1022s/iter; left time: 4126.5804s
	iters: 2400, epoch: 5 | loss: 0.0723060
	speed: 0.1024s/iter; left time: 4125.5745s
	iters: 2500, epoch: 5 | loss: 0.0571138
	speed: 0.1120s/iter; left time: 4500.2247s
	iters: 2600, epoch: 5 | loss: 0.0643532
	speed: 0.1203s/iter; left time: 4820.8371s
Epoch: 5 cost time: 00h:05m:13.00s
Epoch: 5 | Train Loss: 0.0666898 Vali Loss: 0.0816376 Test Loss: 0.0911526
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0592945
	speed: 0.9657s/iter; left time: 38537.4886s
	iters: 200, epoch: 6 | loss: 0.0701825
	speed: 0.1211s/iter; left time: 4821.7485s
	iters: 300, epoch: 6 | loss: 0.0733728
	speed: 0.1185s/iter; left time: 4704.2811s
	iters: 400, epoch: 6 | loss: 0.0500985
	speed: 0.1180s/iter; left time: 4674.7087s
	iters: 500, epoch: 6 | loss: 0.0708840
	speed: 0.1204s/iter; left time: 4756.7930s
	iters: 600, epoch: 6 | loss: 0.0746798
	speed: 0.1205s/iter; left time: 4748.6832s
	iters: 700, epoch: 6 | loss: 0.0672090
	speed: 0.1203s/iter; left time: 4727.8518s
	iters: 800, epoch: 6 | loss: 0.0675267
	speed: 0.1203s/iter; left time: 4716.1069s
	iters: 900, epoch: 6 | loss: 0.0650174
	speed: 0.1200s/iter; left time: 4693.2471s
	iters: 1000, epoch: 6 | loss: 0.0685931
	speed: 0.1204s/iter; left time: 4695.3959s
	iters: 1100, epoch: 6 | loss: 0.0609383
	speed: 0.1209s/iter; left time: 4705.1570s
	iters: 1200, epoch: 6 | loss: 0.0727255
	speed: 0.1204s/iter; left time: 4671.5887s
	iters: 1300, epoch: 6 | loss: 0.0623817
	speed: 0.1203s/iter; left time: 4657.0666s
	iters: 1400, epoch: 6 | loss: 0.0603095
	speed: 0.1207s/iter; left time: 4658.2948s
	iters: 1500, epoch: 6 | loss: 0.0660724
	speed: 0.1200s/iter; left time: 4622.5052s
	iters: 1600, epoch: 6 | loss: 0.0712819
	speed: 0.1202s/iter; left time: 4615.8802s
	iters: 1700, epoch: 6 | loss: 0.0682647
	speed: 0.1206s/iter; left time: 4620.1186s
	iters: 1800, epoch: 6 | loss: 0.0655491
	speed: 0.1210s/iter; left time: 4622.4862s
	iters: 1900, epoch: 6 | loss: 0.0615094
	speed: 0.1206s/iter; left time: 4594.5071s
	iters: 2000, epoch: 6 | loss: 0.0686113
	speed: 0.1201s/iter; left time: 4564.8971s
	iters: 2100, epoch: 6 | loss: 0.0684695
	speed: 0.1208s/iter; left time: 4580.1767s
	iters: 2200, epoch: 6 | loss: 0.0678513
	speed: 0.1203s/iter; left time: 4549.4603s
	iters: 2300, epoch: 6 | loss: 0.0722934
	speed: 0.1206s/iter; left time: 4546.5078s
	iters: 2400, epoch: 6 | loss: 0.0518117
	speed: 0.1205s/iter; left time: 4533.1992s
	iters: 2500, epoch: 6 | loss: 0.0615523
	speed: 0.1204s/iter; left time: 4514.2958s
	iters: 2600, epoch: 6 | loss: 0.0523729
	speed: 0.1207s/iter; left time: 4516.2380s
Epoch: 6 cost time: 00h:05m:21.38s
Epoch: 6 | Train Loss: 0.0646321 Vali Loss: 0.0833404 Test Loss: 0.0923264
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0626126
	speed: 0.9567s/iter; left time: 35627.9855s
	iters: 200, epoch: 7 | loss: 0.0635089
	speed: 0.1106s/iter; left time: 4108.5023s
	iters: 300, epoch: 7 | loss: 0.0645225
	speed: 0.1197s/iter; left time: 4433.4494s
	iters: 400, epoch: 7 | loss: 0.0587169
	speed: 0.1206s/iter; left time: 4455.9176s
	iters: 500, epoch: 7 | loss: 0.0679099
	speed: 0.1199s/iter; left time: 4416.9940s
	iters: 600, epoch: 7 | loss: 0.0761093
	speed: 0.1200s/iter; left time: 4406.9235s
	iters: 700, epoch: 7 | loss: 0.0614073
	speed: 0.1198s/iter; left time: 4388.3678s
	iters: 800, epoch: 7 | loss: 0.0606054
	speed: 0.1196s/iter; left time: 4370.5688s
	iters: 900, epoch: 7 | loss: 0.0640666
	speed: 0.1205s/iter; left time: 4391.2438s
	iters: 1000, epoch: 7 | loss: 0.0652940
	speed: 0.1208s/iter; left time: 4390.7018s
	iters: 1100, epoch: 7 | loss: 0.0591778
	speed: 0.1204s/iter; left time: 4362.7470s
	iters: 1200, epoch: 7 | loss: 0.0599352
	speed: 0.1200s/iter; left time: 4336.2508s
	iters: 1300, epoch: 7 | loss: 0.0674185
	speed: 0.1203s/iter; left time: 4336.9401s
	iters: 1400, epoch: 7 | loss: 0.0645608
	speed: 0.1204s/iter; left time: 4327.4001s
	iters: 1500, epoch: 7 | loss: 0.0626351
	speed: 0.1201s/iter; left time: 4304.2255s
	iters: 1600, epoch: 7 | loss: 0.0564335
	speed: 0.1203s/iter; left time: 4298.8201s
	iters: 1700, epoch: 7 | loss: 0.0628764
	speed: 0.1179s/iter; left time: 4200.4524s
	iters: 1800, epoch: 7 | loss: 0.0579112
	speed: 0.1189s/iter; left time: 4226.9163s
	iters: 1900, epoch: 7 | loss: 0.0576657
	speed: 0.1205s/iter; left time: 4270.9218s
	iters: 2000, epoch: 7 | loss: 0.0645774
	speed: 0.1208s/iter; left time: 4269.8027s
	iters: 2100, epoch: 7 | loss: 0.0611573
	speed: 0.1206s/iter; left time: 4250.7049s
	iters: 2200, epoch: 7 | loss: 0.0668616
	speed: 0.1204s/iter; left time: 4231.6938s
	iters: 2300, epoch: 7 | loss: 0.0692711
	speed: 0.1203s/iter; left time: 4215.0403s
	iters: 2400, epoch: 7 | loss: 0.0704450
	speed: 0.1203s/iter; left time: 4203.9965s
	iters: 2500, epoch: 7 | loss: 0.0594643
	speed: 0.1208s/iter; left time: 4207.7715s
	iters: 2600, epoch: 7 | loss: 0.0567257
	speed: 0.1203s/iter; left time: 4179.7499s
Epoch: 7 cost time: 00h:05m:18.88s
Epoch: 7 | Train Loss: 0.0629600 Vali Loss: 0.0832727 Test Loss: 0.0938695
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.02040581777691841, rmse:0.142848938703537, mae:0.08717440813779831, rse:0.5534131526947021
success delete checkpoints
Intermediate time for FR and pred_len 168: 00h:47m:38.09s

Intermediate time for FR: 03h:16m:59.45s


=== Starting experiments for country: IT ===


=== Starting experiments for pred_len: 24 ===

train 85803
val 18651
test 18651
[2024-11-01 13:04:31,474] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 13:04:32,531] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 13:04:32,531] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 13:04:32,531] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 13:04:32,616] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 13:04:32,617] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 13:04:33,340] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 13:04:33,341] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 13:04:33,341] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 13:04:33,343] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 13:04:33,343] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 13:04:33,343] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 13:04:33,344] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 13:04:33,344] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 13:04:33,344] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 13:04:33,344] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 13:04:33,676] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 13:04:33,677] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 13:04:33,678] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.86 GB, percent = 12.3%
[2024-11-01 13:04:33,804] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 13:04:33,805] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 13:04:33,805] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.86 GB, percent = 12.3%
[2024-11-01 13:04:33,806] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 13:04:33,926] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 13:04:33,927] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 13:04:33,927] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 92.86 GB, percent = 12.3%
[2024-11-01 13:04:33,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 13:04:33,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 13:04:33,928] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 13:04:33,928] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 13:04:33,929] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 13:04:33,929] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 13:04:33,929] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 13:04:33,929] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 13:04:33,929] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7faced1c3790>
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 13:04:33,930] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 13:04:33,931] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 13:04:33,932] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 13:04:33,932] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.1961632
	speed: 0.1833s/iter; left time: 9810.8464s
	iters: 200, epoch: 1 | loss: 0.1897899
	speed: 0.1454s/iter; left time: 7768.9982s
	iters: 300, epoch: 1 | loss: 0.1400119
	speed: 0.1441s/iter; left time: 7684.5852s
	iters: 400, epoch: 1 | loss: 0.1414553
	speed: 0.1453s/iter; left time: 7731.8958s
	iters: 500, epoch: 1 | loss: 0.1245781
	speed: 0.1415s/iter; left time: 7516.0493s
	iters: 600, epoch: 1 | loss: 0.0947767
	speed: 0.1429s/iter; left time: 7579.3498s
	iters: 700, epoch: 1 | loss: 0.0984841
	speed: 0.1441s/iter; left time: 7625.4152s
	iters: 800, epoch: 1 | loss: 0.0828382
	speed: 0.1458s/iter; left time: 7701.1120s
	iters: 900, epoch: 1 | loss: 0.0719742
	speed: 0.1413s/iter; left time: 7451.6957s
	iters: 1000, epoch: 1 | loss: 0.1195307
	speed: 0.1456s/iter; left time: 7663.5386s
	iters: 1100, epoch: 1 | loss: 0.0817368
	speed: 0.1442s/iter; left time: 7571.5605s
	iters: 1200, epoch: 1 | loss: 0.0921901
	speed: 0.1332s/iter; left time: 6984.4445s
	iters: 1300, epoch: 1 | loss: 0.0989637
	speed: 0.1422s/iter; left time: 7440.3441s
	iters: 1400, epoch: 1 | loss: 0.0795155
	speed: 0.1314s/iter; left time: 6862.9960s
	iters: 1500, epoch: 1 | loss: 0.0898348
	speed: 0.1310s/iter; left time: 6829.2729s
	iters: 1600, epoch: 1 | loss: 0.0705952
	speed: 0.1304s/iter; left time: 6783.1200s
	iters: 1700, epoch: 1 | loss: 0.0890884
	speed: 0.1308s/iter; left time: 6790.5149s
	iters: 1800, epoch: 1 | loss: 0.0708546
	speed: 0.1308s/iter; left time: 6776.8064s
	iters: 1900, epoch: 1 | loss: 0.0823215
	speed: 0.1311s/iter; left time: 6779.3560s
	iters: 2000, epoch: 1 | loss: 0.0903587
	speed: 0.1304s/iter; left time: 6733.6372s
	iters: 2100, epoch: 1 | loss: 0.0667403
	speed: 0.1308s/iter; left time: 6739.8755s
	iters: 2200, epoch: 1 | loss: 0.0840566
	speed: 0.1307s/iter; left time: 6720.3720s
	iters: 2300, epoch: 1 | loss: 0.1007551
	speed: 0.1306s/iter; left time: 6700.9664s
	iters: 2400, epoch: 1 | loss: 0.0791763
	speed: 0.1306s/iter; left time: 6688.6590s
	iters: 2500, epoch: 1 | loss: 0.0936417
	speed: 0.1310s/iter; left time: 6699.2369s
	iters: 2600, epoch: 1 | loss: 0.0681735
	speed: 0.1304s/iter; left time: 6653.8129s
Epoch: 1 cost time: 00h:06m:07.48s
Epoch: 1 | Train Loss: 0.1042742 Vali Loss: 0.0697548 Test Loss: 0.0724680
Validation loss decreased (inf --> 0.069755).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0968200
	speed: 1.1572s/iter; left time: 58831.1176s
	iters: 200, epoch: 2 | loss: 0.0908526
	speed: 0.1203s/iter; left time: 6103.8041s
	iters: 300, epoch: 2 | loss: 0.0880430
	speed: 0.1174s/iter; left time: 5945.0386s
	iters: 400, epoch: 2 | loss: 0.0909087
	speed: 0.1202s/iter; left time: 6074.7429s
	iters: 500, epoch: 2 | loss: 0.0755832
	speed: 0.1197s/iter; left time: 6036.9880s
	iters: 600, epoch: 2 | loss: 0.0719677
	speed: 0.1204s/iter; left time: 6058.4529s
	iters: 700, epoch: 2 | loss: 0.0632761
	speed: 0.1204s/iter; left time: 6049.5524s
	iters: 800, epoch: 2 | loss: 0.0799158
	speed: 0.1198s/iter; left time: 6007.3276s
	iters: 900, epoch: 2 | loss: 0.0778257
	speed: 0.1202s/iter; left time: 6016.4166s
	iters: 1000, epoch: 2 | loss: 0.0686750
	speed: 0.1200s/iter; left time: 5991.3429s
	iters: 1100, epoch: 2 | loss: 0.0759580
	speed: 0.1205s/iter; left time: 6007.7322s
	iters: 1200, epoch: 2 | loss: 0.0850438
	speed: 0.1204s/iter; left time: 5987.5987s
	iters: 1300, epoch: 2 | loss: 0.0768398
	speed: 0.1202s/iter; left time: 5967.5839s
	iters: 1400, epoch: 2 | loss: 0.0734043
	speed: 0.1197s/iter; left time: 5930.4064s
	iters: 1500, epoch: 2 | loss: 0.0702756
	speed: 0.1202s/iter; left time: 5942.7494s
	iters: 1600, epoch: 2 | loss: 0.0901470
	speed: 0.1207s/iter; left time: 5956.9218s
	iters: 1700, epoch: 2 | loss: 0.0736003
	speed: 0.1205s/iter; left time: 5933.1071s
	iters: 1800, epoch: 2 | loss: 0.0812662
	speed: 0.1202s/iter; left time: 5907.7950s
	iters: 1900, epoch: 2 | loss: 0.0856911
	speed: 0.1160s/iter; left time: 5689.9465s
	iters: 2000, epoch: 2 | loss: 0.0710515
	speed: 0.1190s/iter; left time: 5822.5993s
	iters: 2100, epoch: 2 | loss: 0.0731606
	speed: 0.1040s/iter; left time: 5078.3971s
	iters: 2200, epoch: 2 | loss: 0.0908238
	speed: 0.1160s/iter; left time: 5655.1282s
	iters: 2300, epoch: 2 | loss: 0.0716156
	speed: 0.1196s/iter; left time: 5817.8012s
	iters: 2400, epoch: 2 | loss: 0.0662761
	speed: 0.1199s/iter; left time: 5820.6415s
	iters: 2500, epoch: 2 | loss: 0.0705364
	speed: 0.1197s/iter; left time: 5796.9391s
	iters: 2600, epoch: 2 | loss: 0.0787798
	speed: 0.1191s/iter; left time: 5755.2663s
Epoch: 2 cost time: 00h:05m:19.68s
Epoch: 2 | Train Loss: 0.0792366 Vali Loss: 0.0630193 Test Loss: 0.0664905
Validation loss decreased (0.069755 --> 0.063019).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0837417
	speed: 1.0234s/iter; left time: 49285.2181s
	iters: 200, epoch: 3 | loss: 0.0720257
	speed: 0.1205s/iter; left time: 5791.6005s
	iters: 300, epoch: 3 | loss: 0.0743371
	speed: 0.1202s/iter; left time: 5765.9035s
	iters: 400, epoch: 3 | loss: 0.0783527
	speed: 0.1204s/iter; left time: 5761.3312s
	iters: 500, epoch: 3 | loss: 0.0714736
	speed: 0.1206s/iter; left time: 5758.4031s
	iters: 600, epoch: 3 | loss: 0.0732643
	speed: 0.1198s/iter; left time: 5710.6399s
	iters: 700, epoch: 3 | loss: 0.0646055
	speed: 0.1192s/iter; left time: 5667.4669s
	iters: 800, epoch: 3 | loss: 0.0739734
	speed: 0.1187s/iter; left time: 5633.6934s
	iters: 900, epoch: 3 | loss: 0.0694846
	speed: 0.1191s/iter; left time: 5642.0237s
	iters: 1000, epoch: 3 | loss: 0.0750011
	speed: 0.1203s/iter; left time: 5685.5456s
	iters: 1100, epoch: 3 | loss: 0.0742698
	speed: 0.1199s/iter; left time: 5653.5893s
	iters: 1200, epoch: 3 | loss: 0.0718982
	speed: 0.1192s/iter; left time: 5609.0992s
	iters: 1300, epoch: 3 | loss: 0.0686082
	speed: 0.1200s/iter; left time: 5635.4408s
	iters: 1400, epoch: 3 | loss: 0.0775685
	speed: 0.1116s/iter; left time: 5230.8185s
	iters: 1500, epoch: 3 | loss: 0.0676080
	speed: 0.1201s/iter; left time: 5616.3261s
	iters: 1600, epoch: 3 | loss: 0.0703222
	speed: 0.1206s/iter; left time: 5627.3612s
	iters: 1700, epoch: 3 | loss: 0.0706295
	speed: 0.1196s/iter; left time: 5568.7014s
	iters: 1800, epoch: 3 | loss: 0.0611054
	speed: 0.1201s/iter; left time: 5579.5153s
	iters: 1900, epoch: 3 | loss: 0.0822397
	speed: 0.1207s/iter; left time: 5596.1161s
	iters: 2000, epoch: 3 | loss: 0.0630606
	speed: 0.1051s/iter; left time: 4860.7075s
	iters: 2100, epoch: 3 | loss: 0.0664413
	speed: 0.1170s/iter; left time: 5399.2471s
	iters: 2200, epoch: 3 | loss: 0.0754516
	speed: 0.1200s/iter; left time: 5528.1149s
	iters: 2300, epoch: 3 | loss: 0.0628932
	speed: 0.1204s/iter; left time: 5534.6005s
	iters: 2400, epoch: 3 | loss: 0.0689445
	speed: 0.1195s/iter; left time: 5480.3888s
	iters: 2500, epoch: 3 | loss: 0.0753874
	speed: 0.1204s/iter; left time: 5509.7758s
	iters: 2600, epoch: 3 | loss: 0.0803154
	speed: 0.1189s/iter; left time: 5429.6057s
Epoch: 3 cost time: 00h:05m:19.44s
Epoch: 3 | Train Loss: 0.0754979 Vali Loss: 0.0626933 Test Loss: 0.0662443
Validation loss decreased (0.063019 --> 0.062693).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0701278
	speed: 1.0181s/iter; left time: 46299.1632s
	iters: 200, epoch: 4 | loss: 0.0728249
	speed: 0.1202s/iter; left time: 5454.8825s
	iters: 300, epoch: 4 | loss: 0.0778461
	speed: 0.1191s/iter; left time: 5393.1478s
	iters: 400, epoch: 4 | loss: 0.0785829
	speed: 0.1196s/iter; left time: 5404.1341s
	iters: 500, epoch: 4 | loss: 0.0790459
	speed: 0.1193s/iter; left time: 5375.8122s
	iters: 600, epoch: 4 | loss: 0.0710924
	speed: 0.1195s/iter; left time: 5374.3405s
	iters: 700, epoch: 4 | loss: 0.0721118
	speed: 0.1201s/iter; left time: 5390.4976s
	iters: 800, epoch: 4 | loss: 0.0836879
	speed: 0.1082s/iter; left time: 4844.9978s
	iters: 900, epoch: 4 | loss: 0.0670347
	speed: 0.1172s/iter; left time: 5236.3352s
	iters: 1000, epoch: 4 | loss: 0.0732893
	speed: 0.1160s/iter; left time: 5172.4386s
	iters: 1100, epoch: 4 | loss: 0.0734157
	speed: 0.1194s/iter; left time: 5311.8766s
	iters: 1200, epoch: 4 | loss: 0.0836176
	speed: 0.1179s/iter; left time: 5230.9850s
	iters: 1300, epoch: 4 | loss: 0.0914069
	speed: 0.1095s/iter; left time: 4849.5702s
	iters: 1400, epoch: 4 | loss: 0.0554709
	speed: 0.1139s/iter; left time: 5030.2668s
	iters: 1500, epoch: 4 | loss: 0.0638680
	speed: 0.1194s/iter; left time: 5264.5478s
	iters: 1600, epoch: 4 | loss: 0.0843564
	speed: 0.1085s/iter; left time: 4773.2362s
	iters: 1700, epoch: 4 | loss: 0.0867873
	speed: 0.1176s/iter; left time: 5159.9130s
	iters: 1800, epoch: 4 | loss: 0.0825667
	speed: 0.1186s/iter; left time: 5192.1792s
	iters: 1900, epoch: 4 | loss: 0.0808909
	speed: 0.1170s/iter; left time: 5109.8835s
	iters: 2000, epoch: 4 | loss: 0.0671010
	speed: 0.1202s/iter; left time: 5238.6629s
	iters: 2100, epoch: 4 | loss: 0.0800280
	speed: 0.1201s/iter; left time: 5219.7348s
	iters: 2200, epoch: 4 | loss: 0.0652930
	speed: 0.1197s/iter; left time: 5193.7120s
	iters: 2300, epoch: 4 | loss: 0.0597176
	speed: 0.1194s/iter; left time: 5168.5659s
	iters: 2400, epoch: 4 | loss: 0.0868424
	speed: 0.1202s/iter; left time: 5189.5003s
	iters: 2500, epoch: 4 | loss: 0.0782121
	speed: 0.1045s/iter; left time: 4500.0510s
	iters: 2600, epoch: 4 | loss: 0.0802435
	speed: 0.1030s/iter; left time: 4426.3750s
Epoch: 4 cost time: 00h:05m:12.92s
Epoch: 4 | Train Loss: 0.0732161 Vali Loss: 0.0602605 Test Loss: 0.0639531
Validation loss decreased (0.062693 --> 0.060260).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0794265
	speed: 1.0224s/iter; left time: 43756.3259s
	iters: 200, epoch: 5 | loss: 0.0705508
	speed: 0.1206s/iter; left time: 5149.2286s
	iters: 300, epoch: 5 | loss: 0.0829213
	speed: 0.1208s/iter; left time: 5145.2070s
	iters: 400, epoch: 5 | loss: 0.0772983
	speed: 0.1199s/iter; left time: 5095.2742s
	iters: 500, epoch: 5 | loss: 0.0697670
	speed: 0.1166s/iter; left time: 4942.0477s
	iters: 600, epoch: 5 | loss: 0.0615391
	speed: 0.1186s/iter; left time: 5016.8114s
	iters: 700, epoch: 5 | loss: 0.0567918
	speed: 0.1126s/iter; left time: 4752.5861s
	iters: 800, epoch: 5 | loss: 0.0847099
	speed: 0.1181s/iter; left time: 4972.8196s
	iters: 900, epoch: 5 | loss: 0.0704188
	speed: 0.1200s/iter; left time: 5039.4053s
	iters: 1000, epoch: 5 | loss: 0.0620770
	speed: 0.1201s/iter; left time: 5030.8103s
	iters: 1100, epoch: 5 | loss: 0.0741380
	speed: 0.1193s/iter; left time: 4985.7148s
	iters: 1200, epoch: 5 | loss: 0.0661858
	speed: 0.1204s/iter; left time: 5020.2137s
	iters: 1300, epoch: 5 | loss: 0.0621480
	speed: 0.1192s/iter; left time: 4959.9121s
	iters: 1400, epoch: 5 | loss: 0.0629700
	speed: 0.1186s/iter; left time: 4921.5209s
	iters: 1500, epoch: 5 | loss: 0.0820492
	speed: 0.1192s/iter; left time: 4935.7549s
	iters: 1600, epoch: 5 | loss: 0.0610860
	speed: 0.1114s/iter; left time: 4599.7470s
	iters: 1700, epoch: 5 | loss: 0.0861114
	speed: 0.1203s/iter; left time: 4955.9866s
	iters: 1800, epoch: 5 | loss: 0.0606930
	speed: 0.1141s/iter; left time: 4690.0508s
	iters: 1900, epoch: 5 | loss: 0.0612833
	speed: 0.1157s/iter; left time: 4745.0385s
	iters: 2000, epoch: 5 | loss: 0.0786318
	speed: 0.1064s/iter; left time: 4351.3976s
	iters: 2100, epoch: 5 | loss: 0.0779789
	speed: 0.1162s/iter; left time: 4738.6194s
	iters: 2200, epoch: 5 | loss: 0.0667817
	speed: 0.1210s/iter; left time: 4922.3772s
	iters: 2300, epoch: 5 | loss: 0.0773585
	speed: 0.1158s/iter; left time: 4702.1170s
	iters: 2400, epoch: 5 | loss: 0.0830474
	speed: 0.1109s/iter; left time: 4489.9204s
	iters: 2500, epoch: 5 | loss: 0.0766403
	speed: 0.1259s/iter; left time: 5086.0663s
	iters: 2600, epoch: 5 | loss: 0.0594169
	speed: 0.1307s/iter; left time: 5267.9848s
Epoch: 5 cost time: 00h:05m:18.84s
Epoch: 5 | Train Loss: 0.0718611 Vali Loss: 0.0608224 Test Loss: 0.0644853
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0779639
	speed: 1.1754s/iter; left time: 47150.9887s
	iters: 200, epoch: 6 | loss: 0.0661459
	speed: 0.1303s/iter; left time: 5214.0397s
	iters: 300, epoch: 6 | loss: 0.0925239
	speed: 0.1318s/iter; left time: 5260.2344s
	iters: 400, epoch: 6 | loss: 0.0681258
	speed: 0.1334s/iter; left time: 5311.6688s
	iters: 500, epoch: 6 | loss: 0.0705238
	speed: 0.1273s/iter; left time: 5056.2473s
	iters: 600, epoch: 6 | loss: 0.0755477
	speed: 0.1314s/iter; left time: 5203.7159s
	iters: 700, epoch: 6 | loss: 0.0716280
	speed: 0.1302s/iter; left time: 5143.2423s
	iters: 800, epoch: 6 | loss: 0.0619959
	speed: 0.1310s/iter; left time: 5163.9305s
	iters: 900, epoch: 6 | loss: 0.0714130
	speed: 0.1301s/iter; left time: 5115.7798s
	iters: 1000, epoch: 6 | loss: 0.0737989
	speed: 0.1327s/iter; left time: 5203.3403s
	iters: 1100, epoch: 6 | loss: 0.0621136
	speed: 0.1328s/iter; left time: 5195.2646s
	iters: 1200, epoch: 6 | loss: 0.0685738
	speed: 0.1330s/iter; left time: 5189.4215s
	iters: 1300, epoch: 6 | loss: 0.0633010
	speed: 0.1306s/iter; left time: 5083.8849s
	iters: 1400, epoch: 6 | loss: 0.0603377
	speed: 0.1326s/iter; left time: 5147.7791s
	iters: 1500, epoch: 6 | loss: 0.0727599
	speed: 0.1344s/iter; left time: 5205.2209s
	iters: 1600, epoch: 6 | loss: 0.0715380
	speed: 0.1310s/iter; left time: 5057.7486s
	iters: 1700, epoch: 6 | loss: 0.0616430
	speed: 0.1327s/iter; left time: 5110.9555s
	iters: 1800, epoch: 6 | loss: 0.0798777
	speed: 0.1323s/iter; left time: 5084.3183s
	iters: 1900, epoch: 6 | loss: 0.0765420
	speed: 0.1295s/iter; left time: 4962.1817s
	iters: 2000, epoch: 6 | loss: 0.0671012
	speed: 0.1204s/iter; left time: 4599.4987s
	iters: 2100, epoch: 6 | loss: 0.0616646
	speed: 0.1280s/iter; left time: 4879.6497s
	iters: 2200, epoch: 6 | loss: 0.0681724
	speed: 0.1334s/iter; left time: 5072.1045s
	iters: 2300, epoch: 6 | loss: 0.0847921
	speed: 0.1345s/iter; left time: 5099.5482s
	iters: 2400, epoch: 6 | loss: 0.0787449
	speed: 0.1322s/iter; left time: 5000.8846s
	iters: 2500, epoch: 6 | loss: 0.0638925
	speed: 0.1329s/iter; left time: 5011.7023s
	iters: 2600, epoch: 6 | loss: 0.0637040
	speed: 0.1309s/iter; left time: 4923.8702s
Epoch: 6 cost time: 00h:05m:52.34s
Epoch: 6 | Train Loss: 0.0710204 Vali Loss: 0.0602071 Test Loss: 0.0637255
Validation loss decreased (0.060260 --> 0.060207).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0805032
	speed: 1.2019s/iter; left time: 44993.6354s
	iters: 200, epoch: 7 | loss: 0.0928424
	speed: 0.2726s/iter; left time: 10176.4829s
	iters: 300, epoch: 7 | loss: 0.0699223
	speed: 0.5141s/iter; left time: 19143.7504s
	iters: 400, epoch: 7 | loss: 0.0772188
	speed: 0.7631s/iter; left time: 28336.7197s
	iters: 500, epoch: 7 | loss: 0.0806367
	speed: 0.7636s/iter; left time: 28280.2318s
	iters: 600, epoch: 7 | loss: 0.0634284
	speed: 0.7528s/iter; left time: 27804.9709s
	iters: 700, epoch: 7 | loss: 0.0699541
	speed: 0.7426s/iter; left time: 27353.2393s
	iters: 800, epoch: 7 | loss: 0.0892019
	speed: 0.7607s/iter; left time: 27945.8585s
	iters: 900, epoch: 7 | loss: 0.0712903
	speed: 0.7552s/iter; left time: 27667.5327s
	iters: 1000, epoch: 7 | loss: 0.0747735
	speed: 0.7578s/iter; left time: 27684.7751s
	iters: 1100, epoch: 7 | loss: 0.0782191
	speed: 0.7544s/iter; left time: 27486.3879s
	iters: 1200, epoch: 7 | loss: 0.0647047
	speed: 0.7484s/iter; left time: 27191.4154s
	iters: 1300, epoch: 7 | loss: 0.0666225
	speed: 0.7504s/iter; left time: 27189.8257s
	iters: 1400, epoch: 7 | loss: 0.0843146
	speed: 0.7509s/iter; left time: 27133.3752s
	iters: 1500, epoch: 7 | loss: 0.0681136
	speed: 0.7478s/iter; left time: 26945.4498s
	iters: 1600, epoch: 7 | loss: 0.0701010
	speed: 0.7438s/iter; left time: 26727.4265s
	iters: 1700, epoch: 7 | loss: 0.0843430
	speed: 0.7085s/iter; left time: 25387.3125s
	iters: 1800, epoch: 7 | loss: 0.0538953
	speed: 0.7126s/iter; left time: 25463.9358s
	iters: 1900, epoch: 7 | loss: 0.0655326
	speed: 0.6850s/iter; left time: 24409.1903s
	iters: 2000, epoch: 7 | loss: 0.0805343
	speed: 0.7074s/iter; left time: 25136.3504s
	iters: 2100, epoch: 7 | loss: 0.0631403
	speed: 0.6977s/iter; left time: 24723.7157s
	iters: 2200, epoch: 7 | loss: 0.0604495
	speed: 0.6846s/iter; left time: 24188.8665s
	iters: 2300, epoch: 7 | loss: 0.0642110
	speed: 0.6690s/iter; left time: 23570.5864s
	iters: 2400, epoch: 7 | loss: 0.0664487
	speed: 0.6574s/iter; left time: 23098.1666s
	iters: 2500, epoch: 7 | loss: 0.0816911
	speed: 0.6447s/iter; left time: 22587.5511s
	iters: 2600, epoch: 7 | loss: 0.0661209
	speed: 0.6348s/iter; left time: 22176.0760s
Epoch: 7 cost time: 00h:30m:02.44s
Epoch: 7 | Train Loss: 0.0702127 Vali Loss: 0.0597712 Test Loss: 0.0634713
Validation loss decreased (0.060207 --> 0.059771).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0825887
	speed: 4.6095s/iter; left time: 160197.7928s
	iters: 200, epoch: 8 | loss: 0.0750446
	speed: 0.3246s/iter; left time: 11249.2383s
	iters: 300, epoch: 8 | loss: 0.0714472
	speed: 0.2551s/iter; left time: 8816.3554s
	iters: 400, epoch: 8 | loss: 0.0683220
	speed: 0.7112s/iter; left time: 24503.0054s
	iters: 500, epoch: 8 | loss: 0.0658177
	speed: 0.7142s/iter; left time: 24534.5410s
	iters: 600, epoch: 8 | loss: 0.0671118
	speed: 0.7222s/iter; left time: 24737.5661s
	iters: 700, epoch: 8 | loss: 0.0654151
	speed: 0.6741s/iter; left time: 23021.5282s
	iters: 800, epoch: 8 | loss: 0.0633116
	speed: 0.7181s/iter; left time: 24452.7294s
	iters: 900, epoch: 8 | loss: 0.0762280
	speed: 0.7174s/iter; left time: 24359.7209s
	iters: 1000, epoch: 8 | loss: 0.0904688
	speed: 0.7146s/iter; left time: 24193.1083s
	iters: 1100, epoch: 8 | loss: 0.0685867
	speed: 0.7113s/iter; left time: 24009.8596s
	iters: 1200, epoch: 8 | loss: 0.0753753
	speed: 0.7057s/iter; left time: 23748.5776s
	iters: 1300, epoch: 8 | loss: 0.0869639
	speed: 0.6965s/iter; left time: 23371.7400s
	iters: 1400, epoch: 8 | loss: 0.0656767
	speed: 0.6695s/iter; left time: 22398.7038s
	iters: 1500, epoch: 8 | loss: 0.0751337
	speed: 0.6512s/iter; left time: 21720.6887s
	iters: 1600, epoch: 8 | loss: 0.0769074
	speed: 0.6062s/iter; left time: 20158.3421s
	iters: 1700, epoch: 8 | loss: 0.0628735
	speed: 0.5882s/iter; left time: 19502.4224s
	iters: 1800, epoch: 8 | loss: 0.0630130
	speed: 0.5631s/iter; left time: 18611.1647s
	iters: 1900, epoch: 8 | loss: 0.0680705
	speed: 0.4794s/iter; left time: 15797.6651s
	iters: 2000, epoch: 8 | loss: 0.0652012
	speed: 0.4208s/iter; left time: 13825.5718s
	iters: 2100, epoch: 8 | loss: 0.0650971
	speed: 0.3317s/iter; left time: 10862.9063s
	iters: 2200, epoch: 8 | loss: 0.0778571
	speed: 0.3664s/iter; left time: 11963.3923s
	iters: 2300, epoch: 8 | loss: 0.0902112
	speed: 0.3738s/iter; left time: 12170.2340s
	iters: 2400, epoch: 8 | loss: 0.0791112
	speed: 0.3123s/iter; left time: 10135.5055s
	iters: 2500, epoch: 8 | loss: 0.0677406
	speed: 0.3436s/iter; left time: 11116.9490s
	iters: 2600, epoch: 8 | loss: 0.0605854
	speed: 0.2813s/iter; left time: 9073.0592s
Epoch: 8 cost time: 00h:23m:28.03s
Epoch: 8 | Train Loss: 0.0696060 Vali Loss: 0.0590203 Test Loss: 0.0629085
Validation loss decreased (0.059771 --> 0.059020).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0732988
	speed: 4.3752s/iter; left time: 140324.9766s
	iters: 200, epoch: 9 | loss: 0.0632006
	speed: 0.7223s/iter; left time: 23092.6556s
	iters: 300, epoch: 9 | loss: 0.0675089
	speed: 0.7233s/iter; left time: 23053.0791s
	iters: 400, epoch: 9 | loss: 0.0753807
	speed: 0.7218s/iter; left time: 22934.9957s
	iters: 500, epoch: 9 | loss: 0.0688046
	speed: 0.7213s/iter; left time: 22846.2242s
	iters: 600, epoch: 9 | loss: 0.0563322
	speed: 0.7189s/iter; left time: 22698.4932s
	iters: 700, epoch: 9 | loss: 0.0637789
	speed: 0.7214s/iter; left time: 22705.7106s
	iters: 800, epoch: 9 | loss: 0.0552997
	speed: 0.7192s/iter; left time: 22563.3068s
	iters: 900, epoch: 9 | loss: 0.0730415
	speed: 0.7191s/iter; left time: 22488.1704s
	iters: 1000, epoch: 9 | loss: 0.0624509
	speed: 0.7211s/iter; left time: 22478.3028s
	iters: 1100, epoch: 9 | loss: 0.0611722
	speed: 0.7118s/iter; left time: 22116.9126s
	iters: 1200, epoch: 9 | loss: 0.0624793
	speed: 0.7194s/iter; left time: 22280.7683s
	iters: 1300, epoch: 9 | loss: 0.0554433
	speed: 0.7182s/iter; left time: 22171.4464s
	iters: 1400, epoch: 9 | loss: 0.0854482
	speed: 0.7182s/iter; left time: 22100.1287s
	iters: 1500, epoch: 9 | loss: 0.1009781
	speed: 0.6917s/iter; left time: 21215.8174s
	iters: 1600, epoch: 9 | loss: 0.0588896
	speed: 0.7189s/iter; left time: 21978.3551s
	iters: 1700, epoch: 9 | loss: 0.0664771
	speed: 0.7186s/iter; left time: 21897.6830s
	iters: 1800, epoch: 9 | loss: 0.0875199
	speed: 0.7169s/iter; left time: 21775.4159s
	iters: 1900, epoch: 9 | loss: 0.0652644
	speed: 0.7179s/iter; left time: 21732.6895s
	iters: 2000, epoch: 9 | loss: 0.0729210
	speed: 0.7177s/iter; left time: 21655.3899s
	iters: 2100, epoch: 9 | loss: 0.0595015
	speed: 0.7170s/iter; left time: 21561.5036s
	iters: 2200, epoch: 9 | loss: 0.0645168
	speed: 0.7147s/iter; left time: 21420.6462s
	iters: 2300, epoch: 9 | loss: 0.0664069
	speed: 0.7131s/iter; left time: 21303.5937s
	iters: 2400, epoch: 9 | loss: 0.0560363
	speed: 0.7055s/iter; left time: 21004.7656s
	iters: 2500, epoch: 9 | loss: 0.0640769
	speed: 0.7129s/iter; left time: 21154.5235s
	iters: 2600, epoch: 9 | loss: 0.0609662
	speed: 0.7118s/iter; left time: 21049.0637s
Epoch: 9 cost time: 00h:32m:01.48s
Epoch: 9 | Train Loss: 0.0688502 Vali Loss: 0.0579161 Test Loss: 0.0620261
Validation loss decreased (0.059020 --> 0.057916).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0692350
	speed: 6.6443s/iter; left time: 195287.7996s
	iters: 200, epoch: 10 | loss: 0.0792829
	speed: 0.5529s/iter; left time: 16194.6119s
	iters: 300, epoch: 10 | loss: 0.0651196
	speed: 0.4403s/iter; left time: 12851.8566s
	iters: 400, epoch: 10 | loss: 0.0529624
	speed: 0.3075s/iter; left time: 8944.8923s
	iters: 500, epoch: 10 | loss: 0.0596995
	speed: 0.4291s/iter; left time: 12440.6286s
	iters: 600, epoch: 10 | loss: 0.0596051
	speed: 0.4261s/iter; left time: 12310.4940s
	iters: 700, epoch: 10 | loss: 0.0729908
	speed: 0.3251s/iter; left time: 9359.6015s
	iters: 800, epoch: 10 | loss: 0.0748923
	speed: 0.2566s/iter; left time: 7363.0057s
	iters: 900, epoch: 10 | loss: 0.0764702
	speed: 0.5224s/iter; left time: 14936.5499s
	iters: 1000, epoch: 10 | loss: 0.0590842
	speed: 0.6963s/iter; left time: 19838.3853s
	iters: 1100, epoch: 10 | loss: 0.0709747
	speed: 0.7237s/iter; left time: 20546.0823s
	iters: 1200, epoch: 10 | loss: 0.0812026
	speed: 0.7222s/iter; left time: 20433.7690s
	iters: 1300, epoch: 10 | loss: 0.0673435
	speed: 0.7218s/iter; left time: 20350.2907s
	iters: 1400, epoch: 10 | loss: 0.0555878
	speed: 0.7215s/iter; left time: 20267.5390s
	iters: 1500, epoch: 10 | loss: 0.0766573
	speed: 0.7186s/iter; left time: 20116.0053s
	iters: 1600, epoch: 10 | loss: 0.0764899
	speed: 0.7202s/iter; left time: 20088.8651s
	iters: 1700, epoch: 10 | loss: 0.0618597
	speed: 0.7196s/iter; left time: 19999.0916s
	iters: 1800, epoch: 10 | loss: 0.0638845
	speed: 0.7189s/iter; left time: 19906.7460s
	iters: 1900, epoch: 10 | loss: 0.0900016
	speed: 0.7082s/iter; left time: 19541.6167s
	iters: 2000, epoch: 10 | loss: 0.0711123
	speed: 0.7172s/iter; left time: 19718.1875s
	iters: 2100, epoch: 10 | loss: 0.0715640
	speed: 0.7158s/iter; left time: 19607.5302s
	iters: 2200, epoch: 10 | loss: 0.0749826
	speed: 0.7173s/iter; left time: 19575.6292s
	iters: 2300, epoch: 10 | loss: 0.0696980
	speed: 0.6916s/iter; left time: 18805.6594s
	iters: 2400, epoch: 10 | loss: 0.0574644
	speed: 0.7143s/iter; left time: 19350.6419s
	iters: 2500, epoch: 10 | loss: 0.0694450
	speed: 0.7180s/iter; left time: 19381.4209s
	iters: 2600, epoch: 10 | loss: 0.0577533
	speed: 0.7160s/iter; left time: 19255.6467s
Epoch: 10 cost time: 00h:27m:37.85s
Epoch: 10 | Train Loss: 0.0683724 Vali Loss: 0.0582843 Test Loss: 0.0620225
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 11 | loss: 0.0733247
	speed: 6.3366s/iter; left time: 169257.6041s
	iters: 200, epoch: 11 | loss: 0.0593850
	speed: 0.3699s/iter; left time: 9844.4107s
	iters: 300, epoch: 11 | loss: 0.0672786
	speed: 0.2805s/iter; left time: 7436.6534s
	iters: 400, epoch: 11 | loss: 0.0505884
	speed: 0.2613s/iter; left time: 6901.5134s
	iters: 500, epoch: 11 | loss: 0.0644879
	speed: 0.2648s/iter; left time: 6966.8331s
	iters: 600, epoch: 11 | loss: 0.0813994
	speed: 0.3414s/iter; left time: 8947.5105s
	iters: 700, epoch: 11 | loss: 0.0774051
	speed: 0.4476s/iter; left time: 11686.6079s
	iters: 800, epoch: 11 | loss: 0.0700469
	speed: 0.3679s/iter; left time: 9568.3668s
	iters: 900, epoch: 11 | loss: 0.0562205
	speed: 0.2569s/iter; left time: 6655.9627s
	iters: 1000, epoch: 11 | loss: 0.0744258
	speed: 0.2539s/iter; left time: 6552.7677s
	iters: 1100, epoch: 11 | loss: 0.0834967
	speed: 0.3397s/iter; left time: 8734.2203s
	iters: 1200, epoch: 11 | loss: 0.0731772
	speed: 0.7240s/iter; left time: 18543.2097s
	iters: 1300, epoch: 11 | loss: 0.0543189
	speed: 0.7243s/iter; left time: 18478.0323s
	iters: 1400, epoch: 11 | loss: 0.0754633
	speed: 0.7214s/iter; left time: 18331.6735s
	iters: 1500, epoch: 11 | loss: 0.0645236
	speed: 0.7227s/iter; left time: 18292.4536s
	iters: 1600, epoch: 11 | loss: 0.0708787
	speed: 0.7223s/iter; left time: 18209.5578s
	iters: 1700, epoch: 11 | loss: 0.0754559
	speed: 0.7215s/iter; left time: 18116.8929s
	iters: 1800, epoch: 11 | loss: 0.0719775
	speed: 0.7214s/iter; left time: 18041.9252s
	iters: 1900, epoch: 11 | loss: 0.0709032
	speed: 0.7202s/iter; left time: 17940.4667s
	iters: 2000, epoch: 11 | loss: 0.0738048
	speed: 0.7205s/iter; left time: 17875.5513s
	iters: 2100, epoch: 11 | loss: 0.0666654
	speed: 0.7198s/iter; left time: 17786.1259s
	iters: 2200, epoch: 11 | loss: 0.0716899
	speed: 0.7193s/iter; left time: 17702.6098s
	iters: 2300, epoch: 11 | loss: 0.0751313
	speed: 0.7203s/iter; left time: 17655.6067s
	iters: 2400, epoch: 11 | loss: 0.0650967
	speed: 0.7194s/iter; left time: 17560.9818s
	iters: 2500, epoch: 11 | loss: 0.0566285
	speed: 0.7187s/iter; left time: 17472.7569s
	iters: 2600, epoch: 11 | loss: 0.0661598
	speed: 0.7174s/iter; left time: 17369.9587s
Epoch: 11 cost time: 00h:25m:03.91s
Epoch: 11 | Train Loss: 0.0677539 Vali Loss: 0.0579457 Test Loss: 0.0615977
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 12 | loss: 0.0564539
	speed: 7.2099s/iter; left time: 173253.7892s
	iters: 200, epoch: 12 | loss: 0.0552143
	speed: 0.7149s/iter; left time: 17106.8491s
	iters: 300, epoch: 12 | loss: 0.0666377
	speed: 0.6841s/iter; left time: 16301.1134s
	iters: 400, epoch: 12 | loss: 0.0854366
	speed: 0.7133s/iter; left time: 16927.5870s
	iters: 500, epoch: 12 | loss: 0.0836129
	speed: 0.7165s/iter; left time: 16931.6899s
	iters: 600, epoch: 12 | loss: 0.0733599
	speed: 0.7167s/iter; left time: 16864.1872s
	iters: 700, epoch: 12 | loss: 0.0519824
	speed: 0.7169s/iter; left time: 16797.1314s
	iters: 800, epoch: 12 | loss: 0.0707659
	speed: 0.7130s/iter; left time: 16634.9932s
	iters: 900, epoch: 12 | loss: 0.0599417
	speed: 0.7100s/iter; left time: 16492.8168s
	iters: 1000, epoch: 12 | loss: 0.0641551
	speed: 0.6997s/iter; left time: 16183.0197s
	iters: 1100, epoch: 12 | loss: 0.0645704
	speed: 0.7038s/iter; left time: 16208.1463s
	iters: 1200, epoch: 12 | loss: 0.0506950
	speed: 0.6999s/iter; left time: 16047.7391s
	iters: 1300, epoch: 12 | loss: 0.0640931
	speed: 0.6931s/iter; left time: 15824.5372s
	iters: 1400, epoch: 12 | loss: 0.0689833
	speed: 0.6828s/iter; left time: 15520.7535s
	iters: 1500, epoch: 12 | loss: 0.0576060
	speed: 0.6710s/iter; left time: 15183.7809s
	iters: 1600, epoch: 12 | loss: 0.0531667
	speed: 0.6260s/iter; left time: 14103.6352s
	iters: 1700, epoch: 12 | loss: 0.0634687
	speed: 0.5965s/iter; left time: 13378.4142s
	iters: 1800, epoch: 12 | loss: 0.0635579
	speed: 0.5781s/iter; left time: 12908.9276s
	iters: 1900, epoch: 12 | loss: 0.0655776
	speed: 0.5432s/iter; left time: 12075.9487s
	iters: 2000, epoch: 12 | loss: 0.0597161
	speed: 0.4989s/iter; left time: 11039.9416s
	iters: 2100, epoch: 12 | loss: 0.0718565
	speed: 0.5966s/iter; left time: 13142.0499s
	iters: 2200, epoch: 12 | loss: 0.0863532
	speed: 0.5659s/iter; left time: 12410.9633s
	iters: 2300, epoch: 12 | loss: 0.0655009
	speed: 0.4799s/iter; left time: 10477.0044s
	iters: 2400, epoch: 12 | loss: 0.0780334
	speed: 0.4327s/iter; left time: 9403.1831s
	iters: 2500, epoch: 12 | loss: 0.0685403
	speed: 0.3394s/iter; left time: 7341.8798s
	iters: 2600, epoch: 12 | loss: 0.0669672
	speed: 0.2542s/iter; left time: 5472.8932s
Epoch: 12 cost time: 00h:27m:07.42s
Epoch: 12 | Train Loss: 0.0672516 Vali Loss: 0.0583924 Test Loss: 0.0623229
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 13 | loss: 0.0646751
	speed: 6.3369s/iter; left time: 135287.3221s
	iters: 200, epoch: 13 | loss: 0.0718063
	speed: 0.7220s/iter; left time: 15341.9971s
	iters: 300, epoch: 13 | loss: 0.0704412
	speed: 0.7247s/iter; left time: 15326.9095s
	iters: 400, epoch: 13 | loss: 0.0566958
	speed: 0.7236s/iter; left time: 15231.4184s
	iters: 500, epoch: 13 | loss: 0.0677867
	speed: 0.7212s/iter; left time: 15108.6916s
	iters: 600, epoch: 13 | loss: 0.0662406
	speed: 0.7077s/iter; left time: 14755.7144s
	iters: 700, epoch: 13 | loss: 0.0692414
	speed: 0.7179s/iter; left time: 14895.9437s
	iters: 800, epoch: 13 | loss: 0.0744722
	speed: 0.7169s/iter; left time: 14804.1117s
	iters: 900, epoch: 13 | loss: 0.0682855
	speed: 0.7169s/iter; left time: 14732.3113s
	iters: 1000, epoch: 13 | loss: 0.0692520
	speed: 0.7171s/iter; left time: 14664.0092s
	iters: 1100, epoch: 13 | loss: 0.0754888
	speed: 0.7191s/iter; left time: 14633.0825s
	iters: 1200, epoch: 13 | loss: 0.0644453
	speed: 0.7198s/iter; left time: 14575.8044s
	iters: 1300, epoch: 13 | loss: 0.0570012
	speed: 0.7231s/iter; left time: 14568.8106s
	iters: 1400, epoch: 13 | loss: 0.0658361
	speed: 0.7206s/iter; left time: 14448.0344s
	iters: 1500, epoch: 13 | loss: 0.0681140
	speed: 0.7030s/iter; left time: 14024.8246s
	iters: 1600, epoch: 13 | loss: 0.0861393
	speed: 0.7192s/iter; left time: 14275.1996s
	iters: 1700, epoch: 13 | loss: 0.0685929
	speed: 0.7161s/iter; left time: 14142.3087s
	iters: 1800, epoch: 13 | loss: 0.0834594
	speed: 0.7192s/iter; left time: 14130.5993s
	iters: 1900, epoch: 13 | loss: 0.0550227
	speed: 0.7182s/iter; left time: 14040.1654s
	iters: 2000, epoch: 13 | loss: 0.0614033
	speed: 0.7166s/iter; left time: 13936.8675s
	iters: 2100, epoch: 13 | loss: 0.0588906
	speed: 0.7071s/iter; left time: 13681.3902s
	iters: 2200, epoch: 13 | loss: 0.0599210
	speed: 0.7207s/iter; left time: 13872.2947s
	iters: 2300, epoch: 13 | loss: 0.0557182
	speed: 0.7178s/iter; left time: 13745.6032s
	iters: 2400, epoch: 13 | loss: 0.0523902
	speed: 0.7217s/iter; left time: 13747.9558s
	iters: 2500, epoch: 13 | loss: 0.0614735
	speed: 0.7156s/iter; left time: 13559.7871s
	iters: 2600, epoch: 13 | loss: 0.0746370
	speed: 0.7206s/iter; left time: 13582.5080s
Epoch: 13 cost time: 00h:32m:05.29s
Epoch: 13 | Train Loss: 0.0666866 Vali Loss: 0.0598697 Test Loss: 0.0634292
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 14 | loss: 0.0550120
	speed: 7.0686s/iter; left time: 131956.4853s
	iters: 200, epoch: 14 | loss: 0.0765724
	speed: 0.6410s/iter; left time: 11901.8081s
	iters: 300, epoch: 14 | loss: 0.0594586
	speed: 0.6166s/iter; left time: 11387.2843s
	iters: 400, epoch: 14 | loss: 0.0718415
	speed: 0.5521s/iter; left time: 10140.8036s
	iters: 500, epoch: 14 | loss: 0.0611447
	speed: 0.5369s/iter; left time: 9807.6063s
	iters: 600, epoch: 14 | loss: 0.0523001
	speed: 0.6810s/iter; left time: 12372.1778s
	iters: 700, epoch: 14 | loss: 0.0722972
	speed: 0.6754s/iter; left time: 12202.6962s
	iters: 800, epoch: 14 | loss: 0.0649306
	speed: 0.6362s/iter; left time: 11431.3179s
	iters: 900, epoch: 14 | loss: 0.0694602
	speed: 0.6536s/iter; left time: 11679.2421s
	iters: 1000, epoch: 14 | loss: 0.0615104
	speed: 0.6041s/iter; left time: 10733.7640s
	iters: 1100, epoch: 14 | loss: 0.0770956
	speed: 0.4852s/iter; left time: 8572.9875s
	iters: 1200, epoch: 14 | loss: 0.0567148
	speed: 0.3995s/iter; left time: 7018.4319s
	iters: 1300, epoch: 14 | loss: 0.0728452
	speed: 0.2530s/iter; left time: 4419.0859s
	iters: 1400, epoch: 14 | loss: 0.0593382
	speed: 0.2210s/iter; left time: 3838.3570s
	iters: 1500, epoch: 14 | loss: 0.0824114
	speed: 0.2521s/iter; left time: 4353.2924s
	iters: 1600, epoch: 14 | loss: 0.0644274
	speed: 0.3984s/iter; left time: 6839.0360s
	iters: 1700, epoch: 14 | loss: 0.0727649
	speed: 0.7231s/iter; left time: 12342.3832s
	iters: 1800, epoch: 14 | loss: 0.0557669
	speed: 0.7232s/iter; left time: 12271.9861s
	iters: 1900, epoch: 14 | loss: 0.0580711
	speed: 0.7225s/iter; left time: 12186.7875s
	iters: 2000, epoch: 14 | loss: 0.0541300
	speed: 0.7227s/iter; left time: 12118.0692s
	iters: 2100, epoch: 14 | loss: 0.0559602
	speed: 0.7214s/iter; left time: 12024.3307s
	iters: 2200, epoch: 14 | loss: 0.0641657
	speed: 0.7229s/iter; left time: 11977.5108s
	iters: 2300, epoch: 14 | loss: 0.0765522
	speed: 0.7225s/iter; left time: 11898.6824s
	iters: 2400, epoch: 14 | loss: 0.0656291
	speed: 0.7235s/iter; left time: 11841.4388s
	iters: 2500, epoch: 14 | loss: 0.0698191
	speed: 0.6963s/iter; left time: 11326.6704s
	iters: 2600, epoch: 14 | loss: 0.0704088
	speed: 0.7223s/iter; left time: 11678.8585s
Epoch: 14 cost time: 00h:26m:47.93s
Epoch: 14 | Train Loss: 0.0661358 Vali Loss: 0.0595082 Test Loss: 0.0636313
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.010770452208817005, rmse:0.10378079116344452, mae:0.06202606484293938, rse:0.39211392402648926
success delete checkpoints
Intermediate time for IT and pred_len 24: 05h:40m:08.68s


=== Starting experiments for country: IT ===

=== Starting experiments for pred_len: 96 ===

--- Running model for IT, pred_len=96 ---
train 85587
val 18435
test 18435
[2024-11-01 18:46:19,796] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 18:46:20,413] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 18:46:20,413] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 18:46:20,413] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 18:46:20,495] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 18:46:20,495] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 18:46:21,225] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 18:46:21,226] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 18:46:21,226] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 18:46:21,228] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 18:46:21,228] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 18:46:21,228] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 18:46:21,228] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 18:46:21,228] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 18:46:21,228] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 18:46:21,228] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 18:46:21,584] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 18:46:21,585] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 18:46:21,585] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 156.88 GB, percent = 20.8%
[2024-11-01 18:46:21,729] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 18:46:21,730] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 18:46:21,730] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 156.88 GB, percent = 20.8%
[2024-11-01 18:46:21,730] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 18:46:21,860] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 18:46:21,861] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB 
[2024-11-01 18:46:21,861] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 156.88 GB, percent = 20.8%
[2024-11-01 18:46:21,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 18:46:21,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 18:46:21,862] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 18:46:21,862] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 18:46:21,863] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 18:46:21,863] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f85a438cfd0>
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 18:46:21,864] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 18:46:21,865] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 18:46:21,866] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 18:46:21,866] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.2074100
	speed: 0.1568s/iter; left time: 8368.8084s
	iters: 200, epoch: 1 | loss: 0.1933736
	speed: 0.1180s/iter; left time: 6287.0515s
	iters: 300, epoch: 1 | loss: 0.1680937
	speed: 0.1187s/iter; left time: 6314.6079s
	iters: 400, epoch: 1 | loss: 0.1478600
	speed: 0.1202s/iter; left time: 6378.3367s
	iters: 500, epoch: 1 | loss: 0.1329422
	speed: 0.1186s/iter; left time: 6284.2614s
	iters: 600, epoch: 1 | loss: 0.1080209
	speed: 0.1171s/iter; left time: 6191.0934s
	iters: 700, epoch: 1 | loss: 0.1268893
	speed: 0.1204s/iter; left time: 6356.3251s
	iters: 800, epoch: 1 | loss: 0.1043758
	speed: 0.1189s/iter; left time: 6263.5940s
	iters: 900, epoch: 1 | loss: 0.1108791
	speed: 0.1223s/iter; left time: 6431.4191s
	iters: 1000, epoch: 1 | loss: 0.1154346
	speed: 0.1192s/iter; left time: 6256.3694s
	iters: 1100, epoch: 1 | loss: 0.0978668
	speed: 0.1174s/iter; left time: 6150.8642s
	iters: 1200, epoch: 1 | loss: 0.0894702
	speed: 0.1182s/iter; left time: 6181.9847s
	iters: 1300, epoch: 1 | loss: 0.1008194
	speed: 0.1185s/iter; left time: 6184.0211s
	iters: 1400, epoch: 1 | loss: 0.1065734
	speed: 0.1158s/iter; left time: 6033.3722s
	iters: 1500, epoch: 1 | loss: 0.1051371
	speed: 0.1154s/iter; left time: 5999.8099s
	iters: 1600, epoch: 1 | loss: 0.0991306
	speed: 0.1183s/iter; left time: 6139.2978s
	iters: 1700, epoch: 1 | loss: 0.1286744
	speed: 0.1183s/iter; left time: 6123.5862s
	iters: 1800, epoch: 1 | loss: 0.1012800
	speed: 0.1167s/iter; left time: 6032.8441s
	iters: 1900, epoch: 1 | loss: 0.1123592
	speed: 0.1175s/iter; left time: 6060.4673s
	iters: 2000, epoch: 1 | loss: 0.0761735
	speed: 0.1185s/iter; left time: 6098.6186s
	iters: 2100, epoch: 1 | loss: 0.1169404
	speed: 0.1183s/iter; left time: 6077.8008s
	iters: 2200, epoch: 1 | loss: 0.1165787
	speed: 0.1164s/iter; left time: 5970.1505s
	iters: 2300, epoch: 1 | loss: 0.1044903
	speed: 0.1160s/iter; left time: 5937.3712s
	iters: 2400, epoch: 1 | loss: 0.0961953
	speed: 0.1196s/iter; left time: 6107.9804s
	iters: 2500, epoch: 1 | loss: 0.1058684
	speed: 0.1171s/iter; left time: 5968.6043s
	iters: 2600, epoch: 1 | loss: 0.0999430
	speed: 0.1171s/iter; left time: 5960.1399s
Epoch: 1 cost time: 00h:05m:17.22s
Epoch: 1 | Train Loss: 0.1198931 Vali Loss: 0.0841650 Test Loss: 0.0884351
Validation loss decreased (inf --> 0.084165).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.1127564
	speed: 1.1111s/iter; left time: 56340.8461s
	iters: 200, epoch: 2 | loss: 0.0858049
	speed: 0.1049s/iter; left time: 5308.5571s
	iters: 300, epoch: 2 | loss: 0.0845444
	speed: 0.1087s/iter; left time: 5490.5068s
	iters: 400, epoch: 2 | loss: 0.0956632
	speed: 0.1069s/iter; left time: 5386.7965s
	iters: 500, epoch: 2 | loss: 0.0922268
	speed: 0.1090s/iter; left time: 5484.9339s
	iters: 600, epoch: 2 | loss: 0.0877490
	speed: 0.1051s/iter; left time: 5275.1599s
	iters: 700, epoch: 2 | loss: 0.0789305
	speed: 0.1053s/iter; left time: 5278.0822s
	iters: 800, epoch: 2 | loss: 0.1000123
	speed: 0.1078s/iter; left time: 5389.9002s
	iters: 900, epoch: 2 | loss: 0.1008030
	speed: 0.1106s/iter; left time: 5520.2775s
	iters: 1000, epoch: 2 | loss: 0.0849907
	speed: 0.1086s/iter; left time: 5410.1729s
	iters: 1100, epoch: 2 | loss: 0.0847871
	speed: 0.1078s/iter; left time: 5358.4583s
	iters: 1200, epoch: 2 | loss: 0.1110906
	speed: 0.1064s/iter; left time: 5275.7505s
	iters: 1300, epoch: 2 | loss: 0.0902140
	speed: 0.1080s/iter; left time: 5347.2691s
	iters: 1400, epoch: 2 | loss: 0.1075663
	speed: 0.1071s/iter; left time: 5290.4028s
	iters: 1500, epoch: 2 | loss: 0.0813371
	speed: 0.1072s/iter; left time: 5286.8969s
	iters: 1600, epoch: 2 | loss: 0.0910764
	speed: 0.1089s/iter; left time: 5360.3944s
	iters: 1700, epoch: 2 | loss: 0.0874856
	speed: 0.1083s/iter; left time: 5316.9056s
	iters: 1800, epoch: 2 | loss: 0.1003650
	speed: 0.1086s/iter; left time: 5321.9737s
	iters: 1900, epoch: 2 | loss: 0.0853289
	speed: 0.1106s/iter; left time: 5407.1370s
	iters: 2000, epoch: 2 | loss: 0.0867084
	speed: 0.1093s/iter; left time: 5336.4430s
	iters: 2100, epoch: 2 | loss: 0.0767493
	speed: 0.1048s/iter; left time: 5102.3173s
	iters: 2200, epoch: 2 | loss: 0.0793778
	speed: 0.1061s/iter; left time: 5156.8419s
	iters: 2300, epoch: 2 | loss: 0.0787130
	speed: 0.1076s/iter; left time: 5217.5350s
	iters: 2400, epoch: 2 | loss: 0.0944487
	speed: 0.1084s/iter; left time: 5247.8970s
	iters: 2500, epoch: 2 | loss: 0.0862754
	speed: 0.1043s/iter; left time: 5039.6532s
	iters: 2600, epoch: 2 | loss: 0.0699872
	speed: 0.1088s/iter; left time: 5243.1170s
Epoch: 2 cost time: 00h:04m:48.62s
Epoch: 2 | Train Loss: 0.0951379 Vali Loss: 0.0802616 Test Loss: 0.0852105
Validation loss decreased (0.084165 --> 0.080262).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0913631
	speed: 0.9733s/iter; left time: 46749.6524s
	iters: 200, epoch: 3 | loss: 0.0941604
	speed: 0.1042s/iter; left time: 4992.4185s
	iters: 300, epoch: 3 | loss: 0.0937610
	speed: 0.1096s/iter; left time: 5244.6674s
	iters: 400, epoch: 3 | loss: 0.0962613
	speed: 0.1093s/iter; left time: 5217.6264s
	iters: 500, epoch: 3 | loss: 0.1008476
	speed: 0.1076s/iter; left time: 5126.2777s
	iters: 600, epoch: 3 | loss: 0.1072278
	speed: 0.1066s/iter; left time: 5068.1680s
	iters: 700, epoch: 3 | loss: 0.0809577
	speed: 0.1087s/iter; left time: 5155.8986s
	iters: 800, epoch: 3 | loss: 0.0869908
	speed: 0.1084s/iter; left time: 5128.8640s
	iters: 900, epoch: 3 | loss: 0.1061004
	speed: 0.1079s/iter; left time: 5095.5592s
	iters: 1000, epoch: 3 | loss: 0.1013325
	speed: 0.1067s/iter; left time: 5029.5449s
	iters: 1100, epoch: 3 | loss: 0.0924709
	speed: 0.1094s/iter; left time: 5145.3761s
	iters: 1200, epoch: 3 | loss: 0.0991043
	speed: 0.1090s/iter; left time: 5113.6184s
	iters: 1300, epoch: 3 | loss: 0.1008329
	speed: 0.1083s/iter; left time: 5069.8496s
	iters: 1400, epoch: 3 | loss: 0.0831598
	speed: 0.1089s/iter; left time: 5087.3484s
	iters: 1500, epoch: 3 | loss: 0.1090582
	speed: 0.1080s/iter; left time: 5037.3135s
	iters: 1600, epoch: 3 | loss: 0.1031286
	speed: 0.1071s/iter; left time: 4982.4246s
	iters: 1700, epoch: 3 | loss: 0.0970030
	speed: 0.1060s/iter; left time: 4923.6348s
	iters: 1800, epoch: 3 | loss: 0.0891229
	speed: 0.1091s/iter; left time: 5055.8422s
	iters: 1900, epoch: 3 | loss: 0.0952215
	speed: 0.1086s/iter; left time: 5021.1765s
	iters: 2000, epoch: 3 | loss: 0.0831259
	speed: 0.1057s/iter; left time: 4875.9754s
	iters: 2100, epoch: 3 | loss: 0.1124142
	speed: 0.1078s/iter; left time: 4960.2853s
	iters: 2200, epoch: 3 | loss: 0.1149694
	speed: 0.1050s/iter; left time: 4824.1959s
	iters: 2300, epoch: 3 | loss: 0.0783673
	speed: 0.1064s/iter; left time: 4878.3588s
	iters: 2400, epoch: 3 | loss: 0.0836947
	speed: 0.1068s/iter; left time: 4884.9441s
	iters: 2500, epoch: 3 | loss: 0.0893349
	speed: 0.1083s/iter; left time: 4943.9959s
	iters: 2600, epoch: 3 | loss: 0.0813950
	speed: 0.1053s/iter; left time: 4793.4178s
Epoch: 3 cost time: 00h:04m:48.08s
Epoch: 3 | Train Loss: 0.0912028 Vali Loss: 0.0809163 Test Loss: 0.0860651
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0766129
	speed: 0.9462s/iter; left time: 42918.5749s
	iters: 200, epoch: 4 | loss: 0.1203493
	speed: 0.1075s/iter; left time: 4864.1124s
	iters: 300, epoch: 4 | loss: 0.0836161
	speed: 0.1079s/iter; left time: 4874.6634s
	iters: 400, epoch: 4 | loss: 0.0988006
	speed: 0.1061s/iter; left time: 4781.4835s
	iters: 500, epoch: 4 | loss: 0.0826896
	speed: 0.1069s/iter; left time: 4806.6804s
	iters: 600, epoch: 4 | loss: 0.0930348
	speed: 0.1066s/iter; left time: 4779.9052s
	iters: 700, epoch: 4 | loss: 0.0988240
	speed: 0.1085s/iter; left time: 4855.1937s
	iters: 800, epoch: 4 | loss: 0.0805480
	speed: 0.1081s/iter; left time: 4829.0842s
	iters: 900, epoch: 4 | loss: 0.0826487
	speed: 0.1080s/iter; left time: 4812.6416s
	iters: 1000, epoch: 4 | loss: 0.0710772
	speed: 0.1082s/iter; left time: 4810.1110s
	iters: 1100, epoch: 4 | loss: 0.0831637
	speed: 0.1053s/iter; left time: 4670.8813s
	iters: 1200, epoch: 4 | loss: 0.0868283
	speed: 0.1081s/iter; left time: 4783.3642s
	iters: 1300, epoch: 4 | loss: 0.1062559
	speed: 0.1054s/iter; left time: 4654.4224s
	iters: 1400, epoch: 4 | loss: 0.0913987
	speed: 0.1097s/iter; left time: 4834.0975s
	iters: 1500, epoch: 4 | loss: 0.0884490
	speed: 0.1070s/iter; left time: 4703.2118s
	iters: 1600, epoch: 4 | loss: 0.0850192
	speed: 0.1078s/iter; left time: 4728.4907s
	iters: 1700, epoch: 4 | loss: 0.0802786
	speed: 0.1068s/iter; left time: 4674.7656s
	iters: 1800, epoch: 4 | loss: 0.0982129
	speed: 0.1047s/iter; left time: 4570.4756s
	iters: 1900, epoch: 4 | loss: 0.0785628
	speed: 0.1073s/iter; left time: 4674.8890s
	iters: 2000, epoch: 4 | loss: 0.0918725
	speed: 0.1100s/iter; left time: 4779.1315s
	iters: 2100, epoch: 4 | loss: 0.0956076
	speed: 0.1055s/iter; left time: 4575.6396s
	iters: 2200, epoch: 4 | loss: 0.0837968
	speed: 0.1071s/iter; left time: 4634.8803s
	iters: 2300, epoch: 4 | loss: 0.1122651
	speed: 0.1055s/iter; left time: 4554.5647s
	iters: 2400, epoch: 4 | loss: 0.0925200
	speed: 0.1056s/iter; left time: 4546.9752s
	iters: 2500, epoch: 4 | loss: 0.0905496
	speed: 0.1068s/iter; left time: 4586.4018s
	iters: 2600, epoch: 4 | loss: 0.0913031
	speed: 0.1079s/iter; left time: 4623.1894s
Epoch: 4 cost time: 00h:04m:47.17s
Epoch: 4 | Train Loss: 0.0887905 Vali Loss: 0.0801354 Test Loss: 0.0864428
Validation loss decreased (0.080262 --> 0.080135).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.0905916
	speed: 0.9738s/iter; left time: 41567.9658s
	iters: 200, epoch: 5 | loss: 0.0949473
	speed: 0.1054s/iter; left time: 4490.4853s
	iters: 300, epoch: 5 | loss: 0.0949715
	speed: 0.1087s/iter; left time: 4618.2646s
	iters: 400, epoch: 5 | loss: 0.0939259
	speed: 0.1068s/iter; left time: 4524.8611s
	iters: 500, epoch: 5 | loss: 0.0792014
	speed: 0.1064s/iter; left time: 4498.9735s
	iters: 600, epoch: 5 | loss: 0.1021533
	speed: 0.1099s/iter; left time: 4636.5897s
	iters: 700, epoch: 5 | loss: 0.0821311
	speed: 0.1077s/iter; left time: 4530.6270s
	iters: 800, epoch: 5 | loss: 0.0785077
	speed: 0.1059s/iter; left time: 4444.6085s
	iters: 900, epoch: 5 | loss: 0.0880126
	speed: 0.1068s/iter; left time: 4472.3946s
	iters: 1000, epoch: 5 | loss: 0.0763944
	speed: 0.1072s/iter; left time: 4478.3228s
	iters: 1100, epoch: 5 | loss: 0.0758381
	speed: 0.1055s/iter; left time: 4398.5781s
	iters: 1200, epoch: 5 | loss: 0.0830716
	speed: 0.1078s/iter; left time: 4483.0852s
	iters: 1300, epoch: 5 | loss: 0.0800337
	speed: 0.1077s/iter; left time: 4469.1844s
	iters: 1400, epoch: 5 | loss: 0.0928819
	speed: 0.1058s/iter; left time: 4379.2067s
	iters: 1500, epoch: 5 | loss: 0.0703389
	speed: 0.1066s/iter; left time: 4402.8637s
	iters: 1600, epoch: 5 | loss: 0.0925038
	speed: 0.1069s/iter; left time: 4401.5081s
	iters: 1700, epoch: 5 | loss: 0.0736254
	speed: 0.1067s/iter; left time: 4382.8549s
	iters: 1800, epoch: 5 | loss: 0.0827256
	speed: 0.1072s/iter; left time: 4395.4075s
	iters: 1900, epoch: 5 | loss: 0.0770165
	speed: 0.1071s/iter; left time: 4378.5323s
	iters: 2000, epoch: 5 | loss: 0.0748519
	speed: 0.1071s/iter; left time: 4369.6054s
	iters: 2100, epoch: 5 | loss: 0.0818176
	speed: 0.1072s/iter; left time: 4360.8976s
	iters: 2200, epoch: 5 | loss: 0.0815690
	speed: 0.1088s/iter; left time: 4415.2942s
	iters: 2300, epoch: 5 | loss: 0.1056789
	speed: 0.1061s/iter; left time: 4294.2385s
	iters: 2400, epoch: 5 | loss: 0.0869661
	speed: 0.1065s/iter; left time: 4299.1544s
	iters: 2500, epoch: 5 | loss: 0.0985921
	speed: 0.1063s/iter; left time: 4282.2412s
	iters: 2600, epoch: 5 | loss: 0.0684036
	speed: 0.1073s/iter; left time: 4313.4579s
Epoch: 5 cost time: 00h:04m:46.79s
Epoch: 5 | Train Loss: 0.0866818 Vali Loss: 0.0797001 Test Loss: 0.0868311
Validation loss decreased (0.080135 --> 0.079700).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.1188883
	speed: 0.9661s/iter; left time: 38653.8334s
	iters: 200, epoch: 6 | loss: 0.0875507
	speed: 0.1062s/iter; left time: 4237.6860s
	iters: 300, epoch: 6 | loss: 0.0807057
	speed: 0.1075s/iter; left time: 4278.8919s
	iters: 400, epoch: 6 | loss: 0.0704877
	speed: 0.1093s/iter; left time: 4339.2258s
	iters: 500, epoch: 6 | loss: 0.0778315
	speed: 0.1070s/iter; left time: 4238.8462s
	iters: 600, epoch: 6 | loss: 0.0950918
	speed: 0.1068s/iter; left time: 4220.4604s
	iters: 700, epoch: 6 | loss: 0.0813851
	speed: 0.1062s/iter; left time: 4186.8063s
	iters: 800, epoch: 6 | loss: 0.0890235
	speed: 0.1066s/iter; left time: 4190.6788s
	iters: 900, epoch: 6 | loss: 0.0926933
	speed: 0.1078s/iter; left time: 4225.9179s
	iters: 1000, epoch: 6 | loss: 0.0856443
	speed: 0.1080s/iter; left time: 4224.1536s
	iters: 1100, epoch: 6 | loss: 0.0886120
	speed: 0.1061s/iter; left time: 4138.3593s
	iters: 1200, epoch: 6 | loss: 0.0603817
	speed: 0.1072s/iter; left time: 4169.3491s
	iters: 1300, epoch: 6 | loss: 0.0879021
	speed: 0.1062s/iter; left time: 4120.1029s
	iters: 1400, epoch: 6 | loss: 0.1013661
	speed: 0.1076s/iter; left time: 4164.3751s
	iters: 1500, epoch: 6 | loss: 0.0748302
	speed: 0.1083s/iter; left time: 4182.7493s
	iters: 1600, epoch: 6 | loss: 0.0890142
	speed: 0.1086s/iter; left time: 4182.2646s
	iters: 1700, epoch: 6 | loss: 0.0706096
	speed: 0.1085s/iter; left time: 4168.9343s
	iters: 1800, epoch: 6 | loss: 0.0830537
	speed: 0.1067s/iter; left time: 4088.1822s
	iters: 1900, epoch: 6 | loss: 0.0720259
	speed: 0.1068s/iter; left time: 4080.3013s
	iters: 2000, epoch: 6 | loss: 0.0876311
	speed: 0.1076s/iter; left time: 4102.2921s
	iters: 2100, epoch: 6 | loss: 0.0846190
	speed: 0.1089s/iter; left time: 4141.0885s
	iters: 2200, epoch: 6 | loss: 0.0942824
	speed: 0.1061s/iter; left time: 4021.2046s
	iters: 2300, epoch: 6 | loss: 0.0858440
	speed: 0.1066s/iter; left time: 4030.9647s
	iters: 2400, epoch: 6 | loss: 0.0759794
	speed: 0.1070s/iter; left time: 4033.2909s
	iters: 2500, epoch: 6 | loss: 0.0880383
	speed: 0.1076s/iter; left time: 4047.9399s
	iters: 2600, epoch: 6 | loss: 0.0596848
	speed: 0.1061s/iter; left time: 3979.8882s
Epoch: 6 cost time: 00h:04m:47.93s
Epoch: 6 | Train Loss: 0.0846411 Vali Loss: 0.0798222 Test Loss: 0.0859858
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0920638
	speed: 0.9491s/iter; left time: 35437.0627s
	iters: 200, epoch: 7 | loss: 0.1065395
	speed: 0.1058s/iter; left time: 3938.3599s
	iters: 300, epoch: 7 | loss: 0.0627838
	speed: 0.1061s/iter; left time: 3940.8544s
	iters: 400, epoch: 7 | loss: 0.0834983
	speed: 0.1066s/iter; left time: 3949.7705s
	iters: 500, epoch: 7 | loss: 0.0813256
	speed: 0.1066s/iter; left time: 3936.9331s
	iters: 600, epoch: 7 | loss: 0.0936052
	speed: 0.1076s/iter; left time: 3963.8027s
	iters: 700, epoch: 7 | loss: 0.0897368
	speed: 0.1092s/iter; left time: 4012.6157s
	iters: 800, epoch: 7 | loss: 0.0712877
	speed: 0.1082s/iter; left time: 3964.6565s
	iters: 900, epoch: 7 | loss: 0.0922524
	speed: 0.1070s/iter; left time: 3908.6714s
	iters: 1000, epoch: 7 | loss: 0.1083432
	speed: 0.1084s/iter; left time: 3947.9697s
	iters: 1100, epoch: 7 | loss: 0.0795755
	speed: 0.1070s/iter; left time: 3888.1207s
	iters: 1200, epoch: 7 | loss: 0.0830358
	speed: 0.1059s/iter; left time: 3837.6740s
	iters: 1300, epoch: 7 | loss: 0.0777278
	speed: 0.1070s/iter; left time: 3868.2004s
	iters: 1400, epoch: 7 | loss: 0.0791193
	speed: 0.1076s/iter; left time: 3878.8119s
	iters: 1500, epoch: 7 | loss: 0.0937434
	speed: 0.1081s/iter; left time: 3886.1613s
	iters: 1600, epoch: 7 | loss: 0.0894421
	speed: 0.1049s/iter; left time: 3758.1150s
	iters: 1700, epoch: 7 | loss: 0.0789753
	speed: 0.1076s/iter; left time: 3845.3894s
	iters: 1800, epoch: 7 | loss: 0.0762554
	speed: 0.1078s/iter; left time: 3840.1671s
	iters: 1900, epoch: 7 | loss: 0.0578167
	speed: 0.1063s/iter; left time: 3779.2279s
	iters: 2000, epoch: 7 | loss: 0.0893710
	speed: 0.1069s/iter; left time: 3787.3885s
	iters: 2100, epoch: 7 | loss: 0.0829187
	speed: 0.1075s/iter; left time: 3798.6228s
	iters: 2200, epoch: 7 | loss: 0.1052914
	speed: 0.1071s/iter; left time: 3772.6337s
	iters: 2300, epoch: 7 | loss: 0.1023362
	speed: 0.1095s/iter; left time: 3848.6824s
	iters: 2400, epoch: 7 | loss: 0.0633124
	speed: 0.1063s/iter; left time: 3724.8790s
	iters: 2500, epoch: 7 | loss: 0.0897403
	speed: 0.1075s/iter; left time: 3756.9259s
	iters: 2600, epoch: 7 | loss: 0.0877524
	speed: 0.1090s/iter; left time: 3797.6586s
Epoch: 7 cost time: 00h:04m:47.29s
Epoch: 7 | Train Loss: 0.0827914 Vali Loss: 0.0802376 Test Loss: 0.0865027
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 8 | loss: 0.0741210
	speed: 0.9454s/iter; left time: 32769.5354s
	iters: 200, epoch: 8 | loss: 0.0855546
	speed: 0.1072s/iter; left time: 3704.5005s
	iters: 300, epoch: 8 | loss: 0.0862117
	speed: 0.1098s/iter; left time: 3785.1524s
	iters: 400, epoch: 8 | loss: 0.0810832
	speed: 0.1084s/iter; left time: 3726.2305s
	iters: 500, epoch: 8 | loss: 0.0992447
	speed: 0.1098s/iter; left time: 3762.9928s
	iters: 600, epoch: 8 | loss: 0.0759280
	speed: 0.1082s/iter; left time: 3695.9535s
	iters: 700, epoch: 8 | loss: 0.0706180
	speed: 0.1090s/iter; left time: 3713.7401s
	iters: 800, epoch: 8 | loss: 0.0777954
	speed: 0.1067s/iter; left time: 3625.5497s
	iters: 900, epoch: 8 | loss: 0.0899965
	speed: 0.1079s/iter; left time: 3653.0943s
	iters: 1000, epoch: 8 | loss: 0.0714895
	speed: 0.1080s/iter; left time: 3644.8021s
	iters: 1100, epoch: 8 | loss: 0.0831028
	speed: 0.1081s/iter; left time: 3638.8867s
	iters: 1200, epoch: 8 | loss: 0.0776870
	speed: 0.1096s/iter; left time: 3679.7083s
	iters: 1300, epoch: 8 | loss: 0.0858583
	speed: 0.1100s/iter; left time: 3680.7878s
	iters: 1400, epoch: 8 | loss: 0.0750962
	speed: 0.1073s/iter; left time: 3578.4679s
	iters: 1500, epoch: 8 | loss: 0.0934992
	speed: 0.1083s/iter; left time: 3600.9218s
	iters: 1600, epoch: 8 | loss: 0.0680919
	speed: 0.1052s/iter; left time: 3490.3557s
	iters: 1700, epoch: 8 | loss: 0.0809952
	speed: 0.1073s/iter; left time: 3548.4462s
	iters: 1800, epoch: 8 | loss: 0.0644422
	speed: 0.1054s/iter; left time: 3472.8346s
	iters: 1900, epoch: 8 | loss: 0.0749647
	speed: 0.1071s/iter; left time: 3519.0414s
	iters: 2000, epoch: 8 | loss: 0.0769117
	speed: 0.1072s/iter; left time: 3513.3857s
	iters: 2100, epoch: 8 | loss: 0.0895205
	speed: 0.1087s/iter; left time: 3551.3185s
	iters: 2200, epoch: 8 | loss: 0.0856249
	speed: 0.1077s/iter; left time: 3505.5672s
	iters: 2300, epoch: 8 | loss: 0.0781523
	speed: 0.1081s/iter; left time: 3508.9550s
	iters: 2400, epoch: 8 | loss: 0.0775857
	speed: 0.1051s/iter; left time: 3402.6150s
	iters: 2500, epoch: 8 | loss: 0.0808454
	speed: 0.1067s/iter; left time: 3442.8840s
	iters: 2600, epoch: 8 | loss: 0.0844256
	speed: 0.1066s/iter; left time: 3427.4898s
Epoch: 8 cost time: 00h:04m:48.47s
Epoch: 8 | Train Loss: 0.0808754 Vali Loss: 0.0805583 Test Loss: 0.0866693
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 9 | loss: 0.0862420
	speed: 0.9500s/iter; left time: 30388.9586s
	iters: 200, epoch: 9 | loss: 0.0791138
	speed: 0.1086s/iter; left time: 3462.0398s
	iters: 300, epoch: 9 | loss: 0.0770254
	speed: 0.1074s/iter; left time: 3412.6888s
	iters: 400, epoch: 9 | loss: 0.0769348
	speed: 0.1057s/iter; left time: 3349.3295s
	iters: 500, epoch: 9 | loss: 0.0745477
	speed: 0.1071s/iter; left time: 3381.8013s
	iters: 600, epoch: 9 | loss: 0.0885054
	speed: 0.1078s/iter; left time: 3394.5918s
	iters: 700, epoch: 9 | loss: 0.0813209
	speed: 0.1079s/iter; left time: 3386.6557s
	iters: 800, epoch: 9 | loss: 0.0839284
	speed: 0.1065s/iter; left time: 3330.7986s
	iters: 900, epoch: 9 | loss: 0.0726186
	speed: 0.1086s/iter; left time: 3388.0660s
	iters: 1000, epoch: 9 | loss: 0.0716390
	speed: 0.1101s/iter; left time: 3422.8263s
	iters: 1100, epoch: 9 | loss: 0.0776923
	speed: 0.1078s/iter; left time: 3339.8868s
	iters: 1200, epoch: 9 | loss: 0.0776154
	speed: 0.1080s/iter; left time: 3337.2683s
	iters: 1300, epoch: 9 | loss: 0.0860990
	speed: 0.1054s/iter; left time: 3245.8279s
	iters: 1400, epoch: 9 | loss: 0.0690729
	speed: 0.1074s/iter; left time: 3296.7388s
	iters: 1500, epoch: 9 | loss: 0.0735717
	speed: 0.1083s/iter; left time: 3312.5226s
	iters: 1600, epoch: 9 | loss: 0.0749671
	speed: 0.1088s/iter; left time: 3317.7888s
	iters: 1700, epoch: 9 | loss: 0.0911820
	speed: 0.1074s/iter; left time: 3264.3587s
	iters: 1800, epoch: 9 | loss: 0.0734640
	speed: 0.1064s/iter; left time: 3223.5899s
	iters: 1900, epoch: 9 | loss: 0.0728578
	speed: 0.1056s/iter; left time: 3188.8085s
	iters: 2000, epoch: 9 | loss: 0.0706099
	speed: 0.1064s/iter; left time: 3202.5999s
	iters: 2100, epoch: 9 | loss: 0.0727396
	speed: 0.1057s/iter; left time: 3168.7169s
	iters: 2200, epoch: 9 | loss: 0.0882496
	speed: 0.1056s/iter; left time: 3157.2907s
	iters: 2300, epoch: 9 | loss: 0.0900344
	speed: 0.1071s/iter; left time: 3190.4316s
	iters: 2400, epoch: 9 | loss: 0.0780393
	speed: 0.1074s/iter; left time: 3187.1405s
	iters: 2500, epoch: 9 | loss: 0.0849080
	speed: 0.1070s/iter; left time: 3165.7953s
	iters: 2600, epoch: 9 | loss: 0.0787509
	speed: 0.1071s/iter; left time: 3158.5391s
Epoch: 9 cost time: 00h:04m:47.14s
Epoch: 9 | Train Loss: 0.0790067 Vali Loss: 0.0807893 Test Loss: 0.0869210
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 10 | loss: 0.0815329
	speed: 0.9467s/iter; left time: 27752.6572s
	iters: 200, epoch: 10 | loss: 0.0723726
	speed: 0.1056s/iter; left time: 3086.5436s
	iters: 300, epoch: 10 | loss: 0.0746200
	speed: 0.1072s/iter; left time: 3120.1906s
	iters: 400, epoch: 10 | loss: 0.0674459
	speed: 0.1071s/iter; left time: 3108.4004s
	iters: 500, epoch: 10 | loss: 0.0791470
	speed: 0.1083s/iter; left time: 3132.8478s
	iters: 600, epoch: 10 | loss: 0.0762916
	speed: 0.1039s/iter; left time: 2995.1592s
	iters: 700, epoch: 10 | loss: 0.0842900
	speed: 0.1083s/iter; left time: 3109.3442s
	iters: 800, epoch: 10 | loss: 0.0661934
	speed: 0.1060s/iter; left time: 3033.7001s
	iters: 900, epoch: 10 | loss: 0.0785321
	speed: 0.1067s/iter; left time: 3042.4933s
	iters: 1000, epoch: 10 | loss: 0.0710449
	speed: 0.1065s/iter; left time: 3025.9503s
	iters: 1100, epoch: 10 | loss: 0.0821774
	speed: 0.1076s/iter; left time: 3046.8154s
	iters: 1200, epoch: 10 | loss: 0.0766501
	speed: 0.1100s/iter; left time: 3103.7786s
	iters: 1300, epoch: 10 | loss: 0.0781828
	speed: 0.1075s/iter; left time: 3023.6201s
	iters: 1400, epoch: 10 | loss: 0.1004712
	speed: 0.1084s/iter; left time: 3038.1119s
	iters: 1500, epoch: 10 | loss: 0.0783593
	speed: 0.1070s/iter; left time: 2987.7387s
	iters: 1600, epoch: 10 | loss: 0.0835777
	speed: 0.1075s/iter; left time: 2990.4313s
	iters: 1700, epoch: 10 | loss: 0.0684503
	speed: 0.1082s/iter; left time: 2999.2111s
	iters: 1800, epoch: 10 | loss: 0.0780601
	speed: 0.1087s/iter; left time: 3001.7177s
	iters: 1900, epoch: 10 | loss: 0.0802295
	speed: 0.1060s/iter; left time: 2917.3336s
	iters: 2000, epoch: 10 | loss: 0.0798366
	speed: 0.1102s/iter; left time: 3021.2508s
	iters: 2100, epoch: 10 | loss: 0.0814212
	speed: 0.1051s/iter; left time: 2872.0196s
	iters: 2200, epoch: 10 | loss: 0.0743018
	speed: 0.1075s/iter; left time: 2926.5272s
	iters: 2300, epoch: 10 | loss: 0.0766831
	speed: 0.1071s/iter; left time: 2903.9019s
	iters: 2400, epoch: 10 | loss: 0.0754861
	speed: 0.1080s/iter; left time: 2918.5208s
	iters: 2500, epoch: 10 | loss: 0.0673950
	speed: 0.1055s/iter; left time: 2840.8183s
	iters: 2600, epoch: 10 | loss: 0.0699747
	speed: 0.1064s/iter; left time: 2852.1384s
Epoch: 10 cost time: 00h:04m:47.15s
Epoch: 10 | Train Loss: 0.0774372 Vali Loss: 0.0823554 Test Loss: 0.0883417
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.019759919494390488, rmse:0.14056998491287231, mae:0.08683112263679504, rse:0.5315272808074951
success delete checkpoints
Intermediate time for IT and pred_len 96: 01h:02m:21.20s

=== Starting experiments for pred_len: 168 ===

--- Running model for IT, pred_len=168 ---
train 85371
val 18219
test 18219
[2024-11-01 19:48:45,252] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-01 19:48:46,156] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-11-01 19:48:46,156] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-11-01 19:48:46,156] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2024-11-01 19:48:46,237] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500
[2024-11-01 19:48:46,237] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-11-01 19:48:46,927] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-11-01 19:48:46,928] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-11-01 19:48:46,928] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-11-01 19:48:46,929] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam
[2024-11-01 19:48:46,929] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>
[2024-11-01 19:48:46,929] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2024-11-01 19:48:46,929] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000
[2024-11-01 19:48:46,929] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2024-11-01 19:48:46,929] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2024-11-01 19:48:46,929] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2024-11-01 19:48:47,275] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states
[2024-11-01 19:48:47,276] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB 
[2024-11-01 19:48:47,276] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.91 GB, percent = 21.2%
[2024-11-01 19:48:47,409] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states
[2024-11-01 19:48:47,410] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.74 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 19:48:47,410] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.92 GB, percent = 21.2%
[2024-11-01 19:48:47,410] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized
[2024-11-01 19:48:47,542] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer
[2024-11-01 19:48:47,543] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.85 GB         Max_CA 1 GB 
[2024-11-01 19:48:47,543] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 159.92 GB, percent = 21.2%
[2024-11-01 19:48:47,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam
[2024-11-01 19:48:47,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-11-01 19:48:47,544] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-11-01 19:48:47,544] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]
[2024-11-01 19:48:47,545] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-11-01 19:48:47,545] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-11-01 19:48:47,545] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-11-01 19:48:47,545] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fcaac3fa6d0>
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-11-01 19:48:47,546] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   train_batch_size ............. 32
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-11-01 19:48:47,547] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   world_size ................... 1
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   zero_enabled ................. True
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-11-01 19:48:47,548] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2
[2024-11-01 19:48:47,548] [INFO] [config.py:986:print_user_config]   json = {
    "bf16": {
        "enabled": true, 
        "auto_cast": true
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true, 
        "sub_group_size": 1.000000e+09
    }, 
    "gradient_accumulation_steps": 1, 
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
	iters: 100, epoch: 1 | loss: 0.2159382
	speed: 0.1625s/iter; left time: 8650.5625s
	iters: 200, epoch: 1 | loss: 0.2169471
	speed: 0.1186s/iter; left time: 6303.3428s
	iters: 300, epoch: 1 | loss: 0.1850180
	speed: 0.1175s/iter; left time: 6234.0535s
	iters: 400, epoch: 1 | loss: 0.1335363
	speed: 0.1192s/iter; left time: 6313.1009s
	iters: 500, epoch: 1 | loss: 0.1362359
	speed: 0.1196s/iter; left time: 6321.5452s
	iters: 600, epoch: 1 | loss: 0.1168138
	speed: 0.1194s/iter; left time: 6297.8483s
	iters: 700, epoch: 1 | loss: 0.1086815
	speed: 0.1203s/iter; left time: 6330.1036s
	iters: 800, epoch: 1 | loss: 0.1136740
	speed: 0.1197s/iter; left time: 6286.5798s
	iters: 900, epoch: 1 | loss: 0.1117396
	speed: 0.1200s/iter; left time: 6291.2907s
	iters: 1000, epoch: 1 | loss: 0.1147921
	speed: 0.1231s/iter; left time: 6445.7360s
	iters: 1100, epoch: 1 | loss: 0.1080129
	speed: 0.1236s/iter; left time: 6457.1588s
	iters: 1200, epoch: 1 | loss: 0.1242537
	speed: 0.1218s/iter; left time: 6348.6780s
	iters: 1300, epoch: 1 | loss: 0.1189426
	speed: 0.1196s/iter; left time: 6222.3027s
	iters: 1400, epoch: 1 | loss: 0.0914909
	speed: 0.1194s/iter; left time: 6201.0761s
	iters: 1500, epoch: 1 | loss: 0.1163723
	speed: 0.1212s/iter; left time: 6281.8316s
	iters: 1600, epoch: 1 | loss: 0.1010581
	speed: 0.1215s/iter; left time: 6285.4440s
	iters: 1700, epoch: 1 | loss: 0.0958032
	speed: 0.1219s/iter; left time: 6295.9882s
	iters: 1800, epoch: 1 | loss: 0.0969449
	speed: 0.1199s/iter; left time: 6179.6927s
	iters: 1900, epoch: 1 | loss: 0.0934629
	speed: 0.1204s/iter; left time: 6193.3448s
	iters: 2000, epoch: 1 | loss: 0.1103176
	speed: 0.1210s/iter; left time: 6213.0971s
	iters: 2100, epoch: 1 | loss: 0.1056070
	speed: 0.1177s/iter; left time: 6032.4514s
	iters: 2200, epoch: 1 | loss: 0.1026355
	speed: 0.1185s/iter; left time: 6058.5829s
	iters: 2300, epoch: 1 | loss: 0.1064908
	speed: 0.1190s/iter; left time: 6071.7748s
	iters: 2400, epoch: 1 | loss: 0.1117751
	speed: 0.1182s/iter; left time: 6022.2998s
	iters: 2500, epoch: 1 | loss: 0.1078130
	speed: 0.1160s/iter; left time: 5898.7287s
	iters: 2600, epoch: 1 | loss: 0.1026039
	speed: 0.1186s/iter; left time: 6019.8095s
Epoch: 1 cost time: 00h:05m:21.09s
Epoch: 1 | Train Loss: 0.1204411 Vali Loss: 0.0876045 Test Loss: 0.0915034
Validation loss decreased (inf --> 0.087604).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 2 | loss: 0.0972830
	speed: 1.0968s/iter; left time: 55467.6135s
	iters: 200, epoch: 2 | loss: 0.0874374
	speed: 0.1075s/iter; left time: 5424.0908s
	iters: 300, epoch: 2 | loss: 0.0931379
	speed: 0.1090s/iter; left time: 5490.5051s
	iters: 400, epoch: 2 | loss: 0.1136137
	speed: 0.1106s/iter; left time: 5562.0945s
	iters: 500, epoch: 2 | loss: 0.1128266
	speed: 0.1077s/iter; left time: 5402.1352s
	iters: 600, epoch: 2 | loss: 0.1001407
	speed: 0.1081s/iter; left time: 5411.0678s
	iters: 700, epoch: 2 | loss: 0.0840503
	speed: 0.1072s/iter; left time: 5358.4367s
	iters: 800, epoch: 2 | loss: 0.0859213
	speed: 0.1103s/iter; left time: 5499.7689s
	iters: 900, epoch: 2 | loss: 0.1103960
	speed: 0.1078s/iter; left time: 5365.5204s
	iters: 1000, epoch: 2 | loss: 0.0919214
	speed: 0.1103s/iter; left time: 5476.6703s
	iters: 1100, epoch: 2 | loss: 0.0923761
	speed: 0.1076s/iter; left time: 5334.5613s
	iters: 1200, epoch: 2 | loss: 0.0950010
	speed: 0.1111s/iter; left time: 5494.2241s
	iters: 1300, epoch: 2 | loss: 0.0965657
	speed: 0.1075s/iter; left time: 5306.5900s
	iters: 1400, epoch: 2 | loss: 0.0979968
	speed: 0.1089s/iter; left time: 5366.1929s
	iters: 1500, epoch: 2 | loss: 0.1063472
	speed: 0.1072s/iter; left time: 5273.7171s
	iters: 1600, epoch: 2 | loss: 0.1021644
	speed: 0.1080s/iter; left time: 5297.7590s
	iters: 1700, epoch: 2 | loss: 0.1312233
	speed: 0.1094s/iter; left time: 5357.0619s
	iters: 1800, epoch: 2 | loss: 0.0861884
	speed: 0.1080s/iter; left time: 5277.2454s
	iters: 1900, epoch: 2 | loss: 0.0921369
	speed: 0.1072s/iter; left time: 5228.3008s
	iters: 2000, epoch: 2 | loss: 0.0864059
	speed: 0.1098s/iter; left time: 5343.3522s
	iters: 2100, epoch: 2 | loss: 0.1039751
	speed: 0.1072s/iter; left time: 5207.4314s
	iters: 2200, epoch: 2 | loss: 0.1015228
	speed: 0.1092s/iter; left time: 5292.8157s
	iters: 2300, epoch: 2 | loss: 0.0781528
	speed: 0.1102s/iter; left time: 5328.7059s
	iters: 2400, epoch: 2 | loss: 0.0949763
	speed: 0.1100s/iter; left time: 5309.7674s
	iters: 2500, epoch: 2 | loss: 0.0828070
	speed: 0.1082s/iter; left time: 5211.2357s
	iters: 2600, epoch: 2 | loss: 0.0963483
	speed: 0.1076s/iter; left time: 5172.2345s
Epoch: 2 cost time: 00h:04m:50.25s
Epoch: 2 | Train Loss: 0.0979559 Vali Loss: 0.0849390 Test Loss: 0.0888758
Validation loss decreased (0.087604 --> 0.084939).  Saving model ...
lr = 0.0000400000
	iters: 100, epoch: 3 | loss: 0.0922209
	speed: 0.9687s/iter; left time: 46409.0279s
	iters: 200, epoch: 3 | loss: 0.0644474
	speed: 0.1104s/iter; left time: 5276.2266s
	iters: 300, epoch: 3 | loss: 0.1041549
	speed: 0.1065s/iter; left time: 5080.0451s
	iters: 400, epoch: 3 | loss: 0.1109336
	speed: 0.1101s/iter; left time: 5240.4659s
	iters: 500, epoch: 3 | loss: 0.1064243
	speed: 0.1073s/iter; left time: 5099.8207s
	iters: 600, epoch: 3 | loss: 0.0900191
	speed: 0.1088s/iter; left time: 5157.0902s
	iters: 700, epoch: 3 | loss: 0.0858806
	speed: 0.1076s/iter; left time: 5090.0047s
	iters: 800, epoch: 3 | loss: 0.1083349
	speed: 0.1071s/iter; left time: 5055.2218s
	iters: 900, epoch: 3 | loss: 0.1029609
	speed: 0.1064s/iter; left time: 5013.4040s
	iters: 1000, epoch: 3 | loss: 0.0872559
	speed: 0.1080s/iter; left time: 5078.9340s
	iters: 1100, epoch: 3 | loss: 0.0983983
	speed: 0.1060s/iter; left time: 4971.6882s
	iters: 1200, epoch: 3 | loss: 0.1123618
	speed: 0.1061s/iter; left time: 4966.2412s
	iters: 1300, epoch: 3 | loss: 0.0855980
	speed: 0.1069s/iter; left time: 4991.4326s
	iters: 1400, epoch: 3 | loss: 0.0841101
	speed: 0.1061s/iter; left time: 4943.2864s
	iters: 1500, epoch: 3 | loss: 0.0859778
	speed: 0.1075s/iter; left time: 5000.7708s
	iters: 1600, epoch: 3 | loss: 0.1071441
	speed: 0.1090s/iter; left time: 5056.4381s
	iters: 1700, epoch: 3 | loss: 0.0972808
	speed: 0.1081s/iter; left time: 5004.9923s
	iters: 1800, epoch: 3 | loss: 0.0949871
	speed: 0.1076s/iter; left time: 4971.3013s
	iters: 1900, epoch: 3 | loss: 0.1109390
	speed: 0.1100s/iter; left time: 5071.3391s
	iters: 2000, epoch: 3 | loss: 0.0801679
	speed: 0.1095s/iter; left time: 5036.8103s
	iters: 2100, epoch: 3 | loss: 0.1097496
	speed: 0.1077s/iter; left time: 4942.2994s
	iters: 2200, epoch: 3 | loss: 0.0926881
	speed: 0.1089s/iter; left time: 4987.8238s
	iters: 2300, epoch: 3 | loss: 0.0823457
	speed: 0.1104s/iter; left time: 5047.5268s
	iters: 2400, epoch: 3 | loss: 0.0971059
	speed: 0.1070s/iter; left time: 4878.8277s
	iters: 2500, epoch: 3 | loss: 0.0847562
	speed: 0.1093s/iter; left time: 4975.2974s
	iters: 2600, epoch: 3 | loss: 0.0877398
	speed: 0.1079s/iter; left time: 4900.1196s
Epoch: 3 cost time: 00h:04m:48.49s
Epoch: 3 | Train Loss: 0.0939890 Vali Loss: 0.0849982 Test Loss: 0.0889016
EarlyStopping counter: 1 out of 5
lr = 0.0000400000
	iters: 100, epoch: 4 | loss: 0.0809531
	speed: 1.7730s/iter; left time: 80211.6398s
	iters: 200, epoch: 4 | loss: 0.1035346
	speed: 0.2306s/iter; left time: 10408.1815s
	iters: 300, epoch: 4 | loss: 0.0931954
	speed: 0.2310s/iter; left time: 10406.4016s
	iters: 400, epoch: 4 | loss: 0.0936391
	speed: 0.2281s/iter; left time: 10251.2154s
	iters: 500, epoch: 4 | loss: 0.0769154
	speed: 0.2328s/iter; left time: 10437.4892s
	iters: 600, epoch: 4 | loss: 0.1011256
	speed: 0.2288s/iter; left time: 10235.0408s
	iters: 700, epoch: 4 | loss: 0.1071842
	speed: 0.2322s/iter; left time: 10365.8645s
	iters: 800, epoch: 4 | loss: 0.0825684
	speed: 0.2298s/iter; left time: 10236.2046s
	iters: 900, epoch: 4 | loss: 0.0715358
	speed: 0.2301s/iter; left time: 10227.1217s
	iters: 1000, epoch: 4 | loss: 0.0911235
	speed: 0.2301s/iter; left time: 10201.2893s
	iters: 1100, epoch: 4 | loss: 0.0931380
	speed: 0.2297s/iter; left time: 10161.0898s
	iters: 1200, epoch: 4 | loss: 0.0906525
	speed: 0.2281s/iter; left time: 10067.3460s
	iters: 1300, epoch: 4 | loss: 0.0844347
	speed: 0.2259s/iter; left time: 9948.2242s
	iters: 1400, epoch: 4 | loss: 0.0868495
	speed: 0.2307s/iter; left time: 10139.0392s
	iters: 1500, epoch: 4 | loss: 0.0898872
	speed: 0.2293s/iter; left time: 10052.1158s
	iters: 1600, epoch: 4 | loss: 0.0944612
	speed: 0.2275s/iter; left time: 9948.7896s
	iters: 1700, epoch: 4 | loss: 0.0744505
	speed: 0.2306s/iter; left time: 10061.9179s
	iters: 1800, epoch: 4 | loss: 0.0840901
	speed: 0.2282s/iter; left time: 9936.3308s
	iters: 1900, epoch: 4 | loss: 0.0785889
	speed: 0.2295s/iter; left time: 9968.4509s
	iters: 2000, epoch: 4 | loss: 0.0908988
	speed: 0.2273s/iter; left time: 9852.6633s
	iters: 2100, epoch: 4 | loss: 0.1051483
	speed: 0.2302s/iter; left time: 9952.8288s
	iters: 2200, epoch: 4 | loss: 0.0749808
	speed: 0.2307s/iter; left time: 9951.5215s
	iters: 2300, epoch: 4 | loss: 0.0964035
	speed: 0.2306s/iter; left time: 9923.2811s
	iters: 2400, epoch: 4 | loss: 0.0797054
	speed: 0.2264s/iter; left time: 9720.9910s
	iters: 2500, epoch: 4 | loss: 0.0989241
	speed: 0.2316s/iter; left time: 9921.9201s
	iters: 2600, epoch: 4 | loss: 0.0763184
	speed: 0.2295s/iter; left time: 9807.0293s
Epoch: 4 cost time: 00h:10m:12.34s
Epoch: 4 | Train Loss: 0.0912334 Vali Loss: 0.0860498 Test Loss: 0.0906333
EarlyStopping counter: 2 out of 5
lr = 0.0000400000
	iters: 100, epoch: 5 | loss: 0.1012761
	speed: 2.2439s/iter; left time: 95527.6044s
	iters: 200, epoch: 5 | loss: 0.0788181
	speed: 0.2084s/iter; left time: 8851.2151s
	iters: 300, epoch: 5 | loss: 0.0916079
	speed: 0.1067s/iter; left time: 4521.4652s
	iters: 400, epoch: 5 | loss: 0.0774744
	speed: 0.1073s/iter; left time: 4535.1739s
	iters: 500, epoch: 5 | loss: 0.0913393
	speed: 0.1118s/iter; left time: 4716.8769s
	iters: 600, epoch: 5 | loss: 0.0951685
	speed: 0.1112s/iter; left time: 4679.1557s
	iters: 700, epoch: 5 | loss: 0.0887147
	speed: 0.1112s/iter; left time: 4668.8883s
	iters: 800, epoch: 5 | loss: 0.0910846
	speed: 0.1113s/iter; left time: 4659.6996s
	iters: 900, epoch: 5 | loss: 0.0891837
	speed: 0.1108s/iter; left time: 4628.0714s
	iters: 1000, epoch: 5 | loss: 0.0790758
	speed: 0.1102s/iter; left time: 4592.6370s
	iters: 1100, epoch: 5 | loss: 0.0895170
	speed: 0.1093s/iter; left time: 4542.9292s
	iters: 1200, epoch: 5 | loss: 0.0942188
	speed: 0.1084s/iter; left time: 4493.6945s
	iters: 1300, epoch: 5 | loss: 0.0948133
	speed: 0.1103s/iter; left time: 4562.9994s
	iters: 1400, epoch: 5 | loss: 0.0987849
	speed: 0.1108s/iter; left time: 4573.1477s
	iters: 1500, epoch: 5 | loss: 0.0812767
	speed: 0.1098s/iter; left time: 4519.8484s
	iters: 1600, epoch: 5 | loss: 0.0904108
	speed: 0.1111s/iter; left time: 4561.8239s
	iters: 1700, epoch: 5 | loss: 0.1042102
	speed: 0.1099s/iter; left time: 4502.1624s
	iters: 1800, epoch: 5 | loss: 0.0898959
	speed: 0.1110s/iter; left time: 4535.6779s
	iters: 1900, epoch: 5 | loss: 0.0911765
	speed: 0.1088s/iter; left time: 4437.4864s
	iters: 2000, epoch: 5 | loss: 0.0696084
	speed: 0.1084s/iter; left time: 4409.7245s
	iters: 2100, epoch: 5 | loss: 0.0943199
	speed: 0.1084s/iter; left time: 4396.9561s
	iters: 2200, epoch: 5 | loss: 0.0874961
	speed: 0.1093s/iter; left time: 4425.6796s
	iters: 2300, epoch: 5 | loss: 0.0919802
	speed: 0.1091s/iter; left time: 4404.1900s
	iters: 2400, epoch: 5 | loss: 0.0831057
	speed: 0.1087s/iter; left time: 4377.1461s
	iters: 2500, epoch: 5 | loss: 0.0805359
	speed: 0.1119s/iter; left time: 4494.4650s
	iters: 2600, epoch: 5 | loss: 0.0857960
	speed: 0.1163s/iter; left time: 4661.8884s
Epoch: 5 cost time: 00h:05m:17.88s
Epoch: 5 | Train Loss: 0.0882231 Vali Loss: 0.0871280 Test Loss: 0.0905764
EarlyStopping counter: 3 out of 5
lr = 0.0000400000
	iters: 100, epoch: 6 | loss: 0.0777886
	speed: 0.9822s/iter; left time: 39197.4713s
	iters: 200, epoch: 6 | loss: 0.0941440
	speed: 0.1113s/iter; left time: 4428.6841s
	iters: 300, epoch: 6 | loss: 0.0958172
	speed: 0.1098s/iter; left time: 4359.8994s
	iters: 400, epoch: 6 | loss: 0.0725196
	speed: 0.1123s/iter; left time: 4449.3066s
	iters: 500, epoch: 6 | loss: 0.0889861
	speed: 0.1163s/iter; left time: 4596.0316s
	iters: 600, epoch: 6 | loss: 0.0903357
	speed: 0.1172s/iter; left time: 4618.9467s
	iters: 700, epoch: 6 | loss: 0.0943096
	speed: 0.1174s/iter; left time: 4615.9566s
	iters: 800, epoch: 6 | loss: 0.0846683
	speed: 0.1175s/iter; left time: 4605.1636s
	iters: 900, epoch: 6 | loss: 0.0848038
	speed: 0.1133s/iter; left time: 4431.4905s
	iters: 1000, epoch: 6 | loss: 0.0868105
	speed: 0.1073s/iter; left time: 4183.8005s
	iters: 1100, epoch: 6 | loss: 0.0821280
	speed: 0.1102s/iter; left time: 4289.0303s
	iters: 1200, epoch: 6 | loss: 0.0953802
	speed: 0.1127s/iter; left time: 4374.1255s
	iters: 1300, epoch: 6 | loss: 0.0808989
	speed: 0.1126s/iter; left time: 4358.3858s
	iters: 1400, epoch: 6 | loss: 0.0898427
	speed: 0.1106s/iter; left time: 4270.6747s
	iters: 1500, epoch: 6 | loss: 0.0939664
	speed: 0.1115s/iter; left time: 4292.8079s
	iters: 1600, epoch: 6 | loss: 0.0925003
	speed: 0.1140s/iter; left time: 4377.7285s
	iters: 1700, epoch: 6 | loss: 0.0959591
	speed: 0.1138s/iter; left time: 4360.4043s
	iters: 1800, epoch: 6 | loss: 0.0839964
	speed: 0.1101s/iter; left time: 4206.4370s
	iters: 1900, epoch: 6 | loss: 0.0757705
	speed: 0.1167s/iter; left time: 4445.6434s
	iters: 2000, epoch: 6 | loss: 0.0871647
	speed: 0.1186s/iter; left time: 4506.6538s
	iters: 2100, epoch: 6 | loss: 0.0874589
	speed: 0.1143s/iter; left time: 4332.6944s
	iters: 2200, epoch: 6 | loss: 0.0961731
	speed: 0.1180s/iter; left time: 4461.5235s
	iters: 2300, epoch: 6 | loss: 0.0795345
	speed: 0.1109s/iter; left time: 4182.2441s
	iters: 2400, epoch: 6 | loss: 0.0825180
	speed: 0.1066s/iter; left time: 4010.1459s
	iters: 2500, epoch: 6 | loss: 0.0753969
	speed: 0.1053s/iter; left time: 3950.3388s
	iters: 2600, epoch: 6 | loss: 0.0764885
	speed: 0.1118s/iter; left time: 4180.5852s
Epoch: 6 cost time: 00h:05m:01.46s
Epoch: 6 | Train Loss: 0.0857598 Vali Loss: 0.0890246 Test Loss: 0.0932542
EarlyStopping counter: 4 out of 5
lr = 0.0000400000
	iters: 100, epoch: 7 | loss: 0.0879309
	speed: 1.0101s/iter; left time: 37615.3618s
	iters: 200, epoch: 7 | loss: 0.0852456
	speed: 0.1209s/iter; left time: 4491.0548s
	iters: 300, epoch: 7 | loss: 0.0813645
	speed: 0.1199s/iter; left time: 4441.2544s
	iters: 400, epoch: 7 | loss: 0.0748249
	speed: 0.1150s/iter; left time: 4248.0719s
	iters: 500, epoch: 7 | loss: 0.0818025
	speed: 0.1151s/iter; left time: 4239.6938s
	iters: 600, epoch: 7 | loss: 0.0957716
	speed: 0.1196s/iter; left time: 4394.5326s
	iters: 700, epoch: 7 | loss: 0.0731218
	speed: 0.1196s/iter; left time: 4380.8388s
	iters: 800, epoch: 7 | loss: 0.0727848
	speed: 0.1191s/iter; left time: 4351.8440s
	iters: 900, epoch: 7 | loss: 0.0822178
	speed: 0.1162s/iter; left time: 4234.4781s
	iters: 1000, epoch: 7 | loss: 0.0866405
	speed: 0.1167s/iter; left time: 4240.3935s
	iters: 1100, epoch: 7 | loss: 0.0839373
	speed: 0.1183s/iter; left time: 4288.2996s
	iters: 1200, epoch: 7 | loss: 0.0864395
	speed: 0.1199s/iter; left time: 4332.5326s
	iters: 1300, epoch: 7 | loss: 0.1001431
	speed: 0.1189s/iter; left time: 4284.6259s
	iters: 1400, epoch: 7 | loss: 0.0870203
	speed: 0.1107s/iter; left time: 3979.0727s
	iters: 1500, epoch: 7 | loss: 0.0783804
	speed: 0.1093s/iter; left time: 3915.4572s
	iters: 1600, epoch: 7 | loss: 0.0840335
	speed: 0.1172s/iter; left time: 4189.5710s
	iters: 1700, epoch: 7 | loss: 0.0848608
	speed: 0.1172s/iter; left time: 4177.0002s
	iters: 1800, epoch: 7 | loss: 0.0887816
	speed: 0.1154s/iter; left time: 4100.6754s
	iters: 1900, epoch: 7 | loss: 0.0716856
	speed: 0.1151s/iter; left time: 4080.3117s
	iters: 2000, epoch: 7 | loss: 0.0809039
	speed: 0.1171s/iter; left time: 4136.9874s
	iters: 2100, epoch: 7 | loss: 0.0809592
	speed: 0.1123s/iter; left time: 3957.4940s
	iters: 2200, epoch: 7 | loss: 0.0854933
	speed: 0.1125s/iter; left time: 3953.1858s
	iters: 2300, epoch: 7 | loss: 0.0758755
	speed: 0.1136s/iter; left time: 3980.6343s
	iters: 2400, epoch: 7 | loss: 0.0947762
	speed: 0.1111s/iter; left time: 3880.2726s
	iters: 2500, epoch: 7 | loss: 0.0809882
	speed: 0.1132s/iter; left time: 3945.1914s
	iters: 2600, epoch: 7 | loss: 0.0749397
	speed: 0.1192s/iter; left time: 4140.6669s
Epoch: 7 cost time: 00h:05m:10.81s
Epoch: 7 | Train Loss: 0.0833416 Vali Loss: 0.0886686 Test Loss: 0.0912572
EarlyStopping counter: 5 out of 5
Early stopping
loading model...
Scaled mse:0.019771769642829895, rmse:0.14061212539672852, mae:0.08887572586536407, rse:0.531994640827179
success delete checkpoints
Intermediate time for IT and pred_len 168: 00h:54m:17.83s
Intermediate time for IT: 01h:56m:39.03s
Total time: 01h:56m:39.03s
