
=== Starting experiments for country: DE ===

=== Starting experiments for pred_len: 24 ===

--- Running model for DE, pred_len=24 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='no_revin_DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : no_revin_DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28777
val 6217
test 6217
	iters: 100, epoch: 1 | loss: 0.1193334
	speed: 0.3741s/iter; left time: 8341.9923s
	iters: 200, epoch: 1 | loss: 0.1139761
	speed: 0.3155s/iter; left time: 7004.2226s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:01m:08.57s
Steps: 224 | Train Loss: 0.1267070 Vali Loss: 0.0935512 Test Loss: 0.0949640
Validation loss decreased (inf --> 0.093551).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0419619
	speed: 0.8710s/iter; left time: 19229.0535s
	iters: 200, epoch: 2 | loss: 0.0285149
	speed: 0.2702s/iter; left time: 5937.9473s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:01m:15.04s
Steps: 224 | Train Loss: 0.0478565 Vali Loss: 0.0277070 Test Loss: 0.0295532
Validation loss decreased (0.093551 --> 0.027707).  Saving model ...
Updating learning rate to 0.0001
/bin/sh: Zeile 1: 59543 Beendet                 python ./PatchTST-main/PatchTST_supervised/run_longExp.py --is_training 1 --root_path "/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/" --data_path "DE_data.csv" --model_id no_revin_DE_336_24_DE --model "PatchTST" --data "custom" --features M --seq_len 336 --pred_len 24 --e_layers 3 --factor 1 --enc_in 5 --c_out 5 --des 'Exp' --train_epochs 100 --patience 10 --n_heads 16 --d_model 128 --d_ff 256 --dropout 0.2 --fc_dropout 0.2 --overlapping_windows --scaler_type minmax --if_relu --loss_fnc MSE --revin 0 --itr 2 --batch_size 128 --learning_rate "0.0001"
