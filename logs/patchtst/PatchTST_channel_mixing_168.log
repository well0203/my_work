
=== Starting experiments for country: DE ===

=== Starting experiments for pred_len: 24 ===

--- Running model for DE, pred_len=24 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_168_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6217
test 6217
	iters: 100, epoch: 1 | loss: 0.0234579
	speed: 0.0700s/iter; left time: 1574.1290s
	iters: 200, epoch: 1 | loss: 0.0188763
	speed: 0.0480s/iter; left time: 1074.2645s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.47s
Steps: 226 | Train Loss: 0.0251614 Vali Loss: 0.0242755 Test Loss: 0.0266506
Validation loss decreased (inf --> 0.024276).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0147026
	speed: 0.0929s/iter; left time: 2069.5066s
	iters: 200, epoch: 2 | loss: 0.0127275
	speed: 0.0476s/iter; left time: 1056.3407s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:11.16s
Steps: 226 | Train Loss: 0.0146741 Vali Loss: 0.0213676 Test Loss: 0.0233677
Validation loss decreased (0.024276 --> 0.021368).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0132120
	speed: 0.1003s/iter; left time: 2210.7943s
	iters: 200, epoch: 3 | loss: 0.0103937
	speed: 0.0483s/iter; left time: 1060.1647s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.26s
Steps: 226 | Train Loss: 0.0117886 Vali Loss: 0.0237567 Test Loss: 0.0268710
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0099479
	speed: 0.0928s/iter; left time: 2025.6468s
	iters: 200, epoch: 4 | loss: 0.0083373
	speed: 0.0488s/iter; left time: 1060.7452s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:11.17s
Steps: 226 | Train Loss: 0.0090726 Vali Loss: 0.0256334 Test Loss: 0.0279961
EarlyStopping counter: 2 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0073438
	speed: 0.0861s/iter; left time: 1859.5452s
	iters: 200, epoch: 5 | loss: 0.0066576
	speed: 0.0477s/iter; left time: 1025.7056s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:11.09s
Steps: 226 | Train Loss: 0.0069540 Vali Loss: 0.0259422 Test Loss: 0.0284075
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0058564
	speed: 0.0965s/iter; left time: 2062.8319s
	iters: 200, epoch: 6 | loss: 0.0050857
	speed: 0.0493s/iter; left time: 1048.4800s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:11.29s
Steps: 226 | Train Loss: 0.0056569 Vali Loss: 0.0269273 Test Loss: 0.0289203
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0046096
	speed: 0.0916s/iter; left time: 1936.9642s
	iters: 200, epoch: 7 | loss: 0.0043860
	speed: 0.0493s/iter; left time: 1037.7382s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:11.58s
Steps: 226 | Train Loss: 0.0047801 Vali Loss: 0.0265904 Test Loss: 0.0292324
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0042168
	speed: 0.0932s/iter; left time: 1949.7598s
	iters: 200, epoch: 8 | loss: 0.0038549
	speed: 0.0497s/iter; left time: 1034.4960s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:11.60s
Steps: 226 | Train Loss: 0.0042179 Vali Loss: 0.0266252 Test Loss: 0.0286232
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0042412
	speed: 0.0944s/iter; left time: 1952.3947s
	iters: 200, epoch: 9 | loss: 0.0034975
	speed: 0.0483s/iter; left time: 994.2371s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:11.30s
Steps: 226 | Train Loss: 0.0037897 Vali Loss: 0.0266672 Test Loss: 0.0288044
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0034196
	speed: 0.0930s/iter; left time: 1902.4802s
	iters: 200, epoch: 10 | loss: 0.0032693
	speed: 0.0504s/iter; left time: 1026.5745s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:11.57s
Steps: 226 | Train Loss: 0.0034596 Vali Loss: 0.0265314 Test Loss: 0.0287724
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0032838
	speed: 0.0972s/iter; left time: 1966.9264s
	iters: 200, epoch: 11 | loss: 0.0030819
	speed: 0.0509s/iter; left time: 1025.8333s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.78s
Steps: 226 | Train Loss: 0.0032145 Vali Loss: 0.0266764 Test Loss: 0.0286681
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0028341
	speed: 0.0893s/iter; left time: 1786.6423s
	iters: 200, epoch: 12 | loss: 0.0030430
	speed: 0.0504s/iter; left time: 1003.7997s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:11.56s
Steps: 226 | Train Loss: 0.0030139 Vali Loss: 0.0263912 Test Loss: 0.0286644
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_168_24_DE_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.02336770109832287, rmse:0.1528649777173996, mae:0.1005844995379448, rse:0.5394816398620605
Intermediate time for DE and pred_len 24: 00h:03m:01.06s
=== Starting experiments for pred_len: 96 ===

--- Running model for DE, pred_len=96 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_168_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6145
test 6145
	iters: 100, epoch: 1 | loss: 0.0332638
	speed: 0.0791s/iter; left time: 1771.5424s
	iters: 200, epoch: 1 | loss: 0.0300356
	speed: 0.0502s/iter; left time: 1119.4530s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.85s
Steps: 225 | Train Loss: 0.0334871 Vali Loss: 0.0348219 Test Loss: 0.0412176
Validation loss decreased (inf --> 0.034822).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0224506
	speed: 0.0969s/iter; left time: 2149.5423s
	iters: 200, epoch: 2 | loss: 0.0186753
	speed: 0.0501s/iter; left time: 1106.3206s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:11.63s
Steps: 225 | Train Loss: 0.0218892 Vali Loss: 0.0342691 Test Loss: 0.0442524
Validation loss decreased (0.034822 --> 0.034269).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0144677
	speed: 0.1107s/iter; left time: 2430.9855s
	iters: 200, epoch: 3 | loss: 0.0123060
	speed: 0.0490s/iter; left time: 1070.5410s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.55s
Steps: 225 | Train Loss: 0.0147549 Vali Loss: 0.0370631 Test Loss: 0.0474851
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0108411
	speed: 0.0979s/iter; left time: 2127.4352s
	iters: 200, epoch: 4 | loss: 0.0097878
	speed: 0.0483s/iter; left time: 1044.4061s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:11.39s
Steps: 225 | Train Loss: 0.0106510 Vali Loss: 0.0379387 Test Loss: 0.0481010
EarlyStopping counter: 2 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0081787
	speed: 0.0963s/iter; left time: 2070.7255s
	iters: 200, epoch: 5 | loss: 0.0077351
	speed: 0.0461s/iter; left time: 986.1043s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:11.12s
Steps: 225 | Train Loss: 0.0083025 Vali Loss: 0.0373596 Test Loss: 0.0464266
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0069760
	speed: 0.0920s/iter; left time: 1958.2338s
	iters: 200, epoch: 6 | loss: 0.0065775
	speed: 0.0505s/iter; left time: 1068.7359s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:11.56s
Steps: 225 | Train Loss: 0.0068311 Vali Loss: 0.0378817 Test Loss: 0.0463117
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0064354
	speed: 0.0926s/iter; left time: 1949.2758s
	iters: 200, epoch: 7 | loss: 0.0056448
	speed: 0.0511s/iter; left time: 1070.0455s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:11.55s
Steps: 225 | Train Loss: 0.0058802 Vali Loss: 0.0378618 Test Loss: 0.0464821
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0053293
	speed: 0.1029s/iter; left time: 2143.9633s
	iters: 200, epoch: 8 | loss: 0.0054496
	speed: 0.0506s/iter; left time: 1048.4218s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:11.68s
Steps: 225 | Train Loss: 0.0052071 Vali Loss: 0.0384322 Test Loss: 0.0474449
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0048091
	speed: 0.0915s/iter; left time: 1884.1641s
	iters: 200, epoch: 9 | loss: 0.0047850
	speed: 0.0495s/iter; left time: 1013.8719s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:11.43s
Steps: 225 | Train Loss: 0.0046842 Vali Loss: 0.0378488 Test Loss: 0.0462881
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0044565
	speed: 0.0980s/iter; left time: 1997.3757s
	iters: 200, epoch: 10 | loss: 0.0038844
	speed: 0.0497s/iter; left time: 1007.4344s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:11.51s
Steps: 225 | Train Loss: 0.0043068 Vali Loss: 0.0380081 Test Loss: 0.0465702
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0042491
	speed: 0.0916s/iter; left time: 1845.9031s
	iters: 200, epoch: 11 | loss: 0.0040506
	speed: 0.0505s/iter; left time: 1013.1239s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.58s
Steps: 225 | Train Loss: 0.0040233 Vali Loss: 0.0386904 Test Loss: 0.0469827
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0037805
	speed: 0.0998s/iter; left time: 1988.0510s
	iters: 200, epoch: 12 | loss: 0.0035495
	speed: 0.0503s/iter; left time: 998.0157s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:11.54s
Steps: 225 | Train Loss: 0.0037756 Vali Loss: 0.0378433 Test Loss: 0.0466710
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_168_96_DE_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.04425235465168953, rmse:0.21036243438720703, mae:0.14291603863239288, rse:0.744935929775238
Intermediate time for DE and pred_len 96: 00h:03m:09.12s
=== Starting experiments for pred_len: 168 ===

--- Running model for DE, pred_len=168 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='DE_168_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28801
val 6073
test 6073
	iters: 100, epoch: 1 | loss: 0.0361657
	speed: 0.0668s/iter; left time: 1496.7550s
	iters: 200, epoch: 1 | loss: 0.0303956
	speed: 0.0504s/iter; left time: 1124.5588s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.83s
Steps: 225 | Train Loss: 0.0362478 Vali Loss: 0.0360635 Test Loss: 0.0436179
Validation loss decreased (inf --> 0.036064).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0248308
	speed: 0.1080s/iter; left time: 2394.2190s
	iters: 200, epoch: 2 | loss: 0.0202720
	speed: 0.0493s/iter; left time: 1088.1554s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:12.10s
Steps: 225 | Train Loss: 0.0239077 Vali Loss: 0.0366986 Test Loss: 0.0456352
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0168566
	speed: 0.0965s/iter; left time: 2119.1420s
	iters: 200, epoch: 3 | loss: 0.0140941
	speed: 0.0500s/iter; left time: 1091.5463s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.64s
Steps: 225 | Train Loss: 0.0165090 Vali Loss: 0.0390133 Test Loss: 0.0496497
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0126213
	speed: 0.1044s/iter; left time: 2268.5671s
	iters: 200, epoch: 4 | loss: 0.0113191
	speed: 0.0512s/iter; left time: 1106.5469s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:11.81s
Steps: 225 | Train Loss: 0.0123056 Vali Loss: 0.0389968 Test Loss: 0.0487190
EarlyStopping counter: 3 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0098067
	speed: 0.0983s/iter; left time: 2114.0404s
	iters: 200, epoch: 5 | loss: 0.0088960
	speed: 0.0515s/iter; left time: 1102.7192s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:11.79s
Steps: 225 | Train Loss: 0.0096736 Vali Loss: 0.0396343 Test Loss: 0.0498428
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0080175
	speed: 0.1043s/iter; left time: 2220.0994s
	iters: 200, epoch: 6 | loss: 0.0072905
	speed: 0.0519s/iter; left time: 1099.7504s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:11.83s
Steps: 225 | Train Loss: 0.0079707 Vali Loss: 0.0397890 Test Loss: 0.0493932
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0067940
	speed: 0.0997s/iter; left time: 2098.0576s
	iters: 200, epoch: 7 | loss: 0.0064623
	speed: 0.0517s/iter; left time: 1084.0475s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:12.12s
Steps: 225 | Train Loss: 0.0069017 Vali Loss: 0.0401710 Test Loss: 0.0496219
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0063115
	speed: 0.1011s/iter; left time: 2105.5356s
	iters: 200, epoch: 8 | loss: 0.0056388
	speed: 0.0510s/iter; left time: 1057.4030s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:12.01s
Steps: 225 | Train Loss: 0.0060350 Vali Loss: 0.0401194 Test Loss: 0.0490433
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0054513
	speed: 0.1060s/iter; left time: 2184.4789s
	iters: 200, epoch: 9 | loss: 0.0053721
	speed: 0.0559s/iter; left time: 1147.0101s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:12.40s
Steps: 225 | Train Loss: 0.0054257 Vali Loss: 0.0398992 Test Loss: 0.0493147
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0049561
	speed: 0.0967s/iter; left time: 1970.4992s
	iters: 200, epoch: 10 | loss: 0.0048473
	speed: 0.0504s/iter; left time: 1022.6361s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:11.71s
Steps: 225 | Train Loss: 0.0049978 Vali Loss: 0.0399362 Test Loss: 0.0488129
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0048232
	speed: 0.1024s/iter; left time: 2064.3837s
	iters: 200, epoch: 11 | loss: 0.0045335
	speed: 0.0513s/iter; left time: 1027.8097s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.98s
Steps: 225 | Train Loss: 0.0046169 Vali Loss: 0.0395273 Test Loss: 0.0489856
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : DE_168_168_DE_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.0436178483068943, rmse:0.20884886384010315, mae:0.1491432934999466, rse:0.7397594451904297
Intermediate time for DE and pred_len 168: 00h:02m:58.36sIntermediate time for DE: 00h:09m:08.55s
=== Starting experiments for country: GB ===

=== Starting experiments for pred_len: 24 ===

--- Running model for GB, pred_len=24 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='GB_168_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6217
test 6217
	iters: 100, epoch: 1 | loss: 0.0218535
	speed: 0.0798s/iter; left time: 1796.0078s
	iters: 200, epoch: 1 | loss: 0.0183579
	speed: 0.0503s/iter; left time: 1127.6273s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.70s
Steps: 226 | Train Loss: 0.0221939 Vali Loss: 0.0227288 Test Loss: 0.0289717
Validation loss decreased (inf --> 0.022729).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0139320
	speed: 0.1053s/iter; left time: 2345.8819s
	iters: 200, epoch: 2 | loss: 0.0140528
	speed: 0.0499s/iter; left time: 1107.2148s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:11.49s
Steps: 226 | Train Loss: 0.0145776 Vali Loss: 0.0207217 Test Loss: 0.0265528
Validation loss decreased (0.022729 --> 0.020722).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0131557
	speed: 0.0922s/iter; left time: 2033.5530s
	iters: 200, epoch: 3 | loss: 0.0105842
	speed: 0.0506s/iter; left time: 1109.6279s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.60s
Steps: 226 | Train Loss: 0.0124672 Vali Loss: 0.0228512 Test Loss: 0.0287703
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0104724
	speed: 0.0913s/iter; left time: 1992.0171s
	iters: 200, epoch: 4 | loss: 0.0084868
	speed: 0.0460s/iter; left time: 999.2377s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:10.65s
Steps: 226 | Train Loss: 0.0099155 Vali Loss: 0.0245583 Test Loss: 0.0308842
EarlyStopping counter: 2 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0084019
	speed: 0.0905s/iter; left time: 1954.3459s
	iters: 200, epoch: 5 | loss: 0.0073181
	speed: 0.0482s/iter; left time: 1036.9286s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:11.05s
Steps: 226 | Train Loss: 0.0077618 Vali Loss: 0.0245623 Test Loss: 0.0308459
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0060664
	speed: 0.0866s/iter; left time: 1851.6961s
	iters: 200, epoch: 6 | loss: 0.0058028
	speed: 0.0477s/iter; left time: 1015.1849s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:10.98s
Steps: 226 | Train Loss: 0.0063329 Vali Loss: 0.0250764 Test Loss: 0.0328130
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0056493
	speed: 0.0916s/iter; left time: 1935.8874s
	iters: 200, epoch: 7 | loss: 0.0053948
	speed: 0.0483s/iter; left time: 1015.6603s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:11.21s
Steps: 226 | Train Loss: 0.0054284 Vali Loss: 0.0253184 Test Loss: 0.0329063
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0044056
	speed: 0.0885s/iter; left time: 1851.6830s
	iters: 200, epoch: 8 | loss: 0.0045532
	speed: 0.0468s/iter; left time: 974.7689s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:10.97s
Steps: 226 | Train Loss: 0.0048233 Vali Loss: 0.0254758 Test Loss: 0.0327160
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0040133
	speed: 0.0913s/iter; left time: 1888.9773s
	iters: 200, epoch: 9 | loss: 0.0042028
	speed: 0.0497s/iter; left time: 1024.3168s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:11.44s
Steps: 226 | Train Loss: 0.0044050 Vali Loss: 0.0256798 Test Loss: 0.0325368
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0039573
	speed: 0.0908s/iter; left time: 1857.6843s
	iters: 200, epoch: 10 | loss: 0.0041755
	speed: 0.0490s/iter; left time: 997.5784s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:11.33s
Steps: 226 | Train Loss: 0.0040621 Vali Loss: 0.0253594 Test Loss: 0.0324591
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0037444
	speed: 0.0904s/iter; left time: 1830.0027s
	iters: 200, epoch: 11 | loss: 0.0037421
	speed: 0.0502s/iter; left time: 1011.4231s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.47s
Steps: 226 | Train Loss: 0.0037959 Vali Loss: 0.0254270 Test Loss: 0.0329862
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0035340
	speed: 0.0960s/iter; left time: 1922.0715s
	iters: 200, epoch: 12 | loss: 0.0034475
	speed: 0.0497s/iter; left time: 990.1470s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:11.53s
Steps: 226 | Train Loss: 0.0035778 Vali Loss: 0.0253695 Test Loss: 0.0325746
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : GB_168_24_GB_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.026552753522992134, rmse:0.16295015811920166, mae:0.10944870114326477, rse:0.5621318817138672
Intermediate time for GB and pred_len 24: 00h:03m:02.28s
=== Starting experiments for pred_len: 96 ===

--- Running model for GB, pred_len=96 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='GB_168_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6145
test 6145
	iters: 100, epoch: 1 | loss: 0.0288654
	speed: 0.0655s/iter; left time: 1468.2221s
	iters: 200, epoch: 1 | loss: 0.0257712
	speed: 0.0481s/iter; left time: 1071.9359s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.49s
Steps: 225 | Train Loss: 0.0295441 Vali Loss: 0.0322599 Test Loss: 0.0463921
Validation loss decreased (inf --> 0.032260).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0204241
	speed: 0.1087s/iter; left time: 2411.0143s
	iters: 200, epoch: 2 | loss: 0.0181788
	speed: 0.0489s/iter; left time: 1079.3847s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:11.23s
Steps: 225 | Train Loss: 0.0211684 Vali Loss: 0.0359143 Test Loss: 0.0490593
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0145193
	speed: 0.0933s/iter; left time: 2048.7223s
	iters: 200, epoch: 3 | loss: 0.0129500
	speed: 0.0498s/iter; left time: 1089.0880s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.41s
Steps: 225 | Train Loss: 0.0148745 Vali Loss: 0.0380365 Test Loss: 0.0511157
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0108255
	speed: 0.0910s/iter; left time: 1977.3957s
	iters: 200, epoch: 4 | loss: 0.0103050
	speed: 0.0481s/iter; left time: 1039.3682s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:11.17s
Steps: 225 | Train Loss: 0.0110534 Vali Loss: 0.0386122 Test Loss: 0.0516633
EarlyStopping counter: 3 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0083075
	speed: 0.0987s/iter; left time: 2121.2651s
	iters: 200, epoch: 5 | loss: 0.0079974
	speed: 0.0550s/iter; left time: 1176.5774s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:12.17s
Steps: 225 | Train Loss: 0.0087882 Vali Loss: 0.0387466 Test Loss: 0.0523526
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0085979
	speed: 0.0950s/iter; left time: 2020.9800s
	iters: 200, epoch: 6 | loss: 0.0070879
	speed: 0.0497s/iter; left time: 1051.8523s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:11.51s
Steps: 225 | Train Loss: 0.0073469 Vali Loss: 0.0378753 Test Loss: 0.0519166
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0068098
	speed: 0.0964s/iter; left time: 2029.8703s
	iters: 200, epoch: 7 | loss: 0.0062420
	speed: 0.0516s/iter; left time: 1080.4960s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:11.80s
Steps: 225 | Train Loss: 0.0064157 Vali Loss: 0.0382622 Test Loss: 0.0509550
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0059088
	speed: 0.0940s/iter; left time: 1957.8672s
	iters: 200, epoch: 8 | loss: 0.0055143
	speed: 0.0541s/iter; left time: 1121.3947s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:12.05s
Steps: 225 | Train Loss: 0.0057242 Vali Loss: 0.0377223 Test Loss: 0.0509155
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0057496
	speed: 0.0990s/iter; left time: 2039.3611s
	iters: 200, epoch: 9 | loss: 0.0049260
	speed: 0.0509s/iter; left time: 1042.8847s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:11.63s
Steps: 225 | Train Loss: 0.0052227 Vali Loss: 0.0377632 Test Loss: 0.0501606
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0051351
	speed: 0.0910s/iter; left time: 1854.3741s
	iters: 200, epoch: 10 | loss: 0.0045289
	speed: 0.0529s/iter; left time: 1072.6055s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:11.88s
Steps: 225 | Train Loss: 0.0048293 Vali Loss: 0.0375795 Test Loss: 0.0502433
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0044681
	speed: 0.0955s/iter; left time: 1923.7912s
	iters: 200, epoch: 11 | loss: 0.0045333
	speed: 0.0506s/iter; left time: 1015.1115s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.96s
Steps: 225 | Train Loss: 0.0044935 Vali Loss: 0.0373866 Test Loss: 0.0508047
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : GB_168_96_GB_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.0463920496404171, rmse:0.21538813412189484, mae:0.1513613760471344, rse:0.7448421716690063
Intermediate time for GB and pred_len 96: 00h:02m:50.20s
=== Starting experiments for pred_len: 168 ===

--- Running model for GB, pred_len=168 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='GB_168_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28801
val 6073
test 6073
	iters: 100, epoch: 1 | loss: 0.0311655
	speed: 0.0808s/iter; left time: 1811.0991s
	iters: 200, epoch: 1 | loss: 0.0268520
	speed: 0.0476s/iter; left time: 1062.3274s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:11.50s
Steps: 225 | Train Loss: 0.0315050 Vali Loss: 0.0344559 Test Loss: 0.0494408
Validation loss decreased (inf --> 0.034456).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0232563
	speed: 0.1223s/iter; left time: 2712.4060s
	iters: 200, epoch: 2 | loss: 0.0201319
	speed: 0.0510s/iter; left time: 1125.2679s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:11.63s
Steps: 225 | Train Loss: 0.0228723 Vali Loss: 0.0356305 Test Loss: 0.0490330
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0164316
	speed: 0.0927s/iter; left time: 2035.5572s
	iters: 200, epoch: 3 | loss: 0.0143577
	speed: 0.0530s/iter; left time: 1157.0310s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:11.93s
Steps: 225 | Train Loss: 0.0164182 Vali Loss: 0.0385980 Test Loss: 0.0549292
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0119379
	speed: 0.1062s/iter; left time: 2306.9108s
	iters: 200, epoch: 4 | loss: 0.0117706
	speed: 0.0515s/iter; left time: 1113.7389s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:11.76s
Steps: 225 | Train Loss: 0.0123429 Vali Loss: 0.0391280 Test Loss: 0.0544823
EarlyStopping counter: 3 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0101041
	speed: 0.0958s/iter; left time: 2059.3053s
	iters: 200, epoch: 5 | loss: 0.0096695
	speed: 0.0529s/iter; left time: 1132.9288s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:12.33s
Steps: 225 | Train Loss: 0.0098903 Vali Loss: 0.0375995 Test Loss: 0.0534631
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0084312
	speed: 0.1035s/iter; left time: 2202.9476s
	iters: 200, epoch: 6 | loss: 0.0077957
	speed: 0.0535s/iter; left time: 1132.6132s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:12.15s
Steps: 225 | Train Loss: 0.0083932 Vali Loss: 0.0387505 Test Loss: 0.0536841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0073348
	speed: 0.0960s/iter; left time: 2019.8842s
	iters: 200, epoch: 7 | loss: 0.0067890
	speed: 0.0512s/iter; left time: 1072.1064s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:11.94s
Steps: 225 | Train Loss: 0.0073746 Vali Loss: 0.0379722 Test Loss: 0.0532853
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0062798
	speed: 0.0980s/iter; left time: 2040.6019s
	iters: 200, epoch: 8 | loss: 0.0067243
	speed: 0.0510s/iter; left time: 1057.5884s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:11.74s
Steps: 225 | Train Loss: 0.0065557 Vali Loss: 0.0379420 Test Loss: 0.0540116
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0063439
	speed: 0.1052s/iter; left time: 2167.4040s
	iters: 200, epoch: 9 | loss: 0.0058767
	speed: 0.0527s/iter; left time: 1080.9459s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:12.14s
Steps: 225 | Train Loss: 0.0059587 Vali Loss: 0.0380186 Test Loss: 0.0534061
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0056824
	speed: 0.0955s/iter; left time: 1945.2567s
	iters: 200, epoch: 10 | loss: 0.0056616
	speed: 0.0567s/iter; left time: 1149.8234s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:12.61s
Steps: 225 | Train Loss: 0.0055202 Vali Loss: 0.0375020 Test Loss: 0.0525390
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0051364
	speed: 0.1039s/iter; left time: 2093.7990s
	iters: 200, epoch: 11 | loss: 0.0053312
	speed: 0.0511s/iter; left time: 1024.1143s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:11.96s
Steps: 225 | Train Loss: 0.0051564 Vali Loss: 0.0378486 Test Loss: 0.0529896
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : GB_168_168_GB_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.04944076016545296, rmse:0.2223527878522873, mae:0.15743298828601837, rse:0.7709290385246277
Intermediate time for GB and pred_len 168: 00h:03m:02.16sIntermediate time for GB: 00h:08m:54.64s
=== Starting experiments for country: ES ===

=== Starting experiments for pred_len: 24 ===

--- Running model for ES, pred_len=24 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='ES_168_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=24, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28945
val 6217
test 6217
	iters: 100, epoch: 1 | loss: 0.0224124
	speed: 0.0455s/iter; left time: 1024.1005s
	iters: 200, epoch: 1 | loss: 0.0196115
	speed: 0.0171s/iter; left time: 382.8865s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:04.61s
Steps: 226 | Train Loss: 0.0269212 Vali Loss: 0.0150415 Test Loss: 0.0203113
Validation loss decreased (inf --> 0.015041).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0107510
	speed: 0.0480s/iter; left time: 1068.4218s
	iters: 200, epoch: 2 | loss: 0.0087262
	speed: 0.0191s/iter; left time: 423.5362s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:04.57s
Steps: 226 | Train Loss: 0.0108435 Vali Loss: 0.0091117 Test Loss: 0.0119008
Validation loss decreased (0.015041 --> 0.009112).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0088294
	speed: 0.0500s/iter; left time: 1102.0087s
	iters: 200, epoch: 3 | loss: 0.0100748
	speed: 0.0236s/iter; left time: 518.3261s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:04.86s
Steps: 226 | Train Loss: 0.0088790 Vali Loss: 0.0088156 Test Loss: 0.0120870
Validation loss decreased (0.009112 --> 0.008816).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0087583
	speed: 0.0492s/iter; left time: 1073.7082s
	iters: 200, epoch: 4 | loss: 0.0078426
	speed: 0.0201s/iter; left time: 437.1992s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:04.78s
Steps: 226 | Train Loss: 0.0082961 Vali Loss: 0.0084341 Test Loss: 0.0115712
Validation loss decreased (0.008816 --> 0.008434).  Saving model ...
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0082415
	speed: 0.0533s/iter; left time: 1151.3912s
	iters: 200, epoch: 5 | loss: 0.0077887
	speed: 0.0164s/iter; left time: 352.8795s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:04.57s
Steps: 226 | Train Loss: 0.0077767 Vali Loss: 0.0086849 Test Loss: 0.0117333
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0078185
	speed: 0.0463s/iter; left time: 988.9833s
	iters: 200, epoch: 6 | loss: 0.0070359
	speed: 0.0164s/iter; left time: 348.8947s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:04.35s
Steps: 226 | Train Loss: 0.0073781 Vali Loss: 0.0087118 Test Loss: 0.0117897
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0074897
	speed: 0.0465s/iter; left time: 982.5427s
	iters: 200, epoch: 7 | loss: 0.0068850
	speed: 0.0157s/iter; left time: 331.0021s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:04.03s
Steps: 226 | Train Loss: 0.0069519 Vali Loss: 0.0086680 Test Loss: 0.0120939
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0069666
	speed: 0.0477s/iter; left time: 997.2415s
	iters: 200, epoch: 8 | loss: 0.0063023
	speed: 0.0164s/iter; left time: 341.8813s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:04.04s
Steps: 226 | Train Loss: 0.0065128 Vali Loss: 0.0088269 Test Loss: 0.0124773
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0064918
	speed: 0.0451s/iter; left time: 933.0429s
	iters: 200, epoch: 9 | loss: 0.0061917
	speed: 0.0164s/iter; left time: 337.4504s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:04.40s
Steps: 226 | Train Loss: 0.0061017 Vali Loss: 0.0089658 Test Loss: 0.0123164
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0054921
	speed: 0.0469s/iter; left time: 959.8101s
	iters: 200, epoch: 10 | loss: 0.0062819
	speed: 0.0219s/iter; left time: 445.3181s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:04.75s
Steps: 226 | Train Loss: 0.0057397 Vali Loss: 0.0093366 Test Loss: 0.0131734
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0056405
	speed: 0.0430s/iter; left time: 870.6743s
	iters: 200, epoch: 11 | loss: 0.0046495
	speed: 0.0235s/iter; left time: 472.7532s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:04.80s
Steps: 226 | Train Loss: 0.0054258 Vali Loss: 0.0093886 Test Loss: 0.0132575
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0050808
	speed: 0.0436s/iter; left time: 871.9838s
	iters: 200, epoch: 12 | loss: 0.0050846
	speed: 0.0249s/iter; left time: 495.5559s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:04.98s
Steps: 226 | Train Loss: 0.0051052 Vali Loss: 0.0094989 Test Loss: 0.0135827
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.874204890000001e-05
	iters: 100, epoch: 13 | loss: 0.0045714
	speed: 0.0455s/iter; left time: 900.1137s
	iters: 200, epoch: 13 | loss: 0.0046720
	speed: 0.0236s/iter; left time: 464.5946s
-------------------------------------------------------------------------------------
Epoch: 13
Cost time: 00h:00m:05.50s
Steps: 226 | Train Loss: 0.0048812 Vali Loss: 0.0094084 Test Loss: 0.0140043
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.486784401000001e-05
	iters: 100, epoch: 14 | loss: 0.0046412
	speed: 0.0451s/iter; left time: 881.5763s
	iters: 200, epoch: 14 | loss: 0.0043698
	speed: 0.0204s/iter; left time: 396.6475s
-------------------------------------------------------------------------------------
Epoch: 14
Cost time: 00h:00m:04.77s
Steps: 226 | Train Loss: 0.0046494 Vali Loss: 0.0096403 Test Loss: 0.0141297
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : ES_168_24_ES_PatchTST_custom_ftM_sl168_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6217
Scaled mse:0.01157116424292326, rmse:0.10756934434175491, mae:0.06930112838745117, rse:0.31656357645988464
Intermediate time for ES and pred_len 24: 00h:01m:44.69s
=== Starting experiments for pred_len: 96 ===

--- Running model for ES, pred_len=96 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='ES_168_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=96, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28873
val 6145
test 6145
	iters: 100, epoch: 1 | loss: 0.0274620
	speed: 0.0403s/iter; left time: 903.6093s
	iters: 200, epoch: 1 | loss: 0.0233340
	speed: 0.0168s/iter; left time: 373.9195s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:05.16s
Steps: 225 | Train Loss: 0.0311444 Vali Loss: 0.0205581 Test Loss: 0.0278780
Validation loss decreased (inf --> 0.020558).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0156541
	speed: 0.0540s/iter; left time: 1198.5014s
	iters: 200, epoch: 2 | loss: 0.0156230
	speed: 0.0168s/iter; left time: 371.3417s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:04.84s
Steps: 225 | Train Loss: 0.0170196 Vali Loss: 0.0159781 Test Loss: 0.0208035
Validation loss decreased (0.020558 --> 0.015978).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0142626
	speed: 0.0513s/iter; left time: 1126.3920s
	iters: 200, epoch: 3 | loss: 0.0143844
	speed: 0.0165s/iter; left time: 360.5415s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:04.48s
Steps: 225 | Train Loss: 0.0147565 Vali Loss: 0.0153022 Test Loss: 0.0208395
Validation loss decreased (0.015978 --> 0.015302).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0129233
	speed: 0.0488s/iter; left time: 1059.6288s
	iters: 200, epoch: 4 | loss: 0.0128198
	speed: 0.0164s/iter; left time: 354.0143s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:04.52s
Steps: 225 | Train Loss: 0.0131599 Vali Loss: 0.0156655 Test Loss: 0.0221003
EarlyStopping counter: 1 out of 10
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0118474
	speed: 0.0515s/iter; left time: 1107.4777s
	iters: 200, epoch: 5 | loss: 0.0098400
	speed: 0.0174s/iter; left time: 372.8807s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:04.54s
Steps: 225 | Train Loss: 0.0113209 Vali Loss: 0.0163465 Test Loss: 0.0240946
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0092215
	speed: 0.0470s/iter; left time: 999.8698s
	iters: 200, epoch: 6 | loss: 0.0096176
	speed: 0.0162s/iter; left time: 342.3958s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:04.46s
Steps: 225 | Train Loss: 0.0098619 Vali Loss: 0.0163042 Test Loss: 0.0241483
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0097937
	speed: 0.0499s/iter; left time: 1050.0762s
	iters: 200, epoch: 7 | loss: 0.0080033
	speed: 0.0164s/iter; left time: 343.5197s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:04.32s
Steps: 225 | Train Loss: 0.0087896 Vali Loss: 0.0167270 Test Loss: 0.0244736
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0076690
	speed: 0.0485s/iter; left time: 1010.0910s
	iters: 200, epoch: 8 | loss: 0.0073171
	speed: 0.0171s/iter; left time: 355.4400s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:04.62s
Steps: 225 | Train Loss: 0.0080117 Vali Loss: 0.0169650 Test Loss: 0.0243798
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0070846
	speed: 0.0461s/iter; left time: 950.3532s
	iters: 200, epoch: 9 | loss: 0.0075421
	speed: 0.0170s/iter; left time: 349.1597s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:04.58s
Steps: 225 | Train Loss: 0.0073967 Vali Loss: 0.0172498 Test Loss: 0.0247350
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0073015
	speed: 0.0469s/iter; left time: 955.3955s
	iters: 200, epoch: 10 | loss: 0.0065840
	speed: 0.0163s/iter; left time: 330.6696s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:04.68s
Steps: 225 | Train Loss: 0.0069268 Vali Loss: 0.0177244 Test Loss: 0.0248713
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0064723
	speed: 0.0462s/iter; left time: 931.3291s
	iters: 200, epoch: 11 | loss: 0.0066135
	speed: 0.0164s/iter; left time: 329.7885s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:04.82s
Steps: 225 | Train Loss: 0.0065312 Vali Loss: 0.0173557 Test Loss: 0.0249669
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0063455
	speed: 0.0480s/iter; left time: 956.3885s
	iters: 200, epoch: 12 | loss: 0.0061154
	speed: 0.0162s/iter; left time: 321.4485s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:04.75s
Steps: 225 | Train Loss: 0.0062166 Vali Loss: 0.0179732 Test Loss: 0.0252495
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.874204890000001e-05
	iters: 100, epoch: 13 | loss: 0.0060675
	speed: 0.0479s/iter; left time: 943.5563s
	iters: 200, epoch: 13 | loss: 0.0061311
	speed: 0.0177s/iter; left time: 346.6826s
-------------------------------------------------------------------------------------
Epoch: 13
Cost time: 00h:00m:04.90s
Steps: 225 | Train Loss: 0.0059431 Vali Loss: 0.0178869 Test Loss: 0.0250740
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : ES_168_96_ES_PatchTST_custom_ftM_sl168_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6145
Scaled mse:0.020839489996433258, rmse:0.14435888826847076, mae:0.09703951328992844, rse:0.42408299446105957
Intermediate time for ES and pred_len 96: 00h:01m:33.04s
=== Starting experiments for pred_len: 168 ===

--- Running model for ES, pred_len=168 ---
Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='ES_168_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=168, label_len=48, pred_len=168, inverse=False, loss_fnc='MSE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 28801
val 6073
test 6073
	iters: 100, epoch: 1 | loss: 0.0277074
	speed: 0.0478s/iter; left time: 1070.9026s
	iters: 200, epoch: 1 | loss: 0.0247151
	speed: 0.0247s/iter; left time: 551.4464s
-------------------------------------------------------------------------------------
Epoch: 1
Cost time: 00h:00m:05.26s
Steps: 225 | Train Loss: 0.0327857 Vali Loss: 0.0228405 Test Loss: 0.0301658
Validation loss decreased (inf --> 0.022841).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.0182268
	speed: 0.0600s/iter; left time: 1330.2683s
	iters: 200, epoch: 2 | loss: 0.0183971
	speed: 0.0170s/iter; left time: 375.2161s
-------------------------------------------------------------------------------------
Epoch: 2
Cost time: 00h:00m:04.79s
Steps: 225 | Train Loss: 0.0186799 Vali Loss: 0.0179325 Test Loss: 0.0228984
Validation loss decreased (0.022841 --> 0.017933).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.0152040
	speed: 0.0564s/iter; left time: 1237.5159s
	iters: 200, epoch: 3 | loss: 0.0145845
	speed: 0.0168s/iter; left time: 367.2814s
-------------------------------------------------------------------------------------
Epoch: 3
Cost time: 00h:00m:04.89s
Steps: 225 | Train Loss: 0.0160117 Vali Loss: 0.0180276 Test Loss: 0.0232034
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0001
	iters: 100, epoch: 4 | loss: 0.0137587
	speed: 0.0492s/iter; left time: 1069.3646s
	iters: 200, epoch: 4 | loss: 0.0131766
	speed: 0.0162s/iter; left time: 350.1691s
-------------------------------------------------------------------------------------
Epoch: 4
Cost time: 00h:00m:04.73s
Steps: 225 | Train Loss: 0.0140758 Vali Loss: 0.0176767 Test Loss: 0.0228745
Validation loss decreased (0.017933 --> 0.017677).  Saving model ...
Updating learning rate to 9e-05
	iters: 100, epoch: 5 | loss: 0.0129491
	speed: 0.0508s/iter; left time: 1091.4610s
	iters: 200, epoch: 5 | loss: 0.0117705
	speed: 0.0172s/iter; left time: 368.1131s
-------------------------------------------------------------------------------------
Epoch: 5
Cost time: 00h:00m:04.62s
Steps: 225 | Train Loss: 0.0123849 Vali Loss: 0.0186744 Test Loss: 0.0246194
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.1e-05
	iters: 100, epoch: 6 | loss: 0.0110090
	speed: 0.0491s/iter; left time: 1044.3217s
	iters: 200, epoch: 6 | loss: 0.0100024
	speed: 0.0163s/iter; left time: 345.8416s
-------------------------------------------------------------------------------------
Epoch: 6
Cost time: 00h:00m:04.60s
Steps: 225 | Train Loss: 0.0109879 Vali Loss: 0.0187169 Test Loss: 0.0243321
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.290000000000001e-05
	iters: 100, epoch: 7 | loss: 0.0105492
	speed: 0.0516s/iter; left time: 1087.0034s
	iters: 200, epoch: 7 | loss: 0.0092284
	speed: 0.0179s/iter; left time: 375.0773s
-------------------------------------------------------------------------------------
Epoch: 7
Cost time: 00h:00m:04.87s
Steps: 225 | Train Loss: 0.0099143 Vali Loss: 0.0193814 Test Loss: 0.0243870
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.561e-05
	iters: 100, epoch: 8 | loss: 0.0092586
	speed: 0.0525s/iter; left time: 1094.0169s
	iters: 200, epoch: 8 | loss: 0.0089153
	speed: 0.0168s/iter; left time: 349.1782s
-------------------------------------------------------------------------------------
Epoch: 8
Cost time: 00h:00m:04.69s
Steps: 225 | Train Loss: 0.0090489 Vali Loss: 0.0190883 Test Loss: 0.0252209
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.904900000000001e-05
	iters: 100, epoch: 9 | loss: 0.0082056
	speed: 0.0545s/iter; left time: 1123.7317s
	iters: 200, epoch: 9 | loss: 0.0080735
	speed: 0.0174s/iter; left time: 356.2632s
-------------------------------------------------------------------------------------
Epoch: 9
Cost time: 00h:00m:04.53s
Steps: 225 | Train Loss: 0.0083603 Vali Loss: 0.0194013 Test Loss: 0.0252273
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.3144100000000005e-05
	iters: 100, epoch: 10 | loss: 0.0082202
	speed: 0.0549s/iter; left time: 1119.6085s
	iters: 200, epoch: 10 | loss: 0.0073720
	speed: 0.0169s/iter; left time: 343.1842s
-------------------------------------------------------------------------------------
Epoch: 10
Cost time: 00h:00m:04.23s
Steps: 225 | Train Loss: 0.0078443 Vali Loss: 0.0196141 Test Loss: 0.0257372
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.782969000000001e-05
	iters: 100, epoch: 11 | loss: 0.0069887
	speed: 0.0570s/iter; left time: 1148.6955s
	iters: 200, epoch: 11 | loss: 0.0071465
	speed: 0.0172s/iter; left time: 343.9165s
-------------------------------------------------------------------------------------
Epoch: 11
Cost time: 00h:00m:04.67s
Steps: 225 | Train Loss: 0.0073931 Vali Loss: 0.0199717 Test Loss: 0.0256369
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.304672100000001e-05
	iters: 100, epoch: 12 | loss: 0.0070513
	speed: 0.0495s/iter; left time: 986.7180s
	iters: 200, epoch: 12 | loss: 0.0067190
	speed: 0.0182s/iter; left time: 360.8075s
-------------------------------------------------------------------------------------
Epoch: 12
Cost time: 00h:00m:04.45s
Steps: 225 | Train Loss: 0.0070412 Vali Loss: 0.0200850 Test Loss: 0.0260791
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.874204890000001e-05
	iters: 100, epoch: 13 | loss: 0.0065328
	speed: 0.0513s/iter; left time: 1010.1836s
	iters: 200, epoch: 13 | loss: 0.0064198
	speed: 0.0168s/iter; left time: 329.5841s
-------------------------------------------------------------------------------------
Epoch: 13
Cost time: 00h:00m:04.41s
Steps: 225 | Train Loss: 0.0067512 Vali Loss: 0.0202014 Test Loss: 0.0263437
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.486784401000001e-05
	iters: 100, epoch: 14 | loss: 0.0063799
	speed: 0.0555s/iter; left time: 1080.7838s
	iters: 200, epoch: 14 | loss: 0.0066022
	speed: 0.0211s/iter; left time: 408.7836s
-------------------------------------------------------------------------------------
Epoch: 14
Cost time: 00h:00m:05.02s
Steps: 225 | Train Loss: 0.0064871 Vali Loss: 0.0201594 Test Loss: 0.0262867
EarlyStopping counter: 10 out of 10
Early stopping
-------------------------------------------------------------------------------------
>>>>>>>testing : ES_168_168_ES_PatchTST_custom_ftM_sl168_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 6073
Scaled mse:0.02287455089390278, rmse:0.15124334394931793, mae:0.10218845307826996, rse:0.4443393349647522
Intermediate time for ES and pred_len 168: 00h:01m:52.09sIntermediate time for ES: 00h:05m:09.83sTotal time: 00h:23m:13.02s